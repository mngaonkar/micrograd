{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5e86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "from IPython import display\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5629e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ab2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for Jupyter Notebook to find the graphviz executables\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\"/opt/homebrew/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eba97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for gradient calculation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-10, 10, 0.5)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cde3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c90bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = -2\n",
    "c = 1\n",
    "d1 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c + h\n",
    "d2 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dc_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dc_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d78e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -5.000002\n",
      "da_dy =  -2.000000000279556\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "a = a + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"da_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ed6158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.9999970000000005\n",
      "db_dy =  2.9999999995311555\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "b = b + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"db_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f10ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dab_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "d2 = a*b + h + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dab_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c68b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    \"\"\" Basic class to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "        else:\n",
    "            raise ValueError(\"Can only add Value to Value\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077e5615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d._prev = (Value(data=-6), Value(data=1)) d = -5\n"
     ]
    }
   ],
   "source": [
    "a = Value(3, label=\"a\")\n",
    "b = Value(-2, label=\"b\")\n",
    "c = Value(1, label=\"c\")\n",
    "d = a*b + c; d.label = \"d\"\n",
    "print(f\"d._prev = {d._prev} d = {d.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db81115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(root):\n",
    "    \"\"\" Vibe codded and it works! \"\"\"\n",
    "    # Initialize a directed graph\n",
    "    dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})  # Left-to-right layout\n",
    "    \n",
    "    def build_graph(node, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        \n",
    "        # Skip if node already visited to avoid cycles\n",
    "        if id(node) in visited:\n",
    "            return\n",
    "        visited.add(id(node))\n",
    "        \n",
    "        # Add node to the graph\n",
    "        node_id = str(id(node))\n",
    "        dot.node(node_id, f\"{{ {node.label} | data = {node.data} grad={node.grad} }}\", shape='record')\n",
    "        \n",
    "        # If node has an operation, create an operation node\n",
    "        if node._op:\n",
    "            op_id = f\"{node_id}_op\"\n",
    "            dot.node(op_id, node._op, shape='circle')\n",
    "            dot.edge(op_id, node_id)  # Edge from operation to result\n",
    "        \n",
    "            # Recursively process children\n",
    "            for child in node._prev:\n",
    "                child_id = str(id(child))\n",
    "                build_graph(child, visited)\n",
    "                dot.edge(child_id, op_id)  # Edge from child to operation\n",
    "    \n",
    "    # Build the graph starting from the root\n",
    "    build_graph(root)\n",
    "    \n",
    "    # Render and display the graph\n",
    "    dot.render('computation_graph', view=True, cleanup=True)\n",
    "    \n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c181f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98dd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ed37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142981514304\n"
     ]
    }
   ],
   "source": [
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec8210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70612029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daba22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "922f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_dn = 1 - math.tanh(o.data)**2\n",
    "y.grad = do_dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72a71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a71919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1_x2w2.grad = y.grad\n",
    "b.grad = y.grad\n",
    "x1w1.grad = x1w1_x2w2.grad\n",
    "x2w2.grad = x1w1_x2w2.grad\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef9473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = x1w1.grad * w1.data\n",
    "x2.grad = x2w2.grad * w2.data\n",
    "w1.grad = x1w1.grad * x1.data\n",
    "w2.grad = x2w2.grad * x2.data\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "d7edad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement generic backpropagation\n",
    "class Value():\n",
    "    \"\"\" Complete class with backprop to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    visited = set()  # Set to keep track of visited nodes during backpropagation\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []  # Topological order of nodes for backpropagation\n",
    "        def build_topo(v, visited=None):\n",
    "            if visited is None:\n",
    "                visited = set()\n",
    "            if id(v) not in visited:\n",
    "                visited.add(id(v))\n",
    "                for child in v._prev:\n",
    "                    build_topo(child, visited)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for item in reversed(topo):\n",
    "            item._backward()\n",
    "            \n",
    "    def _backward(self):\n",
    "        \"\"\" Perform backpropagation to compute gradients. \"\"\"\n",
    "        logger.debug(f\"Backward pass for node: {self.label}, op: {self._op}, data: {self.data}, grad: {self.grad}\")\n",
    "        # For addition operation, local gradient is 1 for each child hence gradient of the child with respect\n",
    "        # to the output is 1 * self gradient.\n",
    "        # Note, we need to accumulate gradients for each child and not simply overwrite them.\n",
    "        if self._op == '+':\n",
    "            for child in self._prev:\n",
    "                child.grad += self.grad\n",
    "\n",
    "        # For multiplication operation, local gradient is the value of the other child hence\n",
    "        # gradient of the child with respect to the output is self.grad * other child's value.\n",
    "        elif self._op == '*':\n",
    "            self._prev[0].grad += self.grad * self._prev[1].data\n",
    "            self._prev[1].grad += self.grad * self._prev[0].data\n",
    "\n",
    "        elif self._op == '/':\n",
    "            # For division operation, local gradient is 1 / other child's value hence\n",
    "            # gradient of the child with respect to the output is self.grad * (1 / other child's value).\n",
    "            self._prev[0].grad += self.grad / self._prev[1].data\n",
    "            self._prev[1].grad += -self.grad * (self._prev[0].data / (self._prev[1].data ** 2))\n",
    "\n",
    "        # For power operation, local gradient is power * base^(power-1) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == '**':\n",
    "            base = self._prev[0].data\n",
    "            power = self._prev[1].data\n",
    "            self._prev[0].grad += self.grad * power * (base ** (power - 1))\n",
    "\n",
    "        # For subtraction operation, local gradient is 1 for the first child and -1 for the second child\n",
    "        # hence gradient of the first child with respect to the output is self.grad * 1 and for the second child\n",
    "        # it is self.grad * -1.\n",
    "        elif self._op == '-':\n",
    "            self._prev[0].grad += self.grad  # First child\n",
    "            self._prev[1].grad += -self.grad  # Second child\n",
    "\n",
    "        # For tanh operation, local gradient is 1 - tanh^2(self.data) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == 'tanh':\n",
    "            logger.debug(f\"tanh: self.data = {self.data}, self.grad = {self.grad}\")\n",
    "            self._prev[0].grad += self.grad * (1 - np.tanh(self._prev[0].data)**2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data - other.data, _children=(self, other), _op='-')\n",
    "        else:\n",
    "            raise ValueError(\"Can only subtract Value from Value\")\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "        \n",
    "    def __pow__(self, power):\n",
    "        return Value(self.data ** power, _children=(self,Value(power)), _op='**')\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "de7dc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "b1415a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "65eb5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0\n",
    "\n",
    "o.visited = set()  # Reset visited set for each backward pass\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "b9b0f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "160da944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142868995667\n"
     ]
    }
   ],
   "source": [
    "# Verfiy with PyTorch\n",
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2.0])\n",
    "x2 = torch.Tensor([3.0])\n",
    "w1 = torch.Tensor([0.5])\n",
    "w2 = torch.Tensor([-1.5])\n",
    "b = torch.Tensor([1.0])\n",
    "x1.requires_grad = True\n",
    "x2.requires_grad = True\n",
    "w1.requires_grad = True\n",
    "w2.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "y = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(y)\n",
    "\n",
    "print(f\"o = {o.item()}\")\n",
    "\n",
    "o.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "182b150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.grad = 0.013296124525368214\n",
      "x2.grad = -0.039888374507427216\n",
      "w1.grad = 0.053184498101472855\n",
      "w2.grad = 0.07977674901485443\n",
      "b.grad = 0.026592249050736427\n"
     ]
    }
   ],
   "source": [
    "print(f\"x1.grad = {x1.grad.item()}\") \n",
    "print(f\"x2.grad = {x2.grad.item()}\") \n",
    "print(f\"w1.grad = {w1.grad.item()}\")\n",
    "print(f\"w2.grad = {w2.grad.item()}\")\n",
    "print(f\"b.grad = {b.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "f1702ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "class N():\n",
    "    \"\"\" Class to represent a single neuron with forward and backward pass. \"\"\"\n",
    "    def __init__(self, input_size, label=\"\"):\n",
    "        self.input_size = input_size\n",
    "        self.weights = [Value(random.uniform(-1, 1), label = f\"{label} w{i}\") for i in range(input_size)]\n",
    "        self.b = Value(random.uniform(-1, 1), label=f\"{label} b\")  # Bias term\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.b]  # Return all parameters (weights and bias)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None) -> Value:\n",
    "        \"\"\" Forward pass for the neuron. \"\"\"\n",
    "        assert len(input) == self.input_size, f\"Input size {len(input)} does not match expected size {self.input_size}\"\n",
    "        wx = [w*x for w, x in zip(self.weights, input)]\n",
    "        wx_sum = Value(0.0)  # Initialize sum of weighted inputs\n",
    "        for item in wx:\n",
    "            wx_sum += item  # Sum the weighted inputs\n",
    "\n",
    "        wx_sum = wx_sum + self.b\n",
    "        if act_fn is None:\n",
    "            return wx_sum\n",
    "        elif act_fn == 'tanh':\n",
    "            return wx_sum.tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {act_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "95f55a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -2.742169638094225\n"
     ]
    }
   ],
   "source": [
    "n = N(2)  # Create a neuron with 2 inputs\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "\n",
    "o = n([x1, x2])\n",
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "f5d28c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\" Class to represent a layer of neurons. \"\"\"\n",
    "    def __init__(self, input, output, label=\"\"):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.neurons = [N(input, label=f\"{label} Neuron {i}\") for i in range(output)]\n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for n in self.neurons:\n",
    "            parameters.extend(n.parameters())  # Collect parameters from each neuron\n",
    "        return parameters\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None):\n",
    "        \"\"\" Forward pass for the layer. \"\"\"\n",
    "        outputs = [n(input, act_fn) for n in self.neurons]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "29894ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class NN():\n",
    "    \"\"\" Class to represent a simple neural network with hidden layers. \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                 hidden_layer_num: int, \n",
    "                 hidden_layer_size: int, \n",
    "                 output_size: int):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_num = hidden_layer_num\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.forward_hook = None  # Hook for forward pass\n",
    "\n",
    "        self.layers = []\n",
    "        for i in range(hidden_layer_num):\n",
    "            if i == 0:\n",
    "                # First layer takes the input size\n",
    "                self.layers.append(Layer(input_size, hidden_layer_size, label=f\"Layer {i}\"))\n",
    "            elif i == hidden_layer_num - 1:\n",
    "                # Last layer is the output layer, use output_size\n",
    "                self.layers.append(Layer(hidden_layer_size, output_size, label=f\"Layer {i}\"))\n",
    "            else:\n",
    "                # Intermediate layers use hidden_layer_size\n",
    "                self.layers.append(Layer(hidden_layer_size, hidden_layer_size, label=f\"Layer {i}\"))\n",
    "           \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for layer in self.layers:\n",
    "            parameters.extend(layer.parameters())  # Collect parameters from each layer\n",
    "        return parameters\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def register_forward_hook(self, func: Callable[[str, list[Value], list[Value]], None]): \n",
    "        self.forward_hook = func\n",
    "\n",
    "    def __call__(self, input):\n",
    "        \"\"\" Forward pass for the neural network. \"\"\"\n",
    "        assert len(input) == self.input_size, \"input size mismatch\"\n",
    "\n",
    "        x = [Value(i) for i in input]\n",
    "        for num, layer in enumerate(self.layers):\n",
    "            if num != len(self.layers) - 1:\n",
    "                act_fn = 'tanh'\n",
    "            else:\n",
    "                act_fn = None\n",
    "            input = x.copy()\n",
    "            x = layer(x, act_fn)  # Forward pass through the layer\n",
    "            self.forward_hook(f\"Layer {num}\", [i.data for i in input], [o.data for o in x]) if self.forward_hook else None\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "7e307dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # For reproducibility\n",
    "mlp = NN(input_size=3, hidden_layer_num=3, hidden_layer_size=4, output_size=1)  # Create a neural network with 2 inputs, 2 hidden layers of size 3, and 1 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "b87ae772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model information:\n",
      "input size: 3\n",
      "total model layers: 3\n",
      "[0] layer input: 3, layer output: 4, neurons: 4\n",
      "[1] layer input: 4, layer output: 4, neurons: 4\n",
      "[2] layer input: 4, layer output: 1, neurons: 1\n",
      "total model parameters: 41\n",
      "model parameters:\n",
      "[tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]), tensor([-0.5536, -0.8261,  0.0107,  0.0899]), tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]), tensor([ 0.6116, -0.3268,  0.6143,  0.1041]), tensor([[0.6588, 0.2370, 0.7234, 0.1547]]), tensor([0.4091])]\n"
     ]
    }
   ],
   "source": [
    "print(\"model information:\")\n",
    "print(f\"input size: {mlp.input_size}\")\n",
    "print(f\"total model layers: {len(mlp.layers)}\")\n",
    "for i, layer in enumerate(mlp.layers):\n",
    "    print(f\"[{i}] layer input: {layer.input}, layer output: {layer.output}, neurons: {len(layer.neurons)}\")\n",
    "print(f\"total model parameters: {len(mlp.parameters())}\")\n",
    "\n",
    "# Build tensor parameters for the model, this will be used to set the parameters in PyTorch\n",
    "mlp_tensor_parameters = []\n",
    "print(\"model parameters:\")\n",
    "\n",
    "# Save pre-defined parameters in a list of tensors\n",
    "for layer_num, layer in enumerate(mlp.layers):\n",
    "    layer_params = []\n",
    "    bias_params = []\n",
    "    for neuron_num, neuron in enumerate(layer.neurons):\n",
    "        layer_params.append([x.data for x in neuron.parameters()][:-1])\n",
    "        bias_params.append([x.data for x in neuron.parameters()][-1])\n",
    "    mlp_tensor_parameters.append(torch.tensor(layer_params))\n",
    "    mlp_tensor_parameters.append(torch.tensor(bias_params))\n",
    "    \n",
    "print(mlp_tensor_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "4fb2c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch model with the same architecture for verification\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 4),  # First hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 4),  # Second hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1)   # Output layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def hook_fn(module, input, output, name=None):\n",
    "    \"\"\" Hook function to capture the output of each layer. \"\"\"\n",
    "    print(f\"Layer: {module}, Input: {input}, Output: {output}\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\" Calculate Root Mean Squared Error. \"\"\"\n",
    "    diffs = torch.stack([(y_true_i - y_pred_i) ** 2 for y_true_i, y_pred_i in zip(y_true, y_pred)])\n",
    "    return torch.mean(diffs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "bd7853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook for layer: \n",
      "Registering hook for layer: layers\n",
      "Registering hook for layer: layers.0\n",
      "Registering hook for layer: layers.1\n",
      "Registering hook for layer: layers.2\n",
      "Registering hook for layer: layers.3\n",
      "Registering hook for layer: layers.4\n",
      "model parameters = [Parameter containing:\n",
      "tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5536, -0.8261,  0.0107,  0.0899], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.6116, -0.3268,  0.6143,  0.1041], requires_grad=True), Parameter containing:\n",
      "tensor([[0.6588, 0.2370, 0.7234, 0.1547]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4091], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmlp = MLP(input_size=3)  # Create a PyTorch model with the same architecture\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "# Register hooks to capture the output of each layer\n",
    "for name, module in tmlp.named_modules():\n",
    "    print(f\"Registering hook for layer: {name}\")\n",
    "    module.register_forward_hook(hook_fn)\n",
    "\n",
    "print(f\"model parameters = {[p for p in tmlp.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "5df68e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model parameters:\n",
      "layers.0.weight: data: tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) grad=None\n",
      "layers.0.bias: data: tensor([-0.5536, -0.8261,  0.0107,  0.0899]) grad=None\n",
      "layers.2.weight: data: tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]) grad=None\n",
      "layers.2.bias: data: tensor([ 0.6116, -0.3268,  0.6143,  0.1041]) grad=None\n",
      "layers.4.weight: data: tensor([[0.6588, 0.2370, 0.7234, 0.1547]]) grad=None\n",
      "layers.4.bias: data: tensor([0.4091]) grad=None\n"
     ]
    }
   ],
   "source": [
    "# Print parameters of the PyTorch model\n",
    "print(\"PyTorch model parameters:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: data: {param.data} grad={param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "bd430978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "\n",
    "y = [1.0, -1.0, -1.0, 1.0]  # Example labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "014ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mse(y_preds, y_true):\n",
    "    \"\"\"Mean squared error loss function.\"\"\"\n",
    "    loss = sum([(i - j)**2 for i, j in zip(y_true, y_preds)])\n",
    "\n",
    "    return loss/len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "8bb459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mae(y_preds, y_true):\n",
    "    \"\"\"Mean absolute error loss function.\"\"\"\n",
    "    loss = sum([(i - j) for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "cab62bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: Layer 0 Neuron 0 w0, data: 0.2788535969157675, grad: 0.0\n",
      "param: Layer 0 Neuron 0 w1, data: -0.9499784895546661, grad: 0.0\n",
      "param: Layer 0 Neuron 0 w2, data: -0.4499413632617615, grad: 0.0\n",
      "param: Layer 0 Neuron 0 b, data: -0.5535785237023545, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w0, data: 0.4729424283280248, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w1, data: 0.3533989748458226, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w2, data: 0.7843591354096908, grad: 0.0\n",
      "param: Layer 0 Neuron 1 b, data: -0.8261223347411677, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w0, data: -0.15615636062945915, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w1, data: -0.9404055611238593, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w2, data: -0.5627240503927933, grad: 0.0\n",
      "param: Layer 0 Neuron 2 b, data: 0.010710576206724776, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w0, data: -0.9469280606322728, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w1, data: -0.602324698626703, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w2, data: 0.2997688755590464, grad: 0.0\n",
      "param: Layer 0 Neuron 3 b, data: 0.08988296120643335, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w0, data: -0.5591187559186066, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w1, data: 0.17853136775181744, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w2, data: 0.6188609133556533, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w3, data: -0.987002480643878, grad: 0.0\n",
      "param: Layer 1 Neuron 0 b, data: 0.6116385036656158, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w0, data: 0.3962787899764537, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w1, data: -0.31949896696401625, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w2, data: -0.6890410003764369, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w3, data: 0.9144261444135624, grad: 0.0\n",
      "param: Layer 1 Neuron 1 b, data: -0.32681090977474647, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w0, data: -0.8145083132397042, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w1, data: -0.806567246333072, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w2, data: 0.6949887326949196, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w3, data: 0.20745206273378214, grad: 0.0\n",
      "param: Layer 1 Neuron 2 b, data: 0.6142565465487604, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w0, data: 0.45946357338763577, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w1, data: 0.07245618290940148, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w2, data: 0.9462315279587412, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w3, data: -0.24293124558329304, grad: 0.0\n",
      "param: Layer 1 Neuron 3 b, data: 0.104081262546454, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w0, data: 0.6588093285059897, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w1, data: 0.2370395047284921, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w2, data: 0.7234138006215545, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w3, data: 0.15470429051352408, grad: 0.0\n",
      "param: Layer 2 Neuron 0 b, data: 0.40914367242984695, grad: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Print grads for our model\n",
    "for param in mlp.parameters():\n",
    "    print(f\"param: {param.label}, data: {param.data}, grad: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "3d011511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795]\n",
      "Layer: Layer 1, Input: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795], Output: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824]\n",
      "Layer: Layer 2, Input: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824], Output: [0.8661433515946025]\n",
      "y_preds = 0.8661433515946025\n",
      "y = 1.0\n",
      "loss = Value(data=0.017917602322326195)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with our model\n",
    "mlp.register_forward_hook(hook_fn)  # Register the hook to capture outputs\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "0f2e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "7c87c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "y_preds_tmlp = 0.8661433458328247\n",
      "loss_tmlp = Value(data=0.017917603864830767)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with PyTorch model\n",
    "y_preds_tmlp = tmlp(torch.tensor(x[0]))\n",
    "print(f\"y_preds_tmlp = {y_preds_tmlp.item()}\")\n",
    "loss_tmlp = loss_fn_mse([Value(y_preds_tmlp.item())], [Value(y[0])])\n",
    "print(f\"loss_tmlp = {loss_tmlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "dedc339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass with our model\n",
    "mlp.zero_grad()\n",
    "loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "loss.visited = set()  # Reset visited set for each backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "494cc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for our model\n",
    "learning_rate = 0.001\n",
    "for param in mlp.parameters():\n",
    "    param.data -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "8964c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "output = tensor([0.8661], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with PyTorch model\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "optimizer.zero_grad()\n",
    "output = tmlp(torch.tensor(x[0]))  # Forward pass\n",
    "print(f\"output = {output}\")\n",
    "loss_rmse = rmse([torch.tensor([y[0]])], [output])  # Calculate loss\n",
    "loss_rmse.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "6bc150d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmlp loss grad = 0.017917603254318237\n"
     ]
    }
   ],
   "source": [
    "# Print gradients of the loss function\n",
    "print(f\"tmlp loss grad = {loss_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "30507a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for PyTorch model\n",
    "optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "46a77386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for our model:\n",
      "Layer 0 Neuron 0 w0: 0.2788439384702872 (grad: 0.009658445480288656)\n",
      "Layer 0 Neuron 0 w1: -0.9499929772228866 (grad: 0.014487668220432983)\n",
      "Layer 0 Neuron 0 w2: -0.44993653403902134 (grad: -0.004829222740144328)\n",
      "Layer 0 Neuron 0 b: -0.5535833529250946 (grad: 0.004829222740144328)\n",
      "Layer 0 Neuron 1 w0: 0.47268365591740313 (grad: 0.2587724106216494)\n",
      "Layer 0 Neuron 1 w1: 0.3530108162298901 (grad: 0.38815861593247414)\n",
      "Layer 0 Neuron 1 w2: 0.7844885216150016 (grad: -0.1293862053108247)\n",
      "Layer 0 Neuron 1 b: -0.8262517209464785 (grad: 0.1293862053108247)\n",
      "Layer 0 Neuron 2 w0: -0.156149540968433 (grad: -0.006819661026130761)\n",
      "Layer 0 Neuron 2 w1: -0.9403953316323201 (grad: -0.010229491539196141)\n",
      "Layer 0 Neuron 2 w2: -0.5627274602233063 (grad: 0.0034098305130653805)\n",
      "Layer 0 Neuron 2 b: 0.010713986037237841 (grad: -0.0034098305130653805)\n",
      "Layer 0 Neuron 3 w0: -0.9469279643907854 (grad: -9.624148732860756e-05)\n",
      "Layer 0 Neuron 3 w1: -0.6023245542644721 (grad: -0.00014436223099291136)\n",
      "Layer 0 Neuron 3 w2: 0.29976882743830274 (grad: 4.812074366430378e-05)\n",
      "Layer 0 Neuron 3 b: 0.08988300932717702 (grad: -4.812074366430378e-05)\n",
      "Layer 1 Neuron 0 w0: -0.5591447037724337 (grad: 0.025947853827143978)\n",
      "Layer 1 Neuron 0 w1: 0.17854129211808092 (grad: -0.00992436626348306)\n",
      "Layer 1 Neuron 0 w2: 0.6188348446513917 (grad: 0.02606870426158594)\n",
      "Layer 1 Neuron 0 w3: -0.9870288415834612 (grad: 0.02636093958323322)\n",
      "Layer 1 Neuron 0 b: 0.6116648857576266 (grad: -0.026382092010792762)\n",
      "Layer 1 Neuron 1 w0: 0.39625526026487373 (grad: 0.02352971157995671)\n",
      "Layer 1 Neuron 1 w1: -0.31948996747306224 (grad: -0.008999490954019754)\n",
      "Layer 1 Neuron 1 w2: -0.6890646396761118 (grad: 0.023639299674820924)\n",
      "Layer 1 Neuron 1 w3: 0.914402240112671 (grad: 0.02390430089140105)\n",
      "Layer 1 Neuron 1 b: -0.32678698629267255 (grad: -0.02392348207389913)\n",
      "Layer 1 Neuron 2 w0: -0.8146900256750575 (grad: 0.18171243535335416)\n",
      "Layer 1 Neuron 2 w1: -0.8064977461433804 (grad: -0.06950018969159072)\n",
      "Layer 1 Neuron 2 w2: 0.6948061739457669 (grad: 0.18255874915264755)\n",
      "Layer 1 Neuron 2 w3: 0.207267457465008 (grad: 0.1846052687741373)\n",
      "Layer 1 Neuron 2 b: 0.6144412999476708 (grad: -0.1847533989104902)\n",
      "Layer 1 Neuron 3 w0: 0.45944679778766173 (grad: 0.01677559997402493)\n",
      "Layer 1 Neuron 3 w1: 0.07246259913170414 (grad: -0.0064162223026606735)\n",
      "Layer 1 Neuron 3 w2: 0.9462146742275059 (grad: 0.01685373123522252)\n",
      "Layer 1 Neuron 3 w3: -0.24294828824818293 (grad: 0.017042664889885966)\n",
      "Layer 1 Neuron 3 b: 0.10409831888664303 (grad: -0.017056340189029483)\n",
      "Layer 2 Neuron 0 w0: 0.6590562086406249 (grad: -0.24688013463515496)\n",
      "Layer 2 Neuron 0 w1: 0.2368281965653681 (grad: 0.2113081631240002)\n",
      "Layer 2 Neuron 0 w2: 0.7234712360937652 (grad: -0.05743547221069753)\n",
      "Layer 2 Neuron 0 w3: 0.15449897445037689 (grad: 0.20531606314719333)\n",
      "Layer 2 Neuron 0 b: 0.40941138572665775 (grad: -0.2677132968107949)\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters for out model\n",
    "print(\"Updated parameters for our model:\")\n",
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "ea105b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for PyTorch model:\n",
      "layers.0.weight: tensor([[ 0.2788, -0.9500, -0.4499],\n",
      "        [ 0.4727,  0.3530,  0.7845],\n",
      "        [-0.1561, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) (grad: tensor([[ 9.6584e-03,  1.4488e-02, -4.8292e-03],\n",
      "        [ 2.5877e-01,  3.8816e-01, -1.2939e-01],\n",
      "        [-6.8197e-03, -1.0229e-02,  3.4098e-03],\n",
      "        [-9.6238e-05, -1.4436e-04,  4.8119e-05]]))\n",
      "layers.0.bias: tensor([-0.5536, -0.8263,  0.0107,  0.0899]) (grad: tensor([ 4.8292e-03,  1.2939e-01, -3.4098e-03, -4.8119e-05]))\n",
      "layers.2.weight: tensor([[-0.5591,  0.1785,  0.6188, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6891,  0.9144],\n",
      "        [-0.8147, -0.8065,  0.6948,  0.2073],\n",
      "        [ 0.4594,  0.0725,  0.9462, -0.2429]]) (grad: tensor([[ 0.0259, -0.0099,  0.0261,  0.0264],\n",
      "        [ 0.0235, -0.0090,  0.0236,  0.0239],\n",
      "        [ 0.1817, -0.0695,  0.1826,  0.1846],\n",
      "        [ 0.0168, -0.0064,  0.0169,  0.0170]]))\n",
      "layers.2.bias: tensor([ 0.6117, -0.3268,  0.6144,  0.1041]) (grad: tensor([-0.0264, -0.0239, -0.1848, -0.0171]))\n",
      "layers.4.weight: tensor([[0.6591, 0.2368, 0.7235, 0.1545]]) (grad: tensor([[-0.2469,  0.2113, -0.0574,  0.2053]]))\n",
      "layers.4.bias: tensor([0.4094]) (grad: tensor([-0.2677]))\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters of PyTorch model\n",
    "print(\"Updated parameters for PyTorch model:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "696d9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "d85f718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9835427836930768, 0.3745107718519387, -0.9881199861535883, -0.9991982266578866]\n",
      "Layer: Layer 1, Input: [-0.9835427836930768, 0.3745107718519387, -0.9881199861535883, -0.9991982266578866], Output: [0.9221529606207961, -0.7890705788700002, 0.21654528178218366, -0.7669462096196659]\n",
      "Layer: Layer 2, Input: [0.9221529606207961, -0.7890705788700002, 0.21654528178218366, -0.7669462096196659], Output: [0.8684597374199408]\n",
      "y_preds = 0.8684597374199408\n",
      "y = 1.0\n",
      "loss = Value(data=0.017302840679630935)\n"
     ]
    }
   ],
   "source": [
    "# Second forward pass with our model\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "20af6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Neuron 0 w0 = 0.2788439384702872, grad = 0.009658445480288656\n",
      "Layer 0 Neuron 0 w1 = -0.9499929772228866, grad = 0.014487668220432983\n",
      "Layer 0 Neuron 0 w2 = -0.44993653403902134, grad = -0.004829222740144328\n",
      "Layer 0 Neuron 0 b = -0.5535833529250946, grad = 0.004829222740144328\n",
      "Layer 0 Neuron 1 w0 = 0.47268365591740313, grad = 0.2587724106216494\n",
      "Layer 0 Neuron 1 w1 = 0.3530108162298901, grad = 0.38815861593247414\n",
      "Layer 0 Neuron 1 w2 = 0.7844885216150016, grad = -0.1293862053108247\n",
      "Layer 0 Neuron 1 b = -0.8262517209464785, grad = 0.1293862053108247\n",
      "Layer 0 Neuron 2 w0 = -0.156149540968433, grad = -0.006819661026130761\n",
      "Layer 0 Neuron 2 w1 = -0.9403953316323201, grad = -0.010229491539196141\n",
      "Layer 0 Neuron 2 w2 = -0.5627274602233063, grad = 0.0034098305130653805\n",
      "Layer 0 Neuron 2 b = 0.010713986037237841, grad = -0.0034098305130653805\n",
      "Layer 0 Neuron 3 w0 = -0.9469279643907854, grad = -9.624148732860756e-05\n",
      "Layer 0 Neuron 3 w1 = -0.6023245542644721, grad = -0.00014436223099291136\n",
      "Layer 0 Neuron 3 w2 = 0.29976882743830274, grad = 4.812074366430378e-05\n",
      "Layer 0 Neuron 3 b = 0.08988300932717702, grad = -4.812074366430378e-05\n",
      "Layer 1 Neuron 0 w0 = -0.5591447037724337, grad = 0.025947853827143978\n",
      "Layer 1 Neuron 0 w1 = 0.17854129211808092, grad = -0.00992436626348306\n",
      "Layer 1 Neuron 0 w2 = 0.6188348446513917, grad = 0.02606870426158594\n",
      "Layer 1 Neuron 0 w3 = -0.9870288415834612, grad = 0.02636093958323322\n",
      "Layer 1 Neuron 0 b = 0.6116648857576266, grad = -0.026382092010792762\n",
      "Layer 1 Neuron 1 w0 = 0.39625526026487373, grad = 0.02352971157995671\n",
      "Layer 1 Neuron 1 w1 = -0.31948996747306224, grad = -0.008999490954019754\n",
      "Layer 1 Neuron 1 w2 = -0.6890646396761118, grad = 0.023639299674820924\n",
      "Layer 1 Neuron 1 w3 = 0.914402240112671, grad = 0.02390430089140105\n",
      "Layer 1 Neuron 1 b = -0.32678698629267255, grad = -0.02392348207389913\n",
      "Layer 1 Neuron 2 w0 = -0.8146900256750575, grad = 0.18171243535335416\n",
      "Layer 1 Neuron 2 w1 = -0.8064977461433804, grad = -0.06950018969159072\n",
      "Layer 1 Neuron 2 w2 = 0.6948061739457669, grad = 0.18255874915264755\n",
      "Layer 1 Neuron 2 w3 = 0.207267457465008, grad = 0.1846052687741373\n",
      "Layer 1 Neuron 2 b = 0.6144412999476708, grad = -0.1847533989104902\n",
      "Layer 1 Neuron 3 w0 = 0.45944679778766173, grad = 0.01677559997402493\n",
      "Layer 1 Neuron 3 w1 = 0.07246259913170414, grad = -0.0064162223026606735\n",
      "Layer 1 Neuron 3 w2 = 0.9462146742275059, grad = 0.01685373123522252\n",
      "Layer 1 Neuron 3 w3 = -0.24294828824818293, grad = 0.017042664889885966\n",
      "Layer 1 Neuron 3 b = 0.10409831888664303, grad = -0.017056340189029483\n",
      "Layer 2 Neuron 0 w0 = 0.6590562086406249, grad = -0.24688013463515496\n",
      "Layer 2 Neuron 0 w1 = 0.2368281965653681, grad = 0.2113081631240002\n",
      "Layer 2 Neuron 0 w2 = 0.7234712360937652, grad = -0.05743547221069753\n",
      "Layer 2 Neuron 0 w3 = 0.15449897445037689, grad = 0.20531606314719333\n",
      "Layer 2 Neuron 0 b = 0.40941138572665775, grad = -0.2677132968107949\n"
     ]
    }
   ],
   "source": [
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label} = {param.data}, grad = {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "f4b8b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276315321914, -0.9918175594997916, -0.8350656162904463, 0.9423739739343306]\n",
      "Layer: Layer 1, Input: [-0.9991276315321914, -0.9918175594997916, -0.8350656162904463, 0.9423739739343306], Output: [0.9237175099716631, -0.7910865084461395, 0.9660906038665381, -0.011681945501092817]\n",
      "Layer: Layer 2, Input: [0.9237175099716631, -0.7910865084461395, 0.9660906038665381, -0.011681945501092817], Output: [-0.6695304217747466]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996886996296201, -0.6386645378500293, -0.8637446594463088, 0.944183622989383]\n",
      "Layer: Layer 1, Input: [-0.996886996296201, -0.6386645378500293, -0.8637446594463088, 0.944183622989383], Output: [0.8822340059944829, -0.7453213735062068, 0.957075979802214, -0.14906437136899842]\n",
      "Layer: Layer 2, Input: [0.8822340059944829, -0.7453213735062068, 0.957075979802214, -0.14906437136899842], Output: [-0.6999307556674828]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784573575697186, -0.8448527847911291, -0.8940667525169448, 0.28513683526960454]\n",
      "Layer: Layer 1, Input: [-0.9784573575697186, -0.8448527847911291, -0.8940667525169448, 0.28513683526960454], Output: [0.7138940973595561, -0.8897996264143349, 0.9824591623525861, 0.0681464016598766]\n",
      "Layer: Layer 2, Input: [0.7138940973595561, -0.8897996264143349, 0.9824591623525861, 0.0681464016598766], Output: [-0.6043407601078499]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522088987764, -0.5490313912555997, -0.3927370301832145, 0.28525678051628184]\n",
      "Layer: Layer 1, Input: [-0.9537522088987764, -0.5490313912555997, -0.3927370301832145, 0.28525678051628184], Output: [0.5273799607497388, -0.7465401796753427, 0.963923556933513, 0.13225188832603177]\n",
      "Layer: Layer 2, Input: [0.5273799607497388, -0.7465401796753427, 0.963923556933513, 0.13225188832603177], Output: [-0.6390967189665377]\n",
      "Epoch 1/100, Loss: 1.4301394172161386, Accuracy: -3.0043556249659513\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991243783376221, -0.9920204931657727, -0.8437730804112693, 0.9364453915713364]\n",
      "Layer: Layer 1, Input: [-0.9991243783376221, -0.9920204931657727, -0.8437730804112693, 0.9364453915713364], Output: [0.9220426299996882, -0.8121265312157566, 0.9659950756524475, 0.01717100571044131]\n",
      "Layer: Layer 2, Input: [0.9220426299996882, -0.8121265312157566, 0.9659950756524475, 0.01717100571044131], Output: [-0.44687761895525946]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968833452985096, -0.638754299296901, -0.8656268466131616, 0.9424900837383652]\n",
      "Layer: Layer 1, Input: [-0.9968833452985096, -0.638754299296901, -0.8656268466131616, 0.9424900837383652], Output: [0.880360095991974, -0.7660893963700628, 0.9565292270317586, -0.12160813008417685]\n",
      "Layer: Layer 2, Input: [0.880360095991974, -0.7660893963700628, 0.9565292270317586, -0.12160813008417685], Output: [-0.482877393092291]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784437399565473, -0.8453974627820722, -0.8954038980834604, 0.2770892490641062]\n",
      "Layer: Layer 1, Input: [-0.9784437399565473, -0.8453974627820722, -0.8954038980834604, 0.2770892490641062], Output: [0.7069138725157731, -0.8995256425054236, 0.9823775957700946, 0.0955150619457389]\n",
      "Layer: Layer 2, Input: [0.7069138725157731, -0.8995256425054236, 0.9823775957700946, 0.0955150619457389], Output: [-0.3910076402239269]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9536548385173402, -0.5539071757188043, -0.4057828540554192, 0.2586534286211126]\n",
      "Layer: Layer 1, Input: [-0.9536548385173402, -0.5539071757188043, -0.4057828540554192, 0.2586534286211126], Output: [0.5086841904908931, -0.7725995555301286, 0.9650822232876243, 0.1569532435681711]\n",
      "Layer: Layer 2, Input: [0.5086841904908931, -0.7725995555301286, 0.9650822232876243, 0.1569532435681711], Output: [-0.43429444101949327]\n",
      "Epoch 2/100, Loss: 1.1972357181534292, Accuracy: -3.0072870266585348\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991213683138273, -0.9922356430938816, -0.8515177196612727, 0.9318146129351585]\n",
      "Layer: Layer 1, Input: [-0.9991213683138273, -0.9922356430938816, -0.8515177196612727, 0.9318146129351585], Output: [0.9213107699703801, -0.8262159668092187, 0.9660646879940318, 0.03649514005607426]\n",
      "Layer: Layer 2, Input: [0.9213107699703801, -0.8262159668092187, 0.9660646879940318, 0.03649514005607426], Output: [-0.2973943118697044]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968802962773424, -0.6365163209502416, -0.8670088178715407, 0.9414184065299017]\n",
      "Layer: Layer 1, Input: [-0.9968802962773424, -0.6365163209502416, -0.8670088178715407, 0.9414184065299017], Output: [0.8793638505282404, -0.7793886239836357, 0.9561473073077114, -0.10370405963706364]\n",
      "Layer: Layer 2, Input: [0.8793638505282404, -0.7793886239836357, 0.9561473073077114, -0.10370405963706364], Output: [-0.3378910895076687]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784341089019332, -0.8457486852484424, -0.8965784583821669, 0.27249088969561186]\n",
      "Layer: Layer 1, Input: [-0.9784341089019332, -0.8457486852484424, -0.8965784583821669, 0.27249088969561186], Output: [0.7038593959790723, -0.9058245251589604, 0.98233187578549, 0.11381686232789534]\n",
      "Layer: Layer 2, Input: [0.7038593959790723, -0.9058245251589604, 0.98233187578549, 0.11381686232789534], Output: [-0.2481268335524917]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9535631037596938, -0.5591260524719267, -0.41782640837934154, 0.23905868896363183]\n",
      "Layer: Layer 1, Input: [-0.9535631037596938, -0.5591260524719267, -0.41782640837934154, 0.23905868896363183], Output: [0.4977982379574429, -0.7907856645223984, 0.966087517429115, 0.17385405289417025]\n",
      "Layer: Layer 2, Input: [0.4977982379574429, -0.7907856645223984, 0.966087517429115, 0.17385405289417025], Output: [-0.2958275519896992]\n",
      "Epoch 3/100, Loss: 1.0915256281861563, Accuracy: -3.0072039407992435\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991185317680142, -0.9924357909826113, -0.8581528918875635, 0.9280338312641639]\n",
      "Layer: Layer 1, Input: [-0.9991185317680142, -0.9924357909826113, -0.8581528918875635, 0.9280338312641639], Output: [0.9209687172875856, -0.835840260017159, 0.9662052532419888, 0.04935291026361556]\n",
      "Layer: Layer 2, Input: [0.9209687172875856, -0.835840260017159, 0.9662052532419888, 0.04935291026361556], Output: [-0.1976397837126873]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968776929991053, -0.6319773550442453, -0.8679298497466927, 0.9407281581644548]\n",
      "Layer: Layer 1, Input: [-0.9968776929991053, -0.6319773550442453, -0.8679298497466927, 0.9407281581644548], Output: [0.8785061937903389, -0.7877579112844222, 0.9558208400602768, -0.09272814689544845]\n",
      "Layer: Layer 2, Input: [0.8785061937903389, -0.7877579112844222, 0.9558208400602768, -0.09272814689544845], Output: [-0.24195044712252944]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784276116070402, -0.845838368597662, -0.8975717955148615, 0.26977695806420166]\n",
      "Layer: Layer 1, Input: [-0.9784276116070402, -0.845838368597662, -0.8975717955148615, 0.26977695806420166], Output: [0.7025379498722247, -0.9099944337650332, 0.9823046303945436, 0.12596808214617505]\n",
      "Layer: Layer 2, Input: [0.7025379498722247, -0.9099944337650332, 0.9823046303945436, 0.12596808214617505], Output: [-0.15277639660987408]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9534752204165705, -0.5640225280103376, -0.42848610977893153, 0.22375551249392775]\n",
      "Layer: Layer 1, Input: [-0.9534752204165705, -0.5640225280103376, -0.42848610977893153, 0.22375551249392775], Output: [0.49075947421182625, -0.8038635331634131, 0.9669506499700713, 0.18555103868683534]\n",
      "Layer: Layer 2, Input: [0.49075947421182625, -0.8038635331634131, 0.9669506499700713, 0.18555103868683534], Output: [-0.20223401849645362]\n",
      "Epoch 4/100, Loss: 1.0430336613801463, Accuracy: -3.005146958476738\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991158208818667, -0.9926141064159182, -0.8638330771607676, 0.9247805496088273]\n",
      "Layer: Layer 1, Input: [-0.9991158208818667, -0.9926141064159182, -0.8638330771607676, 0.9247805496088273], Output: [0.920767993872067, -0.842607399019276, 0.966376182693503, 0.057726311704120875]\n",
      "Layer: Layer 2, Input: [0.920767993872067, -0.842607399019276, 0.966376182693503, 0.057726311704120875], Output: [-0.13141633082612775]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968754235358307, -0.6254087524032574, -0.8684925369960429, 0.940272499746718]\n",
      "Layer: Layer 1, Input: [-0.9968754235358307, -0.6254087524032574, -0.8684925369960429, 0.940272499746718], Output: [0.8775058139527412, -0.7928743502892251, 0.9555014215743206, -0.08681168739949892]\n",
      "Layer: Layer 2, Input: [0.8775058139527412, -0.7928743502892251, 0.9555014215743206, -0.08681168739949892], Output: [-0.1791570698409961]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784235252495349, -0.8456810974577365, -0.8984119519976762, 0.2681320316130767]\n",
      "Layer: Layer 1, Input: [-0.9784235252495349, -0.8456810974577365, -0.8984119519976762, 0.2681320316130767], Output: [0.7019476349839674, -0.9128224876095586, 0.9822871051432667, 0.13385835702105367]\n",
      "Layer: Layer 2, Input: [0.7019476349839674, -0.9128224876095586, 0.9822871051432667, 0.13385835702105367], Output: [-0.0893610514818351]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9533900578177533, -0.5684092395291747, -0.43787226399192425, 0.2110543736743281]\n",
      "Layer: Layer 1, Input: [-0.9533900578177533, -0.5684092395291747, -0.43787226399192425, 0.2110543736743281], Output: [0.4855323781980954, -0.8136383766081069, 0.9677029230072682, 0.19368711040732467]\n",
      "Layer: Layer 2, Input: [0.4855323781980954, -0.8136383766081069, 0.9677029230072682, 0.19368711040732467], Output: [-0.1388621157080219]\n",
      "Epoch 5/100, Loss: 1.0200390607013246, Accuracy: -3.0017603252113183\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991131936418545, -0.9927711319925255, -0.8687421756215176, 0.9218397765983785]\n",
      "Layer: Layer 1, Input: [-0.9991131936418545, -0.9927711319925255, -0.8687421756215176, 0.9218397765983785], Output: [0.9206036728031409, -0.8475169916614086, 0.966559500195019, 0.0630017907757389]\n",
      "Layer: Layer 2, Input: [0.9206036728031409, -0.8475169916614086, 0.966559500195019, 0.0630017907757389], Output: [-0.08764271688959824]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968733960931158, -0.6170884674109326, -0.8687886652337911, 0.9399637963748517]\n",
      "Layer: Layer 1, Input: [-0.9968733960931158, -0.6170884674109326, -0.8687886652337911, 0.9399637963748517], Output: [0.8762726440744126, -0.7957986872989922, 0.9551672107685651, -0.08457959386978393]\n",
      "Layer: Layer 2, Input: [0.8762726440744126, -0.7957986872989922, 0.9551672107685651, -0.08457959386978393], Output: [-0.13863416840831894]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784212352858112, -0.8453131847087215, -0.8991309812176658, 0.26713141926184125]\n",
      "Layer: Layer 1, Input: [-0.9784212352858112, -0.8453131847087215, -0.8991309812176658, 0.26713141926184125], Output: [0.7016568120525272, -0.9147841201073833, 0.9822744651626527, 0.13879416875658698]\n",
      "Layer: Layer 2, Input: [0.7016568120525272, -0.9147841201073833, 0.9822744651626527, 0.13879416875658698], Output: [-0.047280954421339116]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953306617614851, -0.5722801510475929, -0.44618523564307344, 0.19992394363988558]\n",
      "Layer: Layer 1, Input: [-0.953306617614851, -0.5722801510475929, -0.44618523564307344, 0.19992394363988558], Output: [0.48109367747730253, -0.8212402899974532, 0.9683724708575184, 0.19938668780599347]\n",
      "Layer: Layer 2, Input: [0.48109367747730253, -0.8212402899974532, 0.9683724708575184, 0.19938668780599347], Output: [-0.09572589944422114]\n",
      "Epoch 6/100, Loss: 1.0083016504894442, Accuracy: -2.9974534935041612\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991106144691927, -0.992909445913896, -0.873031325091405, 0.9190695807599467]\n",
      "Layer: Layer 1, Input: [-0.9991106144691927, -0.992909445913896, -0.873031325091405, 0.9190695807599467], Output: [0.920433456853717, -0.8511902923052681, 0.9667471422724817, 0.06616511462029796]\n",
      "Layer: Layer 2, Input: [0.920433456853717, -0.8511902923052681, 0.9667471422724817, 0.06616511462029796], Output: [-0.058812674263420045]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968715376489213, -0.6072295828105061, -0.8688862874593228, 0.9397491981220134]\n",
      "Layer: Layer 1, Input: [-0.9968715376489213, -0.6072295828105061, -0.8688862874593228, 0.9397491981220134], Output: [0.8747864399452155, -0.797195789973788, 0.954807693871234, -0.08503458377358765]\n",
      "Layer: Layer 2, Input: [0.8747864399452155, -0.797195789973788, 0.954807693871234, -0.08503458377358765], Output: [-0.113017943089701]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784202559889467, -0.8447698735275396, -0.8997548342780178, 0.2665475611266551]\n",
      "Layer: Layer 1, Input: [-0.9784202559889467, -0.8447698735275396, -0.8997548342780178, 0.2665475611266551], Output: [0.7014867021981968, -0.9161705276238384, 0.982263908203151, 0.14169298153239857]\n",
      "Layer: Layer 2, Input: [0.7014867021981968, -0.9161705276238384, 0.982263908203151, 0.14169298153239857], Output: [-0.019375347858535563]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9532240376958555, -0.5756842665212526, -0.45360563156025846, 0.18972647438328671]\n",
      "Layer: Layer 1, Input: [-0.9532240376958555, -0.5756842665212526, -0.45360563156025846, 0.18972647438328671], Output: [0.4769200670977487, -0.8273758106533571, 0.9689805106054903, 0.2034367654311259]\n",
      "Layer: Layer 2, Input: [0.4769200670977487, -0.8273758106533571, 0.9689805106054903, 0.2034367654311259], Output: [-0.06606245615560649]\n",
      "Epoch 7/100, Loss: 1.0014838293184432, Accuracy: -2.9924818394707904\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991080550938886, -0.9930317328440883, -0.8768138335324689, 0.9163742687483278]\n",
      "Layer: Layer 1, Input: [-0.9991080550938886, -0.9930317328440883, -0.8768138335324689, 0.9163742687483278], Output: [0.920240898822165, -0.8540175527884816, 0.9669356021820957, 0.0679139567085781]\n",
      "Layer: Layer 2, Input: [0.920240898822165, -0.8540175527884816, 0.9669356021820957, 0.0679139567085781], Output: [-0.03988227803975697]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968697928181854, -0.5959699537622197, -0.8688324237175425, 0.9395960892334693]\n",
      "Layer: Layer 1, Input: [-0.9968697928181854, -0.5959699537622197, -0.8688324237175425, 0.9395960892334693], Output: [0.8730465662716971, -0.797480985342578, 0.95441699274225, -0.0874713757995722]\n",
      "Layer: Layer 2, Input: [0.8730465662716971, -0.797480985342578, 0.95441699274225, -0.0874713757995722], Output: [-0.0973688829260784]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784202256932863, -0.8440786539729006, -0.9003025335544501, 0.26625296213414845]\n",
      "Layer: Layer 1, Input: [-0.9784202256932863, -0.8440786539729006, -0.9003025335544501, 0.26625296213414845], Output: [0.7013653443465955, -0.9171628730367812, 0.9822537762358728, 0.1431977353471914]\n",
      "Layer: Layer 2, Input: [0.7013653443465955, -0.9171628730367812, 0.9822537762358728, 0.1431977353471914], Output: [-0.0008386159333428345]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9531416212582877, -0.5786773919607217, -0.4602737957525859, 0.18005733498698911]\n",
      "Layer: Layer 1, Input: [-0.9531416212582877, -0.5786773919607217, -0.4602737957525859, 0.18005733498698911], Output: [0.472731176401923, -0.8324916160676182, 0.9695422576093015, 0.2063888420724493]\n",
      "Layer: Layer 2, Input: [0.472731176401923, -0.8324916160676182, 0.9695422576093015, 0.2063888420724493], Output: [-0.04532154409401418]\n",
      "Epoch 8/100, Loss: 0.9967796719120905, Accuracy: -2.98699632327435\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991054940325975, -0.9931402143574733, -0.8801728827604645, 0.9136868665099147]\n",
      "Layer: Layer 1, Input: [-0.9991054940325975, -0.9931402143574733, -0.8801728827604645, 0.9136868665099147], Output: [0.9200195900622382, -0.856247159952176, 0.9671235727846655, 0.06873798253137942]\n",
      "Layer: Layer 2, Input: [0.9200195900622382, -0.856247159952176, 0.9671235727846655, 0.06873798253137942], Output: [-0.027482356941314456]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968681210713721, -0.5833809213785589, -0.8686584342994322, 0.939483817917536]\n",
      "Layer: Layer 1, Input: [-0.9968681210713721, -0.5833809213785589, -0.8686584342994322, 0.939483817917536], Output: [0.8710528640747419, -0.796911240152087, 0.9539909110599286, -0.0914043927525829]\n",
      "Layer: Layer 2, Input: [0.8710528640747419, -0.796911240152087, 0.9539909110599286, -0.0914043927525829], Output: [-0.08839973213894914]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784208861807464, -0.8432586309860822, -0.9007875581303537, 0.2661724097825534]\n",
      "Layer: Layer 1, Input: [-0.9784208861807464, -0.8432586309860822, -0.9007875581303537, 0.2661724097825534], Output: [0.7012640090383737, -0.9178753262497168, 0.982243083263257, 0.1437563082933687]\n",
      "Layer: Layer 2, Input: [0.7012640090383737, -0.9178753262497168, 0.982243083263257, 0.1437563082933687], Output: [0.0115364361705394]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9530588309631985, -0.581306486712055, -0.46629393692435256, 0.17065184879486756]\n",
      "Layer: Layer 1, Input: [-0.9530588309631985, -0.581306486712055, -0.46629393692435256, 0.17065184879486756], Output: [0.4683656540302446, -0.8368744445709193, 0.9700685203311782, 0.20862781170238537]\n",
      "Layer: Layer 2, Input: [0.4683656540302446, -0.8368744445709193, 0.9700685203311782, 0.20862781170238537], Output: [-0.03045736608093036]\n",
      "Epoch 9/100, Loss: 0.9929458468002658, Accuracy: -2.981076427053835\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991029153693964, -0.9932365720398089, -0.8831699513104608, 0.9109581944670242]\n",
      "Layer: Layer 1, Input: [-0.9991029153693964, -0.9932365720398089, -0.8831699513104608, 0.9109581944670242], Output: [0.9197666477742706, -0.8580393102755747, 0.9673108576448546, 0.06897872646417985]\n",
      "Layer: Layer 2, Input: [0.9197666477742706, -0.8580393102755747, 0.9673108576448546, 0.06897872646417985], Output: [-0.019371599590753075]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996866493423844, -0.5694796836990181, -0.8683847197933993, 0.9393989915407699]\n",
      "Layer: Layer 1, Input: [-0.996866493423844, -0.5694796836990181, -0.8683847197933993, 0.9393989915407699], Output: [0.8687991671364858, -0.7956413858757612, 0.9535256116437755, -0.09650908918347781]\n",
      "Layer: Layer 2, Input: [0.8687991671364858, -0.7956413858757612, 0.9535256116437755, -0.09650908918347781], Output: [-0.08393859826796474]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784220586513664, -0.8423217780997666, -0.9012193965531341, 0.26625919841358403]\n",
      "Layer: Layer 1, Input: [-0.9784220586513664, -0.8423217780997666, -0.9012193965531341, 0.26625919841358403], Output: [0.7011705808288744, -0.9183804828375768, 0.9822312449100656, 0.14367916136345035]\n",
      "Layer: Layer 2, Input: [0.7011705808288744, -0.9183804828375768, 0.9822312449100656, 0.14367916136345035], Output: [0.01988136198767443]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9529752630510415, -0.5836065378142821, -0.4717428705692378, 0.16133111468860253]\n",
      "Layer: Layer 1, Input: [-0.9529752630510415, -0.5836065378142821, -0.4717428705692378, 0.16133111468860253], Output: [0.4637217872857418, -0.8407115332526485, 0.9705670419776239, 0.2104213869564416]\n",
      "Layer: Layer 2, Input: [0.4637217872857418, -0.8407115332526485, 0.9705670419776239, 0.2104213869564416], Output: [-0.019437837616839204]\n",
      "Epoch 10/100, Loss: 0.9894246117725506, Accuracy: -2.974752200927302\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991003074408221, -0.9933220218945161, -0.8858513219643155, 0.9081500451241278]\n",
      "Layer: Layer 1, Input: [-0.9991003074408221, -0.9933220218945161, -0.8858513219643155, 0.9081500451241278], Output: [0.9194801488774198, -0.8594986521375978, 0.967497842394603, 0.06887393864262902]\n",
      "Layer: Layer 2, Input: [0.9194801488774198, -0.8594986521375978, 0.967497842394603, 0.06887393864262902], Output: [-0.014062581426067922]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968648894133382, -0.5542403131608081, -0.8680241731460271, 0.9393327419072293]\n",
      "Layer: Layer 1, Input: [-0.9968648894133382, -0.5542403131608081, -0.8680241731460271, 0.9393327419072293], Output: [0.8662715785144667, -0.7937588808750236, 0.9530170049035471, -0.1025768567144376]\n",
      "Layer: Layer 2, Input: [0.8662715785144667, -0.7937588808750236, 0.9530170049035471, -0.1025768567144376], Output: [-0.08256159917785078]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784236224381155, -0.8412744959349334, -0.9016047743763299, 0.2664829425136077]\n",
      "Layer: Layer 1, Input: [-0.9784236224381155, -0.8412744959349334, -0.9016047743763299, 0.2664829425136077], Output: [0.7010788420261934, -0.9187246932267618, 0.9822179170681758, 0.14318103045692482]\n",
      "Layer: Layer 2, Input: [0.7010788420261934, -0.9187246932267618, 0.9822179170681758, 0.14318103045692482], Output: [0.025608908154637677]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9528906170389915, -0.5856016562031003, -0.47667778585681925, 0.15196985968261306]\n",
      "Layer: Layer 1, Input: [-0.9528906170389915, -0.5856016562031003, -0.47667778585681925, 0.15196985968261306], Output: [0.4587285744222538, -0.8441274213673242, 0.9710434687588521, 0.21195572571755952]\n",
      "Layer: Layer 2, Input: [0.4587285744222538, -0.8441274213673242, 0.9710434687588521, 0.21195572571755952], Output: [-0.010908907391951772]\n",
      "Epoch 11/100, Loss: 0.9859566474705352, Accuracy: -2.968018797794807\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990976616986629, -0.9933974156706301, -0.8882526097329083, 0.9052308255187288]\n",
      "Layer: Layer 1, Input: [-0.9990976616986629, -0.9933974156706301, -0.8882526097329083, 0.9052308255187288], Output: [0.9191581727949122, -0.860694395343422, 0.9676852264290275, 0.06858977277796668]\n",
      "Layer: Layer 2, Input: [0.9191581727949122, -0.860694395343422, 0.9676852264290275, 0.06858977277796668], Output: [-0.010568901373897488]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968632946662129, -0.5376022827930313, -0.8675845400330773, 0.9392790896249866]\n",
      "Layer: Layer 1, Input: [-0.9968632946662129, -0.5376022827930313, -0.8675845400330773, 0.9392790896249866], Output: [0.8634482876125269, -0.7913053552946742, 0.9524604455375109, -0.10948178177081584]\n",
      "Layer: Layer 2, Input: [0.8634482876125269, -0.7913053552946742, 0.9524604455375109, -0.10948178177081584], Output: [-0.08334461071695187]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784254982922793, -0.8401189573089168, -0.9019485210090502, 0.2668230589057719]\n",
      "Layer: Layer 1, Input: [-0.9784254982922793, -0.8401189573089168, -0.9019485210090502, 0.2668230589057719], Output: [0.7009843683925392, -0.9189374764624229, 0.9822028975568843, 0.14241066815113257]\n",
      "Layer: Layer 2, Input: [0.7009843683925392, -0.9189374764624229, 0.9822028975568843, 0.14241066815113257], Output: [0.029654125085270766]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9528046686391092, -0.5873071853074233, -0.481141987879257, 0.14247686265432086]\n",
      "Layer: Layer 1, Input: [-0.9528046686391092, -0.5873071853074233, -0.481141987879257, 0.14247686265432086], Output: [0.453331135137492, -0.8472066066596227, 0.9715020120695705, 0.2133608518848347]\n",
      "Layer: Layer 2, Input: [0.453331135137492, -0.8472066066596227, 0.9715020120695705, 0.2133608518848347], Output: [-0.003967372766187527]\n",
      "Epoch 12/100, Loss: 0.9824111775024644, Accuracy: -2.960845788508404\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999094971822713, -0.9934633297484027, -0.8904017929349968, 0.9021726813986906]\n",
      "Layer: Layer 1, Input: [-0.999094971822713, -0.9934633297484027, -0.8904017929349968, 0.9021726813986906], Output: [0.9187984671915562, -0.8616728547953941, 0.9678738824727625, 0.06824374961882151]\n",
      "Layer: Layer 2, Input: [0.9187984671915562, -0.8616728547953941, 0.9678738824727625, 0.06824374961882151], Output: [-0.008235548358857814]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.99686169906585, -0.519476703265123, -0.8670699712492694, 0.9392339380794696]\n",
      "Layer: Layer 1, Input: [-0.99686169906585, -0.519476703265123, -0.8670699712492694, 0.9392339380794696], Output: [0.860299687057006, -0.7882899078530311, 0.9518505608627933, -0.11715681485131237]\n",
      "Layer: Layer 2, Input: [0.860299687057006, -0.7882899078530311, 0.9518505608627933, -0.11715681485131237], Output: [-0.08569706201658417]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784276360786912, -0.8388541294966169, -0.9022541520284991, 0.2672651048957023]\n",
      "Layer: Layer 1, Input: [-0.9784276360786912, -0.8388541294966169, -0.9022541520284991, 0.2672651048957023], Output: [0.7008830730455775, -0.919037382816241, 0.9821860655855529, 0.14147179029035592]\n",
      "Layer: Layer 2, Input: [0.7008830730455775, -0.919037382816241, 0.9821860655855529, 0.14147179029035592], Output: [0.032636049077276685]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.952717248244972, -0.5887317121189477, -0.4851688494456522, 0.13278272839786945]\n",
      "Layer: Layer 1, Input: [-0.952717248244972, -0.5887317121189477, -0.4851688494456522, 0.13278272839786945], Output: [0.4474829811522497, -0.8500076517675396, 0.9719458925343152, 0.21472859336644842]\n",
      "Layer: Layer 2, Input: [0.4474829811522497, -0.8500076517675396, 0.9719458925343152, 0.21472859336644842], Output: [0.0019916714632021715]\n",
      "Epoch 13/100, Loss: 0.9787116542655833, Accuracy: -2.9531828639563478\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990922330673128, -0.9935201334823861, -0.8923212219364131, 0.8989495233093058]\n",
      "Layer: Layer 1, Input: [-0.9990922330673128, -0.9935201334823861, -0.8923212219364131, 0.8989495233093058], Output: [0.9183983349212709, -0.8624653640172035, 0.9680647825709908, 0.067920947857996]\n",
      "Layer: Layer 2, Input: [0.9183983349212709, -0.8624653640172035, 0.9680647825709908, 0.067920947857996], Output: [-0.006625698659043777]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968600954264555, -0.499750866641547, -0.8664820150329595, 0.9391944399953535]\n",
      "Layer: Layer 1, Input: [-0.9968600954264555, -0.499750866641547, -0.8664820150329595, 0.9391944399953535], Output: [0.8567883610812936, -0.7846971728710339, 0.9511811343702051, -0.12557695713235023]\n",
      "Layer: Layer 2, Input: [0.8567883610812936, -0.7846971728710339, 0.9511811343702051, -0.12557695713235023], Output: [-0.08925147502142508]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784300060618053, -0.8374765045492583, -0.9025242509810303, 0.2677986171802251]\n",
      "Layer: Layer 1, Input: [-0.9784300060618053, -0.8374765045492583, -0.9025242509810303, 0.2677986171802251], Output: [0.70077075872949, -0.9190356813072554, 0.982167344329197, 0.1404376925468366]\n",
      "Layer: Layer 2, Input: [0.70077075872949, -0.9190356813072554, 0.982167344329197, 0.1404376925468366], Output: [0.03496553859804152]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9526282248965412, -0.5898786907957553, -0.48878444800025606, 0.12283208633616839]\n",
      "Layer: Layer 1, Input: [-0.9526282248965412, -0.5898786907957553, -0.48878444800025606, 0.12283208633616839], Output: [0.44114167979904245, -0.8525720639866512, 0.9723776364736373, 0.21612513544848191]\n",
      "Layer: Layer 2, Input: [0.44114167979904245, -0.8525720639866512, 0.9723776364736373, 0.21612513544848191], Output: [0.007376715610083406]\n",
      "Epoch 14/100, Loss: 0.9748032059375041, Accuracy: -2.9449630466255767\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990894417977934, -0.9935680391486343, -0.8940289578206096, 0.8955356079736505]\n",
      "Layer: Layer 1, Input: [-0.9990894417977934, -0.9935680391486343, -0.8940289578206096, 0.8955356079736505], Output: [0.9179545854104395, -0.8630933219608153, 0.9682589603671135, 0.0676853450662805]\n",
      "Layer: Layer 2, Input: [0.9179545854104395, -0.8630933219608153, 0.9682589603671135, 0.0676853450662805], Output: [-0.005445413198191085]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968584785541537, -0.47829176335909185, -0.8658202322183856, 0.9391585916581688]\n",
      "Layer: Layer 1, Input: [-0.9968584785541537, -0.47829176335909185, -0.8658202322183856, 0.9391585916581688], Output: [0.8528688415042743, -0.7804920182293952, 0.9504450137859505, -0.13474743745629095]\n",
      "Layer: Layer 2, Input: [0.8528688415042743, -0.7804920182293952, 0.9504450137859505, -0.13474743745629095], Output: [-0.09379051355260723]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978432592893597, -0.8359806049256067, -0.902760716847311, 0.26841578030433566]\n",
      "Layer: Layer 1, Input: [-0.978432592893597, -0.8359806049256067, -0.902760716847311, 0.26841578030433566], Output: [0.7006430260200309, -0.9189386935673832, 0.9821466777483656, 0.13936139248871118]\n",
      "Layer: Layer 2, Input: [0.7006430260200309, -0.9189386935673832, 0.9821466777483656, 0.13936139248871118], Output: [0.036916936010213786]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9525374947994917, -0.5907476829297222, -0.4920093066674916, 0.11257852959073676]\n",
      "Layer: Layer 1, Input: [-0.9525374947994917, -0.5907476829297222, -0.4920093066674916, 0.11257852959073676], Output: [0.4342662839773778, -0.8549299459927406, 0.972799274600385, 0.21759976397658562]\n",
      "Layer: Layer 2, Input: [0.4342662839773778, -0.8549299459927406, 0.972799274600385, 0.21759976397658562], Output: [0.012467644748557827]\n",
      "Epoch 15/100, Loss: 0.9706382492754497, Accuracy: -2.9361041909072396\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990865951715325, -0.9936071381317914, -0.8955396780175205, 0.8919044619485723]\n",
      "Layer: Layer 1, Input: [-0.9990865951715325, -0.9936071381317914, -0.8955396780175205, 0.8919044619485723], Output: [0.9174634929355129, -0.8635714496445771, 0.968457493996273, 0.0675877450408364]\n",
      "Layer: Layer 2, Input: [0.9174634929355129, -0.8635714496445771, 0.968457493996273, 0.0675877450408364], Output: [-0.004493619712429731]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968568445907361, -0.4549492267788182, -0.865082560096859, 0.9391249701634482]\n",
      "Layer: Layer 1, Input: [-0.9968568445907361, -0.4549492267788182, -0.865082560096859, 0.9391249701634482], Output: [0.848487157131553, -0.7756220441900187, 0.9496340353687092, -0.14469527402587073]\n",
      "Layer: Layer 2, Input: [0.848487157131553, -0.7756220441900187, 0.9496340353687092, -0.14469527402587073], Output: [-0.0991990962154522]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784353915511486, -0.8343593316986928, -0.9029649236827875, 0.26911057892621226]\n",
      "Layer: Layer 1, Input: [-0.9784353915511486, -0.8343593316986928, -0.9029649236827875, 0.26911057892621226], Output: [0.7004952933040592, -0.9187492750098426, 0.9821240162035262, 0.13828264855693087]\n",
      "Layer: Layer 2, Input: [0.7004952933040592, -0.9187492750098426, 0.9821240162035262, 0.13828264855693087], Output: [0.038675581489232835]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9524449733610583, -0.591335306980346, -0.4948595458252813, 0.10198129545139907]\n",
      "Layer: Layer 1, Input: [-0.9524449733610583, -0.591335306980346, -0.4948595458252813, 0.10198129545139907], Output: [0.42681574932110466, -0.8571036342003424, 0.973212476440208, 0.219190947109032]\n",
      "Layer: Layer 2, Input: [0.42681574932110466, -0.8571036342003424, 0.973212476440208, 0.219190947109032], Output: [0.017460788508676828]\n",
      "Epoch 16/100, Loss: 0.9661699915005062, Accuracy: -2.9265093164775333\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990836909259602, -0.9936374279141527, -0.8968653017358531, 0.888028012283303]\n",
      "Layer: Layer 1, Input: [-0.9990836909259602, -0.9936374279141527, -0.8968653017358531, 0.888028012283303], Output: [0.9169207424620951, -0.8639099240645313, 0.9686615009836156, 0.0676713278806354]\n",
      "Layer: Layer 2, Input: [0.9169207424620951, -0.8639099240645313, 0.9686615009836156, 0.0676713278806354], Output: [-0.0036288841806814687]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968551905582033, -0.4295593522233136, -0.8642655089197212, 0.9390925625086417]\n",
      "Layer: Layer 1, Input: [-0.9968551905582033, -0.4295593522233136, -0.8642655089197212, 0.9390925625086417], Output: [0.8435802635416403, -0.770018642591736, 0.9487389692676143, -0.1554629767588676]\n",
      "Layer: Layer 2, Input: [0.8435802635416403, -0.770018642591736, 0.9487389692676143, -0.1554629767588676], Output: [-0.10543315584950849]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978438404650011, -0.8326042128990867, -0.9031378234992925, 0.2698782471839895]\n",
      "Layer: Layer 1, Input: [-0.978438404650011, -0.8326042128990867, -0.9031378234992925, 0.2698782471839895], Output: [0.7003228474672334, -0.9184677543945636, 0.9820993075014234, 0.1372328156530098]\n",
      "Layer: Layer 2, Input: [0.7003228474672334, -0.9184677543945636, 0.9820993075014234, 0.1372328156530098], Output: [0.04036927729871914]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9523505898532296, -0.5916360037745575, -0.4973476529336021, 0.09100307860323677]\n",
      "Layer: Layer 1, Input: [-0.9523505898532296, -0.5916360037745575, -0.4973476529336021, 0.09100307860323677], Output: [0.41874795733379433, -0.8591100754047309, 0.9736186425883537, 0.22093057527251186]\n",
      "Layer: Layer 2, Input: [0.41874795733379433, -0.8591100754047309, 0.9736186425883537, 0.22093057527251186], Output: [0.022498836680652945]\n",
      "Epoch 17/100, Loss: 0.9613493833132165, Accuracy: -2.9160661689492393\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990807272451736, -0.9936588337281458, -0.8980154321713935, 0.8838758353815279]\n",
      "Layer: Layer 1, Input: [-0.9990807272451736, -0.9936588337281458, -0.8980154321713935, 0.8838758353815279], Output: [0.9163213571006512, -0.864115809844946, 0.9688721401830896, 0.06797554940198673]\n",
      "Layer: Layer 2, Input: [0.9163213571006512, -0.864115809844946, 0.9688721401830896, 0.06797554940198673], Output: [-0.0027472954881527234]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968535140441693, -0.40194885969373867, -0.8633642465703251, 0.9390606545254111]\n",
      "Layer: Layer 1, Input: [-0.9968535140441693, -0.40194885969373867, -0.8633642465703251, 0.9390606545254111], Output: [0.8380754876999325, -0.7635971408905716, 0.9477495008505396, -0.16710341803146922]\n",
      "Layer: Layer 2, Input: [0.8380754876999325, -0.7635971408905716, 0.9477495008505396, -0.16710341803146922], Output: [-0.11249936993268514]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784416407184713, -0.8307055998025988, -0.9032800126951052, 0.2707149091407933]\n",
      "Layer: Layer 1, Input: [-0.9784416407184713, -0.8307055998025988, -0.9032800126951052, 0.2707149091407933], Output: [0.7001209061694335, -0.9180925282825952, 0.982072491318983, 0.13623820465142522]\n",
      "Layer: Layer 2, Input: [0.7001209061694335, -0.9180925282825952, 0.982072491318983, 0.13623820465142522], Output: [0.042089111096866916]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9522542840251094, -0.5916427172442111, -0.49948300691168607, 0.07960859854523257]\n",
      "Layer: Layer 1, Input: [-0.9522542840251094, -0.5916427172442111, -0.49948300691168607, 0.07960859854523257], Output: [0.41001915756409796, -0.8609624109567054, 0.9740189693547081, 0.2228469334978883]\n",
      "Layer: Layer 2, Input: [0.41001915756409796, -0.8609624109567054, 0.9740189693547081, 0.2228469334978883], Output: [0.027690717582584012]\n",
      "Epoch 18/100, Loss: 0.9561236407801035, Accuracy: -2.90464631906975\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990777026851442, -0.9936712280566361, -0.8989976770995568, 0.8794144639116069]\n",
      "Layer: Layer 1, Input: [-0.9990777026851442, -0.9936712280566361, -0.8989976770995568, 0.8794144639116069], Output: [0.9156596048896292, -0.8641940586984027, 0.9690906177768045, 0.06853888367957779]\n",
      "Layer: Layer 2, Input: [0.9156596048896292, -0.8641940586984027, 0.9690906177768045, 0.06853888367957779], Output: [-0.0017676977102368263]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968518129863387, -0.37194111699234395, -0.86237260892213, 0.9390287589609173]\n",
      "Layer: Layer 1, Input: [-0.9968518129863387, -0.37194111699234395, -0.86237260892213, 0.9390287589609173], Output: [0.831890180835498, -0.7562564372411671, 0.9466542729109441, -0.17967508957556877]\n",
      "Layer: Layer 2, Input: [0.831890180835498, -0.7562564372411671, 0.9466542729109441, -0.17967508957556877], Output: [-0.12044201770923327]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784451131423618, -0.8286528519966433, -0.9033917753150937, 0.2716173471130315]\n",
      "Layer: Layer 1, Input: [-0.9784451131423618, -0.8286528519966433, -0.9033917753150937, 0.2716173471130315], Output: [0.6998846941890268, -0.9176204369507407, 0.9820434957878011, 0.13532239925890904]\n",
      "Layer: Layer 2, Input: [0.6998846941890268, -0.9176204369507407, 0.9820434957878011, 0.13532239925890904], Output: [0.043903224208144076]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9521560041838162, -0.5913475784211104, -0.501272245973442, 0.0677636827677622]\n",
      "Layer: Layer 1, Input: [-0.9521560041838162, -0.5913475784211104, -0.501272245973442, 0.0677636827677622], Output: [0.4005837429485309, -0.862671066263597, 0.9744144954364264, 0.2249668007878276]\n",
      "Layer: Layer 2, Input: [0.4005837429485309, -0.862671066263597, 0.9744144954364264, 0.2249668007878276], Output: [0.033124820730738525]\n",
      "Epoch 19/100, Loss: 0.9504355795465496, Accuracy: -2.892104083478409\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999074616144173, -0.9936744506679802, -0.899817887718609, 0.8746067098158771]\n",
      "Layer: Layer 1, Input: [-0.999074616144173, -0.9936744506679802, -0.899817887718609, 0.8746067098158771], Output: [0.9149288826147149, -0.8641482549589292, 0.969318195479449, 0.0694007284179034]\n",
      "Layer: Layer 2, Input: [0.9149288826147149, -0.8641482549589292, 0.969318195479449, 0.0694007284179034], Output: [-0.000621793262376158]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968500855284352, -0.3393645875330987, -0.8612830630443908, 0.9389965687769998]\n",
      "Layer: Layer 1, Input: [-0.9968500855284352, -0.3393645875330987, -0.8612830630443908, 0.9389965687769998], Output: [0.8249318553288307, -0.7478784986660416, 0.945441024702006, -0.19323709706214268]\n",
      "Layer: Layer 2, Input: [0.8249318553288307, -0.7478784986660416, 0.945441024702006, -0.19323709706214268], Output: [-0.12933431953099606]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784488395815197, -0.8264345479788657, -0.9034731120647443, 0.2725828584803224]\n",
      "Layer: Layer 1, Input: [-0.9784488395815197, -0.8264345479788657, -0.9034731120647443, 0.2725828584803224], Output: [0.6996095424905905, -0.9170470056453985, 0.982012235570135, 0.13450782759138222]\n",
      "Layer: Layer 2, Input: [0.6996095424905905, -0.9170470056453985, 0.982012235570135, 0.13450782759138222], Output: [0.045865881231197336]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9520557064262982, -0.5907426711858713, -0.5027195381667333, 0.05543471497464294]\n",
      "Layer: Layer 1, Input: [-0.9520557064262982, -0.5907426711858713, -0.5027195381667333, 0.05543471497464294], Output: [0.3903943293069996, -0.8642445382941804, 0.9748061370867911, 0.22731694024302204]\n",
      "Layer: Layer 2, Input: [0.3903943293069996, -0.8642445382941804, 0.9748061370867911, 0.22731694024302204], Output: [0.038877787856581414]\n",
      "Epoch 20/100, Loss: 0.9442235121242838, Accuracy: -2.8782755671059963\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990714668703601, -0.9936683315192186, -0.9004803425793716, 0.8694109733922564]\n",
      "Layer: Layer 1, Input: [-0.9990714668703601, -0.9936683315192186, -0.9004803425793716, 0.8694109733922564], Output: [0.9141215730154432, -0.8639812296522138, 0.9695561997498072, 0.07060266089482593]\n",
      "Layer: Layer 2, Input: [0.9141215730154432, -0.8639812296522138, 0.9695561997498072, 0.07060266089482593], Output: [0.0007524889721866046]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968483299309897, -0.30406446668490617, -0.8600866457875525, 0.9389639257268874]\n",
      "Layer: Layer 1, Input: [-0.9968483299309897, -0.30406446668490617, -0.8600866457875525, 0.9389639257268874], Output: [0.8170991897855276, -0.7383281249622604, 0.9440968755118572, -0.20784335744437737]\n",
      "Layer: Layer 2, Input: [0.8170991897855276, -0.7383281249622604, 0.9440968755118572, -0.20784335744437737], Output: [-0.13927238239065795]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784528417237602, -0.8240387557664512, -0.903523761473325, 0.27360917523740796]\n",
      "Layer: Layer 1, Input: [-0.9784528417237602, -0.8240387557664512, -0.903523761473325, 0.27360917523740796], Output: [0.6992910190616505, -0.9163666093103846, 0.9819786111230325, 0.13381677040127632]\n",
      "Layer: Layer 2, Input: [0.6992910190616505, -0.9163666093103846, 0.9819786111230325, 0.13381677040127632], Output: [0.048023367456740185]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.951953354832259, -0.5898209495429412, -0.5038267963582356, 0.0425883535567332]\n",
      "Layer: Layer 1, Input: [-0.951953354832259, -0.5898209495429412, -0.5038267963582356, 0.0425883535567332], Output: [0.37940214374808556, -0.8656900089700538, 0.9751947161808366, 0.22992514671642414]\n",
      "Layer: Layer 2, Input: [0.37940214374808556, -0.8656900089700538, 0.9751947161808366, 0.22992514671642414], Output: [0.04502031558501263]\n",
      "Epoch 21/100, Loss: 0.9374216990978621, Accuracy: -2.8629781805088834\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990682545016416, -0.993652718529099, -0.900987895890784, 0.8637805164389608]\n",
      "Layer: Layer 1, Input: [-0.9990682545016416, -0.993652718529099, -0.900987895890784, 0.8637805164389608], Output: [0.9132288697816558, -0.8636956318825347, 0.96980603121166, 0.0721891297418542]\n",
      "Layer: Layer 2, Input: [0.9132288697816558, -0.8636956318825347, 0.96980603121166, 0.0721891297418542], Output: [0.0024153733683580647]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968465445291955, -0.265918145775457, -0.8587729001430624, 0.9389307964905292]\n",
      "Layer: Layer 1, Input: [-0.9968465445291955, -0.265918145775457, -0.8587729001430624, 0.9389307964905292], Output: [0.8082844118530689, -0.7274534603899423, 0.9426088108681021, -0.2235356034967545]\n",
      "Layer: Layer 2, Input: [0.8082844118530689, -0.7274534603899423, 0.9426088108681021, -0.2235356034967545], Output: [-0.15037035842949878]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784571452867435, -0.8214533956510427, -0.9035432183102393, 0.2746944283927727]\n",
      "Layer: Layer 1, Input: [-0.9784571452867435, -0.8214533956510427, -0.9035432183102393, 0.2746944283927727], Output: [0.6989250983751548, -0.9155726038289931, 0.9819425090911527, 0.13327190022796903]\n",
      "Layer: Layer 2, Input: [0.6989250983751548, -0.9155726038289931, 0.9819425090911527, 0.13327190022796903], Output: [0.050417677203150824]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9518489225263153, -0.5885773643898914, -0.5045938699734431, 0.029191461255673453]\n",
      "Layer: Layer 1, Input: [-0.9518489225263153, -0.5885773643898914, -0.5045938699734431, 0.029191461255673453], Output: [0.36755774519923645, -0.8670138718408236, 0.9755809841668822, 0.2328209444462535]\n",
      "Layer: Layer 2, Input: [0.36755774519923645, -0.8670138718408236, 0.9755809841668822, 0.2328209444462535], Output: [0.051620884353295315]\n",
      "Epoch 22/100, Loss: 0.9299614646756748, Accuracy: -2.846011061051999\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990649791366685, -0.9936275117332809, -0.9013421053564576, 0.8576626829135752]\n",
      "Layer: Layer 1, Input: [-0.9990649791366685, -0.9936275117332809, -0.9013421053564576, 0.8576626829135752], Output: [0.9122405623693333, -0.8632945256733322, 0.9700691737544239, 0.0742075874008644]\n",
      "Layer: Layer 2, Input: [0.9122405623693333, -0.8632945256733322, 0.9700691737544239, 0.0742075874008644], Output: [0.004427969082332894]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968447277373118, -0.22485478817624477, -0.8573298352899971, 0.9388972497133691]\n",
      "Layer: Layer 1, Input: [-0.9968447277373118, -0.22485478817624477, -0.8573298352899971, 0.9388972497133691], Output: [0.7983776811868518, -0.7150878409719792, 0.9409644337782402, -0.240335020375248]\n",
      "Layer: Layer 2, Input: [0.7983776811868518, -0.7150878409719792, 0.9409644337782402, -0.240335020375248], Output: [-0.16275573274307042]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784617802074811, -0.8186667221695029, -0.9035307538887271, 0.27583714350407545]\n",
      "Layer: Layer 1, Input: [-0.9784617802074811, -0.8186667221695029, -0.9035307538887271, 0.27583714350407545], Output: [0.6985083720644562, -0.9146574582451464, 0.9819038039175316, 0.13289637767225462]\n",
      "Layer: Layer 2, Input: [0.6985083720644562, -0.9146574582451464, 0.9819038039175316, 0.13289637767225462], Output: [0.053088570495808396]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9517423935899576, -0.5870102369013647, -0.5050187415408826, 0.015211209115410606]\n",
      "Layer: Layer 1, Input: [-0.9517423935899576, -0.5870102369013647, -0.5050187415408826, 0.015211209115410606], Output: [0.3548121042003143, -0.8682222329093672, 0.975965643817415, 0.23603596751122524]\n",
      "Layer: Layer 2, Input: [0.3548121042003143, -0.8682222329093672, 0.975965643817415, 0.23603596751122524], Output: [0.05874796807225002]\n",
      "Epoch 23/100, Loss: 0.921773139179286, Accuracy: -2.8271569005981547\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990616414364983, -0.9935927044624551, -0.9015433525885596, 0.850998054151885]\n",
      "Layer: Layer 1, Input: [-0.9990616414364983, -0.9935927044624551, -0.9015433525885596, 0.850998054151885], Output: [0.9111447698384413, -0.862782066223429, 0.9703472030026213, 0.07670800848486997]\n",
      "Layer: Layer 2, Input: [0.9111447698384413, -0.862782066223429, 0.9703472030026213, 0.07670800848486997], Output: [0.006853673625987156]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968428781051093, -0.18087859689081068, -0.8557439425777011, 0.9388634276454552]\n",
      "Layer: Layer 1, Input: [-0.9968428781051093, -0.18087859689081068, -0.8557439425777011, 0.9388634276454552], Output: [0.7872741339649961, -0.7010536579168427, 0.9391530337772056, -0.2582326967986454]\n",
      "Layer: Layer 2, Input: [0.7872741339649961, -0.7010536579168427, 0.9391530337772056, -0.2582326967986454], Output: [-0.17656388957707903]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978466780976778, -0.8156679411694184, -0.9034854429121562, 0.2770362553236684]\n",
      "Layer: Layer 1, Input: [-0.978466780976778, -0.8156679411694184, -0.9034854429121562, 0.2770362553236684], Output: [0.6980382964874092, -0.9136129173076748, 0.981862360815701, 0.1327134792910325]\n",
      "Layer: Layer 2, Input: [0.6980382964874092, -0.9136129173076748, 0.981862360815701, 0.1327134792910325], Output: [0.05607431147000158]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9516337658519798, -0.5851228784575283, -0.5050977547695329, 0.0006153301801639461]\n",
      "Layer: Layer 1, Input: [-0.9516337658519798, -0.5851228784575283, -0.5050977547695329, 0.0006153301801639461], Output: [0.34111805531605216, -0.8693214266651879, 0.9763493697131971, 0.23960400678469693]\n",
      "Layer: Layer 2, Input: [0.34111805531605216, -0.8693214266651879, 0.9763493697131971, 0.23960400678469693], Output: [0.06647103476530991]\n",
      "Epoch 24/100, Loss: 0.9127889834544037, Accuracy: -2.806185713501625\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990582427577062, -0.9935484306937316, -0.9015909680011016, 0.8437195276630942]\n",
      "Layer: Layer 1, Input: [-0.9990582427577062, -0.9935484306937316, -0.9015909680011016, 0.8437195276630942], Output: [0.9099276095921817, -0.862164296388658, 0.9706417940680403, 0.07974170631713416]\n",
      "Layer: Layer 2, Input: [0.9099276095921817, -0.862164296388658, 0.9706417940680403, 0.07974170631713416], Output: [0.009758378379847887]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996840994436258, -0.1340942096813869, -0.8540003075279544, 0.9388295061438208]\n",
      "Layer: Layer 1, Input: [-0.996840994436258, -0.1340942096813869, -0.8540003075279544, 0.9388295061438208], Output: [0.7748841143619006, -0.685168931687639, 0.9371669921698911, -0.27717960329242675]\n",
      "Layer: Layer 2, Input: [0.7748841143619006, -0.685168931687639, 0.9371669921698911, -0.27717960329242675], Output: [-0.19193135163655983]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784721870834635, -0.8124479568333639, -0.9034062016982738, 0.2782911294626642]\n",
      "Layer: Layer 1, Input: [-0.9784721870834635, -0.8124479568333639, -0.9034062016982738, 0.2782911294626642], Output: [0.6975134626147059, -0.912430219340044, 0.9818180401885687, 0.1327456985189766]\n",
      "Layer: Layer 2, Input: [0.6975134626147059, -0.912430219340044, 0.9818180401885687, 0.1327456985189766], Output: [0.059411228633359736]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9515230546059715, -0.5829253966168806, -0.5048259004340155, -0.014627496823495907]\n",
      "Layer: Layer 1, Input: [-0.9515230546059715, -0.5829253966168806, -0.5048259004340155, -0.014627496823495907], Output: [0.326432099286063, -0.8703185698249744, 0.976732827341492, 0.24356066836802434]\n",
      "Layer: Layer 2, Input: [0.326432099286063, -0.8703185698249744, 0.976732827341492, 0.24356066836802434], Output: [0.07486049010847018]\n",
      "Epoch 25/100, Loss: 0.9029471684434026, Accuracy: -2.7828610085084815\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990547853168213, -0.9934950154571498, -0.9014833709222793, 0.8357513088422042]\n",
      "Layer: Layer 1, Input: [-0.9990547853168213, -0.9934950154571498, -0.9014833709222793, 0.8357513088422042], Output: [0.9085727831169806, -0.8614500871541572, 0.9709547287538006, 0.08335936643678596]\n",
      "Layer: Layer 2, Input: [0.9085727831169806, -0.8614500871541572, 0.9709547287538006, 0.08335936643678596], Output: [0.013209498950967125]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968390759803025, -0.08473111135999604, -0.8520828649450626, 0.9387956370814271]\n",
      "Layer: Layer 1, Input: [-0.9968390759803025, -0.08473111135999604, -0.8520828649450626, 0.9387956370814271], Output: [0.7611466768763865, -0.6672571352317107, 0.9350034719708159, -0.2970774826166183]\n",
      "Layer: Layer 2, Input: [0.7611466768763865, -0.6672571352317107, 0.9350034719708159, -0.2970774826166183], Output: [-0.20898742375278817]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784780435312997, -0.8090002100448703, -0.903291842552673, 0.27960157788597534]\n",
      "Layer: Layer 1, Input: [-0.9784780435312997, -0.8090002100448703, -0.903291842552673, 0.27960157788597534], Output: [0.6969338601270574, -0.9111003882737194, 0.9817707033871413, 0.13301325437181924]\n",
      "Layer: Layer 2, Input: [0.6969338601270574, -0.9111003882737194, 0.9817707033871413, 0.13301325437181924], Output: [0.0631321436676276]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9514102972865509, -0.5804365402047816, -0.5041971844481363, -0.030547154794547848]\n",
      "Layer: Layer 1, Input: [-0.9514102972865509, -0.5804365402047816, -0.5041971844481363, -0.030547154794547848], Output: [0.31071647033101407, -0.8712221538201989, 0.9771166894889237, 0.2479425653684547]\n",
      "Layer: Layer 2, Input: [0.31071647033101407, -0.8712221538201989, 0.9771166894889237, 0.2479425653684547], Output: [0.08398663095992992]\n",
      "Epoch 26/100, Loss: 0.8921967089753292, Accuracy: -2.756948590003942\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990512723836449, -0.9934330222141788, -0.9012182334683261, 0.827007803592164]\n",
      "Layer: Layer 1, Input: [-0.9990512723836449, -0.9934330222141788, -0.9012182334683261, 0.827007803592164], Output: [0.9070610567382931, -0.8606522207923438, 0.9712879026427147, 0.08760827853946157]\n",
      "Layer: Layer 2, Input: [0.9070610567382931, -0.8606522207923438, 0.9712879026427147, 0.08760827853946157], Output: [0.017273835867185172]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968371227071606, -0.03316228629905532, -0.849974846718599, 0.9387618683056244]\n",
      "Layer: Layer 1, Input: [-0.9968371227071606, -0.03316228629905532, -0.849974846718599, 0.9387618683056244], Output: [0.7460455876491707, -0.647160384110895, 0.9326662321352754, -0.3177727069566657]\n",
      "Layer: Layer 2, Input: [0.7460455876491707, -0.647160384110895, 0.9326662321352754, -0.3177727069566657], Output: [-0.22784444195971576]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784844013799784, -0.8053215244444784, -0.9031411482572183, 0.2809678538484107]\n",
      "Layer: Layer 1, Input: [-0.9784844013799784, -0.8053215244444784, -0.9031411482572183, 0.2809678538484107], Output: [0.6963010924469081, -0.9096146082992674, 0.9817202193723747, 0.13353197423755567]\n",
      "Layer: Layer 2, Input: [0.6963010924469081, -0.9096146082992674, 0.9817202193723747, 0.13353197423755567], Output: [0.067263704662897]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9512955590702873, -0.5776853315452672, -0.5032050965381007, -0.04717151294582425]\n",
      "Layer: Layer 1, Input: [-0.9512955590702873, -0.5776853315452672, -0.5032050965381007, -0.04717151294582425], Output: [0.29394130060180446, -0.8720426503480677, 0.9775016473403221, 0.25278596752603244]\n",
      "Layer: Layer 2, Input: [0.29394130060180446, -0.8720426503480677, 0.9775016473403221, 0.25278596752603244], Output: [0.09391766354254166]\n",
      "Epoch 27/100, Loss: 0.8805029838036693, Accuracy: -2.7282277632934546\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990477084967281, -0.993363287996216, -0.9007926725224091, 0.8173923972465776]\n",
      "Layer: Layer 1, Input: [-0.9990477084967281, -0.993363287996216, -0.9007926725224091, 0.8173923972465776], Output: [0.9053696112168248, -0.8597885801560737, 0.971643332680523, 0.09252887945602054]\n",
      "Layer: Layer 2, Input: [0.9053696112168248, -0.8597885801560737, 0.971643332680523, 0.09252887945602054], Output: [0.02201435507261179]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968351356639759, 0.020088831845610874, -0.8476594650969385, 0.9387280388346864]\n",
      "Layer: Layer 1, Input: [-0.9968351356639759, 0.020088831845610874, -0.8476594650969385, 0.9387280388346864], Output: [0.729625803844119, -0.6247553831759303, 0.9301672727025295, -0.33905553139959027]\n",
      "Layer: Layer 2, Input: [0.729625803844119, -0.6247553831759303, 0.9301672727025295, -0.33905553139959027], Output: [-0.24858739866857799]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784913182412432, -0.8014128275900714, -0.9029529685732758, 0.2823906118216166]\n",
      "Layer: Layer 1, Input: [-0.9784913182412432, -0.8014128275900714, -0.9029529685732758, 0.2823906118216166], Output: [0.6956184868706071, -0.9079646734724462, 0.9816664714243654, 0.13431059737968043]\n",
      "Layer: Layer 2, Input: [0.6956184868706071, -0.9079646734724462, 0.9816664714243654, 0.13431059737968043], Output: [0.07182273857241045]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9511789392424826, -0.5747121342634404, -0.5018431853365579, -0.06452580218860555]\n",
      "Layer: Layer 1, Input: [-0.9511789392424826, -0.5747121342634404, -0.5018431853365579, -0.06452580218860555], Output: [0.27608662487807983, -0.8727930729605379, 0.9778884126475426, 0.2581248743246738]\n",
      "Layer: Layer 2, Input: [0.27608662487807983, -0.8727930729605379, 0.9778884126475426, 0.2581248743246738], Output: [0.10471690237396425]\n",
      "Epoch 28/100, Loss: 0.8678531567348564, Accuracy: -2.6965040824572566\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990440996882097, -0.993286934913164, -0.9002034673783983, 0.8067961028300223]\n",
      "Layer: Layer 1, Input: [-0.9990440996882097, -0.993286934913164, -0.9002034673783983, 0.8067961028300223], Output: [0.9034712297451898, -0.8588833638531743, 0.9720231657824192, 0.09815091324211762]\n",
      "Layer: Layer 2, Input: [0.9034712297451898, -0.8588833638531743, 0.9720231657824192, 0.09815091324211762], Output: [0.02748616257579506]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968331173976438, 0.07435883887175934, -0.8451208535021368, 0.9386936513798309]\n",
      "Layer: Layer 1, Input: [-0.9968331173976438, 0.07435883887175934, -0.8451208535021368, 0.9386936513798309], Output: [0.7120070564150036, -0.5999705738375875, 0.9275279038453192, -0.3606668750516197]\n",
      "Layer: Layer 2, Input: [0.7120070564150036, -0.5999705738375875, 0.9275279038453192, -0.3606668750516197], Output: [-0.27126424187954185]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784988586349941, -0.7972795781622316, -0.902726337000728, 0.28387082051411294]\n",
      "Layer: Layer 1, Input: [-0.9784988586349941, -0.7972795781622316, -0.902726337000728, 0.28387082051411294], Output: [0.6948910406384646, -0.9061434832672214, 0.9816093626591444, 0.1353476746700971]\n",
      "Layer: Layer 2, Input: [0.6948910406384646, -0.9061434832672214, 0.9816093626591444, 0.1353476746700971], Output: [0.07681190171170521]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.951060577987432, -0.5715687536909113, -0.5001057251738722, -0.08263197898470401]\n",
      "Layer: Layer 1, Input: [-0.951060577987432, -0.5715687536909113, -0.5001057251738722, -0.08263197898470401], Output: [0.257143906218082, -0.8734894067284723, 0.9782777070024148, 0.2639885654753699]\n",
      "Layer: Layer 2, Input: [0.257143906218082, -0.8734894067284723, 0.9782777070024148, 0.2639885654753699], Output: [0.11643939235568762]\n",
      "Epoch 29/100, Loss: 0.8542605470484294, Accuracy: -2.661622104900681\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999040453698119, -0.9932053469442145, -0.8994472915696439, 0.7950960628519096]\n",
      "Layer: Layer 1, Input: [-0.999040453698119, -0.9932053469442145, -0.8994472915696439, 0.7950960628519096], Output: [0.9013332891113941, -0.8579682019600006, 0.9724296884131384, 0.10448973093703368]\n",
      "Layer: Layer 2, Input: [0.9013332891113941, -0.8579682019600006, 0.9724296884131384, 0.10448973093703368], Output: [0.03373219815574696]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968310724040065, 0.12887561951815985, -0.8423452504606872, 0.9386577303509351]\n",
      "Layer: Layer 1, Input: [-0.9968310724040065, 0.12887561951815985, -0.8423452504606872, 0.9386577303509351], Output: [0.693390320248567, -0.5728020404859616, 0.9247788062073562, -0.3823135164665157]\n",
      "Layer: Layer 2, Input: [0.693390320248567, -0.5728020404859616, 0.9247788062073562, -0.3823135164665157], Output: [-0.2958784002974486]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785070940854734, -0.7929317286620309, -0.9024606009549339, 0.2854096235478473]\n",
      "Layer: Layer 1, Input: [-0.9785070940854734, -0.7929317286620309, -0.9024606009549339, 0.2854096235478473], Output: [0.6941251567471882, -0.9041455320163716, 0.9815488189524413, 0.13662839522145417]\n",
      "Layer: Layer 2, Input: [0.6941251567471882, -0.9041455320163716, 0.9815488189524413, 0.13662839522145417], Output: [0.08221512157864758]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9509406630394788, -0.5683172152747618, -0.49798843284854416, -0.10150811255598771]\n",
      "Layer: Layer 1, Input: [-0.9509406630394788, -0.5683172152747618, -0.49798843284854416, -0.10150811255598771], Output: [0.23711676942811744, -0.8741507970530604, 0.9786702351774591, 0.27039881203865496]\n",
      "Layer: Layer 2, Input: [0.23711676942811744, -0.8741507970530604, 0.9786702351774591, 0.27039881203865496], Output: [0.12912835445055237]\n",
      "Epoch 30/100, Loss: 0.8397669211110236, Accuracy: -2.6234761686749\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990367801518637, -0.9931201049992978, -0.8985209377778575, 0.7821538988723887]\n",
      "Layer: Layer 1, Input: [-0.9990367801518637, -0.9931201049992978, -0.8985209377778575, 0.7821538988723887], Output: [0.8989165123162066, -0.8570830121765768, 0.9728653357980318, 0.11154341604815612]\n",
      "Layer: Layer 2, Input: [0.8989165123162066, -0.8570830121765768, 0.9728653357980318, 0.11154341604815612], Output: [0.040779405374582245]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968290075421781, 0.18280917294708562, -0.8393223635877884, 0.9386186801624525]\n",
      "Layer: Layer 1, Input: [-0.9968290075421781, 0.18280917294708562, -0.8393223635877884, 0.9386186801624525], Output: [0.6740533928406743, -0.5433253219029084, 0.9219587775295077, -0.40369050808369894]\n",
      "Layer: Layer 2, Input: [0.6740533928406743, -0.5433253219029084, 0.9219587775295077, -0.40369050808369894], Output: [-0.3223848577123307]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785161028260273, -0.7883831055726109, -0.9021555529704899, 0.28700815320998246]\n",
      "Layer: Layer 1, Input: [-0.9785161028260273, -0.7883831055726109, -0.9021555529704899, 0.28700815320998246], Output: [0.6933281559325207, -0.9019673217692254, 0.981484788105167, 0.13812180234565746]\n",
      "Layer: Layer 2, Input: [0.6933281559325207, -0.9019673217692254, 0.981484788105167, 0.13812180234565746], Output: [0.08799351312820586]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9508194354257892, -0.565027048977713, -0.49548916477789284, -0.12116781590804465]\n",
      "Layer: Layer 1, Input: [-0.9508194354257892, -0.565027048977713, -0.49548916477789284, -0.12116781590804465], Output: [0.21602073799963029, -0.8747993892281908, 0.9790666419377267, 0.27736707199069544]\n",
      "Layer: Layer 2, Input: [0.21602073799963029, -0.8747993892281908, 0.9790666419377267, 0.27736707199069544], Output: [0.14281198272014006]\n",
      "Epoch 31/100, Loss: 0.8244419029470778, Accuracy: -2.582017267321153\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990330906712794, -0.9930328811547188, -0.8974215073651891, 0.7678139290135082]\n",
      "Layer: Layer 1, Input: [-0.9990330906712794, -0.9930328811547188, -0.8974215073651891, 0.7678139290135082], Output: [0.8961734311710529, -0.8562764240770012, 0.9733326973337978, 0.11929144125137345]\n",
      "Layer: Layer 2, Input: [0.8961734311710529, -0.8562764240770012, 0.9733326973337978, 0.11929144125137345], Output: [0.04863623177328541]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968269323385776, 0.23533522286802064, -0.836046800022507, 0.9385741639723161]\n",
      "Layer: Layer 1, Input: [-0.9968269323385776, 0.23533522286802064, -0.836046800022507, 0.9385741639723161], Output: [0.6543339520652676, -0.5117006743569865, 0.9191121527832434, -0.4245073482793448]\n",
      "Layer: Layer 2, Input: [0.6543339520652676, -0.5117006743569865, 0.9191121527832434, -0.4245073482793448], Output: [-0.35069037125986546]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785259689953119, -0.7836501965770213, -0.9018115461668185, 0.2886673170420345]\n",
      "Layer: Layer 1, Input: [-0.9785259689953119, -0.7836501965770213, -0.9018115461668185, 0.2886673170420345], Output: [0.692507598725734, -0.8996076212595995, 0.9814172347468461, 0.1397789042304071]\n",
      "Layer: Layer 2, Input: [0.692507598725734, -0.8996076212595995, 0.9814172347468461, 0.1397789042304071], Output: [0.09408251771338227]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9506971934120522, -0.5617712085994359, -0.4926085051381897, -0.14161971407563656]\n",
      "Layer: Layer 1, Input: [-0.9506971934120522, -0.5617712085994359, -0.4926085051381897, -0.14161971407563656], Output: [0.1938819812607469, -0.8754597402561232, 0.9794674552690187, 0.28489209330786863]\n",
      "Layer: Layer 2, Input: [0.1938819812607469, -0.8754597402561232, 0.9794674552690187, 0.28489209330786863], Output: [0.15750114167177376]\n",
      "Epoch 32/100, Loss: 0.8083792238299008, Accuracy: -2.5372547730084576\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999029398891467, -0.992945302846399, -0.8961465339833725, 0.7519013225757242]\n",
      "Layer: Layer 1, Input: [-0.999029398891467, -0.992945302846399, -0.8961465339833725, 0.7519013225757242], Output: [0.893046493293743, -0.8556056155957424, 0.9738345120452313, 0.12769537825966792]\n",
      "Layer: Layer 2, Input: [0.893046493293743, -0.8556056155957424, 0.9738345120452313, 0.12769537825966792], Output: [0.057292176640332065]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.99682485910871, 0.2857004835878796, -0.8325194113697216, 0.938521024839064]\n",
      "Layer: Layer 1, Input: [-0.99682485910871, 0.2857004835878796, -0.8325194113697216, 0.938521024839064], Output: [0.634601894333435, -0.47817054759971533, 0.916285260445471, -0.44451299841488867]\n",
      "Layer: Layer 2, Input: [0.634601894333435, -0.47817054759971533, 0.916285260445471, -0.44451299841488867], Output: [-0.38065747141858597]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785367812557518, -0.7787504704576285, -0.9014295757954893, 0.2903875924698313]\n",
      "Layer: Layer 1, Input: [-0.9785367812557518, -0.7787504704576285, -0.9014295757954893, 0.2903875924698313], Output: [0.6916704998553789, -0.8970675022899985, 0.9813461313533229, 0.14153208936271414]\n",
      "Layer: Layer 2, Input: [0.6916704998553789, -0.8970675022899985, 0.9813461313533229, 0.14153208936271414], Output: [0.10039087500711744]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9505742937984435, -0.5586210919464673, -0.48935015290765943, -0.16286690773401719]\n",
      "Layer: Layer 1, Input: [-0.9505742937984435, -0.5586210919464673, -0.48935015290765943, -0.16286690773401719], Output: [0.17073534014912922, -0.8761577819361979, 0.979873022464889, 0.29295835074599197]\n",
      "Layer: Layer 2, Input: [0.17073534014912922, -0.8761577819361979, 0.979873022464889, 0.29295835074599197], Output: [0.17318837865054518]\n",
      "Epoch 33/100, Loss: 0.7916901857326466, Accuracy: -2.489252848297654\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990257203634704, -0.9928588062212047, -0.8946940154235362, 0.7342203382600334]\n",
      "Layer: Layer 1, Input: [-0.9990257203634704, -0.9928588062212047, -0.8946940154235362, 0.7342203382600334], Output: [0.8894657302629105, -0.8551354471592668, 0.9743736449980579, 0.13670181710824927]\n",
      "Layer: Layer 2, Input: [0.8894657302629105, -0.8551354471592668, 0.9743736449980579, 0.13670181710824927], Output: [0.06671972618642685]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996822802848783, 0.33327744897240796, -0.8287483869807831, 0.9384552684003327]\n",
      "Layer: Layer 1, Input: [-0.996822802848783, 0.33327744897240796, -0.8287483869807831, 0.9384552684003327], Output: [0.6152261061965038, -0.4430496224637421, 0.9135225805319807, -0.4635149753152993]\n",
      "Layer: Layer 2, Input: [0.6152261061965038, -0.4430496224637421, 0.9135225805319807, -0.4635149753152993], Output: [-0.41211114863437154]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785486308415821, -0.7737004716869487, -0.9010113112341113, 0.29216887798068464]\n",
      "Layer: Layer 1, Input: [-0.9785486308415821, -0.7737004716869487, -0.9010113112341113, 0.29216887798068464], Output: [0.690822548737075, -0.8943501071840116, 0.9812714464607533, 0.14329602599405272]\n",
      "Layer: Layer 2, Input: [0.690822548737075, -0.8943501071840116, 0.9812714464607533, 0.14329602599405272], Output: [0.10680169890351732]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9504511499343473, -0.5556413776049193, -0.4857210343182436, -0.18490635699009933]\n",
      "Layer: Layer 1, Input: [-0.9504511499343473, -0.5556413776049193, -0.4857210343182436, -0.18490635699009933], Output: [0.14662212106092207, -0.8769193864604282, 0.9802834475401238, 0.3015356246554925]\n",
      "Layer: Layer 2, Input: [0.14662212106092207, -0.8769193864604282, 0.9802834475401238, 0.3015356246554925], Output: [0.1898483952647383]\n",
      "Epoch 34/100, Loss: 0.7744952486000919, Accuracy: -2.4381224288179806\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999022072335409, -0.992774501452467, -0.8930623384475936, 0.7145529002146291]\n",
      "Layer: Layer 1, Input: [-0.999022072335409, -0.992774501452467, -0.8930623384475936, 0.7145529002146291], Output: [0.8853458860660293, -0.8549368328451961, 0.9749530330010092, 0.14624721143514915]\n",
      "Layer: Layer 2, Input: [0.8853458860660293, -0.8549368328451961, 0.9749530330010092, 0.14624721143514915], Output: [0.07687850964120407]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968207808882837, 0.3775995543441008, -0.8247499435400704, 0.9383721189082412]\n",
      "Layer: Layer 1, Input: [-0.9968207808882837, 0.3775995543441008, -0.8247499435400704, 0.9383721189082412], Output: [0.5965425041223981, -0.4067090684110402, 0.9108633560184454, -0.48138949542935533]\n",
      "Layer: Layer 2, Input: [0.5965425041223981, -0.4067090684110402, 0.9108633560184454, -0.48138949542935533], Output: [-0.444846959077288]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785616091302292, -0.768513982962372, -0.900559068905247, 0.29401045754885097]\n",
      "Layer: Layer 1, Input: [-0.9785616091302292, -0.768513982962372, -0.900559068905247, 0.29401045754885097], Output: [0.6899674523340505, -0.891460130864126, 0.9811931313265281, 0.14496992699430059]\n",
      "Layer: Layer 2, Input: [0.6899674523340505, -0.891460130864126, 0.9811931313265281, 0.14496992699430059], Output: [0.11317549114206271]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.950328226191706, -0.5528854556881192, -0.48173110353024706, -0.20772809166048098]\n",
      "Layer: Layer 1, Input: [-0.950328226191706, -0.5528854556881192, -0.48173110353024706, -0.20772809166048098], Output: [0.12158824002109887, -0.8777686540257738, 0.9806985381104127, 0.3105798196683854]\n",
      "Layer: Layer 2, Input: [0.12158824002109887, -0.8777686540257738, 0.9806985381104127, 0.3105798196683854], Output: [0.20743980889328895]\n",
      "Epoch 35/100, Loss: 0.7569148788536144, Accuracy: -2.3840102135302814\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.99901847341899, -0.9926930702383797, -0.8912500948798562, 0.6926579029462059]\n",
      "Layer: Layer 1, Input: [-0.99901847341899, -0.9926930702383797, -0.8912500948798562, 0.6926579029462059], Output: [0.8805828937549088, -0.8550843417706551, 0.9755755862958049, 0.15626399802409974]\n",
      "Layer: Layer 2, Input: [0.8805828937549088, -0.8550843417706551, 0.9755755862958049, 0.15626399802409974], Output: [0.08772105910980432]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968188123362015, 0.41837318268108004, -0.8205484973664998, 0.9382661506602377]\n",
      "Layer: Layer 1, Input: [-0.9968188123362015, 0.41837318268108004, -0.8205484973664998, 0.9382661506602377], Output: [0.5788294078702001, -0.36955727458275167, 0.9083392395518027, -0.49808218339372035]\n",
      "Layer: Layer 2, Input: [0.5788294078702001, -0.36955727458275167, 0.9083392395518027, -0.49808218339372035], Output: [-0.47863964624274846]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785758049020716, -0.7632005183414512, -0.9000757246965522, 0.29591113633144617]\n",
      "Layer: Layer 1, Input: [-0.9785758049020716, -0.7632005183414512, -0.9000757246965522, 0.29591113633144617], Output: [0.6891064909275203, -0.8884030322420261, 0.9811111058258634, 0.14644080043395222]\n",
      "Layer: Layer 2, Input: [0.6891064909275203, -0.8884030322420261, 0.9811111058258634, 0.14644080043395222], Output: [0.11935455126242323]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9502060290695487, -0.5503920833732268, -0.47739283868633414, -0.23131416088539206]\n",
      "Layer: Layer 1, Input: [-0.9502060290695487, -0.5503920833732268, -0.47739283868633414, -0.23131416088539206], Output: [0.09568322691237256, -0.8787260909868679, 0.9811177674478287, 0.32003489004554403]\n",
      "Layer: Layer 2, Input: [0.09568322691237256, -0.8787260909868679, 0.9811177674478287, 0.32003489004554403], Output: [0.22590780351573425]\n",
      "Epoch 36/100, Loss: 0.7390607061378398, Accuracy: -2.327086042394136\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990149431611838, -0.9926147082159515, -0.8892558005457594, 0.6682717980333036]\n",
      "Layer: Layer 1, Input: [-0.9990149431611838, -0.9926147082159515, -0.8892558005457594, 0.6682717980333036], Output: [0.8750495924180647, -0.8556530693102956, 0.9762440327815219, 0.16668714656222128]\n",
      "Layer: Layer 2, Input: [0.8750495924180647, -0.8556530693102956, 0.9762440327815219, 0.16668714656222128], Output: [0.09919931372095481]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968169173846807, 0.45546876484278187, -0.8161762605585602, 0.938131486994699]\n",
      "Layer: Layer 1, Input: [-0.9968169173846807, 0.45546876484278187, -0.8161762605585602, 0.938131486994699], Output: [0.5622936273380766, -0.33201922002648165, 0.9059732231209352, -0.5136010810191634]\n",
      "Layer: Layer 2, Input: [0.5622936273380766, -0.33201922002648165, 0.9059732231209352, -0.5136010810191634], Output: [-0.5132519228135748]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9785913014906408, -0.7577643173704188, -0.8995645726343399, 0.29786959973303384]\n",
      "Layer: Layer 1, Input: [-0.9785913014906408, -0.7577643173704188, -0.8995645726343399, 0.29786959973303384], Output: [0.6882383352601887, -0.8851840190088147, 0.9810252435227705, 0.14758716713564235]\n",
      "Layer: Layer 2, Input: [0.6882383352601887, -0.8851840190088147, 0.9810252435227705, 0.14758716713564235], Output: [0.12516805557011046]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9500850954940697, -0.5481836106700838, -0.4727204822816172, -0.2556372694366058]\n",
      "Layer: Layer 1, Input: [-0.9500850954940697, -0.5481836106700838, -0.4727204822816172, -0.2556372694366058], Output: [0.06896039132212671, -0.8798068702012248, 0.9815402541070768, 0.3298355636914616]\n",
      "Layer: Layer 2, Input: [0.06896039132212671, -0.8798068702012248, 0.9815402541070768, 0.3298355636914616], Output: [0.24518719746548473]\n",
      "Epoch 37/100, Loss: 0.7210277717977284, Accuracy: -2.2675296215700964\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990115015499572, -0.9925391156442197, -0.8870775397373433, 0.6411111941883262]\n",
      "Layer: Layer 1, Input: [-0.9990115015499572, -0.9925391156442197, -0.8870775397373433, 0.6411111941883262], Output: [0.8685906088500249, -0.8567148556957929, 0.9769606932560072, 0.1774602947193363]\n",
      "Layer: Layer 2, Input: [0.8685906088500249, -0.8567148556957929, 0.9769606932560072, 0.1774602947193363], Output: [0.11127101394579195]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968151165473129, 0.4888970633343983, -0.8116722656389678, 0.9379620511380893]\n",
      "Layer: Layer 1, Input: [-0.9968151165473129, 0.4888970633343983, -0.8116722656389678, 0.9379620511380893], Output: [0.5470674346514045, -0.29451624716165326, 0.9037797549681846, -0.5280048670209607]\n",
      "Layer: Layer 2, Input: [0.5470674346514045, -0.29451624716165326, 0.9037797549681846, -0.5280048670209607], Output: [-0.5484433875106052]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9786081740234147, -0.7522038980533584, -0.8990291434022292, 0.29988503510573533]\n",
      "Layer: Layer 1, Input: [-0.9786081740234147, -0.7522038980533584, -0.8990291434022292, 0.29988503510573533], Output: [0.6873591301160066, -0.8818068774435712, 0.9809353550394516, 0.14828273397119482]\n",
      "Layer: Layer 2, Input: [0.6873591301160066, -0.8818068774435712, 0.9809353550394516, 0.14828273397119482], Output: [0.13043710845767456]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9499659791578623, -0.5462658092196883, -0.46772910701717924, -0.2806591055768585]\n",
      "Layer: Layer 1, Input: [-0.9499659791578623, -0.5462658092196883, -0.46772910701717924, -0.2806591055768585], Output: [0.041478179175503456, -0.881019362826086, 0.9819647587167446, 0.33991047971007227]\n",
      "Layer: Layer 2, Input: [0.041478179175503456, -0.881019362826086, 0.9819647587167446, 0.33991047971007227], Output: [0.26520553552191195]\n",
      "Epoch 38/100, Loss: 0.7028883865354066, Accuracy: -2.2055171714793653\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990081684876938, -0.9924655314162275, -0.8847125661763656, 0.6108783781519681]\n",
      "Layer: Layer 1, Input: [-0.9990081684876938, -0.9924655314162275, -0.8847125661763656, 0.6108783781519681], Output: [0.8610164076144305, -0.8583339616412629, 0.9777271810557621, 0.18854075229283748]\n",
      "Layer: Layer 2, Input: [0.8610164076144305, -0.8583339616412629, 0.9777271810557621, 0.18854075229283748], Output: [0.12390531081436967]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968134299056546, 0.51877789662846, -0.8070808892829503, 0.9377518484372313]\n",
      "Layer: Layer 1, Input: [-0.9968134299056546, 0.51877789662846, -0.8070808892829503, 0.9377518484372313], Output: [0.5332141676596122, -0.2574476434271658, 0.9017657192573821, -0.5413892412178263]\n",
      "Layer: Layer 2, Input: [0.5332141676596122, -0.2574476434271658, 0.9017657192573821, -0.5413892412178263], Output: [-0.5839794926425064]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9786264869211063, -0.7465121313834265, -0.898473001066436, 0.3019580354514201]\n",
      "Layer: Layer 1, Input: [-0.9786264869211063, -0.7465121313834265, -0.898473001066436, 0.3019580354514201], Output: [0.6864628145298773, -0.8782727436277429, 0.98084116844188, 0.14839963062613584]\n",
      "Layer: Layer 2, Input: [0.6864628145298773, -0.8782727436277429, 0.98084116844188, 0.14839963062613584], Output: [0.134979248472817]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.949849235885007, -0.5446290889297666, -0.46243360837675396, -0.3063284368982903]\n",
      "Layer: Layer 1, Input: [-0.949849235885007, -0.5446290889297666, -0.46243360837675396, -0.3063284368982903], Output: [0.013302483957122045, -0.8823641053443342, 0.9823896960697265, 0.3501853688075694]\n",
      "Layer: Layer 2, Input: [0.013302483957122045, -0.8823641053443342, 0.9823896960697265, 0.3501853688075694], Output: [0.2858859663642982]\n",
      "Epoch 39/100, Loss: 0.6846879286151563, Accuracy: -2.1412084786516425\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990049632666612, -0.992392799986385, -0.8821568969307062, 0.5772707946724934]\n",
      "Layer: Layer 1, Input: [-0.9990049632666612, -0.992392799986385, -0.8821568969307062, 0.5772707946724934], Output: [0.8520966679186968, -0.8605623433002235, 0.9785440285761631, 0.19990282970454581]\n",
      "Layer: Layer 2, Input: [0.8520966679186968, -0.8605623433002235, 0.9785440285761631, 0.19990282970454581], Output: [0.1370871492146258]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968118764225946, 0.5453076013890604, -0.8024500060932499, 0.9374952580480763]\n",
      "Layer: Layer 1, Input: [-0.9968118764225946, 0.5453076013890604, -0.8024500060932499, 0.9374952580480763], Output: [0.5207391423356219, -0.22117522314079205, 0.8999318798983919, -0.5538737317685654]\n",
      "Layer: Layer 2, Input: [0.5207391423356219, -0.22117522314079205, 0.8999318798983919, -0.5538737317685654], Output: [-0.6196401488726198]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9786462917746995, -0.740676741044135, -0.8978995387245259, 0.30409177589056613]\n",
      "Layer: Layer 1, Input: [-0.9786462917746995, -0.740676741044135, -0.8978995387245259, 0.30409177589056613], Output: [0.6855416244498613, -0.8745789305574556, 0.9807423055541252, 0.14781098593360495]\n",
      "Layer: Layer 2, Input: [0.6855416244498613, -0.8745789305574556, 0.9807423055541252, 0.14781098593360495], Output: [0.1386121157729829]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.949735409028307, -0.5432507435621772, -0.45684773276871343, -0.33257912852431254]\n",
      "Layer: Layer 1, Input: [-0.949735409028307, -0.5432507435621772, -0.45684773276871343, -0.33257912852431254], Output: [-0.015490538325731771, -0.8838333195393399, 0.9828131605663846, 0.3605859766808274]\n",
      "Layer: Layer 2, Input: [-0.015490538325731771, -0.8838333195393399, 0.9828131605663846, 0.3605859766808274], Output: [0.30714980671464076]\n",
      "Epoch 40/100, Loss: 0.6664427862301933, Accuracy: -2.0747350109710965\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990019040783448, -0.9923194584839834, -0.8794049382615207, 0.5399955313216781]\n",
      "Layer: Layer 1, Input: [-0.9990019040783448, -0.9923194584839834, -0.8794049382615207, 0.5399955313216781], Output: [0.8415534145927088, -0.8634347164033112, 0.979410257778888, 0.21153910061392453]\n",
      "Layer: Layer 2, Input: [0.8415534145927088, -0.8634347164033112, 0.979410257778888, 0.21153910061392453], Output: [0.1508201895807609]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968104733617419, 0.5687295386938302, -0.7978289475466865, 0.9371873132826976]\n",
      "Layer: Layer 1, Input: [-0.9968104733617419, 0.5687295386938302, -0.7978289475466865, 0.9371873132826976], Output: [0.5096026772441687, -0.18601191352355, 0.8982744379718045, -0.5655902519588554]\n",
      "Layer: Layer 2, Input: [0.5096026772441687, -0.18601191352355, 0.8982744379718045, -0.5655902519588554], Output: [-0.6552272214447271]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9786676256660496, -0.7346811086051058, -0.8973117935307415, 0.3062934136424026]\n",
      "Layer: Layer 1, Input: [-0.9786676256660496, -0.7346811086051058, -0.8973117935307415, 0.3062934136424026], Output: [0.6845867067548801, -0.8707179318041699, 0.9806382539321118, 0.14639278504743528]\n",
      "Layer: Layer 2, Input: [0.6845867067548801, -0.8707179318041699, 0.9806382539321118, 0.14639278504743528], Output: [0.14115618175642572]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.949625015826503, -0.5420978204192037, -0.45098324535732937, -0.3593283174223297]\n",
      "Layer: Layer 1, Input: [-0.949625015826503, -0.5420978204192037, -0.45098324535732937, -0.3593283174223297], Output: [-0.04481174875163118, -0.8854110412626003, 0.9832329638752922, 0.37104052111130764]\n",
      "Layer: Layer 2, Input: [-0.04481174875163118, -0.8854110412626003, 0.9832329638752922, 0.37104052111130764], Output: [0.3289187743750771]\n",
      "Epoch 41/100, Loss: 0.6481405154508828, Accuracy: -2.0061899963558605\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989990075832794, -0.9922438315782486, -0.8764491816461383, 0.49878962336387683]\n",
      "Layer: Layer 1, Input: [-0.9989990075832794, -0.9922438315782486, -0.8764491816461383, 0.49878962336387683], Output: [0.8290547586531848, -0.866963684458891, 0.9803229324222565, 0.2234593340683893]\n",
      "Layer: Layer 2, Input: [0.8290547586531848, -0.866963684458891, 0.9803229324222565, 0.2234593340683893], Output: [0.16512818727101047]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968092358331394, 0.5893098879719849, -0.7932664587610467, 0.9368239522917593]\n",
      "Layer: Layer 1, Input: [-0.9968092358331394, 0.5893098879719849, -0.7932664587610467, 0.9368239522917593], Output: [0.4997328345420662, -0.15221502554438143, 0.8967864606493435, -0.5766739181551681]\n",
      "Layer: Layer 2, Input: [0.4997328345420662, -0.15221502554438143, 0.8967864606493435, -0.5766739181551681], Output: [-0.690570058980448]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978690509945924, -0.7285052673590652, -0.8967122986840136, 0.3085756099271398]\n",
      "Layer: Layer 1, Input: [-0.978690509945924, -0.7285052673590652, -0.8967122986840136, 0.3085756099271398], Output: [0.683588761432732, -0.8666767136496849, 0.9805283355689476, 0.14402508396760663]\n",
      "Layer: Layer 2, Input: [0.683588761432732, -0.8666767136496849, 0.9805283355689476, 0.14402508396760663], Output: [0.1424365827504177]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9495185354960701, -0.5411302329710415, -0.4448493253667155, -0.38647504988179066]\n",
      "Layer: Layer 1, Input: [-0.9495185354960701, -0.5411302329710415, -0.4448493253667155, -0.38647504988179066], Output: [-0.07455706988743631, -0.8870738452318497, 0.9836466847114728, 0.38148156145756756]\n",
      "Layer: Layer 2, Input: [-0.07455706988743631, -0.8870738452318497, 0.9836466847114728, 0.38148156145756756], Output: [0.3511168982470536]\n",
      "Epoch 42/100, Loss: 0.6297421143589322, Accuracy: -1.9356214382519052\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989962885606867, -0.9921641237207125, -0.8732800043185818, 0.45344640177757956]\n",
      "Layer: Layer 1, Input: [-0.9989962885606867, -0.9921641237207125, -0.8732800043185818, 0.45344640177757956], Output: [0.8142107300308297, -0.8711353465066466, 0.98127675437334, 0.2356869557605045]\n",
      "Layer: Layer 2, Input: [0.8142107300308297, -0.8711353465066466, 0.98127675437334, 0.2356869557605045], Output: [0.180054873733379]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996808176469922, 0.6073193682182008, -0.7888088317245846, 0.9364022235427125]\n",
      "Layer: Layer 1, Input: [-0.996808176469922, 0.6073193682182008, -0.7888088317245846, 0.9364022235427125], Output: [0.4910364584313468, -0.11998438560106864, 0.8954590545304691, -0.5872560879836378]\n",
      "Layer: Layer 2, Input: [0.4910364584313468, -0.11998438560106864, 0.8954590545304691, -0.5872560879836378], Output: [-0.7255283715259356]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9787149494355485, -0.7221269862774096, -0.8961029849543888, 0.3109580141972359]\n",
      "Layer: Layer 1, Input: [-0.9787149494355485, -0.7221269862774096, -0.8961029849543888, 0.3109580141972359], Output: [0.6825386245341749, -0.8624363852507927, 0.9804116750192803, 0.14059275794286527]\n",
      "Layer: Layer 2, Input: [0.6825386245341749, -0.8624363852507927, 0.9804116750192803, 0.14059275794286527], Output: [0.14228420184344484]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9494163996229102, -0.5403037997874596, -0.43845225104250724, -0.4138997365299291]\n",
      "Layer: Layer 1, Input: [-0.9494163996229102, -0.5403037997874596, -0.43845225104250724, -0.4138997365299291], Output: [-0.10460694038564419, -0.8887920891609583, 0.9840517312008018, 0.39184723561375323]\n",
      "Layer: Layer 2, Input: [-0.10460694038564419, -0.8887920891609583, 0.9840517312008018, 0.39184723561375323], Output: [0.37367211311106296]\n",
      "Epoch 43/100, Loss: 0.6111861261503666, Accuracy: -1.8630288434730673\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989937596483425, -0.9920785014129931, -0.8698856024369996, 0.4038470930347899]\n",
      "Layer: Layer 1, Input: [-0.9989937596483425, -0.9920785014129931, -0.8698856024369996, 0.4038470930347899], Output: [0.796573522455145, -0.875905982584656, 0.9822637886457242, 0.24825305972777156]\n",
      "Layer: Layer 2, Input: [0.796573522455145, -0.875905982584656, 0.9822637886457242, 0.24825305972777156], Output: [0.19566248495502186]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968073052287212, 0.623020516553323, -0.7844983521389173, 0.9359204340103426]\n",
      "Layer: Layer 1, Input: [-0.9968073052287212, 0.623020516553323, -0.7844983521389173, 0.9359204340103426], Output: [0.48340793712481134, -0.0894649088569241, 0.8942822473201238, -0.5974592851976415]\n",
      "Layer: Layer 2, Input: [0.48340793712481134, -0.0894649088569241, 0.8942822473201238, -0.5974592851976415], Output: [-0.7599921637158655]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9787409319755894, -0.7155228717241443, -0.895485138123368, 0.3134685082037441]\n",
      "Layer: Layer 1, Input: [-0.9787409319755894, -0.7155228717241443, -0.895485138123368, 0.3134685082037441], Output: [0.6814277206120265, -0.8579723036130386, 0.9802871710062476, 0.13598602718751493]\n",
      "Layer: Layer 2, Input: [0.6814277206120265, -0.8579723036130386, 0.9802871710062476, 0.13598602718751493], Output: [0.14053622695159373]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.949318985171565, -0.5395729771976153, -0.43179540606006106, -0.4414647609132011]\n",
      "Layer: Layer 1, Input: [-0.949318985171565, -0.5395729771976153, -0.43179540606006106, -0.4414647609132011], Output: [-0.1348276619405796, -0.8905315496667651, 0.9844454157141463, 0.40208187966960524]\n",
      "Layer: Layer 2, Input: [-0.1348276619405796, -0.8905315496667651, 0.9844454157141463, 0.40208187966960524], Output: [0.3965175389366181]\n",
      "Epoch 44/100, Loss: 0.592394141346654, Accuracy: -1.788364039344088\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989914311733326, -0.9919851614827042, -0.8662520780031199, 0.3499955490926646]\n",
      "Layer: Layer 1, Input: [-0.9989914311733326, -0.9919851614827042, -0.8662520780031199, 0.3499955490926646], Output: [0.7756454666772518, -0.8812005684566795, 0.9832734106333268, 0.26118821010997484]\n",
      "Layer: Layer 2, Input: [0.7756454666772518, -0.8812005684566795, 0.9832734106333268, 0.26118821010997484], Output: [0.21202910569473818]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968066292981249, 0.6366596518109132, -0.7803721399785497, 0.9353782348291676]\n",
      "Layer: Layer 1, Input: [-0.9968066292981249, 0.6366596518109132, -0.7803721399785497, 0.9353782348291676], Output: [0.4767357165518647, -0.06075266228842406, 0.893245599426517, -0.6073935798643213]\n",
      "Layer: Layer 2, Input: [0.4767357165518647, -0.06075266228842406, 0.893245599426517, -0.6073935798643213], Output: [-0.7938788870007002]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978768428212133, -0.708669443670506, -0.894859412543818, 0.316144016404479]\n",
      "Layer: Layer 1, Input: [-0.978768428212133, -0.708669443670506, -0.894859412543818, 0.316144016404479], Output: [0.6802483708942701, -0.8532546279066673, 0.9801534758603975, 0.13010103583728144]\n",
      "Layer: Layer 2, Input: [0.6802483708942701, -0.8532546279066673, 0.9801534758603975, 0.13010103583728144], Output: [0.13703648458965953]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9492266101609002, -0.5388931425932586, -0.42487960966669575, -0.469016441560979]\n",
      "Layer: Layer 1, Input: [-0.9492266101609002, -0.5388931425932586, -0.42487960966669575, -0.469016441560979], Output: [-0.16507477344470808, -0.8922552863724291, 0.9848250397715418, 0.4121360834280999]\n",
      "Layer: Layer 2, Input: [-0.16507477344470808, -0.8922552863724291, 0.9848250397715418, 0.4121360834280999], Output: [0.4195924198370905]\n",
      "Epoch 45/100, Loss: 0.5732772424737198, Accuracy: -1.7115360720571302\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.998989311064393, -0.9918823845158683, -0.8623636949522216, 0.2920526848617933]\n",
      "Layer: Layer 1, Input: [-0.998989311064393, -0.9918823845158683, -0.8623636949522216, 0.2920526848617933], Output: [0.75089903860298, -0.8869138704471364, 0.9842925517047187, 0.27451252409845917]\n",
      "Layer: Layer 2, Input: [0.75089903860298, -0.8869138704471364, 0.9842925517047187, 0.27451252409845917], Output: [0.22924482025373094]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968061530933496, 0.648462495273556, -0.7764614063140546, 0.9347766537324278]\n",
      "Layer: Layer 1, Input: [-0.9968061530933496, 0.648462495273556, -0.7764614063140546, 0.9347766537324278], Output: [0.4709069612901013, -0.03390312207387611, 0.892338594681688, -0.6171540170718488]\n",
      "Layer: Layer 2, Input: [0.4709069612901013, -0.03390312207387611, 0.892338594681688, -0.6171540170718488], Output: [-0.8271283633125317]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9787973914853829, -0.7015441715924379, -0.89422589601938, 0.31903079106593196]\n",
      "Layer: Layer 1, Input: [-0.9787973914853829, -0.7015441715924379, -0.89422589601938, 0.31903079106593196], Output: [0.6789940633606185, -0.8482492827384115, 0.9800089853473177, 0.12284075235051321]\n",
      "Layer: Layer 2, Input: [0.6789940633606185, -0.8482492827384115, 0.9800089853473177, 0.12284075235051321], Output: [0.13163589685055893]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.94913953178077, -0.5382223704903895, -0.4177037496520622, -0.4963882617547481]\n",
      "Layer: Layer 1, Input: [-0.94913953178077, -0.5382223704903895, -0.4177037496520622, -0.4963882617547481], Output: [-0.19519805188562936, -0.8939255469080537, 0.985187982676455, 0.4219662465547581]\n",
      "Layer: Layer 2, Input: [-0.19519805188562936, -0.8939255469080537, 0.985187982676455, 0.4219662465547581], Output: [0.4428426325230181]\n",
      "Epoch 46/100, Loss: 0.5537430712628393, Accuracy: -1.6324200807612779\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989874048270402, -0.9917685752606118, -0.8582033173586288, 0.23036641710539557]\n",
      "Layer: Layer 1, Input: [-0.9989874048270402, -0.9917685752606118, -0.8582033173586288, 0.23036641710539557], Output: [0.7218138354953786, -0.8929145999537462, 0.9853062697783662, 0.2882247577256011]\n",
      "Layer: Layer 2, Input: [0.7218138354953786, -0.8929145999537462, 0.9853062697783662, 0.2882247577256011], Output: [0.2474061664195001]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968058783105418, 0.6586324643681687, -0.7727911033857633, 0.93411810831592]\n",
      "Layer: Layer 1, Input: [-0.9968058783105418, 0.6586324643681687, -0.7727911033857633, 0.93411810831592], Output: [0.465810940375769, -0.008940231790992618, 0.8915508652291952, -0.6268187760076143]\n",
      "Layer: Layer 2, Input: [0.465810940375769, -0.008940231790992618, 0.8915508652291952, -0.6268187760076143], Output: [-0.8596962592896861]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9788277576771262, -0.6941264794494061, -0.8935842180907745, 0.32218428653232706]\n",
      "Layer: Layer 1, Input: [-0.9788277576771262, -0.6941264794494061, -0.8935842180907745, 0.32218428653232706], Output: [0.6776599716560829, -0.8429192199249159, 0.9798518371440177, 0.11411641079682583]\n",
      "Layer: Layer 2, Input: [0.6776599716560829, -0.8429192199249159, 0.9798518371440177, 0.11411641079682583], Output: [0.12419342399634667]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9490579464578939, -0.5375227170447703, -0.4102656839174922, -0.5234048906180072]\n",
      "Layer: Layer 1, Input: [-0.9490579464578939, -0.5375227170447703, -0.4102656839174922, -0.5234048906180072], Output: [-0.22504711780777872, -0.895505515413669, 0.9855317831966555, 0.43153369486139376]\n",
      "Layer: Layer 2, Input: [-0.22504711780777872, -0.895505515413669, 0.9855317831966555, 0.43153369486139376], Output: [0.46622056630998854]\n",
      "Epoch 47/100, Loss: 0.5337034890969399, Accuracy: -1.550870431977172\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989857155547299, -0.9916422937576966, -0.8537530440455602, 0.16549291082897138]\n",
      "Layer: Layer 1, Input: [-0.9989857155547299, -0.9916422937576966, -0.8537530440455602, 0.16549291082897138], Output: [0.6879350200034702, -0.8990525641301375, 0.9862985998894179, 0.302291305490873]\n",
      "Layer: Layer 2, Input: [0.6879350200034702, -0.8990525641301375, 0.9862985998894179, 0.302291305490873], Output: [0.2666076378601592]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968058040107557, 0.6673507931758412, -0.7693799172806881, 0.9334064629079095]\n",
      "Layer: Layer 1, Input: [-0.9968058040107557, 0.6673507931758412, -0.7693799172806881, 0.9334064629079095], Output: [0.4613417518093657, 0.014134997466573391, 0.8908722986682868, -0.6364478518216407]\n",
      "Layer: Layer 2, Input: [0.4613417518093657, 0.014134997466573391, 0.8908722986682868, -0.6364478518216407], Output: [-0.8915469182046629]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9788594448835444, -0.6863987449439074, -0.8929336926306672, 0.3256689788243428]\n",
      "Layer: Layer 1, Input: [-0.9788594448835444, -0.6863987449439074, -0.8929336926306672, 0.3256689788243428], Output: [0.676244193885346, -0.8372257932327345, 0.979679910711581, 0.1038496409546694]\n",
      "Layer: Layer 2, Input: [0.676244193885346, -0.8372257932327345, 0.979679910711581, 0.1038496409546694], Output: [0.11457785151882233]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9489819911441401, -0.5367610846145966, -0.4025633726650001, -0.5498861944836748]\n",
      "Layer: Layer 1, Input: [-0.9489819911441401, -0.5367610846145966, -0.4025633726650001, -0.5498861944836748], Output: [-0.2544761632630969, -0.8969607234742863, 0.9858542016146647, 0.44080342817196255]\n",
      "Layer: Layer 2, Input: [-0.2544761632630969, -0.8969607234742863, 0.9858542016146647, 0.44080342817196255], Output: [0.4896840869187573]\n",
      "Epoch 48/100, Loss: 0.5130831365090545, Accuracy: -1.4667392085352429\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989842439449345, -0.9915022819650069, -0.8489950555539655, 0.09820534381204624]\n",
      "Layer: Layer 1, Input: [-0.9989842439449345, -0.9915022819650069, -0.8489950555539655, 0.09820534381204624], Output: [0.6489550031718857, -0.9051681206718104, 0.9872535747202369, 0.31663628019614426]\n",
      "Layer: Layer 2, Input: [0.6489550031718857, -0.9051681206718104, 0.9872535747202369, 0.31663628019614426], Output: [0.2869284112485393]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968059267032563, 0.6747778037253437, -0.766240540890763, 0.9326472039077509]\n",
      "Layer: Layer 1, Input: [-0.9968059267032563, 0.6747778037253437, -0.766240540890763, 0.9326472039077509], Output: [0.4574008950584086, 0.035337293552371064, 0.8902930642631224, -0.6460821581392052]\n",
      "Layer: Layer 2, Input: [0.4574008950584086, 0.035337293552371064, 0.8902930642631224, -0.6460821581392052], Output: [-0.9226462053477613]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9788923528215077, -0.678347320665006, -0.8922734853898246, 0.329558579740392]\n",
      "Layer: Layer 1, Input: [-0.9788923528215077, -0.678347320665006, -0.8922734853898246, 0.329558579740392], Output: [0.6747502297922504, -0.8311300159501784, 0.9794908185364414, 0.09197538467989506]\n",
      "Layer: Layer 2, Input: [0.6747502297922504, -0.8311300159501784, 0.9794908185364414, 0.09197538467989506], Output: [0.10267080654459868]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.948911744948692, -0.5359097704679431, -0.3945962019332829, -0.5756504582174908]\n",
      "Layer: Layer 1, Input: [-0.948911744948692, -0.5359097704679431, -0.3945962019332829, -0.5756504582174908], Output: [-0.28334637162605386, -0.898260007399844, 0.9861532532750016, 0.4497426556003204]\n",
      "Layer: Layer 2, Input: [-0.28334637162605386, -0.898260007399844, 0.9861532532750016, 0.4497426556003204], Output: [0.5131943561168472]\n",
      "Epoch 49/100, Loss: 0.49182933568846, Accuracy: -1.3799018338314508\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989829882920191, -0.9913474904707547, -0.8439126806458579, 0.029486082025312353]\n",
      "Layer: Layer 1, Input: [-0.9989829882920191, -0.9913474904707547, -0.8439126806458579, 0.029486082025312353], Output: [0.6048133563074675, -0.9111028313055617, 0.9881562794572168, 0.33113439698897223]\n",
      "Layer: Layer 2, Input: [0.6048133563074675, -0.9111028313055617, 0.9881562794572168, 0.33113439698897223], Output: [0.30841297633413195]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968062404039487, 0.68105482274241, -0.7633801608308036, 0.9318477704983091]\n",
      "Layer: Layer 1, Input: [-0.9968062404039487, 0.68105482274241, -0.7633801608308036, 0.9318477704983091], Output: [0.4538999346493873, 0.05469187740913562, 0.8898035870589817, -0.6557430388282874]\n",
      "Layer: Layer 2, Input: [0.4538999346493873, 0.05469187740913562, 0.8898035870589817, -0.6557430388282874], Output: [-0.952954776092956]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9789263619660236, -0.6699635886547949, -0.8916027956087555, 0.3339367801532806]\n",
      "Layer: Layer 1, Input: [-0.9789263619660236, -0.6699635886547949, -0.8916027956087555, 0.3339367801532806], Output: [0.6731909221169535, -0.8245935184812003, 0.9792818846925965, 0.07844571703599654]\n",
      "Layer: Layer 2, Input: [0.6731909221169535, -0.8245935184812003, 0.9792818846925965, 0.07844571703599654], Output: [0.08837149405774747]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9488472302646573, -0.5349468071728226, -0.3863664443519877, -0.6005166455855772]\n",
      "Layer: Layer 1, Input: [-0.9488472302646573, -0.5349468071728226, -0.3863664443519877, -0.6005166455855772], Output: [-0.3115254344158381, -0.8993760235524314, 0.9864272162062683, 0.45831947329969186]\n",
      "Layer: Layer 2, Input: [-0.3115254344158381, -0.8993760235524314, 0.9864272162062683, 0.45831947329969186], Output: [0.5367126317131505]\n",
      "Epoch 50/100, Loss: 0.46992338977178166, Accuracy: -1.2902911099175092\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989819444440212, -0.9911771082519305, -0.8384916529550621, -0.03950365444846722]\n",
      "Layer: Layer 1, Input: [-0.9989819444440212, -0.9911771082519305, -0.8384916529550621, -0.03950365444846722], Output: [0.5557978732477461, -0.9167101913770324, 0.9889938294406441, 0.3456093534675073]\n",
      "Layer: Layer 2, Input: [0.5557978732477461, -0.9167101913770324, 0.9889938294406441, 0.3456093534675073], Output: [0.3310469053482655]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968067366622203, 0.686306395148418, -0.7608010857822106, 0.9310179624238895]\n",
      "Layer: Layer 1, Input: [-0.9968067366622203, 0.686306395148418, -0.7608010857822106, 0.9310179624238895], Output: [0.4507630656881767, 0.07223128332691552, 0.889394499457727, -0.6654322621165487]\n",
      "Layer: Layer 2, Input: [0.4507630656881767, 0.07223128332691552, 0.889394499457727, -0.6654322621165487], Output: [-0.9824219841047028]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9789613325718982, -0.6612450225775819, -0.8909210353946616, 0.33889777738922383]\n",
      "Layer: Layer 1, Input: [-0.9789613325718982, -0.6612450225775819, -0.8909210353946616, 0.33889777738922383], Output: [0.6715932988633214, -0.8175792219255135, 0.9790501258845634, 0.06323478464550705]\n",
      "Layer: Layer 2, Input: [0.6715932988633214, -0.8175792219255135, 0.9790501258845634, 0.06323478464550705], Output: [0.07160379641094938]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9487884128805216, -0.5338561727147473, -0.37788075434489016, -0.6243066717492862]\n",
      "Layer: Layer 1, Input: [-0.9487884128805216, -0.5338561727147473, -0.37788075434489016, -0.6243066717492862], Output: [-0.3388851125328631, -0.9002855019604783, 0.9866746316868418, 0.4665023167064882]\n",
      "Layer: Layer 2, Input: [-0.3388851125328631, -0.9002855019604783, 0.9866746316868418, 0.4665023167064882], Output: [0.5601968336144318]\n",
      "Epoch 51/100, Loss: 0.44739218778301976, Accuracy: -1.1979380733435492\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989811057409161, -0.990990595243486, -0.832721451717763, -0.10748436948109429]\n",
      "Layer: Layer 1, Input: [-0.9989811057409161, -0.990990595243486, -0.832721451717763, -0.10748436948109429], Output: [0.5026146023912058, -0.9218655417607622, 0.9897562038452857, 0.3598412551392812]\n",
      "Layer: Layer 2, Input: [0.5026146023912058, -0.9218655417607622, 0.9897562038452857, 0.3598412551392812], Output: [0.35473369181111314]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968074045807441, 0.6906425784142126, -0.7585014315082305, 0.9301701708100021]\n",
      "Layer: Layer 1, Input: [-0.9968074045807441, 0.6906425784142126, -0.7585014315082305, 0.9301701708100021], Output: [0.4479288833775441, 0.08799399384498824, 0.8890566088490309, -0.6751326624241649]\n",
      "Layer: Layer 2, Input: [0.4479288833775441, 0.08799399384498824, 0.8890566088490309, -0.6751326624241649], Output: [-1.0109806813884208]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9789971039553139, -0.6521961768432804, -0.8902279807924277, 0.3445446310553302]\n",
      "Layer: Layer 1, Input: [-0.9789971039553139, -0.6521961768432804, -0.8902279807924277, 0.3445446310553302], Output: [0.6700025756491812, -0.8100520862331296, 0.9787922788686775, 0.04634511849277728]\n",
      "Layer: Layer 2, Input: [0.6700025756491812, -0.8100520862331296, 0.9787922788686775, 0.04634511849277728], Output: [0.05232636208297109]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9487352013049339, -0.5326278889835939, -0.36915150654009504, -0.6468497577506226]\n",
      "Layer: Layer 1, Input: [-0.9487352013049339, -0.5326278889835939, -0.36915150654009504, -0.6468497577506226], Output: [-0.3652993945079869, -0.9009695500865164, 0.9868943286768649, 0.4742609910816966]\n",
      "Layer: Layer 2, Input: [-0.3652993945079869, -0.9009695500865164, 0.9868943286768649, 0.4742609910816966], Output: [0.5835993591281815]\n",
      "Epoch 52/100, Loss: 0.42431736247517776, Accuracy: -1.1249739925320972\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989804629932211, -0.9907877132831739, -0.8265965207280994, -0.17315410795469355]\n",
      "Layer: Layer 1, Input: [-0.9989804629932211, -0.9907877132831739, -0.8265965207280994, -0.17315410795469355], Output: [0.446385838083256, -0.9264743532668972, 0.9904368844771312, 0.37358598676061894]\n",
      "Layer: Layer 2, Input: [0.446385838083256, -0.9264743532668972, 0.9904368844771312, 0.37358598676061894], Output: [0.3792832553519932]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968082308924363, 0.694161199425505, -0.7564757695203965, 0.9293190394595591]\n",
      "Layer: Layer 1, Input: [-0.9968082308924363, 0.694161199425505, -0.7564757695203965, 0.9293190394595591], Output: [0.4453503269101279, 0.10202436824325595, 0.8887809277325678, -0.6848096853173311]\n",
      "Layer: Layer 2, Input: [0.4453503269101279, 0.10202436824325595, 0.8887809277325678, -0.6848096853173311], Output: [-1.038543501458728]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.979033494655108, -0.6428294653054224, -0.8895238597368268, 0.35098278805197564]\n",
      "Layer: Layer 1, Input: [-0.979033494655108, -0.6428294653054224, -0.8895238597368268, 0.35098278805197564], Output: [0.6684826052889822, -0.8019806241384648, 0.9785049387868945, 0.027815308367224796]\n",
      "Layer: Layer 2, Input: [0.6684826052889822, -0.8019806241384648, 0.9785049387868945, 0.027815308367224796], Output: [0.03054571184744287]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9486874465686407, -0.5312579551906461, -0.360197694543367, -0.6679909645019038]\n",
      "Layer: Layer 1, Input: [-0.9486874465686407, -0.5312579551906461, -0.360197694543367, -0.6679909645019038], Output: [-0.3906463600028366, -0.901414299366992, 0.9870854984587653, 0.4815698428346766]\n",
      "Layer: Layer 2, Input: [-0.3906463600028366, -0.901414299366992, 0.9870854984587653, 0.4815698428346766], Output: [0.6068677711583537]\n",
      "Epoch 53/100, Loss: 0.40083807303806773, Accuracy: -1.082938186795824\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989800045941584, -0.9905685473576987, -0.8201171024408472, -0.23531281189932896]\n",
      "Layer: Layer 1, Input: [-0.9989800045941584, -0.9905685473576987, -0.8201171024408472, -0.23531281189932896], Output: [0.38854697761022444, -0.9304778190573558, 0.9910332167566575, 0.38660585826028426]\n",
      "Layer: Layer 2, Input: [0.38854697761022444, -0.9304778190573558, 0.9910332167566575, 0.38660585826028426], Output: [0.4044228363069225]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968092001886435, 0.69695000598905, -0.7547156650007003, 0.9284802239871811]\n",
      "Layer: Layer 1, Input: [-0.9968092001886435, 0.69695000598905, -0.7547156650007003, 0.9284802239871811], Output: [0.4429919799107213, 0.11437321031872116, 0.8885588027514999, -0.6944141169697595]\n",
      "Layer: Layer 2, Input: [0.4429919799107213, 0.11437321031872116, 0.8885588027514999, -0.6944141169697595], Output: [-1.0650017016019384]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.97907030424001, -0.6331655617564239, -0.8888093464104606, 0.3583070848419829]\n",
      "Layer: Layer 1, Input: [-0.97907030424001, -0.6331655617564239, -0.8888093464104606, 0.3583070848419829], Output: [0.667110302009962, -0.7933398909309743, 0.9781848581556082, 0.007728190619787815]\n",
      "Layer: Layer 2, Input: [0.667110302009962, -0.7933398909309743, 0.9781848581556082, 0.007728190619787815], Output: [0.006330881906334629]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.948644944667155, -0.5297480128782314, -0.35104510206361933, -0.6876041726754155]\n",
      "Layer: Layer 1, Input: [-0.948644944667155, -0.5297480128782314, -0.35104510206361933, -0.6876041726754155], Output: [-0.41481541903206537, -0.9016119471699967, 0.9872478182242561, 0.48841276032627085]\n",
      "Layer: Layer 2, Input: [-0.41481541903206537, -0.9016119471699967, 0.9872478182242561, 0.48841276032627085], Output: [0.6299489662755862]\n",
      "Epoch 54/100, Loss: 0.37714424764068166, Accuracy: -1.0369607809257646\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989797168579339, -0.9903335083216691, -0.8132894972891503, -0.29299045086441194]\n",
      "Layer: Layer 1, Input: [-0.9989797168579339, -0.9903335083216691, -0.8132894972891503, -0.29299045086441194], Output: [0.33065201639729835, -0.9338544723715064, 0.9915463776750526, 0.3987049424280027]\n",
      "Layer: Layer 2, Input: [0.33065201639729835, -0.9338544723715064, 0.9915463776750526, 0.3987049424280027], Output: [0.42983299199016156]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968102953854293, 0.6990886465194749, -0.7532100920563518, 0.9276682738375026]\n",
      "Layer: Layer 1, Input: [-0.9968102953854293, 0.6990886465194749, -0.7532100920563518, 0.9276682738375026], Output: [0.44082485424921564, 0.1250983500762126, 0.8883821406247516, -0.7038861442296886]\n",
      "Layer: Layer 2, Input: [0.44082485424921564, 0.1250983500762126, 0.8883821406247516, -0.7038861442296886], Output: [-1.0902278228104967]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9791073174098536, -0.6232332806597088, -0.8880854595275366, 0.36658361741004847]\n",
      "Layer: Layer 1, Input: [-0.9791073174098536, -0.6232332806597088, -0.8880854595275366, 0.36658361741004847], Output: [0.6659637196777785, -0.7841161071714613, 0.9778293912439397, -0.013782560940824907]\n",
      "Layer: Layer 2, Input: [0.6659637196777785, -0.7841161071714613, 0.9778293912439397, -0.013782560940824907], Output: [-0.02017397113106381]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9486074438686923, -0.5281046523593058, -0.3417256279407087, -0.7056065854273845]\n",
      "Layer: Layer 1, Input: [-0.9486074438686923, -0.5281046523593058, -0.3417256279407087, -0.7056065854273845], Output: [-0.4377184249523225, -0.9015618711036163, 0.9873815827008535, 0.4947884244558092]\n",
      "Layer: Layer 2, Input: [-0.4377184249523225, -0.9015618711036163, 0.9873815827008535, 0.4947884244558092], Output: [0.6527953434422039]\n",
      "Epoch 55/100, Loss: 0.35346039935412504, Accuracy: -0.9874255162470673\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989795846208583, -0.9900833119698651, -0.8061257808559413, -0.3455422387813209]\n",
      "Layer: Layer 1, Input: [-0.9989795846208583, -0.9900833119698651, -0.8061257808559413, -0.3455422387813209], Output: [0.2741450740804132, -0.9366170410935712, 0.99198088097269, 0.4097579787311245]\n",
      "Layer: Layer 2, Input: [0.2741450740804132, -0.9366170410935712, 0.99198088097269, 0.4097579787311245], Output: [0.4551980303434341]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968114984527797, 0.7006503844274153, -0.7519458011475809, 0.9268941802729254]\n",
      "Layer: Layer 1, Input: [-0.9968114984527797, 0.7006503844274153, -0.7519458011475809, 0.9268941802729254], Output: [0.43882008665646577, 0.13426479021545853, 0.8882436754646665, -0.7131605502155602]\n",
      "Layer: Layer 2, Input: [0.43882008665646577, 0.13426479021545853, 0.8882436754646665, -0.7131605502155602], Output: [-1.1140828157870077]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9791443105563448, -0.6130688880147113, -0.8873534070541199, 0.37583163266358627]\n",
      "Layer: Layer 1, Input: [-0.9791443105563448, -0.6130688880147113, -0.8873534070541199, 0.37583163266358627], Output: [0.6651068208983769, -0.7743120831558069, 0.977436979429304, -0.03653043406789823]\n",
      "Layer: Layer 2, Input: [0.6651068208983769, -0.7743120831558069, 0.977436979429304, -0.03653043406789823], Output: [-0.04874391565092215]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9485746578198564, -0.5263383619920572, -0.33227596287443273, -0.7219694249907557]\n",
      "Layer: Layer 1, Input: [-0.9485746578198564, -0.5263383619920572, -0.33227596287443273, -0.7219694249907557], Output: [-0.4593001982620647, -0.9012712387152081, 0.9874877794395218, 0.5007134047729662]\n",
      "Layer: Layer 2, Input: [-0.4593001982620647, -0.9012712387152081, 0.9874877794395218, 0.5007134047729662], Output: [0.6753696085512503]\n",
      "Epoch 56/100, Loss: 0.3300242760157186, Accuracy: -0.9347712612414014\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989795920450611, -0.9898189363878959, -0.7986432584938009, -0.392681554226639]\n",
      "Layer: Layer 1, Input: [-0.9989795920450611, -0.9898189363878959, -0.7986432584938009, -0.392681554226639], Output: [0.2201758703892194, -0.9388051007210887, 0.9923436884365827, 0.41972287298689875]\n",
      "Layer: Layer 2, Input: [0.2201758703892194, -0.9388051007210887, 0.9923436884365827, 0.41972287298689875], Output: [0.48025122516681984]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968127913311896, 0.7017034406196768, -0.7509077631681912, 0.9261634432260625]\n",
      "Layer: Layer 1, Input: [-0.9968127913311896, 0.7017034406196768, -0.7509077631681912, 0.9261634432260625], Output: [0.4369437376647089, 0.14194421397269252, 0.8881371896665554, -0.7221724154272938]\n",
      "Layer: Layer 2, Input: [0.4369437376647089, 0.14194421397269252, 0.8881371896665554, -0.7221724154272938], Output: [-1.1364268625865859]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.97918106021945, -0.6027149160660791, -0.8866144523161407, 0.38601217212891786]\n",
      "Layer: Layer 1, Input: [-0.97918106021945, -0.6027149160660791, -0.8866144523161407, 0.38601217212891786], Output: [0.6645762956175525, -0.7639518248850491, 0.9770075228954331, -0.06028111548392074]\n",
      "Layer: Layer 2, Input: [0.6645762956175525, -0.7639518248850491, 0.9770075228954331, -0.06028111548392074], Output: [-0.07907842552220237]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9485462830619201, -0.5244622515093202, -0.32273608178949487, -0.7367201369603803]\n",
      "Layer: Layer 1, Input: [-0.9485462830619201, -0.5244622515093202, -0.32273608178949487, -0.7367201369603803], Output: [-0.479543642064384, -0.9007546440202823, 0.9875680596001948, 0.5062211964756191]\n",
      "Layer: Layer 2, Input: [-0.479543642064384, -0.9007546440202823, 0.9875680596001948, 0.5062211964756191], Output: [0.6976449116888173]\n",
      "Epoch 57/100, Loss: 0.307066555885535, Accuracy: -0.8794523002087464\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989797234779414, -0.9895415659688549, -0.7908640135470207, -0.4344462227697437]\n",
      "Layer: Layer 1, Input: [-0.9989797234779414, -0.9895415659688549, -0.7908640135470207, -0.4344462227697437], Output: [0.16951182968950732, -0.9404755017797832, 0.9926431405541826, 0.4286339009964991]\n",
      "Layer: Layer 2, Input: [0.16951182968950732, -0.9404755017797832, 0.9926431405541826, 0.4286339009964991], Output: [0.5047984824691568]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968141568742874, 0.7023118952902168, -0.7500797743193466, 0.9254753286400428]\n",
      "Layer: Layer 1, Input: [-0.9968141568742874, 0.7023118952902168, -0.7500797743193466, 0.9254753286400428], Output: [0.435154426436287, 0.1482138727333429, 0.8880576166872228, -0.7308624166769303]\n",
      "Layer: Layer 2, Input: [0.435154426436287, 0.1482138727333429, 0.8880576166872228, -0.7308624166769303], Output: [-1.1571316421758648]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9792173522398062, -0.5922186499408737, -0.8858698663765122, 0.39702787984648]\n",
      "Layer: Layer 1, Input: [-0.9792173522398062, -0.5922186499408737, -0.8858698663765122, 0.39702787984648], Output: [0.664375110898822, -0.7530827513751182, 0.9765425184397435, -0.08476485070883678]\n",
      "Layer: Layer 2, Input: [0.664375110898822, -0.7530827513751182, 0.9765425184397435, -0.08476485070883678], Output: [-0.11081775393039375]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.94852201749016, -0.5224907675936102, -0.3131480125464723, -0.7499350739463948]\n",
      "Layer: Layer 1, Input: [-0.94852201749016, -0.5224907675936102, -0.3131480125464723, -0.7499350739463948], Output: [-0.4984673659103497, -0.9000327327150368, 0.9876246041495603, 0.5113570692232265]\n",
      "Layer: Layer 2, Input: [-0.4984673659103497, -0.9000327327150368, 0.9876246041495603, 0.5113570692232265], Output: [0.7195994555414137]\n",
      "Epoch 58/100, Loss: 0.28479610699894886, Accuracy: -0.8219159502349007\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989799641970659, -0.9892525325819089, -0.7828147417189006, -0.47111939776087103]\n",
      "Layer: Layer 1, Input: [-0.9989799641970659, -0.9892525325819089, -0.7828147417189006, -0.47111939776087103], Output: [0.12254919310619489, -0.9416930233307542, 0.9928879619506368, 0.4365808412162459]\n",
      "Layer: Layer 2, Input: [0.12254919310619489, -0.9416930233307542, 0.9928879619506368, 0.4365808412162459], Output: [0.5287168940744753]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968155796372739, 0.7025361653368261, -0.7494451945873868, 0.9248234347983415]\n",
      "Layer: Layer 1, Input: [-0.9968155796372739, 0.7025361653368261, -0.7494451945873868, 0.9248234347983415], Output: [0.43340415646579034, 0.15315502930284636, 0.888001006463917, -0.7391808931111843]\n",
      "Layer: Layer 2, Input: [0.43340415646579034, 0.15315502930284636, 0.888001006463917, -0.7391808931111843], Output: [-1.1760912472761194]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.979252990202495, -0.5816304749233292, -0.885120981545258, 0.4087336473899794]\n",
      "Layer: Layer 1, Input: [-0.979252990202495, -0.5816304749233292, -0.885120981545258, 0.4087336473899794], Output: [0.664474212130404, -0.741774827496837, 0.9760449400521575, -0.10969381734632015]\n",
      "Layer: Layer 2, Input: [0.664474212130404, -0.741774827496837, 0.9760449400521575, -0.10969381734632015], Output: [-0.1435668662885995]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.948501575758952, -0.5204386067382567, -0.3035550617167739, -0.7617256608023063]\n",
      "Layer: Layer 1, Input: [-0.948501575758952, -0.5204386067382567, -0.3035550617167739, -0.7617256608023063], Output: [-0.5161174343659519, -0.8991302099918906, 0.9876599299105727, 0.5161704836034922]\n",
      "Layer: Layer 2, Input: [-0.5161174343659519, -0.8991302099918906, 0.9876599299105727, 0.5161704836034922], Output: [0.7412078373616724]\n",
      "Epoch 59/100, Loss: 0.26339174731495524, Accuracy: -0.7625996495513723\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989803009194487, -0.9889532616710528, -0.7745267951644899, -0.5031363837234759]\n",
      "Layer: Layer 1, Input: [-0.9989803009194487, -0.9889532616710528, -0.7745267951644899, -0.5031363837234759], Output: [0.07938764425030065, -0.9425230378115085, 0.9930865185486061, 0.44368317843289484]\n",
      "Layer: Layer 2, Input: [0.07938764425030065, -0.9425230378115085, 0.9930865185486061, 0.44368317843289484], Output: [0.5519364037094925]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968170463867355, 0.7024331606227241, -0.7489876922956797, 0.9241971692399479]\n",
      "Layer: Layer 1, Input: [-0.9968170463867355, 0.7024331606227241, -0.7489876922956797, 0.9241971692399479], Output: [0.43164138050099243, 0.15685122695188092, 0.8879643840820488, -0.7470902390198148]\n",
      "Layer: Layer 2, Input: [0.43164138050099243, 0.15685122695188092, 0.8879643840820488, -0.7470902390198148], Output: [-1.1932296920360643]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9792878020580581, -0.571002228464774, -0.8843693068021123, 0.42095389445309145]\n",
      "Layer: Layer 1, Input: [-0.9792878020580581, -0.571002228464774, -0.8843693068021123, 0.42095389445309145], Output: [0.6648203748491474, -0.7301169676246971, 0.9755189297200522, -0.13478076982260115]\n",
      "Layer: Layer 2, Input: [0.6648203748491474, -0.7301169676246971, 0.9755189297200522, -0.13478076982260115], Output: [-0.17692131925380267]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484846988959468, -0.5183199340301567, -0.2940013476539373, -0.7722227932719481]\n",
      "Layer: Layer 1, Input: [-0.9484846988959468, -0.5183199340301567, -0.2940013476539373, -0.7722227932719481], Output: [-0.5325569092047536, -0.8980737736266708, 0.9876766926136747, 0.5207076005394006]\n",
      "Layer: Layer 2, Input: [-0.5325569092047536, -0.8980737736266708, 0.9876766926136747, 0.5207076005394006], Output: [0.7624329301228545]\n",
      "Epoch 60/100, Loss: 0.2429988318985121, Accuracy: -0.7019390389499147\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989807220388756, -0.9886452263320806, -0.7660361816001472, -0.5310022680650517]\n",
      "Layer: Layer 1, Input: [-0.9989807220388756, -0.9886452263320806, -0.7660361816001472, -0.5310022680650517], Output: [0.039925116479031214, -0.9430268118258749, 0.9932463768051469, 0.4500672297243811]\n",
      "Layer: Layer 2, Input: [0.039925116479031214, -0.9430268118258749, 0.9932463768051469, 0.4500672297243811], Output: [0.5744166397413936]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968185462983384, 0.7020562632953586, -0.7486918442827716, 0.9235835473693327]\n",
      "Layer: Layer 1, Input: [-0.9968185462983384, 0.7020562632953586, -0.7486918442827716, 0.9235835473693327], Output: [0.42981484596363245, 0.15938667688405048, 0.8879455530334817, -0.7545656500050751]\n",
      "Layer: Layer 2, Input: [0.42981484596363245, 0.15938667688405048, 0.8879455530334817, -0.7545656500050751], Output: [-1.208504355421188]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9793216443674713, -0.5603856376389724, -0.8836166418698019, 0.4335012367337217]\n",
      "Layer: Layer 1, Input: [-0.9793216443674713, -0.5603856376389724, -0.8836166418698019, 0.4335012367337217], Output: [0.6653466370113698, -0.7182116852673298, 0.9749694025042761, -0.15975551216944958]\n",
      "Layer: Layer 2, Input: [0.6653466370113698, -0.7182116852673298, 0.9749694025042761, -0.15975551216944958], Output: [-0.21049020763866752]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484711575062661, -0.5161479055315547, -0.284531337831494, -0.7815633284654575]\n",
      "Layer: Layer 1, Input: [-0.9484711575062661, -0.5161479055315547, -0.284531337831494, -0.7815633284654575], Output: [-0.5478565161300755, -0.8968903733746033, 0.9876775269751972, 0.5250058511513559]\n",
      "Layer: Layer 2, Input: [-0.5478565161300755, -0.8968903733746033, 0.9876775269751972, 0.5250058511513559], Output: [0.7832213664455404]\n",
      "Epoch 61/100, Loss: 0.22372848773969625, Accuracy: -0.6403761415955866\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989812176280111, -0.9883299087756191, -0.7573832587670721, -0.5552319460257765]\n",
      "Layer: Layer 1, Input: [-0.9989812176280111, -0.9883299087756191, -0.7573832587670721, -0.5552319460257765], Output: [0.003942726778956146, -0.9432591475168086, 0.993374119382638, 0.455850186847751]\n",
      "Layer: Layer 2, Input: [0.003942726778956146, -0.9432591475168086, 0.993374119382638, 0.455850186847751], Output: [0.5961278511795809]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968200708862066, 0.7014552580039181, -0.7485434943670729, 0.9229688384554199]\n",
      "Layer: Layer 1, Input: [-0.9968200708862066, 0.7014552580039181, -0.7485434943670729, 0.9229688384554199], Output: [0.4278770283170133, 0.16084499523066742, 0.8879428882898484, -0.7615945711429694]\n",
      "Layer: Layer 2, Input: [0.4278770283170133, 0.16084499523066742, 0.8879428882898484, -0.7615945711429694], Output: [-1.2219059083533315]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9793544041545875, -0.54983088097267, -0.8828651379392563, 0.4461925939106541]\n",
      "Layer: Layer 1, Input: [-0.9793544041545875, -0.54983088097267, -0.8828651379392563, 0.4461925939106541], Output: [0.6659821723484545, -0.7061690382685056, 0.9744016551870773, -0.18437713917552037]\n",
      "Layer: Layer 2, Input: [0.6659821723484545, -0.7061690382685056, 0.9744016551870773, -0.18437713917552037], Output: [-0.24391353227374862]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484607497353829, -0.5139344235270322, -0.2751891518716037, -0.7898804591498505]\n",
      "Layer: Layer 1, Input: [-0.9484607497353829, -0.5139344235270322, -0.2751891518716037, -0.7898804591498505], Output: [-0.5620881318839005, -0.8956059523216856, 0.9876649375450343, 0.529091347723142]\n",
      "Layer: Layer 2, Input: [-0.5620881318839005, -0.8956059523216856, 0.9876649375450343, 0.529091347723142], Output: [0.8035037118337955]\n",
      "Epoch 62/100, Loss: 0.20565812067419892, Accuracy: -0.5783608130662063\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989817792793397, -0.9880087672729733, -0.7486119827663206, -0.5763131727816667]\n",
      "Layer: Layer 1, Input: [-0.9989817792793397, -0.9880087672729733, -0.7486119827663206, -0.5763131727816667], Output: [-0.02883262704249938, -0.9432676695655084, 0.993475333628628, 0.46113154185505556]\n",
      "Layer: Layer 2, Input: [-0.02883262704249938, -0.9432676695655084, 0.993475333628628, 0.46113154185505556], Output: [0.61703958414786]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996821613746924, 0.700676290796728, -0.7485298543495255, 0.9223398161138269]\n",
      "Layer: Layer 1, Input: [-0.996821613746924, 0.700676290796728, -0.7485298543495255, 0.9223398161138269], Output: [0.4257865427140141, 0.16130839658756846, 0.8879551477471673, -0.7681753054410738]\n",
      "Layer: Layer 2, Input: [0.4257865427140141, 0.16130839658756846, 0.8879551477471673, -0.7681753054410738], Output: [-1.2334558260602542]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9793859986979916, -0.5393853027284147, -0.8821172822816702, 0.45886085705790436]\n",
      "Layer: Layer 1, Input: [-0.9793859986979916, -0.5393853027284147, -0.8821172822816702, 0.45886085705790436], Output: [0.6666598369753078, -0.6941006856966435, 0.9738210317008168, -0.20844147511608413]\n",
      "Layer: Layer 2, Input: [0.6666598369753078, -0.6941006856966435, 0.9738210317008168, -0.20844147511608413], Output: [-0.2768734876563274]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484532960128254, -0.5116900397357838, -0.2660175635496513, -0.7972980063700184]\n",
      "Layer: Layer 1, Input: [-0.9484532960128254, -0.5116900397357838, -0.2660175635496513, -0.7972980063700184], Output: [-0.5753212244292829, -0.8942446405198654, 0.9876412352085783, 0.5329788804776783]\n",
      "Layer: Layer 2, Input: [-0.5753212244292829, -0.8942446405198654, 0.9876412352085783, 0.5329788804776783], Output: [0.8231986137344371]\n",
      "Epoch 63/100, Loss: 0.18883274646771703, Accuracy: -0.5163441405216296\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989823998627375, -0.9876832071452811, -0.7397687168465336, -0.5946877892584671]\n",
      "Layer: Layer 1, Input: [-0.9989823998627375, -0.9876832071452811, -0.7397687168465336, -0.5946877892584671], Output: [-0.058688314628357656, -0.9430930664186851, 0.9935546941889273, 0.46599039863314357]\n",
      "Layer: Layer 2, Input: [-0.058688314628357656, -0.9430930664186851, 0.9935546941889273, 0.46599039863314357], Output: [0.6371167149759525]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968231702050394, 0.6997618825943024, -0.7486393971022505, 0.9216845660133547]\n",
      "Layer: Layer 1, Input: [-0.9968231702050394, 0.6997618825943024, -0.7486393971022505, 0.9216845660133547], Output: [0.42350943193632945, 0.16085731742264073, 0.8879813157169789, -0.7743151966329239]\n",
      "Layer: Layer 2, Input: [0.42350943193632945, 0.16085731742264073, 0.8879813157169789, -0.7743151966329239], Output: [-1.2432025684629444]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9794163737445856, -0.5290923138190705, -0.8813758119823107, 0.47136190299437164]\n",
      "Layer: Layer 1, Input: [-0.9794163737445856, -0.5290923138190705, -0.8813758119823107, 0.47136190299437164], Output: [0.6673209207844457, -0.6821145840321329, 0.9732326658074274, -0.2317841629694036]\n",
      "Layer: Layer 2, Input: [0.6673209207844457, -0.6821145840321329, 0.9732326658074274, -0.2317841629694036], Output: [-0.30910044364145806]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484486325891417, -0.5094239411184803, -0.25705679115027513, -0.8039277715412277]\n",
      "Layer: Layer 1, Input: [-0.9484486325891417, -0.5094239411184803, -0.25705679115027513, -0.8039277715412277], Output: [-0.5876215227101262, -0.8928282930104359, 0.9876085068072744, 0.5366737044266718]\n",
      "Layer: Layer 2, Input: [-0.5876215227101262, -0.8928282930104359, 0.9876085068072744, 0.5366737044266718], Output: [0.842219292594625]\n",
      "Epoch 64/100, Loss: 0.17326717911564699, Accuracy: -0.45476611725090876\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989830732619617, -0.9873545554482958, -0.7309007209337189, -0.6107451042321115]\n",
      "Layer: Layer 1, Input: [-0.9989830732619617, -0.9873545554482958, -0.7309007209337189, -0.6107451042321115], Output: [-0.0859036363094622, -0.9427697752110072, 0.9936160835963009, 0.4704866144946586]\n",
      "Layer: Layer 2, Input: [-0.0859036363094622, -0.9427697752110072, 0.9936160835963009, 0.4704866144946586], Output: [0.6563206008517427]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968247369307902, 0.6987509886473917, -0.7488616222272922, 0.9209929125698542]\n",
      "Layer: Layer 1, Input: [-0.9968247369307902, 0.6987509886473917, -0.7488616222272922, 0.9209929125698542], Output: [0.4210195163418187, 0.15957034765264952, 0.8880204827569641, -0.7800286922088632]\n",
      "Layer: Layer 2, Input: [0.4210195163418187, 0.15957034765264952, 0.8880204827569641, -0.7800286922088632], Output: [-1.2512172183372514]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9794455006439138, -0.5189905188049795, -0.8806435791843963, 0.48357766596567175]\n",
      "Layer: Layer 1, Input: [-0.9794455006439138, -0.5189905188049795, -0.8806435791843963, 0.48357766596567175], Output: [0.6679174334134254, -0.6703106227257972, 0.9726413010026573, -0.2542803372879786]\n",
      "Layer: Layer 2, Input: [0.6679174334134254, -0.6703106227257972, 0.9726413010026573, -0.2542803372879786], Output: [-0.3403748304489348]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484466053855093, -0.507143980863629, -0.24834324686017262, -0.8098689048990805]\n",
      "Layer: Layer 1, Input: [-0.9484466053855093, -0.507143980863629, -0.24834324686017262, -0.8098689048990805], Output: [-0.5990509955778632, -0.891376262331672, 0.9875686056907395, 0.5401742277577577]\n",
      "Layer: Layer 2, Input: [-0.5990509955778632, -0.891376262331672, 0.9875686056907395, 0.5401742277577577], Output: [0.8604806555649437]\n",
      "Epoch 65/100, Loss: 0.1589491579912182, Accuracy: -0.3940411314716301\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989837941309381, -0.987024039875832, -0.7220545000517292, -0.6248223859393356]\n",
      "Layer: Layer 1, Input: [-0.9989837941309381, -0.987024039875832, -0.7220545000517292, -0.6248223859393356], Output: [-0.11073920064022137, -0.9423267992064244, 0.9936627177390078, 0.47466394556205943]\n",
      "Layer: Layer 2, Input: [-0.11073920064022137, -0.9423267992064244, 0.9936627177390078, 0.47466394556205943], Output: [0.6746128556247959]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968263115784057, 0.6976790817322289, -0.74918677526936, 0.9202565633868299]\n",
      "Layer: Layer 1, Input: [-0.9968263115784057, 0.6976790817322289, -0.74918677526936, 0.9202565633868299], Output: [0.4182980869393594, 0.15752431174123938, 0.8880717611253373, -0.7853354828971193]\n",
      "Layer: Layer 2, Input: [0.4182980869393594, 0.15752431174123938, 0.8880717611253373, -0.7853354828971193], Output: [-1.2575890469337792]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9794733728511129, -0.5091131030775219, -0.8799233958536393, 0.49541629578355734]\n",
      "Layer: Layer 1, Input: [-0.9794733728511129, -0.5091131030775219, -0.8799233958536393, 0.49541629578355734], Output: [0.6684125709777379, -0.6587773422331193, 0.9720511779692068, -0.27584191077959014]\n",
      "Layer: Layer 2, Input: [0.6684125709777379, -0.6587773422331193, 0.9720511779692068, -0.27584191077959014], Output: [-0.3705260850310184]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.948447065055092, -0.5048567385870633, -0.23990842271816518, -0.8152084209006776]\n",
      "Layer: Layer 1, Input: [-0.948447065055092, -0.5048567385870633, -0.23990842271816518, -0.8152084209006776], Output: [-0.6096683856193061, -0.8899053244876373, 0.9875231543863375, 0.5434748751312947]\n",
      "Layer: Layer 2, Input: [-0.6096683856193061, -0.8899053244876373, 0.9875231543863375, 0.5434748751312947], Output: [0.8779057059851127]\n",
      "Epoch 66/100, Loss: 0.14584333427056825, Accuracy: -0.33454440029285215\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989845576913409, -0.9866927727268597, -0.7132741970321195, -0.6372089460607245]\n",
      "Layer: Layer 1, Input: [-0.9989845576913409, -0.9866927727268597, -0.7132741970321195, -0.6372089460607245], Output: [-0.13343320179323245, -0.9417884982680353, 0.9936972600907048, 0.4785538747293917]\n",
      "Layer: Layer 2, Input: [-0.13343320179323245, -0.9417884982680353, 0.9936972600907048, 0.4785538747293917], Output: [0.6919597817687214]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968278924727931, 0.6965782383215245, -0.749605583971278, 0.9194690668142543]\n",
      "Layer: Layer 1, Input: [-0.9968278924727931, 0.6965782383215245, -0.749605583971278, 0.9194690668142543], Output: [0.4153332063691684, 0.1547943543290802, 0.8881342325303272, -0.7902588293055295]\n",
      "Layer: Layer 2, Input: [0.4153332063691684, 0.1547943543290802, 0.8881342325303272, -0.7902588293055295], Output: [-1.2624212445907217]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.979500002168836, -0.4994874978667873, -0.8792178835759453, 0.5068104029807708]\n",
      "Layer: Layer 1, Input: [-0.979500002168836, -0.4994874978667873, -0.8792178835759453, 0.5068104029807708], Output: [0.6687800233953646, -0.6475897660549146, 0.9714659768407679, -0.29641340075634576]\n",
      "Layer: Layer 2, Input: [0.6687800233953646, -0.6475897660549146, 0.9714659768407679, -0.29641340075634576], Output: [-0.3994295944098605]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484498636164543, -0.5025676048492645, -0.2317780495451577, -0.8200222598273585]\n",
      "Layer: Layer 1, Input: [-0.9484498636164543, -0.5025676048492645, -0.2317780495451577, -0.8200222598273585], Output: [-0.6195298174734881, -0.8884297078711775, 0.9874735540345535, 0.5465686455825389]\n",
      "Layer: Layer 2, Input: [-0.6195298174734881, -0.8884297078711775, 0.9874735540345535, 0.5465686455825389], Output: [0.8944304596239306]\n",
      "Epoch 67/100, Loss: 0.1338958563966091, Accuracy: -0.27660140878820894\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989853595785588, -0.9863617406008445, -0.7046001867277282, -0.6481516478154127]\n",
      "Layer: Layer 1, Input: [-0.9989853595785588, -0.9863617406008445, -0.7046001867277282, -0.6481516478154127], Output: [-0.15420129833374965, -0.9411752877532866, 0.9937219189572568, 0.48217930265980974]\n",
      "Layer: Layer 2, Input: [-0.15420129833374965, -0.9411752877532866, 0.9937219189572568, 0.48217930265980974], Output: [0.7083362119218348]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968294783566306, 0.6954772158008021, -0.7501090512723653, 0.9186256589066883]\n",
      "Layer: Layer 1, Input: [-0.9968294783566306, 0.6954772158008021, -0.7501090512723653, 0.9186256589066883], Output: [0.4121188221271838, 0.15145392933564839, 0.8882069233751555, -0.7948241280244356]\n",
      "Layer: Layer 2, Input: [0.4121188221271838, 0.15145392933564839, 0.8882069233751555, -0.7948241280244356], Output: [-1.265826924909984]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9795254150148609, -0.49013531810576977, -0.878529347212505, 0.5177142148827479]\n",
      "Layer: Layer 1, Input: [-0.9795254150148609, -0.49013531810576977, -0.878529347212505, 0.5177142148827479], Output: [0.6690026592104057, -0.6368082923229444, 0.9708888016287669, -0.31596704103234163]\n",
      "Layer: Layer 2, Input: [0.6690026592104057, -0.6368082923229444, 0.9708888016287669, -0.31596704103234163], Output: [-0.4270023470181351]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484548526390518, -0.5002808880214084, -0.2239716046156363, -0.8243765314743255]\n",
      "Layer: Layer 1, Input: [-0.9484548526390518, -0.5002808880214084, -0.2239716046156363, -0.8243765314743255], Output: [-0.6286892441027236, -0.8869611956626036, 0.9874209977005503, 0.5494491160281559]\n",
      "Layer: Layer 2, Input: [-0.6286892441027236, -0.8869611956626036, 0.9874209977005503, 0.5494491160281559], Output: [0.9100070641100788]\n",
      "Epoch 68/100, Loss: 0.12303918952900407, Accuracy: -0.2204813018599352\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.998986195733959, -0.9860318000112849, -0.6960679813814926, -0.6578606336671285]\n",
      "Layer: Layer 1, Input: [-0.998986195733959, -0.9860318000112849, -0.6960679813814926, -0.6578606336671285], Output: [-0.17323808911453673, -0.9405042321333956, 0.9937385274381091, 0.48555767525910287]\n",
      "Layer: Layer 2, Input: [-0.17323808911453673, -0.9405042321333956, 0.9937385274381091, 0.48555767525910287], Output: [0.7237281499951934]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968310681991631, 0.6944015188191096, -0.7506883223401798, 0.9177230547193528]\n",
      "Layer: Layer 1, Input: [-0.9968310681991631, 0.6944015188191096, -0.7506883223401798, 0.9177230547193528], Output: [0.40865383083010925, 0.14757464480064894, 0.8882888018719676, -0.799057732380699]\n",
      "Layer: Layer 2, Input: [0.40865383083010925, 0.14757464480064894, 0.8882888018719676, -0.799057732380699], Output: [-1.2679254564294922]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9795496489215335, -0.4810725457235384, -0.8778596833593755, 0.5281002554449403]\n",
      "Layer: Layer 1, Input: [-0.9795496489215335, -0.4810725457235384, -0.8778596833593755, 0.5281002554449403], Output: [0.6690709690234219, -0.6264785235471213, 0.9703221954764194, -0.3344977332700492]\n",
      "Layer: Layer 2, Input: [0.6690709690234219, -0.6264785235471213, 0.9703221954764194, -0.3344977332700492], Output: [-0.45319783057850294]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484618827389971, -0.4979999401719832, -0.21650218405073263, -0.8283287452537925]\n",
      "Layer: Layer 1, Input: [-0.9484618827389971, -0.4979999401719832, -0.21650218405073263, -0.8283287452537925], Output: [-0.6371986623653959, -0.8855092832314939, 0.9873664860747157, 0.5521118169705924]\n",
      "Layer: Layer 2, Input: [-0.6371986623653959, -0.8855092832314939, 0.9873664860747157, 0.5521118169705924], Output: [0.9246051718446364]\n",
      "Epoch 69/100, Loss: 0.11319679447616561, Accuracy: -0.1663943040111593\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989870623364125, -0.9857036785590203, -0.6877075033683688, -0.6665146784526794]\n",
      "Layer: Layer 1, Input: [-0.9989870623364125, -0.9857036785590203, -0.6877075033683688, -0.6665146784526794], Output: [-0.19071909309398566, -0.9397895425111897, 0.9937486081676279, 0.48870338988320766]\n",
      "Layer: Layer 2, Input: [-0.19071909309398566, -0.9397895425111897, 0.9937486081676279, 0.48870338988320766], Output: [0.7381340593629832]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968326610614457, 0.6933734605422681, -0.7513346256404791, 0.9167592207203424]\n",
      "Layer: Layer 1, Input: [-0.9968326610614457, 0.6933734605422681, -0.7513346256404791, 0.9167592207203424], Output: [0.40494117812714436, 0.14322596330775036, 0.8883787910938509, -0.8029860204531509]\n",
      "Layer: Layer 2, Input: [0.40494117812714436, 0.14322596330775036, 0.8883787910938509, -0.8029860204531509], Output: [-1.26883915979003]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.979572749400497, -0.4723099135514665, -0.87721032735394, 0.5379559685890838]\n",
      "Layer: Layer 1, Input: [-0.979572749400497, -0.4723099135514665, -0.87721032735394, 0.5379559685890838], Output: [0.6689815093946304, -0.6166318664694972, 0.9697681770785587, -0.3520182184287837]\n",
      "Layer: Layer 2, Input: [0.6689815093946304, -0.6166318664694972, 0.9697681770785587, -0.3520182184287837], Output: [-0.4780005921647965]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484708040473357, -0.4957272961701922, -0.20937670840212752, -0.8319289364886805]\n",
      "Layer: Layer 1, Input: [-0.9484708040473357, -0.4957272961701922, -0.20937670840212752, -0.8319289364886805], Output: [-0.6451081231696383, -0.8840813763621287, 0.9873108447243241, 0.5545550204930463]\n",
      "Layer: Layer 2, Input: [-0.6451081231696383, -0.8840813763621287, 0.9873108447243241, 0.5545550204930463], Output: [0.9382118304034873]\n",
      "Epoch 70/100, Loss: 0.10428735609617736, Accuracy: -0.11449267785876316\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989879557641476, -0.9853779808458172, -0.6795427321721521, -0.6742659275245648]\n",
      "Layer: Layer 1, Input: [-0.9989879557641476, -0.9853779808458172, -0.6795427321721521, -0.6742659275245648], Output: [-0.2068027090728489, -0.9390429945296551, 0.9937534255861256, 0.49162948671237916]\n",
      "Layer: Layer 2, Input: [-0.2068027090728489, -0.9390429945296551, 0.9937534255861256, 0.49162948671237916], Output: [0.7515649254814143]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968342560093936, 0.6924122286275252, -0.7520392768956797, 0.9157331513740999]\n",
      "Layer: Layer 1, Input: [-0.9968342560093936, 0.6924122286275252, -0.7520392768956797, 0.9157331513740999], Output: [0.40098703976702105, 0.1384747916122615, 0.8884757922189755, -0.8066346897934454]\n",
      "Layer: Layer 2, Input: [0.40098703976702105, 0.1384747916122615, 0.8884757922189755, -0.8066346897934454], Output: [-1.268690404846654]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9795947672443617, -0.46385343523871564, -0.8765822369777975, 0.547280548030005]\n",
      "Layer: Layer 1, Input: [-0.9795947672443617, -0.46385343523871564, -0.8765822369777975, 0.547280548030005], Output: [0.6687354827483113, -0.6072867097044296, 0.9692282903164275, -0.3685547047057861]\n",
      "Layer: Layer 2, Input: [0.6687354827483113, -0.6072867097044296, 0.9692282903164275, -0.3685547047057861], Output: [-0.5014207843259761]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484814673032622, -0.49346481843577844, -0.20259639896210258, -0.8352206583105038]\n",
      "Layer: Layer 1, Input: [-0.9484814673032622, -0.49346481843577844, -0.20259639896210258, -0.8352206583105038], Output: [-0.6524656008367555, -0.8826830172256339, 0.9872547422876854, 0.5567800413154683]\n",
      "Layer: Layer 2, Input: [-0.6524656008367555, -0.8826830172256339, 0.9872547422876854, 0.5567800413154683], Output: [0.9508302517371663]\n",
      "Epoch 71/100, Loss: 0.09622835458851735, Accuracy: -0.06487444330209735\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.998988872578013, -0.9850551980181728, -0.671591693405537, -0.6812439682891518]\n",
      "Layer: Layer 1, Input: [-0.998988872578013, -0.9850551980181728, -0.671591693405537, -0.6812439682891518], Output: [-0.22163195351315815, -0.9382742829996306, 0.9937540283686769, 0.49434871891597915]\n",
      "Layer: Layer 2, Input: [-0.22163195351315815, -0.9382742829996306, 0.9937540283686769, 0.49434871891597915], Output: [0.7640433591997419]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968358520647809, 0.691533966333511, -0.7527937292029543, 0.914644663234539]\n",
      "Layer: Layer 1, Input: [-0.9968358520647809, 0.691533966333511, -0.7527937292029543, 0.914644663234539], Output: [0.39680010355212536, 0.13338501100025846, 0.8885787128260774, -0.8100282512477573]\n",
      "Layer: Layer 2, Input: [0.39680010355212536, 0.13338501100025846, 0.8885787128260774, -0.8100282512477573], Output: [-1.2675991369504582]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9796157562878048, -0.4557050246145995, -0.8759759073194352, 0.5560821186441878]\n",
      "Layer: Layer 1, Input: [-0.9796157562878048, -0.4557050246145995, -0.8759759073194352, 0.5560821186441878], Output: [0.6683375155134115, -0.5984499844987922, 0.9687036607896063, -0.38414307555721894]\n",
      "Layer: Layer 2, Input: [0.6683375155134115, -0.5984499844987922, 0.9687036607896063, -0.38414307555721894], Output: [-0.5234889448829347]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9484937252657023, -0.4912138393628988, -0.19615744762723772, -0.8382418389109911]\n",
      "Layer: Layer 1, Input: [-0.9484937252657023, -0.4912138393628988, -0.19615744762723772, -0.8382418389109911], Output: [-0.6593167920299935, -0.8813181253622573, 0.9871987090536972, 0.5587911737036015]\n",
      "Layer: Layer 2, Input: [-0.6593167920299935, -0.8813181253622573, 0.9871987090536972, 0.5587911737036015], Output: [0.9624778356284207]\n",
      "Epoch 72/100, Loss: 0.08893888322556968, Accuracy: -0.017588997239360804\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989898095183523, -0.9847357197275652, -0.6638667317034185, -0.6875592743641035]\n",
      "Layer: Layer 1, Input: [-0.9989898095183523, -0.9847357197275652, -0.6638667317034185, -0.6875592743641035], Output: [-0.23533593823019502, -0.9374913265588759, 0.9937512842078648, 0.4968741307001442]\n",
      "Layer: Layer 2, Input: [-0.23533593823019502, -0.9374913265588759, 0.9937512842078648, 0.4968741307001442], Output: [0.7756020482851419]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968374481845578, 0.6907518772294052, -0.7535896513171012, 0.9134942132941142]\n",
      "Layer: Layer 1, Input: [-0.9968374481845578, 0.6907518772294052, -0.7535896513171012, 0.9134942132941142], Output: [0.392390956125987, 0.12801700380860276, 0.8886864960043983, -0.813189691317025]\n",
      "Layer: Layer 2, Input: [0.392390956125987, 0.12801700380860276, 0.8886864960043983, -0.813189691317025], Output: [-1.2656808502284724]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9796357716144666, -0.4478631524171708, -0.8753914093659863, 0.5643753311056773]\n",
      "Layer: Layer 1, Input: [-0.9796357716144666, -0.4478631524171708, -0.8753914093659863, 0.5643753311056773], Output: [0.6677946504464674, -0.5901189298201481, 0.9681950544299391, -0.3988257184265951]\n",
      "Layer: Layer 2, Input: [0.6677946504464674, -0.5901189298201481, 0.9681950544299391, -0.3988257184265951], Output: [-0.5442511892667827]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.948507434201402, -0.48897529431878545, -0.1900518017200851, -0.8410255171412744]\n",
      "Layer: Layer 1, Input: [-0.948507434201402, -0.48897529431878545, -0.1900518017200851, -0.8410255171412744], Output: [-0.6657049032362787, -0.879989241732593, 0.9871431553834393, 0.5605953841526223]\n",
      "Layer: Layer 2, Input: [-0.6657049032362787, -0.879989241732593, 0.9871431553834393, 0.5605953841526223], Output: [0.9731837855135622]\n",
      "Epoch 73/100, Loss: 0.08234171068901808, Accuracy: 0.027356172837014414\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989907635092596, -0.9844198473483594, -0.656374996369106, -0.6933060979836958]\n",
      "Layer: Layer 1, Input: [-0.9989907635092596, -0.9844198473483594, -0.656374996369106, -0.6933060979836958], Output: [-0.24803112042699793, -0.9367005321682655, 0.9937459086570607, 0.49921927592375126]\n",
      "Layer: Layer 2, Input: [-0.24803112042699793, -0.9367005321682655, 0.9937459086570607, 0.49921927592375126], Output: [0.786281846149663]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968390432598867, 0.6900763585949969, -0.7544190177214668, 0.9122827440236754]\n",
      "Layer: Layer 1, Input: [-0.9968390432598867, 0.6900763585949969, -0.7544190177214668, 0.9122827440236754], Output: [0.38777156959635184, 0.12242722527239795, 0.8887981470963725, -0.8161402723270984]\n",
      "Layer: Layer 2, Input: [0.38777156959635184, 0.12242722527239795, 0.8887981470963725, -0.8161402723270984], Output: [-1.2630450091982577]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9796548681720828, -0.44032349705467305, -0.8748284444514391, 0.5721793764237536]\n",
      "Layer: Layer 1, Input: [-0.9796548681720828, -0.44032349705467305, -0.8748284444514391, 0.5721793764237536], Output: [0.6671155425500117, -0.5822829112931435, 0.9677029347176169, -0.412648958045427]\n",
      "Layer: Layer 2, Input: [0.6671155425500117, -0.5822829112931435, 0.9677029347176169, -0.412648958045427], Output: [-0.5637649313312467]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9485224552776611, -0.48674983983221354, -0.18426799305270972, -0.8436004735398378]\n",
      "Layer: Layer 1, Input: [-0.9485224552776611, -0.48674983983221354, -0.18426799305270972, -0.8436004735398378], Output: [-0.6716704682992172, -0.8786977654779247, 0.9870883894684352, 0.5622018631944362]\n",
      "Layer: Layer 2, Input: [-0.6716704682992172, -0.8786977654779247, 0.9870883894684352, 0.5622018631944362], Output: [0.9829865913821405]\n",
      "Epoch 74/100, Loss: 0.07636465433963448, Accuracy: 0.06998835966479255\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989917316656465, -0.9841078074589193, -0.6491190667460208, -0.6985648944583766]\n",
      "Layer: Layer 1, Input: [-0.9989917316656465, -0.9841078074589193, -0.6491190667460208, -0.6985648944583766], Output: [-0.2598223784686892, -0.9359070262728173, 0.9937384893059453, 0.5013981960367554]\n",
      "Layer: Layer 2, Input: [-0.2598223784686892, -0.9359070262728173, 0.9937384893059453, 0.5013981960367554], Output: [0.7961297373342433]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968406361277559, 0.6895151648221123, -0.7552741973198809, 0.9110115548366561]\n",
      "Layer: Layer 1, Input: [-0.9968406361277559, 0.6895151648221123, -0.7552741973198809, 0.9110115548366561], Output: [0.38295487846449894, 0.11666785771884015, 0.8889127559573503, -0.8188994413916668]\n",
      "Layer: Layer 2, Input: [0.38295487846449894, 0.11666785771884015, 0.8889127559573503, -0.8188994413916668], Output: [-1.2597939017695172]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9796730997447576, -0.43307955682603116, -0.8742864072717276, 0.5795163935657569]\n",
      "Layer: Layer 1, Input: [-0.9796730997447576, -0.43307955682603116, -0.8742864072717276, 0.5795163935657569], Output: [0.6663098348240358, -0.5749251779882005, 0.9672275161598092, -0.4256610429703553]\n",
      "Layer: Layer 2, Input: [0.6663098348240358, -0.5749251779882005, 0.9672275161598092, -0.4256610429703553], Output: [-0.5820951929083885]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9485386557519366, -0.4845379536439452, -0.1787919537318621, -0.8459917735346397]\n",
      "Layer: Layer 1, Input: [-0.9485386557519366, -0.4845379536439452, -0.1787919537318621, -0.8459917735346397], Output: [-0.6772512201673708, -0.8774441752335705, 0.9870346339966696, 0.5636215174776023]\n",
      "Layer: Layer 2, Input: [-0.6772512201673708, -0.8774441752335705, 0.9870346339966696, 0.5636215174776023], Output: [0.9919315832678142]\n",
      "Epoch 75/100, Loss: 0.07094137063371884, Accuracy: 0.11036261174092876\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.998992711300037, -0.9837997648127188, -0.6420976504409028, -0.7034043573771035]\n",
      "Layer: Layer 1, Input: [-0.998992711300037, -0.9837997648127188, -0.6420976504409028, -0.7034043573771035], Output: [-0.27080396413647323, -0.93511485729954, 0.9937295062165371, 0.5034252543485501]\n",
      "Layer: Layer 2, Input: [-0.27080396413647323, -0.93511485729954, 0.9937295062165371, 0.5034252543485501], Output: [0.8051968589101421]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968422255895649, 0.689073598686216, -0.7561480313691156, 0.9096821981242883]\n",
      "Layer: Layer 1, Input: [-0.9968422255895649, 0.689073598686216, -0.7561480313691156, 0.9096821981242883], Output: [0.37795443551915203, 0.11078656984509906, 0.8890295135834214, -0.8214848220435639]\n",
      "Layer: Layer 2, Input: [0.37795443551915203, 0.11078656984509906, 0.8890295135834214, -0.8214848220435639], Output: [-1.2560218899593614]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9796905182259252, -0.42612320192489284, -0.8737644513678045, 0.5864102255935308]\n",
      "Layer: Layer 1, Input: [-0.9796905182259252, -0.42612320192489284, -0.8737644513678045, 0.5864102255935308], Output: [0.6653876853260297, -0.5680244762623085, 0.966768812623325, -0.4379106154821425]\n",
      "Layer: Layer 2, Input: [0.6653876853260297, -0.5680244762623085, 0.966768812623325, -0.4379106154821425], Output: [-0.5993115161115192]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9485559099032314, -0.48234001528271936, -0.1736077764283481, -0.8482212374330486]\n",
      "Layer: Layer 1, Input: [-0.9485559099032314, -0.48234001528271936, -0.1736077764283481, -0.8482212374330486], Output: [-0.6824820267950895, -0.8762282293160032, 0.9869820414028762, 0.5648664606526564]\n",
      "Layer: Layer 2, Input: [-0.6824820267950895, -0.8762282293160032, 0.9869820414028762, 0.5648664606526564], Output: [1.0000686914250203]\n",
      "Epoch 76/100, Loss: 0.0660116844390499, Accuracy: 0.1484177936372797\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989936999272536, -0.9834958342601382, -0.6353062985677861, -0.7078831329054226]\n",
      "Layer: Layer 1, Input: [-0.9989936999272536, -0.9834958342601382, -0.6353062985677861, -0.7078831329054226], Output: [-0.2810603705283222, -0.9343271727792256, 0.9937193492960031, 0.5053149001847194]\n",
      "Layer: Layer 2, Input: [-0.2810603705283222, -0.9343271727792256, 0.9937193492960031, 0.5053149001847194], Output: [0.8135366980119367]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996843810432549, 0.6887547257010938, -0.7570338949344086, 0.9082963971790579]\n",
      "Layer: Layer 1, Input: [-0.996843810432549, 0.6887547257010938, -0.7570338949344086, 0.9082963971790579], Output: [0.37278413514475733, 0.10482639016088091, 0.8891477227561995, -0.823912265936536]\n",
      "Layer: Layer 2, Input: [0.37278413514475733, 0.10482639016088091, 0.8891477227561995, -0.823912265936536], Output: [-1.251815011824521]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.979707173136014, -0.419445154298637, -0.8732615524267207, 0.592885472733569]\n",
      "Layer: Layer 1, Input: [-0.979707173136014, -0.419445154298637, -0.8732615524267207, 0.592885472733569], Output: [0.6643594171468581, -0.5615564718123852, 0.9663266798363769, -0.44944558846609683]\n",
      "Layer: Layer 2, Input: [0.6643594171468581, -0.5615564718123852, 0.9663266798363769, -0.44944558846609683], Output: [-0.615485456872525]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9485740996897511, -0.480156367493797, -0.16869839163938713, -0.850307849233441]\n",
      "Layer: Layer 1, Input: [-0.9485740996897511, -0.480156367493797, -0.16869839163938713, -0.850307849233441], Output: [-0.6873948909035685, -0.8750491415114751, 0.9869307074966535, 0.5659495414922008]\n",
      "Layer: Layer 2, Input: [-0.6873948909035685, -0.8750491415114751, 0.9869307074966535, 0.5659495414922008], Output: [1.0074504919257206]\n",
      "Epoch 77/100, Loss: 0.061521576718735364, Accuracy: 0.16975665113422012\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989946952660839, -0.9831960912970588, -0.6287380953210467, -0.7120512700899005]\n",
      "Layer: Layer 1, Input: [-0.9989946952660839, -0.9831960912970588, -0.6287380953210467, -0.7120512700899005], Output: [-0.290667141783759, -0.9335463735844884, 0.9937083331068389, 0.5070814148241396]\n",
      "Layer: Layer 2, Input: [-0.290667141783759, -0.9335463735844884, 0.9937083331068389, 0.5070814148241396], Output: [0.8212035349124485]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996845389451173, 0.6885596050774077, -0.7579257392775482, 0.9068559829964371]\n",
      "Layer: Layer 1, Input: [-0.996845389451173, 0.6885596050774077, -0.7579257392775482, 0.9068559829964371], Output: [0.3674579931767192, 0.09882569232253056, 0.8892668029520098, -0.826195945758585]\n",
      "Layer: Layer 2, Input: [0.3674579931767192, 0.09882569232253056, 0.8892668029520098, -0.826195945758585], Output: [-1.2472508802628903]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9797231113330743, -0.41303539132959677, -0.8727765662017068, 0.5989667906619827]\n",
      "Layer: Layer 1, Input: [-0.9797231113330743, -0.41303539132959677, -0.8727765662017068, 0.5989667906619827], Output: [0.663235265583249, -0.5554949575439097, 0.9659008519063786, -0.46031235441740825]\n",
      "Layer: Layer 2, Input: [0.663235265583249, -0.5554949575439097, 0.9659008519063786, -0.46031235441740825], Output: [-0.6306886135414753]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9485931151444736, -0.47798736006275994, -0.16404614736005416, -0.852268113883665]\n",
      "Layer: Layer 1, Input: [-0.9485931151444736, -0.47798736006275994, -0.16404614736005416, -0.852268113883665], Output: [-0.6920190068524195, -0.8739057312837852, 0.9868806833744095, 0.5668839313792702]\n",
      "Layer: Layer 2, Input: [-0.6920190068524195, -0.8739057312837852, 0.9868806833744095, 0.5668839313792702], Output: [1.0141305715420885]\n",
      "Epoch 78/100, Loss: 0.05742293673465051, Accuracy: 0.19051069664894493\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989956952376862, -0.9829005810955477, -0.6223842922989072, -0.7159514534371042]\n",
      "Layer: Layer 1, Input: [-0.9989956952376862, -0.9829005810955477, -0.6223842922989072, -0.7159514534371042], Output: [-0.29969163971941504, -0.9327742473734688, 0.9936967094966386, 0.5087386729009195]\n",
      "Layer: Layer 2, Input: [-0.29969163971941504, -0.9327742473734688, 0.9936967094966386, 0.5087386729009195], Output: [0.8282511611028652]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996846961466671, 0.6884875300556507, -0.758818114994993, 0.9053628469384196]\n",
      "Layer: Layer 1, Input: [-0.996846961466671, 0.6884875300556507, -0.758818114994993, 0.9053628469384196], Output: [0.3619899735635085, 0.09281828177821341, 0.8893862901637994, -0.8283484741436647]\n",
      "Layer: Layer 2, Input: [0.3619899735635085, 0.09281828177821341, 0.8893862901637994, -0.8283484741436647], Output: [-1.2423988214394135]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9797383768709214, -0.40688347513364576, -0.8723082791433803, 0.6046783861432862]\n",
      "Layer: Layer 1, Input: [-0.9797383768709214, -0.40688347513364576, -0.8723082791433803, 0.6046783861432862], Output: [0.662025200522738, -0.5498128449379179, 0.965490972066431, -0.4705552580609202]\n",
      "Layer: Layer 2, Input: [0.662025200522738, -0.5498128449379179, 0.965490972066431, -0.4705552580609202], Output: [-0.6449911295777885]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9486128545369199, -0.47583337833450534, -0.15963328682920694, -0.8541163706030022]\n",
      "Layer: Layer 1, Input: [-0.9486128545369199, -0.47583337833450534, -0.15963328682920694, -0.8541163706030022], Output: [-0.6963808644743893, -0.872796548861456, 0.9868319856176341, 0.5676827810504547]\n",
      "Layer: Layer 2, Input: [-0.6963808644743893, -0.872796548861456, 0.9868319856176341, 0.5676827810504547], Output: [1.0201622133472001]\n",
      "Epoch 79/100, Loss: 0.053673166305810795, Accuracy: 0.21068125589404008\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989966979609204, -0.9826093260081784, -0.6162348697063345, -0.7196200549250911]\n",
      "Layer: Layer 1, Input: [-0.9989966979609204, -0.9826093260081784, -0.6162348697063345, -0.7196200549250911], Output: [-0.30819377431687706, -0.9320120831517891, 0.9936846783512157, 0.5102999387179589]\n",
      "Layer: Layer 2, Input: [-0.30819377431687706, -0.9320120831517891, 0.9936846783512157, 0.5102999387179589], Output: [0.8347318729427393]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968485253437014, 0.6885362704290835, -0.7597061773917541, 0.9038189064282296]\n",
      "Layer: Layer 1, Input: [-0.9968485253437014, 0.6885362704290835, -0.7597061773917541, 0.9038189064282296], Output: [0.35639385339126217, 0.08683356793731303, 0.8895058325102663, -0.8303810367181416]\n",
      "Layer: Layer 2, Input: [0.35639385339126217, 0.08683356793731303, 0.8895058325102663, -0.8303810367181416], Output: [-1.2373201969051566]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9797530109664582, -0.4009788131463936, -0.8718554508836155, 0.6100436680047453]\n",
      "Layer: Layer 1, Input: [-0.9797530109664582, -0.4009788131463936, -0.8718554508836155, 0.6100436680047453], Output: [0.6607388059835525, -0.5444829505169958, 0.9650966180931287, -0.48021627285174157]\n",
      "Layer: Layer 2, Input: [0.6607388059835525, -0.5444829505169958, 0.9650966180931287, -0.48021627285174157], Output: [-0.6584606027214169]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9486332243378923, -0.4736948590837198, -0.15544232748664732, -0.8558650683115854]\n",
      "Layer: Layer 1, Input: [-0.9486332243378923, -0.4736948590837198, -0.15544232748664732, -0.8558650683115854], Output: [-0.7005043885575771, -0.8717199768295136, 0.986784604854726, 0.5683589479257688]\n",
      "Layer: Layer 2, Input: [-0.7005043885575771, -0.8717199768295136, 0.986784604854726, 0.5683589479257688], Output: [1.0255973830035048]\n",
      "Epoch 80/100, Loss: 0.050234703897540776, Accuracy: 0.23027489575549487\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989977017450434, -0.9823223316318497, -0.6102790161506575, -0.7230880351672095]\n",
      "Layer: Layer 1, Input: [-0.9989977017450434, -0.9823223316318497, -0.6102790161506575, -0.7230880351672095], Output: [-0.31622669973667933, -0.9312607687955075, 0.9936723967224685, 0.5117777064769357]\n",
      "Layer: Layer 2, Input: [-0.31622669973667933, -0.9312607687955075, 0.9936723967224685, 0.5117777064769357], Output: [0.8406957223786431]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968500800036819, 0.6887023107078019, -0.7605856765836833, 0.902226081134645]\n",
      "Layer: Layer 1, Input: [-0.9968500800036819, 0.6887023107078019, -0.7605856765836833, 0.902226081134645], Output: [0.3506831191243126, 0.08089680359704522, 0.8896251825925025, -0.8323035303562724]\n",
      "Layer: Layer 2, Input: [0.3506831191243126, 0.08089680359704522, 0.8896251825925025, -0.8323035303562724], Output: [-1.232068857909581]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9797670520449051, -0.39531085789116016, -0.8714168484991879, 0.6150850179314893]\n",
      "Layer: Layer 1, Input: [-0.9797670520449051, -0.39531085789116016, -0.8714168484991879, 0.6150850179314893], Output: [0.6593852024050629, -0.5394785975890439, 0.9647173229635314, -0.48933483117498244]\n",
      "Layer: Layer 2, Input: [0.6593852024050629, -0.5394785975890439, 0.9647173229635314, -0.48933483117498244], Output: [-0.671161332566325]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9486541390265285, -0.47157229643832743, -0.15145634920244563, -0.8575250080258041]\n",
      "Layer: Layer 1, Input: [-0.9486541390265285, -0.47157229643832743, -0.15145634920244563, -0.8575250080258041], Output: [-0.7044111029622455, -0.8706743105765331, 0.9867385128153873, 0.5689247898640093]\n",
      "Layer: Layer 2, Input: [-0.7044111029622455, -0.8706743105765331, 0.9867385128153873, 0.5689247898640093], Output: [1.030485983137109]\n",
      "Epoch 81/100, Loss: 0.047074518011827715, Accuracy: 0.2493022138982781\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989987050803125, -0.982039591574898, -0.6045055259946998, -0.7263817175488424]\n",
      "Layer: Layer 1, Input: [-0.9989987050803125, -0.982039591574898, -0.6045055259946998, -0.7263817175488424], Output: [-0.3238374746153871, -0.9305208733400125, 0.9936599865461204, 0.5131835862614802]\n",
      "Layer: Layer 2, Input: [-0.3238374746153871, -0.9305208733400125, 0.9936599865461204, 0.5131835862614802], Output: [0.8461899951568307]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968516244347574, 0.6889810783876057, -0.761452935293608, 0.9005862774364402]\n",
      "Layer: Layer 1, Input: [-0.9968516244347574, 0.6889810783876057, -0.761452935293608, 0.9005862774364402], Output: [0.3448708881206454, 0.07502937302209296, 0.8897441875414366, -0.8341247001971073]\n",
      "Layer: Layer 2, Input: [0.3448708881206454, 0.07502937302209296, 0.8897441875414366, -0.8341247001971073], Output: [-1.2266916868013937]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9797805358381563, -0.38986925476919143, -0.8709912730205747, 0.6198236519244874]\n",
      "Layer: Layer 1, Input: [-0.9797805358381563, -0.38986925476919143, -0.8709912730205747, 0.6198236519244874], Output: [0.6579730004538609, -0.5347740577854857, 0.964352591367905, -0.4979477673369243]\n",
      "Layer: Layer 2, Input: [0.6579730004538609, -0.5347740577854857, 0.964352591367905, -0.4979477673369243], Output: [-0.6831538422380306]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9486755207777205, -0.46946624038729007, -0.14765920264138688, -0.8591055562037837]\n",
      "Layer: Layer 1, Input: [-0.9486755207777205, -0.46946624038729007, -0.14765920264138688, -0.8591055562037837], Output: [-0.7081203095235797, -0.8696578203090184, 0.986693668037361, 0.5693920180501777]\n",
      "Layer: Layer 2, Input: [-0.7081203095235797, -0.8696578203090184, 0.986693668037361, 0.5693920180501777], Output: [1.0348753373312753]\n",
      "Epoch 82/100, Loss: 0.044163603824302504, Accuracy: 0.26777681326219216\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9989997066270752, -0.981761091100313, -0.5989031182789668, -0.7295234545607421]\n",
      "Layer: Layer 1, Input: [-0.9989997066270752, -0.981761091100313, -0.5989031182789668, -0.7295234545607421], Output: [-0.3310676841979019, -0.9297927157934679, 0.9936475411376591, 0.5145282330671359]\n",
      "Layer: Layer 2, Input: [-0.3310676841979019, -0.9297927157934679, 0.9936475411376591, 0.5145282330671359], Output: [0.851258881912276]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968531576986249, 0.6893671579861992, -0.7623048173851265, 0.8989013792936156]\n",
      "Layer: Layer 1, Input: [-0.9968531576986249, 0.6893671579861992, -0.7623048173851265, 0.8989013792936156], Output: [0.338969850547229, 0.06924911124808122, 0.8898627776146856, -0.8358522709946815]\n",
      "Layer: Layer 2, Input: [0.338969850547229, 0.06924911124808122, 0.8898627776146856, -0.8358522709946815], Output: [-1.221229187747449]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9797934955171604, -0.38464394674967245, -0.870577578979832, 0.6242795490335105]\n",
      "Layer: Layer 1, Input: [-0.9797934955171604, -0.38464394674967245, -0.870577578979832, 0.6242795490335105], Output: [0.6565102777369051, -0.5303448581362981, 0.9640019126913147, -0.5060893408402418]\n",
      "Layer: Layer 2, Input: [0.6565102777369051, -0.5303448581362981, 0.9640019126913147, -0.5060893408402418], Output: [-0.6944946162344346]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9486972990642945, -0.4673772901047471, -0.14403564979461675, -0.86061483238475]\n",
      "Layer: Layer 1, Input: [-0.9486972990642945, -0.4673772901047471, -0.14403564979461675, -0.86061483238475], Output: [-0.7116492734701145, -0.868668797430671, 0.9866500203986751, 0.5697716002982385]\n",
      "Layer: Layer 2, Input: [-0.7116492734701145, -0.868668797430671, 0.9866500203986751, 0.5697716002982385], Output: [1.0388098641269488]\n",
      "Epoch 83/100, Loss: 0.04147650469616997, Accuracy: 0.2857144462723129\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990007052038801, -0.9814868098256752, -0.5934606843831696, -0.7325322020029574]\n",
      "Layer: Layer 1, Input: [-0.9990007052038801, -0.9814868098256752, -0.5934606843831696, -0.7325322020029574], Output: [-0.33795402177846195, -0.9290764221617019, 0.9936351306333419, 0.5158213136097095]\n",
      "Layer: Layer 2, Input: [-0.33795402177846195, -0.9290764221617019, 0.9936351306333419, 0.5158213136097095], Output: [0.8559433067070872]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968546789345707, 0.6898544877427915, -0.7631386899917515, 0.8971732439688078]\n",
      "Layer: Layer 1, Input: [-0.9968546789345707, 0.6898544877427915, -0.7631386899917515, 0.8971732439688078], Output: [0.3329922277298935, 0.06357063928936665, 0.889980954078686, -0.837493069966727]\n",
      "Layer: Layer 2, Input: [0.3329922277298935, 0.06357063928936665, 0.889980954078686, -0.837493069966727], Output: [-1.2157160964661051]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.979805961843964, -0.3796252442851396, -0.8701746879556588, 0.6284714289651553]\n",
      "Layer: Layer 1, Input: [-0.979805961843964, -0.3796252442851396, -0.8701746879556588, 0.6284714289651553], Output: [0.6550045719195033, -0.5261679785479183, 0.9636647710405101, -0.513791314688697]\n",
      "Layer: Layer 2, Input: [0.6550045719195033, -0.5261679785479183, 0.9636647710405101, -0.513791314688697], Output: [-0.705236004109655]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.94871941020355, -0.4653060839625401, -0.14057144871632585, -0.8620598739941263]\n",
      "Layer: Layer 1, Input: [-0.94871941020355, -0.4653060839625401, -0.14057144871632585, -0.8620598739941263], Output: [-0.715013408776965, -0.8677055879780707, 0.986607514648774, 0.5700737057883833]\n",
      "Layer: Layer 2, Input: [-0.715013408776965, -0.8677055879780707, 0.986607514648774, 0.5700737057883833], Output: [1.0423309033381913]\n",
      "Epoch 84/100, Loss: 0.03899087095193324, Accuracy: 0.30313231101244575\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990016997750828, -0.9812167236538959, -0.5881674732594542, -0.735424013997642]\n",
      "Layer: Layer 1, Input: [-0.9990016997750828, -0.9812167236538959, -0.5881674732594542, -0.735424013997642], Output: [-0.34452882750095093, -0.9283719722718383, 0.9936228065246667, 0.5170715044938616]\n",
      "Layer: Layer 2, Input: [-0.34452882750095093, -0.9283719722718383, 0.9936228065246667, 0.5170715044938616], Output: [0.8602808795180193]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968561873611542, 0.6904365370372496, -0.7639523817569417, 0.8954037013268952]\n",
      "Layer: Layer 1, Input: [-0.9968561873611542, 0.6904365370372496, -0.7639523817569417, 0.8954037013268952], Output: [0.3269497437284789, 0.05800570250295197, 0.8900987769739781, -0.8390531395249928]\n",
      "Layer: Layer 2, Input: [0.3269497437284789, 0.05800570250295197, 0.8900987769739781, -0.8390531395249928], Output: [-1.210181985706985]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798179633329294, -0.37480386789104586, -0.8697815971182518, 0.6324167643299907]\n",
      "Layer: Layer 1, Input: [-0.9798179633329294, -0.37480386789104586, -0.8697815971182518, 0.6324167643299907], Output: [0.6534628853941741, -0.5222219623954624, 0.9633406528373006, -0.521083069508835]\n",
      "Layer: Layer 2, Input: [0.6534628853941741, -0.5222219623954624, 0.9633406528373006, -0.521083069508835], Output: [-0.7154262476108922]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9487417968725973, -0.4632532877324977, -0.13725339375008525, -0.8634467808307434]\n",
      "Layer: Layer 1, Input: [-0.9487417968725973, -0.4632532877324977, -0.13725339375008525, -0.8634467808307434], Output: [-0.7182264584853976, -0.8667666155788655, 0.9865660931030191, 0.5703076827217642]\n",
      "Layer: Layer 2, Input: [-0.7182264584853976, -0.8667666155788655, 0.9865660931030191, 0.5703076827217642], Output: [1.0454766606941517]\n",
      "Epoch 85/100, Loss: 0.03668706174017443, Accuracy: 0.3200484807277748\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990026894383423, -0.9809508060935879, -0.5830132236256564, -0.7382124696308106]\n",
      "Layer: Layer 1, Input: [-0.9990026894383423, -0.9809508060935879, -0.5830132236256564, -0.7382124696308106], Output: [-0.3508205834577441, -0.9276792378595374, 0.9936106054180452, 0.5182865151205888]\n",
      "Layer: Layer 2, Input: [-0.3508205834577441, -0.9276792378595374, 0.9936106054180452, 0.5182865151205888], Output: [0.8643059426744177]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996857682275973, 0.6911064636038875, -0.7647441392855255, 0.8935945556880186]\n",
      "Layer: Layer 1, Input: [-0.996857682275973, 0.6911064636038875, -0.7647441392855255, 0.8935945556880186], Output: [0.32085360754386677, 0.05256350204043369, 0.8902163532243477, -0.8405378391704832]\n",
      "Layer: Layer 2, Input: [0.32085360754386677, 0.05256350204043369, 0.8902163532243477, -0.8405378391704832], Output: [-1.2046518494691754]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798295264136698, -0.37017096979347525, -0.8693973837404506, 0.6361318166785256]\n",
      "Layer: Layer 1, Input: [-0.9798295264136698, -0.37017096979347525, -0.8693973837404506, 0.6361318166785256], Output: [0.6518916979121027, -0.5184869601309338, 0.9630290524360994, -0.5279917391697174]\n",
      "Layer: Layer 2, Input: [0.6518916979121027, -0.5184869601309338, 0.9630290524360994, -0.5279917391697174], Output: [-0.7251095964860195]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9487644076119214, -0.4612195821309524, -0.13406932133863425, -0.8647808414753128]\n",
      "Layer: Layer 1, Input: [-0.9487644076119214, -0.4612195821309524, -0.13406932133863425, -0.8647808414753128], Output: [-0.7213006664523176, -0.8658503961101234, 0.9865256976504914, 0.5704820612480547]\n",
      "Layer: Layer 2, Input: [-0.7213006664523176, -0.8658503961101234, 0.9865256976504914, 0.5704820612480547], Output: [1.0482822413722137]\n",
      "Epoch 86/100, Loss: 0.03454779136515904, Accuracy: 0.33648144831904814\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990036734123146, -0.9806890291081629, -0.5779882523029396, -0.7409090403853557]\n",
      "Layer: Layer 1, Input: [-0.9990036734123146, -0.9806890291081629, -0.5779882523029396, -0.7409090403853557], Output: [-0.35685436499385675, -0.9269980132474039, 0.9935985521360082, 0.5194731290964085]\n",
      "Layer: Layer 2, Input: [-0.35685436499385675, -0.9269980132474039, 0.9935985521360082, 0.5194731290964085], Output: [0.8680496854790066]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968591630539326, 0.6918572504587551, -0.765512583477974, 0.891747589418468]\n",
      "Layer: Layer 1, Input: [-0.9968591630539326, 0.6918572504587551, -0.765512583477974, 0.891747589418468], Output: [0.3147145038580489, 0.04725101186950468, 0.8903338254244579, -0.8419519364777281]\n",
      "Layer: Layer 2, Input: [0.3147145038580489, 0.04725101186950468, 0.8903338254244579, -0.8419519364777281], Output: [-1.1991466542684948]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798406755906107, -0.36571813999392255, -0.8690212065565525, 0.6396316881721094]\n",
      "Layer: Layer 1, Input: [-0.9798406755906107, -0.36571813999392255, -0.8690212065565525, 0.6396316881721094], Output: [0.6502969845464427, -0.5149447227834436, 0.9627294761584508, -0.534542357454185]\n",
      "Layer: Layer 2, Input: [0.6502969845464427, -0.5149447227834436, 0.9627294761584508, -0.534542357454185], Output: [-0.7343264850906427]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9487871963320729, -0.45920565054939044, -0.13100809012091943, -0.8660666436333909]\n",
      "Layer: Layer 1, Input: [-0.9487871963320729, -0.45920565054939044, -0.13100809012091943, -0.8660666436333909], Output: [-0.7242469382000217, -0.8649555459240181, 0.9864862712075909, 0.570604575078512]\n",
      "Layer: Layer 2, Input: [-0.7242469382000217, -0.8649555459240181, 0.9864862712075909, 0.570604575078512], Output: [1.0507797477500405]\n",
      "Epoch 87/100, Loss: 0.03255781867859368, Accuracy: 0.3524497685511141\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990046510247799, -0.9804313636115345, -0.5730835072012251, -0.743523406209724]\n",
      "Layer: Layer 1, Input: [-0.9990046510247799, -0.9804313636115345, -0.5730835072012251, -0.743523406209724], Output: [-0.3626522490265, -0.9263280397981538, 0.993586662261965, 0.5206372586155709]\n",
      "Layer: Layer 2, Input: [-0.3626522490265, -0.9263280397981538, 0.993586662261965, 0.5206372586155709], Output: [0.8715403056279306]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968606291443936, 0.6926818231191462, -0.7662566670139667, 0.8898645676174063]\n",
      "Layer: Layer 1, Input: [-0.9968606291443936, 0.6926818231191462, -0.7662566670139667, 0.8898645676174063], Output: [0.30854259060185696, 0.04207327612187479, 0.8904513615312388, -0.8432996875275541]\n",
      "Layer: Layer 2, Input: [0.30854259060185696, 0.04207327612187479, 0.8904513615312388, -0.8432996875275541], Output: [-1.1936838501055522]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798514335958491, -0.3614374011045149, -0.8686523047398085, 0.6429303828466848]\n",
      "Layer: Layer 1, Input: [-0.9798514335958491, -0.3614374011045149, -0.8686523047398085, 0.6429303828466848], Output: [0.64868423707279, -0.5115785592730223, 0.9624414450755308, -0.5407580083392015]\n",
      "Layer: Layer 2, Input: [0.64868423707279, -0.5115785592730223, 0.9624414450755308, -0.5407580083392015], Output: [-0.743113747955506]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9488101218344513, -0.457212167555068, -0.1280595425961363, -0.8673081702334376]\n",
      "Layer: Layer 1, Input: [-0.9488101218344513, -0.457212167555068, -0.1280595425961363, -0.8673081702334376], Output: [-0.7270749895105884, -0.8640807852030088, 0.9864477587315934, 0.570682196291593]\n",
      "Layer: Layer 2, Input: [-0.7270749895105884, -0.8640807852030088, 0.9864477587315934, 0.570682196291593], Output: [1.052998421271166]\n",
      "Epoch 88/100, Loss: 0.030703676504144694, Accuracy: 0.36797178220671833\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990056217013719, -0.9801777797075857, -0.5682905925142132, -0.7460637269985865]\n",
      "Layer: Layer 1, Input: [-0.9990056217013719, -0.9801777797075857, -0.5682905925142132, -0.7460637269985865], Output: [-0.36823368095204184, -0.9256690251825556, 0.9935749442173174, 0.5217840071367564]\n",
      "Layer: Layer 2, Input: [-0.36823368095204184, -0.9256690251825556, 0.9935749442173174, 0.5217840071367564], Output: [0.874803200219025]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968620800675219, 0.6935731481785897, -0.7669756338924018, 0.8879472433990055]\n",
      "Layer: Layer 1, Input: [-0.9968620800675219, 0.6935731481785897, -0.7669756338924018, 0.8879472433990055], Output: [0.302347501956704, 0.03703368345549255, 0.8905691455938237, -0.8445849074251846]\n",
      "Layer: Layer 2, Input: [0.302347501956704, 0.03703368345549255, 0.8905691455938237, -0.8445849074251846], Output: [-1.1882778371999105]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798618215332975, -0.35732119541513224, -0.8682899951508571, 0.6460408730583844]\n",
      "Layer: Layer 1, Input: [-0.9798618215332975, -0.35732119541513224, -0.8682899951508571, 0.6460408730583844], Output: [0.6470584873829054, -0.5083732687462631, 0.9621644968132391, -0.5466599747323508]\n",
      "Layer: Layer 2, Input: [0.6470584873829054, -0.5083732687462631, 0.9621644968132391, -0.5466599747323508], Output: [-0.7515048575786566]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9488331473538585, -0.4552397885349728, -0.1252144542820271, -0.8685088829297752]\n",
      "Layer: Layer 1, Input: [-0.9488331473538585, -0.4552397885349728, -0.1252144542820271, -0.8685088829297752], Output: [-0.729793482165316, -0.8632249377239912, 0.9864101078904667, 0.5707211788788451]\n",
      "Layer: Layer 2, Input: [-0.729793482165316, -0.8632249377239912, 0.9864101078904667, 0.5707211788788451], Output: [1.0549648124573574]\n",
      "Epoch 89/100, Loss: 0.028973437267887446, Accuracy: 0.3830654081404137\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990065849550162, -0.9799282467515021, -0.5636017726390092, -0.7485368753782188]\n",
      "Layer: Layer 1, Input: [-0.9990065849550162, -0.9799282467515021, -0.5636017726390092, -0.7485368753782188], Output: [-0.373615802301255, -0.9250206583643574, 0.9935634009476337, 0.5229177365476193]\n",
      "Layer: Layer 2, Input: [-0.373615802301255, -0.9250206583643574, 0.9935634009476337, 0.5229177365476193], Output: [0.8778611728925723]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968635154101179, 0.6945243146288981, -0.7676689816312305, 0.8859973633836593]\n",
      "Layer: Layer 1, Input: [-0.9968635154101179, 0.6945243146288981, -0.7676689816312305, 0.8859973633836593], Output: [0.2961383556438614, 0.03213421668781423, 0.8906873695851476, -0.845811031699792]\n",
      "Layer: Layer 2, Input: [0.2961383556438614, 0.03213421668781423, 0.8906873695851476, -0.845811031699792], Output: [-1.1829403871414657]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798718590130424, -0.35336236688460626, -0.8679336683932125, 0.6489751679447078]\n",
      "Layer: Layer 1, Input: [-0.9798718590130424, -0.35336236688460626, -0.8679336683932125, 0.6489751679447078], Output: [0.6454243319385123, -0.5053150567553539, 0.9618981866047525, -0.5522678822277782]\n",
      "Layer: Layer 2, Input: [0.6454243319385123, -0.5053150567553539, 0.9618981866047525, -0.5522678822277782], Output: [-0.759530171915751]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9488562401278459, -0.4532891406924653, -0.12246447507414453, -0.8696717945044116]\n",
      "Layer: Layer 1, Input: [-0.9488562401278459, -0.4532891406924653, -0.12246447507414453, -0.8696717945044116], Output: [-0.7324101467937787, -0.862386928059451, 0.9863732694687318, 0.5707271075157201]\n",
      "Layer: Layer 2, Input: [-0.7324101467937787, -0.862386928059451, 0.9863732694687318, 0.5707271075157201], Output: [1.0567029667015153]\n",
      "Epoch 90/100, Loss: 0.02735651074656722, Accuracy: 0.3977479909653423\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.99900754037614, -0.9796827332942726, -0.5590099602882204, -0.7509486359435664]\n",
      "Layer: Layer 1, Input: [-0.99900754037614, -0.9796827332942726, -0.5590099602882204, -0.7509486359435664], Output: [-0.3788137417173773, -0.9243826210760577, 0.9935520312836638, 0.5240421358313238]\n",
      "Layer: Layer 2, Input: [-0.3788137417173773, -0.9243826210760577, 0.9935520312836638, 0.5240421358313238], Output: [0.8807346468924071]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968649348211402, 0.6955285995171633, -0.7683364264839063, 0.8840166731029265]\n",
      "Layer: Layer 1, Input: [-0.9968649348211402, 0.6955285995171633, -0.7683364264839063, 0.8840166731029265], Output: [0.28992376355183436, 0.027375677179843075, 0.8908062263438876, -0.8469811694554095]\n",
      "Layer: Layer 2, Input: [0.28992376355183436, 0.027375677179843075, 0.8908062263438876, -0.8469811694554095], Output: [-1.1776810189907037]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798815642755144, -0.34955414010412944, -0.8675827841050868, 0.6517443816748958]\n",
      "Layer: Layer 1, Input: [-0.9798815642755144, -0.34955414010412944, -0.8675827841050868, 0.6517443816748958], Output: [0.6437859565583753, -0.5023914420702335, 0.9616420877725215, -0.5575998357106202]\n",
      "Layer: Layer 2, Input: [0.6437859565583753, -0.5023914420702335, 0.9616420877725215, -0.5575998357106202], Output: [-0.767217182438278]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9488793709957889, -0.4513608154827213, -0.11980206645222553, -0.8707995315170302]\n",
      "Layer: Layer 1, Input: [-0.9488793709957889, -0.4513608154827213, -0.11980206645222553, -0.8707995315170302], Output: [-0.7349318931998844, -0.8615657770268246, 0.986337197574388, 0.5707049488529485]\n",
      "Layer: Layer 2, Input: [-0.7349318931998844, -0.8615657770268246, 0.986337197574388, 0.5707049488529485], Output: [1.0582346165094672]\n",
      "Epoch 91/100, Loss: 0.02584346991835807, Accuracy: 0.41203619383051426\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990084876236848, -0.9794412069573266, -0.5545086932799658, -0.7533038754535398]\n",
      "Layer: Layer 1, Input: [-0.9990084876236848, -0.9794412069573266, -0.5545086932799658, -0.7533038754535398], Output: [-0.38384087208493306, -0.9237545964426256, 0.9935408310332252, 0.5251602889795388]\n",
      "Layer: Layer 2, Input: [-0.38384087208493306, -0.9237545964426256, 0.9935408310332252, 0.5251602889795388], Output: [0.883441876546856]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968663380071032, 0.6965795196155449, -0.7689778718365027, 0.8820069220949411]\n",
      "Layer: Layer 1, Input: [-0.9968663380071032, 0.6965795196155449, -0.7689778718365027, 0.8820069220949411], Output: [0.2837118449109699, 0.02275788436372464, 0.8909259035959944, -0.8480981491571006]\n",
      "Layer: Layer 2, Input: [0.2837118449109699, 0.02275788436372464, 0.8909259035959944, -0.8480981491571006], Output: [-1.1725073321616462]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9798909543055135, -0.3458900977549134, -0.8672368658226729, 0.6543587999657257]\n",
      "Layer: Layer 1, Input: [-0.9798909543055135, -0.3458900977549134, -0.8672368658226729, 0.6543587999657257], Output: [0.6421471610411025, -0.4995911592288607, 0.9613957917854343, -0.5626725475566984]\n",
      "Layer: Layer 2, Input: [0.6421471610411025, -0.4995911592288607, 0.9613957917854343, -0.5626725475566984], Output: [-0.7745907563171575]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9489025140290157, -0.44945536248427204, -0.11722043728547034, -0.871894388417114]\n",
      "Layer: Layer 1, Input: [-0.9489025140290157, -0.44945536248427204, -0.11722043728547034, -0.871894388417114], Output: [-0.7373649088043257, -0.8607605960148568, 0.9863018496991299, 0.5706591033049391]\n",
      "Layer: Layer 2, Input: [-0.7373649088043257, -0.8607605960148568, 0.9863018496991299, 0.5706591033049391], Output: [1.0595793733502195]\n",
      "Epoch 92/100, Loss: 0.0244259011647307, Accuracy: 0.42594592735214787\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990094264169144, -0.9792036342723821, -0.5500921036094318, -0.7556066879334111]\n",
      "Layer: Layer 1, Input: [-0.9990094264169144, -0.9792036342723821, -0.5500921036094318, -0.7556066879334111], Output: [-0.38870903675414825, -0.9231362753061487, 0.9935297938513842, 0.5262747405195545]\n",
      "Layer: Layer 2, Input: [-0.38870903675414825, -0.9231362753061487, 0.9935297938513842, 0.5262747405195545], Output: [0.8859991518740319]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968677247274799, 0.6976708707897492, -0.7695933798045449, 0.8799698685238545]\n",
      "Layer: Layer 1, Input: [-0.9968677247274799, 0.6976708707897492, -0.7695933798045449, 0.8799698685238545], Output: [0.2775102413536999, 0.018279851455043093, 0.8910465789980732, -0.8491645579102981]\n",
      "Layer: Layer 2, Input: [0.2775102413536999, 0.018279851455043093, 0.8910465789980732, -0.8491645579102981], Output: [-1.1674252987646887]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799000449364429, -0.342364157661437, -0.8668954956697343, 0.6568279438591106]\n",
      "Layer: Layer 1, Input: [-0.9799000449364429, -0.342364157661437, -0.8668954956697343, 0.6568279438591106], Output: [0.6405113832788014, -0.4969040605642832, 0.961158908006656, -0.5675014568272251]\n",
      "Layer: Layer 2, Input: [0.6405113832788014, -0.4969040605642832, 0.961158908006656, -0.5675014568272251], Output: [-0.7816733683777555]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9489256461921378, -0.4475732846429675, -0.114713480253037, -0.8729583742054435]\n",
      "Layer: Layer 1, Input: [-0.9489256461921378, -0.4475732846429675, -0.114713480253037, -0.8729583742054435], Output: [-0.7397147460121001, -0.8599705806653994, 0.986267186673216, 0.5705934558688628]\n",
      "Layer: Layer 2, Input: [-0.7397147460121001, -0.8599705806653994, 0.986267186673216, 0.5705934558688628], Output: [1.0607549142730734]\n",
      "Epoch 93/100, Loss: 0.02309627543093227, Accuracy: 0.4394923072140252\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990103565280044, -0.9789699805119054, -0.5457548816397683, -0.7578605181427697]\n",
      "Layer: Layer 1, Input: [-0.9990103565280044, -0.9789699805119054, -0.5457548816397683, -0.7578605181427697], Output: [-0.39342874781287274, -0.9225273607129484, 0.9935189119288427, 0.527387557537224]\n",
      "Layer: Layer 2, Input: [-0.39342874781287274, -0.9225273607129484, 0.9935189119288427, 0.527387557537224], Output: [0.8884209927649229]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968690947902092, 0.6987967567001659, -0.7701831459440933, 0.8779072832016507]\n",
      "Layer: Layer 1, Input: [-0.9968690947902092, 0.6987967567001659, -0.7701831459440933, 0.8779072832016507], Output: [0.27132613330572675, 0.013939938821923323, 0.8911684161278534, -0.8501827750401247]\n",
      "Layer: Layer 2, Input: [0.27132613330572675, 0.013939938821923323, 0.8911684161278534, -0.8501827750401247], Output: [-1.162439518577298]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799088509452737, -0.33897055021165884, -0.866558309061764, 0.6591606301389725]\n",
      "Layer: Layer 1, Input: [-0.9799088509452737, -0.33897055021165884, -0.866558309061764, 0.6591606301389725], Output: [0.6388817226280559, -0.49432102036085984, 0.9609310632227954, -0.5721008393124266]\n",
      "Layer: Layer 2, Input: [0.6388817226280559, -0.49432102036085984, 0.9609310632227954, -0.5721008393124266], Output: [-0.7884853200663937]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9489487470348691, -0.44571503478561725, -0.11227571030444641, -0.8739932526139662]\n",
      "Layer: Layer 1, Input: [-0.9489487470348691, -0.44571503478561725, -0.11227571030444641, -0.8739932526139662], Output: [-0.741986399404875, -0.8591950042673266, 0.9862331725472959, 0.5705114249540157]\n",
      "Layer: Layer 2, Input: [-0.741986399404875, -0.8591950042673266, 0.9862331725472959, 0.5705114249540157], Output: [1.0617771600202466]\n",
      "Epoch 94/100, Loss: 0.021847837344693193, Accuracy: 0.45268963423377206\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990112777753706, -0.9787402095278972, -0.5414922376021549, -0.7600682664334973]\n",
      "Layer: Layer 1, Input: [-0.9990112777753706, -0.9787402095278972, -0.5414922376021549, -0.7600682664334973], Output: [-0.39800935928127773, -0.921927570945495, 0.9935081765319409, 0.5285003874890087]\n",
      "Layer: Layer 2, Input: [-0.39800935928127773, -0.921927570945495, 0.9935081765319409, 0.5285003874890087], Output: [0.8907203305522847]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968704480473826, 0.6999516083763127, -0.7707474769201964, 0.8758209529260437]\n",
      "Layer: Layer 1, Input: [-0.9968704480473826, 0.6999516083763127, -0.7707474769201964, 0.8758209529260437], Output: [0.2651662572432639, 0.009735986741649827, 0.8912915613376438, -0.8511550007121511]\n",
      "Layer: Layer 2, Input: [0.2651662572432639, 0.009735986741649827, 0.8912915613376438, -0.8511550007121511], Output: [-1.1575534400387895]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799173861388762, -0.33570379666150224, -0.8662249895589955, 0.6613650280409079]\n",
      "Layer: Layer 1, Input: [-0.9799173861388762, -0.33570379666150224, -0.8662249895589955, 0.6613650280409079], Output: [0.6372609623859229, -0.4918338429439153, 0.9607119010248242, -0.5764839085848633]\n",
      "Layer: Layer 2, Input: [0.6372609623859229, -0.4918338429439153, 0.9607119010248242, -0.5764839085848633], Output: [-0.7950449438626249]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9489717984130421, -0.4438810132781441, -0.10990220611835323, -0.8750005766633657]\n",
      "Layer: Layer 1, Input: [-0.9489717984130421, -0.4438810132781441, -0.10990220611835323, -0.8750005766633657], Output: [-0.7441843736913374, -0.8584332111221933, 0.9861997744260912, 0.5704160085505995]\n",
      "Layer: Layer 2, Input: [-0.7441843736913374, -0.8584332111221933, 0.9861997744260912, 0.5704160085505995], Output: [1.0626604425722532]\n",
      "Epoch 95/100, Loss: 0.02067450968057089, Accuracy: 0.46555139180386695\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990121900177011, -0.9785142836107236, -0.5372998620583754, -0.7622323776370196]\n",
      "Layer: Layer 1, Input: [-0.9990121900177011, -0.9785142836107236, -0.5372998620583754, -0.7622323776370196], Output: [-0.4024592179679168, -0.9213366414136089, 0.993497578422107, 0.5296145114167716]\n",
      "Layer: Layer 2, Input: [-0.4024592179679168, -0.9213366414136089, 0.993497578422107, 0.5296145114167716], Output: [0.8929086757974157]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968717843911511, 0.7011301960857371, -0.7712867709306332, 0.8737126830762676]\n",
      "Layer: Layer 1, Input: [-0.9968717843911511, 0.7011301960857371, -0.7712867709306332, 0.8737126830762676], Output: [0.2590369234279584, 0.005665429401942318, 0.8914161413830343, -0.8520832802641845]\n",
      "Layer: Layer 2, Input: [0.2590369234279584, 0.005665429401942318, 0.8914161413830343, -0.8520832802641845], Output: [-1.1527695507048648]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799256634323944, -0.3325586886489045, -0.8658952639597326, 0.6634487121053376]\n",
      "Layer: Layer 1, Input: [-0.9799256634323944, -0.3325586886489045, -0.8658952639597326, 0.6634487121053376], Output: [0.6356515912778954, -0.4894351758569012, 0.9605010810948568, -0.5806629084222812]\n",
      "Layer: Layer 2, Input: [0.6356515912778954, -0.4894351758569012, 0.9605010810948568, -0.5806629084222812], Output: [-0.801368792447756]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.948994784237148, -0.4420715666929618, -0.10758855515797217, -0.875981718356698]\n",
      "Layer: Layer 1, Input: [-0.948994784237148, -0.4420715666929618, -0.10758855515797217, -0.875981718356698], Output: [-0.7463127433410057, -0.8576846100650319, 0.9861669622728131, 0.5703098273354565]\n",
      "Layer: Layer 2, Input: [-0.7463127433410057, -0.8576846100650319, 0.9861669622728131, 0.5703098273354565], Output: [1.0634176609742303]\n",
      "Epoch 96/100, Loss: 0.01957081091978357, Accuracy: 0.47809025656607673\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990130931486354, -0.9782921633751238, -0.5331738865433175, -0.7643549162779332]\n",
      "Layer: Layer 1, Input: [-0.9990130931486354, -0.9782921633751238, -0.5331738865433175, -0.7643549162779332], Output: [-0.4067857945490728, -0.9207543256618704, 0.9934871081778308, 0.5307308924212485]\n",
      "Layer: Layer 2, Input: [-0.4067857945490728, -0.9207543256618704, 0.9934871081778308, 0.5307308924212485], Output: [0.8949962718809874]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968731037498901, 0.7023276347847789, -0.7718015006578128, 0.8715842994311729]\n",
      "Layer: Layer 1, Input: [-0.9968731037498901, 0.7023276347847789, -0.7718015006578128, 0.8715842994311729], Output: [0.2529440337971698, 0.0017253920326500455, 0.8915422617395578, -0.852969524845563]\n",
      "Layer: Layer 2, Input: [0.2529440337971698, 0.0017253920326500455, 0.8915422617395578, -0.852969524845563], Output: [-1.1480895405068863]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799336949203449, -0.3295302691004226, -0.8655688976921869, 0.6654187111632787]\n",
      "Layer: Layer 1, Input: [-0.9799336949203449, -0.3295302691004226, -0.8655688976921869, 0.6654187111632787], Output: [0.6340558239079883, -0.48711842879085876, 0.9602982784398503, -0.5846491970811153]\n",
      "Layer: Layer 2, Input: [0.6340558239079883, -0.48711842879085876, 0.9602982784398503, -0.5846491970811153], Output: [-0.8074718125675165]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9490176902465088, -0.4402869873489053, -0.10533080264893041, -0.8769378941752313]\n",
      "Layer: Layer 1, Input: [-0.9490176902465088, -0.4402869873489053, -0.10533080264893041, -0.8769378941752313], Output: [-0.7483752047913388, -0.8569486682646699, 0.9861347086984161, 0.5701951645140071]\n",
      "Layer: Layer 2, Input: [-0.7483752047913388, -0.8569486682646699, 0.9861347086984161, 0.5701951645140071], Output: [1.064060424962341]\n",
      "Epoch 97/100, Loss: 0.01853178398220636, Accuracy: 0.4903181189792766\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990139870920417, -0.9780738076770955, -0.529110845256597, -0.766437630107579]\n",
      "Layer: Layer 1, Input: [-0.9990139870920417, -0.9780738076770955, -0.529110845256597, -0.766437630107579], Output: [-0.4109957972331257, -0.920180395701736, 0.9934767564382179, 0.5318502194275851]\n",
      "Layer: Layer 2, Input: [-0.4109957972331257, -0.920180395701736, 0.9934767564382179, 0.5318502194275851], Output: [0.8969922345225773]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968744060846308, 0.7035393842996025, -0.7722921985116282, 0.8694376491924718]\n",
      "Layer: Layer 1, Input: [-0.9968744060846308, 0.7035393842996025, -0.7722921985116282, 0.8694376491924718], Output: [0.2468930997448786, -0.0020872269872570987, 0.89167000552323, -0.8538155288896075]\n",
      "Layer: Layer 2, Input: [0.2468930997448786, -0.0020872269872570987, 0.89167000552323, -0.8538155288896075], Output: [-1.1435144409853226]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799414919411106, -0.3266138146102995, -0.8652456905376742, 0.667281553538778]\n",
      "Layer: Layer 1, Input: [-0.9799414919411106, -0.3266138146102995, -0.8652456905376742, 0.667281553538778], Output: [0.6324756201524946, -0.4848776985703291, 0.960103182602934, -0.5884533239677379]\n",
      "Layer: Layer 2, Input: [0.6324756201524946, -0.4848776985703291, 0.960103182602934, -0.5884533239677379], Output: [-0.8133675039621586]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9490405038070915, -0.438527513591632, -0.10312540460373876, -0.8778701869590294]\n",
      "Layer: Layer 1, Input: [-0.9490405038070915, -0.438527513591632, -0.10312540460373876, -0.8778701869590294], Output: [-0.7503751220645148, -0.8562249053829373, 0.9861029887459932, 0.5700740023455657]\n",
      "Layer: Layer 2, Input: [-0.7503751220645148, -0.8562249053829373, 0.9861029887459932, 0.5700740023455657], Output: [1.0645991863905713]\n",
      "Epoch 98/100, Loss: 0.017552934494905, Accuracy: 0.502246111108842\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990148717978412, -0.9778591735628532, -0.5251076383987835, -0.7684820036824932]\n",
      "Layer: Layer 1, Input: [-0.9990148717978412, -0.9778591735628532, -0.5251076383987835, -0.7684820036824932], Output: [-0.41509527016078834, -0.9196146418364479, 0.9934665140837879, 0.532972946401349]\n",
      "Layer: Layer 2, Input: [-0.41509527016078834, -0.9196146418364479, 0.9934665140837879, 0.532972946401349], Output: [0.8989046777233078]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968756913857666, 0.7047612452482587, -0.7727594439268194, 0.8672746012112985]\n",
      "Layer: Layer 1, Input: [-0.9968756913857666, 0.7047612452482587, -0.7727594439268194, 0.8672746012112985], Output: [0.2408892595791114, -0.005775687290353606, 0.8917994329358405, -0.8546229848784375]\n",
      "Layer: Layer 2, Input: [0.2408892595791114, -0.005775687290353606, 0.8917994329358405, -0.8546229848784375], Output: [-1.139044743440461]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799490651354569, -0.3238048192991841, -0.8649254726991722, 0.6690433086149773]\n",
      "Layer: Layer 1, Input: [-0.9799490651354569, -0.3238048192991841, -0.8649254726991722, 0.6690433086149773], Output: [0.6309127035016706, -0.48270770024042, 0.9599154968749235, -0.5920850992819274]\n",
      "Layer: Layer 2, Input: [0.6309127035016706, -0.48270770024042, 0.9599154968749235, -0.5920850992819274], Output: [-0.8190680640266583]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9490632137309538, -0.4367933306908222, -0.10096918487191602, -0.8787795646796316]\n",
      "Layer: Layer 1, Input: [-0.9490632137309538, -0.4367933306908222, -0.10096918487191602, -0.8787795646796316], Output: [-0.7523155665665007, -0.8555128881383537, 0.9860717796776721, 0.569948055404617]\n",
      "Layer: Layer 2, Input: [-0.7523155665665007, -0.8555128881383537, 0.9860717796776721, 0.569948055404617], Output: [1.0650433587918016]\n",
      "Epoch 99/100, Loss: 0.016630177210658074, Accuracy: 0.5138846395177037\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9990157472383286, -0.9776482162492837, -0.5211614975359669, -0.77048930347568]\n",
      "Layer: Layer 1, Input: [-0.9990157472383286, -0.9776482162492837, -0.5211614975359669, -0.77048930347568], Output: [-0.41908967848008083, -0.9190568721132831, 0.9934563723673485, 0.5340993272570225]\n",
      "Layer: Layer 2, Input: [-0.41908967848008083, -0.9190568721132831, 0.9934563723673485, 0.5340993272570225], Output: [0.9007408268662692]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968769596700316, 0.7059893515827194, -0.7732038524865681, 0.8650970454292459]\n",
      "Layer: Layer 1, Input: [-0.9968769596700316, 0.7059893515827194, -0.7732038524865681, 0.8650970454292459], Output: [0.234937295486462, -0.009343349309217062, 0.891930581161798, -0.8553934957985507]\n",
      "Layer: Layer 2, Input: [0.234937295486462, -0.009343349309217062, 0.891930581161798, -0.8553934957985507], Output: [-1.1346804986914254]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9799564244996618, -0.3210989801101979, -0.8646081012155739, 0.6707096249503468]\n",
      "Layer: Layer 1, Input: [-0.9799564244996618, -0.3210989801101979, -0.8646081012155739, 0.6707096249503468], Output: [0.6293685783698058, -0.48060370411873704, 0.9597349375222018, -0.5955536572081237]\n",
      "Layer: Layer 2, Input: [0.6293685783698058, -0.48060370411873704, 0.9597349375222018, -0.5955536572081237], Output: [-0.8245845190436287]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9490858101153556, -0.4350845722411437, -0.09885929609374919, -0.8796668965450027]\n",
      "Layer: Layer 1, Input: [-0.9490858101153556, -0.4350845722411437, -0.09885929609374919, -0.8796668965450027], Output: [-0.754199351772541, -0.8548122252949716, 0.9860410607690832, 0.569818800702886]\n",
      "Layer: Layer 2, Input: [-0.754199351772541, -0.8548122252949716, 0.9860410607690832, 0.569818800702886], Output: [1.0654014256278295]\n",
      "Epoch 100/100, Loss: 0.015759789403067635, Accuracy: 0.5252434215906431\n"
     ]
    }
   ],
   "source": [
    "# Run our model training for multiple epochs\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Reset model parameters\n",
    "for param in mlp.parameters():\n",
    "    param.data = random.uniform(-1, 1)  # Random initialization of parameters\n",
    "    param.grad = 0.0\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "y_true = [Value(y_i) for y_i in y]  # Convert labels to Value objects\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_preds = [mlp(i)[0] for i in x]  # Forward pass through the neural network\n",
    "    loss = loss_fn_mse(y_preds, y_true)\n",
    "    losses.append(loss)\n",
    "    accuracy.append(1 - sum([abs(y_true - y_pred.data) for y_true, y_pred in zip(y, y_preds)]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.data}, Accuracy: {accuracy[-1]}\")\n",
    "        \n",
    "    mlp.zero_grad()  # Reset gradients of all parameters\n",
    "    loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "    visited = set()\n",
    "    loss.backward()\n",
    "    for param in mlp.parameters():\n",
    "        param.data = param.data - learning_rate * param.grad  # Update parameters using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "62fd9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds after training: [1.1114531692458625, -0.9919692898553708, -0.9923811532169381, 0.8860080244828509]\n",
      "y_true after training: [1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_preds after training: {[item.data for item in y_preds]}\")\n",
    "print(f\"y_true after training: {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "08b99310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(range(epochs), [item.data for item in losses])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2e370b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy over epochs\n",
    "plt.plot(range(epochs), accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "912faec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.0080,  0.6310,  0.2013, -1.9987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0080,  0.6310,  0.2013, -1.9987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7649,  0.5588,  0.1986, -0.9639], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.7649,  0.5588,  0.1986, -0.9639], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3581, -1.2205, -0.5212,  0.9182], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3581, -1.2205, -0.5212,  0.9182], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8759, -0.8398, -0.4786,  0.7250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8759, -0.8398, -0.4786,  0.7250], grad_fn=<TanhBackward0>),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.8141,  0.5476, -1.5705, -0.6861], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.8141,  0.5476, -1.5705, -0.6861], grad_fn=<ViewBackward0>),), Output: tensor([-0.9482,  0.4987, -0.9171, -0.5955], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9482,  0.4987, -0.9171, -0.5955], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2511, -0.7744,  0.2241, -1.0185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2511, -0.7744,  0.2241, -1.0185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8486, -0.6495,  0.2204, -0.7693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8486, -0.6495,  0.2204, -0.7693], grad_fn=<TanhBackward0>),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7748, -0.7850, -0.5231, -1.7591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7748, -0.7850, -0.5231, -1.7591], grad_fn=<ViewBackward0>),), Output: tensor([-0.6497, -0.6556, -0.4801, -0.9424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6497, -0.6556, -0.4801, -0.9424], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4910, -0.9057,  1.1436, -0.4672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4910, -0.9057,  1.1436, -0.4672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9035, -0.7191,  0.8156, -0.4360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9035, -0.7191,  0.8156, -0.4360], grad_fn=<TanhBackward0>),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3531,  0.4963, -2.6552, -3.9193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3531,  0.4963, -2.6552, -3.9193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9821,  0.4592, -0.9902, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9821,  0.4592, -0.9902, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5757, -1.1224,  0.0079, -1.0246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5757, -1.1224,  0.0079, -1.0246], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9179, -0.8084,  0.0079, -0.7717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9179, -0.8084,  0.0079, -0.7717], grad_fn=<TanhBackward0>),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1021,  0.7992, -0.0230, -2.0032], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1021,  0.7992, -0.0230, -2.0032], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8013,  0.6636, -0.0230, -0.9643], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8013,  0.6636, -0.0230, -0.9643], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1917, -1.1030, -0.8884,  0.7203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1917, -1.1030, -0.8884,  0.7203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8311, -0.8016, -0.7106,  0.6171], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8311, -0.8016, -0.7106,  0.6171], grad_fn=<TanhBackward0>),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7888,  0.6298, -1.6242, -0.6931], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7888,  0.6298, -1.6242, -0.6931], grad_fn=<ViewBackward0>),), Output: tensor([-0.9456,  0.5579, -0.9252, -0.5999], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9456,  0.5579, -0.9252, -0.5999], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2236, -0.8162,  0.0418, -1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2236, -0.8162,  0.0418, -1.0341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8407, -0.6730,  0.0418, -0.7755], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8407, -0.6730,  0.0418, -0.7755], grad_fn=<TanhBackward0>),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7485, -0.7334, -0.5837, -1.7624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7485, -0.7334, -0.5837, -1.7624], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.6251, -0.5254, -0.9428], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.6251, -0.5254, -0.9428], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4321, -0.8981,  0.9794, -0.5130], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4321, -0.8981,  0.9794, -0.5130], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8921, -0.7154,  0.7528, -0.4723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8921, -0.7154,  0.7528, -0.4723], grad_fn=<TanhBackward0>),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3352,  0.4862, -2.7083, -3.9337], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3352,  0.4862, -2.7083, -3.9337], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814,  0.4512, -0.9912, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814,  0.4512, -0.9912, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5461, -1.1419, -0.0660, -1.0364], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5461, -1.1419, -0.0660, -1.0364], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9131, -0.8151, -0.0659, -0.7765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9131, -0.8151, -0.0659, -0.7765], grad_fn=<TanhBackward0>),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1407,  0.8638, -0.1561, -2.0103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1407,  0.8638, -0.1561, -2.0103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8147,  0.6982, -0.1548, -0.9647], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8147,  0.6982, -0.1548, -0.9647], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0857, -1.0351, -1.0761,  0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0857, -1.0351, -1.0761,  0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7953, -0.7760, -0.7918,  0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7953, -0.7760, -0.7918,  0.5320], grad_fn=<TanhBackward0>),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7759,  0.6673, -1.6569, -0.7048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7759,  0.6673, -1.6569, -0.7048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9442,  0.5832, -0.9298, -0.6074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9442,  0.5832, -0.9298, -0.6074], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2069, -0.8486, -0.0589, -1.0438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2069, -0.8486, -0.0589, -1.0438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358, -0.6903, -0.0588, -0.7794], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8358, -0.6903, -0.0588, -0.7794], grad_fn=<TanhBackward0>),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -0.7397, -0.6175, -1.7678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -0.7397, -0.6175, -1.7678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6280, -0.6289, -0.5494, -0.9434], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6280, -0.6289, -0.5494, -0.9434], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3961, -0.8933,  0.9110, -0.5400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3961, -0.8933,  0.9110, -0.5400], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8845, -0.7130,  0.7216, -0.4930], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8845, -0.7130,  0.7216, -0.4930], grad_fn=<TanhBackward0>),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279,  0.4142, -2.7411, -3.9491], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279,  0.4142, -2.7411, -3.9491], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.3921, -0.9917, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.3921, -0.9917, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5162, -1.1395, -0.0601, -1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5162, -1.1395, -0.0601, -1.0477], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9080, -0.8143, -0.0600, -0.7809], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9080, -0.8143, -0.0600, -0.7809], grad_fn=<TanhBackward0>),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1622,  0.8913, -0.2480, -2.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1622,  0.8913, -0.2480, -2.0177], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217,  0.7120, -0.2431, -0.9653], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8217,  0.7120, -0.2431, -0.9653], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0099, -0.9920, -1.1905,  0.5040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0099, -0.9920, -1.1905,  0.5040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7657, -0.7582, -0.8307,  0.4652], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7657, -0.7582, -0.8307,  0.4652], grad_fn=<TanhBackward0>),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7676,  0.6819, -1.6798, -0.7174], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7676,  0.6819, -1.6798, -0.7174], grad_fn=<ViewBackward0>),), Output: tensor([-0.9433,  0.5928, -0.9328, -0.6153], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9433,  0.5928, -0.9328, -0.6153], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1954, -0.8732, -0.1147, -1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1954, -0.8732, -0.1147, -1.0502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8323, -0.7030, -0.1142, -0.7819], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8323, -0.7030, -0.1142, -0.7819], grad_fn=<TanhBackward0>),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7341, -0.7761, -0.6384, -1.7735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7341, -0.7761, -0.6384, -1.7735], grad_fn=<ViewBackward0>),), Output: tensor([-0.6256, -0.6505, -0.5638, -0.9440], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6256, -0.6505, -0.5638, -0.9440], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3708, -0.8863,  0.8927, -0.5579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3708, -0.8863,  0.8927, -0.5579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8789, -0.7096,  0.7127, -0.5064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8789, -0.7096,  0.7127, -0.5064], grad_fn=<TanhBackward0>),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3259,  0.2992, -2.7629, -3.9641], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3259,  0.2992, -2.7629, -3.9641], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.2906, -0.9921, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.2906, -0.9921, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4848, -1.1186,  0.0036, -1.0591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4848, -1.1186,  0.0036, -1.0591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9024, -0.8071,  0.0036, -0.7853], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9024, -0.8071,  0.0036, -0.7853], grad_fn=<TanhBackward0>),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1761,  0.8992, -0.3173, -2.0250], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761,  0.8992, -0.3173, -2.0250], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262,  0.7159, -0.3070, -0.9658], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8262,  0.7159, -0.3070, -0.9658], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9513, -0.9619, -1.2662,  0.4373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9513, -0.9619, -1.2662,  0.4373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7404, -0.7451, -0.8528,  0.4114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7404, -0.7451, -0.8528,  0.4114], grad_fn=<TanhBackward0>),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7616,  0.6820, -1.6972, -0.7299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7616,  0.6820, -1.6972, -0.7299], grad_fn=<ViewBackward0>),), Output: tensor([-0.9427,  0.5928, -0.9351, -0.6230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9427,  0.5928, -0.9351, -0.6230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1864, -0.8918, -0.1448, -1.0549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1864, -0.8918, -0.1448, -1.0549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8295, -0.7123, -0.1438, -0.7837], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8295, -0.7123, -0.1438, -0.7837], grad_fn=<TanhBackward0>),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7332, -0.8333, -0.6523, -1.7790], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7332, -0.8333, -0.6523, -1.7790], grad_fn=<ViewBackward0>),), Output: tensor([-0.6250, -0.6822, -0.5732, -0.9446], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6250, -0.6822, -0.5732, -0.9446], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3513, -0.8767,  0.9032, -0.5706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3513, -0.8767,  0.9032, -0.5706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8744, -0.7048,  0.7179, -0.5158], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8744, -0.7048,  0.7179, -0.5158], grad_fn=<TanhBackward0>),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3264,  0.1554, -2.7784, -3.9786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3264,  0.1554, -2.7784, -3.9786], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.1542, -0.9923, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.1542, -0.9923, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4515, -1.0824,  0.1091, -1.0711], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4515, -1.0824,  0.1091, -1.0711], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8960, -0.7941,  0.1087, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8960, -0.7941,  0.1087, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1863,  0.8956, -0.3723, -2.0321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1863,  0.8956, -0.3723, -2.0321], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8294,  0.7141, -0.3560, -0.9662], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8294,  0.7141, -0.3560, -0.9662], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9035, -0.9396, -1.3204,  0.3847], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9035, -0.9396, -1.3204,  0.3847], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7180, -0.7350, -0.8669,  0.3668], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7180, -0.7350, -0.8669,  0.3668], grad_fn=<TanhBackward0>),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7568,  0.6731, -1.7113, -0.7420], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7568,  0.6731, -1.7113, -0.7420], grad_fn=<ViewBackward0>),), Output: tensor([-0.9421,  0.5870, -0.9368, -0.6304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9421,  0.5870, -0.9368, -0.6304], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1785, -0.9063, -0.1620, -1.0588], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1785, -0.9063, -0.1620, -1.0588], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8270, -0.7193, -0.1606, -0.7852], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8270, -0.7193, -0.1606, -0.7852], grad_fn=<TanhBackward0>),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7338, -0.9042, -0.6623, -1.7843], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7338, -0.9042, -0.6623, -1.7843], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.7183, -0.5799, -0.9452], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.7183, -0.5799, -0.9452], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3355, -0.8654,  0.9283, -0.5804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3355, -0.8654,  0.9283, -0.5804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8706, -0.6990,  0.7298, -0.5230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8706, -0.6990,  0.7298, -0.5230], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3276e+00,  2.5095e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3276e+00,  2.5095e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.0025, -0.9925, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.0025, -0.9925, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4186, -1.0379,  0.2323, -1.0828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4186, -1.0379,  0.2323, -1.0828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8893, -0.7771,  0.2282, -0.7942], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8893, -0.7771,  0.2282, -0.7942], grad_fn=<TanhBackward0>),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1945,  0.8873, -0.4175, -2.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1945,  0.8873, -0.4175, -2.0390], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8320,  0.7100, -0.3948, -0.9667], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8320,  0.7100, -0.3948, -0.9667], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8632, -0.9229, -1.3641,  0.3420], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8632, -0.9229, -1.3641,  0.3420], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6979, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6979, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7524,  0.6612, -1.7234, -0.7538], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7524,  0.6612, -1.7234, -0.7538], grad_fn=<ViewBackward0>),), Output: tensor([-0.9416,  0.5792, -0.9383, -0.6374], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9416,  0.5792, -0.9383, -0.6374], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1714, -0.9188, -0.1769, -1.0623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1714, -0.9188, -0.1769, -1.0623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7349, -0.9794, -0.6698, -1.7895], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7349, -0.9794, -0.6698, -1.7895], grad_fn=<ViewBackward0>),), Output: tensor([-0.6260, -0.7528, -0.5849, -0.9457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6260, -0.7528, -0.5849, -0.9457], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3224, -0.8540,  0.9562, -0.5882], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3224, -0.8540,  0.9562, -0.5882], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8674, -0.6931,  0.7426, -0.5286], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8674, -0.6931,  0.7426, -0.5286], grad_fn=<TanhBackward0>),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -0.1379, -2.8001, -4.0063], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -0.1379, -2.8001, -4.0063], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.1370, -0.9926, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.1370, -0.9926, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3898, -0.9951,  0.3450, -1.0929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3898, -0.9951,  0.3450, -1.0929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8831, -0.7595,  0.3320, -0.7979], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8831, -0.7595,  0.3320, -0.7979], grad_fn=<TanhBackward0>),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2013,  0.8801, -0.4551, -2.0457], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2013,  0.8801, -0.4551, -2.0457], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8341,  0.7065, -0.4261, -0.9671], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8341,  0.7065, -0.4261, -0.9671], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8289, -0.9109, -1.4039,  0.3069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8289, -0.9109, -1.4039,  0.3069], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6799, -0.7216, -0.8862,  0.2976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6799, -0.7216, -0.8862,  0.2976], grad_fn=<TanhBackward0>),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7482,  0.6525, -1.7338, -0.7653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7482,  0.6525, -1.7338, -0.7653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.0490, -0.6758, -1.7944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.0490, -0.6758, -1.7944], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.7814, -0.5888, -0.9462], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.7814, -0.5888, -0.9462], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.8439,  0.9791, -0.5942], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.8439,  0.9791, -0.5942], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.6879,  0.7527, -0.5329], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.6879,  0.7527, -0.5329], grad_fn=<TanhBackward0>),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3297, -0.2561, -2.8077, -4.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3297, -0.2561, -2.8077, -4.0193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.2507, -0.9927, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.2507, -0.9927, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3666, -0.9588,  0.4344, -1.1007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3666, -0.9588,  0.4344, -1.1007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8779, -0.7437,  0.4090, -0.8008], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8779, -0.7437,  0.4090, -0.8008], grad_fn=<TanhBackward0>),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2070,  0.8764, -0.4862, -2.0522], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2070,  0.8764, -0.4862, -2.0522], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8358,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8001, -0.9029, -1.4418,  0.2780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8001, -0.9029, -1.4418,  0.2780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6641, -0.7177, -0.8941,  0.2711], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6641, -0.7177, -0.8941,  0.2711], grad_fn=<TanhBackward0>),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7442,  0.6493, -1.7430, -0.7763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7442,  0.6493, -1.7430, -0.7763], grad_fn=<ViewBackward0>),), Output: tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8211, -0.7366, -0.2205, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8211, -0.7366, -0.2205, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7371, -1.1083, -0.6803, -1.7992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7371, -1.1083, -0.6803, -1.7992], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.8353,  0.9953, -0.5987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.8353,  0.9953, -0.5987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6833,  0.7596, -0.5361], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6833,  0.7596, -0.5361], grad_fn=<TanhBackward0>),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3307, -0.3540, -2.8135, -4.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3307, -0.3540, -2.8135, -4.0317], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.3399, -0.9928, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.3399, -0.9928, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3485, -0.9288,  0.5030, -1.1065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3485, -0.9288,  0.5030, -1.1065], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8737, -0.7300,  0.4644, -0.8028], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8737, -0.7300,  0.4644, -0.8028], grad_fn=<TanhBackward0>),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2117,  0.8755, -0.5119, -2.0584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2117,  0.8755, -0.5119, -2.0584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7760, -0.8979, -1.4773,  0.2544], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7760, -0.8979, -1.4773,  0.2544], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6504, -0.7153, -0.9010,  0.2491], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6504, -0.7153, -0.9010,  0.2491], grad_fn=<TanhBackward0>),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7404,  0.6505, -1.7509, -0.7868], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7404,  0.6505, -1.7509, -0.7868], grad_fn=<ViewBackward0>),), Output: tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1562, -0.9548, -0.2550, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1562, -0.9548, -0.2550, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8198, -0.7419, -0.2496, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8198, -0.7419, -0.2496, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7383, -1.1580, -0.6836, -1.8036], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7383, -1.1580, -0.6836, -1.8036], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.8204, -0.5939, -0.9472], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.8204, -0.5939, -0.9472], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2979, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2979, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8612, -0.6792,  0.7646, -0.5383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8612, -0.6792,  0.7646, -0.5383], grad_fn=<TanhBackward0>),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3319, -0.4362, -2.8175, -4.0432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3319, -0.4362, -2.8175, -4.0432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.4105, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.4105, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3346, -0.9033,  0.5565, -1.1106], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3346, -0.9033,  0.5565, -1.1106], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8704, -0.7179,  0.5054, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8704, -0.7179,  0.5054, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2155,  0.8762, -0.5328, -2.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2155,  0.8762, -0.5328, -2.0641], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7559, -0.8948, -1.5099,  0.2352], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7559, -0.8948, -1.5099,  0.2352], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7370,  0.6546, -1.7576, -0.7966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7370,  0.6546, -1.7576, -0.7966], grad_fn=<ViewBackward0>),), Output: tensor([-0.9399,  0.5748, -0.9422, -0.6621], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9399,  0.5748, -0.9422, -0.6621], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1532, -0.9657, -0.2872, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1532, -0.9657, -0.2872, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7468, -0.2795, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7468, -0.2795, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7396, -1.2004, -0.6858, -1.8078], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7396, -1.2004, -0.6858, -1.8078], grad_fn=<ViewBackward0>),), Output: tensor([-0.6289, -0.8338, -0.5953, -0.9476], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6289, -0.8338, -0.5953, -0.9476], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2938, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2938, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8601, -0.6753,  0.7685, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8601, -0.6753,  0.7685, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3332, -0.5065, -2.8201, -4.0539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3332, -0.5065, -2.8201, -4.0539], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.4672, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.4672, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3239, -0.8809,  0.5996, -1.1134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3239, -0.8809,  0.5996, -1.1134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8677, -0.7069,  0.5368, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8677, -0.7069,  0.5368, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2186,  0.8779, -0.5498, -2.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2186,  0.8779, -0.5498, -2.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8392,  0.7054, -0.5004, -0.9686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8392,  0.7054, -0.5004, -0.9686], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7394, -0.8931, -1.5391,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7394, -0.8931, -1.5391,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6288, -0.7129, -0.9120,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6288, -0.7129, -0.9120,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1511, -0.9754, -0.3191, -1.0732], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1511, -0.9754, -0.3191, -1.0732], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7511, -0.3087, -0.7907], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7511, -0.3087, -0.7907], grad_fn=<TanhBackward0>),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7410, -1.2370, -0.6870, -1.8117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7410, -1.2370, -0.6870, -1.8117], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8594, -0.6713,  0.7721, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8594, -0.6713,  0.7721, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3346, -0.5673, -2.8216, -4.0638], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3346, -0.5673, -2.8216, -4.0638], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.5133, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.5133, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.8609,  0.6352, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.8609,  0.6352, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.6967,  0.5616, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.6967,  0.5616, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2210,  0.8799, -0.5635, -2.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2210,  0.8799, -0.5635, -2.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8399,  0.7064, -0.5105, -0.9689], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8399,  0.7064, -0.5105, -0.9689], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7257, -0.8922, -1.5653,  0.2072], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7257, -0.8922, -1.5653,  0.2072], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6205, -0.7125, -0.9163,  0.2043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6205, -0.7125, -0.9163,  0.2043], grad_fn=<TanhBackward0>),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1495, -0.9841, -0.3499, -1.0741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1495, -0.9841, -0.3499, -1.0741], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8176, -0.7548, -0.3363, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8176, -0.7548, -0.3363, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7424, -1.2691, -0.6876, -1.8152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7424, -1.2691, -0.6876, -1.8152], grad_fn=<ViewBackward0>),), Output: tensor([-0.6306, -0.8536, -0.5964, -0.9484], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6306, -0.8536, -0.5964, -0.9484], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3361, -0.6203, -2.8221, -4.0729], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3361, -0.6203, -2.8221, -4.0729], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5514, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5514, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.8426,  0.6650, -1.1164], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.8426,  0.6650, -1.1164], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6872,  0.5817, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6872,  0.5817, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2229,  0.8821, -0.5744, -2.0791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2229,  0.8821, -0.5744, -2.0791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8405,  0.7075, -0.5186, -0.9692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8405,  0.7075, -0.5186, -0.9692], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7145, -0.8918, -1.5886,  0.1972], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7145, -0.8918, -1.5886,  0.1972], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6135, -0.7123, -0.9199,  0.1947], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6135, -0.7123, -0.9199,  0.1947], grad_fn=<TanhBackward0>),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1484, -0.9916, -0.3794, -1.0747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1484, -0.9916, -0.3794, -1.0747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7580, -0.3622, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7580, -0.3622, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7438, -1.2974, -0.6875, -1.8185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7438, -1.2974, -0.6875, -1.8185], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.8611, -0.5964, -0.9487], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.8611, -0.5964, -0.9487], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7987,  1.0417, -0.6043], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7987,  1.0417, -0.6043], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6633,  0.7786, -0.5401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6633,  0.7786, -0.5401], grad_fn=<TanhBackward0>),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3376, -0.6670, -2.8221, -4.0813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3376, -0.6670, -2.8221, -4.0813], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5830, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5830, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3040, -0.8258,  0.6905, -1.1170], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3040, -0.8258,  0.6905, -1.1170], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.6782,  0.5983, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.6782,  0.5983, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2245,  0.8842, -0.5830, -2.0834], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2245,  0.8842, -0.5830, -2.0834], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8410,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8410,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7054, -0.8919, -1.6093,  0.1892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7054, -0.8919, -1.6093,  0.1892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6078, -0.7123, -0.9231,  0.1870], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6078, -0.7123, -0.9231,  0.1870], grad_fn=<TanhBackward0>),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7261,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7261,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9386,  0.5933, -0.9443, -0.6802], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9386,  0.5933, -0.9443, -0.6802], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1477, -0.9981, -0.4072, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1477, -0.9981, -0.4072, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7608, -0.3861, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7608, -0.3861, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7452, -1.3226, -0.6871, -1.8215], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7452, -1.3226, -0.6871, -1.8215], grad_fn=<ViewBackward0>),), Output: tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7915,  1.0495, -0.6035], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7915,  1.0495, -0.6035], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3389, -0.7083, -2.8215, -4.0891], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3389, -0.7083, -2.8215, -4.0891], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6096, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6096, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3001, -0.8102,  0.7124, -1.1172], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3001, -0.8102,  0.7124, -1.1172], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8618, -0.6697,  0.6122, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8618, -0.6697,  0.6122, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2258,  0.8862, -0.5897, -2.0874], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2258,  0.8862, -0.5897, -2.0874], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6980, -0.8921, -1.6277,  0.1831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6980, -0.8921, -1.6277,  0.1831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1473, -1.0038, -0.4335, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1473, -1.0038, -0.4335, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7465, -1.3450, -0.6864, -1.8242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7465, -1.3450, -0.6864, -1.8242], grad_fn=<ViewBackward0>),), Output: tensor([-0.6330, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6330, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3402, -0.7450, -2.8207, -4.0962], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3402, -0.7450, -2.8207, -4.0962], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6322, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6322, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2971, -0.7957,  0.7315, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2971, -0.7957,  0.7315, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6617,  0.6240, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6617,  0.6240, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2268,  0.8880, -0.5947, -2.0910], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2268,  0.8880, -0.5947, -2.0910], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6921, -0.8924, -1.6439,  0.1783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6921, -0.8924, -1.6439,  0.1783], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5994, -0.7126, -0.9280,  0.1765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5994, -0.7126, -0.9280,  0.1765], grad_fn=<TanhBackward0>),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7220,  0.6983, -1.7822, -0.8424], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7220,  0.6983, -1.7822, -0.8424], grad_fn=<ViewBackward0>),), Output: tensor([-0.9381,  0.6033, -0.9449, -0.6871], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9381,  0.6033, -0.9449, -0.6871], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0087, -0.4582, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0087, -0.4582, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7477, -1.3652, -0.6854, -1.8268], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7477, -1.3652, -0.6854, -1.8268], grad_fn=<ViewBackward0>),), Output: tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2906, -0.7773,  1.0645, -0.6009], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2906, -0.7773,  1.0645, -0.6009], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3413, -0.7778, -2.8196, -4.1028], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3413, -0.7778, -2.8196, -4.1028], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6515, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6515, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2947, -0.7823,  0.7483, -1.1168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2947, -0.7823,  0.7483, -1.1168], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2276,  0.8896, -0.5983, -2.0944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2276,  0.8896, -0.5983, -2.0944], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8419,  0.7112, -0.5359, -0.9701], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8419,  0.7112, -0.5359, -0.9701], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6875, -0.8929, -1.6583,  0.1749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6875, -0.8929, -1.6583,  0.1749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5964, -0.7128, -0.9300,  0.1731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5964, -0.7128, -0.9300,  0.1731], grad_fn=<TanhBackward0>),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7201,  0.7059, -1.7846, -0.8482], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7201,  0.7059, -1.7846, -0.8482], grad_fn=<ViewBackward0>),), Output: tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0129, -0.4814, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0129, -0.4814, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7670, -0.4474, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7670, -0.4474, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7488, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7488, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>),), Output: tensor([-0.6344, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6344, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2917, -0.7704,  1.0715, -0.5994], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2917, -0.7704,  1.0715, -0.5994], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3423, -0.8073, -2.8184, -4.1090], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3423, -0.8073, -2.8184, -4.1090], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6681, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6681, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2929, -0.7697,  0.7630, -1.1163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2929, -0.7697,  0.7630, -1.1163], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6467,  0.6428, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6467,  0.6428, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2282,  0.8909, -0.6008, -2.0975], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2282,  0.8909, -0.6008, -2.0975], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8421,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8421,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6841, -0.8934, -1.6710,  0.1725], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6841, -0.8934, -1.6710,  0.1725], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5942, -0.7131, -0.9317,  0.1708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5942, -0.7131, -0.9317,  0.1708], grad_fn=<TanhBackward0>),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>),), Output: tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1472, -1.0166, -0.5033, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1472, -1.0166, -0.5033, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7685, -0.4647, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7685, -0.4647, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7498, -1.3998, -0.6832, -1.8313], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7498, -1.3998, -0.6832, -1.8313], grad_fn=<ViewBackward0>),), Output: tensor([-0.6350, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6350, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2930, -0.7637,  1.0781, -0.5978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2930, -0.7637,  1.0781, -0.5978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3432, -0.8339, -2.8172, -4.1146], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3432, -0.8339, -2.8172, -4.1146], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6826, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6826, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2915, -0.7579,  0.7761, -1.1158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2915, -0.7579,  0.7761, -1.1158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8595, -0.6398,  0.6505, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8595, -0.6398,  0.6505, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2288,  0.8920, -0.6022, -2.1004], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2288,  0.8920, -0.6022, -2.1004], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8422,  0.7124, -0.5386, -0.9705], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8422,  0.7124, -0.5386, -0.9705], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6815, -0.8939, -1.6822,  0.1710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6815, -0.8939, -1.6822,  0.1710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7168,  0.7203, -1.7885, -0.8584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7168,  0.7203, -1.7885, -0.8584], grad_fn=<ViewBackward0>),), Output: tensor([-0.9375,  0.6171, -0.9456, -0.6954], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9375,  0.6171, -0.9456, -0.6954], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1474, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1474, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8169, -0.7698, -0.4806, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8169, -0.7698, -0.4806, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7507, -1.4147, -0.6820, -1.8334], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7507, -1.4147, -0.6820, -1.8334], grad_fn=<ViewBackward0>),), Output: tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2944, -0.7572,  1.0844, -0.5961], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2944, -0.7572,  1.0844, -0.5961], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8603, -0.6394,  0.7948, -0.5343], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8603, -0.6394,  0.7948, -0.5343], grad_fn=<TanhBackward0>),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3438, -0.8580, -2.8160, -4.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3438, -0.8580, -2.8160, -4.1199], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2292,  0.8927, -0.6027, -2.1031], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2292,  0.8927, -0.6027, -2.1031], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6799, -0.8944, -1.6919,  0.1703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6799, -0.8944, -1.6919,  0.1703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5914, -0.7136, -0.9344,  0.1687], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5914, -0.7136, -0.9344,  0.1687], grad_fn=<TanhBackward0>),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>),), Output: tensor([-0.9373,  0.6213, -0.9458, -0.6978], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9373,  0.6213, -0.9458, -0.6978], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1478, -1.0226, -0.5430, -1.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1478, -1.0226, -0.5430, -1.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7515, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7515, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>),), Output: tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2958, -0.7510,  1.0902, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2958, -0.7510,  1.0902, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8606, -0.6357,  0.7970, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8606, -0.6357,  0.7970, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3444, -0.8799, -2.8148, -4.1248], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3444, -0.8799, -2.8148, -4.1248], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7064, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7064, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2895, -0.7366,  0.7982, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2895, -0.7366,  0.7982, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2295,  0.8932, -0.6025, -2.1057], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2295,  0.8932, -0.6025, -2.1057], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8424,  0.7130, -0.5388, -0.9708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8424,  0.7130, -0.5388, -0.9708], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8949, -1.7004,  0.1703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8949, -1.7004,  0.1703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7138, -0.9355,  0.1686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7138, -0.9355,  0.1686], grad_fn=<TanhBackward0>),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7139,  0.7335, -1.7914, -0.8672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7139,  0.7335, -1.7914, -0.8672], grad_fn=<ViewBackward0>),), Output: tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1482, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1482, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7522, -1.4408, -0.6796, -1.8370], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7522, -1.4408, -0.6796, -1.8370], grad_fn=<ViewBackward0>),), Output: tensor([-0.6365, -0.8939, -0.5913, -0.9505], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6365, -0.8939, -0.5913, -0.9505], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2972, -0.7450,  1.0957, -0.5928], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2972, -0.7450,  1.0957, -0.5928], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3448, -0.9000, -2.8137, -4.1294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3448, -0.9000, -2.8137, -4.1294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7163, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7163, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2889, -0.7269,  0.8075, -1.1139], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2889, -0.7269,  0.8075, -1.1139], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2298,  0.8934, -0.6017, -2.1080], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2298,  0.8934, -0.6017, -2.1080], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8425,  0.7131, -0.5382, -0.9709], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8425,  0.7131, -0.5382, -0.9709], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6786, -0.8955, -1.7078,  0.1709], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6786, -0.8955, -1.7078,  0.1709], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5906, -0.7141, -0.9364,  0.1692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5906, -0.7141, -0.9364,  0.1692], grad_fn=<TanhBackward0>),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7125,  0.7396, -1.7926, -0.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7125,  0.7396, -1.7926, -0.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1487, -1.0271, -0.5780, -1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1487, -1.0271, -0.5780, -1.0739], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2987, -0.7393,  1.1008, -0.5913], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2987, -0.7393,  1.1008, -0.5913], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8614, -0.6287,  0.8008, -0.5308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8614, -0.6287,  0.8008, -0.5308], grad_fn=<TanhBackward0>),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3450, -0.9183, -2.8126, -4.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3450, -0.9183, -2.8126, -4.1337], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2884, -0.7179,  0.8159, -1.1133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2884, -0.7179,  0.8159, -1.1133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8587, -0.6156,  0.6728, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8587, -0.6156,  0.6728, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2300,  0.8934, -0.6002, -2.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2300,  0.8934, -0.6002, -2.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7131, -0.5372, -0.9710], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7131, -0.5372, -0.9710], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8960, -1.7141,  0.1720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8960, -1.7141,  0.1720], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7143, -0.9372,  0.1703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7143, -0.9372,  0.1703], grad_fn=<TanhBackward0>),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>),), Output: tensor([-0.9368,  0.6324, -0.9461, -0.7038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9368,  0.6324, -0.9461, -0.7038], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1492, -1.0290, -0.5939, -1.0735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1492, -1.0290, -0.5939, -1.0735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.4628, -0.6774, -1.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.4628, -0.6774, -1.8402], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3000, -0.7339,  1.1055, -0.5897], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3000, -0.7339,  1.1055, -0.5897], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8617, -0.6254,  0.8025, -0.5297], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8617, -0.6254,  0.8025, -0.5297], grad_fn=<TanhBackward0>),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9353, -2.8117, -4.1378], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9353, -2.8117, -4.1378], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2880, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2880, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8586, -0.6104,  0.6770, -0.8050], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8586, -0.6104,  0.6770, -0.8050], grad_fn=<TanhBackward0>),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2302,  0.8931, -0.5983, -2.1123], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2302,  0.8931, -0.5983, -2.1123], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6797, -0.8965, -1.7195,  0.1735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6797, -0.8965, -1.7195,  0.1735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5913, -0.7146, -0.9378,  0.1718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5913, -0.7146, -0.9378,  0.1718], grad_fn=<TanhBackward0>),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7101,  0.7508, -1.7945, -0.8783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7101,  0.7508, -1.7945, -0.8783], grad_fn=<ViewBackward0>),), Output: tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7537, -1.4726, -0.6764, -1.8417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7537, -1.4726, -0.6764, -1.8417], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3014, -0.7287,  1.1099, -0.5883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3014, -0.7287,  1.1099, -0.5883], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9509, -2.8108, -4.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9509, -2.8108, -4.1416], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2878, -0.7016,  0.8304, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2878, -0.7016,  0.8304, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2303,  0.8926, -0.5959, -2.1143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2303,  0.8926, -0.5959, -2.1143], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7127, -0.5341, -0.9713], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7127, -0.5341, -0.9713], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6809, -0.8970, -1.7240,  0.1755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6809, -0.8970, -1.7240,  0.1755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5921, -0.7148, -0.9383,  0.1737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5921, -0.7148, -0.9383,  0.1737], grad_fn=<TanhBackward0>),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7090,  0.7559, -1.7953, -0.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7090,  0.7559, -1.7953, -0.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.9365,  0.6387, -0.9463, -0.7072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9365,  0.6387, -0.9463, -0.7072], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1504, -1.0320, -0.6229, -1.0727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1504, -1.0320, -0.6229, -1.0727], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8179, -0.7747, -0.5532, -0.7905], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8179, -0.7747, -0.5532, -0.7905], grad_fn=<TanhBackward0>),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.4817, -0.6754, -1.8431], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.4817, -0.6754, -1.8431], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3027, -0.7238,  1.1139, -0.5869], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3027, -0.7238,  1.1139, -0.5869], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3451, -0.9654, -2.8101, -4.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3451, -0.9654, -2.8101, -4.1451], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2876, -0.6942,  0.8367, -1.1116], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2876, -0.6942,  0.8367, -1.1116], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8919, -0.5932, -2.1161], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8919, -0.5932, -2.1161], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6824, -0.8975, -1.7277,  0.1778], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6824, -0.8975, -1.7277,  0.1778], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5931, -0.7151, -0.9388,  0.1759], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5931, -0.7151, -0.9388,  0.1759], grad_fn=<TanhBackward0>),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7079,  0.7607, -1.7960, -0.8845], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7079,  0.7607, -1.7960, -0.8845], grad_fn=<ViewBackward0>),), Output: tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1510, -1.0333, -0.6361, -1.0723], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1510, -1.0333, -0.6361, -1.0723], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7752, -0.5623, -0.7903], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7752, -0.5623, -0.7903], grad_fn=<TanhBackward0>),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.4901, -0.6745, -1.8444], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.4901, -0.6745, -1.8444], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3449, -0.9790, -2.8094, -4.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3449, -0.9790, -2.8094, -4.1485], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2874, -0.6873,  0.8424, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2874, -0.6873,  0.8424, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5962,  0.6871, -0.8045], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5962,  0.6871, -0.8045], grad_fn=<TanhBackward0>),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8909, -0.5901, -2.1178], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8909, -0.5901, -2.1178], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7119, -0.5300, -0.9715], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7119, -0.5300, -0.9715], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6843, -0.8980, -1.7307,  0.1804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6843, -0.8980, -1.7307,  0.1804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7069,  0.7652, -1.7966, -0.8873], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7069,  0.7652, -1.7966, -0.8873], grad_fn=<ViewBackward0>),), Output: tensor([-0.9363,  0.6442, -0.9465, -0.7101], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9363,  0.6442, -0.9465, -0.7101], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1517, -1.0344, -0.6486, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1517, -1.0344, -0.6486, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.4980, -0.6736, -1.8456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.4980, -0.6736, -1.8456], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3050, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3050, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3446, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3446, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7581, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7581, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2873, -0.6808,  0.8476, -1.1107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2873, -0.6808,  0.8476, -1.1107], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5920,  0.6898, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5920,  0.6898, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8898, -0.5868, -2.1195], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8898, -0.5868, -2.1195], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6864, -0.8985, -1.7331,  0.1832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6864, -0.8985, -1.7331,  0.1832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5957, -0.7156, -0.9394,  0.1812], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5957, -0.7156, -0.9394,  0.1812], grad_fn=<TanhBackward0>),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7059,  0.7695, -1.7971, -0.8900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7059,  0.7695, -1.7971, -0.8900], grad_fn=<ViewBackward0>),), Output: tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1524, -1.0354, -0.6603, -1.0715], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1524, -1.0354, -0.6603, -1.0715], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8185, -0.7761, -0.5786, -0.7900], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8185, -0.7761, -0.5786, -0.7900], grad_fn=<TanhBackward0>),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3061, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3061, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.6110,  0.8090, -0.5250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.6110,  0.8090, -0.5250], grad_fn=<TanhBackward0>),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3443, -1.0035, -2.8085, -4.1547], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3443, -1.0035, -2.8085, -4.1547], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7631, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7631, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6747,  0.8524, -1.1103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6747,  0.8524, -1.1103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8886, -0.5833, -2.1210], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8886, -0.5833, -2.1210], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7107, -0.5250, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7107, -0.5250, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6888, -0.8991, -1.7348,  0.1863], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6888, -0.8991, -1.7348,  0.1863], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5972, -0.7158, -0.9396,  0.1842], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5972, -0.7158, -0.9396,  0.1842], grad_fn=<TanhBackward0>),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>),), Output: tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1530, -1.0363, -0.6713, -1.0712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1530, -1.0363, -0.6713, -1.0712], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5124, -0.6721, -1.8479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5124, -0.6721, -1.8479], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9074, -0.5864, -0.9516], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9074, -0.5864, -0.9516], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3071, -0.7066,  1.1270, -0.5822], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3071, -0.7066,  1.1270, -0.5822], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6690,  0.8568, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6690,  0.8568, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5843,  0.6946, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5843,  0.6946, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8871, -0.5795, -2.1225], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8871, -0.5795, -2.1225], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7100, -0.5223, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7100, -0.5223, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6914, -0.8996, -1.7361,  0.1896], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6914, -0.8996, -1.7361,  0.1896], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7041,  0.7772, -1.7979, -0.8948], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7041,  0.7772, -1.7979, -0.8948], grad_fn=<ViewBackward0>),), Output: tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1537, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1537, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8190, -0.7767, -0.5926, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8190, -0.7767, -0.5926, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.7029,  1.1296, -0.5812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.7029,  1.1296, -0.5812], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3434, -1.0253, -2.8079, -4.1603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3434, -1.0253, -2.8079, -4.1603], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6636,  0.8609, -1.1096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6636,  0.8609, -1.1096], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8856, -0.5756, -2.1239], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8856, -0.5756, -2.1239], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7092, -0.5195, -0.9718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7092, -0.5195, -0.9718], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6942, -0.9001, -1.7368,  0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6942, -0.9001, -1.7368,  0.1930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6007, -0.7163, -0.9399,  0.1906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6007, -0.7163, -0.9399,  0.1906], grad_fn=<TanhBackward0>),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7032,  0.7806, -1.7983, -0.8970], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7032,  0.7806, -1.7983, -0.8970], grad_fn=<ViewBackward0>),), Output: tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1544, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1544, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8192, -0.7770, -0.5990, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8192, -0.7770, -0.5990, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.5252, -0.6708, -1.8500], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.5252, -0.6708, -1.8500], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9096, -0.5855, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9096, -0.5855, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3428, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3428, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6586,  0.8648, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6586,  0.8648, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5774,  0.6987, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5774,  0.6987, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8839, -0.5716, -2.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8839, -0.5716, -2.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7084, -0.5165, -0.9719], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7084, -0.5165, -0.9719], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6971, -0.9006, -1.7371,  0.1966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6971, -0.9006, -1.7371,  0.1966], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6025, -0.7166, -0.9399,  0.1941], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6025, -0.7166, -0.9399,  0.1941], grad_fn=<TanhBackward0>),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7024,  0.7839, -1.7985, -0.8991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7024,  0.7839, -1.7985, -0.8991], grad_fn=<ViewBackward0>),), Output: tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1551, -1.0384, -0.7008, -1.0700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1551, -1.0384, -0.7008, -1.0700], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8194, -0.7773, -0.6049, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8194, -0.7773, -0.6049, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7543, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7543, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3098, -0.6960,  1.1341, -0.5794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3098, -0.6960,  1.1341, -0.5794], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.6018,  0.8124, -0.5223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.6018,  0.8124, -0.5223], grad_fn=<TanhBackward0>),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3422, -1.0448, -2.8077, -4.1653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3422, -1.0448, -2.8077, -4.1653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8821, -0.5675, -2.1265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8821, -0.5675, -2.1265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7075, -0.5135, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7075, -0.5135, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7001, -0.9012, -1.7370,  0.2003], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7001, -0.9012, -1.7370,  0.2003], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6044, -0.7169, -0.9399,  0.1976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6044, -0.7169, -0.9399,  0.1976], grad_fn=<TanhBackward0>),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7016,  0.7869, -1.7988, -0.9011], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7016,  0.7869, -1.7988, -0.9011], grad_fn=<ViewBackward0>),), Output: tensor([-0.9356,  0.6567, -0.9467, -0.7168], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9356,  0.6567, -0.9467, -0.7168], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8197, -0.7775, -0.6104, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8197, -0.7775, -0.6104, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>),), Output: tensor([-0.6376, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6376, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3105, -0.6929,  1.1361, -0.5787], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3105, -0.6929,  1.1361, -0.5787], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5998,  0.8131, -0.5217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5998,  0.8131, -0.5217], grad_fn=<TanhBackward0>),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3416, -1.0539, -2.8077, -4.1677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3416, -1.0539, -2.8077, -4.1677], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8802, -0.5632, -2.1277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8802, -0.5632, -2.1277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7065, -0.5104, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7065, -0.5104, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7032, -0.9017, -1.7366,  0.2040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7032, -0.9017, -1.7366,  0.2040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7009,  0.7898, -1.7990, -0.9030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7009,  0.7898, -1.7990, -0.9030], grad_fn=<ViewBackward0>),), Output: tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.5421, -0.6694, -1.8529], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.5421, -0.6694, -1.8529], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3112, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3112, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3409, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3409, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7867, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7867, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6452,  0.8748, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6452,  0.8748, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8782, -0.5589, -2.1288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8782, -0.5589, -2.1288], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7055, -0.5072, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7055, -0.5072, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7064, -0.9022, -1.7358,  0.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7064, -0.9022, -1.7358,  0.2079], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7001,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7001,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1572, -1.0399, -0.7255, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1572, -1.0399, -0.7255, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7538, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7538, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>),), Output: tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6870,  1.1396, -0.5774], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6870,  1.1396, -0.5774], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5960,  0.8143, -0.5208], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5960,  0.8143, -0.5208], grad_fn=<TanhBackward0>),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3402, -1.0709, -2.8081, -4.1721], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3402, -1.0709, -2.8081, -4.1721], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8761, -0.5546, -2.1299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8761, -0.5546, -2.1299], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7045, -0.5040, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7045, -0.5040, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7096, -0.9028, -1.7348,  0.2118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7096, -0.9028, -1.7348,  0.2118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6105, -0.7177, -0.9396,  0.2087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6105, -0.7177, -0.9396,  0.2087], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6994,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6994,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6612, -0.9467, -0.7194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6612, -0.9467, -0.7194], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1578, -1.0403, -0.7329, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1578, -1.0403, -0.7329, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3395, -1.0789, -2.8083, -4.1742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3395, -1.0789, -2.8083, -4.1742], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6374,  0.8805, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6374,  0.8805, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5631,  0.7067, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5631,  0.7067, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8740, -0.5502, -2.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8740, -0.5502, -2.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7034, -0.5007, -0.9722], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7034, -0.5007, -0.9722], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7129, -0.9033, -1.7334,  0.2157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7129, -0.9033, -1.7334,  0.2157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6125, -0.7179, -0.9395,  0.2125], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6125, -0.7179, -0.9395,  0.2125], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6625, -0.9467, -0.7202], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6625, -0.9467, -0.7202], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1585, -1.0407, -0.7398, -1.0684], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1585, -1.0407, -0.7398, -1.0684], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8205, -0.7781, -0.6291, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8205, -0.7781, -0.6291, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.5568, -0.6685, -1.8554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.5568, -0.6685, -1.8554], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.9149, -0.5840, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.9149, -0.5840, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3130, -0.6817,  1.1426, -0.5763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3130, -0.6817,  1.1426, -0.5763], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3387, -1.0866, -2.8087, -4.1762], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3387, -1.0866, -2.8087, -4.1762], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7957, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7957, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6338,  0.8832, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6338,  0.8832, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8718, -0.5459, -2.1320], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8718, -0.5459, -2.1320], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7023, -0.4974, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7023, -0.4974, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7162, -0.9039, -1.7319,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7162, -0.9039, -1.7319,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6981,  0.7994, -1.7996, -0.9096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6981,  0.7994, -1.7996, -0.9096], grad_fn=<ViewBackward0>),), Output: tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1591, -1.0410, -0.7464, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1591, -1.0410, -0.7464, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7530, -1.5613, -0.6683, -1.8561], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7530, -1.5613, -0.6683, -1.8561], grad_fn=<ViewBackward0>),), Output: tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3135, -0.6792,  1.1439, -0.5759], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3135, -0.6792,  1.1439, -0.5759], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3380, -1.0941, -2.8091, -4.1781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3380, -1.0941, -2.8091, -4.1781], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6304,  0.8858, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6304,  0.8858, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8695, -0.5415, -2.1330], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8695, -0.5415, -2.1330], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7195, -0.9045, -1.7301,  0.2237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7195, -0.9045, -1.7301,  0.2237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>),), Output: tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1597, -1.0412, -0.7527, -1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1597, -1.0412, -0.7527, -1.0679], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7527, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7527, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5895,  0.8161, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5895,  0.8161, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6272,  0.8882, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6272,  0.8882, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5561,  0.7105, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5561,  0.7105, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8673, -0.5371, -2.1339], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8673, -0.5371, -2.1339], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7000, -0.4908, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7000, -0.4908, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7228, -0.9050, -1.7282,  0.2277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7228, -0.9050, -1.7282,  0.2277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6969,  0.8033, -1.7997, -0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6969,  0.8033, -1.7997, -0.9125], grad_fn=<ViewBackward0>),), Output: tensor([-0.9350,  0.6659, -0.9468, -0.7223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9350,  0.6659, -0.9468, -0.7223], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1604, -1.0415, -0.7586, -1.0676], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1604, -1.0415, -0.7586, -1.0676], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7524, -1.5698, -0.6680, -1.8576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7524, -1.5698, -0.6680, -1.8576], grad_fn=<ViewBackward0>),), Output: tensor([-0.6366, -0.9170, -0.5837, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6366, -0.9170, -0.5837, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3143, -0.6746,  1.1462, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3143, -0.6746,  1.1462, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3364, -1.1083, -2.8102, -4.1817], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3364, -1.1083, -2.8102, -4.1817], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8035, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8035, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8649, -0.5328, -2.1348], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8649, -0.5328, -2.1348], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6988, -0.4875, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6988, -0.4875, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7261, -0.9056, -1.7261,  0.2317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7261, -0.9056, -1.7261,  0.2317], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6207, -0.7190, -0.9386,  0.2276], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6207, -0.7190, -0.9386,  0.2276], grad_fn=<TanhBackward0>),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6963,  0.8050, -1.7998, -0.9138], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6963,  0.8050, -1.7998, -0.9138], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1610, -1.0417, -0.7642, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1610, -1.0417, -0.7642, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7521, -1.5739, -0.6679, -1.8583], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7521, -1.5739, -0.6679, -1.8583], grad_fn=<ViewBackward0>),), Output: tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6724,  1.1472, -0.5750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6724,  1.1472, -0.5750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5866,  0.8168, -0.5190], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5866,  0.8168, -0.5190], grad_fn=<TanhBackward0>),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3355, -1.1151, -2.8108, -4.1835], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3355, -1.1151, -2.8108, -4.1835], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6212,  0.8928, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6212,  0.8928, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2309,  0.8626, -0.5285, -2.1357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2309,  0.8626, -0.5285, -2.1357], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6976, -0.4842, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6976, -0.4842, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7294, -0.9062, -1.7239,  0.2356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7294, -0.9062, -1.7239,  0.2356], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6227, -0.7193, -0.9383,  0.2314], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6227, -0.7193, -0.9383,  0.2314], grad_fn=<TanhBackward0>),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6957,  0.8066, -1.7999, -0.9151], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6957,  0.8066, -1.7999, -0.9151], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1615, -1.0419, -0.7695, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1615, -1.0419, -0.7695, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8215, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8215, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7517, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7517, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>),), Output: tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3149, -0.6704,  1.1481, -0.5748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3149, -0.6704,  1.1481, -0.5748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5852,  0.8171, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5852,  0.8171, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3347, -1.1216, -2.8115, -4.1851], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3347, -1.1216, -2.8115, -4.1851], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6184,  0.8950, -1.1088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6184,  0.8950, -1.1088], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5500,  0.7139, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5500,  0.7139, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8602, -0.5242, -2.1365], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8602, -0.5242, -2.1365], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6964, -0.4809, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6964, -0.4809, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7326, -0.9068, -1.7216,  0.2396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7326, -0.9068, -1.7216,  0.2396], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6247, -0.7196, -0.9381,  0.2351], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6247, -0.7196, -0.9381,  0.2351], grad_fn=<TanhBackward0>),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6952,  0.8082, -1.7999, -0.9163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6952,  0.8082, -1.7999, -0.9163], grad_fn=<ViewBackward0>),), Output: tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1621, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1621, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>),), Output: tensor([-0.6360, -0.9189, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6360, -0.9189, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3339, -1.1281, -2.8123, -4.1867], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3339, -1.1281, -2.8123, -4.1867], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8104, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8104, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8578, -0.5200, -2.1373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8578, -0.5200, -2.1373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7358, -0.9073, -1.7191,  0.2435], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7358, -0.9073, -1.7191,  0.2435], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6266, -0.7198, -0.9378,  0.2388], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6266, -0.7198, -0.9378,  0.2388], grad_fn=<TanhBackward0>),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6946,  0.8096, -1.8000, -0.9175], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6946,  0.8096, -1.8000, -0.9175], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6694, -0.9468, -0.7247], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6694, -0.9468, -0.7247], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1627, -1.0421, -0.7793, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1627, -1.0421, -0.7793, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8219, -0.7787, -0.6523, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8219, -0.7787, -0.6523, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7510, -1.5854, -0.6680, -1.8603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7510, -1.5854, -0.6680, -1.8603], grad_fn=<ViewBackward0>),), Output: tensor([-0.6357, -0.9194, -0.5837, -0.9527], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6357, -0.9194, -0.5837, -0.9527], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6664,  1.1498, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6664,  1.1498, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5826,  0.8177, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5826,  0.8177, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3330, -1.1343, -2.8131, -4.1883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3330, -1.1343, -2.8131, -4.1883], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6132,  0.8992, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6132,  0.8992, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2311,  0.8554, -0.5158, -2.1381], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2311,  0.8554, -0.5158, -2.1381], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6939, -0.4745, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6939, -0.4745, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7390, -0.9079, -1.7166,  0.2473], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7390, -0.9079, -1.7166,  0.2473], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6285, -0.7201, -0.9375,  0.2424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6285, -0.7201, -0.9375,  0.2424], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6941,  0.8109, -1.8001, -0.9186], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6941,  0.8109, -1.8001, -0.9186], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1632, -1.0422, -0.7838, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1632, -1.0422, -0.7838, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7506, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7506, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>),), Output: tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6108,  0.9013, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6108,  0.9013, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2312,  0.8530, -0.5117, -2.1388], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2312,  0.8530, -0.5117, -2.1388], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7421, -0.9085, -1.7140,  0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7421, -0.9085, -1.7140,  0.2512], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6304, -0.7204, -0.9371,  0.2460], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6304, -0.7204, -0.9371,  0.2460], grad_fn=<TanhBackward0>),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6936,  0.8121, -1.8001, -0.9197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6936,  0.8121, -1.8001, -0.9197], grad_fn=<ViewBackward0>),), Output: tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1637, -1.0423, -0.7881, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1637, -1.0423, -0.7881, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8222, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8222, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7502, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7502, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>),), Output: tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6628,  1.1512, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6628,  1.1512, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5802,  0.8182, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5802,  0.8182, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3313, -1.1464, -2.8148, -4.1912], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3313, -1.1464, -2.8148, -4.1912], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8166, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8166, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6084,  0.9032, -1.1095], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6084,  0.9032, -1.1095], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5430,  0.7179, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5430,  0.7179, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2313,  0.8506, -0.5077, -2.1395], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2313,  0.8506, -0.5077, -2.1395], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6914, -0.4681, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6914, -0.4681, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7452, -0.9090, -1.7113,  0.2549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7452, -0.9090, -1.7113,  0.2549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6323, -0.7207, -0.9368,  0.2495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6323, -0.7207, -0.9368,  0.2495], grad_fn=<TanhBackward0>),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1642, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1642, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7498, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7498, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>),), Output: tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3305, -1.1522, -2.8158, -4.1926], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3305, -1.1522, -2.8158, -4.1926], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5414,  0.7188, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5414,  0.7188, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8482, -0.5037, -2.1402], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8482, -0.5037, -2.1402], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6901, -0.4650, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6901, -0.4650, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7482, -0.9096, -1.7086,  0.2586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7482, -0.9096, -1.7086,  0.2586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6341, -0.7209, -0.9365,  0.2530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6341, -0.7209, -0.9365,  0.2530], grad_fn=<TanhBackward0>),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6926,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6926,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6719, -0.9468, -0.7267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6719, -0.9468, -0.7267], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1647, -1.0424, -0.7960, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1647, -1.0424, -0.7960, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7494, -1.5993, -0.6686, -1.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7494, -1.5993, -0.6686, -1.8627], grad_fn=<ViewBackward0>),), Output: tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6594,  1.1525, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6594,  1.1525, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5780,  0.8186, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5780,  0.8186, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3296, -1.1579, -2.8168, -4.1940], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3296, -1.1579, -2.8168, -4.1940], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6040,  0.9071, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6040,  0.9071, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8458, -0.4998, -2.1409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8458, -0.4998, -2.1409], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6889, -0.4620, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6889, -0.4620, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7512, -0.9101, -1.7059,  0.2623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7512, -0.9101, -1.7059,  0.2623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6922,  0.8153, -1.8003, -0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6922,  0.8153, -1.8003, -0.9227], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7789, -0.6639, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7789, -0.6639, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7490, -1.6025, -0.6689, -1.8633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7490, -1.6025, -0.6689, -1.8633], grad_fn=<ViewBackward0>),), Output: tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6577,  1.1531, -0.5749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6577,  1.1531, -0.5749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5769,  0.8188, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5769,  0.8188, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -1.1636, -2.8178, -4.1953], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -1.1636, -2.8178, -4.1953], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.6019,  0.9090, -1.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.6019,  0.9090, -1.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2316,  0.8434, -0.4960, -2.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2316,  0.8434, -0.4960, -2.1416], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6876, -0.4590, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6876, -0.4590, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7541, -0.9106, -1.7031,  0.2659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7541, -0.9106, -1.7031,  0.2659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6376, -0.7214, -0.9358,  0.2598], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6376, -0.7214, -0.9358,  0.2598], grad_fn=<TanhBackward0>),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6917,  0.8162, -1.8003, -0.9237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6917,  0.8162, -1.8003, -0.9237], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6730, -0.9468, -0.7276], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6730, -0.9468, -0.7276], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1656, -1.0425, -0.8032, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1656, -1.0425, -0.8032, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7486, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7486, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279, -1.1690, -2.8189, -4.1966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279, -1.1690, -2.8189, -4.1966], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2317,  0.8411, -0.4922, -2.1422], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2317,  0.8411, -0.4922, -2.1422], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6864, -0.4560, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6864, -0.4560, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7569, -0.9112, -1.7003,  0.2694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7569, -0.9112, -1.7003,  0.2694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6393, -0.7217, -0.9354,  0.2631], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6393, -0.7217, -0.9354,  0.2631], grad_fn=<TanhBackward0>),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1661, -1.0425, -0.8065, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1661, -1.0425, -0.8065, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7482, -1.6088, -0.6695, -1.8644], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7482, -1.6088, -0.6695, -1.8644], grad_fn=<ViewBackward0>),), Output: tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6546,  1.1541, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6546,  1.1541, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3271, -1.1744, -2.8201, -4.1979], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3271, -1.1744, -2.8201, -4.1979], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5980,  0.9127, -1.1108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5980,  0.9127, -1.1108], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2318,  0.8387, -0.4886, -2.1428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2318,  0.8387, -0.4886, -2.1428], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6851, -0.4531, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6851, -0.4531, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7597, -0.9117, -1.6975,  0.2728], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7597, -0.9117, -1.6975,  0.2728], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6409, -0.7219, -0.9351,  0.2663], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6409, -0.7219, -0.9351,  0.2663], grad_fn=<TanhBackward0>),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6908,  0.8178, -1.8005, -0.9254], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6908,  0.8178, -1.8005, -0.9254], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6739, -0.9469, -0.7285], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6739, -0.9469, -0.7285], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1665, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1665, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8231, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8231, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7478, -1.6118, -0.6698, -1.8649], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7478, -1.6118, -0.6698, -1.8649], grad_fn=<ViewBackward0>),), Output: tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6531,  1.1545, -0.5755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6531,  1.1545, -0.5755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3262, -1.1797, -2.8212, -4.1991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3262, -1.1797, -2.8212, -4.1991], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5961,  0.9145, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5961,  0.9145, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5342,  0.7233, -0.8044], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5342,  0.7233, -0.8044], grad_fn=<TanhBackward0>),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2319,  0.8363, -0.4850, -2.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2319,  0.8363, -0.4850, -2.1434], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6839, -0.4502, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6839, -0.4502, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7624, -0.9122, -1.6946,  0.2762], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7624, -0.9122, -1.6946,  0.2762], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6425, -0.7222, -0.9347,  0.2694], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6425, -0.7222, -0.9347,  0.2694], grad_fn=<TanhBackward0>),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6904,  0.8185, -1.8005, -0.9263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6904,  0.8185, -1.8005, -0.9263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1669, -1.0424, -0.8126, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1669, -1.0424, -0.8126, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8233, -0.7788, -0.6710, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8233, -0.7788, -0.6710, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7474, -1.6148, -0.6702, -1.8654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7474, -1.6148, -0.6702, -1.8654], grad_fn=<ViewBackward0>),), Output: tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6516,  1.1550, -0.5758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6516,  1.1550, -0.5758], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3254, -1.1849, -2.8224, -4.2003], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3254, -1.1849, -2.8224, -4.2003], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2866, -0.5942,  0.9162, -1.1114], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2866, -0.5942,  0.9162, -1.1114], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5329,  0.7241, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5329,  0.7241, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2320,  0.8340, -0.4815, -2.1440], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2320,  0.8340, -0.4815, -2.1440], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6826, -0.4474, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6826, -0.4474, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7651, -0.9127, -1.6918,  0.2795], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7651, -0.9127, -1.6918,  0.2795], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6441, -0.7224, -0.9344,  0.2725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6441, -0.7224, -0.9344,  0.2725], grad_fn=<TanhBackward0>),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6746, -0.9469, -0.7292], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6746, -0.9469, -0.7292], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1673, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1673, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7470, -1.6177, -0.6706, -1.8659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7470, -1.6177, -0.6706, -1.8659], grad_fn=<ViewBackward0>),), Output: tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3245, -1.1900, -2.8237, -4.2015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3245, -1.1900, -2.8237, -4.2015], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5317,  0.7250, -0.8047], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5317,  0.7250, -0.8047], grad_fn=<TanhBackward0>),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2321,  0.8317, -0.4781, -2.1445], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2321,  0.8317, -0.4781, -2.1445], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6814, -0.4447, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6814, -0.4447, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7677, -0.9132, -1.6890,  0.2828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7677, -0.9132, -1.6890,  0.2828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6456, -0.7227, -0.9340,  0.2755], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6456, -0.7227, -0.9340,  0.2755], grad_fn=<TanhBackward0>),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8235, -0.7788, -0.6741, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8235, -0.7788, -0.6741, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>),), Output: tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5708,  0.8197, -0.5201], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5708,  0.8197, -0.5201], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3237, -1.1951, -2.8249, -4.2026], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3237, -1.1951, -2.8249, -4.2026], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5304,  0.7258, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5304,  0.7258, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2323,  0.8294, -0.4747, -2.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2323,  0.8294, -0.4747, -2.1451], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6802, -0.4420, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6802, -0.4420, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7702, -0.9137, -1.6862,  0.2859], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7702, -0.9137, -1.6862,  0.2859], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6470, -0.7229, -0.9337,  0.2784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6470, -0.7229, -0.9337,  0.2784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6892,  0.8203, -1.8008, -0.9286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6892,  0.8203, -1.8008, -0.9286], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1681, -1.0422, -0.8207, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1681, -1.0422, -0.8207, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8237, -0.7788, -0.6755, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8237, -0.7788, -0.6755, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>),), Output: tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3229, -1.2000, -2.8262, -4.2037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3229, -1.2000, -2.8262, -4.2037], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5292,  0.7266, -0.8049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5292,  0.7266, -0.8049], grad_fn=<TanhBackward0>),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2324,  0.8272, -0.4715, -2.1456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2324,  0.8272, -0.4715, -2.1456], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7726, -0.9141, -1.6834,  0.2890], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7726, -0.9141, -1.6834,  0.2890], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6485, -0.7231, -0.9333,  0.2812], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6485, -0.7231, -0.9333,  0.2812], grad_fn=<TanhBackward0>),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6888,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6888,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1684, -1.0421, -0.8231, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1684, -1.0421, -0.8231, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7458, -1.6261, -0.6719, -1.8674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7458, -1.6261, -0.6719, -1.8674], grad_fn=<ViewBackward0>),), Output: tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.6460,  1.1565, -0.5772], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.6460,  1.1565, -0.5772], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5690,  0.8199, -0.5206], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5690,  0.8199, -0.5206], grad_fn=<TanhBackward0>),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3221, -1.2049, -2.8276, -4.2048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3221, -1.2049, -2.8276, -4.2048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2325,  0.8249, -0.4683, -2.1461], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2325,  0.8249, -0.4683, -2.1461], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6777, -0.4368, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6777, -0.4368, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7750, -0.9146, -1.6807,  0.2920], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7750, -0.9146, -1.6807,  0.2920], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6498, -0.7233, -0.9329,  0.2840], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6498, -0.7233, -0.9329,  0.2840], grad_fn=<TanhBackward0>),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6885,  0.8213, -1.8010, -0.9301], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6885,  0.8213, -1.8010, -0.9301], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6758, -0.9469, -0.7306], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6758, -0.9469, -0.7306], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1688, -1.0420, -0.8255, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1688, -1.0420, -0.8255, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7454, -1.6288, -0.6724, -1.8678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7454, -1.6288, -0.6724, -1.8678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6324, -0.9259, -0.5866, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6324, -0.9259, -0.5866, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6447,  1.1568, -0.5776], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6447,  1.1568, -0.5776], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3212, -1.2097, -2.8289, -4.2058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3212, -1.2097, -2.8289, -4.2058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5859,  0.9249, -1.1132], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5859,  0.9249, -1.1132], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5269,  0.7282, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5269,  0.7282, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2327,  0.8227, -0.4652, -2.1466], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2327,  0.8227, -0.4652, -2.1466], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6765, -0.4343, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6765, -0.4343, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7773, -0.9150, -1.6779,  0.2949], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7773, -0.9150, -1.6779,  0.2949], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6512, -0.7235, -0.9326,  0.2867], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6512, -0.7235, -0.9326,  0.2867], grad_fn=<TanhBackward0>),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6881,  0.8217, -1.8011, -0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6881,  0.8217, -1.8011, -0.9308], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1691, -1.0419, -0.8277, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1691, -1.0419, -0.8277, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7449, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7449, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>),), Output: tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6434,  1.1572, -0.5781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6434,  1.1572, -0.5781], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3204, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3204, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2862, -0.5844,  0.9266, -1.1136], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2862, -0.5844,  0.9266, -1.1136], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5258,  0.7290, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5258,  0.7290, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2328,  0.8205, -0.4622, -2.1471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2328,  0.8205, -0.4622, -2.1471], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7796, -0.9154, -1.6752,  0.2978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7796, -0.9154, -1.6752,  0.2978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6525, -0.7237, -0.9322,  0.2893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6525, -0.7237, -0.9322,  0.2893], grad_fn=<TanhBackward0>),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6877,  0.8221, -1.8012, -0.9314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6877,  0.8221, -1.8012, -0.9314], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1694, -1.0418, -0.8297, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1694, -1.0418, -0.8297, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7445, -1.6341, -0.6735, -1.8687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7445, -1.6341, -0.6735, -1.8687], grad_fn=<ViewBackward0>),), Output: tensor([-0.6319, -0.9266, -0.5873, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6319, -0.9266, -0.5873, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3150, -0.6421,  1.1575, -0.5786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3150, -0.6421,  1.1575, -0.5786], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5663,  0.8202, -0.5216], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5663,  0.8202, -0.5216], grad_fn=<TanhBackward0>),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3196, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3196, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5829,  0.9282, -1.1140], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5829,  0.9282, -1.1140], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5247,  0.7298, -0.8055], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5247,  0.7298, -0.8055], grad_fn=<TanhBackward0>),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2330,  0.8183, -0.4593, -2.1476], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2330,  0.8183, -0.4593, -2.1476], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6742, -0.4295, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6742, -0.4295, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7818, -0.9159, -1.6725,  0.3006], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7818, -0.9159, -1.6725,  0.3006], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6537, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6537, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1697, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1697, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7441, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7441, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>),), Output: tensor([-0.6316, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6316, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3148, -0.6409,  1.1577, -0.5791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3148, -0.6409,  1.1577, -0.5791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3188, -1.2236, -2.8331, -4.2088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3188, -1.2236, -2.8331, -4.2088], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2331,  0.8162, -0.4565, -2.1480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2331,  0.8162, -0.4565, -2.1480], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6730, -0.4272, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6730, -0.4272, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7839, -0.9163, -1.6699,  0.3033], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7839, -0.9163, -1.6699,  0.3033], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6550, -0.7241, -0.9315,  0.2943], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6550, -0.7241, -0.9315,  0.2943], grad_fn=<TanhBackward0>),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6870,  0.8227, -1.8014, -0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6870,  0.8227, -1.8014, -0.9327], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1700, -1.0416, -0.8336, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1700, -1.0416, -0.8336, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8243, -0.7785, -0.6824, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8243, -0.7785, -0.6824, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7437, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7437, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6396,  1.1580, -0.5796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6396,  1.1580, -0.5796], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5646,  0.8204, -0.5224], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5646,  0.8204, -0.5224], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3181, -1.2281, -2.8346, -4.2098], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3181, -1.2281, -2.8346, -4.2098], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5226,  0.7313, -0.8058], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5226,  0.7313, -0.8058], grad_fn=<TanhBackward0>),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2333,  0.8141, -0.4537, -2.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2333,  0.8141, -0.4537, -2.1485], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6718, -0.4249, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6718, -0.4249, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7860, -0.9166, -1.6673,  0.3059], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7860, -0.9166, -1.6673,  0.3059], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6561, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6561, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6867,  0.8230, -1.8016, -0.9333], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6867,  0.8230, -1.8016, -0.9333], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1703, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1703, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8244, -0.7784, -0.6834, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8244, -0.7784, -0.6834, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7433, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7433, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>),), Output: tensor([-0.6311, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6311, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3173, -1.2325, -2.8361, -4.2108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3173, -1.2325, -2.8361, -4.2108], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5216,  0.7321, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5216,  0.7321, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2334,  0.8120, -0.4510, -2.1489], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2334,  0.8120, -0.4510, -2.1489], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6707, -0.4227, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6707, -0.4227, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7880, -0.9170, -1.6647,  0.3085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7880, -0.9170, -1.6647,  0.3085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6573, -0.7245, -0.9308,  0.2991], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6573, -0.7245, -0.9308,  0.2991], grad_fn=<TanhBackward0>),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6864,  0.8232, -1.8017, -0.9339], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6864,  0.8232, -1.8017, -0.9339], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1706, -1.0413, -0.8371, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1706, -1.0413, -0.8371, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>),), Output: tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3141, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3141, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3165, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3165, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5772,  0.9348, -1.1157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5772,  0.9348, -1.1157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5206,  0.7328, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5206,  0.7328, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2336,  0.8100, -0.4484, -2.1494], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2336,  0.8100, -0.4484, -2.1494], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6696, -0.4206, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6696, -0.4206, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7900, -0.9174, -1.6622,  0.3110], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7900, -0.9174, -1.6622,  0.3110], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6861,  0.8235, -1.8018, -0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6861,  0.8235, -1.8018, -0.9345], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>),), Output: tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3157, -1.2412, -2.8391, -4.2126], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3157, -1.2412, -2.8391, -4.2126], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2337,  0.8080, -0.4459, -2.1498], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2337,  0.8080, -0.4459, -2.1498], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6685, -0.4185, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6685, -0.4185, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7919, -0.9177, -1.6597,  0.3134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7919, -0.9177, -1.6597,  0.3134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6857,  0.8237, -1.8020, -0.9351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6857,  0.8237, -1.8020, -0.9351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7330], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7330], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1711, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1711, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7782, -0.6860, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7782, -0.6860, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3136, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3136, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8652, -0.5613,  0.8207, -0.5240], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8652, -0.5613,  0.8207, -0.5240], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2339,  0.8060, -0.4434, -2.1502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2339,  0.8060, -0.4434, -2.1502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6674, -0.4165, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6674, -0.4165, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7937, -0.9180, -1.6572,  0.3158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7937, -0.9180, -1.6572,  0.3158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6605, -0.7250, -0.9298,  0.3057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6605, -0.7250, -0.9298,  0.3057], grad_fn=<TanhBackward0>),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6854,  0.8238, -1.8021, -0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6854,  0.8238, -1.8021, -0.9356], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1714, -1.0407, -0.8418, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1714, -1.0407, -0.8418, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7417, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7417, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>),), Output: tensor([-0.6302, -0.9290, -0.5901, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6302, -0.9290, -0.5901, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3134, -0.6336,  1.1592, -0.5825], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3134, -0.6336,  1.1592, -0.5825], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5605,  0.8208, -0.5245], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5605,  0.8208, -0.5245], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3142, -1.2497, -2.8421, -4.2143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3142, -1.2497, -2.8421, -4.2143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2341,  0.8040, -0.4410, -2.1506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2341,  0.8040, -0.4410, -2.1506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6663, -0.4145, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6663, -0.4145, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7955, -0.9183, -1.6548,  0.3180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7955, -0.9183, -1.6548,  0.3180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6851,  0.8240, -1.8023, -0.9362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6851,  0.8240, -1.8023, -0.9362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1716, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1716, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7413, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7413, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>),), Output: tensor([-0.6299, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6299, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5598,  0.8208, -0.5249], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5598,  0.8208, -0.5249], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3135, -1.2538, -2.8437, -4.2152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3135, -1.2538, -2.8437, -4.2152], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5721,  0.9411, -1.1175], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5721,  0.9411, -1.1175], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5169,  0.7358, -0.8067], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5169,  0.7358, -0.8067], grad_fn=<TanhBackward0>),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2342,  0.8021, -0.4387, -2.1510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2342,  0.8021, -0.4387, -2.1510], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6652, -0.4126, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6652, -0.4126, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7973, -0.9186, -1.6524,  0.3203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7973, -0.9186, -1.6524,  0.3203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6848,  0.8241, -1.8025, -0.9367], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6848,  0.8241, -1.8025, -0.9367], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1719, -1.0404, -0.8445, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1719, -1.0404, -0.8445, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8249, -0.7780, -0.6882, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8249, -0.7780, -0.6882, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7409, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7409, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3128, -0.6313,  1.1596, -0.5837], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3128, -0.6313,  1.1596, -0.5837], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3127, -1.2579, -2.8452, -4.2160], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3127, -1.2579, -2.8452, -4.2160], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2855, -0.5708,  0.9427, -1.1180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2855, -0.5708,  0.9427, -1.1180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2344,  0.8001, -0.4365, -2.1514], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2344,  0.8001, -0.4365, -2.1514], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6641, -0.4107, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6641, -0.4107, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7989, -0.9189, -1.6501,  0.3224], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7989, -0.9189, -1.6501,  0.3224], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6634, -0.7254, -0.9289,  0.3117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6634, -0.7254, -0.9289,  0.3117], grad_fn=<TanhBackward0>),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6845,  0.8242, -1.8026, -0.9372], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6845,  0.8242, -1.8026, -0.9372], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6773, -0.9471, -0.7339], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6773, -0.9471, -0.7339], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1721, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1721, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7405, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7405, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>),), Output: tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6302,  1.1598, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6302,  1.1598, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5582,  0.8210, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5582,  0.8210, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3120, -1.2619, -2.8468, -4.2168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3120, -1.2619, -2.8468, -4.2168], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2854, -0.5696,  0.9443, -1.1185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2854, -0.5696,  0.9443, -1.1185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2345,  0.7983, -0.4343, -2.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2345,  0.7983, -0.4343, -2.1517], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6631, -0.4089, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6631, -0.4089, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8006, -0.9192, -1.6478,  0.3245], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8006, -0.9192, -1.6478,  0.3245], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6644, -0.7255, -0.9285,  0.3136], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6644, -0.7255, -0.9285,  0.3136], grad_fn=<TanhBackward0>),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6843,  0.8243, -1.8028, -0.9377], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6843,  0.8243, -1.8028, -0.9377], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1723, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1723, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7401, -1.6598, -0.6805, -1.8731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7401, -1.6598, -0.6805, -1.8731], grad_fn=<ViewBackward0>),), Output: tensor([-0.6292, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6292, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3122, -0.6291,  1.1600, -0.5850], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3122, -0.6291,  1.1600, -0.5850], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5574,  0.8210, -0.5263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5574,  0.8210, -0.5263], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3113, -1.2659, -2.8484, -4.2176], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3113, -1.2659, -2.8484, -4.2176], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5142,  0.7379, -0.8072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5142,  0.7379, -0.8072], grad_fn=<TanhBackward0>),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2347,  0.7964, -0.4321, -2.1521], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2347,  0.7964, -0.4321, -2.1521], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6620, -0.4071, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6620, -0.4071, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8021, -0.9194, -1.6455,  0.3265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8021, -0.9194, -1.6455,  0.3265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6652, -0.7256, -0.9282,  0.3154], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6652, -0.7256, -0.9282,  0.3154], grad_fn=<TanhBackward0>),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1726, -1.0397, -0.8480, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1726, -1.0397, -0.8480, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7398, -1.6620, -0.6812, -1.8734], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7398, -1.6620, -0.6812, -1.8734], grad_fn=<ViewBackward0>),), Output: tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6280,  1.1601, -0.5857], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6280,  1.1601, -0.5857], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3105, -1.2698, -2.8500, -4.2184], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3105, -1.2698, -2.8500, -4.2184], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2349,  0.7946, -0.4301, -2.1525], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2349,  0.7946, -0.4301, -2.1525], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6610, -0.4054, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6610, -0.4054, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8037, -0.9197, -1.6433,  0.3285], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8037, -0.9197, -1.6433,  0.3285], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6661, -0.7257, -0.9279,  0.3172], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6661, -0.7257, -0.9279,  0.3172], grad_fn=<TanhBackward0>),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6837,  0.8244, -1.8032, -0.9387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6837,  0.8244, -1.8032, -0.9387], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1728, -1.0395, -0.8491, -1.0667], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1728, -1.0395, -0.8491, -1.0667], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7394, -1.6640, -0.6820, -1.8738], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7394, -1.6640, -0.6820, -1.8738], grad_fn=<ViewBackward0>),), Output: tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3116, -0.6269,  1.1603, -0.5864], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3116, -0.6269,  1.1603, -0.5864], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5559,  0.8211, -0.5273], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5559,  0.8211, -0.5273], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3098, -1.2736, -2.8516, -4.2192], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3098, -1.2736, -2.8516, -4.2192], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5125,  0.7392, -0.8075], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5125,  0.7392, -0.8075], grad_fn=<TanhBackward0>),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2350,  0.7928, -0.4281, -2.1528], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2350,  0.7928, -0.4281, -2.1528], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6600, -0.4037, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6600, -0.4037, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8052, -0.9199, -1.6411,  0.3304], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8052, -0.9199, -1.6411,  0.3304], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6669, -0.7259, -0.9276,  0.3189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6669, -0.7259, -0.9276,  0.3189], grad_fn=<TanhBackward0>),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6834,  0.8244, -1.8034, -0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6834,  0.8244, -1.8034, -0.9391], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1730, -1.0393, -0.8501, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1730, -1.0393, -0.8501, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7390, -1.6661, -0.6827, -1.8741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7390, -1.6661, -0.6827, -1.8741], grad_fn=<ViewBackward0>),), Output: tensor([-0.6285, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6285, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3112, -0.6258,  1.1605, -0.5871], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3112, -0.6258,  1.1605, -0.5871], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3091, -1.2774, -2.8532, -4.2199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3091, -1.2774, -2.8532, -4.2199], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5651,  0.9503, -1.1203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5651,  0.9503, -1.1203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5117,  0.7399, -0.8077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5117,  0.7399, -0.8077], grad_fn=<TanhBackward0>),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2352,  0.7910, -0.4262, -2.1532], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2352,  0.7910, -0.4262, -2.1532], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6590, -0.4021, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6590, -0.4021, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8066, -0.9201, -1.6390,  0.3323], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8066, -0.9201, -1.6390,  0.3323], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6677, -0.7260, -0.9273,  0.3206], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6677, -0.7260, -0.9273,  0.3206], grad_fn=<TanhBackward0>),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6832,  0.8244, -1.8035, -0.9396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6832,  0.8244, -1.8035, -0.9396], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6775, -0.9472, -0.7350], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6775, -0.9472, -0.7350], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7386, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7386, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>),), Output: tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8645, -0.5544,  0.8212, -0.5283], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8645, -0.5544,  0.8212, -0.5283], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3084, -1.2812, -2.8548, -4.2207], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3084, -1.2812, -2.8548, -4.2207], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2354,  0.7893, -0.4243, -2.1535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2354,  0.7893, -0.4243, -2.1535], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6580, -0.4005, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6580, -0.4005, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8080, -0.9203, -1.6369,  0.3341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8080, -0.9203, -1.6369,  0.3341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6685, -0.7261, -0.9270,  0.3222], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6685, -0.7261, -0.9270,  0.3222], grad_fn=<TanhBackward0>),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6829,  0.8244, -1.8037, -0.9400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6829,  0.8244, -1.8037, -0.9400], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6775, -0.9472, -0.7352], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6775, -0.9472, -0.7352], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1734, -1.0388, -0.8520, -1.0671], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1734, -1.0388, -0.8520, -1.0671], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3106, -0.6237,  1.1608, -0.5885], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3106, -0.6237,  1.1608, -0.5885], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5537,  0.8213, -0.5288], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5537,  0.8213, -0.5288], grad_fn=<TanhBackward0>),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3077, -1.2849, -2.8565, -4.2214], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3077, -1.2849, -2.8565, -4.2214], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5101,  0.7413, -0.8080], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5101,  0.7413, -0.8080], grad_fn=<TanhBackward0>),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2356,  0.7876, -0.4225, -2.1538], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2356,  0.7876, -0.4225, -2.1538], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6570, -0.3990, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6570, -0.3990, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8093, -0.9205, -1.6348,  0.3358], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8093, -0.9205, -1.6348,  0.3358], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6692, -0.7262, -0.9267,  0.3237], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6692, -0.7262, -0.9267,  0.3237], grad_fn=<TanhBackward0>),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6827,  0.8244, -1.8039, -0.9404], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6827,  0.8244, -1.8039, -0.9404], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1736, -1.0386, -0.8529, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1736, -1.0386, -0.8529, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8254, -0.7773, -0.6926, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8254, -0.7773, -0.6926, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>),), Output: tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3102, -0.6227,  1.1609, -0.5892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3102, -0.6227,  1.1609, -0.5892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8643, -0.5530,  0.8213, -0.5293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8643, -0.5530,  0.8213, -0.5293], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3070, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3070, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5618,  0.9547, -1.1218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5618,  0.9547, -1.1218], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5093,  0.7419, -0.8082], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5093,  0.7419, -0.8082], grad_fn=<TanhBackward0>),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2357,  0.7859, -0.4207, -2.1542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2357,  0.7859, -0.4207, -2.1542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6561, -0.3975, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6561, -0.3975, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8107, -0.9207, -1.6328,  0.3375], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8107, -0.9207, -1.6328,  0.3375], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6700, -0.7262, -0.9265,  0.3252], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6700, -0.7262, -0.9265,  0.3252], grad_fn=<TanhBackward0>),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6824,  0.8243, -1.8041, -0.9409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6824,  0.8243, -1.8041, -0.9409], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1737, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1737, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7772, -0.6930, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7772, -0.6930, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>),), Output: tensor([-0.6276, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6276, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3099, -0.6216,  1.1610, -0.5900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3099, -0.6216,  1.1610, -0.5900], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3063, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3063, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2359,  0.7842, -0.4190, -2.1545], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2359,  0.7842, -0.4190, -2.1545], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6551, -0.3961, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6551, -0.3961, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8119, -0.9209, -1.6308,  0.3391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8119, -0.9209, -1.6308,  0.3391], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6707, -0.7263, -0.9262,  0.3267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6707, -0.7263, -0.9262,  0.3267], grad_fn=<TanhBackward0>),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1739, -1.0381, -0.8545, -1.0675], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1739, -1.0381, -0.8545, -1.0675], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7771, -0.6934, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7771, -0.6934, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7371, -1.6759, -0.6866, -1.8758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7371, -1.6759, -0.6866, -1.8758], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3095, -0.6206,  1.1611, -0.5907], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3095, -0.6206,  1.1611, -0.5907], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2848, -0.5598,  0.9576, -1.1227], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2848, -0.5598,  0.9576, -1.1227], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2361,  0.7826, -0.4173, -2.1548], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2361,  0.7826, -0.4173, -2.1548], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6542, -0.3947, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6542, -0.3947, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8132, -0.9211, -1.6289,  0.3407], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8132, -0.9211, -1.6289,  0.3407], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6819,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6819,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7360], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7770, -0.6938, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7770, -0.6938, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>),), Output: tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3092, -0.6196,  1.1613, -0.5914], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3092, -0.6196,  1.1613, -0.5914], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8641, -0.5509,  0.8215, -0.5309], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8641, -0.5509,  0.8215, -0.5309], grad_fn=<TanhBackward0>),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3050, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3050, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2362,  0.7810, -0.4157, -2.1551], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2362,  0.7810, -0.4157, -2.1551], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6533, -0.3933, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6533, -0.3933, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8144, -0.9212, -1.6270,  0.3423], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8144, -0.9212, -1.6270,  0.3423], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6720, -0.7265, -0.9256,  0.3295], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6720, -0.7265, -0.9256,  0.3295], grad_fn=<TanhBackward0>),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6817,  0.8242, -1.8048, -0.9421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6817,  0.8242, -1.8048, -0.9421], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1743, -1.0376, -0.8559, -1.0678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1743, -1.0376, -0.8559, -1.0678], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7769, -0.6941, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7769, -0.6941, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7364, -1.6796, -0.6881, -1.8764], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7364, -1.6796, -0.6881, -1.8764], grad_fn=<ViewBackward0>),), Output: tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3088, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3088, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3043, -1.3027, -2.8647, -4.2249], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3043, -1.3027, -2.8647, -4.2249], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5063,  0.7445, -0.8089], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5063,  0.7445, -0.8089], grad_fn=<TanhBackward0>),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2364,  0.7794, -0.4142, -2.1554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2364,  0.7794, -0.4142, -2.1554], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6523, -0.3920, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6523, -0.3920, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8155, -0.9213, -1.6251,  0.3438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8155, -0.9213, -1.6251,  0.3438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6726, -0.7265, -0.9254,  0.3308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6726, -0.7265, -0.9254,  0.3308], grad_fn=<TanhBackward0>),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6814,  0.8241, -1.8050, -0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6814,  0.8241, -1.8050, -0.9424], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6773, -0.9473, -0.7363], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6773, -0.9473, -0.7363], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1744, -1.0374, -0.8566, -1.0680], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1744, -1.0374, -0.8566, -1.0680], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7768, -0.6945, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7768, -0.6945, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.6814, -0.6889, -1.8767], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.6814, -0.6889, -1.8767], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3037, -1.3062, -2.8663, -4.2256], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3037, -1.3062, -2.8663, -4.2256], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5568,  0.9618, -1.1242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5568,  0.9618, -1.1242], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2366,  0.7778, -0.4126, -2.1557], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2366,  0.7778, -0.4126, -2.1557], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6514, -0.3907, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6514, -0.3907, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8166, -0.9215, -1.6233,  0.3452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8166, -0.9215, -1.6233,  0.3452], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6812,  0.8240, -1.8052, -0.9428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6812,  0.8240, -1.8052, -0.9428], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1746, -1.0371, -0.8572, -1.0682], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1746, -1.0371, -0.8572, -1.0682], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7767, -0.6948, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7767, -0.6948, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7357, -1.6832, -0.6897, -1.8770], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7357, -1.6832, -0.6897, -1.8770], grad_fn=<ViewBackward0>),), Output: tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.6166,  1.1616, -0.5937], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.6166,  1.1616, -0.5937], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3030, -1.3096, -2.8680, -4.2263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3030, -1.3096, -2.8680, -4.2263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2367,  0.7763, -0.4112, -2.1560], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2367,  0.7763, -0.4112, -2.1560], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6506, -0.3895, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6506, -0.3895, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8177, -0.9216, -1.6215,  0.3466], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8177, -0.9216, -1.6215,  0.3466], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6738, -0.7267, -0.9248,  0.3334], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6738, -0.7267, -0.9248,  0.3334], grad_fn=<TanhBackward0>),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1747, -1.0368, -0.8578, -1.0683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1747, -1.0368, -0.8578, -1.0683], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7766, -0.6951, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7766, -0.6951, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7353, -1.6850, -0.6905, -1.8773], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7353, -1.6850, -0.6905, -1.8773], grad_fn=<ViewBackward0>),), Output: tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3077, -0.6156,  1.1617, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3077, -0.6156,  1.1617, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3024, -1.3129, -2.8696, -4.2269], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3024, -1.3129, -2.8696, -4.2269], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2369,  0.7747, -0.4098, -2.1563], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2369,  0.7747, -0.4098, -2.1563], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6497, -0.3883, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6497, -0.3883, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8188, -0.9217, -1.6197,  0.3480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8188, -0.9217, -1.6197,  0.3480], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6744, -0.7267, -0.9246,  0.3346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6744, -0.7267, -0.9246,  0.3346], grad_fn=<TanhBackward0>),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6808,  0.8238, -1.8057, -0.9435], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6808,  0.8238, -1.8057, -0.9435], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6771, -0.9474, -0.7368], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6771, -0.9474, -0.7368], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7350, -1.6867, -0.6913, -1.8776], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7350, -1.6867, -0.6913, -1.8776], grad_fn=<ViewBackward0>),), Output: tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3073, -0.6147,  1.1618, -0.5952], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3073, -0.6147,  1.1618, -0.5952], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3017, -1.3162, -2.8713, -4.2275], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3017, -1.3162, -2.8713, -4.2275], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2371,  0.7732, -0.4084, -2.1565], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2371,  0.7732, -0.4084, -2.1565], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6488, -0.3871, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6488, -0.3871, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8198, -0.9218, -1.6180,  0.3493], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8198, -0.9218, -1.6180,  0.3493], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6750, -0.7268, -0.9243,  0.3358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6750, -0.7268, -0.9243,  0.3358], grad_fn=<TanhBackward0>),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6805,  0.8237, -1.8059, -0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6805,  0.8237, -1.8059, -0.9439], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1750, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1750, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7764, -0.6957, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7764, -0.6957, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7346, -1.6884, -0.6922, -1.8779], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7346, -1.6884, -0.6922, -1.8779], grad_fn=<ViewBackward0>),), Output: tensor([-0.6259, -0.9339, -0.5994, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6259, -0.9339, -0.5994, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3070, -0.6137,  1.1618, -0.5960], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3070, -0.6137,  1.1618, -0.5960], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.5467,  0.8216, -0.5342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.5467,  0.8216, -0.5342], grad_fn=<TanhBackward0>),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5531,  0.9673, -1.1261], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5531,  0.9673, -1.1261], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2372,  0.7718, -0.4070, -2.1568], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2372,  0.7718, -0.4070, -2.1568], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6480, -0.3859, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6480, -0.3859, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8208, -0.9219, -1.6163,  0.3506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8208, -0.9219, -1.6163,  0.3506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6755, -0.7268, -0.9241,  0.3369], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6755, -0.7268, -0.9241,  0.3369], grad_fn=<TanhBackward0>),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6803,  0.8236, -1.8061, -0.9442], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6803,  0.8236, -1.8061, -0.9442], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1752, -1.0360, -0.8593, -1.0688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1752, -1.0360, -0.8593, -1.0688], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7343, -1.6901, -0.6930, -1.8782], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7343, -1.6901, -0.6930, -1.8782], grad_fn=<ViewBackward0>),), Output: tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3066, -0.6127,  1.1619, -0.5968], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3066, -0.6127,  1.1619, -0.5968], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3004, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3004, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5021,  0.7481, -0.8099], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5021,  0.7481, -0.8099], grad_fn=<TanhBackward0>),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2374,  0.7703, -0.4057, -2.1571], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2374,  0.7703, -0.4057, -2.1571], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6471, -0.3848, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6471, -0.3848, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8218, -0.9220, -1.6147,  0.3518], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8218, -0.9220, -1.6147,  0.3518], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6760, -0.7268, -0.9238,  0.3380], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6760, -0.7268, -0.9238,  0.3380], grad_fn=<TanhBackward0>),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1753, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1753, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7762, -0.6962, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7762, -0.6962, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3062, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3062, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2998, -1.3259, -2.8762, -4.2294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2998, -1.3259, -2.8762, -4.2294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2376,  0.7689, -0.4045, -2.1574], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2376,  0.7689, -0.4045, -2.1574], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6463, -0.3838, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6463, -0.3838, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8227, -0.9221, -1.6131,  0.3530], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8227, -0.9221, -1.6131,  0.3530], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6765, -0.7269, -0.9236,  0.3391], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6765, -0.7269, -0.9236,  0.3391], grad_fn=<TanhBackward0>),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6799,  0.8233, -1.8066, -0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6799,  0.8233, -1.8066, -0.9449], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6769, -0.9475, -0.7375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6769, -0.9475, -0.7375], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7761, -0.6964, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7761, -0.6964, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>),), Output: tensor([-0.6252, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6252, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3058, -0.6109,  1.1621, -0.5983], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3058, -0.6109,  1.1621, -0.5983], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8632, -0.5447,  0.8217, -0.5359], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8632, -0.5447,  0.8217, -0.5359], grad_fn=<TanhBackward0>),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2992, -1.3290, -2.8779, -4.2300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2992, -1.3290, -2.8779, -4.2300], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2378,  0.7675, -0.4032, -2.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2378,  0.7675, -0.4032, -2.1576], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6455, -0.3827, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6455, -0.3827, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8236, -0.9221, -1.6115,  0.3542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8236, -0.9221, -1.6115,  0.3542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6770, -0.7269, -0.9234,  0.3401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6770, -0.7269, -0.9234,  0.3401], grad_fn=<TanhBackward0>),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6797,  0.8232, -1.8068, -0.9452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6797,  0.8232, -1.8068, -0.9452], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1756, -1.0352, -0.8607, -1.0693], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1756, -1.0352, -0.8607, -1.0693], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7332, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7332, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>),), Output: tensor([-0.6250, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6250, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3055, -0.6099,  1.1621, -0.5991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3055, -0.6099,  1.1621, -0.5991], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2986, -1.3321, -2.8795, -4.2306], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2986, -1.3321, -2.8795, -4.2306], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5495,  0.9725, -1.1281], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5495,  0.9725, -1.1281], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2379,  0.7661, -0.4020, -2.1579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2379,  0.7661, -0.4020, -2.1579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6446, -0.3817, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6446, -0.3817, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8245, -0.9222, -1.6099,  0.3553], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8245, -0.9222, -1.6099,  0.3553], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6775, -0.7269, -0.9231,  0.3411], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6775, -0.7269, -0.9231,  0.3411], grad_fn=<TanhBackward0>),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1757, -1.0349, -0.8610, -1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1757, -1.0349, -0.8610, -1.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>),), Output: tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3051, -0.6090,  1.1622, -0.5999], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3051, -0.6090,  1.1622, -0.5999], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.5434,  0.8218, -0.5370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.5434,  0.8218, -0.5370], grad_fn=<TanhBackward0>),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2979, -1.3352, -2.8812, -4.2312], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2979, -1.3352, -2.8812, -4.2312], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4995,  0.7504, -0.8105], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4995,  0.7504, -0.8105], grad_fn=<TanhBackward0>),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2381,  0.7647, -0.4009, -2.1581], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2381,  0.7647, -0.4009, -2.1581], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6438, -0.3807, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6438, -0.3807, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8253, -0.9222, -1.6084,  0.3564], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8253, -0.9222, -1.6084,  0.3564], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6780, -0.7270, -0.9229,  0.3421], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6780, -0.7270, -0.9229,  0.3421], grad_fn=<TanhBackward0>),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6793,  0.8229, -1.8073, -0.9459], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6793,  0.8229, -1.8073, -0.9459], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7325, -1.6983, -0.6971, -1.8796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7325, -1.6983, -0.6971, -1.8796], grad_fn=<ViewBackward0>),), Output: tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2973, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2973, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8712, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8712, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5478,  0.9750, -1.1290], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5478,  0.9750, -1.1290], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2383,  0.7634, -0.3998, -2.1584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2383,  0.7634, -0.3998, -2.1584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6430, -0.3797, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6430, -0.3797, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8261, -0.9223, -1.6069,  0.3575], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8261, -0.9223, -1.6069,  0.3575], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1760, -1.0344, -0.8618, -1.0699], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1760, -1.0344, -0.8618, -1.0699], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7757, -0.6972, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7757, -0.6972, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>),), Output: tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3043, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3043, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.5421,  0.8218, -0.5381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.5421,  0.8218, -0.5381], grad_fn=<TanhBackward0>),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2967, -1.3412, -2.8844, -4.2323], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2967, -1.3412, -2.8844, -4.2323], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2384,  0.7620, -0.3987, -2.1586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2384,  0.7620, -0.3987, -2.1586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6423, -0.3788, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6423, -0.3788, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8270, -0.9223, -1.6054,  0.3585], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8270, -0.9223, -1.6054,  0.3585], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1761, -1.0341, -0.8621, -1.0701], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761, -1.0341, -0.8621, -1.0701], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7755, -0.6973, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7755, -0.6973, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7319, -1.7013, -0.6987, -1.8802], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7319, -1.7013, -0.6987, -1.8802], grad_fn=<ViewBackward0>),), Output: tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.6063,  1.1624, -0.6022], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.6063,  1.1624, -0.6022], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.5415,  0.8218, -0.5386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.5415,  0.8218, -0.5386], grad_fn=<TanhBackward0>),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2961, -1.3442, -2.8861, -4.2329], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2961, -1.3442, -2.8861, -4.2329], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2386,  0.7607, -0.3976, -2.1589], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2386,  0.7607, -0.3976, -2.1589], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6415, -0.3779, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6415, -0.3779, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8277, -0.9224, -1.6040,  0.3596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8277, -0.9224, -1.6040,  0.3596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6793, -0.7270, -0.9223,  0.3448], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6793, -0.7270, -0.9223,  0.3448], grad_fn=<TanhBackward0>),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6787,  0.8224, -1.8080, -0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6787,  0.8224, -1.8080, -0.9468], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7383], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7315, -1.7029, -0.6995, -1.8804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7315, -1.7029, -0.6995, -1.8804], grad_fn=<ViewBackward0>),), Output: tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2955, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2955, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4970,  0.7525, -0.8112], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4970,  0.7525, -0.8112], grad_fn=<TanhBackward0>),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2388,  0.7594, -0.3966, -2.1591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2388,  0.7594, -0.3966, -2.1591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6407, -0.3770, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6407, -0.3770, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8285, -0.9224, -1.6026,  0.3605], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8285, -0.9224, -1.6026,  0.3605], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6797, -0.7270, -0.9221,  0.3457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6797, -0.7270, -0.9221,  0.3457], grad_fn=<TanhBackward0>),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6763, -0.9477, -0.7385], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6763, -0.9477, -0.7385], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1764, -1.0335, -0.8627, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1764, -1.0335, -0.8627, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>),), Output: tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3032, -0.6045,  1.1624, -0.6038], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3032, -0.6045,  1.1624, -0.6038], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8625, -0.5402,  0.8218, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8625, -0.5402,  0.8218, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2949, -1.3500, -2.8893, -4.2340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2949, -1.3500, -2.8893, -4.2340], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4964,  0.7531, -0.8114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4964,  0.7531, -0.8114], grad_fn=<TanhBackward0>),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2389,  0.7581, -0.3956, -2.1594], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2389,  0.7581, -0.3956, -2.1594], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6400, -0.3762, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6400, -0.3762, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8292, -0.9224, -1.6012,  0.3615], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8292, -0.9224, -1.6012,  0.3615], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6801, -0.7270, -0.9218,  0.3465], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6801, -0.7270, -0.9218,  0.3465], grad_fn=<TanhBackward0>),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1765, -1.0332, -0.8629, -1.0706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1765, -1.0332, -0.8629, -1.0706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7752, -0.6978, -0.7897], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7752, -0.6978, -0.7897], grad_fn=<TanhBackward0>),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7309, -1.7058, -0.7012, -1.8810], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7309, -1.7058, -0.7012, -1.8810], grad_fn=<ViewBackward0>),), Output: tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3028, -0.6036,  1.1625, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3028, -0.6036,  1.1625, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.5396,  0.8218, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.5396,  0.8218, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2943, -1.3529, -2.8910, -4.2345], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2943, -1.3529, -2.8910, -4.2345], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5438,  0.9812, -1.1314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5438,  0.9812, -1.1314], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2391,  0.7569, -0.3946, -2.1596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2391,  0.7569, -0.3946, -2.1596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6392, -0.3753, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6392, -0.3753, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8299, -0.9224, -1.5998,  0.3624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8299, -0.9224, -1.5998,  0.3624], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6804, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6804, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6781,  0.8218, -1.8087, -0.9477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6781,  0.8218, -1.8087, -0.9477], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1766, -1.0329, -0.8632, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1766, -1.0329, -0.8632, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7305, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7305, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>),), Output: tensor([-0.6234, -0.9363, -0.6057, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6234, -0.9363, -0.6057, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8623, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8623, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9798, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9798, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2393,  0.7556, -0.3937, -2.1598], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2393,  0.7556, -0.3937, -2.1598], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6385, -0.3745, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6385, -0.3745, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8306, -0.9224, -1.5985,  0.3633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8306, -0.9224, -1.5985,  0.3633], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6808, -0.7270, -0.9214,  0.3481], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6808, -0.7270, -0.9214,  0.3481], grad_fn=<TanhBackward0>),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6779,  0.8217, -1.8090, -0.9479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6779,  0.8217, -1.8090, -0.9479], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6760, -0.9477, -0.7388], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6760, -0.9477, -0.7388], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1767, -1.0326, -0.8634, -1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1767, -1.0326, -0.8634, -1.0710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7302, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7302, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3020, -0.6019,  1.1625, -0.6061], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3020, -0.6019,  1.1625, -0.6061], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8622, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8622, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Run model training for multiple epochs with PyTorch model\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "# with torch.no_grad():\n",
    "#     for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "#         param_tmlp.copy_(param_mlp)\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "loss_rmse_list = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_preds = [tmlp(torch.tensor(i)) for i in x]\n",
    "    y_true = [torch.tensor([y_i.data]) for y_i in y_true]\n",
    "    loss_rmse = rmse(y_true, y_preds)  # Calculate loss\n",
    "    loss_rmse_list.append(loss_rmse.item())\n",
    "    loss_rmse.backward()  # Perform backpropagation\n",
    "    optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3c92ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds_tmlp = [0.9358316659927368, -1.0214028358459473, -0.9719010591506958, 1.059489369392395]\n",
      "y_true = [tensor([1.]), tensor([-1.]), tensor([-1.]), tensor([1.])]\n"
     ]
    }
   ],
   "source": [
    "# Print prediction using PyTorch model\n",
    "print(f\"y_preds_tmlp = {[item.item() for item in y_preds]}\")\n",
    "print(f\"y_true = {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a83fc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_rmse_list = [1.5003691911697388, 0.9619162678718567, 0.7609615325927734, 0.655165433883667, 0.5759391188621521, 0.5016622543334961, 0.43051496148109436, 0.36708199977874756, 0.31330305337905884, 0.2682991623878479, 0.2305852323770523, 0.19882233440876007, 0.17192722856998444, 0.14904920756816864, 0.12952131032943726, 0.11281421035528183, 0.09849988669157028, 0.08622519671916962, 0.07569411396980286, 0.06665531545877457, 0.058893948793411255, 0.05222536623477936, 0.04649071767926216, 0.04155323654413223, 0.03729568049311638, 0.03361736610531807, 0.030432311818003654, 0.027667148038744926, 0.025259433314204216, 0.023156164214015007, 0.021312301978468895, 0.019689971581101418, 0.018256904557347298, 0.01698593981564045, 0.01585417240858078, 0.014842196367681026, 0.013933653943240643, 0.013114718720316887, 0.012373685836791992, 0.011700637638568878, 0.011087149381637573, 0.010526053607463837, 0.010011209174990654, 0.009537411853671074, 0.00910014659166336, 0.0086955726146698, 0.00832032784819603, 0.00797151681035757, 0.00764659745618701, 0.007343349978327751, 0.007059840019792318, 0.006794353015720844, 0.0065453508868813515, 0.0063115074299275875, 0.006091567687690258, 0.005884472280740738, 0.00568923307582736, 0.005504969507455826, 0.00533088855445385, 0.005166247952729464, 0.005010389722883701, 0.0048626987263560295, 0.00472262641415, 0.004589674063026905, 0.004463345743715763, 0.004343234933912754, 0.004228922072798014, 0.004120033700019121, 0.0040162717923521996, 0.003917261958122253, 0.0038227392360568047, 0.0037324270233511925, 0.003646071534603834, 0.0035634422674775124, 0.003484305925667286, 0.003408467397093773, 0.003335739718750119, 0.003265946637839079, 0.003198919352144003, 0.00313448254019022, 0.003072521183639765, 0.0030128881335258484, 0.002955453936010599, 0.002900109626352787, 0.002846744377166033, 0.0027952452655881643, 0.00274552870541811, 0.0026974882930517197, 0.0026510474272072315, 0.0026061353273689747, 0.0025626537390053272, 0.002520540729165077, 0.002479751594364643, 0.0024402074050158262, 0.0024018418043851852, 0.0023646228946745396, 0.0023284698836505413, 0.0022933539003133774, 0.0022592328023165464, 0.0022260479163378477]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "print(f\"loss_rmse_list = {loss_rmse_list}\")\n",
    "plt.plot(range(epochs), loss_rmse_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ec98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
