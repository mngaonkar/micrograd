{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "7b5e86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "from IPython import display\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "d5629e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "84ab2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for Jupyter Notebook to find the graphviz executables\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\"/opt/homebrew/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "4eba97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for gradient calculation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "3fbd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAATshJREFUeJzt3Ql8TOf6B/Bf9n0R2WUhtgQRxBZFFbUrpYsutKqUi1a1qu7t1VZ7S+m/u0t7b4sWpVrcUstVaxFbbBEEEZLIKpFFIuvM//O+SeYmxJL1nJn5fT+f0zkzcxLP6cnMPPMuz2ui1Wq1ICIiIlIxU6UDICIiIrofJixERESkekxYiIiISPWYsBAREZHqMWEhIiIi1WPCQkRERKrHhIWIiIhUjwkLERERqZ459JBGo0FiYiIcHBxgYmKidDhERET0AESt2pycHHh7e8PU1NTwExaRrPj6+iodBhEREdVAfHw8fHx8DD9hES0r5Sfs6OiodDhERET0ALKzs2WDQ/nnuMEnLOXdQCJZYcJCRESkX2oynIODbomIiEj1mLAQERGR6jFhISIiItVjwkJERESGlbAsWbIE7du31w12DQsLw9atW3XP9+nTRw6kqbhNnjy50u+Ii4vD0KFDYWtrC3d3d8yaNQvFxcV1d0ZERERkcKo1S0jMmV6wYAFatmwpi7+sWLECI0aMwIkTJ9C2bVt5zMSJEzFv3jzdz4jEpFxJSYlMVjw9PXHw4EEkJSVh3LhxsLCwwEcffVSX50VEREQGxEQrMo9acHFxwaJFizBhwgTZwtKhQwd8/vnnVR4rWmOGDRsmC795eHjIx5YuXYrZs2cjLS0NlpaWDzyP28nJCVlZWZzWTEREpCdq8/ld4zEsorVkzZo1yM3NlV1D5VatWgVXV1e0a9cOc+bMQV5enu658PBwBAcH65IVYeDAgfIEoqKiahoKERERGbhqF46LjIyUCUp+fj7s7e2xYcMGtGnTRj737LPPwt/fX64RcPr0adlyEh0djfXr18vnk5OTKyUrQvl98dzdFBQUyK2cSHCIiIjIeFQ7YWndujVOnjwpm3N++eUXvPDCC9i7d69MWiZNmqQ7TrSkeHl5oV+/foiJiUHz5s1rHOT8+fPx/vvv1/jniYiISL9Vu0tIjDNp0aIFQkNDZSIREhKCL774ospju3XrJm8vXbokb8Vg25SUlErHlN8Xz92N6FoSCVL5JtYQIiIiIuNR6zosGo2mUndNRaIlRhAtLYLoShJdSqmpqbpjduzYIQfelHcrVcXKyko3lZrrBxERERmfanUJiZaOwYMHw8/PDzk5OVi9ejX27NmD7du3y24fcX/IkCFo3LixHMPy+uuvo3fv3rJ2izBgwACZmIwdOxYLFy6U41beeecdTJ06VSYlSjubmI3VR66iS1MXjOjQROlwiIiIqCYJi2gZEXVTRP0UMS1JJCIiWXn00UdlN80ff/whpzSLmUNi+ejRo0fLhKScmZkZNm/ejClTpsjWFjs7OzkGpmLdFiXtvZCGlYfiEJ2cw4SFiIjIkOqwKKG+6rCkZOcjbP5OaLTAnjf7oKmrXZ39biIiImOXrUQdFkPk4WiN3q3c5P6vxxOUDoeIiIjKMGG5zROhPvL214gEaERTCxERESmOCctt+gd5wNHaHIlZ+TgYk650OERERMSE5U7WFmZ4rIO33P8lgvVeiIiI1IAJSxWeCPWVt9uikpGdX6R0OEREREaPCUsVQnyc0NLdHvlFGmw5naR0OEREREaPCUsVTExMdINvf4ngbCEiIiKlMWG5i8c7NoGpCXDs6g1cTrupdDhERERGjQnLXbg7WuNh1mQhIiJSBSYsDzD4dv3xayhhTRYiIiLFMGG5h35B7nCysUCSrMlyXelwiIiIjBYTlvvUZBmhq8nCbiEiIiKlMGG5j/LZQtvOJCPrFmuyEBERKYEJy30EN3FCKw97FBRr8DtrshARESmCCUu1arKwVD8REZESmLA8gJEdmsDM1ATH4zIRw5osREREDY4JS3VrsnDwLRERUYNjwvKAnizrFmJNFiIioobHhOUB9Q1yh7OtBZKz87H/EmuyEBERNSQmLA/IytwMI0JYk4WIiEgJTFhqUKp/exRrshARETUkJizV0K6JI1p7OKCwWIPNpxOVDoeIiMhoMGGpZk2WJzuXDr5dd4zdQkRERA2FCUs1jSiryXIyPhOXUnOUDoeIiMgoMGGpJjcHKzzSurQmyy8R15QOh4iIyCgwYamB8lL9G04ksCYLERFRA2DCUgN9Az3QyNYCKdkF+PNimtLhEBERGTwmLDVgaW4qx7II61iThYiIqN4xYallt9COqBRk5hUqHQ4REZFBY8JSQ229HRHo6YDCEg02nuDgWyIiovrEhKUWNVnGdCmtfLvmaDy0Wg6+JSIiqi9MWGrh8Y4+sDI3xfnkHFmXhYiIiOoHE5ZacLK1wJBgL7m/5ki80uEQEREZLCYstVTeLbTpdCJuFhQrHQ4REZFBYsJSS12buSDAzQ55hSX47SQXRCQiIqoPTFjqdPBtnNLhEBERGSQmLHVgdCcfWJiZ4HRCFqISs5QOh4iIyOAwYakDje2tMKCNp9zn4FsiIqK6x4SljozpWtottPHkNdwqLFE6HCIiIuNNWJYsWYL27dvD0dFRbmFhYdi6davu+fz8fEydOhWNGzeGvb09Ro8ejZSUlEq/Iy4uDkOHDoWtrS3c3d0xa9YsFBfr/+yah5q7wtfFBjn5xfg9MknpcIiIiIw3YfHx8cGCBQsQERGBY8eOoW/fvhgxYgSioqLk86+//jo2bdqEdevWYe/evUhMTMSoUaN0P19SUiKTlcLCQhw8eBArVqzA8uXLMXfuXOg7U1MTPN25bPDtEQ6+JSIiqksm2lrWlHdxccGiRYvwxBNPwM3NDatXr5b7wvnz5xEUFITw8HB0795dtsYMGzZMJjIeHh7ymKVLl2L27NlIS0uDpaXlA/2b2dnZcHJyQlZWlmzpUYuU7Hz0WLALJRotdrzeGy09HJQOiYiISDVq8/ld4zEsorVkzZo1yM3NlV1DotWlqKgI/fv31x0TGBgIPz8/mbAI4jY4OFiXrAgDBw6UJ1DeSlOVgoICeUzFTY08HK3RN9Bdt74QERER1Y1qJyyRkZFyfIqVlRUmT56MDRs2oE2bNkhOTpYtJM7OzpWOF8mJeE4QtxWTlfLny5+7m/nz58uMrHzz9S3telGjZ8oG364/noCCYg6+JSIiUiRhad26NU6ePInDhw9jypQpeOGFF3D27FnUpzlz5sjmo/ItPl69rRcPt3KHl5M1buQVYXtU5QHHRERE1EAJi2hFadGiBUJDQ2XLR0hICL744gt4enrKwbSZmZVXLRazhMRzgri9fdZQ+f3yY6oiWnPKZyaVb2plZmqCJzn4loiISF11WDQajRxjIhIYCwsL7Ny5U/dcdHS0nMYsxrgI4lZ0KaWmpuqO2bFjh0xARLeSoXiqsw9MTICDMem4mp6rdDhERER6z7y6XTODBw+WA2lzcnLkjKA9e/Zg+/btcmzJhAkTMHPmTDlzSCQh06dPl0mKmCEkDBgwQCYmY8eOxcKFC+W4lXfeeUfWbhGtKIbCp5Eterd0w94LaXLw7exBgUqHREREZDwtLKJlZNy4cXIcS79+/XD06FGZrDz66KPy+c8++0xOWxYF43r37i27edavX6/7eTMzM2zevFneikTm+eefl79v3rx5MDTlg2/XHUtAUYlG6XCIiIiMuw6LEtRah6UikaSEzd+F6zcLsPT5UAxqd/cxOkRERMYgW4k6LHRvFmameCLUR+6vOcrBt0RERLXBhKUejelS2i0kxrJcy7yldDhERER6iwlLPWrqaoewgMYQnW4/s/ItERFRjTFhqWdjdINv4+UaQ0RERFR9TFjq2cC2nnC2tUBiVj72XUhTOhwiIiK9xISlnllbmGFUx9LBtz+x8i0REVGNMGFpwJosO8+nIjU7X+lwiIiI9A4TlgbQ0sMBnf0byTEs6yISlA6HiIhI7zBhaSBjuvrpuoU4+JaIiKh6mLA0kKHBXnCysUDCjVvYe+F/iz8SERHR/TFhaSA2lmZ4sqzy7Y/hV5UOh4iISK8wYWlAz3f3l7d7LqQhLj1P6XCIiIj0BhOWBq5827uVm6x8u+owW1mIiIgeFBOWBjaurJVl7bF45BeVKB0OERGRXmDC0sAeCXRHE2cbZOYVYfPpJKXDISIi0gtMWBqYmakJnu1WOsX5x0PsFiIiInoQTFgU8HQXX1iameJUfCZOJ2QqHQ4REZHqMWFRgKu9FYYEe8p9TnEmIiK6PyYsChkb1lTe/nYqEZl5hUqHQ0REpGpMWBTSyc8ZbbwcUVCswbpjXF+IiIjoXpiwKMTExARjw0qnOK88fBUari9ERER0V0xYFDSigzccrM1xNT0P+y6mKR0OERGRajFhUZCtpTmeKFtfaCWnOBMREd0VExaVrC+083wq4jO4vhAREVFVmLAorLmbPXq2cJXrC60+Eqd0OERERKrEhEUFygffrj0aj4Jiri9ERER0OyYsKtAv0B1eTtbIyC3ElkiuL0RERHQ7JiwqYG5mime7lq0vxMq3REREd2DCohJPd/WFhZkJjsdl4sy1LKXDISIiUhUmLCrh7mCNQe285D6nOBMREVXGhEVFxpUNvt148hqybhUpHQ4REZFqMGFRkc7+jRDo6YD8Ig1+ieD6QkREROWYsKhsfaHyQnKiW4jrCxEREZViwqIyj3dsAnsrc8Rez8XBmHSlwyEiIlIFJiwqY2dljtGdmsj9H8KvKB0OERGRKjBhUXHl2z/OpeBa5i2lwyEiIlIcExYVauHugLCAxhBDWDjFmYiIiAmLao1/qKm8XX04DrcKub4QEREZt2olLPPnz0eXLl3g4OAAd3d3jBw5EtHR0ZWO6dOnj5ztUnGbPHlypWPi4uIwdOhQ2Nrayt8za9YsFBcX180ZGYh+QR7wc7GV9Vh+Pc4pzkREZNyqlbDs3bsXU6dOxaFDh7Bjxw4UFRVhwIAByM3NrXTcxIkTkZSUpNsWLlyoe66kpEQmK4WFhTh48CBWrFiB5cuXY+7cuXV3VgbAzNRE18qy7EAspzgTEZFRM9FqtTX+JExLS5MtJCKR6d27t66FpUOHDvj888+r/JmtW7di2LBhSExMhIeHh3xs6dKlmD17tvx9lpaW9/13s7Oz4eTkhKysLDg6OsJQ3SwoRthHO5FTUIxl47vgkdbuSodERERUY7X5/K7VGBbxDwouLi6VHl+1ahVcXV3Rrl07zJkzB3l5ebrnwsPDERwcrEtWhIEDB8qTiIqKqvLfKSgokM9X3IyBqMfyVBdfuf/9/lilwyEiIlJMjRMWjUaDGTNm4KGHHpKJSblnn30WK1euxO7du2Wy8uOPP+L555/XPZ+cnFwpWRHK74vn7jZ2RmRk5Zuvb+mHuDF4sUdTmJoAf168jgspOUqHQ0REpAjzmv6gGMty5swZ7N+/v9LjkyZN0u2LlhQvLy/069cPMTExaN68eY3+LZH4zJw5U3dftLAYS9Li62KLAW08sS0qWY5lmT+qvdIhERER6UcLy7Rp07B582bZiuLj43PPY7t16yZvL126JG89PT2RkpJS6Zjy++K5qlhZWcm+roqbMZnQq5m8XX/8GjJyC5UOh4iISN0JixifK5KVDRs2YNeuXWjWrPSD9F5Onjwpb0VLixAWFobIyEikpqbqjhEzjkQS0qZNm+qfgZGs4hzcxAkFxRr8dCRO6XCIiIjUnbCIbiAxPmX16tWyFosYcyK2W7dKy8eLbp8PPvgAERERuHLlCn777TeMGzdOziBq3760K0NMgxaJydixY3Hq1Cls374d77zzjvzdoiWF7iRq2bzUs3SK84qDV1BYrFE6JCIiIvUmLEuWLJEzg8TUZdFiUr6tXbtWPi+mJP/xxx8yKQkMDMQbb7yB0aNHY9OmTbrfYWZmJruTxK1obREDckVSM2/evLo/OwMyNNgb7g5WSM0pwJbIJKXDISIi0p86LEoxljost/t610V88t8Lsnvot2kPyZYXIiIifaFYHRZqWM9284eVuSkir2Xh2NUbSodDRETUYJiw6BEXO0uM6tRE7rOQHBERGRMmLHpm/EOlM7O2RyUjPuN/FYSJiIgMGRMWPdPKwwG9WrpCrIUoZgwRERHVpeISDZKySmf/qgkTFj30Us/SVpa1R+PlAolERER1ZXtUCnp9vBvv/Vb1+n5KYcKihx5u6YYANzu5ivO6Y/FKh0NERAZCq9Xi230xKNZo4WhjATVhwqKHTE1N8FLZWJblB6+gRPQPERER1dLh2AycSsiSM1LHhflDTZiw6CkxW8jJxgJX0/Ow81zltZmIiIhq4tt9l+Xt6FAfuNqrq/o8ExY9ZWtpjme7+cn97w9wijMREdXOxZQc7DqfClGTdGKvAKgNExY9JprrzExNcOhyBqISs5QOh4iI9Ni//ixtXRnQxgPNXO2gNkxY9JiXkw2GBJeugv39fk5xJiKimknNzsfGE4lyf1Jv9bWuCExY9NyEsinOm04lIjUnX+lwiIhIDy07eAWFJRqE+jdCqL8L1IgJi57r4OuMTn7O8g9t5aE4pcMhIiI9c7OgGKsOXVV164rAhMUATOhZ+ge28tBV5BeVKB0OERHpkbVH45GdXyzHrTwa5AG1YsJiAAa29YBPIxtk5BaykBwRET2wohKNbjHdl3s1k3W+1IoJiwEwNzPVTUH79s/Lch0IIiKi+9kSmYRrmbfQ2M4Sozv5QM2YsBiIpzr7wsXOEvEZt7DlTLLS4RARkV6U4b8s91/o0RTWFmZQMyYsBsLG0gwvhDWV+0v3xMg/RCIiors5GJOOqMRsWFuYYmx3dZXhrwoTFgMrJGdjYYazSdn48+J1pcMhIiIV+6asdUW00Deys4TaMWExIOIPbkxXX7m/dG+M0uEQEZFKnUvKxr4LaRBjbF8um2mqdkxYDMzLvQJgbmoim/pOJ2QqHQ4REam4DP/gdl7wa2wLfcCExcA0cbbBYyHecp+tLEREdLukrFv47aS6y/BXhQmLAXrl4ebyduuZZMRez1U6HCIiUpFlB66gWKNF12YuCPF1hr5gwmKAWns6oG+gO8REofIpa0RERNn5RVh9uHQZl1f0qHVFYMJioKb0KW1l+fV4AhdFJCIiac2ROLl2UAt3ezzS2h36hAmLgerS1EWuullYrJHNf0REZNwKi0UZ/tLPg0m9AlRdhr8qTFgM2OSysSxiUcSc/CKlwyEiIgVtOpWI5Ox8uDlYYUTH0skZ+oQJiwHrF+iOlu72yMkv1vVZEhGR8dFqtbqpzC/2aAorc3WX4a8KExYDJpr7yqesfbc/FgXFJUqHRERECth38TrOJ+fA1tIMz3dTfxn+qjBhMXAjOjSBl5M1UnMKsOH4NaXDISIiBXy7r7Qu15gufnCytYA+YsJi4CzNTTGhZzO5L6Y4l2i4KCIRkTE5FZ+JA5fSYWZqgpd6li6Sq4+YsBiBMV394GhtjsvXc7HjbLLS4RARUQP6evcleTuigzd8GulHGf6qMGExAvZW5hgXVppVL9l7WQ6+IiIi41jkcMfZFJiYAH/p0wL6jAmLkXjxITEq3FQ2DR66nKF0OERE1AAWl7WuDAn2ksXi9BkTFiPham+FJzv7yH0uikhEZPhi0m7i98gkuT/tEf1uXRGYsBiRSb2aQxQ23HshDWcTs5UOh4iI6tE/d8fINeX6B3kgyMsR+o4JixHxa2wrmwWFb8qmuBERkeGJz8jDxpOlpSym9dX/1hWBCYuRluvffDpJ/kETEZHhWbI3Rpax6NXSFR18nWF0Ccv8+fPRpUsXODg4wN3dHSNHjkR0dHSlY/Lz8zF16lQ0btwY9vb2GD16NFJSUiodExcXh6FDh8LW1lb+nlmzZqG4uLhuzojuqV0TJ/kHLP6Q2cpCRGR4krJu4ZdjCXJ/et+WMBTVSlj27t0rk5FDhw5hx44dKCoqwoABA5Cbm6s75vXXX8emTZuwbt06eXxiYiJGjRqle76kpEQmK4WFhTh48CBWrFiB5cuXY+7cuXV7ZnRXU8sGX/18NEH+YRMRkeH4dt9lFJZo0LWZi9wMhYm2FkU50tLSZAuJSEx69+6NrKwsuLm5YfXq1XjiiSfkMefPn0dQUBDCw8PRvXt3bN26FcOGDZOJjIeHhzxm6dKlmD17tvx9lpaW9/13s7Oz4eTkJP89R0f9H0ikhKe/Ccfh2Ay8EOaP90e0UzocIiKqA9dvFqDnx7uQX6TBjxO6oldLN6hJbT6/azWGRfyDgotLaQYXEREhW1369++vOyYwMBB+fn4yYRHEbXBwsC5ZEQYOHChPIioqqsp/p6CgQD5fcaPaea1faTPhT0fjkZKdr3Q4RERUB77bHyuTlRBfZ/Rs4QpDUuOERaPRYMaMGXjooYfQrl3pN/Tk5GTZQuLsXHmAj0hOxHPlx1RMVsqfL3/ubmNnREZWvvn6+tY0bCoT1rwxujRthMJiDeuyEBEZgMy8Qvxw8Ircn/5IC5iI8rYGpMYJixjLcubMGaxZswb1bc6cObI1p3yLj4+v93/T0Ik/5FfLWllWH45DKltZiIj02vKDV5BbWCJrrvQLcoehqVHCMm3aNGzevBm7d++Gj09p9VTB09NTDqbNzMysdLyYJSSeKz/m9llD5ffLj7mdlZWV7OuquFHtiebCTn7OKCjWyEFaRESkn3Lyi7DswBVdVVtDa12pdsIixueKZGXDhg3YtWsXmjVrVun50NBQWFhYYOfOnbrHxLRnMY05LCxM3he3kZGRSE1N1R0jZhyJJKRNmza1PyOqUSvLysNXkZZToHRIRERUAysPxSHrVhGau9lhULuqv/wbVcIiuoFWrlwpZwGJWixizInYbt0qnRorxpdMmDABM2fOlK0vYhDu+PHjZZIiZggJYhq0SEzGjh2LU6dOYfv27XjnnXfk7xYtKdSwHm7lJgdniUFa//6TrSxERPrmVmGJ7v1blK0wE2uwGHvCsmTJEjmGpE+fPvDy8tJta9eu1R3z2WefyWnLomCcmOosunnWr1+ve97MzEx2J4lbkcg8//zzGDduHObNm1e3Z0YP3Moyo6yV5Yfwq0i/yVYWIiJ98tOROKTnFsLXxQaPhXjDUNWqDotSWIelbok/gRGLD+B0QpYs3f/24EClQyIiogdQUFyC3gt3IyW7APNHBeOZrn5QM8XqsJABjWUpK9/8Q/gVZOQWKh0SERE9gF8iEmSy4uVkjVGdmsCQMWEhSUyBa+vtiLzCEny3n2NZiIjUrqhEgyV7SutovdI7AFbmZjBkTFjojhlDKw5elQWIiIhIvf5zMhEJN27B1d4SY1TeFVQXmLCQzqNBHgj0dMDNgmJ8vz9W6XCIiOguSjRa/HP3Jbk/sVcArC0Mu3VFYMJCOqamJro1hkQBoqy8IqVDIiKiKmyJTMLl67lwtrXAc939YQyYsFAlA9t6orWHA3IKirHsIFtZiIjU2Lryxc6Lcn98j2awtzKHMWDCQne0skzv10Lui26h7Hy2shARqclvp67hUupNONlYYHzPpjAWTFjoDkPaeaGluz2y84uxomxtCiIiUsfMoM//KG1dEXWzHK0tYCyYsFCVrSzT+pa2svx7f6xcVIuIiNRRd+Vqep6cGfRCD+MYu1KOCQtVaVh7bwS42cnFtETJfiIiUlZ+UQm+LBu78pc+LWBraRxjV8oxYaEqicWzppe3svx5GbkFxUqHRERk1NYciUNSVj48Ha3xbDfDr7tyOyYsdFfD23ujmasdbuSxlYWISOkVmb/eXVrVVkyMMIa6K7djwkJ3ZW5mimmPlLay/OvPy7KgHBERNbwfwq/g+s0CuSLzk6G+MEZMWOieRnTwRtPGtnJBRFa/JSJqeGLiw9K9pa0rr/VrBUtz4/zoNs6zpmq1sswc0Fru/2vfZdzgSs5ERA1KVB6/kVckJ0KM7OANY8WEhe5rWLAX2ng5yuq3S8qyfCIiqn9iIVrxZVGY+Wgr+SXSWBnvmVO16rLMGljayrLi4BUkZ+UrHRIRkVEQ4wfFl8VATwdZ1NOYMWGhB9KntRu6NG2EgmKNbg0LIiKqP2KQregOEt4Y0Fp+eTRmTFjogZiYmOCtQYFy/+dj8Yi9nqt0SEREBm3JnhjkFZYgxMcJ/YPcYeyYsNAD69LUBY+0dpMrhX6644LS4RARGSzR9f7joau61hUTE+NuXRGYsFC1vFk2lmXTqUREJWYpHQ4RkUH6evdFFBZr0LWpC3q1dFU6HFVgwkLV0tbbCcNDSqfVfbI9WulwiIgMTnxGHtYejZf7bwxoxdaVMkxYqNrE1Dqx1tDu6DQcic1QOhwiIoMiFjgsKtHKlpVuAY2VDkc1mLBQtYn1hZ7uUloaeuG289BqtUqHRERkEC6n3cSvxxN0Y1fof5iwUI282rclrMxNcezqDeyOTlU6HCIig/D5Hxeh0QL9gzzQwddZ6XBUhQkL1YinkzVe7NFU7i/afgEa8QojIqIaO5+cjU2nE3Vd71QZExaqsckPN4eDlTnOJf3vRUZERDXz6X8vQPSwD23vhTbejkqHozpMWKjGGtlZYlLvALkv6rIUlWiUDomISC+diLuB/55NgShm+3r/lkqHo0pMWKhWXurZDK72lrianicr4BIRUfWIiQsfbTkn90d38kELdwelQ1IlJixUK3ZW5pj6SAvdVLz8ohKlQyIi0iuiZeXolRuwtjDlzKB7YMJCtfZsNz80cbZBSnaBXM2ZiIgejOhKX7D1vNyf2CtATmigqjFhoVqzMjfDjLI+1yV7Y5CdX6R0SEREeuGnI3FyMVnRtf7Kw82VDkfVmLBQnRgl+13tkZlXhH/tu6x0OEREqie+3Im6K8KM/q1gb2WudEiqxoSF6oQo1f/mgNK6Ad/tj0VaToHSIRERqdrSPTHIyC1Eczc7jCmrHk53x4SF6szAtp4I8XFCXmEJvtpV+q2BiIjulJh5S365E+YMDoK5GT+O74f/h6jOiBVFZw8OlPurDsfhUmqO0iEREanSJ/+NRkGxBt2auaBfkLvS4egFJixUp3o0d5VrYJRotPjH76V1BYiI6H/OXMvChhPX5P7fhgbJL3t0f0xYqM79dUggzE1NsDs6DfsupCkdDhGR6orEiRL8Izp4o70PFzist4Rl3759GD58OLy9vWVWuHHjxkrPv/jii/LxitugQYMqHZORkYHnnnsOjo6OcHZ2xoQJE3Dz5s3qhkIqFeBmj3FhpQsjfvj7WRSzZD8RkbQnOg0HY9JhaW6KN1kkrn4TltzcXISEhGDx4sV3PUYkKElJSbrtp59+qvS8SFaioqKwY8cObN68WSZBkyZNqm4opGKv9WsJZ1sLXEi5ibUs2U9EJL+8lZfgH9+jKXxdbJUOSa9Ue9L34MGD5XYvVlZW8PT0rPK5c+fOYdu2bTh69Cg6d+4sH/vqq68wZMgQfPLJJ7LlhvSfk60FZvRrifc2nZUrkA4P8YajtYXSYRERKWZdRAIupt6UX+b+UrakCSk8hmXPnj1wd3dH69atMWXKFKSnp+ueCw8Pl91A5cmK0L9/f5iamuLw4cNV/r6CggJkZ2dX2kj9nuvujwA3O6TnFmLx7ktKh0NEpJjcgmK5qr3wat+WcLLhFzjFExbRHfTDDz9g586d+Pjjj7F3717ZIlNSUrooXnJyskxmKjI3N4eLi4t8rirz58+Hk5OTbvP1ZYEdfWBhZoq/DQmS+8v2X0Fcep7SIRERKeLbfZdlQU3/xrZ4vru/0uHopTpPWMaMGYPHHnsMwcHBGDlypByjIrp/RKtLTc2ZMwdZWVm6LT6eYyL0Rd9Ad/Rs4YpCscDXNk5zJiLjk5qdLxMWYfagQDnglqqv3v+vBQQEwNXVFZculXYJiLEtqamplY4pLi6WM4fuNu5FjIkRM4oqbqQfxCyxd4YFwdQE2BKZjCOxGUqHRETUoERX0K2iEnTyc8bgdlV/zpEKEpaEhAQ5hsXLy0veDwsLQ2ZmJiIiInTH7Nq1CxqNBt26davvcEgBgZ6OeLqLn9z/YPNZaDRapUMiImoQ0ck5+LlspiSLxDVwwiLqpZw8eVJuQmxsrNyPi4uTz82aNQuHDh3ClStX5DiWESNGoEWLFhg4cKA8PigoSI5zmThxIo4cOYIDBw5g2rRpsiuJM4QM18xHS1cijaxQ4ZGIyNDN33oO4jvakGBPhPq7KB2OcSUsx44dQ8eOHeUmzJw5U+7PnTsXZmZmOH36tBzD0qpVK1kQLjQ0FH/++afs1im3atUqBAYGol+/fnI6c8+ePfHtt9/W7ZmRqrg5WGFq2TS+hdvPI6+wWOmQiIjq1YFL12WhOAszE7w1sHSdNao5E62oE6xnxLRmMVtIDMDleBb9kV9Ugv6f7kXCjVuY0b8lZvRvpXRIRET1ViRu2Ff7cT45By/2aIr3HmurdEh6//nNocrUYKwtzOQy6sI3ey8jOStf6ZCIiOrFykNXZbIiisSJyt9Ue0xYqEGJftzO/o3kiHnRNUREZGiu3yzA/5UViZs1sDUa2VkqHZJBYMJCDUqMkP/7sDZyf/3xazidkKl0SEREdWrhtvPIyS9GuyaOGFM2Q5JqjwkLNbgQX2c83rGJbpqzHg6jIiKq0om4G/j5WILcf/+xdjATRaioTjBhIUW8Nag1rC1McfTKDWw9U/WSDERE+qREo8Xc/0TJ/SdDfRDq30jpkAwKExZShJeTDSb1bq6rUyBmEBER6bO1R+NlrSkHa3O8NYjTmOsaExZSzOSHA+DhaIX4jFty1hARkb66kVuom0ggCmWK2lNUt5iwkGJsLc3xztDSAbiL91zC1fRcpUMiIqqR/9sRjcy8IrT2cMBYrsZcL5iwkKKGtfcqXc25WCP7fjkAl4j0zZlrWVh1OE7uzxvRFuZm/GitD/y/SopPcxYvcEszU+y9kIbtURyAS0T6QyzmOvc/ZyC+a43o4I1uAY2VDslgMWEhxQW42cvxLML7m84it4DrDBGRflh/4hqOx2XCztIMfx1SWsmb6gcTFlKFvzzSAr4uNkjKyscXOy8qHQ4R0X1l5xdhwdZzcv/Vfi3h4WitdEgGjQkLqWadoXmPtZP73+2PRXRyjtIhERHd0+c7LuL6zUIEuNlh/EPNlA7H4DFhIdV4JNAdA9t6yOJL72yM5ABcIlKt88nZWBF+Re6/N7wtLM35cVrf+H+YVGXu8LawsTCTFXB/PX5N6XCIiO4gvky9+58o+eVqUFtP9G7lpnRIRoEJC6lKE2cbvNa/dCn2+VvOITOvUOmQiIgq2XQ6CYdjM+TyIu8M40DbhsKEhVRnQs9maOluj/TcQizaHq10OEREOmIW4z9+Pyv3p/ZpAZ9GtkqHZDSYsJDqWJiZ4sORpQNwVx+Jw8n4TKVDIiKSvtx1ESnZBfBzscXE3qXlGKhhMGEhVRLFl0Z1aiKLMf1tQ6TsKyYiUtKl1Bx8vz9W7r87vI2c3UgNhwkLqdacwUFwtDZHVGI2Vh66qnQ4RGTkFW3f/jUSRSVa9A10R78gD6VDMjpMWEi1xGqns8qWaP9kezRSc/KVDomIjNSqw1dx7OoNWdH2g7Iua2pYTFhI1Z7t6ocQHyfkFBTjo99LK0oSETWkxMxbWLD1vNx/a1CgnM1IDY8JC6mamakJPhwZDBMTYOPJRByMua50SERkZDVX3tl4BrmFJejk54yx3f2VDsloMWEh1Qv2cdK9Sfx94xkUFmuUDomIjKjmyq7zqXJF+Y9Ht4epqYnSIRktJiykF94Y0Bqu9paIScvFv/68rHQ4RGQEbuQW4v3fouT+1EdaoKWHg9IhGTUmLKQXnGws8LehpRUlxWrOl1JvKh0SERm4DzaflQUsW3nYY0qf5kqHY/SYsJDeGNmhCfq0dpNdQrN+OcXaLERUb/ZeSMP6E9fk+LkFo9tzcUMV4BUgvWFiYoL5o4LhYGWOE3GZugJORER1XX7/r+sj5f6LPZqik18jpUMiJiykb7ycbHRdQ5/8NxqX09g1RER1S7y3XMu8JacvvzmgtdLhUBkmLKR3nu7ii14tXVFQrMFbv5xm1xAR1ZnjcTew/OAVuf/RqGDYWZkrHRKVYcJCets1JCpOisqTK8reXIiIakOMj3v719NyDbNRHZvg4VZuSodEFTBhIb0klnSfM6S0a2jh9vO4mp6rdEhEpOeW7InBhZSbaGxnib8Pa6N0OHQbJiyk12X7wwIaI7+otGtILE5GRFQTF1Ny8PXui3J/7vA2aGRnqXRIdBsmLKS3RMXJhU+0h62lGQ7HZmDlYa7oTETVJ77szP71tG4l5sdCvJUOiarAhIX0mq+LLWaXregsFieLz8hTOiQi0jM/HrqK43GZsLcyx4cj28lxcqQ+TFhI74l1hro2c0FeYYn8liQWKyMiehBi+vLCbaUrMc8e1BreXIlZtZiwkGF0DY1uD2sLUxyMScfqI3FKh0REekB8uREF4sRKzJ39G+G5blyJWc2YsJBBaOpqh1kDS7uG5m85L781ERHdy8pDV2UJflF2f8HoYK7ErHJMWMhgiBLaof6NcLOguKyWAruGiKhqMWk38Y8t5+T+24MC0cKdKzEbXMKyb98+DB8+HN7e3nJg0saNGys9Lz4k5s6dCy8vL9jY2KB///64eLF0qli5jIwMPPfcc3B0dISzszMmTJiAmzdZYp1qx6xs1pCVuSn+vHgdPx+LVzokIlKhohINZqw5KUsi9GzhKr/skPpVO2HJzc1FSEgIFi9eXOXzCxcuxJdffomlS5fi8OHDsLOzw8CBA5Gfn687RiQrUVFR2LFjBzZv3iyToEmTJtXuTIgANHezxxsDWsn9DzefQ1IWu4aIqLIv/riIyGtZcLKxwCdPhrArSE+YaGvRbi5aWDZs2ICRI0fK++JXiZaXN954A2+++aZ8LCsrCx4eHli+fDnGjBmDc+fOoU2bNjh69Cg6d+4sj9m2bRuGDBmChIQE+fP3k52dDScnJ/m7RSsNUUVibaHRSw7iZHwmHmnthu9f7MJpikQkHbuSgae+CYeoM7n42U4Y2t5L6ZCMSnYtPr/rdAxLbGwskpOTZTdQORFYt27dEB4eLu+LW9ENVJ6sCOJ4U1NT2SJTlYKCAnmSFTeie3UNffJkezmQbnd0GtYcZdcQEQE5+UV4/eeTMlkZ1akJkxU9U6cJi0hWBNGiUpG4X/6cuHV3d6/0vLm5OVxcXHTH3G7+/Pky8SnffH196zJsMkBiAN2bZV1D72+KwqXUHKVDIiKFzdt0FvEZt9DE2QbvPdZW6XDIEGcJzZkzRzYflW/x8fzGTPf3cs8A9GrpKgfWTf9JDLArUTokIlLItjNJWBeRANE7/NnTHeBobaF0SKRkwuLp6SlvU1JSKj0u7pc/J25TU1MrPV9cXCxnDpUfczsrKyvZ11VxI7ofMZDu/54MgYudJc4lZePjsmqWRGRcUrPzMWd9pNyf/HBzWRmbjDxhadasmUw6du7cqXtMjDcRY1PCwsLkfXGbmZmJiIgI3TG7du2CRqORY12I6pK7o7UczyIsO3AFu89XTpaJyLCJySBv/nIaN/KK0NbbEa/3L+0qJiNIWES9lJMnT8qtfKCt2I+Li5MzMWbMmIEPP/wQv/32GyIjIzFu3Dg586d8JlFQUBAGDRqEiRMn4siRIzhw4ACmTZsmZxA9yAwhourqG+ihq7Pw5rpT8tsWERmHH8KvYt+FNFmf6YsxHeRgfNJP1b5yx44dQ8eOHeUmzJw5U+6LYnHCW2+9henTp8u6Kl26dJEJjpi2bG1trfsdq1atQmBgIPr16yenM/fs2RPffvttXZ4XUSVvDw5EkJcj0nML8ca6U3I5eSIybGKw/Udl1Wz/OiSI1WyNuQ6LUliHhWr65jXsq/1yEO5fhwRiUu/mSodERPWksFiDx/95AFGJ2ejdyg0rxrMekxqopg4LkZqJb1dzh5VOZVy0PRqRCVlKh0RE9eTzPy7IZKWRrQUWPdGeyYoBYMJCRuWZrr4Y1NYTRSVavLrmBHILipUOiYjq2JHYDCzZGyP3548Khofj/4YkkP5iwkJGRXzLEsvIezlZI/Z6Lt79LUrpkIiorqvZrj0JMdjhyVAfDGrHaraGggkLGR1nW0t8/nQHiPXOfolIwG+nEpUOiYjqgBiSOfvX07iWeQu+LjZ4l9VsDQoTFjJK3QIaY9ojLeT+39ZHIj4jT+mQiKiWvj9wBVsik2FhZoIvx3SEvZW50iFRHWLCQkbr1X4tEerfCDkFxXhtzQkUl2iUDomIarEK8/yyKczvDG2Djn6NlA6J6hgTFjJa5mamsmvIwdocx+My8cXOi0qHREQ1cP1mAaauPo5ijRbDQ7wxLsxf6ZCoHjBhIaPm62KLjx4Plvtf776EQ5fTlQ6JiKqhRKOVLaQp2QVo4W6PBaOCOYXZQDFhIaMnvpGJ2QRiVoF440vNYel+In3x2Y4LOHApHbaWZlj6fCfYcdyKwWLCQgTgvcfaoqW7vfyWNnXVcVklk4jUbee5FNkyKiwY3Z6l9w0cExYiQH4r+2ZsKByszHH0yg18+PtZpUMionsQM/tEvRXhhTB/PBbCxXMNHRMWojIBbvb4fEwH3QqvPx+LVzokIqpCflEJpqyKQHZ+MTr4OuNvQ9soHRI1ACYsRBX0C/LAjP4t5f47G8/gVHym0iER0W3e33QWZ66VrhO0+LlOsDTnR5kx4FUmus2rfVuif5C7HMcyeWWEnDJJROrwa0QCfjoSBzER6IsxHdHE2UbpkKiBMGEhuo2pqQk+fboDAlztkJSVLwfhFrGoHJHizidn428bI+X+jH6t0LuVm9IhUQNiwkJUBUdrC3w7LhR2lmY4HCsqaJ5XOiQio5adX4QpK48jv0iDh1u5YXrf0qU1yHgwYSG6CzFF8v+eKh2E+/2BWGw4kaB0SERGu6jhW+tOyxXWRReQXLxUrF5KRoUJC9E9DGrnqfsm9/avkThzLUvpkIiMznf7Y7EtqnRRQzHItpGdpdIhkQKYsBDdx4z+rdCntRsKijV45ccIZOQWKh0SkdHYE52Kj8oWNZw7rI2cxkzGiQkL0X2YmZrgi6c7wr+xLa5l3sL0n45zZWeiBhpkO231CWi0kMtnPN+dixoaMyYsRA/AydYC347tLNcrEeuWLNoerXRIRAYtNTsfLy07ipsFxQgLaIx/PM5FDY0dExaiB9Ta0wGLngiR+9/su4xNpxKVDonIIN0qLMHLPxxDYlY+AtzssPT5UBaHIyYsRNUxtL0XJj/cXO6/9ctpRCVyEC5RXdJotHKNoNMJWbKS7bIXu8gWTiImLETVNGtga/Rq6YpbRSUYv+woEm7kKR0SkcH4eNt5OSPI0swU347rDP/GdkqHRCrBhIWoBoNwv362E1p7OCA1pwAvLjuKrLwipcMi0nui5L7obhUWPtEeXZq6KB0SqQgTFqIacLKxwLLxXeDpaI1LqTcx8YdjcgVZIqqZ/RevywVHBbEA6ciOTZQOiVSGCQtRDXk722D5S13gYGWOI1cy8MbPp2T/OxFVz8WUHExZFYESjRaPd2yC1/qVrphOVBETFqJaCPR0xDfjQmUFzt8jk/Dh76UFrojowYjV0McvP4qc/GJ0adoIC0Zz+jJVjQkLUS31aO6KT54M0a059O8/S/vgiejeRDeq6E5NuHFLFmb8ZmxnWJmbKR0WqRQTFqI6MKJDE8wZHCj3RSsLa7QQ3ZvoPn1j3SmciMuUY8K+f7ELXLhGEN0DExaiOjKpdwBe7NFU7ovxLOEx6UqHRKRan+64gN9PJ8nuVFEYrrmbvdIhkcoxYSGqI6Lf/e/D2mBQW08Ulmgw6cdjuJCSo3RYRKqz5kgcvt59Se5/9Hgwwpo3Vjok0gNMWIjquEbL52M6oLN/IzmI8IXvjyA5K1/psIhU4z8nr2HOhki5P/WR5niys6/SIZGeYMJCVMesLczw7xc6o7mbHZKy8vHisiPIzmdhOaJtZ5Ix8+dT0GqB57r54c0BrZUOifQIExaieuBsa4nl47vCzcEK55NzMPnHCBQWa5QOi0gxu6NTMf2n47LWyuhOPvhgRDtOX6ZqYcJCVE98XWzlwm12lmY4GJOON9edkm/WRMZGDEAXSXtRiVYuIPrx6GCYmjJZoephwkJUj9o1ccKS50NhbmqC304lYtYvTFrIuERcvYEJK46ioFiD/kHu+PzpDjA340cPVR//aojqWe9WbvjymY5yQO7649eYtJDROHMtCy9+fwR5hSVyhXOxaKgFkxWqoTr/y3nvvfdkv2TFLTCwtKCWkJ+fj6lTp6Jx48awt7fH6NGjkZKSUtdhEKnKkGAvfMWkhYxIdHIOxn53GDkFxeja1AXfjA2VA9KJaqpeUt22bdsiKSlJt+3fv1/33Ouvv45NmzZh3bp12Lt3LxITEzFq1Kj6CINIVZi0kLG4nHYTz/37MG7kFSHE1xnfvdgZtpbmSodFeq5e/oLMzc3h6el5x+NZWVn47rvvsHr1avTt21c+tmzZMgQFBeHQoUPo3r17fYRDpKqkRZj+0wmZtAiLngiRSQyRIYjPyJPJiljUMMjLESvGd4GDtYXSYZEBqJcWlosXL8Lb2xsBAQF47rnnEBcXJx+PiIhAUVER+vfvrztWdBf5+fkhPDz8rr+voKAA2dnZlTYifcWWFjJUokiiSFZE/SFRh+jHCV3lFH8iVSYs3bp1w/Lly7Ft2zYsWbIEsbGx6NWrF3JycpCcnAxLS0s4OztX+hkPDw/53N3Mnz8fTk5Ous3Xl5URybCSlrd+Oc2khfSaaFF57t+HEJeRJ1deXj2xO1ztrZQOiwxInXcJDR48WLffvn17mcD4+/vj559/ho2NTY1+55w5czBz5kzdfdHCwqSFDCFpERU/X11zAr8eT5CPLXyiPbuHSO+k5RTIAbYxabnwdrLGqpe7wcPRWumwyMDU+/wy0ZrSqlUrXLp0SY5rKSwsRGZmZqVjxCyhqsa8lLOysoKjo2OljcgQiCJaX44pbWkRSQtbWkjfxKXn4YmlB2VFZ1HZedXE7vBpZKt0WGSA6j1huXnzJmJiYuDl5YXQ0FBYWFhg586duuejo6PlGJewsLD6DoVIlZi0kL46l5SN0UsP4mp6HnxdbLDulTA0c7VTOiwyUHXeJfTmm29i+PDhshtITFl+9913YWZmhmeeeUaOP5kwYYLs3nFxcZEtJdOnT5fJCmcIkbEnLQK7h0hfHInNkBVsxarkgZ4O+OGlrnBnNxDpU8KSkJAgk5P09HS4ubmhZ8+ecsqy2Bc+++wzmJqayoJxYvbPwIED8c9//rOuwyDS+6Qlv6gE//dUCIttker8cTYFU1cfl+X2RVG4f73QGU42nLpM9ctEqxXD/vSLGHQrWmtEXReOZyFDsyUyCa+tOSEXiuvs3wj/GtcZjew4NZTUYd2xeLy9PlJ2W4q1gUS5fSbV1BCf31zUgUiFs4dWvNQVDtbmOHb1BkYtEWMEcpUOiwjf7I3BrLIxVk+E+mDp8yy3Tw2HCQuRCvVo7or1U3qgibMNYq/nYtQ/D+JE3A2lwyIjJRri5285h/lbz8v7k3oHYNET7bnqMjUo/rURqVRLDwdsmNoD7Zo4Ij23EM/86xC2R929wCJRfSgu0chWlW/2XZb35wwOxF+HBMmFbYkaEhMWIhVzd7DG2klh6BvojvwiDSavjMD3+2OVDouMhBj4Lf7mfolIkDPWxMy1Vx5urnRYZKSYsBCpnJ2VOb4dG4rnuvnJyrjzNp/FvE1nWauF6lXWrSKM++4I/jiXCitzUzle5anOrDBOymHCQqQHxFiBD0e2w9uDA+X97w/EYuqq4/IbMFFdu5iSg8cXH8CRKxly8LeosfJoGw+lwyIjx4SFSE+IMQOTH24uF020NDPFtqhkOa4l/WaB0qGRAfn9dBJGLD6Ay9dL1wUSXZLdAhorHRYRExYifTM8xBsrX+4mC3WdiMuU057FTCKi2g6u/WjLOVkQLq+wBD2aN8am6T3Rxpu1rkgdmLAQ6aGuzVzw65Qecv0WsY7LyMUHZPVRopoQrXRjvzuCb8tmAr3SO0B2AzW2t1I6NCIdJixEeqqFuz3WT3kIHXyd5QDJl384hg83n0VhsUbp0EiPnIrPxPCv9iP8cjpsLc2w+NlOmDMkiDVWSHX4F0mkx9wcrLD2le546aFm8v6/98fiyW/CEZ+Rp3RopAfWHInDk0vDkZiVjwBXO/xn6kO6Na2I1IYJC5GeszI3w9zhbeTUZ0drc/mNeeiXf2LbGRaZo6oVFJdgzvrTck2gwhKNnAG0cdpDslghkVoxYSEyEAPaemLLa73Q0c8Z2fnFsuDXe79FyQ8nonKJmbfw1NJw/HQkHqJY7ayBrfHN8yLZ5WrLpG5MWIgMiE8jW/z8SpgcNCksP3gFTywJ5+KJJB2MuS7Hq5xKyIKzrQWWj++KqY+0gKkpy+yT+jFhITIwFmamctDk9y92RiNbC0Rey8LQL/dj8+lEpUMjhYgCg2LK8vP/PizXpWrj5YhN03ri4VZuSodG9MCYsBAZqL6BHrKLqEvTRrhZUIxpq0/gbxsiWR3XyBy7koEhX/wppyyL1RyeCPXB+r+IKfG2SodGVC0mWrFuuJ7Jzs6Gk5MTsrKy4OjIokZE9ysI9umOC/jnnhh5P9DTQVbL5QBLw5ZXWIxF26Nlt6B4l/dwtMI/RgajP0vsk55+fjNhITISey+kYebak7JLwMLMBJN6B2DaIy1hY2mmdGhUx8Jj0jH719OIK5ve/mSoD94Z1kZWRyZSEhMWInogKdn5+Ov6SOw8nyrvi0q5H4xohz6t3ZUOjepAbkExFmw9jx8PXZX3vZysMX9UMK8vqQYTFiJ6YOIlvz0qBe9vikJSVr58bGiwF/4+rA08nayVDo9qaP/F67JV5VrmLXn/ma5++OuQQDhwujKpCBMWIqo2MRD38x0XsOzgFZRotLC3MscbA1phXFhTmHGaq97Izi/C/C3nZF0VoYmzDT4e3R49W7oqHRrRHZiwEFGNRSVm4W8bzuBkfKa8366JIz56PBjtfZyVDo3uQbx1//dsiiwOWN5SNi7MH28NCpTJJ5EaMWEholrRaLT46WgcPt56XlbJFRVQx3X3xxsDW7MCqgodvpyOj7edx/G40iTTv7GtbFXpHtBY6dCI7okJCxHVibScAllgbMOJa7rFFd8ZGoTh7b1ZDVUFziZmY+H289gTnSbvW1uYyoUvp/VtAVtLtqqQ+jFhIaI6dfDSdbyz8QwuXy8t6d/aw0F+KA4J9uL4FgWIpRVELZ3/nCytVmxuaoIxXX3xat+WcHfkQGnSH0xYiKjOiUUTv917WVZIzSkolo81d7OTiYtocTE3Y6Hs+paak4+vdl7CT0fiUCzK1AIYHuKNNx5thaaudkqHR1RtTFiIqN5k3SrC8gNX8P2BWLkvNG1si7880gKPd2wi1y6iup/5I5LF7/bH4lbZUgpi3R+xsnK7Jk5Kh0dUY0xYiKje5eQX4Yfwq/j3n5dxI680cfFpZIO/9GmB0aFNYGXOirl1kaisORInl1HILPt/3MHXGbMHBSKsOQfUkv5jwkJEDVpNddXhq/h2Xyyu3yzQVVSd/HBzPN3FF9YWTFyq63RCJlYdisNvpxJ1LSot3O1li8qANh4wEdO2iAwAExYianBi1WcxtmLp3hikZBfoZhWN7e4vu4q4GvD9Ez8xiHb1kas4cy1b93hLd3tM7B2A0Z18OMCZDE42ExYiUjJxWReRgKV7YnRl4YUuTRvh8Y4+suy/ky1ruVScmixaqESyIqoNC5bmphjSzhPPdfdHZ/9GbFEhg5XNhIWIlFZYrMHm04n49XgCDsako/ydxdLMFH0D3fF4pybo09rNKMe63Coskf9vVh2O01UUFpq52uHZrn4YHeoDFztLRWMkaghMWIhIVZKybuG3k4myAN355Bzd4042FhjW3gujOjVBJz/DbknIyivCgZjr2HchDVsik2QF4fIaKgNFa0pXPzmQ1pD/HxDdjgkLEam6C2TjyWvYeOIaUnNKx7oIfi62eCzEGz1aNJYzYfS9UqtYQPJUQqZMUMQmWlLKSqfoZlQ9280PT4b6yrE+RMYomwkLEenDB3p4TDrWn0jAtjPJyCssnQ1T3urQtokTuvg3QuemLujctBFc7dX/oZ6YeQt/XhQJynXsv3RdV6emnJjp06ulK/oFeqBH88Zc3oCMXjYTFiLSJ3mFxfhvVAr+OJeCY1duIDm7dLXhigJc7WTiIhKYLk1dZLE6pbpPxNvk9ZuFiL2ei9jrN3EuKUcmKJdSb1Y6ztHaHD1buqJ3Szf0auWGJs42isRLpFZMWIhIb4m3IDG7SCQuR69kyNvolP+Neynnam+JVh4O8HSyhqejtbz1ELeO1rIOTGN7q1pPAxazdq5cz5VrKF1Ou1mWoOQiNi1XtzxBReKfE91ZvVq6oXcrN4T4OHHJAqJ6+vzW705jItJ7otXEp5Gt3EZ2bKIbsHo87n8JzMmETNnCcf1m+l1/j0hW3B2sdEmMq4OlnKlUVKJBcYkWhWW3xRoNCsVtiUY+V1SilbdipeqKY2zujLN0HEozV3vZ+tO1mQseau7KKdtEDUTRFpbFixdj0aJFSE5ORkhICL766it07dr1vj/HFhYi41uIURRXi8vIRXJWAVKy8+VMpOTsAqRk5ctFAisOcK0N0ZIjphuXbvYIcLOTCYoohMcqvkRG2MKydu1azJw5E0uXLkW3bt3w+eefY+DAgYiOjoa7u7tSYRGRConaLaH+jeRWFdFaIlpgxFiY5Kx8mdCk3yyQg1zF4owWZiYwNzWFhbkpLMoeMzcrf650v5FtaaIipl4Tkfoo1sIikpQuXbrg66+/lvc1Gg18fX0xffp0vP322/f8WbawEBER6Z/afH4rMjqssLAQERER6N+///8CMTWV98PDw+84vqCgQJ5kxY2IiIiMhyIJy/Xr11FSUgIPD49Kj4v7YjzL7ebPny8zsvJNtMQQERGR8dCL+Xdz5syRzUflW3x8vNIhERERUQNSZNCtq6srzMzMkJKSUulxcd/T0/OO462srORGRERExkmRFhZLS0uEhoZi586dusfEoFtxPywsTImQiIiISMUUm9YspjS/8MIL6Ny5s6y9IqY15+bmYvz48UqFRERERCqlWMLy9NNPIy0tDXPnzpUDbTt06IBt27bdMRCXiIiIiGsJERERUYPQuzosRERERNXBhIWIiIhUjwkLERERqR4TFiIiIlI9JixERESkeopNa66N8olNXASRiIhIf5R/btdkgrJeJiw5OTnylosgEhER6efnuJjebPB1WEQZ/8TERDg4OMDExKTOsz+RCIkFFg21xosxnKPA8zQsPE/DYQznKPA87yRSDpGseHt7w9TU1PBbWMRJ+vj41Ou/If6nG/IfmLGco8DzNCw8T8NhDOco8Dwrq27LSjkOuiUiIiLVY8JCREREqseE5TZWVlZ499135a2hMoZzFHiehoXnaTiM4RwFnmfd0stBt0RERGRc2MJCREREqseEhYiIiFSPCQsRERGpHhMWIiIiUj2jS1j+8Y9/oEePHrC1tYWzs3OVx8TFxWHo0KHyGHd3d8yaNQvFxcX3/L0ZGRl47rnnZNEc8XsnTJiAmzdvQg327NkjKwJXtR09evSuP9enT587jp88eTLUrGnTpnfEvGDBgnv+TH5+PqZOnYrGjRvD3t4eo0ePRkpKCtTqypUr8u+rWbNmsLGxQfPmzeUI/cLCwnv+nD5cz8WLF8traG1tjW7duuHIkSP3PH7dunUIDAyUxwcHB2PLli1Qs/nz56NLly6ySrd4bxk5ciSio6Pv+TPLly+/47qJ81Wz9957746YxXUypGtZ1XuN2MR7iT5fx3379mH48OGyEq2IcePGjZWeF/N05s6dCy8vL/n+079/f1y8eLHOX9tVMbqERbypP/nkk5gyZUqVz5eUlMhkRRx38OBBrFixQv6hiQt0LyJZiYqKwo4dO7B582Z50SdNmgQ1EAlaUlJSpe3ll1+WH3idO3e+589OnDix0s8tXLgQajdv3rxKMU+fPv2ex7/++uvYtGmTfMPcu3evXPZh1KhRUKvz58/L5Sm++eYb+Tf32WefYenSpfjrX/96359V8/Vcu3YtZs6cKZOv48ePIyQkBAMHDkRqamqVx4vX5zPPPCOTtxMnTsgPf7GdOXMGaiX+vsQH2qFDh+R7RVFREQYMGIDc3Nx7/pz4IlTxul29ehVq17Zt20ox79+//67H6uO1FF/2Kp6fuJ6C+HzR5+uYm5srX3siwaiKeM/48ssv5XvO4cOHYWdnJ1+n4otfXb2270prpJYtW6Z1cnK64/EtW7ZoTU1NtcnJybrHlixZonV0dNQWFBRU+bvOnj0rpoZrjx49qnts69atWhMTE+21a9e0alNYWKh1c3PTzps3757HPfzww9rXXntNq0/8/f21n3322QMfn5mZqbWwsNCuW7dO99i5c+fk9QwPD9fqi4ULF2qbNWum19eza9eu2qlTp+rul5SUaL29vbXz58+v8vinnnpKO3To0EqPdevWTfvKK69o9UVqaqr8W9u7d2+136vU7N1339WGhIQ88PGGcC3Fa6t58+ZajUZjMNcRgHbDhg26++LcPD09tYsWLar0HmplZaX96aef6uy1fTdG18JyP+Hh4bI50sPDQ/eYyATF4k7i2+zdfkZ0A1VsrRDNZGLNI5GBqs1vv/2G9PR0jB8//r7Hrlq1Cq6urmjXrh3mzJmDvLw8qJ3oAhLdOx07dsSiRYvu2Z0XEREhv+WK61VONEv7+fnJ66ovsrKy4OLiorfXU7RoimtR8TqI14+4f7frIB6veHz5a1Xfrptwv2snupf9/f3lAnMjRoy463uRmohuAtGtEBAQIFugRVf73ej7tRR/vytXrsRLL710zwV59fE6VhQbG4vk5ORK10qsCyS6eO52rWry2jaoxQ/rk7gYFZMVofy+eO5uPyP6oysyNzeXb0J3+xklfffdd/LN4H4LSD777LPyxSXedE6fPo3Zs2fL/vb169dDrV599VV06tRJ/r8XzcziQ1k0vX766adVHi+uj6Wl5R3jmcQ1V+O1q8qlS5fw1Vdf4ZNPPtHb63n9+nXZHVvVa090gVXntaov1010682YMQMPPfSQTCDvpnXr1vj+++/Rvn17meCI6yy6ecWHXX0vAltT4gNMdKWL2MXr7/3330evXr1kF48Yv2No11KM88jMzMSLL75oUNfxduXXozrXqiavbYNOWN5++218/PHH9zzm3Llz9x30ZQznnZCQgO3bt+Pnn3++7++vOAZHtDqJQVb9+vVDTEyMHOipxvMU/aTlxBuDSEZeeeUVOdhR7eWxa3I9r127hkGDBsl+czE+RR+uJ5USY1nEB/i9xnYIYWFhcisnPuSCgoLkGKYPPvgAajR48OBKr0ORwIhkWbzviHEqhkZ8CRTnLL4MGNJ1VBuDSFjeeOONe2a2gmiWfBCenp53jF4unzEinrvbz9w+eEh0Q4iZQ3f7GaXOe9myZbK75LHHHqv2vyfedMq/0TfkB1xtrq+IWVwLMbNGfMO5nbg+oslSfDuq2Moirnl9Xru6OE8xOPiRRx6Rb3zffvut3lzPqohuKjMzsztmZ93rOojHq3O8mkybNk03OL+6364tLCxkd6e4bvpCvLZatWp115j1+VqKgbN//PFHtVsq9fE6epZdD3FtxBeecuJ+hw4d6uy1fVdaI3W/QbcpKSm6x7755hs56DY/P/+eg26PHTume2z79u2qG3QrBkyJgZlvvPFGjX5+//798jxPnTql1RcrV66U1zMjI+Oeg25/+eUX3WPnz59X/aDbhIQEbcuWLbVjxozRFhcXG8T1FAPzpk2bVmlgXpMmTe456HbYsGGVHgsLC1P1QE3xGhSDD8WAwwsXLtTod4jr3bp1a+3rr7+u1Rc5OTnaRo0aab/44guDuZYVBxiLgahFRUUGdx1xl0G3n3zyie6xrKysBxp0W53X9l3j0RqZq1evak+cOKF9//33tfb29nJfbOIFVf5H1K5dO+2AAQO0J0+e1G7btk3OqJkzZ47udxw+fFj+oYkPjXKDBg3SduzYUT4nPgjEh8kzzzyjVZM//vhD/gGKWTC3E+cizknEL1y6dEnOIhJJWGxsrPY///mPNiAgQNu7d2+tWh08eFDOEBLXLSYmRiYr4tqNGzfurucpTJ48Wevn56fdtWuXPF/xRik2tRLn0KJFC22/fv3kflJSkm7T5+u5Zs0a+ca3fPly+SVg0qRJWmdnZ92MvbFjx2rffvtt3fEHDhzQmpubyzdP8TctPjhE8hkZGalVqylTpsgvSnv27Kl03fLy8nTH3H6e4r1KfAESf9MREREySbW2ttZGRUVp1Up8KRLnKP7WxHXq37+/1tXVVc6KMpRrWf7BK947Zs+efcdz+nodc3JydJ+L4vPi008/lfvis1NYsGCBfF2K95DTp09rR4wYIb8I37p1S/c7+vbtq/3qq68e+LX9oIwuYXnhhRfkRbh92717t+6YK1euaAcPHqy1sbGRLzLx4quYPYtjxc+IF2O59PR0maCIJEi0xowfP16XBKmFiK9Hjx5VPifOpeL/h7i4OPlh5uLiIv/QxAfkrFmzZDatVuJNQEyFFB8I4o0gKChI+9FHH1VqGbv9PAXxQvvLX/4ivwHa2tpqH3/88Uof/mpsHazqb7hig6m+Xk/xJic+ACwtLeW3skOHDlWali1evxX9/PPP2latWsnj27Ztq/3999+1ana36yau6d3Oc8aMGbr/Jx4eHtohQ4Zojx8/rlWzp59+Wuvl5SVjFt+kxX2RNBvStRREAiKuX3R09B3P6et13F32+Xb7Vn4uopXl73//uzwH8V4ivjjdfv6ivIRIOh/0tf2gTMR/atKXRURERNRQWIeFiIiIVI8JCxEREakeExYiIiJSPSYsREREpHpMWIiIiEj1mLAQERGR6jFhISIiItVjwkJERESqx4SFiIiIVI8JCxEREakeExYiIiJSPSYsREREBLX7f8X/QAC6d2feAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-10, 10, 0.5)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "08cde3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "71c90bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = -2\n",
    "c = 1\n",
    "d1 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "id": "4e7752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c + h\n",
    "d2 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "id": "c7b273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dc_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dc_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "id": "68d78e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -5.000002\n",
      "da_dy =  -2.000000000279556\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "a = a + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"da_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "id": "49ed6158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.9999970000000005\n",
      "db_dy =  2.9999999995311555\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "b = b + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"db_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "c4f10ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dab_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "d2 = a*b + h + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dab_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "id": "e5c68b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    \"\"\" Basic class to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "        else:\n",
    "            raise ValueError(\"Can only add Value to Value\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "id": "077e5615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d._prev = (Value(data=-6), Value(data=1)) d = -5\n"
     ]
    }
   ],
   "source": [
    "a = Value(3, label=\"a\")\n",
    "b = Value(-2, label=\"b\")\n",
    "c = Value(1, label=\"c\")\n",
    "d = a*b + c; d.label = \"d\"\n",
    "print(f\"d._prev = {d._prev} d = {d.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "db81115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(root):\n",
    "    \"\"\" Vibe codded and it works! \"\"\"\n",
    "    # Initialize a directed graph\n",
    "    dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})  # Left-to-right layout\n",
    "    \n",
    "    def build_graph(node, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        \n",
    "        # Skip if node already visited to avoid cycles\n",
    "        if id(node) in visited:\n",
    "            return\n",
    "        visited.add(id(node))\n",
    "        \n",
    "        # Add node to the graph\n",
    "        node_id = str(id(node))\n",
    "        dot.node(node_id, f\"{{ {node.label} | data = {node.data} grad={node.grad} }}\", shape='record')\n",
    "        \n",
    "        # If node has an operation, create an operation node\n",
    "        if node._op:\n",
    "            op_id = f\"{node_id}_op\"\n",
    "            dot.node(op_id, node._op, shape='circle')\n",
    "            dot.edge(op_id, node_id)  # Edge from operation to result\n",
    "        \n",
    "            # Recursively process children\n",
    "            for child in node._prev:\n",
    "                child_id = str(id(child))\n",
    "                build_graph(child, visited)\n",
    "                dot.edge(child_id, op_id)  # Edge from child to operation\n",
    "    \n",
    "    # Build the graph starting from the root\n",
    "    build_graph(root)\n",
    "    \n",
    "    # Render and display the graph\n",
    "    dot.render('computation_graph', view=True, cleanup=True)\n",
    "    \n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "84c181f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "id": "98dd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "id": "68ed37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142981514304\n"
     ]
    }
   ],
   "source": [
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "ec8210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "id": "70612029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "daba22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "922f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_dn = 1 - math.tanh(o.data)**2\n",
    "y.grad = do_dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "72a71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "2a71919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1_x2w2.grad = y.grad\n",
    "b.grad = y.grad\n",
    "x1w1.grad = x1w1_x2w2.grad\n",
    "x2w2.grad = x1w1_x2w2.grad\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "ef9473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = x1w1.grad * w1.data\n",
    "x2.grad = x2w2.grad * w2.data\n",
    "w1.grad = x1w1.grad * x1.data\n",
    "w2.grad = x2w2.grad * x2.data\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1731,
   "id": "d7edad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement generic backpropagation\n",
    "class Value():\n",
    "    \"\"\" Complete class with backprop to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "\n",
    "    def backward(self, root_node, visited=None):\n",
    "        visited.add(self)\n",
    "        logger.debug(f\"node.data = {self.data}\")\n",
    "        self._backward()  # Compute the gradient for childeren of this node\n",
    "        for item in self._prev:\n",
    "            if item not in visited:\n",
    "                item.backward(root_node, visited)\n",
    "\n",
    "    def _backward(self):\n",
    "        \"\"\" Perform backpropagation to compute gradients. \"\"\"\n",
    "        logger.debug(f\"Backward pass for node: {self.label}, op: {self._op}, data: {self.data}, grad: {self.grad}\")\n",
    "        # For addition operation, local gradient is 1 for each child hence gradient of the child with respect\n",
    "        # to the output is 1 * self gradient.\n",
    "        # Note, we need to accumulate gradients for each child and not simply overwrite them.\n",
    "        if self._op == '+':\n",
    "            for child in self._prev:\n",
    "                child.grad += self.grad\n",
    "\n",
    "        # For multiplication operation, local gradient is the value of the other child hence\n",
    "        # gradient of the child with respect to the output is self.grad * other child's value.\n",
    "        elif self._op == '*':\n",
    "            self._prev[0].grad = self.grad * self._prev[1].data\n",
    "            self._prev[1].grad = self.grad * self._prev[0].data\n",
    "\n",
    "        elif self._op == '/':\n",
    "            # For division operation, local gradient is 1 / other child's value hence\n",
    "            # gradient of the child with respect to the output is self.grad * (1 / other child's value).\n",
    "            self._prev[0].grad = self.grad / self._prev[1].data\n",
    "            self._prev[1].grad = -self.grad * (self._prev[0].data / (self._prev[1].data ** 2))\n",
    "\n",
    "        # For power operation, local gradient is power * base^(power-1) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == '**':\n",
    "            base = self._prev[0].data\n",
    "            power = self._prev[1].data\n",
    "            self._prev[0].grad = self.grad * power * (base ** (power - 1))\n",
    "            print(f\"Power operation: base = {base}, power = {power}, grad = {self.grad}\")\n",
    "\n",
    "        # For subtraction operation, local gradient is 1 for the first child and -1 for the second child\n",
    "        # hence gradient of the first child with respect to the output is self.grad * 1 and for the second child\n",
    "        # it is self.grad * -1.\n",
    "        elif self._op == '-':\n",
    "            self._prev[0].grad = self.grad  # First child\n",
    "            self._prev[1].grad = -self.grad  # Second child\n",
    "\n",
    "        # For tanh operation, local gradient is 1 - tanh^2(self.data) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == 'tanh':\n",
    "            logger.debug(f\"tanh: self.data = {self.data}, self.grad = {self.grad}\")\n",
    "            self._prev[0].grad = self.grad * (1 - np.tanh(self._prev[0].data)**2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data - other.data, _children=(self, other), _op='-')\n",
    "        else:\n",
    "            raise ValueError(\"Can only subtract Value from Value\")\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "        \n",
    "    def __pow__(self, power):\n",
    "        return Value(self.data ** power, _children=(self,Value(power)), _op='**')\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "id": "de7dc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "id": "b1415a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1734,
   "id": "65eb5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0\n",
    "\n",
    "visited = set()\n",
    "o.backward(o, visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1735,
   "id": "b9b0f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1736,
   "id": "160da944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142868995667\n"
     ]
    }
   ],
   "source": [
    "# Verfiy with PyTorch\n",
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2.0])\n",
    "x2 = torch.Tensor([3.0])\n",
    "w1 = torch.Tensor([0.5])\n",
    "w2 = torch.Tensor([-1.5])\n",
    "b = torch.Tensor([1.0])\n",
    "x1.requires_grad = True\n",
    "x2.requires_grad = True\n",
    "w1.requires_grad = True\n",
    "w2.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "y = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(y)\n",
    "\n",
    "print(f\"o = {o.item()}\")\n",
    "\n",
    "o.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "id": "182b150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.grad = 0.013296124525368214\n",
      "x2.grad = -0.039888374507427216\n",
      "w1.grad = 0.053184498101472855\n",
      "w2.grad = 0.07977674901485443\n",
      "b.grad = 0.026592249050736427\n"
     ]
    }
   ],
   "source": [
    "print(f\"x1.grad = {x1.grad.item()}\") \n",
    "print(f\"x2.grad = {x2.grad.item()}\") \n",
    "print(f\"w1.grad = {w1.grad.item()}\")\n",
    "print(f\"w2.grad = {w2.grad.item()}\")\n",
    "print(f\"b.grad = {b.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "id": "f1702ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "class N():\n",
    "    \"\"\" Class to represent a single neuron with forward and backward pass. \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "        self.weights = [Value(random.uniform(-1, 1)) for _ in range(input_size)]\n",
    "        self.b = Value(random.uniform(-1, 1))  # Bias term\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.b]  # Return all parameters (weights and bias)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None) -> Value:\n",
    "        \"\"\" Forward pass for the neuron. \"\"\"\n",
    "        assert len(input) == self.input_size, f\"Input size {len(input)} does not match expected size {self.input_size}\"\n",
    "        wx = [w*x for w, x in zip(self.weights, input)]\n",
    "        wx_sum = Value(0.0)  # Initialize sum of weighted inputs\n",
    "        for item in wx:\n",
    "            wx_sum += item  # Sum the weighted inputs\n",
    "\n",
    "        wx_sum = wx_sum + self.b\n",
    "        if act_fn is None:\n",
    "            return wx_sum\n",
    "        elif act_fn == 'tanh':\n",
    "            return wx_sum.tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {act_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "id": "95f55a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -2.742169638094225\n"
     ]
    }
   ],
   "source": [
    "n = N(2)  # Create a neuron with 2 inputs\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "\n",
    "o = n([x1, x2])\n",
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "id": "f5d28c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\" Class to represent a layer of neurons. \"\"\"\n",
    "    def __init__(self, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.neurons = [N(input) for _ in range(output)]\n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for n in self.neurons:\n",
    "            parameters.extend(n.parameters())  # Collect parameters from each neuron\n",
    "        return parameters\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None):\n",
    "        \"\"\" Forward pass for the layer. \"\"\"\n",
    "        outputs = [n(input, act_fn) for n in self.neurons]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1741,
   "id": "29894ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class NN():\n",
    "    \"\"\" Class to represent a simple neural network with hidden layers. \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                 hidden_layer_num: int, \n",
    "                 hidden_layer_size: int, \n",
    "                 output_size: int):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_num = hidden_layer_num\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.forward_hook = None  # Hook for forward pass\n",
    "\n",
    "        self.layers = []\n",
    "        for i in range(hidden_layer_num):\n",
    "            if i == 0:\n",
    "                # First layer takes the input size\n",
    "                self.layers.append(Layer(input_size, hidden_layer_size))\n",
    "            elif i == hidden_layer_num - 1:\n",
    "                # Last layer is the output layer, use output_size\n",
    "                self.layers.append(Layer(hidden_layer_size, output_size))\n",
    "            else:\n",
    "                # Intermediate layers use hidden_layer_size\n",
    "                self.layers.append(Layer(hidden_layer_size, hidden_layer_size))\n",
    "           \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for layer in self.layers:\n",
    "            parameters.extend(layer.parameters())  # Collect parameters from each layer\n",
    "        return parameters\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def register_forward_hook(self, func: Callable[[str, list[Value], list[Value]], None]): \n",
    "        self.forward_hook = func\n",
    "\n",
    "    def __call__(self, input):\n",
    "        \"\"\" Forward pass for the neural network. \"\"\"\n",
    "        assert len(input) == self.input_size, \"input size mismatch\"\n",
    "\n",
    "        x = [Value(i) for i in input]\n",
    "        for num, layer in enumerate(self.layers):\n",
    "            if num != len(self.layers) - 1:\n",
    "                act_fn = 'tanh'\n",
    "            else:\n",
    "                act_fn = None\n",
    "            input = x.copy()\n",
    "            x = layer(x, act_fn)  # Forward pass through the layer\n",
    "            self.forward_hook(f\"Layer {num}\", [i.data for i in input], [o.data for o in x]) if self.forward_hook else None\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "id": "7e307dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # For reproducibility\n",
    "mlp = NN(input_size=3, hidden_layer_num=3, hidden_layer_size=4, output_size=1)  # Create a neural network with 2 inputs, 2 hidden layers of size 3, and 1 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "id": "b87ae772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model information:\n",
      "input size: 3\n",
      "total model layers: 3\n",
      "[0] layer input: 3, layer output: 4, neurons: 4\n",
      "[1] layer input: 4, layer output: 4, neurons: 4\n",
      "[2] layer input: 4, layer output: 1, neurons: 1\n",
      "total model parameters: 41\n",
      "model parameters:\n",
      "[tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]), tensor([-0.5536, -0.8261,  0.0107,  0.0899]), tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]), tensor([ 0.6116, -0.3268,  0.6143,  0.1041]), tensor([[0.6588, 0.2370, 0.7234, 0.1547]]), tensor([0.4091])]\n"
     ]
    }
   ],
   "source": [
    "print(\"model information:\")\n",
    "print(f\"input size: {mlp.input_size}\")\n",
    "print(f\"total model layers: {len(mlp.layers)}\")\n",
    "for i, layer in enumerate(mlp.layers):\n",
    "    print(f\"[{i}] layer input: {layer.input}, layer output: {layer.output}, neurons: {len(layer.neurons)}\")\n",
    "print(f\"total model parameters: {len(mlp.parameters())}\")\n",
    "\n",
    "# Build tensor parameters for the model, this will be used to set the parameters in PyTorch\n",
    "mlp_tensor_parameters = []\n",
    "print(\"model parameters:\")\n",
    "for layer_num, layer in enumerate(mlp.layers):\n",
    "    layer_params = []\n",
    "    bias_params = []\n",
    "    for neuron_num, neuron in enumerate(layer.neurons):\n",
    "        layer_params.append([x.data for x in neuron.parameters()][:-1])\n",
    "        bias_params.append([x.data for x in neuron.parameters()][-1])\n",
    "    mlp_tensor_parameters.append(torch.tensor(layer_params))\n",
    "    mlp_tensor_parameters.append(torch.tensor(bias_params))\n",
    "    \n",
    "print(mlp_tensor_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1796,
   "id": "4fb2c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch model with the same architecture for verification\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 4),  # First hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 4),  # Second hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1)   # Output layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def hook_fn(module, input, output, name=None):\n",
    "    \"\"\" Hook function to capture the output of each layer. \"\"\"\n",
    "    print(f\"Layer: {module}, Input: {input}, Output: {output}\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\" Calculate Root Mean Squared Error. \"\"\"\n",
    "    diffs = torch.stack([(y_true_i - y_pred_i) ** 2 for y_true_i, y_pred_i in zip(y_true, y_pred)])\n",
    "    return torch.mean(diffs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook for layer: \n",
      "Registering hook for layer: layers\n",
      "Registering hook for layer: layers.0\n",
      "Registering hook for layer: layers.1\n",
      "Registering hook for layer: layers.2\n",
      "Registering hook for layer: layers.3\n",
      "Registering hook for layer: layers.4\n",
      "model parameters = [Parameter containing:\n",
      "tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5536, -0.8261,  0.0107,  0.0899], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.6116, -0.3268,  0.6143,  0.1041], requires_grad=True), Parameter containing:\n",
      "tensor([[0.6588, 0.2370, 0.7234, 0.1547]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4091], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmlp = MLP(input_size=3)  # Create a PyTorch model with the same architecture\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "# Register hooks to capture the output of each layer\n",
    "for name, module in tmlp.named_modules():\n",
    "    print(f\"Registering hook for layer: {name}\")\n",
    "    module.register_forward_hook(hook_fn)\n",
    "\n",
    "print(f\"model parameters = {[p for p in tmlp.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1746,
   "id": "5df68e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model parameters:\n",
      "layers.0.weight: data: tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) grad=None\n",
      "layers.0.bias: data: tensor([-0.5536, -0.8261,  0.0107,  0.0899]) grad=None\n",
      "layers.2.weight: data: tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]) grad=None\n",
      "layers.2.bias: data: tensor([ 0.6116, -0.3268,  0.6143,  0.1041]) grad=None\n",
      "layers.4.weight: data: tensor([[0.6588, 0.2370, 0.7234, 0.1547]]) grad=None\n",
      "layers.4.bias: data: tensor([0.4091]) grad=None\n"
     ]
    }
   ],
   "source": [
    "# Print parameters of the PyTorch model\n",
    "print(\"PyTorch model parameters:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: data: {param.data} grad={param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "id": "bd430978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "\n",
    "y = [1.0, -1.0, -1.0, 1.0]  # Example labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "id": "014ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mse(y_preds, y_true):\n",
    "    \"\"\"Mean squared error loss function.\"\"\"\n",
    "    loss = sum([(i - j)**2 for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss/len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1749,
   "id": "8bb459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mae(y_preds, y_true):\n",
    "    \"\"\"Mean absolute error loss function.\"\"\"\n",
    "    loss = sum([(i - j) for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "id": "cab62bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: , data: 0.2788535969157675, grad: 0.0009631703851826798\n",
      "param: , data: -0.9499784895546661, grad: 0.0014447555777740196\n",
      "param: , data: -0.4499413632617615, grad: -0.0004815851925913399\n",
      "param: , data: -0.5535785237023545, grad: 0.0004815851925913399\n",
      "param: , data: 0.4729424283280248, grad: -0.008087029052452697\n",
      "param: , data: 0.3533989748458226, grad: -0.012130543578679046\n",
      "param: , data: 0.7843591354096908, grad: 0.004043514526226349\n",
      "param: , data: -0.8261223347411677, grad: -0.004043514526226349\n",
      "param: , data: -0.15615636062945915, grad: -0.0007711660821590733\n",
      "param: , data: -0.9404055611238593, grad: -0.00115674912323861\n",
      "param: , data: -0.5627240503927933, grad: 0.00038558304107953663\n",
      "param: , data: 0.010710576206724776, grad: -0.00038558304107953663\n",
      "param: , data: -0.9469280606322728, grad: 8.347651589647732e-05\n",
      "param: , data: -0.602324698626703, grad: 0.000125214773844716\n",
      "param: , data: 0.2997688755590464, grad: -4.173825794823866e-05\n",
      "param: , data: 0.08988296120643335, grad: 4.173825794823866e-05\n",
      "param: , data: -0.5591187559186066, grad: 0.025947853827143978\n",
      "param: , data: 0.17853136775181744, grad: -0.00992436626348306\n",
      "param: , data: 0.6188609133556533, grad: 0.02606870426158594\n",
      "param: , data: -0.987002480643878, grad: 0.02636093958323322\n",
      "param: , data: 0.6116385036656158, grad: -0.026382092010792762\n",
      "param: , data: 0.3962787899764537, grad: 0.02352971157995671\n",
      "param: , data: -0.31949896696401625, grad: -0.008999490954019754\n",
      "param: , data: -0.6890410003764369, grad: 0.023639299674820924\n",
      "param: , data: 0.9144261444135624, grad: 0.02390430089140105\n",
      "param: , data: -0.32681090977474647, grad: -0.02392348207389913\n",
      "param: , data: -0.8145083132397042, grad: 0.18171243535335416\n",
      "param: , data: -0.806567246333072, grad: -0.06950018969159072\n",
      "param: , data: 0.6949887326949196, grad: 0.18255874915264755\n",
      "param: , data: 0.20745206273378214, grad: 0.1846052687741373\n",
      "param: , data: 0.6142565465487604, grad: -0.1847533989104902\n",
      "param: , data: 0.45946357338763577, grad: 0.01677559997402493\n",
      "param: , data: 0.07245618290940148, grad: -0.0064162223026606735\n",
      "param: , data: 0.9462315279587412, grad: 0.01685373123522252\n",
      "param: , data: -0.24293124558329304, grad: 0.017042664889885966\n",
      "param: , data: 0.104081262546454, grad: -0.017056340189029483\n",
      "param: , data: 0.6588093285059897, grad: -0.24688013463515496\n",
      "param: , data: 0.2370395047284921, grad: 0.2113081631240002\n",
      "param: , data: 0.7234138006215545, grad: -0.05743547221069753\n",
      "param: , data: 0.15470429051352408, grad: 0.20531606314719333\n",
      "param: , data: 0.40914367242984695, grad: -0.2677132968107949\n"
     ]
    }
   ],
   "source": [
    "# Print grads for our model\n",
    "for param in mlp.parameters():\n",
    "    print(f\"param: {param.label}, data: {param.data}, grad: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "id": "3d011511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795]\n",
      "Layer: Layer 1, Input: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795], Output: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824]\n",
      "Layer: Layer 2, Input: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824], Output: [0.8661433515946025]\n",
      "y_preds = 0.8661433515946025\n",
      "y = 1.0\n",
      "loss = Value(data=0.017917602322326195)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with our model\n",
    "mlp.register_forward_hook(hook_fn)  # Register the hook to capture outputs\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "id": "0f2e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "id": "7c87c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "y_preds_tmlp = 0.8661433458328247\n",
      "loss_tmlp = Value(data=0.017917603864830767)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with PyTorch model\n",
    "y_preds_tmlp = tmlp(torch.tensor(x[0]))\n",
    "print(f\"y_preds_tmlp = {y_preds_tmlp.item()}\")\n",
    "loss_tmlp = loss_fn_mse([Value(y_preds_tmlp.item())], [Value(y[0])])\n",
    "print(f\"loss_tmlp = {loss_tmlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "id": "dedc339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power operation: base = -0.13385664840539746, power = 2, grad = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with our model\n",
    "mlp.zero_grad()\n",
    "visited = set()\n",
    "loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "loss.backward(loss, visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "id": "494cc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for our model\n",
    "learning_rate = 0.001\n",
    "for param in mlp.parameters():\n",
    "    param.data -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1797,
   "id": "8964c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "output = tensor([0.8685], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with PyTorch model\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "optimizer.zero_grad()\n",
    "output = tmlp(torch.tensor(x[0]))  # Forward pass\n",
    "print(f\"output = {output}\")\n",
    "loss_rmse = rmse([torch.tensor([y[0]])], [output])  # Calculate loss\n",
    "loss_rmse.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1757,
   "id": "6bc150d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmlp loss grad = 0.017917603254318237\n"
     ]
    }
   ],
   "source": [
    "# Print gradients of the loss function\n",
    "print(f\"tmlp loss grad = {loss_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1758,
   "id": "30507a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for PyTorch model\n",
    "optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1759,
   "id": "46a77386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for our model:\n",
      ": 0.2788535969157675 (grad: 0.0009631703851826798)\n",
      ": -0.9499784895546661 (grad: 0.0014447555777740196)\n",
      ": -0.4499413632617615 (grad: -0.0004815851925913399)\n",
      ": -0.5535785237023545 (grad: 0.0004815851925913399)\n",
      ": 0.4729424283280248 (grad: -0.008087029052452697)\n",
      ": 0.3533989748458226 (grad: -0.012130543578679046)\n",
      ": 0.7843591354096908 (grad: 0.004043514526226349)\n",
      ": -0.8261223347411677 (grad: -0.004043514526226349)\n",
      ": -0.15615636062945915 (grad: -0.0007711660821590733)\n",
      ": -0.9404055611238593 (grad: -0.00115674912323861)\n",
      ": -0.5627240503927933 (grad: 0.00038558304107953663)\n",
      ": 0.010710576206724776 (grad: -0.00038558304107953663)\n",
      ": -0.9469280606322728 (grad: 8.347651589647732e-05)\n",
      ": -0.602324698626703 (grad: 0.000125214773844716)\n",
      ": 0.2997688755590464 (grad: -4.173825794823866e-05)\n",
      ": 0.08988296120643335 (grad: 4.173825794823866e-05)\n",
      ": -0.5591187559186066 (grad: 0.025947853827143978)\n",
      ": 0.17853136775181744 (grad: -0.00992436626348306)\n",
      ": 0.6188609133556533 (grad: 0.02606870426158594)\n",
      ": -0.987002480643878 (grad: 0.02636093958323322)\n",
      ": 0.6116385036656158 (grad: -0.026382092010792762)\n",
      ": 0.3962787899764537 (grad: 0.02352971157995671)\n",
      ": -0.31949896696401625 (grad: -0.008999490954019754)\n",
      ": -0.6890410003764369 (grad: 0.023639299674820924)\n",
      ": 0.9144261444135624 (grad: 0.02390430089140105)\n",
      ": -0.32681090977474647 (grad: -0.02392348207389913)\n",
      ": -0.8145083132397042 (grad: 0.18171243535335416)\n",
      ": -0.806567246333072 (grad: -0.06950018969159072)\n",
      ": 0.6949887326949196 (grad: 0.18255874915264755)\n",
      ": 0.20745206273378214 (grad: 0.1846052687741373)\n",
      ": 0.6142565465487604 (grad: -0.1847533989104902)\n",
      ": 0.45946357338763577 (grad: 0.01677559997402493)\n",
      ": 0.07245618290940148 (grad: -0.0064162223026606735)\n",
      ": 0.9462315279587412 (grad: 0.01685373123522252)\n",
      ": -0.24293124558329304 (grad: 0.017042664889885966)\n",
      ": 0.104081262546454 (grad: -0.017056340189029483)\n",
      ": 0.6588093285059897 (grad: -0.24688013463515496)\n",
      ": 0.2370395047284921 (grad: 0.2113081631240002)\n",
      ": 0.7234138006215545 (grad: -0.05743547221069753)\n",
      ": 0.15470429051352408 (grad: 0.20531606314719333)\n",
      ": 0.40914367242984695 (grad: -0.2677132968107949)\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters for out model\n",
    "print(\"Updated parameters for our model:\")\n",
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1760,
   "id": "ea105b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for PyTorch model:\n",
      "layers.0.weight: tensor([[ 0.2788, -0.9500, -0.4499],\n",
      "        [ 0.4727,  0.3530,  0.7845],\n",
      "        [-0.1561, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) (grad: tensor([[ 9.6584e-03,  1.4488e-02, -4.8292e-03],\n",
      "        [ 2.5877e-01,  3.8816e-01, -1.2939e-01],\n",
      "        [-6.8197e-03, -1.0229e-02,  3.4098e-03],\n",
      "        [-9.6238e-05, -1.4436e-04,  4.8119e-05]]))\n",
      "layers.0.bias: tensor([-0.5536, -0.8263,  0.0107,  0.0899]) (grad: tensor([ 4.8292e-03,  1.2939e-01, -3.4098e-03, -4.8119e-05]))\n",
      "layers.2.weight: tensor([[-0.5591,  0.1785,  0.6188, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6891,  0.9144],\n",
      "        [-0.8147, -0.8065,  0.6948,  0.2073],\n",
      "        [ 0.4594,  0.0725,  0.9462, -0.2429]]) (grad: tensor([[ 0.0259, -0.0099,  0.0261,  0.0264],\n",
      "        [ 0.0235, -0.0090,  0.0236,  0.0239],\n",
      "        [ 0.1817, -0.0695,  0.1826,  0.1846],\n",
      "        [ 0.0168, -0.0064,  0.0169,  0.0170]]))\n",
      "layers.2.bias: tensor([ 0.6117, -0.3268,  0.6144,  0.1041]) (grad: tensor([-0.0264, -0.0239, -0.1848, -0.0171]))\n",
      "layers.4.weight: tensor([[0.6591, 0.2368, 0.7235, 0.1545]]) (grad: tensor([[-0.2469,  0.2113, -0.0574,  0.2053]]))\n",
      "layers.4.bias: tensor([0.4094]) (grad: tensor([-0.2677]))\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters of PyTorch model\n",
    "print(\"Updated parameters for PyTorch model:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "id": "d85f718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9837086880999435, 0.4104862500252361, -0.9880359995850213, -0.9991988033317043]\n",
      "Layer: Layer 1, Input: [-0.9837086880999435, 0.4104862500252361, -0.9880359995850213, -0.9991988033317043], Output: [0.9300756159974627, -0.7781620501975345, 0.4325779256190116, -0.7567228577133508]\n",
      "Layer: Layer 2, Input: [0.9300756159974627, -0.7781620501975345, 0.4325779256190116, -0.7567228577133508], Output: [1.218553099743485]\n",
      "y_preds = 1.218553099743485\n",
      "y = 1.0\n",
      "loss = Value(data=0.047765457407485716)\n"
     ]
    }
   ],
   "source": [
    "# Second forward pass with our model\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "id": "20af6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = 0.2781168415395158, grad = 0.73675537625166\n",
      " = -0.95101455180252, grad = 1.0360622478538968\n",
      " = -0.4496190327846514, grad = -0.32233047711010127\n",
      " = -0.5538548069684489, grad = 0.27628326609437254\n",
      " = 0.47874179372064934, grad = -5.7993653926245345\n",
      " = 0.361518086395497, grad = -8.119111549674347\n",
      " = 0.7818460770728869, grad = 2.5130583368039647\n",
      " = -0.8239959007638721, grad = -2.126433977295662\n",
      " = -0.15564021035113365, grad = -0.5161502783255044\n",
      " = -0.939686637521906, grad = -0.7189236019533811\n",
      " = -0.5629452576549328, grad = 0.22120726213950187\n",
      " = 0.010894915591841027, grad = -0.18433938511625153\n",
      " = -0.9469799415771389, grad = 0.05188094486624031\n",
      " = -0.6023965337811332, grad = 0.07183515443017889\n",
      " = 0.29979082518956673, grad = -0.021949630520332438\n",
      " = 0.08986500241782581, grad = 0.017958788607544723\n",
      " = -0.5740049233377658, grad = 14.886167419159179\n",
      " = 0.1837504684843409, grad = -5.219100732523457\n",
      " = 0.6063979977126209, grad = 12.46291564303239\n",
      " = -0.998344845293084, grad = 11.342364649205999\n",
      " = 0.6204674216180595, grad = -8.828917952443646\n",
      " = 0.38390480742858285, grad = 12.373982547870861\n",
      " = -0.3151964939502172, grad = -4.30247301379903\n",
      " = -0.6992123205646679, grad = 10.171320188230926\n",
      " = 0.9052836175729262, grad = 9.14252684063618\n",
      " = -0.31994851256506335, grad = -6.862397209683107\n",
      " = -0.9013813212102605, grad = 86.87300797055632\n",
      " = -0.7766632858850004, grad = -29.903960448071558\n",
      " = 0.6251666420299947, grad = 69.82209066492487\n",
      " = 0.14567285390800375, grad = 61.77920882577839\n",
      " = 0.6584199618508769, grad = -44.16341530211658\n",
      " = 0.4522455085112372, grad = 7.218064876398609\n",
      " = 0.07491015489059694, grad = -2.4539719811954543\n",
      " = 0.9405913304259814, grad = 5.640197532759838\n",
      " = -0.24781989580672836, grad = 4.888650223435316\n",
      " = 0.10734297784801546, grad = -3.2617153015614506\n",
      " = 0.7414291772992669, grad = -82.6198487932772\n",
      " = 0.17642623177240094, grad = 60.613272956091166\n",
      " = 0.7371431643424521, grad = -13.729363720897624\n",
      " = 0.11544132217437869, grad = 39.26296833914538\n",
      " = 0.4347413254715256, grad = -25.597653041678633\n"
     ]
    }
   ],
   "source": [
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label} = {param.data}, grad = {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "id": "f4b8b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9624437362235917, 0.7842708027085034, -0.9675376141403886, -0.9607055353476632]\n",
      "Layer: Layer 1, Input: [0.9624437362235917, 0.7842708027085034, -0.9675376141403886, -0.9607055353476632], Output: [-0.8656596538543742, 0.24532005826845613, -0.7787528824441328, -0.5962473497765924]\n",
      "Layer: Layer 2, Input: [-0.8656596538543742, 0.24532005826845613, -0.7787528824441328, -0.5962473497765924], Output: [-0.14406765254043966]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965463907107457, 0.8317466751113165, 0.13996779920473548, -0.8017320021804215]\n",
      "Layer: Layer 1, Input: [0.9965463907107457, 0.8317466751113165, 0.13996779920473548, -0.8017320021804215], Output: [-0.8855727264899874, -0.13594100820606084, -0.6842323546692994, -0.5718532726290331]\n",
      "Layer: Layer 2, Input: [-0.8855727264899874, -0.13594100820606084, -0.6842323546692994, -0.5718532726290331], Output: [0.195096862093195]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8906868367302101, -0.5597750757491593, 0.5324586252898038, -0.7440634965438513]\n",
      "Layer: Layer 1, Input: [0.8906868367302101, -0.5597750757491593, 0.5324586252898038, -0.7440634965438513], Output: [-0.3204456584119029, -0.6007208307409918, -0.4747313408504545, 0.1819296196599558]\n",
      "Layer: Layer 2, Input: [-0.3204456584119029, -0.6007208307409918, -0.4747313408504545, 0.1819296196599558], Output: [0.4146130189618783]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7500609846431351, 0.8505747669076428, -0.7479521742985102, -0.6599760407818295]\n",
      "Layer: Layer 1, Input: [0.7500609846431351, 0.8505747669076428, -0.7479521742985102, -0.6599760407818295], Output: [-0.7811054474584959, 0.03604697214209223, -0.6819784109099045, -0.43915476504782247]\n",
      "Layer: Layer 2, Input: [-0.7811054474584959, 0.03604697214209223, -0.6819784109099045, -0.43915476504782247], Output: [0.018615388029081303]\n",
      "Epoch 1/500, Loss: 1.4253482633510361, Accuracy: -3.7351621455664317\n",
      "Power operation: base = -1.1440676525404396, power = 2, grad = 0.25\n",
      "Power operation: base = 1.195096862093195, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4146130189618784, power = 2, grad = 0.25\n",
      "Power operation: base = -0.9813846119709186, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.96290287142851, 0.7837960594547836, -0.9675315691218458, -0.9616743343056738]\n",
      "Layer: Layer 1, Input: [0.96290287142851, 0.7837960594547836, -0.9675315691218458, -0.9616743343056738], Output: [-0.8666289438104343, 0.19270550031604272, -0.7787127014346686, -0.5900022872472812]\n",
      "Layer: Layer 2, Input: [-0.8666289438104343, 0.19270550031604272, -0.7787127014346686, -0.5900022872472812], Output: [-0.07401540681655827]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965545447978588, 0.8295475215470078, 0.13810585572168338, -0.8012288788163129]\n",
      "Layer: Layer 1, Input: [0.9965545447978588, 0.8295475215470078, 0.13810585572168338, -0.8012288788163129], Output: [-0.8845604452109106, -0.17252760700795075, -0.6840512911536523, -0.5668647268081043]\n",
      "Layer: Layer 2, Input: [-0.8845604452109106, -0.17252760700795075, -0.6840512911536523, -0.5668647268081043], Output: [0.24838800867450916]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8906980647314252, -0.5655131594069692, 0.5307788067925682, -0.7420264795472333]\n",
      "Layer: Layer 1, Input: [0.8906980647314252, -0.5655131594069692, 0.5307788067925682, -0.7420264795472333], Output: [-0.3035360146328714, -0.6043467700871199, -0.47419618733769325, 0.1840660787346838]\n",
      "Layer: Layer 2, Input: [-0.3035360146328714, -0.6043467700871199, -0.47419618733769325, 0.1840660787346838], Output: [0.40616495961814736]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7513173024599573, 0.8491472797518786, -0.7484954296507157, -0.6618374699497658]\n",
      "Layer: Layer 1, Input: [0.7513173024599573, 0.8491472797518786, -0.7484954296507157, -0.6618374699497658], Output: [-0.7815952116084564, -0.009205468878168427, -0.6823294898156795, -0.4335250305362095]\n",
      "Layer: Layer 2, Input: [-0.7815952116084564, -0.009205468878168427, -0.6823294898156795, -0.4335250305362095], Output: [0.07695476604658796]\n",
      "Epoch 2/500, Loss: 1.3853235279659146, Accuracy: -3.651613609062627\n",
      "Power operation: base = -1.0740154068165584, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2483880086745092, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4061649596181474, power = 2, grad = 0.25\n",
      "Power operation: base = -0.9230452339534121, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9633346280369706, 0.7830637375090341, -0.9675417365667998, -0.9625264917161801]\n",
      "Layer: Layer 1, Input: [0.9633346280369706, 0.7830637375090341, -0.9675417365667998, -0.9625264917161801], Output: [-0.8670027160108967, 0.14462678514336438, -0.7787767868580463, -0.5847546996351759]\n",
      "Layer: Layer 2, Input: [-0.8670027160108967, 0.14462678514336438, -0.7787767868580463, -0.5847546996351759], Output: [-0.015259480768695155]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.996561538300107, 0.827147101071183, 0.1361199759593959, -0.8004401062734121]\n",
      "Layer: Layer 1, Input: [0.996561538300107, 0.827147101071183, 0.1361199759593959, -0.8004401062734121], Output: [-0.8830285567557855, -0.20395309637725256, -0.6838964302815477, -0.5625957469237903]\n",
      "Layer: Layer 2, Input: [-0.8830285567557855, -0.20395309637725256, -0.6838964302815477, -0.5625957469237903], Output: [0.2904351677869918]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8906812471773583, -0.5715545999514166, 0.5290251601534691, -0.7396649341550209]\n",
      "Layer: Layer 1, Input: [0.8906812471773583, -0.5715545999514166, 0.5290251601534691, -0.7396649341550209], Output: [-0.2844680054549626, -0.6060212882068398, -0.4733789283723266, 0.18592620080316388]\n",
      "Layer: Layer 2, Input: [-0.2844680054549626, -0.6060212882068398, -0.4733789283723266, 0.18592620080316388], Output: [0.3894937752783046]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.752476183835677, 0.8475407923549777, -0.7491114714702086, -0.6631582032630504]\n",
      "Layer: Layer 1, Input: [0.752476183835677, 0.8475407923549777, -0.7491114714702086, -0.6631582032630504], Output: [-0.7810610216656139, -0.04918878610036693, -0.6826890665570132, -0.42875153224970597]\n",
      "Layer: Layer 2, Input: [-0.7810610216656139, -0.04918878610036693, -0.6826890665570132, -0.42875153224970597], Output: [0.12367050470787733]\n",
      "Epoch 3/500, Loss: 1.3486552678520662, Accuracy: -3.571517919126115\n",
      "Power operation: base = -1.0152594807686952, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2904351677869919, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3894937752783045, power = 2, grad = 0.25\n",
      "Power operation: base = -0.8763294952921227, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9637469793758886, 0.7821522087100186, -0.9675638966074862, -0.9632920974546099]\n",
      "Layer: Layer 1, Input: [0.9637469793758886, 0.7821522087100186, -0.9675638966074862, -0.9632920974546099], Output: [-0.8669249391463075, 0.1005995528122377, -0.7788962486904276, -0.5802795005024743]\n",
      "Layer: Layer 2, Input: [-0.8669249391463075, 0.1005995528122377, -0.7788962486904276, -0.5802795005024743], Output: [0.034432213201268935]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965676817575383, 0.8245830149879858, 0.1340477452317396, -0.799416112227108]\n",
      "Layer: Layer 1, Input: [0.9965676817575383, 0.8245830149879858, 0.1340477452317396, -0.799416112227108], Output: [-0.8810670749675062, -0.23113950499581976, -0.683714214464097, -0.5588441744457956]\n",
      "Layer: Layer 2, Input: [-0.8810670749675062, -0.23113950499581976, -0.683714214464097, -0.5588441744457956], Output: [0.3236356409696744]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8906429447671103, -0.5778059395234857, 0.527220522934218, -0.7370212174188182]\n",
      "Layer: Layer 1, Input: [0.8906429447671103, -0.5778059395234857, 0.527220522934218, -0.7370212174188182], Output: [-0.2635612178376454, -0.6060922859790958, -0.4722537445249109, 0.18766195939027214]\n",
      "Layer: Layer 2, Input: [-0.2635612178376454, -0.6060922859790958, -0.4722537445249109, 0.18766195939027214], Output: [0.366142379146939]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7535659977284592, 0.8457964529869718, -0.7497789928786694, -0.6640590208890771]\n",
      "Layer: Layer 1, Input: [0.7535659977284592, 0.8457964529869718, -0.7497789928786694, -0.6640590208890771], Output: [-0.7797266440464182, -0.08470265408297709, -0.6830156318274007, -0.4246122135378135]\n",
      "Layer: Layer 2, Input: [-0.7797266440464182, -0.08470265408297709, -0.6830156318274007, -0.4246122135378135], Output: [0.16115079645851166]\n",
      "Epoch 4/500, Loss: 1.3135863618330121, Accuracy: -3.4941950104568322\n",
      "Power operation: base = -0.9655677867987311, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3236356409696743, power = 2, grad = 0.25\n",
      "Power operation: base = 1.366142379146939, power = 2, grad = 0.25\n",
      "Power operation: base = -0.8388492035414883, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9641463794995674, 0.7811294742027771, -0.9675946388060034, -0.9639945345380703]\n",
      "Layer: Layer 1, Input: [0.9641463794995674, 0.7811294742027771, -0.9675946388060034, -0.9639945345380703], Output: [-0.8665130906397589, 0.06010885857006905, -0.7790417948045737, -0.5764023884971816]\n",
      "Layer: Layer 2, Input: [-0.8665130906397589, 0.06010885857006905, -0.7790417948045737, -0.5764023884971816], Output: [0.07691398373503278]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965732395183079, 0.8218893852356599, 0.131920946720289, -0.7981991557943107]\n",
      "Layer: Layer 1, Input: [0.9965732395183079, 0.8218893852356599, 0.131920946720289, -0.7981991557943107], Output: [-0.8787512601016748, -0.25486584092874554, -0.6834735931940852, -0.555456765846217]\n",
      "Layer: Layer 2, Input: [-0.8787512601016748, -0.25486584092874554, -0.6834735931940852, -0.555456765846217], Output: [0.34991053601862077]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8905888737714477, -0.5841860334181067, 0.5253847233652305, -0.7341316297878404]\n",
      "Layer: Layer 1, Input: [0.8905888737714477, -0.5841860334181067, 0.5253847233652305, -0.7341316297878404], Output: [-0.24110607257264294, -0.6048382708815804, -0.47081295755407554, 0.1893801089768718]\n",
      "Layer: Layer 2, Input: [-0.24110607257264294, -0.6048382708815804, -0.47081295755407554, 0.1893801089768718], Output: [0.33736815086477967]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7546104551079111, 0.8439510203063739, -0.7504804453191236, -0.6646389349391357]\n",
      "Layer: Layer 1, Input: [0.7546104551079111, 0.8439510203063739, -0.7504804453191236, -0.6646389349391357], Output: [-0.7777759280819457, -0.11647137492565905, -0.6832890661271025, -0.4209413167893826]\n",
      "Layer: Layer 2, Input: [-0.7777759280819457, -0.11647137492565905, -0.6832890661271025, -0.4209413167893826], Output: [0.1913463418335266]\n",
      "Epoch 5/500, Loss: 1.2792051396228767, Accuracy: -3.4190183613148406\n",
      "Power operation: base = -0.9230860162649672, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3499105360186208, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3373681508647797, power = 2, grad = 0.25\n",
      "Power operation: base = -0.8086536581664734, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9645380363364383, 0.7800550246117922, -0.9676311981593504, -0.9646521358300639]\n",
      "Layer: Layer 1, Input: [0.9645380363364383, 0.7800550246117922, -0.9676311981593504, -0.9646521358300639], Output: [-0.865865283118502, 0.022667977428879556, -0.7791973838797506, -0.5729910254014874]\n",
      "Layer: Layer 2, Input: [-0.865865283118502, 0.022667977428879556, -0.7791973838797506, -0.5729910254014874], Output: [0.11370415360178898]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965784378003982, 0.8190975590779943, 0.12976682644769563, -0.7968254064300072]\n",
      "Layer: Layer 1, Input: [0.9965784378003982, 0.8190975590779943, 0.12976682644769563, -0.7968254064300072], Output: [-0.876146156962865, -0.27577083187282525, -0.6831586741734822, -0.5523200459099223]\n",
      "Layer: Layer 2, Input: [-0.876146156962865, -0.27577083187282525, -0.6831586741734822, -0.5523200459099223], Output: [0.3707867504609075]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8905240586167686, -0.5906245801028241, 0.5235352651591201, -0.7310281412056324]\n",
      "Layer: Layer 1, Input: [0.8905240586167686, -0.5906245801028241, 0.5235352651591201, -0.7310281412056324], Output: [-0.21737206018960262, -0.602479869669672, -0.4690604521915487, 0.19115234459658198]\n",
      "Layer: Layer 2, Input: [-0.21737206018960262, -0.602479869669672, -0.4690604521915487, 0.19115234459658198], Output: [0.30419699564173264]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7556294022895825, 0.8420377045892908, -0.751201253703633, -0.6649802878300427]\n",
      "Layer: Layer 1, Input: [0.7556294022895825, 0.8420377045892908, -0.751201253703633, -0.6649802878300427], Output: [-0.7753640860555326, -0.14511780956776776, -0.6835032931095265, -0.417618572974304]\n",
      "Layer: Layer 2, Input: [-0.7753640860555326, -0.14511780956776776, -0.6835032931095265, -0.417618572974304], Output: [0.21583400837445232]\n",
      "Epoch 6/500, Loss: 1.245105687111224, Accuracy: -3.3454455841263986\n",
      "Power operation: base = -0.886295846398211, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3707867504609075, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3041969956417327, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7841659916255477, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9649261246988234, 0.7789811107654653, -0.9676713298750143, -0.9652793472919199]\n",
      "Layer: Layer 1, Input: [0.9649261246988234, 0.7789811107654653, -0.9676713298750143, -0.9652793472919199], Output: [-0.865065078645532, -0.012153826481585736, -0.7793557686070702, -0.5699467846607479]\n",
      "Layer: Layer 2, Input: [-0.865065078645532, -0.012153826481585736, -0.7793557686070702, -0.5699467846607479], Output: [0.1460323144570566]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965834709980141, 0.8162365836829623, 0.12760899265377032, -0.7953264631986845]\n",
      "Layer: Layer 1, Input: [0.9965834709980141, 0.8162365836829623, 0.12760899265377032, -0.7953264631986845], Output: [-0.8733097477450497, -0.29436821994468876, -0.6827636366795643, -0.549352232976055]\n",
      "Layer: Layer 2, Input: [-0.8733097477450497, -0.29436821994468876, -0.6827636366795643, -0.549352232976055], Output: [0.38747125088207096]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8904529507802839, -0.5970609074912503, 0.5216877960139861, -0.7277396762413788]\n",
      "Layer: Layer 1, Input: [0.8904529507802839, -0.5970609074912503, 0.5216877960139861, -0.7277396762413788], Output: [-0.19261308821893627, -0.5991906239793111, -0.4670072972555493, 0.1930235350061591]\n",
      "Layer: Layer 2, Input: [-0.19261308821893627, -0.5991906239793111, -0.4670072972555493, 0.1930235350061591], Output: [0.2674691004200122]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7566394466606378, 0.8400867334700833, -0.7519292352990573, -0.6651524538772952]\n",
      "Layer: Layer 1, Input: [0.7566394466606378, 0.8400867334700833, -0.7519292352990573, -0.6651524538772952], Output: [-0.7726253755099266, -0.1711605346916353, -0.6836612191769919, -0.41455963924940525]\n",
      "Layer: Layer 2, Input: [-0.7726253755099266, -0.1711605346916353, -0.6836612191769919, -0.41455963924940525], Output: [0.23588005130827255]\n",
      "Epoch 7/500, Loss: 1.2111736241209985, Accuracy: -3.2730279855367534\n",
      "Power operation: base = -0.8539676855429434, power = 2, grad = 0.25\n",
      "Power operation: base = 1.387471250882071, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2674691004200123, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7641199486917274, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9653139504118937, 0.777953554245266, -0.9677132149333353, -0.9658875489808457]\n",
      "Layer: Layer 1, Input: [0.9653139504118937, 0.777953554245266, -0.9677132149333353, -0.9658875489808457], Output: [-0.8641846533616961, -0.04472235865432239, -0.7795153994255271, -0.5671975494079132]\n",
      "Layer: Layer 2, Input: [-0.8641846533616961, -0.04472235865432239, -0.7795153994255271, -0.5671975494079132], Output: [0.17488585245779797]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965885064317102, 0.8133334835732269, 0.12546803415573918, -0.7937304377012706]\n",
      "Layer: Layer 1, Input: [0.9965885064317102, 0.8133334835732269, 0.12546803415573918, -0.7937304377012706], Output: [-0.8702950653217509, -0.31106610640075794, -0.6822892438090775, -0.5464964278998702]\n",
      "Layer: Layer 2, Input: [-0.8702950653217509, -0.31106610640075794, -0.6822892438090775, -0.5464964278998702], Output: [0.40091468153754883]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8903795166157721, -0.6034429969223334, 0.5198564090209138, -0.7242930389817338]\n",
      "Layer: Layer 1, Input: [0.8903795166157721, -0.6034429969223334, 0.5198564090209138, -0.7242930389817338], Output: [-0.16707041870082048, -0.5951063893537583, -0.46466886499396254, 0.19501829913625093]\n",
      "Layer: Layer 2, Input: [-0.16707041870082048, -0.5951063893537583, -0.46466886499396254, 0.19501829913625093], Output: [0.22787645410497182]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7576544365996093, 0.8381256906700932, -0.7526541769380969, -0.6652144858505097]\n",
      "Layer: Layer 1, Input: [0.7576544365996093, 0.8381256906700932, -0.7526541769380969, -0.6652144858505097], Output: [-0.769678175946938, -0.1950224069362643, -0.6837712743508274, -0.4117080029896271]\n",
      "Layer: Layer 2, Input: [-0.769678175946938, -0.1950224069362643, -0.6837712743508274, -0.4117080029896271], Output: [0.2524973419468106]\n",
      "Epoch 8/500, Loss: 1.1774540279409322, Accuracy: -3.201407941237912\n",
      "Power operation: base = -0.825114147542202, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4009146815375488, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2278764541049718, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7475026580531894, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9657040765744573, 0.7770122180810217, -0.9677553891031692, -0.96648563915506]\n",
      "Layer: Layer 1, Input: [0.9657040765744573, 0.7770122180810217, -0.9677553891031692, -0.96648563915506], Output: [-0.8632867865215997, -0.0753398557725746, -0.779678282600248, -0.5646916689804222]\n",
      "Layer: Layer 2, Input: [-0.8632867865215997, -0.0753398557725746, -0.779678282600248, -0.5646916689804222], Output: [0.20105225364011925]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965936878124475, 0.8104133799720173, 0.12336193065817333, -0.7920626987735405]\n",
      "Layer: Layer 1, Input: [0.9965936878124475, 0.8104133799720173, 0.12336193065817333, -0.7920626987735405], Output: [-0.86715151597269, -0.3261860634216505, -0.6817404583752786, -0.5437150136713577]\n",
      "Layer: Layer 2, Input: [-0.86715151597269, -0.3261860634216505, -0.6817404583752786, -0.5437150136713577], Output: [0.4118639482823542]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8903072987289475, -0.6097266982549249, 0.51805381994438, -0.7207135454943141]\n",
      "Layer: Layer 1, Input: [0.8903072987289475, -0.6097266982549249, 0.51805381994438, -0.7207135454943141], Output: [-0.14097369442167143, -0.5903331753982499, -0.46206294946964316, 0.19714621642088562]\n",
      "Layer: Layer 2, Input: [-0.14097369442167143, -0.5903331753982499, -0.46206294946964316, 0.19714621642088562], Output: [0.18599278647019057]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7586858228158601, 0.8361796783970429, -0.7533675305971741, -0.665216972692985]\n",
      "Layer: Layer 1, Input: [0.7586858228158601, 0.8361796783970429, -0.7533675305971741, -0.665216972692985], Output: [-0.7666281694484287, -0.21704359483537702, -0.6838450491714447, -0.40902829366940696]\n",
      "Layer: Layer 2, Input: [-0.7666281694484287, -0.21704359483537702, -0.6838450491714447, -0.40902829366940696], Output: [0.26649435467737403]\n",
      "Epoch 9/500, Loss: 1.1440716827881148, Accuracy: -3.1303101264350515\n",
      "Power operation: base = -0.7989477463598808, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4118639482823543, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1859927864701905, power = 2, grad = 0.25\n",
      "Power operation: base = -0.733505645322626, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9660984218968917, 0.7761912480355495, -0.967796689106632, -0.9670804564255241]\n",
      "Layer: Layer 1, Input: [0.9660984218968917, 0.7761912480355495, -0.967796689106632, -0.9670804564255241], Output: [-0.8624260281789211, -0.10425131530112496, -0.7798484994435376, -0.5623930072646667]\n",
      "Layer: Layer 2, Input: [-0.8624260281789211, -0.10425131530112496, -0.7798484994435376, -0.5623930072646667], Output: [0.22515573360437657]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9965991377117933, 0.8074994942522615, 0.12130631664936636, -0.7903463593516812]\n",
      "Layer: Layer 1, Input: [0.9965991377117933, 0.8074994942522615, 0.12130631664936636, -0.7903463593516812], Output: [-0.8639256021807706, -0.33998017758954135, -0.6811248107849293, -0.5409851129495538]\n",
      "Layer: Layer 2, Input: [-0.8639256021807706, -0.33998017758954135, -0.6811248107849293, -0.5409851129495538], Output: [0.4209047319320097]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8902394564272583, -0.6158750793699167, 0.5162914574393028, -0.7170254228322703]\n",
      "Layer: Layer 1, Input: [0.8902394564272583, -0.6158750793699167, 0.5162914574393028, -0.7170254228322703], Output: [-0.11454056315315632, -0.5849535263390442, -0.45920854243943077, 0.19940593582224062]\n",
      "Layer: Layer 2, Input: [-0.11454056315315632, -0.5849535263390442, -0.45920854243943077, 0.19940593582224062], Output: [0.1422969276332946]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7597429292190191, 0.8342713543169225, -0.754062193632409, -0.6652033195602889]\n",
      "Layer: Layer 1, Input: [0.7597429292190191, 0.8342713543169225, -0.754062193632409, -0.6652033195602889], Output: [-0.7635701572100319, -0.23749539401664418, -0.6838956741740516, -0.40650083417408234]\n",
      "Layer: Layer 2, Input: [-0.7635701572100319, -0.23749539401664418, -0.6838956741740516, -0.40650083417408234], Output: [0.27851563763447484]\n",
      "Epoch 10/500, Loss: 1.1111839626028504, Accuracy: -3.059530288326453\n",
      "Power operation: base = -0.7748442663956234, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4209047319320098, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1422969276332946, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7214843623655252, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9664983395833786, 0.7755191829908966, -0.967836210779636, -0.9676770939136631]\n",
      "Layer: Layer 1, Input: [0.9664983395833786, 0.7755191829908966, -0.967836210779636, -0.9676770939136631], Output: [-0.8616493206498375, -0.13165270746976826, -0.780031182748966, -0.560276949361618]\n",
      "Layer: Layer 2, Input: [-0.8616493206498375, -0.13165270746976826, -0.780031182748966, -0.560276949361618], Output: [0.2476879915464273]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966049593214946, 0.804613077978953, 0.11931464971358571, -0.7886025729196894]\n",
      "Layer: Layer 1, Input: [0.9966049593214946, 0.804613077978953, 0.11931464971358571, -0.7886025729196894], Output: [-0.8606612011535079, -0.35264547153313625, -0.6804512772306873, -0.5382949287949016]\n",
      "Layer: Layer 2, Input: [-0.8606612011535079, -0.35264547153313625, -0.6804512772306873, -0.5382949287949016], Output: [0.4284953879172033]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8901787909440219, -0.6218578554473609, 0.51457949759052, -0.7132520272619184]\n",
      "Layer: Layer 1, Input: [0.8901787909440219, -0.6218578554473609, 0.51457949759052, -0.7132520272619184], Output: [-0.08797540122635764, -0.5790316459579123, -0.45612503977226765, 0.2017884045795873]\n",
      "Layer: Layer 2, Input: [-0.08797540122635764, -0.5790316459579123, -0.45612503977226765, 0.2017884045795873], Output: [0.09719073072531004]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7608331595886603, 0.8324208919249289, -0.7547323462761111, -0.6652106196597358]\n",
      "Layer: Layer 1, Input: [0.7608331595886603, 0.8324208919249289, -0.7547323462761111, -0.6652106196597358], Output: [-0.7605889296751758, -0.2565930790901108, -0.6839367035270727, -0.404117240998944]\n",
      "Layer: Layer 2, Input: [-0.7605889296751758, -0.2565930790901108, -0.6839367035270727, -0.404117240998944], Output: [0.28907449287114295]\n",
      "Epoch 11/500, Loss: 1.078953751910033, Accuracy: -2.988923634224943\n",
      "Power operation: base = -0.7523120084535727, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4284953879172033, power = 2, grad = 0.25\n",
      "Power operation: base = 1.09719073072531, power = 2, grad = 0.25\n",
      "Power operation: base = -0.710925507128857, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9669046835912442, 0.7750190184250502, -0.9678732752118976, -0.9682791442633372]\n",
      "Layer: Layer 1, Input: [0.9669046835912442, 0.7750190184250502, -0.9678732752118976, -0.9682791442633372], Output: [-0.8609962922562833, -0.1576994099894763, -0.7802318118295677, -0.558327220854261]\n",
      "Layer: Layer 2, Input: [-0.8609962922562833, -0.1576994099894763, -0.7802318118295677, -0.558327220854261], Output: [0.26903354844923455]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966112377573975, 0.8017733094658893, 0.1173983238027196, -0.7868506967564158]\n",
      "Layer: Layer 1, Input: [0.9966112377573975, 0.8017733094658893, 0.1173983238027196, -0.7868506967564158], Output: [-0.8573995327695126, -0.36433575559628506, -0.6797295058750703, -0.535640807904928]\n",
      "Layer: Layer 2, Input: [-0.8573995327695126, -0.36433575559628506, -0.6797295058750703, -0.535640807904928], Output: [0.43499376128649625]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8901277608183045, -0.6276508529056525, 0.512926868556891, -0.7094159293950989]\n",
      "Layer: Layer 1, Input: [0.8901277608183045, -0.6276508529056525, 0.512926868556891, -0.7094159293950989], Output: [-0.06146760394141208, -0.5726174922972511, -0.4528317310128974, 0.20427939231529268]\n",
      "Layer: Layer 2, Input: [-0.06146760394141208, -0.5726174922972511, -0.4528317310128974, 0.20427939231529268], Output: [0.051012697663571194]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7619621629216287, 0.8306459086484065, -0.7553733250181616, -0.6652702541866393]\n",
      "Layer: Layer 1, Input: [0.7619621629216287, 0.8306459086484065, -0.7553733250181616, -0.6652702541866393], Output: [-0.7577595292203081, -0.2745071100598967, -0.683981346212379, -0.40187689980353436]\n",
      "Layer: Layer 2, Input: [-0.7577595292203081, -0.2745071100598967, -0.683981346212379, -0.40187689980353436], Output: [0.2985789957007171]\n",
      "Epoch 12/500, Loss: 1.0475345410365389, Accuracy: -2.918393914800116\n",
      "Power operation: base = -0.7309664515507655, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4349937612864962, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0510126976635712, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7014210042992829, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9673178674521018, 0.7747082898418017, -0.9679073999063261, -0.96888890294782]\n",
      "Layer: Layer 1, Input: [0.9673178674521018, 0.7747082898418017, -0.9679073999063261, -0.96888890294782], Output: [-0.8604993962259301, -0.1825140498669375, -0.7804557330713412, -0.5565333852968984]\n",
      "Layer: Layer 2, Input: [-0.8604993962259301, -0.1825140498669375, -0.7804557330713412, -0.5565333852968984], Output: [0.28949040626012346]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966180411222251, 0.7989971915545495, 0.11556675823114501, -0.7851083702838111]\n",
      "Layer: Layer 1, Input: [0.9966180411222251, 0.7989971915545495, 0.11556675823114501, -0.7851083702838111], Output: [-0.8541789343240206, -0.37517120553916755, -0.6789692836788486, -0.5330248923386361]\n",
      "Layer: Layer 2, Input: [-0.8541789343240206, -0.37517120553916755, -0.6789692836788486, -0.5330248923386361], Output: [0.44067831763001375]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8900884921467137, -0.6332354761487682, 0.5113412454960858, -0.7055389090753323]\n",
      "Layer: Layer 1, Input: [0.8900884921467137, -0.6332354761487682, 0.5113412454960858, -0.7055389090753323], Output: [-0.03518984807478002, -0.5657500503455062, -0.4493474780421283, 0.20686144686391386]\n",
      "Layer: Layer 2, Input: [-0.03518984807478002, -0.5657500503455062, -0.4493474780421283, 0.20686144686391386], Output: [0.004048354327481407]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.763133976087781, 0.8289613991926257, -0.7559815160635123, -0.665408328454813]\n",
      "Layer: Layer 1, Input: [0.763133976087781, 0.8289613991926257, -0.7559815160635123, -0.665408328454813], Output: [-0.7551471827647632, -0.29137255321743466, -0.6840419436115109, -0.3997841720635503]\n",
      "Layer: Layer 2, Input: [-0.7551471827647632, -0.29137255321743466, -0.6840419436115109, -0.3997841720635503], Output: [0.3073525591849393]\n",
      "Epoch 13/500, Loss: 1.017062868195257, Accuracy: -2.847883706512433\n",
      "Power operation: base = -0.7105095937398765, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4406783176300137, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0040483543274814, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6926474408150607, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9677379192675558, 0.7745992239485058, -0.9679382729357615, -0.9695075483547533]\n",
      "Layer: Layer 1, Input: [0.9677379192675558, 0.7745992239485058, -0.9679382729357615, -0.9695075483547533], Output: [-0.860184026466309, -0.2061934095223048, -0.7807078434818319, -0.5548889041476106]\n",
      "Layer: Layer 2, Input: [-0.860184026466309, -0.2061934095223048, -0.7807078434818319, -0.5548889041476106], Output: [0.30928682143360464]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966254214940045, 0.7962994779616214, 0.11382748400702448, -0.7833915481843357]\n",
      "Layer: Layer 1, Input: [0.9966254214940045, 0.7962994779616214, 0.11382748400702448, -0.7833915481843357], Output: [-0.8510345438206556, -0.38524602731864394, -0.6781801734170408, -0.5304532532002036]\n",
      "Layer: Layer 2, Input: [-0.8510345438206556, -0.38524602731864394, -0.6781801734170408, -0.5304532532002036], Output: [0.44576478683385046]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8900627875204915, -0.6385981593992591, 0.5098290504124675, -0.7016418974032803]\n",
      "Layer: Layer 1, Input: [0.8900627875204915, -0.6385981593992591, 0.5098290504124675, -0.7016418974032803], Output: [-0.009296644744080094, -0.5584599591562476, -0.44569052339633475, 0.20951538758912316]\n",
      "Layer: Layer 2, Input: [-0.009296644744080094, -0.5584599591562476, -0.44569052339633475, 0.20951538758912316], Output: [-0.04346172556622119]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7643511577874573, 0.8273797029190749, -0.75655425804664, -0.6656460269274124]\n",
      "Layer: Layer 1, Input: [0.7643511577874573, 0.8273797029190749, -0.75655425804664, -0.6656460269274124], Output: [-0.7528071260782803, -0.30729682659621155, -0.6841296283854029, -0.3978462168506047]\n",
      "Layer: Layer 2, Input: [-0.7528071260782803, -0.30729682659621155, -0.6841296283854029, -0.3978462168506047], Output: [0.3156501632668446]\n",
      "Epoch 14/500, Loss: 0.9876551708468677, Accuracy: -2.7773660765671804\n",
      "Power operation: base = -0.6907131785663954, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4457647868338506, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9565382744337788, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6843498367331554, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9681645350689915, 0.7746989856634733, -0.9679657288684215, -0.9701353099753596]\n",
      "Layer: Layer 1, Input: [0.9681645350689915, 0.7746989856634733, -0.9679657288684215, -0.9701353099753596], Output: [-0.8600687025825603, -0.22881430500756267, -0.7809923945864548, -0.5533896616590736]\n",
      "Layer: Layer 2, Input: [-0.8600687025825603, -0.22881430500756267, -0.7809923945864548, -0.5533896616590736], Output: [0.3285949286150698]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.996633415956381, 0.7936926468457066, 0.11218624086610665, -0.7817145191697903]\n",
      "Layer: Layer 1, Input: [0.996633415956381, 0.7936926468457066, 0.11218624086610665, -0.7817145191697903], Output: [-0.8479979760253404, -0.39463455420941623, -0.6773712744162069, -0.5279344228910156]\n",
      "Layer: Layer 2, Input: [-0.8479979760253404, -0.39463455420941623, -0.6773712744162069, -0.5279344228910156], Output: [0.45041930039360634]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8900521364258029, -0.6437297987538774, 0.5083954663269958, -0.6977448968588056]\n",
      "Layer: Layer 1, Input: [0.8900521364258029, -0.6437297987538774, 0.5083954663269958, -0.6977448968588056], Output: [0.016076601534472486, -0.5507716353495563, -0.4418783904498805, 0.21222141975557096]\n",
      "Layer: Layer 2, Input: [0.016076601534472486, -0.5507716353495563, -0.4418783904498805, 0.21222141975557096], Output: [-0.09131552173826352]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7656149231554054, 0.8259105242114488, -0.7570897474687597, -0.6659999463527912]\n",
      "Layer: Layer 1, Input: [0.7656149231554054, 0.8259105242114488, -0.7570897474687597, -0.6659999463527912], Output: [-0.750784486733378, -0.32236597583595356, -0.6842541217954916, -0.3960713338108269]\n",
      "Layer: Layer 2, Input: [-0.750784486733378, -0.32236597583595356, -0.6842541217954916, -0.3960713338108269], Output: [0.3236712115530489]\n",
      "Epoch 15/500, Loss: 0.9594072569879016, Accuracy: -2.706837638487224\n",
      "Power operation: base = -0.6714050713849302, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4504193003936063, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9086844782617365, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6763287884469511, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9685971315214751, 0.7750100303463726, -0.9679897258630433, -0.9707716303926525]\n",
      "Layer: Layer 1, Input: [0.9685971315214751, 0.7750100303463726, -0.9679897258630433, -0.9707716303926525], Output: [-0.860165379116739, -0.25043846793334645, -0.7813128865720373, -0.5520328724837771]\n",
      "Layer: Layer 2, Input: [-0.860165379116739, -0.25043846793334645, -0.7813128865720373, -0.5520328724837771], Output: [0.3475418429422428]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966420477380635, 0.7911869312306027, 0.11064709136934336, -0.7800899324239494]\n",
      "Layer: Layer 1, Input: [0.9966420477380635, 0.7911869312306027, 0.11064709136934336, -0.7800899324239494], Output: [-0.84509705552044, -0.4033960752113887, -0.6765510756272891, -0.5254782598884287]\n",
      "Layer: Layer 2, Input: [-0.84509705552044, -0.4033960752113887, -0.6765510756272891, -0.5254782598884287], Output: [0.4547688028527388]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8900577288260633, -0.6486251697479984, 0.5070444705029736, -0.6938669032289865]\n",
      "Layer: Layer 1, Input: [0.8900577288260633, -0.6486251697479984, 0.5070444705029736, -0.6938669032289865], Output: [0.04081391693085828, -0.5427050030057275, -0.43792785059904776, 0.21495993816307696]\n",
      "Layer: Layer 2, Input: [0.04081391693085828, -0.5427050030057275, -0.43792785059904776, 0.21495993816307696], Output: [-0.13934424570866233]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7669252840450516, 0.8245610148538653, -0.7575869437853681, -0.6664824446973088]\n",
      "Layer: Layer 1, Input: [0.7669252840450516, 0.8245610148538653, -0.7575869437853681, -0.6664824446973088], Output: [-0.7491143380290343, -0.33664970555599244, -0.6844236395705808, -0.3944677483697436]\n",
      "Layer: Layer 2, Input: [-0.7491143380290343, -0.33664970555599244, -0.6844236395705808, -0.3944677483697436], Output: [0.33156980216445975]\n",
      "Epoch 16/500, Loss: 0.9323952933095117, Accuracy: -2.636312912037374\n",
      "Power operation: base = -0.6524581570577572, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4547688028527388, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8606557542913377, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6684301978355403, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9690348980074508, 0.7755305546343518, -0.9680103237919636, -0.9714153225638428]\n",
      "Layer: Layer 1, Input: [0.9690348980074508, 0.7755305546343518, -0.9680103237919636, -0.9714153225638428], Output: [-0.8604799002987157, -0.27111651751765364, -0.7816720303357422, -0.5508163016393494]\n",
      "Layer: Layer 2, Input: [-0.8604799002987157, -0.27111651751765364, -0.7816720303357422, -0.5508163016393494], Output: [0.36621874961612777]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966513274852628, 0.7887904076175893, 0.10921255294648587, -0.7785288452404994]\n",
      "Layer: Layer 1, Input: [0.9966513274852628, 0.7887904076175893, 0.10921255294648587, -0.7785288452404994], Output: [-0.8423556495841196, -0.4115786411002224, -0.6757273787969182, -0.5230950920349702]\n",
      "Layer: Layer 2, Input: [-0.8423556495841196, -0.4115786411002224, -0.6757273787969182, -0.5230950920349702], Output: [0.4589093450394406]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8900804726674312, -0.6532823424293769, 0.505778887639577, -0.6900258454903111]\n",
      "Layer: Layer 1, Input: [0.8900804726674312, -0.6532823424293769, 0.505778887639577, -0.6900258454903111], Output: [0.06481845003240162, -0.5342769126700156, -0.43385493991918056, 0.21771207775621798]\n",
      "Layer: Layer 2, Input: [0.06481845003240162, -0.5342769126700156, -0.43385493991918056, 0.21771207775621798], Output: [-0.18740771444374538]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7682811963575953, 0.8233359184562478, -0.7580454736380972, -0.6671020247456402]\n",
      "Layer: Layer 1, Input: [0.7682811963575953, 0.8233359184562478, -0.7580454736380972, -0.6671020247456402], Output: [-0.7478219842059934, -0.35020537630428483, -0.6846448834656315, -0.3930427694193204]\n",
      "Layer: Layer 2, Input: [-0.7478219842059934, -0.35020537630428483, -0.6846448834656315, -0.3930427694193204], Output: [0.3394630286526601]\n",
      "Epoch 17/500, Loss: 0.906677615860952, Accuracy: -2.565819852326907\n",
      "Power operation: base = -0.6337812503838722, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4589093450394406, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8125922855562546, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6605369713473399, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9694768474744381, 0.7762550271964083, -0.9680276635406154, -0.9720647210701667]\n",
      "Layer: Layer 1, Input: [0.9694768474744381, 0.7762550271964083, -0.9680276635406154, -0.9720647210701667], Output: [-0.861012593793872, -0.2908911284510274, -0.7820717599096841, -0.5497377357602724]\n",
      "Layer: Layer 2, Input: [-0.861012593793872, -0.2908911284510274, -0.7820717599096841, -0.5497377357602724], Output: [0.3846883772523706]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966612546563778, 0.7865091373540005, 0.1078837449472162, -0.7770407978104126]\n",
      "Layer: Layer 1, Input: [0.9966612546563778, 0.7865091373540005, 0.1078837449472162, -0.7770407978104126], Output: [-0.8397936227377315, -0.41922204625157006, -0.6749072748971549, -0.5207950923079846]\n",
      "Layer: Layer 2, Input: [-0.8397936227377315, -0.41922204625157006, -0.6749072748971549, -0.5207950923079846], Output: [0.4629127240519062]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8901210152374683, -0.6577021091548507, 0.5046004611321574, -0.6862385525916436]\n",
      "Layer: Layer 1, Input: [0.8901210152374683, -0.6577021091548507, 0.5046004611321574, -0.6862385525916436], Output: [0.08801159103271194, -0.5255023100827171, -0.42967501172368866, 0.22046006143837882]\n",
      "Layer: Layer 2, Input: [0.08801159103271194, -0.5255023100827171, -0.42967501172368866, 0.22046006143837882], Output: [-0.23539017975062065]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7696807129705905, 0.8222377697549048, -0.7584655353999545, -0.6678637559558124]\n",
      "Layer: Layer 1, Input: [0.7696807129705905, 0.8222377697549048, -0.7584655353999545, -0.6678637559558124], Output: [-0.746923491499903, -0.3630811497738108, -0.6849230992875656, -0.3918022553886119]\n",
      "Layer: Layer 2, Input: [-0.746923491499903, -0.3630811497738108, -0.6849230992875656, -0.3918022553886119], Output: [0.3474377761315297]\n",
      "Epoch 18/500, Loss: 0.8822969161308103, Accuracy: -2.495396390917385\n",
      "Power operation: base = -0.6153116227476294, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4629127240519062, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7646098202493794, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6525622238684703, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9699218650694148, 0.777174773218875, -0.9680419477747157, -0.9727178244574497]\n",
      "Layer: Layer 1, Input: [0.9699218650694148, 0.777174773218875, -0.9680419477747157, -0.9727178244574497], Output: [-0.8617589766911709, -0.30979950257977773, -0.7825132808753588, -0.5487946522168071]\n",
      "Layer: Layer 2, Input: [-0.8617589766911709, -0.30979950257977773, -0.7825132808753588, -0.5487946522168071], Output: [0.4029911567989438]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966718190041031, 0.784347350599771, 0.10666054554329465, -0.7756339149911878]\n",
      "Layer: Layer 1, Input: [0.9966718190041031, 0.784347350599771, 0.10666054554329465, -0.7756339149911878], Output: [-0.8374269162505962, -0.42636014422490753, -0.674097160172632, -0.5185878464388581]\n",
      "Layer: Layer 2, Input: [-0.8374269162505962, -0.42636014422490753, -0.674097160172632, -0.5185878464388581], Output: [0.46683182131552925]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8901797677153143, -0.6618874404908118, 0.5035099387244651, -0.6825207498776235]\n",
      "Layer: Layer 1, Input: [0.8901797677153143, -0.6618874404908118, 0.5035099387244651, -0.6825207498776235], Output: [0.11033162840269545, -0.5163951981396881, -0.42540281358298404, 0.22318738938377816]\n",
      "Layer: Layer 2, Input: [0.11033162840269545, -0.5163951981396881, -0.42540281358298404, 0.22318738938377816], Output: [-0.28319648514005435]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.771121138970268, 0.8212671366890236, -0.758847806074168, -0.6687697270186593]\n",
      "Layer: Layer 1, Input: [0.771121138970268, 0.8212671366890236, -0.758847806074168, -0.6687697270186593], Output: [-0.7464264433176467, -0.3753184359483452, -0.6852621841366888, -0.3907503287352942]\n",
      "Layer: Layer 2, Input: [-0.7464264433176467, -0.3753184359483452, -0.6852621841366888, -0.3907503287352942], Output: [0.3555563526044837]\n",
      "Epoch 19/500, Loss: 0.8592825111170262, Accuracy: -2.4250878267720473\n",
      "Power operation: base = -0.5970088432010562, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4668318213155294, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7168035148599456, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6444436473955163, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9703687534781171, 0.7782785834443475, -0.9680534234924084, -0.9733724253224322]\n",
      "Layer: Layer 1, Input: [0.9703687534781171, 0.7782785834443475, -0.9680534234924084, -0.9733724253224322], Output: [-0.8627105349415991, -0.3278752474311627, -0.7829971426873886, -0.5479840395270289]\n",
      "Layer: Layer 2, Input: [-0.8627105349415991, -0.3278752474311627, -0.7829971426873886, -0.5479840395270289], Output: [0.4211502936975253]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966830020967645, 0.7823076601727168, 0.10554175248493713, -0.7743150305227237]\n",
      "Layer: Layer 1, Input: [0.9966830020967645, 0.7823076601727168, 0.10554175248493713, -0.7743150305227237], Output: [-0.8352677413213938, -0.4330226233995682, -0.673302780220099, -0.5164820758139582]\n",
      "Layer: Layer 2, Input: [-0.8352677413213938, -0.4330226233995682, -0.673302780220099, -0.5164820758139582], Output: [0.47070490252894337]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8902569318950034, -0.6658429825000495, 0.5025071680447354, -0.6788870831246939]\n",
      "Layer: Layer 1, Input: [0.8902569318950034, -0.6658429825000495, 0.5025071680447354, -0.6788870831246939], Output: [0.1317320778295283, -0.5069694229304951, -0.4210525786808181, 0.22587890878385752]\n",
      "Layer: Layer 2, Input: [0.1317320778295283, -0.5069694229304951, -0.4210525786808181, 0.22587890878385752], Output: [-0.33074850030765246]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7725991849747058, 0.8204228906098753, -0.7591933528081128, -0.6698195147268947]\n",
      "Layer: Layer 1, Input: [0.7725991849747058, 0.8204228906098753, -0.7591933528081128, -0.6698195147268947], Output: [-0.7463308729987513, -0.38695376974028206, -0.6856648270625962, -0.3898892830615885]\n",
      "Layer: Layer 2, Input: [-0.7463308729987513, -0.38695376974028206, -0.6856648270625962, -0.3898892830615885], Output: [0.36386119751843293]\n",
      "Epoch 20/500, Loss: 0.8376525096680671, Accuracy: -2.354944911005332\n",
      "Power operation: base = -0.5788497063024747, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4707049025289434, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6692514996923475, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6361388024815671, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9708162739844381, 0.7795533194606121, -0.9680623666238857, -0.9740262251499315]\n",
      "Layer: Layer 1, Input: [0.9708162739844381, 0.7795533194606121, -0.9680623666238857, -0.9740262251499315], Output: [-0.8638555331324991, -0.3451497569769608, -0.7835233247781767, -0.5473023290215797]\n",
      "Layer: Layer 2, Input: [-0.8638555331324991, -0.3451497569769608, -0.7835233247781767, -0.5473023290215797], Output: [0.43917592667712835]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9966947788268795, 0.7803912919550985, 0.10452524191874989, -0.7730898265900679]\n",
      "Layer: Layer 1, Input: [0.9966947788268795, 0.7803912919550985, 0.10452524191874989, -0.7730898265900679], Output: [-0.8333248648626388, -0.43923634461808614, -0.6725292920895631, -0.5144854827014567]\n",
      "Layer: Layer 2, Input: [-0.8333248648626388, -0.43923634461808614, -0.6725292920895631, -0.5144854827014567], Output: [0.47455907804694675]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8903525279234448, -0.6695746052303583, 0.5015911974354764, -0.6753511650171097]\n",
      "Layer: Layer 1, Input: [0.8903525279234448, -0.6695746052303583, 0.5015911974354764, -0.6753511650171097], Output: [0.15217982106009592, -0.49723930578841896, -0.4166381224991498, 0.2285207976810297]\n",
      "Layer: Layer 2, Input: [0.15217982106009592, -0.49723930578841896, -0.4166381224991498, 0.2285207976810297], Output: [-0.3779818315250948]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7741111142185376, 0.8197024895776786, -0.7595035510447132, -0.6710106518540916]\n",
      "Layer: Layer 1, Input: [0.7741111142185376, 0.8197024895776786, -0.7595035510447132, -0.6710106518540916], Output: [-0.7466303144232816, -0.398020222915319, -0.6861326688853993, -0.38921963210510857]\n",
      "Layer: Layer 2, Input: [-0.7466303144232816, -0.398020222915319, -0.6861326688853993, -0.38921963210510857], Output: [0.37237883733884647]\n",
      "Epoch 21/500, Loss: 0.8174157604005333, Accuracy: -2.285022482505877\n",
      "Power operation: base = -0.5608240733228717, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4745590780469469, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6220181684749052, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6276211626611535, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9712631824965569, 0.7809844906617437, -0.9680690688410929, -0.9746769317776389]\n",
      "Layer: Layer 1, Input: [0.9712631824965569, 0.7809844906617437, -0.9680690688410929, -0.9746769317776389], Output: [-0.8651798134547275, -0.3616531816768245, -0.7840913281487173, -0.5467454041272032]\n",
      "Layer: Layer 2, Input: [-0.8651798134547275, -0.3616531816768245, -0.7840913281487173, -0.5467454041272032], Output: [0.4570685090732136]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9967071188585512, 0.7785983194855097, 0.1036081203545765, -0.7719629806851473]\n",
      "Layer: Layer 1, Input: [0.9967071188585512, 0.7785983194855097, 0.1036081203545765, -0.7719629806851473], Output: [-0.8316039617870763, -0.4450263242447777, -0.6717813358495389, -0.5126046885047923]\n",
      "Layer: Layer 2, Input: [-0.8316039617870763, -0.4450263242447777, -0.6717813358495389, -0.5126046885047923], Output: [0.4784130750089377]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8904664219288896, -0.6730890082207449, 0.5007603779255522, -0.6719256372983489]\n",
      "Layer: Layer 1, Input: [0.8904664219288896, -0.6730890082207449, 0.5007603779255522, -0.6719256372983489], Output: [0.17165317904290184, -0.4872201373640953, -0.41217293702716185, 0.23110049119212894]\n",
      "Layer: Layer 2, Input: [0.17165317904290184, -0.4872201373640953, -0.41217293702716185, 0.23110049119212894], Output: [-0.4248428295594634]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.775652879553714, 0.8191022609661415, -0.7597800108249445, -0.6723390770302023]\n",
      "Layer: Layer 1, Input: [0.775652879553714, 0.8191022609661415, -0.7597800108249445, -0.6723390770302023], Output: [-0.7473129077766304, -0.4085484395295492, -0.6866664688302545, -0.3887402560010033]\n",
      "Layer: Layer 2, Input: [-0.7473129077766304, -0.4085484395295492, -0.6866664688302545, -0.3887402560010033], Output: [0.3811232079416096]\n",
      "Epoch 22/500, Loss: 0.7985735196637537, Accuracy: -2.215378528434651\n",
      "Power operation: base = -0.5429314909267864, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4784130750089377, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5751571704405366, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6188767920583904, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9717082600857945, 0.7825567837401242, -0.9680738266252046, -0.9753223384748798]\n",
      "Layer: Layer 1, Input: [0.9717082600857945, 0.7825567837401242, -0.9680738266252046, -0.9753223384748798], Output: [-0.8666675490685926, -0.377415066374067, -0.7847002659363186, -0.5463086598689247]\n",
      "Layer: Layer 2, Input: [-0.8666675490685926, -0.377415066374067, -0.7847002659363186, -0.5463086598689247], Output: [0.47482152390202503]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9967199879738493, 0.7769278923213813, 0.10278686608516667, -0.7709383120399113]\n",
      "Layer: Layer 1, Input: [0.9967199879738493, 0.7769278923213813, 0.10278686608516667, -0.7709383120399113], Output: [-0.8301080067746335, -0.45041643176267876, -0.6710631085397045, -0.5108452396149967]\n",
      "Layer: Layer 2, Input: [-0.8301080067746335, -0.45041643176267876, -0.6710631085397045, -0.5108452396149967], Output: [0.482279439186003]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8905983525706663, -0.6763933849716651, 0.5000124629281392, -0.6686222415368495]\n",
      "Layer: Layer 1, Input: [0.8905983525706663, -0.6763933849716651, 0.5000124629281392, -0.6686222415368495], Output: [0.1901400208659911, -0.4769285460798639, -0.40767027607147355, 0.23360657309741176]\n",
      "Layer: Layer 2, Input: [0.1901400208659911, -0.4769285460798639, -0.40767027607147355, 0.23360657309741176], Output: [-0.4712859220285491]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7772202473807122, 0.8186176719499209, -0.7600245121409962, -0.6737995521178063]\n",
      "Layer: Layer 1, Input: [0.7772202473807122, 0.8186176719499209, -0.7600245121409962, -0.6737995521178063], Output: [-0.7483625026746911, -0.41856736899241187, -0.6872662678546985, -0.3884486072193121]\n",
      "Layer: Layer 2, Input: [-0.7483625026746911, -0.41856736899241187, -0.6872662678546985, -0.3884486072193121], Output: [0.39009843135034705]\n",
      "Epoch 23/500, Loss: 0.7811208168191679, Accuracy: -2.146073561905082\n",
      "Power operation: base = -0.525178476097975, power = 2, grad = 0.25\n",
      "Power operation: base = 1.482279439186003, power = 2, grad = 0.25\n",
      "Power operation: base = 0.528714077971451, power = 2, grad = 0.25\n",
      "Power operation: base = -0.609901568649653, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9721503378946988, 0.7842545316549026, -0.9680769325318248, -0.9759603847356704]\n",
      "Layer: Layer 1, Input: [0.9721503378946988, 0.7842545316549026, -0.9680769325318248, -0.9759603847356704], Output: [-0.8683019258059285, -0.3924647261358552, -0.7853489481645448, -0.5459870910849041]\n",
      "Layer: Layer 2, Input: [-0.8683019258059285, -0.3924647261358552, -0.7853489481645448, -0.5459870910849041], Output: [0.4924236281069072]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9967333492893655, 0.7753784502300137, 0.10205745764670654, -0.7700189210750623]\n",
      "Layer: Layer 1, Input: [0.9967333492893655, 0.7753784502300137, 0.10205745764670654, -0.7700189210750623], Output: [-0.8288376806469873, -0.45542985974781197, -0.6703784349566041, -0.509211659469025]\n",
      "Layer: Layer 2, Input: [-0.8288376806469873, -0.45542985974781197, -0.6703784349566041, -0.509211659469025], Output: [0.48616626135227037]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8907479557625979, -0.6794951450267748, 0.49934470309230794, -0.6654518920868525]\n",
      "Layer: Layer 1, Input: [0.8907479557625979, -0.6794951450267748, 0.49934470309230794, -0.6654518920868525], Output: [0.20763598322390986, -0.4663827512983269, -0.4031432267634414, 0.23602865066814374]\n",
      "Layer: Layer 2, Input: [0.20763598322390986, -0.4663827512983269, -0.4031432267634414, 0.23602865066814374], Output: [-0.517271291041996]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7788089065510038, 0.8182435793340257, -0.7602389496426152, -0.6753860363616605]\n",
      "Layer: Layer 1, Input: [0.7788089065510038, 0.8182435793340257, -0.7602389496426152, -0.6753860363616605], Output: [-0.7497597107865797, -0.428104759360063, -0.6879315409649034, -0.38834094597176333]\n",
      "Layer: Layer 2, Input: [-0.7497597107865797, -0.428104759360063, -0.6879315409649034, -0.38834094597176333], Output: [0.3993011150831167]\n",
      "Epoch 24/500, Loss: 0.7650475216196471, Accuracy: -2.0771702271202503\n",
      "Power operation: base = -0.5075763718930928, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4861662613522704, power = 2, grad = 0.25\n",
      "Power operation: base = 0.482728708958004, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6006988849168833, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9725883165507507, 0.7860621149140645, -0.968078668506766, -0.9765891998423032]\n",
      "Layer: Layer 1, Input: [0.9725883165507507, 0.7860621149140645, -0.968078668506766, -0.9765891998423032], Output: [-0.8700657355212018, -0.40683142163207814, -0.7860359574633763, -0.545775393208445]\n",
      "Layer: Layer 2, Input: [-0.8700657355212018, -0.40683142163207814, -0.7860359574633763, -0.545775393208445], Output: [0.5098603110034823]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9967471643256275, 0.7739479178271911, 0.10141548807773161, -0.7692073169274682]\n",
      "Layer: Layer 1, Input: [0.9967471643256275, 0.7739479178271911, 0.10141548807773161, -0.7692073169274682], Output: [-0.8277917705447594, -0.46008941484718313, -0.6697308312262791, -0.5077075294532604]\n",
      "Layer: Layer 2, Input: [-0.8277917705447594, -0.46008941484718313, -0.6697308312262791, -0.5077075294532604], Output: [0.49007850684334864]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8909147870647317, -0.6824016898096686, 0.4987539345550382, -0.662424746032118]\n",
      "Layer: Layer 1, Input: [0.8909147870647317, -0.6824016898096686, 0.4987539345550382, -0.662424746032118], Output: [0.22414284892238845, -0.45560271062483026, -0.3986047639181682, 0.23835722593856234]\n",
      "Layer: Layer 2, Input: [0.22414284892238845, -0.45560271062483026, -0.3986047639181682, 0.23835722593856234], Output: [-0.562762905228799]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.780414561305609, 0.817974453130454, -0.7604252864954058, -0.6770920107521238]\n",
      "Layer: Layer 1, Input: [0.780414561305609, 0.817974453130454, -0.7604252864954058, -0.6770920107521238], Output: [-0.7514828724122578, -0.4371874638269388, -0.6886613332227918, -0.38841258212252344]\n",
      "Layer: Layer 2, Input: [-0.7514828724122578, -0.4371874638269388, -0.6886613332227918, -0.38841258212252344], Output: [0.40872223177634104]\n",
      "Epoch 25/500, Loss: 0.7503391368814044, Accuracy: -2.008733058834726\n",
      "Power operation: base = -0.4901396889965177, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4900785068433486, power = 2, grad = 0.25\n",
      "Power operation: base = 0.437237094771201, power = 2, grad = 0.25\n",
      "Power operation: base = -0.591277768223659, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9730211804461116, 0.7879642931318952, -0.9680793010446463, -0.977207130964653]\n",
      "Layer: Layer 1, Input: [0.9730211804461116, 0.7879642931318952, -0.9680793010446463, -0.977207130964653], Output: [-0.8719418731320037, -0.4205443871843146, -0.7867597139357138, -0.545668064141324]\n",
      "Layer: Layer 2, Input: [-0.8719418731320037, -0.4205443871843146, -0.7867597139357138, -0.545668064141324], Output: [0.527115144382316]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9967613939225709, 0.7726338766298757, 0.10085626468904235, -0.768505529849921]\n",
      "Layer: Layer 1, Input: [0.9967613939225709, 0.7726338766298757, 0.10085626468904235, -0.768505529849921], Output: [-0.8269675480415525, -0.4644176706248372, -0.6691235585337695, -0.5063355851248496]\n",
      "Layer: Layer 2, Input: [-0.8269675480415525, -0.4644176706248372, -0.6691235585337695, -0.5063355851248496], Output: [0.4940190153879239]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8910983414668125, -0.6851202366993715, 0.4982366595534138, -0.659550266343942]\n",
      "Layer: Layer 1, Input: [0.8910983414668125, -0.6851202366993715, 0.4982366595534138, -0.659550266343942], Output: [0.2396671100646963, -0.4446101705593011, -0.3940677853905451, 0.24058357256173005]\n",
      "Layer: Layer 2, Input: [0.2396671100646963, -0.4446101705593011, -0.3940677853905451, 0.24058357256173005], Output: [-0.6077269019944199]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7820330082193452, 0.817804570964095, -0.7605855168149148, -0.6789107499738272]\n",
      "Layer: Layer 1, Input: [0.7820330082193452, 0.817804570964095, -0.7605855168149148, -0.6789107499738272], Output: [-0.753508914033985, -0.4458416050892309, -0.6894543763611367, -0.38865810727139827]\n",
      "Layer: Layer 2, Input: [-0.753508914033985, -0.4458416050892309, -0.6894543763611367, -0.38865810727139827], Output: [0.41834863127109656]\n",
      "Epoch 26/500, Loss: 0.7369773507940905, Accuracy: -1.9408283377400912\n",
      "Power operation: base = -0.472884855617684, power = 2, grad = 0.25\n",
      "Power operation: base = 1.494019015387924, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3922730980055801, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5816513687289034, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9734480074015207, 0.7899464688767808, -0.9680790779484653, -0.9778127579967125]\n",
      "Layer: Layer 1, Input: [0.9734480074015207, 0.7899464688767808, -0.9680790779484653, -0.9778127579967125], Output: [-0.8739137366726426, -0.4336327563255633, -0.7875185284954432, -0.5456594996325922]\n",
      "Layer: Layer 2, Input: [-0.8739137366726426, -0.4336327563255633, -0.7875185284954432, -0.5456594996325922], Output: [0.5441706952445726]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9967759990029329, 0.7714337134446363, 0.10037489476435685, -0.7679152068787671]\n",
      "Layer: Layer 1, Input: [0.9967759990029329, 0.7714337134446363, 0.10037489476435685, -0.7679152068787671], Output: [-0.8263611143169154, -0.46843701644921315, -0.6685596656327347, -0.5050978176904277]\n",
      "Layer: Layer 2, Input: [-0.8263611143169154, -0.46843701644921315, -0.6685596656327347, -0.5050978176904277], Output: [0.49798922950409086]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8912980704811821, -0.6876576849416762, 0.49778911892726313, -0.6568372759149154]\n",
      "Layer: Layer 1, Input: [0.8912980704811821, -0.6876576849416762, 0.49778911892726313, -0.6568372759149154], Output: [0.2542187234407513, -0.433428629926439, -0.38954512790625645, 0.24269962401672943]\n",
      "Layer: Layer 2, Input: [0.2542187234407513, -0.433428629926439, -0.38954512790625645, 0.24269962401672943], Output: [-0.6521303037631714]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7836601978406728, 0.8177281826026979, -0.7607216358586292, -0.6808355426050088]\n",
      "Layer: Layer 1, Input: [0.7836601978406728, 0.8177281826026979, -0.7607216358586292, -0.6808355426050088], Output: [-0.7558140851813584, -0.454092634967716, -0.6903091848178787, -0.3890716063931332]\n",
      "Layer: Layer 2, Input: [-0.7558140851813584, -0.454092634967716, -0.6903091848178787, -0.3890716063931332], Output: [0.42816423435006423]\n",
      "Epoch 27/500, Loss: 0.7249403888051069, Accuracy: -1.8735239961462824\n",
      "Power operation: base = -0.4558293047554274, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4979892295040909, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3478696962368286, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5718357656499358, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9738679743247092, 0.7919948887223026, -0.9680782264371856, -0.9784048975154517]\n",
      "Layer: Layer 1, Input: [0.9738679743247092, 0.7919948887223026, -0.9680782264371856, -0.9784048975154517], Output: [-0.8759655351721877, -0.4461254217825553, -0.7883106448933, -0.5457440776712593]\n",
      "Layer: Layer 2, Input: [-0.8759655351721877, -0.4461254217825553, -0.7883106448933, -0.5457440776712593], Output: [0.5610091657647287]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.996790941191897, 0.7703447455030621, 0.09996635808206153, -0.7674376904946284]\n",
      "Layer: Layer 1, Input: [0.996790941191897, 0.7703447455030621, 0.09996635808206153, -0.7674376904946284], Output: [-0.8259677059932097, -0.47216963076018725, -0.6680420198008913, -0.5039955736690847]\n",
      "Layer: Layer 2, Input: [-0.8259677059932097, -0.47216963076018725, -0.6680420198008913, -0.5039955736690847], Output: [0.5019897025482971]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8915133966127196, -0.6900205167412617, 0.4974073564664465, -0.6542940013825866]\n",
      "Layer: Layer 1, Input: [0.8915133966127196, -0.6900205167412617, 0.4974073564664465, -0.6542940013825866], Output: [0.26781005254455026, -0.4220832259390748, -0.3850495639604206, 0.24469787627738532]\n",
      "Layer: Layer 2, Input: [0.26781005254455026, -0.4220832259390748, -0.3850495639604206, 0.24469787627738532], Output: [-0.6959400424416317]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7852922822308306, 0.8177396455774567, -0.7608356170344064, -0.6828598627043302]\n",
      "Layer: Layer 1, Input: [0.7852922822308306, 0.8177396455774567, -0.7608356170344064, -0.6828598627043302], Output: [-0.7583745721990626, -0.4619653202121031, -0.6912241315033518, -0.3896468430578105]\n",
      "Layer: Layer 2, Input: [-0.7583745721990626, -0.4619653202121031, -0.6912241315033518, -0.3896468430578105], Output: [0.43815095507145485]\n",
      "Epoch 28/500, Loss: 0.7142032065453041, Accuracy: -1.8068895392704816\n",
      "Power operation: base = -0.4389908342352713, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5019897025482971, power = 2, grad = 0.25\n",
      "Power operation: base = 0.30405995755836834, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5618490449285451, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9742803595088256, 0.7940967882300601, -0.9680769523548564, -0.978982598224733]\n",
      "Layer: Layer 1, Input: [0.9742803595088256, 0.7940967882300601, -0.9680769523548564, -0.978982598224733], Output: [-0.8780825128466342, -0.4580508594195186, -0.7891342712847865, -0.5459162297445579]\n",
      "Layer: Layer 2, Input: [-0.8780825128466342, -0.4580508594195186, -0.7891342712847865, -0.5459162297445579], Output: [0.5776128183807262]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.996806183305599, 0.7693643237837021, 0.09962556741952124, -0.7670740809980477]\n",
      "Layer: Layer 1, Input: [0.996806183305599, 0.7693643237837021, 0.09962556741952124, -0.7670740809980477], Output: [-0.825781958917497, -0.4756374019580716, -0.6675733267168308, -0.5030296481222463]\n",
      "Layer: Layer 2, Input: [-0.825781958917497, -0.4756374019580716, -0.6675733267168308, -0.5030296481222463], Output: [0.5060204311702098]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8917437253778226, -0.6922147270990964, 0.49708727534968883, -0.6519281066473811]\n",
      "Layer: Layer 1, Input: [0.8917437253778226, -0.6922147270990964, 0.49708727534968883, -0.6519281066473811], Output: [0.2804549821517262, -0.4106005532431403, -0.38059378124526405, 0.24657130607169547]\n",
      "Layer: Layer 2, Input: [0.2804549821517262, -0.4106005532431403, -0.38059378124526405, 0.24657130607169547], Output: [-0.7391222598447373]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7869256499223708, 0.8178335340010198, -0.7609293947533247, -0.6849774975495255]\n",
      "Layer: Layer 1, Input: [0.7869256499223708, 0.8178335340010198, -0.7609293947533247, -0.6849774975495255], Output: [-0.7611669933908503, -0.46948367967147064, -0.6921975047090857, -0.3903774158071779]\n",
      "Layer: Layer 2, Input: [-0.7611669933908503, -0.46948367967147064, -0.6921975047090857, -0.3903774158071779], Output: [0.4482893961781146]\n",
      "Epoch 29/500, Loss: 0.704737563994101, Accuracy: -1.7409959567666315\n",
      "Power operation: base = -0.4223871816192738, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5060204311702097, power = 2, grad = 0.25\n",
      "Power operation: base = 0.26087774015526266, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5517106038218854, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.974684542206432, 0.7962404884904517, -0.968075440253261, -0.979545130076016]\n",
      "Layer: Layer 1, Input: [0.974684542206432, 0.7962404884904517, -0.968075440253261, -0.979545130076016], Output: [-0.8802511001677206, -0.46943693902395683, -0.7899876026029615, -0.5461704984921764]\n",
      "Layer: Layer 2, Input: [-0.8802511001677206, -0.46943693902395683, -0.7899876026029615, -0.5461704984921764], Output: [0.5939642368663485]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9968216897234661, 0.7684899165798653, 0.09934741831973569, -0.7668252839852965]\n",
      "Layer: Layer 1, Input: [0.9968216897234661, 0.7684899165798653, 0.09934741831973569, -0.7668252839852965], Output: [-0.8257981299385551, -0.47886181572889297, -0.6671561403129596, -0.5022003687586815]\n",
      "Layer: Layer 2, Input: [-0.8257981299385551, -0.47886181572889297, -0.6671561403129596, -0.5022003687586815], Output: [0.5100810510790246]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.891988455107667, -0.69424577649373, 0.49682468710786865, -0.6497467166925748]\n",
      "Layer: Layer 1, Input: [0.891988455107667, -0.69424577649373, 0.49682468710786865, -0.6497467166925748], Output: [0.29216818670049066, -0.3990084267492452, -0.3761903466894616, 0.2483133044783488]\n",
      "Layer: Layer 2, Input: [0.29216818670049066, -0.3990084267492452, -0.3761903466894616, 0.2483133044783488], Output: [-0.7816418482197763]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7885569499644166, 0.8180047233621254, -0.7610048521901221, -0.6871826371629223]\n",
      "Layer: Layer 1, Input: [0.7885569499644166, 0.8180047233621254, -0.7610048521901221, -0.6871826371629223], Output: [-0.7641687846200456, -0.476670892959238, -0.6932275482801474, -0.3912568858023437]\n",
      "Layer: Layer 2, Input: [-0.7641687846200456, -0.476670892959238, -0.6932275482801474, -0.3912568858023437], Output: [0.458559358942763]\n",
      "Epoch 30/500, Loss: 0.6965120180022013, Accuracy: -1.675915607050137\n",
      "Power operation: base = -0.40603576313365153, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5100810510790246, power = 2, grad = 0.25\n",
      "Power operation: base = 0.21835815178022366, power = 2, grad = 0.25\n",
      "Power operation: base = -0.541440641057237, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9750800000726164, 0.7984154520315021, -0.9680738541453938, -0.9800919689941867]\n",
      "Layer: Layer 1, Input: [0.9750800000726164, 0.7984154520315021, -0.9680738541453938, -0.9800919689941867], Output: [-0.8824590031522123, -0.48031073897334897, -0.7908688352130614, -0.5465015824089788]\n",
      "Layer: Layer 2, Input: [-0.8824590031522123, -0.48031073897334897, -0.7908688352130614, -0.5465015824089788], Output: [0.6100464670101398]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9968374266601839, 0.7677191756606192, 0.09912682941189563, -0.7666920446780522]\n",
      "Layer: Layer 1, Input: [0.9968374266601839, 0.7677191756606192, 0.09912682941189563, -0.7666920446780522], Output: [-0.8260102786299817, -0.4818638238058183, -0.6667928640271787, -0.5015076696582582]\n",
      "Layer: Layer 2, Input: [-0.8260102786299817, -0.4818638238058183, -0.6667928640271787, -0.5015076696582582], Output: [0.5141709295053642]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8922469848003932, -0.6961185612190669, 0.4966153536505279, -0.6477564327480975]\n",
      "Layer: Layer 1, Input: [0.8922469848003932, -0.6961185612190669, 0.4966153536505279, -0.6477564327480975], Output: [0.30296453192298933, -0.3873355993950346, -0.37185165758321864, 0.24991762472345413]\n",
      "Layer: Layer 2, Input: [0.30296453192298933, -0.3873355993950346, -0.37185165758321864, 0.24991762472345413], Output: [-0.8234621938366533]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7901831067367402, 0.8182484543706713, -0.7610638130902692, -0.6894699315169666]\n",
      "Layer: Layer 1, Input: [0.7901831067367402, 0.8182484543706713, -0.7610638130902692, -0.6894699315169666], Output: [-0.7673584870902136, -0.4835491963351694, -0.6943124875568893, -0.3922788775319257]\n",
      "Layer: Layer 2, Input: [-0.7673584870902136, -0.4835491963351694, -0.6943124875568893, -0.3922788775319257], Output: [0.46894020498765987]\n",
      "Epoch 31/500, Loss: 0.6894918661334822, Accuracy: -1.6117220636709115\n",
      "Power operation: base = -0.38995353298986024, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5141709295053642, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1765378061633467, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5310597950123401, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9754663050087176, 0.8006123055801472, -0.9680723387551675, -0.9806227788290965]\n",
      "Layer: Layer 1, Input: [0.9754663050087176, 0.8006123055801472, -0.9680723387551675, -0.9806227788290965], Output: [-0.8846952420475293, -0.4906983768374472, -0.7917761753855337, -0.5469043689275435]\n",
      "Layer: Layer 2, Input: [-0.8846952420475293, -0.4906983768374472, -0.7917761753855337, -0.5469043689275435], Output: [0.6258430733579528]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9968533623527612, 0.7670499874110206, 0.09895877452227421, -0.7666749709916663]\n",
      "Layer: Layer 1, Input: [0.9968533623527612, 0.7670499874110206, 0.09895877452227421, -0.7666749709916663], Output: [-0.8264124120636694, -0.48466370591103586, -0.666485745062751, -0.5009511543672093]\n",
      "Layer: Layer 2, Input: [-0.8264124120636694, -0.48466370591103586, -0.666485745062751, -0.5009511543672093], Output: [0.5182891825165661]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.892518720290737, -0.6978373969802092, 0.49645502294417065, -0.6459633400454645]\n",
      "Layer: Layer 1, Input: [0.892518720290737, -0.6978373969802092, 0.49645502294417065, -0.6459633400454645], Output: [0.3128585894038611, -0.37561144614060177, -0.3675898824541508, 0.2513783425532141]\n",
      "Layer: Layer 2, Input: [0.3128585894038611, -0.37561144614060177, -0.3675898824541508, 0.2513783425532141], Output: [-0.8645450873319144]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7918013271349775, 0.8185603789398024, -0.7611080368589813, -0.691834521120381]\n",
      "Layer: Layer 1, Input: [0.7918013271349775, 0.8185603789398024, -0.7611080368589813, -0.691834521120381], Output: [-0.7707159501244085, -0.4901397777376436, -0.6954505437114593, -0.39343715534421386]\n",
      "Layer: Layer 2, Input: [-0.7707159501244085, -0.4901397777376436, -0.6954505437114593, -0.39343715534421386], Output: [0.4794111032406454]\n",
      "Epoch 32/500, Loss: 0.6836390700740212, Accuracy: -1.5484899185860534\n",
      "Power operation: base = -0.37415692664204725, power = 2, grad = 0.25\n",
      "Power operation: base = 1.518289182516566, power = 2, grad = 0.25\n",
      "Power operation: base = 0.13545491266808563, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5205888967593546, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9758431178660688, 0.8028228365069017, -0.9680710211166712, -0.9811373918381475]\n",
      "Layer: Layer 1, Input: [0.9758431178660688, 0.8028228365069017, -0.9680710211166712, -0.9811373918381475], Output: [-0.8869501497906151, -0.5006248638312979, -0.7927078430691148, -0.5473739575543013]\n",
      "Layer: Layer 2, Input: [-0.8869501497906151, -0.5006248638312979, -0.7927078430691148, -0.5473739575543013], Output: [0.6413381416213277]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9968694671770898, 0.7664805112036285, 0.0988383077208331, -0.7667745471828854]\n",
      "Layer: Layer 1, Input: [0.9968694671770898, 0.7664805112036285, 0.0988383077208331, -0.7667745471828854], Output: [-0.8269985962999105, -0.48728093386699023, -0.6662368633067941, -0.500530148774992]\n",
      "Layer: Layer 2, Input: [-0.8269985962999105, -0.48728093386699023, -0.6662368633067941, -0.500530148774992], Output: [0.5224346404438234]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8928030789918203, -0.6994060121381545, 0.49633945894444065, -0.6443730094392792]\n",
      "Layer: Layer 1, Input: [0.8928030789918203, -0.6994060121381545, 0.49633945894444065, -0.6443730094392792], Output: [0.32186424526512764, -0.36386562542707584, -0.36341689438430147, 0.2526898273686813]\n",
      "Layer: Layer 2, Input: [0.32186424526512764, -0.36386562542707584, -0.36341689438430147, 0.2526898273686813], Output: [-0.9048507665657062]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7934091015891064, 0.8189365912112594, -0.7611392162692363, -0.6942720461958729]\n",
      "Layer: Layer 1, Input: [0.7934091015891064, 0.8189365912112594, -0.7611392162692363, -0.6942720461958729], Output: [-0.774222461733402, -0.4964626796846995, -0.6966399390265721, -0.39472567901008165]\n",
      "Layer: Layer 2, Input: [-0.774222461733402, -0.4964626796846995, -0.6966399390265721, -0.39472567901008165], Output: [0.48995119050093994]\n",
      "Epoch 33/500, Loss: 0.6789121819433747, Accuracy: -1.4862945417558495\n",
      "Power operation: base = -0.35866185837867226, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5224346404438234, power = 2, grad = 0.25\n",
      "Power operation: base = 0.09514923343429382, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5100488094990601, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9762101823947033, 0.8050399689512853, -0.9680700124021913, -0.9816357887078052]\n",
      "Layer: Layer 1, Input: [0.9762101823947033, 0.8050399689512853, -0.9680700124021913, -0.9816357887078052], Output: [-0.889215339452877, -0.5101139876868218, -0.7936620723124928, -0.5479056748328874]\n",
      "Layer: Layer 2, Input: [-0.889215339452877, -0.5101139876868218, -0.7936620723124928, -0.5479056748328874], Output: [0.6565162500173483]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9968857137068743, 0.7660092070113781, 0.09876058234391231, -0.7669911397577988]\n",
      "Layer: Layer 1, Input: [0.9968857137068743, 0.7660092070113781, 0.09876058234391231, -0.7669911397577988], Output: [-0.8277630383907363, -0.48973404454916897, -0.6660481164887081, -0.5002437445635797]\n",
      "Layer: Layer 2, Input: [-0.8277630383907363, -0.48973404454916897, -0.6660481164887081, -0.5002437445635797], Output: [0.5266057801608011]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.893099493439121, -0.7008275477350914, 0.4962644663762949, -0.6429904940731328]\n",
      "Layer: Layer 1, Input: [0.893099493439121, -0.7008275477350914, 0.4962644663762949, -0.6429904940731328], Output: [0.32999438642140067, -0.3521277289931521, -0.35934419935401335, 0.25384672233068273]\n",
      "Layer: Layer 2, Input: [0.32999438642140067, -0.3521277289931521, -0.35934419935401335, 0.25384672233068273], Output: [-0.9443380607237487]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.795004200204798, 0.8193736462313345, -0.7611589772232508, -0.6967786390036813]\n",
      "Layer: Layer 1, Input: [0.795004200204798, 0.8193736462313345, -0.7611589772232508, -0.6967786390036813], Output: [-0.7778608189950736, -0.5025367160723311, -0.6978788954510732, -0.39613864158721046]\n",
      "Layer: Layer 2, Input: [-0.7778608189950736, -0.5025367160723311, -0.6978788954510732, -0.39613864158721046], Output: [0.5005396693428577]\n",
      "Epoch 34/500, Loss: 0.6752662919766621, Accuracy: -1.4252118000768466\n",
      "Power operation: base = -0.34348374998265174, power = 2, grad = 0.25\n",
      "Power operation: base = 1.526605780160801, power = 2, grad = 0.25\n",
      "Power operation: base = 0.05566193927625129, power = 2, grad = 0.25\n",
      "Power operation: base = -0.49946033065714235, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9765673187504212, 0.8072577247230651, -0.9680694098809921, -0.9821180788574775]\n",
      "Layer: Layer 1, Input: [0.9765673187504212, 0.8072577247230651, -0.9680694098809921, -0.9821180788574775], Output: [-0.891483648559133, -0.5191882258788447, -0.7946371095031122, -0.5484950828432803]\n",
      "Layer: Layer 2, Input: [-0.891483648559133, -0.5191882258788447, -0.7946371095031122, -0.5484950828432803], Output: [0.6713624271336283]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9969020767260868, 0.7656348539726245, 0.09872086492865076, -0.767324997094298]\n",
      "Layer: Layer 1, Input: [0.9969020767260868, 0.7656348539726245, 0.09872086492865076, -0.767324997094298], Output: [-0.8287001425359087, -0.4920405264149586, -0.6659212030139078, -0.5000908341939092]\n",
      "Layer: Layer 2, Input: [-0.8287001425359087, -0.4920405264149586, -0.6659212030139078, -0.5000908341939092], Output: [0.5308006388668882]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8934074138363689, -0.7021045620976699, 0.496225910937161, -0.6418203220910779]\n",
      "Layer: Layer 1, Input: [0.8934074138363689, -0.7021045620976699, 0.496225910937161, -0.6418203220910779], Output: [0.33726065040633707, -0.34042693033190335, -0.35538286199782315, 0.2548439318048072]\n",
      "Layer: Layer 2, Input: [0.33726065040633707, -0.34042693033190335, -0.35538286199782315, 0.2548439318048072], Output: [-0.9829646079203349]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7965846651336226, 0.8198685685254014, -0.7611688800892444, -0.6993509031430708]\n",
      "Layer: Layer 1, Input: [0.7965846651336226, 0.8198685685254014, -0.7611688800892444, -0.6993509031430708], Output: [-0.7816153490716886, -0.5083794066792903, -0.6991656284722044, -0.3976704926687034]\n",
      "Layer: Layer 2, Input: [-0.7816153490716886, -0.5083794066792903, -0.6991656284722044, -0.3976704926687034], Output: [0.5111558625092771]\n",
      "Epoch 35/500, Loss: 0.6726530113992824, Accuracy: -1.365317741303648\n",
      "Power operation: base = -0.32863757286637174, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5308006388668882, power = 2, grad = 0.25\n",
      "Power operation: base = 0.01703539207966509, power = 2, grad = 0.25\n",
      "Power operation: base = -0.48884413749072286, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9769144168083244, 0.8094711731807971, -0.9680692989301848, -0.9825844815449739]\n",
      "Layer: Layer 1, Input: [0.9769144168083244, 0.8094711731807971, -0.9680692989301848, -0.9825844815449739], Output: [-0.8937490668276018, -0.5278686891365968, -0.7956312103900678, -0.549137982776939]\n",
      "Layer: Layer 2, Input: [-0.8937490668276018, -0.5278686891365968, -0.7956312103900678, -0.549137982776939], Output: [0.6858621089901185]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9969185332043613, 0.7653565612997002, 0.09871454489857022, -0.7677762439796948]\n",
      "Layer: Layer 1, Input: [0.9969185332043613, 0.7653565612997002, 0.09871454489857022, -0.7677762439796948], Output: [-0.8298045437054331, -0.49421672273035466, -0.6658576037147224, -0.5000701384219913]\n",
      "Layer: Layer 2, Input: [-0.8298045437054331, -0.49421672273035466, -0.6658576037147224, -0.5000701384219913], Output: [0.5350167204135403]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8937263097711939, -0.7032390383944066, 0.49621973547441595, -0.6408664861792223]\n",
      "Layer: Layer 1, Input: [0.8937263097711939, -0.7032390383944066, 0.49621973547441595, -0.6408664861792223], Output: [0.3436732273669585, -0.32879164118841925, -0.35154343089180506, 0.2556766147610083]\n",
      "Layer: Layer 2, Input: [0.3436732273669585, -0.32879164118841925, -0.35154343089180506, 0.2556766147610083], Output: [-1.0206871223767724]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7981488000981537, 0.8204188524412723, -0.7611704222101027, -0.7019858829489123]\n",
      "Layer: Layer 1, Input: [0.7981488000981537, 0.8204188524412723, -0.7611704222101027, -0.7019858829489123], Output: [-0.7854718903063156, -0.514006931385862, -0.700498338011384, -0.3993159497620912]\n",
      "Layer: Layer 2, Input: [-0.7854718903063156, -0.514006931385862, -0.700498338011384, -0.3993159497620912], Output: [0.5217792387163582]\n",
      "Epoch 36/500, Loss: 0.6710205000180536, Accuracy: -1.3480624950838358\n",
      "Power operation: base = -0.31413789100988154, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5350167204135403, power = 2, grad = 0.25\n",
      "Power operation: base = -0.020687122376772393, power = 2, grad = 0.25\n",
      "Power operation: base = -0.47822076128364177, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9772514294735837, 0.8116763734536822, -0.9680697550349243, -0.9830353081101866]\n",
      "Layer: Layer 1, Input: [0.9772514294735837, 0.8116763734536822, -0.9680697550349243, -0.9830353081101866], Output: [-0.8960066526149648, -0.5361750937040924, -0.7966426366541466, -0.5498304149030602]\n",
      "Layer: Layer 2, Input: [-0.8960066526149648, -0.5361750937040924, -0.7966426366541466, -0.5498304149030602], Output: [0.7000011038301905]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9969350622430905, 0.7651737726080968, 0.09873714075577024, -0.768344872012269]\n",
      "Layer: Layer 1, Input: [0.9969350622430905, 0.7651737726080968, 0.09873714075577024, -0.768344872012269], Output: [-0.8310711216405747, -0.4962777532829386, -0.6658585635436748, -0.5001802272693051]\n",
      "Layer: Layer 2, Input: [-0.8310711216405747, -0.4962777532829386, -0.6658585635436748, -0.5001802272693051], Output: [0.5392509020930183]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8940556712374259, -0.7042323940146011, 0.49624197266418485, -0.640132430496249]\n",
      "Layer: Layer 1, Input: [0.8940556712374259, -0.7042323940146011, 0.49624197266418485, -0.640132430496249], Output: [0.34924070529191903, -0.3172491843772096, -0.3478358651877241, 0.25634018302633926]\n",
      "Layer: Layer 2, Input: [0.34924070529191903, -0.3172491843772096, -0.3478358651877241, 0.25634018302633926], Output: [-1.0574616911814547]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7996951578310858, 0.8210224557640231, -0.7611650412423274, -0.7046810254404217]\n",
      "Layer: Layer 1, Input: [0.7996951578310858, 0.8210224557640231, -0.7611650412423274, -0.7046810254404217], Output: [-0.7894177414308978, -0.5194341046798627, -0.7018751977116653, -0.40107000013492927]\n",
      "Layer: Layer 2, Input: [-0.7894177414308978, -0.5194341046798627, -0.7018751977116653, -0.40107000013492927], Output: [0.532389421030121]\n",
      "Epoch 37/500, Loss: 0.6703135442038133, Accuracy: -1.3643220684141615\n",
      "Power operation: base = -0.29999889616980946, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5392509020930183, power = 2, grad = 0.25\n",
      "Power operation: base = -0.05746169118145472, power = 2, grad = 0.25\n",
      "Power operation: base = -0.467610578969879, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9775783661313998, 0.8138703116228527, -0.9680708457279591, -0.9834709455504989]\n",
      "Layer: Layer 1, Input: [0.9775783661313998, 0.8138703116228527, -0.9680708457279591, -0.9834709455504989], Output: [-0.8982524422194194, -0.5441257597972298, -0.797669652595879, -0.550568655993327]\n",
      "Layer: Layer 2, Input: [-0.8982524422194194, -0.5441257597972298, -0.797669652595879, -0.550568655993327], Output: [0.7137655698077452]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.996951644998498, 0.7650862644504155, 0.09878430346429859, -0.7690307265852495]\n",
      "Layer: Layer 1, Input: [0.996951644998498, 0.7650862644504155, 0.09878430346429859, -0.7690307265852495], Output: [-0.8324949977336793, -0.4982374552791537, -0.6659250740141203, -0.5004195352488877]\n",
      "Layer: Layer 2, Input: [-0.8324949977336793, -0.4982374552791537, -0.6659250740141203, -0.5004195352488877], Output: [0.5434993471936624]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8943950090726401, -0.7050854910457895, 0.49628875469533307, -0.6396210353398798]\n",
      "Layer: Layer 1, Input: [0.8943950090726401, -0.7050854910457895, 0.49628875469533307, -0.6396210353398798], Output: [0.3539699517976128, -0.30582548988625485, -0.34426946408983994, 0.25683030358058717]\n",
      "Layer: Layer 2, Input: [0.3539699517976128, -0.30582548988625485, -0.34426946408983994, 0.25683030358058717], Output: [-1.0932440845562006]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8012225260385942, 0.8216777877649212, -0.761154119033383, -0.7074341367015281]\n",
      "Layer: Layer 1, Input: [0.8012225260385942, 0.8216777877649212, -0.761154119033383, -0.7074341367015281], Output: [-0.7934415855944782, -0.5246743699119087, -0.7032943436645165, -0.4029278950358036]\n",
      "Layer: Layer 2, Input: [-0.7934415855944782, -0.5246743699119087, -0.7032943436645165, -0.4029278950358036], Output: [0.5429661857585997]\n",
      "Epoch 38/500, Loss: 0.6704736876198784, Accuracy: -1.3800116761835182\n",
      "Power operation: base = -0.2862344301922548, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5434993471936624, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09324408455620059, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4570338142414003, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9778952863376014, 0.8160508348256215, -0.9680726324286532, -0.983891841513318]\n",
      "Layer: Layer 1, Input: [0.9778952863376014, 0.8160508348256215, -0.9680726324286532, -0.983891841513318], Output: [-0.9004833552203322, -0.5517376330642846, -0.7987105223412317, -0.5513492150258509]\n",
      "Layer: Layer 2, Input: [-0.9004833552203322, -0.5517376330642846, -0.7987105223412317, -0.5513492150258509], Output: [0.727142008104529]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9969682645866548, 0.7650941395767868, 0.09885181765050302, -0.7698334909756341]\n",
      "Layer: Layer 1, Input: [0.9969682645866548, 0.7650941395767868, 0.09885181765050302, -0.7698334909756341], Output: [-0.8340715169107128, -0.5001083432487143, -0.6660578569843003, -0.5007863715010795]\n",
      "Layer: Layer 2, Input: [-0.8340715169107128, -0.5001083432487143, -0.6660578569843003, -0.5007863715010795], Output: [0.54775742650976]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8947438548947283, -0.7057986474643972, 0.49635632044122474, -0.6393345997149513]\n",
      "Layer: Layer 1, Input: [0.8947438548947283, -0.7057986474643972, 0.49635632044122474, -0.6393345997149513], Output: [0.35786602781096843, -0.2945448197967588, -0.34085280035428056, 0.25714290436032816]\n",
      "Layer: Layer 2, Input: [0.35786602781096843, -0.2945448197967588, -0.34085280035428056, 0.25714290436032816], Output: [-1.1279900673679808]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8027299123692326, 0.8223836925441188, -0.7611389857847809, -0.7102433340899285]\n",
      "Layer: Layer 1, Input: [0.8027299123692326, 0.8223836925441188, -0.7611389857847809, -0.7102433340899285], Output: [-0.7975333947432438, -0.5297398119346434, -0.7047538633367898, -0.40488513779220364]\n",
      "Layer: Layer 2, Input: [-0.7975333947432438, -0.5297398119346434, -0.7047538633367898, -0.40488513779220364], Output: [0.5534894571629936]\n",
      "Epoch 39/500, Loss: 0.6714394143167006, Accuracy: -1.395116028610218\n",
      "Power operation: base = -0.272857991895471, power = 2, grad = 0.25\n",
      "Power operation: base = 1.54775742650976, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1279900673679808, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4465105428370064, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9782022938184237, 0.8182165836922111, -0.9680751721494822, -0.9842984907128258]\n",
      "Layer: Layer 1, Input: [0.9782022938184237, 0.8182165836922111, -0.9680751721494822, -0.9842984907128258], Output: [-0.9026970982209243, -0.55902632552059, -0.7997635078196855, -0.5521688277591138]\n",
      "Layer: Layer 2, Input: [-0.9026970982209243, -0.55902632552059, -0.7997635078196855, -0.5521688277591138], Output: [0.7401172720505591]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9969849059743069, 0.7651978152160076, 0.09893560119768359, -0.7707526679052669]\n",
      "Layer: Layer 1, Input: [0.9969849059743069, 0.7651978152160076, 0.09893560119768359, -0.7707526679052669], Output: [-0.83579621632746, -0.501901587097795, -0.6662573501939848, -0.5012789253443025]\n",
      "Layer: Layer 2, Input: [-0.83579621632746, -0.501901587097795, -0.6662573501939848, -0.5012789253443025], Output: [0.5520196503607964]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8951017606002675, -0.7063716489310251, 0.49644102058218986, -0.6392748218290346]\n",
      "Layer: Layer 1, Input: [0.8951017606002675, -0.7063716489310251, 0.49644102058218986, -0.6392748218290346], Output: [0.3609321302627583, -0.2834295260579092, -0.33759365869407065, 0.2572741832817325]\n",
      "Layer: Layer 2, Input: [0.3609321302627583, -0.2834295260579092, -0.33759365869407065, 0.2572741832817325], Output: [-1.1616557032677663]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8042165287605066, 0.823139428264777, -0.7611209242789312, -0.7131069952871182]\n",
      "Layer: Layer 1, Input: [0.8042165287605066, 0.823139428264777, -0.7611209242789312, -0.7131069952871182], Output: [-0.8016843188840708, -0.5346411861824552, -0.7062517852150212, -0.40693746692326194]\n",
      "Layer: Layer 2, Input: [-0.8016843188840708, -0.5346411861824552, -0.7062517852150212, -0.40693746692326194], Output: [0.5639393012270584]\n",
      "Epoch 40/500, Loss: 0.6731463817014586, Accuracy: -1.4096187803509452\n",
      "Power operation: base = -0.2598827279494409, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5520196503607964, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16165570326776635, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4360606987729416, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9784995308217831, 0.8203669240640494, -0.968078519044099, -0.9846914227241114]\n",
      "Layer: Layer 1, Input: [0.9784995308217831, 0.8203669240640494, -0.968078519044099, -0.9846914227241114], Output: [-0.9048920687036032, -0.5660061723365175, -0.8008268676531409, -0.5530244505633148]\n",
      "Layer: Layer 2, Input: [-0.9048920687036032, -0.5660061723365175, -0.8008268676531409, -0.5530244505633148], Output: [0.7526785914545551]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9970015558584575, 0.7653980064808363, 0.09903170377180966, -0.7717875588309167]\n",
      "Layer: Layer 1, Input: [0.9970015558584575, 0.7653980064808363, 0.09903170377180966, -0.7717875588309167], Output: [-0.8376647824563183, -0.5036270069487174, -0.6665236948051297, -0.5018952676131839]\n",
      "Layer: Layer 2, Input: [-0.8376647824563183, -0.5036270069487174, -0.6665236948051297, -0.5018952676131839], Output: [0.5562796114987876]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.895468297470249, -0.7068037613086743, 0.4965393211230849, -0.6394427774504668]\n",
      "Layer: Layer 1, Input: [0.895468297470249, -0.7068037613086743, 0.4965393211230849, -0.6394427774504668], Output: [0.36316956246155246, -0.2724998436902706, -0.33449897970728437, 0.2572206203961975]\n",
      "Layer: Layer 2, Input: [0.36316956246155246, -0.2724998436902706, -0.33449897970728437, 0.2572206203961975], Output: [-1.1941976462551478]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8056817754444763, 0.8239446426557421, -0.7611011739718075, -0.7160237049107172]\n",
      "Layer: Layer 1, Input: [0.8056817754444763, 0.8239446426557421, -0.7611011739718075, -0.7160237049107172], Output: [-0.8058865639478234, -0.5393879618877564, -0.7077860694876021, -0.4090808350996595]\n",
      "Layer: Layer 2, Input: [-0.8058865639478234, -0.5393879618877564, -0.7077860694876021, -0.4090808350996595], Output: [0.5742959202102182]\n",
      "Epoch 41/500, Loss: 0.6755276994131061, Accuracy: -1.423502746089162\n",
      "Power operation: base = -0.24732140854544493, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5562796114987876, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1941976462551478, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42570407978978175, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9787871728418107, 0.8225018785677399, -0.9680827257758067, -0.9850711910733594]\n",
      "Layer: Layer 1, Input: [0.9787871728418107, 0.8225018785677399, -0.9680827257758067, -0.9850711910733594], Output: [-0.9070672601929515, -0.5726903009564983, -0.8018988570062592, -0.5539132537248215]\n",
      "Layer: Layer 2, Input: [-0.9070672601929515, -0.5726903009564983, -0.8018988570062592, -0.5539132537248215], Output: [0.7648136104968912]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9970182025369038, 0.7656957048469519, 0.09913630478014432, -0.7729372411540881]\n",
      "Layer: Layer 1, Input: [0.9970182025369038, 0.7656957048469519, 0.09913630478014432, -0.7729372411540881], Output: [-0.8396729979923385, -0.5052930830624105, -0.6668567250733255, -0.5026333480500795]\n",
      "Layer: Layer 2, Input: [-0.8396729979923385, -0.5052930830624105, -0.6668567250733255, -0.5026333480500795], Output: [0.5605299385297462]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8958430549151213, -0.7070937442092841, 0.49664780573208, -0.6398388960254552]\n",
      "Layer: Layer 1, Input: [0.8958430549151213, -0.7070937442092841, 0.49664780573208, -0.6398388960254552], Output: [0.3645777321843256, -0.2617737206213482, -0.331574809720511, 0.25697899324941936]\n",
      "Layer: Layer 2, Input: [0.3645777321843256, -0.2617737206213482, -0.331574809720511, 0.25697899324941936], Output: [-1.2255734176134867]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8071252248193019, 0.8247993449795705, -0.7610809347725993, -0.7189921992058633]\n",
      "Layer: Layer 1, Input: [0.8071252248193019, 0.8247993449795705, -0.7610809347725993, -0.7189921992058633], Output: [-0.810133261331925, -0.5439883769575652, -0.7093545999362757, -0.4113113845416833]\n",
      "Layer: Layer 2, Input: [-0.810133261331925, -0.5439883769575652, -0.7093545999362757, -0.4113113845416833], Output: [0.5845396487024841]\n",
      "Epoch 42/500, Loss: 0.6785142492723113, Accuracy: -1.4367500969438574\n",
      "Power operation: base = -0.23518638950310877, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5605299385297462, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2255734176134867, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4154603512975159, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9790654237225775, 0.824622058320361, -0.9680878446889786, -0.9854383635233133]\n",
      "Layer: Layer 1, Input: [0.9790654237225775, 0.824622058320361, -0.9680878446889786, -0.9854383635233133], Output: [-0.909222169533139, -0.5790907092680486, -0.8029777283875421, -0.5548326143015393]\n",
      "Layer: Layer 2, Input: [-0.909222169533139, -0.5790907092680486, -0.8029777283875421, -0.5548326143015393], Output: [0.7765104371077232]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9970348357713347, 0.7660921515378617, 0.09924571123302695, -0.7742005435189211]\n",
      "Layer: Layer 1, Input: [0.9970348357713347, 0.7660921515378617, 0.09924571123302695, -0.7742005435189211], Output: [-0.8418166799453976, -0.5069069789465362, -0.6672559601867716, -0.5034909889439877]\n",
      "Layer: Layer 2, Input: [-0.8418166799453976, -0.5069069789465362, -0.6672559601867716, -0.5034909889439877], Output: [0.5647622591059571]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8962256388808286, -0.7072398660296337, 0.4967631773079484, -0.6404629344675241]\n",
      "Layer: Layer 1, Input: [0.8962256388808286, -0.7072398660296337, 0.4967631773079484, -0.6404629344675241], Output: [0.36515417872217626, -0.25126668414362896, -0.3288262567611547, 0.2565463956203432]\n",
      "Layer: Layer 2, Input: [0.36515417872217626, -0.25126668414362896, -0.3288262567611547, 0.2565463956203432], Output: [-1.2557416689969407]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8085466053334055, 0.8257038745207852, -0.7610613703473483, -0.7220113092057046]\n",
      "Layer: Layer 1, Input: [0.8085466053334055, 0.8257038745207852, -0.7610613703473483, -0.7220113092057046], Output: [-0.8144183317303887, -0.5484495020211907, -0.710955177104445, -0.4136254192713881]\n",
      "Layer: Layer 2, Input: [-0.8144183317303887, -0.5484495020211907, -0.710955177104445, -0.4136254192713881], Output: [0.5946509513418079]\n",
      "Epoch 43/500, Loss: 0.6820350411884004, Accuracy: -1.449342539653367\n",
      "Power operation: base = -0.22348956289227684, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5647622591059571, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25574166899694073, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4053490486581921, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9793345111349687, 0.8267285948114707, -0.9680939287689629, -0.9857935134452178]\n",
      "Layer: Layer 1, Input: [0.9793345111349687, 0.8267285948114707, -0.9680939287689629, -0.9857935134452178], Output: [-0.9113567068087165, -0.5852183498813439, -0.8040617333526082, -0.5557801085029266]\n",
      "Layer: Layer 2, Input: [-0.9113567068087165, -0.5852183498813439, -0.8040617333526082, -0.5557801085029266], Output: [0.7877577016612574]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9970514466441363, 0.7665888055678414, 0.09935635594868586, -0.7755760193856546]\n",
      "Layer: Layer 1, Input: [0.9970514466441363, 0.7665888055678414, 0.09935635594868586, -0.7755760193856546], Output: [-0.8440916103070367, -0.5084745756913002, -0.6677205982534736, -0.5044658751770945]\n",
      "Layer: Layer 2, Input: [-0.8440916103070367, -0.5084745756913002, -0.6677205982534736, -0.5044658751770945], Output: [0.568967172113771]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8966156699303522, -0.7072399210684213, 0.4968822591627742, -0.6413139486045437]\n",
      "Layer: Layer 1, Input: [0.8966156699303522, -0.7072399210684213, 0.4968822591627742, -0.6413139486045437], Output: [0.36489463117820675, -0.24099174297601528, -0.3262574527437812, 0.25592025986980027]\n",
      "Layer: Layer 2, Input: [0.36489463117820675, -0.24099174297601528, -0.3262574527437812, 0.25592025986980027], Output: [-1.284662434942775]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8099457854808868, 0.8266588655442159, -0.7610436107974679, -0.7250799026932786]\n",
      "Layer: Layer 1, Input: [0.8099457854808868, 0.8266588655442159, -0.7610436107974679, -0.7250799026932786], Output: [-0.818736345536814, -0.5527773112779641, -0.7125855127467211, -0.4160193745247193]\n",
      "Layer: Layer 2, Input: [-0.818736345536814, -0.5527773112779641, -0.7125855127467211, -0.4160193745247193], Output: [0.6046104221825304]\n",
      "Epoch 44/500, Loss: 0.6860176001222555, Accuracy: -1.4612614832127586\n",
      "Power operation: base = -0.21224229833874264, power = 2, grad = 0.25\n",
      "Power operation: base = 1.568967172113771, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2846624349427751, power = 2, grad = 0.25\n",
      "Power operation: base = -0.39538957781746964, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9795946824118382, 0.8288230718383104, -0.9681010323785264, -0.9861372121689788]\n",
      "Layer: Layer 1, Input: [0.9795946824118382, 0.8288230718383104, -0.9681010323785264, -0.9861372121689788], Output: [-0.9134711082555607, -0.5910832179848111, -0.8051491250429452, -0.5567535034967291]\n",
      "Layer: Layer 2, Input: [-0.9134711082555607, -0.5910832179848111, -0.8051491250429452, -0.5567535034967291], Output: [0.7985446229807909]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9970680274097141, 0.7671873061529492, 0.09946479650977277, -0.7770619191251428]\n",
      "Layer: Layer 1, Input: [0.9970680274097141, 0.7671873061529492, 0.09946479650977277, -0.7770619191251428], Output: [-0.8464934607796926, -0.5100005156295957, -0.6682495123932886, -0.5055555408457036]\n",
      "Layer: Layer 2, Input: [-0.8464934607796926, -0.5100005156295957, -0.6682495123932886, -0.5055555408457036], Output: [0.573134228336829]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8970127810110012, -0.7070912494264225, 0.4970019961841344, -0.6423902623951352]\n",
      "Layer: Layer 1, Input: [0.8970127810110012, -0.7070912494264225, 0.4970019961841344, -0.6423902623951352], Output: [0.3637931012371931, -0.23095932313446685, -0.3238715218792227, 0.25509838312889993]\n",
      "Layer: Layer 2, Input: [0.3637931012371931, -0.23095932313446685, -0.3238715218792227, 0.25509838312889993], Output: [-1.3122973801970843]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8113227579693723, 0.8276652086044726, -0.7610287545772635, -0.7281968253002948]\n",
      "Layer: Layer 1, Input: [0.8113227579693723, 0.8276652086044726, -0.7610287545772635, -0.7281968253002948], Output: [-0.823082381913931, -0.556976757995278, -0.7142432255366994, -0.4184897835811905]\n",
      "Layer: Layer 2, Input: [-0.823082381913931, -0.556976757995278, -0.7142432255366994, -0.4184897835811905], Output: [0.6143987858485171]\n",
      "Epoch 45/500, Loss: 0.6903883798319805, Accuracy: -1.472488199704605\n",
      "Power operation: base = -0.20145537701920913, power = 2, grad = 0.25\n",
      "Power operation: base = 1.573134228336829, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3122973801970843, power = 2, grad = 0.25\n",
      "Power operation: base = -0.38560121415148285, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9798462007203204, 0.8309074572583424, -0.9681092117611745, -0.9864700222100599]\n",
      "Layer: Layer 1, Input: [0.9798462007203204, 0.8309074572583424, -0.9681092117611745, -0.9864700222100599], Output: [-0.9155658524090139, -0.5966944406782698, -0.8062381614907754, -0.5577507485032275]\n",
      "Layer: Layer 2, Input: [-0.9155658524090139, -0.5966944406782698, -0.8062381614907754, -0.5577507485032275], Output: [0.8088610799907212]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9970845713409225, 0.7678894291986238, 0.0995677153463354, -0.7786561609737408]\n",
      "Layer: Layer 1, Input: [0.9970845713409225, 0.7678894291986238, 0.0995677153463354, -0.7786561609737408], Output: [-0.849017713224641, -0.5114882535695758, -0.6688412488960657, -0.5067573526691334]\n",
      "Layer: Layer 2, Input: [-0.849017713224641, -0.5114882535695758, -0.6688412488960657, -0.5067573526691334], Output: [0.5772519195628385]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8974166149162731, -0.7067907604829524, 0.4971194563144359, -0.643689435205578]\n",
      "Layer: Layer 1, Input: [0.8974166149162731, -0.7067907604829524, 0.4971194563144359, -0.643689435205578], Output: [0.36184201440586206, -0.2211772352903267, -0.32167055528980215, 0.25407895750439813]\n",
      "Layer: Layer 2, Input: [0.36184201440586206, -0.2211772352903267, -0.32167055528980215, 0.25407895750439813], Output: [-1.338610048945167]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8126776240933913, 0.8287240080553879, -0.7610178695282844, -0.7313608411352287]\n",
      "Layer: Layer 1, Input: [0.8126776240933913, 0.8287240080553879, -0.7610178695282844, -0.7313608411352287], Output: [-0.8274518885439814, -0.561051852804518, -0.7159258380122654, -0.42103324227789446]\n",
      "Layer: Layer 2, Input: [-0.8274518885439814, -0.561051852804518, -0.7159258380122654, -0.42103324227789446], Output: [0.6239969009959421]\n",
      "Epoch 46/500, Loss: 0.695073200053569, Accuracy: -1.483003987521342\n",
      "Power operation: base = -0.1911389200092788, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5772519195628385, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3386100489451671, power = 2, grad = 0.25\n",
      "Power operation: base = -0.37600309900405793, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9800893415460666, 0.832984034264621, -0.9681185253039489, -0.9867924912829856]\n",
      "Layer: Layer 1, Input: [0.9800893415460666, 0.832984034264621, -0.9681185253039489, -0.9867924912829856], Output: [-0.9176415797074942, -0.6020603661252047, -0.8073271096294943, -0.5587699650244066]\n",
      "Layer: Layer 2, Input: [-0.9176415797074942, -0.6020603661252047, -0.8073271096294943, -0.5587699650244066], Output: [0.818697687801148]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9971010725710668, 0.768697037614781, 0.09966192128114036, -0.7803563013139309]\n",
      "Layer: Layer 1, Input: [0.9971010725710668, 0.768697037614781, 0.09966192128114036, -0.7803563013139309], Output: [-0.8516595777123965, -0.5129401140761483, -0.6694940274364496, -0.5080684904859201]\n",
      "Layer: Layer 2, Input: [-0.8516595777123965, -0.5129401140761483, -0.6694940274364496, -0.5080684904859201], Output: [0.5813076767658385]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8978268214525418, -0.7063349608137388, 0.49723183265402726, -0.6452082276671901]\n",
      "Layer: Layer 1, Input: [0.8978268214525418, -0.7063349608137388, 0.49723183265402726, -0.6452082276671901], Output: [0.35903238433320606, -0.2116506710126246, -0.3196555918373165, 0.2528606043727507]\n",
      "Layer: Layer 2, Input: [0.35903238433320606, -0.2116506710126246, -0.3196555918373165, 0.2528606043727507], Output: [-1.3635661242905324]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8140105783269332, 0.8298365356141896, -0.761011992923615, -0.7345705734370963]\n",
      "Layer: Layer 1, Input: [0.8140105783269332, 0.8298365356141896, -0.761011992923615, -0.7345705734370963], Output: [-0.8318405440891599, -0.5650057432898691, -0.7176307747637698, -0.4236463715362399]\n",
      "Layer: Layer 2, Input: [-0.8318405440891599, -0.5650057432898691, -0.7176307747637698, -0.4236463715362399], Output: [0.6333857671777676]\n",
      "Epoch 47/500, Loss: 0.6999977048616742, Accuracy: -1.4927903460774554\n",
      "Power operation: base = -0.18130231219885196, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5813076767658385, power = 2, grad = 0.25\n",
      "Power operation: base = -0.36356612429053237, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3666142328222324, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9803243894619101, 0.8350553318835496, -0.9681290335547421, -0.9871051470258452]\n",
      "Layer: Layer 1, Input: [0.9803243894619101, 0.8350553318835496, -0.9681290335547421, -0.9871051470258452], Output: [-0.9196990158015911, -0.6071886512874436, -0.8084142499655017, -0.5598094360675092]\n",
      "Layer: Layer 2, Input: [-0.9196990158015911, -0.6071886512874436, -0.8084142499655017, -0.5598094360675092], Output: [0.8280458775054642]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9971175259319461, 0.7696120253000751, 0.09974435282757638, -0.7821595048998644]\n",
      "Layer: Layer 1, Input: [0.9971175259319461, 0.7696120253000751, 0.09974435282757638, -0.7821595048998644], Output: [-0.8544139103318873, -0.5143573535626422, -0.6702057433852835, -0.50948592525866]\n",
      "Layer: Layer 2, Input: [-0.8544139103318873, -0.5143573535626422, -0.6702057433852835, -0.50948592525866], Output: [0.5852878787743847]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8982430543252271, -0.705719987464635, 0.49733644645773273, -0.6469425669075016]\n",
      "Layer: Layer 1, Input: [0.8982430543252271, -0.705719987464635, 0.49733644645773273, -0.6469425669075016], Output: [0.35535403521755204, -0.20238222523706503, -0.31782660523796213, 0.2514424126774148]\n",
      "Layer: Layer 2, Input: [0.35535403521755204, -0.20238222523706503, -0.31782660523796213, 0.2514424126774148], Output: [-1.3871337070811058]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8153218931377066, 0.8310041798816553, -0.7610121304331716, -0.7378244458957718]\n",
      "Layer: Layer 1, Input: [0.8153218931377066, 0.8310041798816553, -0.7610121304331716, -0.7378244458957718], Output: [-0.8362441254811126, -0.5688407937383402, -0.7193553619142161, -0.4263257783380101]\n",
      "Layer: Layer 2, Input: [-0.8362441254811126, -0.5688407937383402, -0.7193553619142161, -0.4263257783380101], Output: [0.6425465368745047]\n",
      "Epoch 48/500, Loss: 0.7050878410726559, Accuracy: -1.5018291714755216\n",
      "Power operation: base = -0.1719541224945358, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5852878787743847, power = 2, grad = 0.25\n",
      "Power operation: base = -0.38713370708110584, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3574534631254953, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9805516351528311, 0.8371240544416493, -0.9681407989920042, -0.9874084923769026]\n",
      "Layer: Layer 1, Input: [0.9805516351528311, 0.8371240544416493, -0.9681407989920042, -0.9874084923769026], Output: [-0.9217388989008767, -0.6120863473912902, -0.8094978818876295, -0.5608675942575091]\n",
      "Layer: Layer 2, Input: [-0.9217388989008767, -0.6120863473912902, -0.8094978818876295, -0.5608675942575091], Output: [0.8368979794568487]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997133926788497, 0.7706362547808919, 0.09981208347559208, -0.7840625158228176]\n",
      "Layer: Layer 1, Input: [0.997133926788497, 0.7706362547808919, 0.09981208347559208, -0.7840625158228176], Output: [-0.8572751332149551, -0.5157402262742354, -0.6709739723218685, -0.5110063951628014]\n",
      "Layer: Layer 2, Input: [-0.8572751332149551, -0.5157402262742354, -0.6709739723218685, -0.5110063951628014], Output: [0.5891778736646163]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8986649677666321, -0.7049416475164849, 0.4974307512501751, -0.6488875122588795]\n",
      "Layer: Layer 1, Input: [0.8986649677666321, -0.7049416475164849, 0.4974307512501751, -0.6488875122588795], Output: [0.350795877425781, -0.19337194245127248, -0.31618249764406964, 0.2498239809369677]\n",
      "Layer: Layer 2, Input: [0.350795877425781, -0.19337194245127248, -0.31618249764406964, 0.2498239809369677], Output: [-1.4092836233776938]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8166119040228206, 0.8322283918095725, -0.7610192539428247, -0.741120625457609]\n",
      "Layer: Layer 1, Input: [0.8166119040228206, 0.8322283918095725, -0.7610192539428247, -0.741120625457609], Output: [-0.8406583823015849, -0.5725586642966956, -0.721096827996353, -0.4290680157355022]\n",
      "Layer: Layer 2, Input: [-0.8406583823015849, -0.5725586642966956, -0.721096827996353, -0.4290680157355022], Output: [0.6514605351635936]\n",
      "Epoch 49/500, Loss: 0.710270356541018, Accuracy: -1.5101029824218677\n",
      "Power operation: base = -0.16310202054315126, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5891778736646163, power = 2, grad = 0.25\n",
      "Power operation: base = -0.40928362337769375, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3485394648364064, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9807713726699965, 0.83919300984904, -0.9681538855481591, -0.9877030015623737]\n",
      "Layer: Layer 1, Input: [0.9807713726699965, 0.83919300984904, -0.9681538855481591, -0.9877030015623737], Output: [-0.9237619116128165, -0.6167599826108051, -0.8105763296116342, -0.5619430087887366]\n",
      "Layer: Layer 2, Input: [-0.9237619116128165, -0.6167599826108051, -0.8105763296116342, -0.5619430087887366], Output: [0.8452473102185176]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9971502708708249, 0.7717714886922753, 0.09986232913506311, -0.7860616302017785]\n",
      "Layer: Layer 1, Input: [0.9971502708708249, 0.7717714886922753, 0.09986232913506311, -0.7860616302017785], Output: [-0.8602371595382109, -0.5170880535801391, -0.6717959769250916, -0.5126263805148329]\n",
      "Layer: Layer 2, Input: [-0.8602371595382109, -0.5170880535801391, -0.6717959769250916, -0.5126263805148329], Output: [0.5929620159266584]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.8990922129384578, -0.7039954648606336, 0.49751233823227786, -0.6510372228847648]\n",
      "Layer: Layer 1, Input: [0.8990922129384578, -0.7039954648606336, 0.49751233823227786, -0.6510372228847648], Output: [0.3453462412052546, -0.18461738439613967, -0.3147211000083082, 0.2480054624179658]\n",
      "Layer: Layer 2, Input: [0.3453462412052546, -0.18461738439613967, -0.3147211000083082, 0.2480054624179658], Output: [-1.4299897694239598]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8178809947713258, 0.8335106262433815, -0.7610342981867657, -0.7444569676377935]\n",
      "Layer: Layer 1, Input: [0.8178809947713258, 0.8335106262433815, -0.7610342981867657, -0.7444569676377935], Output: [-0.8450789206879652, -0.5761603891426851, -0.7228523063935608, -0.43186954266055405]\n",
      "Layer: Layer 2, Input: [-0.8450789206879652, -0.5761603891426851, -0.7228523063935608, -0.43186954266055405], Output: [0.660109290172108]\n",
      "Epoch 50/500, Loss: 0.7154733189040764, Accuracy: -1.5175951849599927\n",
      "Power operation: base = -0.15475268978148238, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5929620159266584, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42998976942395983, power = 2, grad = 0.25\n",
      "Power operation: base = -0.33989070982789205, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9809838968889852, 0.8412650367031079, -0.9681683578922622, -0.9879891166728175]\n",
      "Layer: Layer 1, Input: [0.9809838968889852, 0.8412650367031079, -0.9681683578922622, -0.9879891166728175], Output: [-0.9257686178783149, -0.6212156417322391, -0.8116479487766365, -0.5630343712398161]\n",
      "Layer: Layer 2, Input: [-0.9257686178783149, -0.6212156417322391, -0.8116479487766365, -0.5630343712398161], Output: [0.853088263714014]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997166554104739, 0.7730193155505393, 0.09989245782662547, -0.7881526717789475]\n",
      "Layer: Layer 1, Input: [0.997166554104739, 0.7730193155505393, 0.09989245782662547, -0.7881526717789475], Output: [-0.8632933265470054, -0.5183992963218402, -0.6726687164985031, -0.5143420784935592]\n",
      "Layer: Layer 2, Input: [-0.8632933265470054, -0.5183992963218402, -0.6726687164985031, -0.5143420784935592], Output: [0.5966237231689755]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.899524434156227, -0.702876735041394, 0.4975789430883042, -0.6533849291113264]\n",
      "Layer: Layer 1, Input: [0.899524434156227, -0.702876735041394, 0.4975789430883042, -0.6533849291113264], Output: [0.33899327265897394, -0.17611371751321608, -0.3134391797018067, 0.2459876126313995]\n",
      "Layer: Layer 2, Input: [0.33899327265897394, -0.17611371751321608, -0.3134391797018067, 0.2459876126313995], Output: [-1.4492295018217096]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8191295829735395, 0.834852279852946, -0.7610581561850398, -0.7478309655772623]\n",
      "Layer: Layer 1, Input: [0.8191295829735395, 0.834852279852946, -0.7610581561850398, -0.7478309655772623], Output: [-0.8495010993686058, -0.5796464536066444, -0.7246188395739496, -0.43472668449932966]\n",
      "Layer: Layer 2, Input: [-0.8495010993686058, -0.5796464536066444, -0.7246188395739496, -0.43472668449932966], Output: [0.6684745780223491]\n",
      "Epoch 51/500, Loss: 0.7206266555922414, Accuracy: -1.5242903832543222\n",
      "Power operation: base = -0.14691173628598597, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5966237231689755, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4492295018217096, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3315254219776509, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9811895011510354, 0.8433429304256324, -0.9681842804826453, -0.9882672448235391]\n",
      "Layer: Layer 1, Input: [0.9811895011510354, 0.8433429304256324, -0.9681842804826453, -0.9882672448235391], Output: [-0.9277594057724416, -0.6254590427776846, -0.8127111337255807, -0.5641404803654074]\n",
      "Layer: Layer 2, Input: [-0.9277594057724416, -0.6254590427776846, -0.8127111337255807, -0.5641404803654074], Output: [0.8604164073022456]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9971827724423641, 0.7743810705914274, 0.09990000161559973, -0.7903309717858664]\n",
      "Layer: Layer 1, Input: [0.9971827724423641, 0.7743810705914274, 0.09990000161559973, -0.7903309717858664], Output: [-0.8664363398724481, -0.5196716302702501, -0.6735888594581481, -0.5161493788139582]\n",
      "Layer: Layer 2, Input: [-0.8664363398724481, -0.5196716302702501, -0.6735888594581481, -0.5161493788139582], Output: [0.6001455566687173]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.899961265000398, -0.7015805888988866, 0.4976284542286061, -0.6559229095910598]\n",
      "Layer: Layer 1, Input: [0.899961265000398, -0.7015805888988866, 0.4976284542286061, -0.6559229095910598], Output: [0.33172539486730035, -0.16785381886974318, -0.31233245602102405, 0.24377183798335197]\n",
      "Layer: Layer 2, Input: [0.33172539486730035, -0.16785381886974318, -0.31233245602102405, 0.24377183798335197], Output: [-1.4669840786453023]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8203581058204116, 0.8362546259980387, -0.7610916735173336, -0.7512397042978972]\n",
      "Layer: Layer 1, Input: [0.8203581058204116, 0.8362546259980387, -0.7610916735173336, -0.7512397042978972], Output: [-0.8539199405695884, -0.5830168704597803, -0.7263933854042757, -0.4376355956113308]\n",
      "Layer: Layer 2, Input: [-0.8539199405695884, -0.5830168704597803, -0.7263933854042757, -0.4376355956113308], Output: [0.6765384863634583]\n",
      "Epoch 52/500, Loss: 0.7256627155973241, Accuracy: -1.5301747416483158\n",
      "Power operation: base = -0.13958359269775444, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6001455566687173, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46698407864530234, power = 2, grad = 0.25\n",
      "Power operation: base = -0.32346151363654174, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9813884750711818, 0.8454293689071096, -0.9682017164065558, -0.9885377559109497]\n",
      "Layer: Layer 1, Input: [0.9813884750711818, 0.8454293689071096, -0.9682017164065558, -0.9885377559109497], Output: [-0.9297344370998388, -0.6294956107126071, -0.8137643255106446, -0.5652602260795654]\n",
      "Layer: Layer 2, Input: [-0.9297344370998388, -0.6294956107126071, -0.8137643255106446, -0.5652602260795654], Output: [0.867228583536594]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9971989216949626, 0.7758577528297469, 0.09988267067427044, -0.7925913546069197]\n",
      "Layer: Layer 1, Input: [0.9971989216949626, 0.7758577528297469, 0.09988267067427044, -0.7925913546069197], Output: [-0.8696582325428014, -0.5209020250059173, -0.6745527991748241, -0.518043841712904]\n",
      "Layer: Layer 2, Input: [-0.8696582325428014, -0.5209020250059173, -0.6745527991748241, -0.518043841712904], Output: [0.6035093303629337]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9004023243995131, -0.7001020655497477, 0.49765892241734155, -0.6586424767290132]\n",
      "Layer: Layer 1, Input: [0.9004023243995131, -0.7001020655497477, 0.49765892241734155, -0.6586424767290132], Output: [0.32353183506356725, -0.1598283998149509, -0.31139562437423585, 0.24136024406115497]\n",
      "Layer: Layer 2, Input: [0.32353183506356725, -0.1598283998149509, -0.31139562437423585, 0.24136024406115497], Output: [-1.483239154353393]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8215670062680415, 0.8377187473542457, -0.7611356415104628, -0.7546798218069328]\n",
      "Layer: Layer 1, Input: [0.8215670062680415, 0.8377187473542457, -0.7611356415104628, -0.7546798218069328], Output: [-0.8583300585987667, -0.5862712558035055, -0.7281728258759007, -0.44059222517681623]\n",
      "Layer: Layer 2, Input: [-0.8583300585987667, -0.5862712558035055, -0.7281728258759007, -0.44059222517681623], Output: [0.6842835007094612]\n",
      "Epoch 53/500, Loss: 0.7305168524537847, Accuracy: -1.5352364004702714\n",
      "Power operation: base = -0.13277141646340596, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6035093303629337, power = 2, grad = 0.25\n",
      "Power operation: base = -0.48323915435339293, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3157164992905388, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9815811025033508, 0.8475268384357197, -0.9682207260311994, -0.9888009809909009]\n",
      "Layer: Layer 1, Input: [0.9815811025033508, 0.8475268384357197, -0.9682207260311994, -0.9888009809909009], Output: [-0.9316936048523409, -0.6333305484399075, -0.8148060206651494, -0.5663925729543047]\n",
      "Layer: Layer 2, Input: [-0.9316936048523409, -0.6333305484399075, -0.8148060206651494, -0.5663925729543047], Output: [0.8735230182120324]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9972149973707517, 0.7774499399269853, 0.09983836923166528, -0.7949281308836188]\n",
      "Layer: Layer 1, Input: [0.9972149973707517, 0.7774499399269853, 0.09983836923166528, -0.7949281308836188], Output: [-0.8729503420823365, -0.5220868267343873, -0.6755566736061664, -0.5200206797830706]\n",
      "Layer: Layer 2, Input: [-0.8729503420823365, -0.5220868267343873, -0.6755566736061664, -0.5200206797830706], Output: [0.6066962528203694]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9008472127935899, -0.698436194961456, 0.4976685716370173, -0.6615339730405974]\n",
      "Layer: Layer 1, Input: [0.9008472127935899, -0.698436194961456, 0.4976685716370173, -0.6615339730405974], Output: [0.31440321601093624, -0.15202614711053372, -0.3106223900696698, 0.23875568168294067]\n",
      "Layer: Layer 2, Input: [0.31440321601093624, -0.15202614711053372, -0.3106223900696698, 0.23875568168294067], Output: [-1.4979853275063932]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.822756719681873, 0.8392454674419908, -0.7611907894704087, -0.7581474788580099]\n",
      "Layer: Layer 1, Input: [0.822756719681873, 0.8392454674419908, -0.7611907894704087, -0.7581474788580099], Output: [-0.8627256088631106, -0.5894089051375254, -0.7299539786023745, -0.4435922879377512]\n",
      "Layer: Layer 2, Input: [-0.8627256088631106, -0.5894089051375254, -0.7299539786023745, -0.4435922879377512], Output: [0.6916926176011238]\n",
      "Epoch 54/500, Loss: 0.7351280260506268, Accuracy: -1.5394659445136067\n",
      "Power operation: base = -0.12647698178796762, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6066962528203694, power = 2, grad = 0.25\n",
      "Power operation: base = -0.49798532750639324, power = 2, grad = 0.25\n",
      "Power operation: base = -0.30830738239887623, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9817676596596132, 0.8496375610225338, -0.9682413654990069, -0.9890572113154209]\n",
      "Layer: Layer 1, Input: [0.9817676596596132, 0.8496375610225338, -0.9682413654990069, -0.9890572113154209], Output: [-0.9336364996890495, -0.6369689052930482, -0.8158347807741437, -0.5675365436671971]\n",
      "Layer: Layer 2, Input: [-0.9336364996890495, -0.6369689052930482, -0.8158347807741437, -0.5675365436671971], Output: [0.8792994349380996]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9972309945212086, 0.7791577029154946, 0.09976521303002127, -0.7973350997532965]\n",
      "Layer: Layer 1, Input: [0.9972309945212086, 0.7791577029154946, 0.09976521303002127, -0.7973350997532965], Output: [-0.8763033089002674, -0.5232218456643473, -0.6765963891695377, -0.5220747453256342]\n",
      "Layer: Layer 2, Input: [-0.8763033089002674, -0.5232218456643473, -0.6765963891695377, -0.5220747453256342], Output: [0.6096871062542635]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9012955085099523, -0.696578089998008, 0.4976558109343187, -0.6645867812461018]\n",
      "Layer: Layer 1, Input: [0.9012955085099523, -0.696578089998008, 0.4976558109343187, -0.6645867812461018], Output: [0.30433220612710515, -0.14443388168134672, -0.31000551271370425, 0.2359617885034]\n",
      "Layer: Layer 2, Input: [0.30433220612710515, -0.14443388168134672, -0.31000551271370425, 0.2359617885034], Output: [-1.5112187354540174]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8239276611202048, 0.8408352825429241, -0.761257776149387, -0.7616383392663494]\n",
      "Layer: Layer 1, Input: [0.8239276611202048, 0.8408352825429241, -0.761257776149387, -0.7616383392663494], Output: [-0.8671002598699965, -0.5924288702417974, -0.7317336114503009, -0.4466312415315328]\n",
      "Layer: Layer 2, Input: [-0.8671002598699965, -0.5924288702417974, -0.7317336114503009, -0.4466312415315328], Output: [0.6987494880074177]\n",
      "Epoch 55/500, Loss: 0.739439418225621, Accuracy: -1.5428569187627632\n",
      "Power operation: base = -0.12070056506190041, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6096871062542635, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5112187354540174, power = 2, grad = 0.25\n",
      "Power operation: base = -0.30125051199258235, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9819484133885128, 0.8517634245798673, -0.9682636851091518, -0.9893066980697475]\n",
      "Layer: Layer 1, Input: [0.9819484133885128, 0.8517634245798673, -0.9682636851091518, -0.9893066980697475], Output: [-0.9355623866226659, -0.640415643184391, -0.816849242854872, -0.5686912029358547]\n",
      "Layer: Layer 2, Input: [-0.9355623866226659, -0.640415643184391, -0.816849242854872, -0.5686912029358547], Output: [0.8845591758857718]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9972469076000628, 0.7809805232954378, 0.09966154775750947, -0.7998055618760322]\n",
      "Layer: Layer 1, Input: [0.9972469076000628, 0.7809805232954378, 0.09966154775750947, -0.7998055618760322], Output: [-0.8797070987599349, -0.524302448591264, -0.6776676492846421, -0.5242005249615705]\n",
      "Layer: Layer 2, Input: [-0.8797070987599349, -0.524302448591264, -0.6776676492846421, -0.5242005249615705], Output: [0.6124624656623421]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9017467645070282, -0.6945230473348364, 0.49761924687740555, -0.6677893509017989]\n",
      "Layer: Layer 1, Input: [0.9017467645070282, -0.6945230473348364, 0.49761924687740555, -0.6677893509017989], Output: [0.29331421847073647, -0.13703673539704705, -0.3095368622474434, 0.23298302367977258]\n",
      "Layer: Layer 2, Input: [0.29331421847073647, -0.13703673539704705, -0.3095368622474434, 0.23298302367977258], Output: [-1.5229416843803727]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8250802134645073, 0.8424882958338832, -0.7613371807023649, -0.7651475626711501]\n",
      "Layer: Layer 1, Input: [0.8250802134645073, 0.8424882958338832, -0.7613371807023649, -0.7651475626711501], Output: [-0.8714471903643765, -0.5953300374691617, -0.7335084606346884, -0.4497042721794249]\n",
      "Layer: Layer 2, Input: [-0.8714471903643765, -0.5953300374691617, -0.7335084606346884, -0.4497042721794249], Output: [0.7054385933266756]\n",
      "Epoch 56/500, Loss: 0.7433990536515002, Accuracy: -1.5454063808302676\n",
      "Power operation: base = -0.11544082411422818, power = 2, grad = 0.25\n",
      "Power operation: base = 1.612462465662342, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5229416843803727, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2945614066733244, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.982123619625189, 0.8539059177398831, -0.9682877276368581, -0.989549652850915]\n",
      "Layer: Layer 1, Input: [0.982123619625189, 0.8539059177398831, -0.9682877276368581, -0.989549652850915], Output: [-0.9374701930270531, -0.6436757004456516, -0.8178481305244664, -0.5698556425654752]\n",
      "Layer: Layer 2, Input: [-0.9374701930270531, -0.6436757004456516, -0.8178481305244664, -0.5698556425654752], Output: [0.8893053275409748]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9972627303398246, 0.7829172154582635, 0.0995259677743475, -0.802332344751041]\n",
      "Layer: Layer 1, Input: [0.9972627303398246, 0.7829172154582635, 0.0995259677743475, -0.802332344751041], Output: [-0.8831510514540696, -0.5253236572275092, -0.678765987945907, -0.5263921432216989]\n",
      "Layer: Layer 2, Input: [-0.8831510514540696, -0.5253236572275092, -0.678765987945907, -0.5263921432216989], Output: [0.6150029596623228]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9022005056619689, -0.6922666560615995, 0.49755769613876605, -0.6711292441815297]\n",
      "Layer: Layer 1, Input: [0.9022005056619689, -0.6922666560615995, 0.49755769613876605, -0.6711292441815297], Output: [0.2813481435438631, -0.12981834637298115, -0.30920748758119704, 0.229824692892649]\n",
      "Layer: Layer 2, Input: [0.2813481435438631, -0.12981834637298115, -0.30920748758119704, 0.229824692892649], Output: [-1.5331632965639397]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8262147166504413, 0.8442041558917012, -0.7614294934525996, -0.7686698115114624]\n",
      "Layer: Layer 1, Input: [0.8262147166504413, 0.8442041558917012, -0.7614294934525996, -0.7686698115114624], Output: [-0.8757591131334274, -0.5981112079040103, -0.735275252540232, -0.4528062904572569]\n",
      "Layer: Layer 2, Input: [-0.8757591131334274, -0.5981112079040103, -0.735275252540232, -0.4528062904572569], Output: [0.7117454548049593]\n",
      "Epoch 57/500, Loss: 0.74696041346435, Accuracy: -1.5471154738803286\n",
      "Power operation: base = -0.1106946724590252, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6150029596623228, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5331632965639397, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2882545451950407, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9822935220332435, 0.8560660713827171, -0.9683135266512654, -0.989786248921329]\n",
      "Layer: Layer 1, Input: [0.9822935220332435, 0.8560660713827171, -0.9683135266512654, -0.989786248921329], Output: [-0.9393585088999684, -0.6467540532205395, -0.81883026588459, -0.5710289682972229]\n",
      "Layer: Layer 2, Input: [-0.9393585088999684, -0.6467540532205395, -0.81883026588459, -0.5710289682972229], Output: [0.8935428492712019]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9972784556511773, 0.7849658577532096, 0.09935733430407528, -0.8049078415390698]\n",
      "Layer: Layer 1, Input: [0.9972784556511773, 0.7849658577532096, 0.09935733430407528, -0.8049078415390698], Output: [-0.8866239568825167, -0.5262802525888903, -0.6798868085609576, -0.528643376704372]\n",
      "Layer: Layer 2, Input: [-0.8866239568825167, -0.5262802525888903, -0.6798868085609576, -0.528643376704372], Output: [0.6172895725162433]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9026562267923084, -0.689804912126364, 0.4974701976071362, -0.6745932030213045]\n",
      "Layer: Layer 1, Input: [0.9026562267923084, -0.689804912126364, 0.4974701976071362, -0.6745932030213045], Output: [0.26843709520915593, -0.12276107312755354, -0.30900769860807986, 0.22649296092242877]\n",
      "Layer: Layer 2, Input: [0.26843709520915593, -0.12276107312755354, -0.30900769860807986, 0.22649296092242877], Output: [-1.5419001497590394]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8273314582930422, 0.8459820019881729, -0.7615351068476687, -0.7721992737077299]\n",
      "Layer: Layer 1, Input: [0.8273314582930422, 0.8459820019881729, -0.7615351068476687, -0.7721992737077299], Output: [-0.8800283261559372, -0.6007711795941064, -0.7370307294153735, -0.45593193872034393]\n",
      "Layer: Layer 2, Input: [-0.8800283261559372, -0.6007711795941064, -0.7370307294153735, -0.45593193872034393], Output: [0.7176568751616506]\n",
      "Epoch 58/500, Loss: 0.7500830246908551, Accuracy: -1.5479899978424303\n",
      "Power operation: base = -0.10645715072879813, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6172895725162433, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5419001497590394, power = 2, grad = 0.25\n",
      "Power operation: base = -0.28234312483834945, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9824583508642057, 0.8582444091394951, -0.9683411049006251, -0.9900166232551827]\n",
      "Layer: Layer 1, Input: [0.9824583508642057, 0.8582444091394951, -0.9683411049006251, -0.9900166232551827], Output: [-0.9412256000087257, -0.6496557740433819, -0.8197945819913406, -0.5722102891683152]\n",
      "Layer: Layer 2, Input: [-0.9412256000087257, -0.6496557740433819, -0.8197945819913406, -0.5722102891683152], Output: [0.8972787013109085]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9972940755508046, 0.7871237357492703, 0.09915479213624168, -0.8075240641785436]\n",
      "Layer: Layer 1, Input: [0.9972940755508046, 0.7871237357492703, 0.09915479213624168, -0.8075240641785436], Output: [-0.8901141585450726, -0.5271668853807349, -0.6810254281075514, -0.5309476801278824]\n",
      "Layer: Layer 2, Input: [-0.8901141585450726, -0.5271668853807349, -0.6810254281075514, -0.5309476801278824], Output: [0.6193039842412529]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9031133916069836, -0.6871343360516535, 0.4973560233363459, -0.6781672391984752]\n",
      "Layer: Layer 1, Input: [0.9031133916069836, -0.6871343360516535, 0.4973560233363459, -0.6781672391984752], Output: [0.25458914324973286, -0.11584622752374653, -0.308927162073424, 0.22299484904124264]\n",
      "Layer: Layer 2, Input: [0.25458914324973286, -0.11584622752374653, -0.308927162073424, 0.22299484904124264], Output: [-1.5491768767450327]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8284306660259283, 0.8478204187642883, -0.7616543070403928, -0.7757297021026333]\n",
      "Layer: Layer 1, Input: [0.8284306660259283, 0.8478204187642883, -0.7616543070403928, -0.7757297021026333], Output: [-0.8842467906954224, -0.6033088317097521, -0.7387716789234425, -0.45907561145829506]\n",
      "Layer: Layer 2, Input: [-0.8842467906954224, -0.6033088317097521, -0.7387716789234425, -0.45907561145829506], Output: [0.7231612087494397]\n",
      "Epoch 59/500, Loss: 0.7527330042191174, Accuracy: -1.5480409509259374\n",
      "Power operation: base = -0.10272129868909152, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6193039842412529, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5491768767450327, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2768387912505603, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9826183220641767, 0.8604409092056078, -0.968370472839421, -0.9902408793721412]\n",
      "Layer: Layer 1, Input: [0.9826183220641767, 0.8604409092056078, -0.968370472839421, -0.9902408793721412], Output: [-0.9430694341131308, -0.6523860869736978, -0.8207401357047392, -0.5733987100677661]\n",
      "Layer: Layer 2, Input: [-0.9430694341131308, -0.6523860869736978, -0.8207401357047392, -0.5733987100677661], Output: [0.9005219674600229]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9973095811230863, 0.7893873012991425, 0.09891778379627433, -0.8101727110095108]\n",
      "Layer: Layer 1, Input: [0.9973095811230863, 0.7893873012991425, 0.09891778379627433, -0.8101727110095108], Output: [-0.8936096830649777, -0.5279781918274584, -0.6821771264160956, -0.5332982252007585]\n",
      "Layer: Layer 2, Input: [-0.8936096830649777, -0.5279781918274584, -0.6821771264160956, -0.5332982252007585], Output: [0.621028942687569]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9035714327744366, -0.6842520906162745, 0.49721468756949383, -0.6818367480294588]\n",
      "Layer: Layer 1, Input: [0.9035714327744366, -0.6842520906162745, 0.49721468756949383, -0.6818367480294588], Output: [0.23981800074762671, -0.10905432574191819, -0.308955011336728, 0.21933821472524295]\n",
      "Layer: Layer 2, Input: [0.23981800074762671, -0.10905432574191819, -0.308955011336728, 0.21933821472524295], Output: [-1.5550266870127267]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8295125018808321, 0.8497174029052477, -0.7617872665662557, -0.7792544711068934]\n",
      "Layer: Layer 1, Input: [0.8295125018808321, 0.8497174029052477, -0.7617872665662557, -0.7792544711068934], Output: [-0.8884062346720252, -0.6057232100372161, -0.7404949673254255, -0.46223148940780656]\n",
      "Layer: Layer 2, Input: [-0.8884062346720252, -0.6057232100372161, -0.7404949673254255, -0.46223148940780656], Output: [0.7282486537860018]\n",
      "Epoch 60/500, Loss: 0.7548835323635615, Accuracy: -1.5472850084542706\n",
      "Power operation: base = -0.09947803253997711, power = 2, grad = 0.25\n",
      "Power operation: base = 1.621028942687569, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5550266870127267, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2717513462139982, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9827736366579759, 0.8626549797059421, -0.9684016273744807, -0.9904590909222402]\n",
      "Layer: Layer 1, Input: [0.9827736366579759, 0.8626549797059421, -0.9684016273744807, -0.9904590909222402], Output: [-0.9448877199114003, -0.6549504183723054, -0.8216661206284297, -0.5745933280855423]\n",
      "Layer: Layer 2, Input: [-0.9448877199114003, -0.6549504183723054, -0.8216661206284297, -0.5745933280855423], Output: [0.9032839664637442]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9973249625205209, 0.791752150831827, 0.09864606009923688, -0.8128452484151354]\n",
      "Layer: Layer 1, Input: [0.9973249625205209, 0.791752150831827, 0.09864606009923688, -0.8128452484151354], Output: [-0.8970983928228374, -0.5287089137740727, -0.6833372000833261, -0.5356879526870544]\n",
      "Layer: Layer 2, Input: [-0.8970983928228374, -0.5287089137740727, -0.6833372000833261, -0.5356879526870544], Output: [0.6224486581981656]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9040297532722069, -0.681156094508152, 0.49704595304572013, -0.685586645252761]\n",
      "Layer: Layer 1, Input: [0.9040297532722069, -0.681156094508152, 0.49704595304572013, -0.685586645252761], Output: [0.2241436301973658, -0.1023653555906403, -0.309079969489456, 0.21553171164804188]\n",
      "Layer: Layer 2, Input: [0.2241436301973658, -0.1023653555906403, -0.309079969489456, 0.21553171164804188], Output: [-1.5594917681104117]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8305770590138232, 0.8516703442945142, -0.7619340386031925, -0.7827666502304177]\n",
      "Layer: Layer 1, Input: [0.8305770590138232, 0.8516703442945142, -0.7619340386031925, -0.7827666502304177], Output: [-0.8924982782681291, -0.608013612692721, -0.7421975758179361, -0.4653935876551161]\n",
      "Layer: Layer 2, Input: [-0.8924982782681291, -0.608013612692721, -0.7421975758179361, -0.4653935876551161], Output: [0.7329115572523435]\n",
      "Epoch 61/500, Loss: 0.7565152286161744, Accuracy: -1.5457449025924896\n",
      "Power operation: base = -0.0967160335362558, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6224486581981656, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5594917681104117, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26708844274765653, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9829244804381996, 0.8648854495673631, -0.9684345509052131, -0.9906713059500748]\n",
      "Layer: Layer 1, Input: [0.9829244804381996, 0.8648854495673631, -0.9684345509052131, -0.9906713059500748], Output: [-0.9466779577196923, -0.6573544421224125, -0.8225718797618079, -0.5757932331020585]\n",
      "Layer: Layer 2, Input: [-0.9466779577196923, -0.6573544421224125, -0.8225718797618079, -0.5757932331020585], Output: [0.9055783448284638]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9973402090066238, 0.7942130258460036, 0.098339686032229, -0.8155330051878731]\n",
      "Layer: Layer 1, Input: [0.9973402090066238, 0.7942130258460036, 0.098339686032229, -0.8155330051878731], Output: [-0.9005681572141939, -0.5293540211886817, -0.6845010201776502, -0.5381096373705921]\n",
      "Layer: Layer 2, Input: [-0.9005681572141939, -0.5293540211886817, -0.6845010201776502, -0.5381096373705921], Output: [0.6235492081953402]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9044877291412687, -0.6778451273887426, 0.49684983381573367, -0.6894015253633211]\n",
      "Layer: Layer 1, Input: [0.9044877291412687, -0.6778451273887426, 0.49684983381573367, -0.6894015253633211], Output: [0.20759272986036523, -0.09575905730244572, -0.30929048460190794, 0.2115847285927901]\n",
      "Layer: Layer 2, Input: [0.20759272986036523, -0.09575905730244572, -0.30929048460190794, 0.2115847285927901], Output: [-1.5626235222821365]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8316243610332735, 0.8536760237769913, -0.7620945532841169, -0.786259093289407]\n",
      "Layer: Layer 1, Input: [0.8316243610332735, 0.8536760237769913, -0.7620945532841169, -0.786259093289407], Output: [-0.8965145773262552, -0.6101796743828697, -0.7438766392702209, -0.46855581723390766]\n",
      "Layer: Layer 2, Input: [-0.8965145773262552, -0.6101796743828697, -0.7438766392702209, -0.46855581723390766], Output: [0.7371447201978145]\n",
      "Epoch 62/500, Loss: 0.7576164015855229, Accuracy: -1.5434496654511984\n",
      "Power operation: base = -0.09442165517153622, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6235492081953402, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5626235222821365, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2628552798021855, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9830710239796487, 0.8671305763605208, -0.9684692107259419, -0.9908775517277535]\n",
      "Layer: Layer 1, Input: [0.9830710239796487, 0.8671305763605208, -0.9684692107259419, -0.9908775517277535], Output: [-0.9484375002199049, -0.6596041178481671, -0.8234569174010162, -0.5769975128505093]\n",
      "Layer: Layer 2, Input: [-0.9484375002199049, -0.6596041178481671, -0.8234569174010162, -0.5769975128505093], Output: [0.9074211428831485]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9973553090434035, 0.79676383782649, 0.09799904101793075, -0.8182272774777124]\n",
      "Layer: Layer 1, Input: [0.9973553090434035, 0.79676383782649, 0.09799904101793075, -0.8182272774777124], Output: [-0.9040070365816137, -0.5299088344618581, -0.6856640925294913, -0.5405559648545901]\n",
      "Layer: Layer 2, Input: [-0.9040070365816137, -0.5299088344618581, -0.6856640925294913, -0.5405559648545901], Output: [0.6243189360769212]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9049447137089147, -0.6743189214539946, 0.49662659387058666, -0.6932658382580613]\n",
      "Layer: Layer 1, Input: [0.9049447137089147, -0.6743189214539946, 0.49662659387058666, -0.6932658382580613], Output: [0.19019906205515516, -0.08921521365533494, -0.30957487509976583, 0.20750730680755192]\n",
      "Layer: Layer 2, Input: [0.19019906205515516, -0.08921521365533494, -0.30957487509976583, 0.20750730680755192], Output: [-1.5644825955871462]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8326543640995506, 0.855730629094914, -0.7622686164819458, -0.7897245411209199]\n",
      "Layer: Layer 1, Input: [0.8326543640995506, 0.855730629094914, -0.7622686164819458, -0.7897245411209199], Output: [-0.9004469788094556, -0.6122214469839055, -0.7455294863149828, -0.47171205890781104]\n",
      "Layer: Layer 2, Input: [-0.9004469788094556, -0.6122214469839055, -0.7455294863149828, -0.47171205890781104], Output: [0.74094568871768]\n",
      "Epoch 63/500, Loss: 0.7581831469494708, Accuracy: -1.5404347000632388\n",
      "Power operation: base = -0.09257885711685154, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6243189360769212, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5644825955871462, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25905431128232004, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9832134229886311, 0.8693880718800876, -0.9685055588453924, -0.9910778400082553]\n",
      "Layer: Layer 1, Input: [0.9832134229886311, 0.8693880718800876, -0.9685055588453924, -0.9910778400082553], Output: [-0.9501636209536276, -0.6617057204974895, -0.8243209097515417, -0.5782052624153228]\n",
      "Layer: Layer 2, Input: [-0.9501636209536276, -0.6617057204974895, -0.8243209097515417, -0.5782052624153228], Output: [0.9088308253882367]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9973702504233686, 0.7993977187698846, 0.09762481280590554, -0.8209194413511687]\n",
      "Layer: Layer 1, Input: [0.9973702504233686, 0.7993977187698846, 0.09762481280590554, -0.8209194413511687], Output: [-0.9074034716637409, -0.530369143199394, -0.6868221190407013, -0.5430196183223076]\n",
      "Layer: Layer 2, Input: [-0.9074034716637409, -0.530369143199394, -0.6868221190407013, -0.5430196183223076], Output: [0.6247488265005925]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9054000432678653, -0.67057823451474, 0.4963767410310386, -0.697164079648874]\n",
      "Layer: Layer 1, Input: [0.9054000432678653, -0.67057823451474, 0.4963767410310386, -0.697164079648874], Output: [0.17200358849020642, -0.0827139439153127, -0.3099214824680992, 0.20331003639114836]\n",
      "Layer: Layer 2, Input: [0.17200358849020642, -0.0827139439153127, -0.3099214824680992, 0.20331003639114836], Output: [-1.5651386623832668]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8336669618489478, 0.857829789784155, -0.7624559113985362, -0.7931557346835769]\n",
      "Layer: Layer 1, Input: [0.8336669618489478, 0.857829789784155, -0.7624559113985362, -0.7931557346835769], Output: [-0.9042876815510631, -0.6141394737240703, -0.7471536794755281, -0.4748562469773339]\n",
      "Layer: Layer 2, Input: [-0.9042876815510631, -0.6141394737240703, -0.7471536794755281, -0.4748562469773339], Output: [0.7443150140991179]\n",
      "Epoch 64/500, Loss: 0.7582192718374812, Accuracy: -1.5367416493965047\n",
      "Power operation: base = -0.09116917461176333, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6247488265005925, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5651386623832668, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25568498590088207, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9833518189822443, 0.8716551453724501, -0.968543532259936, -0.9912721725177847]\n",
      "Layer: Layer 1, Input: [0.9833518189822443, 0.8716551453724501, -0.968543532259936, -0.9912721725177847], Output: [-0.9518535876714533, -0.663665859572355, -0.8251637136646569, -0.5794155978237833]\n",
      "Layer: Layer 2, Input: [-0.9518535876714533, -0.663665859572355, -0.8251637136646569, -0.5794155978237833], Output: [0.9098282680911036]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9973850204434825, 0.8021070972275508, 0.09721798451679615, -0.8236010692620808]\n",
      "Layer: Layer 1, Input: [0.9973850204434825, 0.8021070972275508, 0.09721798451679615, -0.8236010692620808], Output: [-0.910746470595969, -0.5307313176203151, -0.6879710581326443, -0.545493372597226]\n",
      "Layer: Layer 2, Input: [-0.910746470595969, -0.5307313176203151, -0.6879710581326443, -0.545493372597226], Output: [0.6248328378426455]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9058530441107313, -0.6666248999216989, 0.49610101575094206, -0.7010809894284196]\n",
      "Layer: Layer 1, Input: [0.9058530441107313, -0.6666248999216989, 0.49610101575094206, -0.7010809894284196], Output: [0.15305438473147184, -0.07623599484490767, -0.31031882771606994, 0.1990039334727164]\n",
      "Layer: Layer 2, Input: [0.15305438473147184, -0.07623599484490767, -0.31031882771606994, 0.1990039334727164], Output: [-1.564669938203037]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.834661993050401, 0.8599686308691735, -0.7626560031640641, -0.7965455345671374]\n",
      "Layer: Layer 1, Input: [0.834661993050401, 0.8599686308691735, -0.7626560031640641, -0.7965455345671374], Output: [-0.9080293948549444, -0.615934853896442, -0.7487470537870775, -0.47798246014333395]\n",
      "Layer: Layer 2, Input: [-0.9080293948549444, -0.615934853896442, -0.7487470537870775, -0.47798246014333395], Output: [0.747256464880476]\n",
      "Epoch 65/500, Loss: 0.7577360314555426, Accuracy: -1.5324180430741028\n",
      "Power operation: base = -0.09017173190889638, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6248328378426455, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5646699382030369, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25274353511952397, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9834863402760199, 0.8739285633518691, -0.9685830536939615, -0.9914605464816109]\n",
      "Layer: Layer 1, Input: [0.9834863402760199, 0.8739285633518691, -0.9685830536939615, -0.9914605464816109], Output: [-0.9535047372355193, -0.6654914863433686, -0.8259853728940508, -0.5806276730705824]\n",
      "Layer: Layer 2, Input: [-0.9535047372355193, -0.6654914863433686, -0.8259853728940508, -0.5806276730705824], Output: [0.9104366924648779]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9973996061157647, 0.8048837983373255, 0.09677981471500134, -0.8262640461916619]\n",
      "Layer: Layer 1, Input: [0.9973996061157647, 0.8048837983373255, 0.09677981471500134, -0.8262640461916619], Output: [-0.9140257852123721, -0.530992408289105, -0.6891071822231665, -0.5479701921551845]\n",
      "Layer: Layer 2, Input: [-0.9140257852123721, -0.530992408289105, -0.6891071822231665, -0.5479701921551845], Output: [0.6245681726453449]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.906303040724731, -0.6624618493695942, 0.49580037474828964, -0.7050017511753349]\n",
      "Layer: Layer 1, Input: [0.906303040724731, -0.6624618493695942, 0.49580037474828964, -0.7050017511753349], Output: [0.13340631640231174, -0.06976302101956958, -0.31075576738870664, 0.19460030115144875]\n",
      "Layer: Layer 2, Input: [0.13340631640231174, -0.06976302101956958, -0.31075576738870664, 0.19460030115144875], Output: [-1.5631624084244455]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8356392517437565, 0.8621418441356785, -0.7628683464978578, -0.7998870422703706]\n",
      "Layer: Layer 1, Input: [0.8356392517437565, 0.8621418441356785, -0.7628683464978578, -0.7998870422703706], Output: [-0.911665487328007, -0.6176092948702809, -0.7503077522255324, -0.4810850157765447]\n",
      "Layer: Layer 2, Input: [-0.911665487328007, -0.6176092948702809, -0.7503077522255324, -0.4810850157765447], Output: [0.7497771740971315]\n",
      "Epoch 66/500, Loss: 0.7567516736235265, Accuracy: -1.5275167145077813\n",
      "Power operation: base = -0.0895633075351221, power = 2, grad = 0.25\n",
      "Power operation: base = 1.624568172645345, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5631624084244455, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2502228259028685, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9836171032408326, 0.8762047239525547, -0.9686240327943496, -0.9916429599663091]\n",
      "Layer: Layer 1, Input: [0.9836171032408326, 0.8762047239525547, -0.9686240327943496, -0.9916429599663091], Output: [-0.9551145485783709, -0.6671898876044954, -0.8267861212979007, -0.5818406996189166]\n",
      "Layer: Layer 2, Input: [-0.9551145485783709, -0.6671898876044954, -0.8267861212979007, -0.5818406996189166], Output: [0.9106815425227675]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9974139944065746, 0.807719164836756, 0.09631181078429674, -0.8289006809304894]\n",
      "Layer: Layer 1, Input: [0.9974139944065746, 0.807719164836756, 0.09631181078429674, -0.8289006809304894], Output: [-0.9172320687125172, -0.531150229811376, -0.6902271300169917, -0.5504433292345441]\n",
      "Layer: Layer 2, Input: [-0.9172320687125172, -0.531150229811376, -0.6902271300169917, -0.5504433292345441], Output: [0.6239554684221713]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9067493648605265, -0.6580931057318429, 0.4954759696745129, -0.7089121853887489]\n",
      "Layer: Layer 1, Input: [0.9067493648605265, -0.6580931057318429, 0.4954759696745129, -0.7089121853887489], Output: [0.11312047319000346, -0.06327784608987806, -0.311221644464553, 0.19011057828879696]\n",
      "Layer: Layer 2, Input: [0.11312047319000346, -0.06327784608987806, -0.311221644464553, 0.19011057828879696], Output: [-1.5607087778718485]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8365984994474537, 0.8643437746796228, -0.7630922963061625, -0.8031737182238589]\n",
      "Layer: Layer 1, Input: [0.8365984994474537, 0.8643437746796228, -0.7630922963061625, -0.8031737182238589], Output: [-0.9151901186983712, -0.6191651482641298, -0.7518342562220401, -0.48415856346785513]\n",
      "Layer: Layer 2, Input: [-0.9151901186983712, -0.6191651482641298, -0.7518342562220401, -0.48415856346785513], Output: [0.7518877069508267]\n",
      "Epoch 67/500, Loss: 0.7552907984522618, Accuracy: -1.5220949968204254\n",
      "Power operation: base = -0.08931845747723255, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6239554684221713, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5607087778718485, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24811229304917326, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9837442137736718, 0.8784797428422206, -0.9686663677386309, -0.9918194168248229]\n",
      "Layer: Layer 1, Input: [0.9837442137736718, 0.8784797428422206, -0.9686663677386309, -0.9918194168248229], Output: [-0.9566807102819671, -0.6687686649226304, -0.8275663824920637, -0.5830539671812949]\n",
      "Layer: Layer 2, Input: [-0.9566807102819671, -0.6687686649226304, -0.8275663824920637, -0.5830539671812949], Output: [0.910590300064464]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9974281724943198, 0.8106041946704257, 0.09581569629488645, -0.8315038080034295]\n",
      "Layer: Layer 1, Input: [0.9974281724943198, 0.8106041946704257, 0.09581569629488645, -0.8315038080034295], Output: [-0.9203570076827593, -0.5312034243684047, -0.691327951442779, -0.5529064179328836]\n",
      "Layer: Layer 2, Input: [-0.9203570076827593, -0.5312034243684047, -0.691327951442779, -0.5529064179328836], Output: [0.6229988943295153]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9071913651111639, -0.6535237445509529, 0.4951291213416033, -0.712798928947715]\n",
      "Layer: Layer 1, Input: [0.9071913651111639, -0.6535237445509529, 0.4951291213416033, -0.712798928947715], Output: [0.09226337212085205, -0.05676469655281128, -0.31170642930230297, 0.18554618118220562]\n",
      "Layer: Layer 2, Input: [0.09226337212085205, -0.05676469655281128, -0.31170642930230297, 0.18554618118220562], Output: [-1.5574071660710997]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8375394788787254, 0.8665685194335918, -0.7633271209116143, -0.8063994914982029]\n",
      "Layer: Layer 1, Input: [0.8375394788787254, 0.8665685194335918, -0.7633271209116143, -0.8063994914982029], Output: [-0.9185983483009599, -0.6206054275306644, -0.7533254096378916, -0.4871981735366265]\n",
      "Layer: Layer 2, Input: [-0.9185983483009599, -0.6206054275306644, -0.7533254096378916, -0.4871981735366265], Output: [0.7536020375452575]\n",
      "Epoch 68/500, Loss: 0.7533835525316637, Accuracy: -1.5162137227908934\n",
      "Power operation: base = -0.08940969993553605, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6229988943295153, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5574071660710997, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24639796245474255, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9838677689136865, 0.8807495469719973, -0.96870994719065, -0.9919899310502256]\n",
      "Layer: Layer 1, Input: [0.9838677689136865, 0.8807495469719973, -0.96870994719065, -0.9919899310502256], Output: [-0.958201179667101, -0.6702356989101962, -0.8283267655936541, -0.5842668644301938]\n",
      "Layer: Layer 2, Input: [-0.958201179667101, -0.6702356989101962, -0.8283267655936541, -0.5842668644301938], Output: [0.9101922378712024]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9974421280336672, 0.8135296896677993, 0.09529337344003655, -0.8340668761028018]\n",
      "Layer: Layer 1, Input: [0.9974421280336672, 0.8135296896677993, 0.09529337344003655, -0.8340668761028018], Output: [-0.9233934229406604, -0.5311515015881417, -0.6924071432897322, -0.5553535602176622]\n",
      "Layer: Layer 2, Input: [-0.9233934229406604, -0.5311515015881417, -0.6924071432897322, -0.5553535602176622], Output: [0.6217061438092724]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9076284165820705, -0.6487598245355116, 0.4947612903181397, -0.7166495937507916]\n",
      "Layer: Layer 1, Input: [0.9076284165820705, -0.6487598245355116, 0.4947612903181397, -0.7166495937507916], Output: [0.07090595738092391, -0.050209400135369925, -0.3122008459471636, 0.18091834379299898]\n",
      "Layer: Layer 2, Input: [0.07090595738092391, -0.050209400135369925, -0.3122008459471636, 0.18091834379299898], Output: [-1.553359592316347]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8384619285181133, 0.8688100335636478, -0.763572017440596, -0.8095588564796493]\n",
      "Layer: Layer 1, Input: [0.8384619285181133, 0.8688100335636478, -0.763572017440596, -0.8095588564796493], Output: [-0.9218862153363512, -0.6219338048884255, -0.7547804348099884, -0.4901994162984888]\n",
      "Layer: Layer 2, Input: [-0.9218862153363512, -0.6219338048884255, -0.7547804348099884, -0.4901994162984888], Output: [0.7549374280106764]\n",
      "Epoch 69/500, Loss: 0.7510646884014648, Accuracy: -1.5099360702437403\n",
      "Power operation: base = -0.0898077621287976, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6217061438092724, power = 2, grad = 0.25\n",
      "Power operation: base = -0.553359592316347, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24506257198932357, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9839878585265518, 0.883009971945094, -0.968754652516036, -0.9921545303784639]\n",
      "Layer: Layer 1, Input: [0.9839878585265518, 0.883009971945094, -0.968754652516036, -0.9921545303784639], Output: [-0.9596742308533607, -0.6715990987685125, -0.8290680568757266, -0.585478898246838]\n",
      "Layer: Layer 2, Input: [-0.9596742308533607, -0.6715990987685125, -0.8290680568757266, -0.585478898246838], Output: [0.9095181140008153]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.99745584941355, 0.8164864090060294, 0.09474688194517734, -0.8365840195799679]\n",
      "Layer: Layer 1, Input: [0.99745584941355, 0.8164864090060294, 0.09474688194517734, -0.8365840195799679], Output: [-0.9263353355752784, -0.530994852235397, -0.6934626739847225, -0.5577794001304228]\n",
      "Layer: Layer 2, Input: [-0.9263353355752784, -0.530994852235397, -0.6934626739847225, -0.5577794001304228], Output: [0.6200883190393927]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9080599302086759, -0.6438082892420907, 0.49437404494890547, -0.7204528984940645]\n",
      "Layer: Layer 1, Input: [0.9080599302086759, -0.6438082892420907, 0.49437404494890547, -0.7204528984940645], Output: [0.04912243848025055, -0.04359954206985879, -0.31269647959797414, 0.17623796247016948]\n",
      "Layer: Layer 2, Input: [0.04912243848025055, -0.04359954206985879, -0.31269647959797414, 0.17623796247016948], Output: [-1.5486703117352703]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8393655972869446, 0.8710622401045044, -0.7638261287557501, -0.8126469525024557]\n",
      "Layer: Layer 1, Input: [0.8393655972869446, 0.8710622401045044, -0.7638261287557501, -0.8126469525024557], Output: [-0.9250507878047536, -0.6231545864889669, -0.7561989396443571, -0.49315842834909135]\n",
      "Layer: Layer 2, Input: [-0.9250507878047536, -0.6231545864889669, -0.7561989396443571, -0.49315842834909135], Output: [0.7559142089497328]\n",
      "Epoch 70/500, Loss: 0.7483725293885419, Accuracy: -1.503326307824115\n",
      "Power operation: base = -0.09048188599918472, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6200883190393927, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5486703117352703, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24408579105026718, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9841045669778187, 0.8852568586122911, -0.9688003601548477, -0.9923132590267935]\n",
      "Layer: Layer 1, Input: [0.9841045669778187, 0.8852568586122911, -0.9688003601548477, -0.9923132590267935], Output: [-0.9610984900093766, -0.6728671381628557, -0.8297912073709155, -0.5866897101964945]\n",
      "Layer: Layer 2, Input: [-0.9610984900093766, -0.6728671381628557, -0.8297912073709155, -0.5866897101964945], Output: [0.9085998141308622]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9974693259964806, 0.8194652208772322, 0.09417835607656104, -0.8390501104963295]\n",
      "Layer: Layer 1, Input: [0.9974693259964806, 0.8194652208772322, 0.09417835607656104, -0.8390501104963295], Output: [-0.9291779967031093, -0.5307347344906496, -0.6944929964835619, -0.5601791831095498]\n",
      "Layer: Layer 2, Input: [-0.9291779967031093, -0.5307347344906496, -0.6944929964835619, -0.5601791831095498], Output: [0.6181597094107694]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9084853612889894, -0.63867684387089, 0.49396902802161624, -0.7241987690159797]\n",
      "Layer: Layer 1, Input: [0.9084853612889894, -0.63867684387089, 0.49396902802161624, -0.7241987690159797], Output: [0.026989020089292576, -0.03692457429736335, -0.31318586184954006, 0.17151545096236806]\n",
      "Layer: Layer 2, Input: [0.026989020089292576, -0.03692457429736335, -0.31318586184954006, 0.17151545096236806], Output: [-1.5434440760333195]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8402502586008093, 0.8733191380229949, -0.7640885612268179, -0.8156596234431883]\n",
      "Layer: Layer 1, Input: [0.8402502586008093, 0.8733191380229949, -0.7640885612268179, -0.8156596234431883], Output: [-0.9280901790129568, -0.6242726658611571, -0.7575809152083228, -0.49607196287571065]\n",
      "Layer: Layer 2, Input: [-0.9280901790129568, -0.6242726658611571, -0.7575809152083228, -0.49607196287571065], Output: [0.7565554661842058]\n",
      "Epoch 71/500, Loss: 0.7453478859894389, Accuracy: -1.4964485051290213\n",
      "Power operation: base = -0.09140018586913778, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6181597094107694, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5434440760333195, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24344453381579423, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9842179747198785, 0.8874861446685645, -0.9688469440419232, -0.9924661795086119]\n",
      "Layer: Layer 1, Input: [0.9842179747198785, 0.8874861446685645, -0.9688469440419232, -0.9924661795086119], Output: [-0.9624729568849313, -0.674048179324447, -0.8304973166960369, -0.5878990891161843]\n",
      "Layer: Layer 2, Input: [-0.9624729568849313, -0.674048179324447, -0.8304973166960369, -0.5878990891161843], Output: [0.907469952486756]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9974825483279143, 0.8224572459909926, 0.09358998147555157, -0.8414607898632016]\n",
      "Layer: Layer 1, Input: [0.9974825483279143, 0.8224572459909926, 0.09358998147555157, -0.8414607898632016], Output: [-0.9319178816384084, -0.5303732330692492, -0.695497048883431, -0.5625487982392398]\n",
      "Layer: Layer 2, Input: [-0.9319178816384084, -0.5303732330692492, -0.695497048883431, -0.5625487982392398], Output: [0.6159374726792213]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9089042168445056, -0.6333738125960483, 0.49354792337954173, -0.7278784044395057]\n",
      "Layer: Layer 1, Input: [0.9089042168445056, -0.6333738125960483, 0.49354792337954173, -0.7278784044395057], Output: [0.0045825840340872085, -0.030175874843983087, -0.31366253140176154, 0.16676061094424513]\n",
      "Layer: Layer 2, Input: [0.0045825840340872085, -0.030175874843983087, -0.31366253140176154, 0.16676061094424513], Output: [-1.5377843989175455]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8411157231162345, 0.8755749040930484, -0.7643584025938691, -0.81859345551065]\n",
      "Layer: Layer 1, Input: [0.8411157231162345, 0.8755749040930484, -0.7643584025938691, -0.81859345551065], Output: [-0.9310035325519916, -0.6252934569259668, -0.7589267238098097, -0.49893742199626656]\n",
      "Layer: Layer 2, Input: [-0.9310035325519916, -0.6252934569259668, -0.7589267238098097, -0.49893742199626656], Output: [0.7568866446880289]\n",
      "Epoch 72/500, Loss: 0.7420329721379657, Accuracy: -1.4893652744219819\n",
      "Power operation: base = -0.09253004751324401, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6159374726792213, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5377843989175455, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2431133553119711, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9843281597270399, 0.8896939475120667, -0.9688942779673675, -0.9926133735215891]\n",
      "Layer: Layer 1, Input: [0.9843281597270399, 0.8896939475120667, -0.9688942779673675, -0.9926133735215891], Output: [-0.9637970126104957, -0.6751505880463369, -0.8311876135982548, -0.5891069789953748]\n",
      "Layer: Layer 2, Input: [-0.9637970126104957, -0.6751505880463369, -0.8311876135982548, -0.5891069789953748], Output: [0.9061614448965474]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9974955083065415, 0.8254539872376506, 0.09298395350874182, -0.8438124778965471]\n",
      "Layer: Layer 1, Input: [0.9974955083065415, 0.8254539872376506, 0.09298395350874182, -0.8438124778965471], Output: [-0.9345526511780228, -0.5299131929716387, -0.6964742430387728, -0.5648848022666481]\n",
      "Layer: Layer 2, Input: [-0.9345526511780228, -0.5299131929716387, -0.6964742430387728, -0.5648848022666481], Output: [0.6134412332901038]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9093160614997988, -0.6279079829290093, 0.4931124237528848, -0.7314843083009932]\n",
      "Layer: Layer 1, Input: [0.9093160614997988, -0.6279079829290093, 0.4931124237528848, -0.7314843083009932], Output: [-0.018020614104940685, -0.023346757080405196, -0.31412106917461446, 0.16198252235044786]\n",
      "Layer: Layer 2, Input: [-0.018020614104940685, -0.023346757080405196, -0.31412106917461446, 0.16198252235044786], Output: [-1.5317919055097728]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8419618495961212, 0.8778239845082518, -0.7646347391964156, -0.8214457927845187]\n",
      "Layer: Layer 1, Input: [0.8419618495961212, 0.8778239845082518, -0.7646347391964156, -0.8214457927845187], Output: [-0.9337909784552705, -0.6262228091028276, -0.7602370781032892, -0.5017528702478848]\n",
      "Layer: Layer 2, Input: [-0.9337909784552705, -0.6262228091028276, -0.7602370781032892, -0.5017528702478848], Output: [0.7569350857673955]\n",
      "Epoch 73/500, Loss: 0.7384703677503033, Accuracy: -1.4821366081359342\n",
      "Power operation: base = -0.09383855510345263, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6134412332901038, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5317919055097728, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24306491423260446, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9844351987277581, 0.8918766353753081, -0.9689422377796976, -0.9927549419588981]\n",
      "Layer: Layer 1, Input: [0.9844351987277581, 0.8918766353753081, -0.9689422377796976, -0.9927549419588981], Output: [-0.9650704145772391, -0.6761826428655338, -0.8318634339228856, -0.5903134816891891]\n",
      "Layer: Layer 2, Input: [-0.9650704145772391, -0.6761826428655338, -0.8318634339228856, -0.5903134816891891], Output: [0.9047070696070703]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975081993091741, 0.8284474409346599, 0.09236243866040134, -0.8461023642618605]\n",
      "Layer: Layer 1, Input: [0.9975081993091741, 0.8284474409346599, 0.09236243866040134, -0.8461023642618605], Output: [-0.937081084346857, -0.5293581310974257, -0.6974244421146092, -0.5671844253122572]\n",
      "Layer: Layer 2, Input: [-0.937081084346857, -0.5293581310974257, -0.6974244421146092, -0.5671844253122572], Output: [0.6106926170683293]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9097205216707076, -0.6222884441701306, 0.4926642009596132, -0.7350102857803512]\n",
      "Layer: Layer 1, Input: [0.9097205216707076, -0.6222884441701306, 0.4926642009596132, -0.7350102857803512], Output: [-0.04074617470922035, -0.016432431069721982, -0.3145571080707719, 0.15718945660296135]\n",
      "Layer: Layer 2, Input: [-0.04074617470922035, -0.016432431069721982, -0.3145571080707719, 0.15718945660296135], Output: [-1.5255628374826848]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8427885534695624, 0.8800611729864353, -0.7649166719161583, -0.824214731336617]\n",
      "Layer: Layer 1, Input: [0.8427885534695624, 0.8800611729864353, -0.7649166719161583, -0.824214731336617], Output: [-0.9364535647112701, -0.6270669081064707, -0.7615130122713771, -0.5045170294923368]\n",
      "Layer: Layer 2, Input: [-0.9364535647112701, -0.6270669081064707, -0.7615130122713771, -0.5045170294923368], Output: [0.7567295174809276]\n",
      "Epoch 74/500, Loss: 0.7347020682673021, Accuracy: -1.474818867463016\n",
      "Power operation: base = -0.09529293039292974, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6106926170683293, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5255628374826848, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24327048251907235, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9845391682004953, 0.8940308846605259, -0.9689907033509885, -0.9928910041382151]\n",
      "Layer: Layer 1, Input: [0.9845391682004953, 0.8940308846605259, -0.9689907033509885, -0.9928910041382151], Output: [-0.9662932798970622, -0.6771524421320132, -0.832526196852475, -0.5915188543865239]\n",
      "Layer: Layer 2, Input: [-0.9662932798970622, -0.6771524421320132, -0.832526196852475, -0.5915188543865239], Output: [0.9031390324499631]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975206162670313, 0.8314301864499362, 0.09172754022463896, -0.8483283802824311]\n",
      "Layer: Layer 1, Input: [0.9975206162670313, 0.8314301864499362, 0.09172754022463896, -0.8483283802824311], Output: [-0.9395029881175699, -0.5287121301569151, -0.6983479285764774, -0.5694455592253653]\n",
      "Layer: Layer 2, Input: [-0.9395029881175699, -0.5287121301569151, -0.6983479285764774, -0.5694455592253653], Output: [0.6077147445777213]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.910117287962236, -0.6165244270002543, 0.49220487942452434, -0.7384514098613147]\n",
      "Layer: Layer 1, Input: [0.910117287962236, -0.6165244270002543, 0.49220487942452434, -0.7384514098613147], Output: [-0.06352265916988407, -0.009429921496847281, -0.31496731886514956, 0.15238881445586364]\n",
      "Layer: Layer 2, Input: [-0.06352265916988407, -0.009429921496847281, -0.31496731886514956, 0.15238881445586364], Output: [-1.5191877722529203]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8435958128360244, 0.8822816731385841, -0.7652033302999731, -0.8268990938927233]\n",
      "Layer: Layer 1, Input: [0.8435958128360244, 0.8822816731385841, -0.7652033302999731, -0.8268990938927233], Output: [-0.9389931693141135, -0.6278321668498604, -0.7627558467493405, -0.5072292565627184]\n",
      "Layer: Layer 2, Input: [-0.9389931693141135, -0.6278321668498604, -0.7627558467493405, -0.5072292565627184], Output: [0.7562995206191432]\n",
      "Epoch 75/500, Loss: 0.7307686533686868, Accuracy: -1.4674639637615354\n",
      "Power operation: base = -0.09686096755003692, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6077147445777213, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5191877722529203, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24370047938085682, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.984640145118024, 0.8961537224041369, -0.9690395602447309, -0.9930216963764879]\n",
      "Layer: Layer 1, Input: [0.984640145118024, 0.8961537224041369, -0.9690395602447309, -0.9930216963764879], Output: [-0.9674660594371395, -0.6780678128096687, -0.833177380351488, -0.5927235021208498]\n",
      "Layer: Layer 2, Input: [-0.9674660594371395, -0.6780678128096687, -0.833177380351488, -0.5927235021208498], Output: [0.901488552667302]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975327556933803, 0.8343954524909348, 0.09108126921375517, -0.8504891558518161]\n",
      "Layer: Layer 1, Input: [0.9975327556933803, 0.8343954524909348, 0.09108126921375517, -0.8504891558518161], Output: [-0.9418190902511986, -0.5279797201581061, -0.6992453645443338, -0.5716667304150311]\n",
      "Layer: Layer 2, Input: [-0.9418190902511986, -0.5279797201581061, -0.6992453645443338, -0.5716667304150311], Output: [0.6045317067488114]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9105061157883694, -0.6106251507309791, 0.491736013708745, -0.7418039606133486]\n",
      "Layer: Layer 1, Input: [0.9105061157883694, -0.6106251507309791, 0.491736013708745, -0.7418039606133486], Output: [-0.08628253094367352, -0.0023379485505313847, -0.31534937476409164, 0.14758708879770685]\n",
      "Layer: Layer 2, Input: [-0.08628253094367352, -0.0023379485505313847, -0.31534937476409164, 0.14758708879770685], Output: [-1.512750597132626]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8443836718432245, 0.8844811439696229, -0.76549388447829, -0.8294983878690687]\n",
      "Layer: Layer 1, Input: [0.8443836718432245, 0.8844811439696229, -0.76549388447829, -0.8294983878690687], Output: [-0.9414123985455733, -0.6285251113446408, -0.7639671482494098, -0.5098895058510781]\n",
      "Layer: Layer 2, Input: [-0.9414123985455733, -0.6285251113446408, -0.7639671482494098, -0.5098895058510781], Output: [0.75567499311831]\n",
      "Epoch 76/500, Loss: 0.7267085967663597, Accuracy: -1.4601187580958257\n",
      "Power operation: base = -0.09851144733269801, power = 2, grad = 0.25\n",
      "Power operation: base = 1.6045317067488114, power = 2, grad = 0.25\n",
      "Power operation: base = -0.512750597132626, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24432500688169, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9847382074422942, 0.8982425537576741, -0.9690887010505038, -0.9931471700585636]\n",
      "Layer: Layer 1, Input: [0.9847382074422942, 0.8982425537576741, -0.9690887010505038, -0.9931471700585636], Output: [-0.9685895047046229, -0.6789362247193319, -0.8338184967640231, -0.5939279659231879]\n",
      "Layer: Layer 2, Input: [-0.9685895047046229, -0.6789362247193319, -0.8338184967640231, -0.5939279659231879], Output: [0.8997854842480091]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975446156653398, 0.8373371598137708, 0.090425521025675, -0.8525839642835296]\n",
      "Layer: Layer 1, Input: [0.9975446156653398, 0.8373371598137708, 0.090425521025675, -0.8525839642835296], Output: [-0.9440309215155649, -0.5271657531661448, -0.7001177466968604, -0.5738470596495936]\n",
      "Layer: Layer 2, Input: [-0.9440309215155649, -0.5271657531661448, -0.7001177466968604, -0.5738470596495936], Output: [0.601168045843268]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9108868243261744, -0.6045996837622017, 0.4912590704599948, -0.7450653427114146]\n",
      "Layer: Layer 1, Input: [0.9108868243261744, -0.6045996837622017, 0.4912590704599948, -0.7450653427114146], Output: [-0.10896290698789875, 0.004843220552196817, -0.31570189798381343, 0.14278985146974751]\n",
      "Layer: Layer 2, Input: [-0.10896290698789875, 0.004843220552196817, -0.31570189798381343, 0.14278985146974751], Output: [-1.506327760057463]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8451522415341953, 0.8866557284403951, -0.7657875546552333, -0.8320127501928186]\n",
      "Layer: Layer 1, Input: [0.8451522415341953, 0.8866557284403951, -0.7657875546552333, -0.8320127501928186], Output: [-0.943714477211089, -0.6291522665881877, -0.7651486869826029, -0.5124982796660498]\n",
      "Layer: Layer 2, Input: [-0.943714477211089, -0.6291522665881877, -0.7651486869826029, -0.5124982796660498], Output: [0.7548856346171748]\n",
      "Epoch 77/500, Loss: 0.7225577282296971, Accuracy: -1.4528246870355472\n",
      "Power operation: base = -0.10021451575199092, power = 2, grad = 0.25\n",
      "Power operation: base = 1.601168045843268, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5063277600574629, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24511436538282516, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9848334343867159, 0.9002951752192331, -0.969138026372567, -0.9932675893545343]\n",
      "Layer: Layer 1, Input: [0.9848334343867159, 0.9002951752192331, -0.969138026372567, -0.9932675893545343], Output: [-0.969664629930053, -0.6797647135372228, -0.8344510694553688, -0.5951329074488215]\n",
      "Layer: Layer 2, Input: [-0.969664629930053, -0.6797647135372228, -0.8344510694553688, -0.5951329074488215], Output: [0.8980579851732653]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975561957649663, 0.8402499414114482, 0.08976205804558247, -0.8546126585388016]\n",
      "Layer: Layer 1, Input: [0.9975561957649663, 0.8402499414114482, 0.08976205804558247, -0.8546126585388016], Output: [-0.9461406931934446, -0.526275277010361, -0.7009663579927901, -0.5759862117293123]\n",
      "Layer: Layer 2, Input: [-0.9461406931934446, -0.526275277010361, -0.7009663579927901, -0.5759862117293123], Output: [0.5976482626628434]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9112592939974481, -0.5984568215231376, 0.49077541491578663, -0.748233986768931]\n",
      "Layer: Layer 1, Input: [0.9112592939974481, -0.5984568215231376, 0.49077541491578663, -0.748233986768931], Output: [-0.1315061080630632, 0.012111941023652152, -0.31602439220106326, 0.13800176207874554]\n",
      "Layer: Layer 2, Input: [-0.1315061080630632, 0.012111941023652152, -0.31602439220106326, 0.13800176207874554], Output: [-1.499987799570208]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8459016983975012, 0.8888020659546131, -0.7660836181042711, -0.8344428825770706]\n",
      "Layer: Layer 1, Input: [0.8459016983975012, 0.8888020659546131, -0.7660836181042711, -0.8344428825770706], Output: [-0.9459031361694507, -0.6297200471546239, -0.7663023929664793, -0.5150565695435216]\n",
      "Layer: Layer 2, Input: [-0.9459031361694507, -0.6297200471546239, -0.7663023929664793, -0.5150565695435216], Output: [0.7539604702144809]\n",
      "Epoch 78/500, Loss: 0.7183488488781685, Accuracy: -1.445617606845305\n",
      "Power operation: base = -0.1019420148267347, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5976482626628434, power = 2, grad = 0.25\n",
      "Power operation: base = -0.499987799570208, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24603952978551913, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9849259064738513, 0.9023097750201707, -0.9691874454800082, -0.9933831287356014]\n",
      "Layer: Layer 1, Input: [0.9849259064738513, 0.9023097750201707, -0.9691874454800082, -0.9933831287356014], Output: [-0.9706926715906178, -0.6805598152503566, -0.8350766112718853, -0.5963390910483661]\n",
      "Layer: Layer 2, Input: [-0.9706926715906178, -0.6805598152503566, -0.8350766112718853, -0.5963390910483661], Output: [0.8963322438061221]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975674969863786, 0.8431291422889476, 0.0890924980274036, -0.8565756022202248]\n",
      "Layer: Layer 1, Input: [0.9975674969863786, 0.8431291422889476, 0.0890924980274036, -0.8565756022202248], Output: [-0.948151175098809, -0.5253134131875722, -0.7017927183885059, -0.5780843380936009]\n",
      "Layer: Layer 2, Input: [-0.948151175098809, -0.5253134131875722, -0.7017927183885059, -0.5780843380936009], Output: [0.5939963674781779]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9116234627278061, -0.5922049847519822, 0.490286301841949, -0.751309240080237]\n",
      "Layer: Layer 1, Input: [0.9116234627278061, -0.5922049847519822, 0.490286301841949, -0.751309240080237], Output: [-0.15386000948928474, 0.019465372514252156, -0.3163171649200503, 0.13322659597242117]\n",
      "Layer: Layer 2, Input: [-0.15386000948928474, 0.019465372514252156, -0.3163171649200503, 0.13322659597242117], Output: [-1.4937911400148005]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8466322809561286, 0.890917290375261, -0.7663814137429079, -0.836789980891925]\n",
      "Layer: Layer 1, Input: [0.8466322809561286, 0.890917290375261, -0.7663814137429079, -0.836789980891925], Output: [-0.9479825018036806, -0.6302346566164089, -0.7674303131638183, -0.5175657917771426]\n",
      "Layer: Layer 2, Input: [-0.9479825018036806, -0.6302346566164089, -0.7674303131638183, -0.5175657917771426], Output: [0.7529274287301853]\n",
      "Epoch 79/500, Loss: 0.7141114921597234, Accuracy: -1.438527834956671\n",
      "Power operation: base = -0.10366775619387791, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5939963674781779, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4937911400148005, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24707257126981474, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9850157054236375, 0.904284922536002, -0.9692368766427483, -0.993493970423821]\n",
      "Layer: Layer 1, Input: [0.9850157054236375, 0.904284922536002, -0.9692368766427483, -0.993493970423821], Output: [-0.9716750473693446, -0.6813275140111912, -0.8356966054333931, -0.597547364299317]\n",
      "Layer: Layer 2, Input: [-0.9716750473693446, -0.6813275140111912, -0.8356966054333931, -0.597547364299317], Output: [0.8946322681234111]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975785216165793, 0.8459708016738106, 0.08841830783271212, -0.8584735984525508]\n",
      "Layer: Layer 1, Input: [0.9975785216165793, 0.8459708016738106, 0.08841830783271212, -0.8584735984525508], Output: [-0.950065578400679, -0.5242852434572545, -0.702598536504787, -0.5801420153515353]\n",
      "Layer: Layer 2, Input: [-0.950065578400679, -0.5242852434572545, -0.702598536504787, -0.5801420153515353], Output: [0.5902354878994944]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9119793212639701, -0.585852139547809, 0.48979287058506327, -0.7542912520213682]\n",
      "Layer: Layer 1, Input: [0.9119793212639701, -0.585852139547809, 0.48979287058506327, -0.7542912520213682], Output: [-0.17597820492843053, 0.026899665745608373, -0.31658124370419566, 0.12846728803253327]\n",
      "Layer: Layer 2, Input: [-0.17597820492843053, 0.026899665745608373, -0.31658124370419566, 0.12846728803253327], Output: [-1.4877901247010041]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8473442847917597, 0.8929990156877846, -0.7666803444726188, -0.8390556620050049]\n",
      "Layer: Layer 1, Input: [0.8473442847917597, 0.8929990156877846, -0.7666803444726188, -0.8390556620050049], Output: [-0.949956991196173, -0.6307019990946543, -0.7685345709487083, -0.5200277202827968]\n",
      "Layer: Layer 2, Input: [-0.949956991196173, -0.6307019990946543, -0.7685345709487083, -0.5200277202827968], Output: [0.7518129863677108]\n",
      "Epoch 80/500, Loss: 0.7098718163468238, Accuracy: -1.4315803581093767\n",
      "Power operation: base = -0.10536773187658888, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5902354878994944, power = 2, grad = 0.25\n",
      "Power operation: base = -0.48779012470100414, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24818701363228923, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9851029139104884, 0.9062195488455365, -0.9692862471897501, -0.9936003018902981]\n",
      "Layer: Layer 1, Input: [0.9851029139104884, 0.9062195488455365, -0.9692862471897501, -0.9936003018902981], Output: [-0.9726133162123564, -0.6820732045047923, -0.8363124892868415, -0.5987586379763891]\n",
      "Layer: Layer 2, Input: [-0.9726133162123564, -0.6820732045047923, -0.8363124892868415, -0.5987586379763891], Output: [0.892979739915656]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975892730978593, 0.8487716209346983, 0.08774080191016308, -0.8603078193527307]\n",
      "Layer: Layer 1, Input: [0.9975892730978593, 0.8487716209346983, 0.08774080191016308, -0.8603078193527307], Output: [-0.9518874465321961, -0.5231957086486823, -0.7033856638696817, -0.5821601824666616]\n",
      "Layer: Layer 2, Input: [-0.9518874465321961, -0.5231957086486823, -0.7033856638696817, -0.5821601824666616], Output: [0.5863875423123408]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9123269078367375, -0.5794057393298222, 0.48929614376906727, -0.7571808587372463]\n",
      "Layer: Layer 1, Input: [0.9123269078367375, -0.5794057393298222, 0.48929614376906727, -0.7571808587372463], Output: [-0.1978200039886926, 0.03441014678468622, -0.31681828989089766, 0.1237259887181965]\n",
      "Layer: Layer 2, Input: [-0.1978200039886926, 0.03441014678468622, -0.31681828989089766, 0.1237259887181965], Output: [-1.4820292508001622]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8480380564236198, 0.8950453117090105, -0.7669798775508757, -0.841241891023987]\n",
      "Layer: Layer 1, Input: [0.8480380564236198, 0.8950453117090105, -0.7669798775508757, -0.841241891023987], Output: [-0.9518312158075363, -0.6311276052681026, -0.7696173290792675, -0.5224444195750194]\n",
      "Layer: Layer 2, Input: [-0.9518312158075363, -0.6311276052681026, -0.7696173290792675, -0.5224444195750194], Output: [0.75064188207901]\n",
      "Epoch 81/500, Loss: 0.7056526100180933, Accuracy: -1.4247951711178368\n",
      "Power operation: base = -0.10702026008434395, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5863875423123408, power = 2, grad = 0.25\n",
      "Power operation: base = -0.48202925080016223, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24935811792099005, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9851876152274819, 0.9081129206283036, -0.96933549333311, -0.9937023134922773]\n",
      "Layer: Layer 1, Input: [0.9851876152274819, 0.9081129206283036, -0.96933549333311, -0.9937023134922773], Output: [-0.9735091407707448, -0.6828016691196188, -0.8369256411584887, -0.5999738663355072]\n",
      "Layer: Layer 2, Input: [-0.9735091407707448, -0.6828016691196188, -0.8369256411584887, -0.5999738663355072], Output: [0.8913939327713805]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9975997558793215, 0.8515289206130938, 0.08706114477979832, -0.8620797382834422]\n",
      "Layer: Layer 1, Input: [0.9975997558793215, 0.8515289206130938, 0.08706114477979832, -0.8620797382834422], Output: [-0.9536205564428086, -0.5220495221154264, -0.7041560529825311, -0.5841400789398907]\n",
      "Layer: Layer 2, Input: [-0.9536205564428086, -0.5220495221154264, -0.7041560529825311, -0.5841400789398907], Output: [0.5824729829924769]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9126663024436242, -0.5728726877512487, 0.4887970290751866, -0.7599794709531801]\n",
      "Layer: Layer 1, Input: [0.9126663024436242, -0.5728726877512487, 0.4887970290751866, -0.7599794709531801], Output: [-0.21935028970393733, 0.04199149321226739, -0.31703051290900197, 0.11900412882582373]\n",
      "Layer: Layer 2, Input: [-0.21935028970393733, 0.04199149321226739, -0.31703051290900197, 0.11900412882582373], Output: [-1.4765455649774821]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8487139864504661, 0.8970546723127006, -0.7672795433103036, -0.8433509113309247]\n",
      "Layer: Layer 1, Input: [0.8487139864504661, 0.8970546723127006, -0.7672795433103036, -0.8433509113309247], Output: [-0.9536098955120322, -0.6315165741625082, -0.7706807570080193, -0.5248181801755583]\n",
      "Layer: Layer 2, Input: [-0.9536098955120322, -0.6315165741625082, -0.7706807570080193, -0.5248181801755583], Output: [0.7494369065575666]\n",
      "Epoch 82/500, Loss: 0.701473389758781, Accuracy: -1.4181877086410117\n",
      "Power operation: base = -0.10860606722861954, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5824729829924769, power = 2, grad = 0.25\n",
      "Power operation: base = -0.47654556497748213, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25056309344243344, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9852698928930722, 0.9099646095021677, -0.9693845598047376, -0.9938001963147794]\n",
      "Layer: Layer 1, Input: [0.9852698928930722, 0.9099646095021677, -0.9693845598047376, -0.9938001963147794], Output: [-0.9743642531367392, -0.6835170694637566, -0.8375373703609551, -0.6011940284384766]\n",
      "Layer: Layer 2, Input: [-0.9743642531367392, -0.6835170694637566, -0.8375373703609551, -0.6011940284384766], Output: [0.8898916898439797]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976099752642882, 0.8542405898647717, 0.086380356737281, -0.8637910665464664]\n",
      "Layer: Layer 1, Input: [0.9976099752642882, 0.8542405898647717, 0.086380356737281, -0.8637910665464664], Output: [-0.9552688315142583, -0.5208510991853178, -0.7049117200474869, -0.5860831858742781]\n",
      "Layer: Layer 2, Input: [-0.9552688315142583, -0.5208510991853178, -0.7049117200474869, -0.5860831858742781], Output: [0.5785106089456842]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9129976209966212, -0.5662593207857795, 0.48829632350599206, -0.7626889678865117]\n",
      "Layer: Layer 1, Input: [0.9129976209966212, -0.5662593207857795, 0.48829632350599206, -0.7626889678865117], Output: [-0.2405392643879465, 0.049637897818332874, -0.3172205877227063, 0.11430248966926776]\n",
      "Layer: Layer 2, Input: [-0.2405392643879465, 0.049637897818332874, -0.3172205877227063, 0.11430248966926776], Output: [-1.471369177817209]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8493725023284078, 0.8990259785432734, -0.7675789325586164, -0.8453851792183769]\n",
      "Layer: Layer 1, Input: [0.8493725023284078, 0.8990259785432734, -0.7675789325586164, -0.8453851792183769], Output: [-0.9552977839848329, -0.631873531082824, -0.7717270030159785, -0.527151458256039]\n",
      "Layer: Layer 2, Input: [-0.9552977839848329, -0.631873531082824, -0.7717270030159785, -0.527151458256039], Output: [0.7482187629437806]\n",
      "Epoch 83/500, Loss: 0.6973505689122802, Accuracy: -1.411769333975133\n",
      "Power operation: base = -0.1101083101560203, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5785106089456842, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4713691778172091, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25178123705621935, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9853498302312552, 0.9117744587027536, -0.9694333993518057, -0.993894140259105]\n",
      "Layer: Layer 1, Input: [0.9853498302312552, 0.9117744587027536, -0.9694333993518057, -0.993894140259105], Output: [-0.9751804244359721, -0.6842229511413657, -0.8381489102541427, -0.6024201110746678]\n",
      "Layer: Layer 2, Input: [-0.9751804244359721, -0.6842229511413657, -0.8381489102541427, -0.6024201110746678], Output: [0.88848745521548]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976199372593153, 0.8569050313201148, 0.08569932200174696, -0.8654436956520373]\n",
      "Layer: Layer 1, Input: [0.9976199372593153, 0.8569050313201148, 0.08569932200174696, -0.8654436956520373], Output: [-0.9568362666584685, -0.5196045029524128, -0.7056547128480857, -0.5879911713239302]\n",
      "Layer: Layer 2, Input: [-0.9568362666584685, -0.5196045029524128, -0.7056547128480857, -0.5879911713239302], Output: [0.5745174451319763]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9133210095424633, -0.559571405644893, 0.48779471954012227, -0.7653115993819486]\n",
      "Layer: Layer 1, Input: [0.9133210095424633, -0.559571405644893, 0.48779471954012227, -0.7653115993819486], Output: [-0.26136211242369234, 0.05734321684417716, -0.3173915772977586, 0.10962127576372578]\n",
      "Layer: Layer 2, Input: [-0.26136211242369234, 0.05734321684417716, -0.3173915772977586, 0.10962127576372578], Output: [-1.466523857200326]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8500140611047565, 0.9009584587647699, -0.7678776929872922, -0.8473473043738432]\n",
      "Layer: Layer 1, Input: [0.8500140611047565, 0.9009584587647699, -0.7678776929872922, -0.8473473043738432], Output: [-0.9568996057126434, -0.6322026012094053, -0.77275817134204, -0.5294468207914461]\n",
      "Layer: Layer 2, Input: [-0.9568996057126434, -0.6322026012094053, -0.77275817134204, -0.5294468207914461], Output: [0.747005994229125]\n",
      "Epoch 84/500, Loss: 0.6932976772405773, Accuracy: -1.4055478528876972\n",
      "Power operation: base = -0.11151254478452, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5745174451319763, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4665238572003261, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25299400577087505, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9854275099506391, 0.9135425487361779, -0.9694819721339665, -0.9939843324000339]\n",
      "Layer: Layer 1, Input: [0.9854275099506391, 0.9135425487361779, -0.9694819721339665, -0.9939843324000339], Output: [-0.9759594385382937, -0.6849222602289062, -0.8387614141333076, -0.603653093661367]\n",
      "Layer: Layer 2, Input: [-0.9759594385382937, -0.6849222602289062, -0.8387614141333076, -0.603653093661367], Output: [0.8871933511801546]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976296484293645, 0.8595211039697869, 0.08501879858312134, -0.8670396458318238]\n",
      "Layer: Layer 1, Input: [0.9976296484293645, 0.8595211039697869, 0.08501879858312134, -0.8670396458318238], Output: [-0.9583268654733275, -0.5183134059048318, -0.7063870839027749, -0.5898658408673187]\n",
      "Layer: Layer 2, Input: [-0.9583268654733275, -0.5183134059048318, -0.7063870839027749, -0.5898658408673187], Output: [0.5705086821576031]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9136366387203827, -0.5528141538770709, 0.48729281262322455, -0.7678498976119237]\n",
      "Layer: Layer 1, Input: [0.9136366387203827, -0.5528141538770709, 0.48729281262322455, -0.7678498976119237], Output: [-0.2817986067788599, 0.06510110107845989, -0.3175468613798864, 0.1049601875600809]\n",
      "Layer: Layer 2, Input: [-0.2817986067788599, 0.06510110107845989, -0.3175468613798864, 0.1049601875600809], Output: [-1.4620276650589101]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8506391423671188, 0.9028516476894202, -0.7681755248931159, -0.8492399969499412]\n",
      "Layer: Layer 1, Input: [0.8506391423671188, 0.9028516476894202, -0.7681755248931159, -0.8492399969499412], Output: [-0.9584200043302955, -0.632507397701589, -0.7737763042137569, -0.5317068970102813]\n",
      "Layer: Layer 2, Input: [-0.9584200043302955, -0.632507397701589, -0.7737763042137569, -0.5317068970102813], Output: [0.7458149700853993]\n",
      "Epoch 85/500, Loss: 0.6893256133657126, Accuracy: -1.3995280259509593\n",
      "Power operation: base = -0.11280664881984537, power = 2, grad = 0.25\n",
      "Power operation: base = 1.570508682157603, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46202766505891013, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2541850299146007, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9855030137421328, 0.9152691633342225, -0.9695302450604053, -0.9940709556167157]\n",
      "Layer: Layer 1, Input: [0.9855030137421328, 0.9152691633342225, -0.9695302450604053, -0.9940709556167157], Output: [-0.9767030699083413, -0.685617369577806, -0.8393759536271577, -0.60489393534066]\n",
      "Layer: Layer 2, Input: [-0.9767030699083413, -0.685617369577806, -0.8393759536271577, -0.60489393534066], Output: [0.8860192929565525]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976391157625148, 0.8620880662226801, 0.08433942922587244, -0.8685810210670448]\n",
      "Layer: Layer 1, Input: [0.9976391157625148, 0.8620880662226801, 0.08433942922587244, -0.8685810210670448], Output: [-0.9597445888549615, -0.516981066214978, -0.7071108687700963, -0.5917090939319234]\n",
      "Layer: Layer 2, Input: [-0.9597445888549615, -0.516981066214978, -0.7071108687700963, -0.5917090939319234], Output: [0.5664976687788177]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9139446985797341, -0.5459922459080674, 0.48679110950195226, -0.7703065990094955]\n",
      "Layer: Layer 1, Input: [0.9139446985797341, -0.5459922459080674, 0.48679110950195226, -0.7703065990094955], Output: [-0.301832683032886, 0.07290510922758908, -0.3176900723306359, 0.10031849227011012]\n",
      "Layer: Layer 2, Input: [-0.301832683032886, 0.07290510922758908, -0.3176900723306359, 0.10031849227011012], Output: [-1.4578936074757034]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8512482416042728, 0.9047053457909631, -0.7684721764811062, -0.8510660215263715]\n",
      "Layer: Layer 1, Input: [0.8512482416042728, 0.9047053457909631, -0.7684721764811062, -0.8510660215263715], Output: [-0.9598635015726383, -0.6327910226587948, -0.774783368478865, -0.5339343364987729]\n",
      "Layer: Layer 2, Input: [-0.9598635015726383, -0.6327910226587948, -0.774783368478865, -0.5339343364987729], Output: [0.744659924422959]\n",
      "Epoch 86/500, Loss: 0.6854429144575993, Accuracy: -1.3937120588750096\n",
      "Power operation: base = -0.11398070704344754, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5664976687788177, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4578936074757034, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25534007557704097, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9855764219094694, 0.9169547567366935, -0.9695781910989414, -0.994154187489286]\n",
      "Layer: Layer 1, Input: [0.9855764219094694, 0.9169547567366935, -0.9695781910989414, -0.994154187489286], Output: [-0.9774130654355683, -0.6863101129135878, -0.8399935192332548, -0.6061435643479299]\n",
      "Layer: Layer 2, Input: [-0.9774130654355683, -0.6863101129135878, -0.8399935192332548, -0.6061435643479299], Output: [0.884973132127576]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976483465464988, 0.8646055208137952, 0.08366175288296337, -0.8700699705879562]\n",
      "Layer: Layer 1, Input: [0.9976483465464988, 0.8646055208137952, 0.08366175288296337, -0.8700699705879562], Output: [-0.961093314141043, -0.515610317048185, -0.7078280691675624, -0.5935228860495744]\n",
      "Layer: Layer 2, Input: [-0.961093314141043, -0.515610317048185, -0.7078280691675624, -0.5935228860495744], Output: [0.562495948605179]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.91424539384027, -0.5391098643584278, 0.48629003698130024, -0.7726845765542006]\n",
      "Layer: Layer 1, Input: [0.91424539384027, -0.5391098643584278, 0.48629003698130024, -0.7726845765542006], Output: [-0.321452001004348, 0.080748803878585, -0.3178250383061516, 0.0956950913058367]\n",
      "Layer: Layer 2, Input: [-0.321452001004348, 0.080748803878585, -0.3178250383061516, 0.0956950913058367], Output: [-1.4541302741539275]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8518418641161303, 0.9065195802658533, -0.7687674389755211, -0.8528281579259541]\n",
      "Layer: Layer 1, Input: [0.8518418641161303, 0.9065195802658533, -0.7687674389755211, -0.8528281579259541], Output: [-0.9612344658604064, -0.6330560789808057, -0.775781246391039, -0.5361317739654855]\n",
      "Layer: Layer 2, Input: [-0.9612344658604064, -0.6330560789808057, -0.775781246391039, -0.5361317739654855], Output: [0.743553034322864]\n",
      "Epoch 87/500, Loss: 0.6816560304620676, Accuracy: -1.3881000563086667\n",
      "Power operation: base = -0.115026867872424, power = 2, grad = 0.25\n",
      "Power operation: base = 1.562495948605179, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4541302741539275, power = 2, grad = 0.25\n",
      "Power operation: base = -0.256446965677136, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9856478130418662, 0.9185999230410048, -0.9696257885832585, -0.9942341994440009]\n",
      "Layer: Layer 1, Input: [0.9856478130418662, 0.9185999230410048, -0.9696257885832585, -0.9942341994440009], Output: [-0.9780911299576309, -0.6870018246828515, -0.8406150225939414, -0.6074028696108621]\n",
      "Layer: Layer 2, Input: [-0.9780911299576309, -0.6870018246828515, -0.8406150225939414, -0.6074028696108621], Output: [0.8840608203978935]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976573482583929, 0.8670733627956009, 0.08298621627546855, -0.87150865656598]\n",
      "Layer: Layer 1, Input: [0.9976573482583929, 0.8670733627956009, 0.08298621627546855, -0.87150865656598], Output: [-0.9623768036680278, -0.5142035669639866, -0.7085406404288898, -0.5953091969470281]\n",
      "Layer: Layer 2, Input: [-0.9623768036680278, -0.5142035669639866, -0.7085406404288898, -0.5953091969470281], Output: [0.5585133321095208]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9145389396431792, -0.5321707336718651, 0.48578995076296605, -0.7749867821134465]\n",
      "Layer: Layer 1, Input: [0.9145389396431792, -0.5321707336718651, 0.48578995076296605, -0.7749867821134465], Output: [-0.3406475101342087, 0.08862583104270075, -0.3179557337003002, 0.09108858329878443]\n",
      "Layer: Layer 2, Input: [-0.3406475101342087, 0.08862583104270075, -0.3179557337003002, 0.09108858329878443], Output: [-1.4507424492515986]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8524205195575965, 0.9082945683850234, -0.7690611417221713, -0.8545291685905646]\n",
      "Layer: Layer 1, Input: [0.8524205195575965, 0.9082945683850234, -0.7690611417221713, -0.8545291685905646], Output: [-0.9625370893895177, -0.633304691029256, -0.7767717300145737, -0.5383018004035631]\n",
      "Layer: Layer 2, Input: [-0.9625370893895177, -0.633304691029256, -0.7767717300145737, -0.5383018004035631], Output: [0.7425045309713894]\n",
      "Epoch 88/500, Loss: 0.6779695929643813, Accuracy: -1.3826904299918366\n",
      "Power operation: base = -0.11593917960210653, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5585133321095208, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45074244925159856, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25749546902861065, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9857172637339792, 0.9202053681076845, -0.9696730205384433, -0.9943111561237311]\n",
      "Layer: Layer 1, Input: [0.9857172637339792, 0.9202053681076845, -0.9696730205384433, -0.9943111561237311], Output: [-0.9787389151134479, -0.6876933836930359, -0.841241300118163, -0.6086726944499993]\n",
      "Layer: Layer 2, Input: [-0.9787389151134479, -0.6876933836930359, -0.841241300118163, -0.6086726944499993], Output: [0.8832865859230741]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976661284680003, 0.8694917314500167, 0.08231318519179838, -0.8728992275580889]\n",
      "Layer: Layer 1, Input: [0.9976661284680003, 0.8694917314500167, 0.08231318519179838, -0.8728992275580889], Output: [-0.963598681540619, -0.5127628093685039, -0.7092504827436207, -0.5970700041731559]\n",
      "Layer: Layer 2, Input: [-0.963598681540619, -0.5127628093685039, -0.7092504827436207, -0.5970700041731559], Output: [0.5545579953098092]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.914825557812288, -0.5251781638610644, 0.48529114409756485, -0.7772161982447832]\n",
      "Layer: Layer 1, Input: [0.914825557812288, -0.5251781638610644, 0.48529114409756485, -0.7772161982447832], Output: [-0.3594130309509591, 0.09652998472077498, -0.3180862365045543, 0.08649732204909366]\n",
      "Layer: Layer 2, Input: [-0.3594130309509591, 0.09652998472077498, -0.3180862365045543, 0.08649732204909366], Output: [-1.447731681041091]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8529847171571988, 0.9100306837953495, -0.7693531474235098, -0.8561717720462708]\n",
      "Layer: Layer 1, Input: [0.8529847171571988, 0.9100306837953495, -0.7693531474235098, -0.8561717720462708], Output: [-0.9637753725406074, -0.6335385319950192, -0.777756518673299, -0.5404469401970202]\n",
      "Layer: Layer 2, Input: [-0.9637753725406074, -0.6335385319950192, -0.777756518673299, -0.5404469401970202], Output: [0.7415228337068696]\n",
      "Epoch 89/500, Loss: 0.6743866713774881, Accuracy: -1.3774802567209568\n",
      "Power operation: base = -0.11671341407692593, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5545579953098092, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44773168104109096, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25847716629313044, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9857848483549912, 0.9217718842993731, -0.9697198740396286, -0.9943852149574292]\n",
      "Layer: Layer 1, Input: [0.9857848483549912, 0.9217718842993731, -0.9697198740396286, -0.9943852149574292], Output: [-0.9793580111238156, -0.6883852587664817, -0.8418731175768829, -0.6099538321912628]\n",
      "Layer: Layer 2, Input: [-0.9793580111238156, -0.6883852587664817, -0.8418731175768829, -0.6099538321912628], Output: [0.8826531153817596]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976746947548454, 0.871860966621461, 0.08164295527042251, -0.8742437971641289]\n",
      "Layer: Layer 1, Input: [0.9976746947548454, 0.871860966621461, 0.08164295527042251, -0.8742437971641289], Output: [-0.9647624174082923, -0.5112896389963483, -0.7099594355916644, -0.5988072618262515]\n",
      "Layer: Layer 2, Input: [-0.9647624174082923, -0.5112896389963483, -0.7099594355916644, -0.5988072618262515], Output: [0.5506365971399627]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9151054736222856, -0.5181350964882574, 0.48479385605230507, -0.7793757986722148]\n",
      "Layer: Layer 1, Input: [0.9151054736222856, -0.5181350964882574, 0.48479385605230507, -0.7793757986722148], Output: [-0.3777448614468532, 0.10445525819197407, -0.3182206920552028, 0.08191946907221927]\n",
      "Layer: Layer 2, Input: [-0.3777448614468532, 0.10445525819197407, -0.3182206920552028, 0.08191946907221927], Output: [-1.4450968025733315]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8535349616164633, 0.9117284260912476, -0.7696433476100918, -0.8577586218788918]\n",
      "Layer: Layer 1, Input: [0.8535349616164633, 0.9117284260912476, -0.7696433476100918, -0.8577586218788918], Output: [-0.9649531144448606, -0.6337588559894523, -0.778737218869345, -0.5425696335962135]\n",
      "Layer: Layer 2, Input: [-0.9649531144448606, -0.6337588559894523, -0.778737218869345, -0.5425696335962135], Output: [0.7406146991211204]\n",
      "Epoch 90/500, Loss: 0.67090901142311, Accuracy: -1.372465585210414\n",
      "Power operation: base = -0.11734688461824039, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5506365971399627, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4450968025733315, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25938530087887957, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9858506388661662, 0.9233003281615428, -0.9697663396138881, -0.9944565259011101]\n",
      "Layer: Layer 1, Input: [0.9858506388661662, 0.9233003281615428, -0.9697663396138881, -0.9944565259011101], Output: [-0.979949941089004, -0.6890775548612065, -0.8425111753360772, -0.6112470234644135]\n",
      "Layer: Layer 2, Input: [-0.979949941089004, -0.6890775548612065, -0.8425111753360772, -0.6112470234644135], Output: [0.8821617360187561]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976830546382368, 0.8741815696980851, 0.08097576208833551, -0.8755444273094802]\n",
      "Layer: Layer 1, Input: [0.9976830546382368, 0.8741815696980851, 0.08097576208833551, -0.8755444273094802], Output: [-0.9658713160975697, -0.5097852735223614, -0.7106692747920881, -0.6005228838628311]\n",
      "Layer: Layer 2, Input: [-0.9658713160975697, -0.5097852735223614, -0.7106692747920881, -0.6005228838628311], Output: [0.5467544084350497]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9153789130541254, -0.5110441513171279, 0.48429827925576807, -0.7814685165439833]\n",
      "Layer: Layer 1, Input: [0.9153789130541254, -0.5110441513171279, 0.48429827925576807, -0.7814685165439833], Output: [-0.3956414141612922, 0.11239588382992693, -0.3183632825312791, 0.07735304066155799]\n",
      "Layer: Layer 2, Input: [-0.3956414141612922, 0.11239588382992693, -0.3183632825312791, 0.07735304066155799], Output: [-1.4428343993913622]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8540717496698307, 0.9133883937848108, -0.7699316584192092, -0.8592922905884114]\n",
      "Layer: Layer 1, Input: [0.8540717496698307, 0.9133883937848108, -0.7699316584192092, -0.8592922905884114], Output: [-0.9660739086109558, -0.6339665330687061, -0.7797153461271752, -0.5446722239243249]\n",
      "Layer: Layer 2, Input: [-0.9660739086109558, -0.6339665330687061, -0.7797153461271752, -0.5446722239243249], Output: [0.7397853782048407]\n",
      "Epoch 91/500, Loss: 0.6675372527879201, Accuracy: -1.367641693602815\n",
      "Power operation: base = -0.11783826398124386, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5467544084350497, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44283439939136215, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2602146217951593, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9859147046844018, 0.9247916010235737, -0.9698124106916529, -0.9945252313233638]\n",
      "Layer: Layer 1, Input: [0.9859147046844018, 0.9247916010235737, -0.9698124106916529, -0.9945252313233638], Output: [-0.9805161574057292, -0.689770058369977, -0.8431561139359706, -0.6125529549451082]\n",
      "Layer: Layer 2, Input: [-0.9805161574057292, -0.689770058369977, -0.8431561139359706, -0.6125529549451082], Output: [0.8818125929884837]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976912155195446, 0.8764541692562009, 0.08031179044303156, -0.8768031155558481]\n",
      "Layer: Layer 1, Input: [0.9976912155195446, 0.8764541692562009, 0.08031179044303156, -0.8768031155558481], Output: [-0.9669285120395334, -0.5082505785948025, -0.711381711619804, -0.602218731432158]\n",
      "Layer: Layer 2, Input: [-0.9669285120395334, -0.5082505785948025, -0.711381711619804, -0.602218731432158], Output: [0.5429154465016901]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9156461005062257, -0.5039076723793787, 0.4838045670317576, -0.7834972195408251]\n",
      "Layer: Layer 1, Input: [0.9156461005062257, -0.5039076723793787, 0.4838045670317576, -0.7834972195408251], Output: [-0.4131028872514912, 0.12034636323077975, -0.318518201519562, 0.07279594957334565]\n",
      "Layer: Layer 2, Input: [-0.4131028872514912, 0.12034636323077975, -0.318518201519562, 0.07279594957334565], Output: [-1.4409392233488119]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8545955672664918, 0.9150112606554369, -0.7702180167242691, -0.8607752576801321]\n",
      "Layer: Layer 1, Input: [0.8545955672664918, 0.9150112606554369, -0.7702180167242691, -0.8607752576801321], Output: [-0.9671411426173574, -0.6341620856392927, -0.7806923282679601, -0.5467569488589998]\n",
      "Layer: Layer 2, Input: [-0.9671411426173574, -0.6341620856392927, -0.7806923282679601, -0.5467569488589998], Output: [0.7390387756726002]\n",
      "Epoch 92/500, Loss: 0.6642711243798811, Accuracy: -1.3630033011894178\n",
      "Power operation: base = -0.11818740701151631, power = 2, grad = 0.25\n",
      "Power operation: base = 1.54291544650169, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44093922334881186, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26096122432739977, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9859771125881418, 0.926246632404703, -0.9698580831108049, -0.9945914660099757]\n",
      "Layer: Layer 1, Input: [0.9859771125881418, 0.926246632404703, -0.9698580831108049, -0.9945914660099757], Output: [-0.9810580399330933, -0.6904622805751401, -0.8438085197734548, -0.6138722592976013]\n",
      "Layer: Layer 2, Input: [-0.9810580399330933, -0.6904622805751401, -0.8438085197734548, -0.6138722592976013], Output: [0.8816048184017675]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9976991846356361, 0.8786794912261146, 0.07965118276858091, -0.8780217858611798]\n",
      "Layer: Layer 1, Input: [0.9976991846356361, 0.8786794912261146, 0.07965118276858091, -0.8780217858611798], Output: [-0.9679369675435325, -0.5066860948132011, -0.7120983934960318, -0.6038966036778647]\n",
      "Layer: Layer 2, Input: [-0.9679369675435325, -0.5066860948132011, -0.7120983934960318, -0.6038966036778647], Output: [0.5391226103303204]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9159072569228889, -0.4967277724801166, 0.4833128398748383, -0.785464690914912]\n",
      "Layer: Layer 1, Input: [0.9159072569228889, -0.4967277724801166, 0.4833128398748383, -0.785464690914912], Output: [-0.4301309708297059, 0.12830148933144706, -0.31868963296162317, 0.06824604157306421]\n",
      "Layer: Layer 2, Input: [-0.4301309708297059, 0.12830148933144706, -0.31868963296162317, 0.06824604157306421], Output: [-1.439404553811713]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8551068873236745, 0.9165977553523309, -0.7705023766366563, -0.8622099013702169]\n",
      "Layer: Layer 1, Input: [0.8551068873236745, 0.9165977553523309, -0.7705023766366563, -0.8622099013702169], Output: [-0.9681580009894233, -0.6343457249539749, -0.7816695096805416, -0.5488259351493645]\n",
      "Layer: Layer 2, Input: [-0.9681580009894233, -0.6343457249539749, -0.7816695096805416, -0.5488259351493645], Output: [0.7383776067570711]\n",
      "Epoch 93/500, Loss: 0.6611096168030816, Accuracy: -1.3585447389831948\n",
      "Power operation: base = -0.11839518159823248, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5391226103303204, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43940455381171306, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2616223932429289, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9860379266613162, 0.9276663660453711, -0.9699033546742142, -0.9946553572644607]\n",
      "Layer: Layer 1, Input: [0.9860379266613162, 0.9276663660453711, -0.9699033546742142, -0.9946553572644607], Output: [-0.9815768955725955, -0.6911534984926072, -0.8444689306928839, -0.6152055160860356]\n",
      "Layer: Layer 2, Input: [-0.9815768955725955, -0.6911534984926072, -0.8444689306928839, -0.6152055160860356], Output: [0.8815366894722336]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977069690223176, 0.8808583333283395, 0.07899404666744718, -0.8792022822464581]\n",
      "Layer: Layer 1, Input: [0.9977069690223176, 0.8808583333283395, 0.07899404666744718, -0.8792022822464581], Output: [-0.9688994740878123, -0.5050920654220097, -0.7128209058204106, -0.6055582314697943]\n",
      "Layer: Layer 2, Input: [-0.9688994740878123, -0.5050920654220097, -0.7128209058204106, -0.6055582314697943], Output: [0.5353778125599007]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9161625982976324, -0.4895063754136972, 0.48282319125184725, -0.7873736155851095]\n",
      "Layer: Layer 1, Input: [0.9161625982976324, -0.4895063754136972, 0.48282319125184725, -0.7873736155851095], Output: [-0.44672858832209184, 0.13625636203438943, -0.31888173382882323, 0.06370112716938646]\n",
      "Layer: Layer 2, Input: [-0.44672858832209184, 0.13625636203438943, -0.31888173382882323, 0.06370112716938646], Output: [-1.4382225090623226]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8556061679943707, 0.9181486440496583, -0.7707847063850086, -0.8635984933232713]\n",
      "Layer: Layer 1, Input: [0.8556061679943707, 0.9181486440496583, -0.7707847063850086, -0.8635984933232713], Output: [-0.969127470500782, -0.6345173866692305, -0.7826481562212054, -0.5508811961679547]\n",
      "Layer: Layer 2, Input: [-0.969127470500782, -0.6345173866692305, -0.7826481562212054, -0.5508811961679547], Output: [0.7378035478571809]\n",
      "Epoch 94/500, Loss: 0.6580511325518956, Accuracy: -1.3542600842928088\n",
      "Power operation: base = -0.11846331052776637, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5353778125599007, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43822250906232263, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26219645214281906, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9860972082706698, 0.9290517483449984, -0.9699482247597014, -0.9947170250838786]\n",
      "Layer: Layer 1, Input: [0.9860972082706698, 0.9290517483449984, -0.9699482247597014, -0.9947170250838786], Output: [-0.9820739589667404, -0.6918427925726908, -0.8451378413358995, -0.616553253440858]\n",
      "Layer: Layer 2, Input: [-0.9820739589667404, -0.6918427925726908, -0.8451378413358995, -0.616553253440858], Output: [0.8816057740386771]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977145754865986, 0.882991543459015, 0.07834046157036323, -0.8803463648750035]\n",
      "Layer: Layer 1, Input: [0.9977145754865986, 0.882991543459015, 0.07834046157036323, -0.8803463648750035], Output: [-0.9698186559171378, -0.5034684637369441, -0.7135507745781083, -0.6072052735671923]\n",
      "Layer: Layer 2, Input: [-0.9698186559171378, -0.5034684637369441, -0.7135507745781083, -0.6072052735671923], Output: [0.5316821052778704]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.916412334508031, -0.48224525537306073, 0.48233569273741206, -0.7892265704812824]\n",
      "Layer: Layer 1, Input: [0.916412334508031, -0.48224525537306073, 0.48233569273741206, -0.7892265704812824], Output: [-0.462899671498078, 0.1442063986633439, -0.31909861992302024, 0.059159008911571616]\n",
      "Layer: Layer 2, Input: [-0.462899671498078, 0.1442063986633439, -0.31909861992302024, 0.059159008911571616], Output: [-1.4373843117017215]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8560938513899986, 0.919664715908232, -0.7710649855643601, -0.8649431958916958]\n",
      "Layer: Layer 1, Input: [0.8560938513899986, 0.919664715908232, -0.7710649855643601, -0.8649431958916958], Output: [-0.9700523472554721, -0.6346767646839852, -0.7836294604401502, -0.5529246317508898]\n",
      "Layer: Layer 2, Input: [-0.9700523472554721, -0.6346767646839852, -0.7836294604401502, -0.5529246317508898], Output: [0.7373173784168587]\n",
      "Epoch 95/500, Loss: 0.6550936150435027, Accuracy: -1.350143264524056\n",
      "Power operation: base = -0.11839422596132287, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5316821052778704, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43738431170172154, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26268262158314126, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9861550160718171, 0.9304037189668988, -0.9699926939801446, -0.9947765823919759]\n",
      "Layer: Layer 1, Input: [0.9861550160718171, 0.9304037189668988, -0.9699926939801446, -0.9947765823919759], Output: [-0.9825503940608579, -0.6925290809309683, -0.8458157081419648, -0.617915950290046]\n",
      "Layer: Layer 2, Input: [-0.9825503940608579, -0.6925290809309683, -0.8458157081419648, -0.617915950290046], Output: [0.8818090624899142]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997722010586621, 0.8850800016641984, 0.07769048455852877, -0.8814557081032179]\n",
      "Layer: Layer 1, Input: [0.997722010586621, 0.8850800016641984, 0.07769048455852877, -0.8814557081032179], Output: [-0.9706969753505341, -0.5018150195514199, -0.7142894694195491, -0.6088393147620164]\n",
      "Layer: Layer 2, Input: [-0.9706969753505341, -0.5018150195514199, -0.7142894694195491, -0.6088393147620164], Output: [0.5280357975984948]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9166566684395039, -0.4749460732112342, 0.4818503985085438, -0.7910260184093004]\n",
      "Layer: Layer 1, Input: [0.9166566684395039, -0.4749460732112342, 0.4818503985085438, -0.7910260184093004], Output: [-0.4786489670641612, 0.15214734037248887, -0.3193443542643646, 0.0546175046477853]\n",
      "Layer: Layer 2, Input: [-0.4786489670641612, 0.15214734037248887, -0.3193443542643646, 0.0546175046477853], Output: [-1.4368805123837]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8565703626989821, 0.9211467710734613, -0.7713432027388072, -0.8662460613844721]\n",
      "Layer: Layer 1, Input: [0.8565703626989821, 0.9211467710734613, -0.7713432027388072, -0.8662460613844721], Output: [-0.9709352450164881, -0.6348233427039784, -0.7846145468943865, -0.55495802984092]\n",
      "Layer: Layer 2, Input: [-0.9709352450164881, -0.6348233427039784, -0.7846145468943865, -0.55495802984092], Output: [0.7369191122748986]\n",
      "Epoch 96/500, Loss: 0.6522346580097133, Accuracy: -1.3461881352173823\n",
      "Power operation: base = -0.1181909375100858, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5280357975984948, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43688051238370007, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2630808877251014, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9862114060395181, 0.9317232033651026, -0.9700367638906138, -0.994834135314325]\n",
      "Layer: Layer 1, Input: [0.9862114060395181, 0.9317232033651026, -0.9700367638906138, -0.994834135314325], Output: [-0.983007296311329, -0.693211149955514, -0.8465029539268448, -0.6192940389900456]\n",
      "Layer: Layer 2, Input: [-0.983007296311329, -0.693211149955514, -0.8465029539268448, -0.6192940389900456], Output: [0.8821430857344086]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977292806181528, 0.8871246053271336, 0.07704415539717965, -0.8825319001162661]\n",
      "Layer: Layer 1, Input: [0.9977292806181528, 0.8871246053271336, 0.07704415539717965, -0.8825319001162661], Output: [-0.9715367393056251, -0.5001312439773749, -0.7150384069703372, -0.6104618656031527]\n",
      "Layer: Layer 2, Input: [-0.9715367393056251, -0.5001312439773749, -0.7150384069703372, -0.6104618656031527], Output: [0.5244385636968536]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.916895795357619, -0.467610409356129, 0.4813673492349275, -0.7927743047918767]\n",
      "Layer: Layer 1, Input: [0.916895795357619, -0.467610409356129, 0.4813673492349275, -0.7927743047918767], Output: [-0.4939818722452264, 0.16007525543406034, -0.3196229375959086, 0.05007446714268144]\n",
      "Layer: Layer 2, Input: [-0.4939818722452264, 0.16007525543406034, -0.3196229375959086, 0.05007446714268144], Output: [-1.4367011764153725]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8570361096447812, 0.9225956109315406, -0.7716193533755056, -0.8675090329523164]\n",
      "Layer: Layer 1, Input: [0.8570361096447812, 0.9225956109315406, -0.7716193533755056, -0.8675090329523164], Output: [-0.9717786043448343, -0.6349564231713131, -0.7856044773626157, -0.5569830695116288]\n",
      "Layer: Layer 2, Input: [-0.9717786043448343, -0.6349564231713131, -0.7856044773626157, -0.5569830695116288], Output: [0.7366081174523655]\n",
      "Epoch 97/500, Loss: 0.6494715970002224, Accuracy: -1.3423885369254522\n",
      "Power operation: base = -0.11785691426559142, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5244385636968536, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43670117641537254, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26339188254763446, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9862664315179701, 0.9330111069922823, -0.9700804367389144, -0.9948897834825883]\n",
      "Layer: Layer 1, Input: [0.9862664315179701, 0.9330111069922823, -0.9700804367389144, -0.9948897834825883], Output: [-0.9834456953591577, -0.6938876812771332, -0.847199971996067, -0.6206879082167371]\n",
      "Layer: Layer 2, Input: [-0.9834456953591577, -0.6938876812771332, -0.847199971996067, -0.6206879082167371], Output: [0.8826040193433444]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977363916066323, 0.8891262571942936, 0.07640150083873765, -0.8835764438151826]\n",
      "Layer: Layer 1, Input: [0.9977363916066323, 0.8891262571942936, 0.07640150083873765, -0.8835764438151826], Output: [-0.9723401066378681, -0.49841645235361387, -0.7157989541827352, -0.6120743633550542]\n",
      "Layer: Layer 2, Input: [-0.9723401066378681, -0.49841645235361387, -0.7157989541827352, -0.6120743633550542], Output: [0.5208895405809875]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9171299024914534, -0.4602397932925745, 0.48088657540873714, -0.7944736567232378]\n",
      "Layer: Layer 1, Input: [0.9171299024914534, -0.4602397932925745, 0.48088657540873714, -0.7944736567232378], Output: [-0.5089042965279038, 0.1679865401461325, -0.31993830060281403, 0.04552780043904899]\n",
      "Layer: Layer 2, Input: [-0.5089042965279038, 0.1679865401461325, -0.31993830060281403, 0.04552780043904899], Output: [-1.436836037724011]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8574914822307674, 0.924012030349951, -0.7718934380843065, -0.868733946733604]\n",
      "Layer: Layer 1, Input: [0.8574914822307674, 0.924012030349951, -0.7718934380843065, -0.868733946733604], Output: [-0.9725847021996856, -0.6350751533621687, -0.7866002558262601, -0.5590013250133156]\n",
      "Layer: Layer 2, Input: [-0.9725847021996856, -0.6350751533621687, -0.7866002558262601, -0.5590013250133156], Output: [0.7363832239330197]\n",
      "Epoch 98/500, Loss: 0.6468015848503367, Accuracy: -1.3387383350286344\n",
      "Power operation: base = -0.11739598065665557, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5208895405809875, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43683603772401103, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2636167760669803, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9863201432872699, 0.9342683109594563, -0.9701237152556584, -0.994943620357276]\n",
      "Layer: Layer 1, Input: [0.9863201432872699, 0.9342683109594563, -0.9701237152556584, -0.994943620357276], Output: [-0.9838665580199583, -0.6945572751981444, -0.8479071297745122, -0.6220979060010738]\n",
      "Layer: Layer 2, Input: [-0.9838665580199583, -0.6945572751981444, -0.8479071297745122, -0.6220979060010738], Output: [0.8831877743634302]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977433493038383, 0.8910858558797697, 0.07576253825853813, -0.8845907586714882]\n",
      "Layer: Layer 1, Input: [0.9977433493038383, 0.8910858558797697, 0.07576253825853813, -0.8845907586714882], Output: [-0.973109095972859, -0.4966697850041551, -0.7165724315867178, -0.6136781738950752]\n",
      "Layer: Layer 2, Input: [-0.973109095972859, -0.4966697850041551, -0.7165724315867178, -0.6136781738950752], Output: [0.5173874153670415]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9173591687939623, -0.45283572961285457, 0.48040810016164975, -0.7961261838544896]\n",
      "Layer: Layer 1, Input: [0.9173591687939623, -0.45283572961285457, 0.48040810016164975, -0.7961261838544896], Output: [-0.5234225466596937, 0.1758779179388953, -0.32029429750831584, 0.04097547332553841]\n",
      "Layer: Layer 2, Input: [-0.5234225466596937, 0.1758779179388953, -0.32029429750831584, 0.04097547332553841], Output: [-1.43727462449155]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8579368527239667, 0.9253968116405887, -0.7721654611356072, -0.86992253495922]\n",
      "Layer: Layer 1, Input: [0.8579368527239667, 0.9253968116405887, -0.7721654611356072, -0.86992253495922], Output: [-0.9733556617246696, -0.6351785485876213, -0.7876028331218832, -0.5610142705395619]\n",
      "Layer: Layer 2, Input: [-0.9733556617246696, -0.6351785485876213, -0.7876028331218832, -0.5610142705395619], Output: [0.7362428194533446]\n",
      "Epoch 99/500, Loss: 0.6442216529716466, Accuracy: -1.3352314460418166\n",
      "Power operation: base = -0.11681222563656979, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5173874153670415, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43727462449154997, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2637571805466554, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9863725896426039, 0.9354956689341003, -0.9701666024799257, -0.9949957335603534]\n",
      "Layer: Layer 1, Input: [0.9863725896426039, 0.9354956689341003, -0.9701666024799257, -0.9949957335603534], Output: [-0.9842707914697044, -0.6952184707556915, -0.8486247719521122, -0.6235243428164313]\n",
      "Layer: Layer 2, Input: [-0.9842707914697044, -0.6952184707556915, -0.8486247719521122, -0.6235243428164313], Output: [0.8838900755590378]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977501591883651, 0.8930042885092437, 0.07512727868773499, -0.8855761833105316]\n",
      "Layer: Layer 1, Input: [0.9977501591883651, 0.8930042885092437, 0.07512727868773499, -0.8855761833105316], Output: [-0.9738455937780169, -0.49489022574961905, -0.7173601163379972, -0.6152745943009674]\n",
      "Layer: Layer 2, Input: [-0.9738455937780169, -0.49489022574961905, -0.7173601163379972, -0.6152745943009674], Output: [0.513930502192534]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9175837648489029, -0.44539972070295786, 0.47993194161810226, -0.7977338806993165]\n",
      "Layer: Layer 1, Input: [0.9175837648489029, -0.44539972070295786, 0.47993194161810226, -0.7977338806993165], Output: [-0.5375432320388177, 0.18374643711704114, -0.3206947007672266, 0.036415530244376076]\n",
      "Layer: Layer 2, Input: [-0.5375432320388177, 0.18374643711704114, -0.3206947007672266, 0.036415530244376076], Output: [-1.438006360458456]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8583725758346363, 0.9267507200012838, -0.7724354292285771, -0.8710764297633248]\n",
      "Layer: Layer 1, Input: [0.8583725758346363, 0.9267507200012838, -0.7724354292285771, -0.8710764297633248], Output: [-0.974093462008126, -0.6352655125349997, -0.7886131112039592, -0.5630232854666576]\n",
      "Layer: Layer 2, Input: [-0.974093462008126, -0.6352655125349997, -0.7886131112039592, -0.5630232854666576], Output: [0.7361849336651889]\n",
      "Epoch 100/500, Loss: 0.641728760262482, Accuracy: -1.3318618534267634\n",
      "Power operation: base = -0.11610992444096224, power = 2, grad = 0.25\n",
      "Power operation: base = 1.513930502192534, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4380063604584561, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2638150663348111, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9864238164831328, 0.9366940050817504, -0.9702091016166416, -0.9950462052107808]\n",
      "Layer: Layer 1, Input: [0.9864238164831328, 0.9366940050817504, -0.9702091016166416, -0.9950462052107808], Output: [-0.9846592465299729, -0.6958697626511574, -0.8493532231597726, -0.6249674946446847]\n",
      "Layer: Layer 2, Input: [-0.9846592465299729, -0.6958697626511574, -0.8493532231597726, -0.6249674946446847], Output: [0.8847065280179462]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977568264691742, 0.8948824251911742, 0.07449572930721905, -0.8865339786250351]\n",
      "Layer: Layer 1, Input: [0.9977568264691742, 0.8948824251911742, 0.07449572930721905, -0.8865339786250351], Output: [-0.9745513624772342, -0.49307661816869275, -0.7181632449927952, -0.6168648559226725]\n",
      "Layer: Layer 2, Input: [-0.9745513624772342, -0.49307661816869275, -0.7181632449927952, -0.6168648559226725], Output: [0.5105168091752339]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.917803852897424, -0.43793328618021626, 0.4794581148333756, -0.7992986300152688]\n",
      "Layer: Layer 1, Input: [0.917803852897424, -0.43793328618021626, 0.4794581148333756, -0.7992986300152688], Output: [-0.5512731877557808, 0.19158946755830658, -0.3211431966295874, 0.03184609994247843]\n",
      "Layer: Layer 2, Input: [-0.5512731877557808, 0.19158946755830658, -0.3211431966295874, 0.03184609994247843], Output: [-1.439020645542529]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8587989890536327, 0.9280745002118901, -0.7727033504824451, -0.8721971674905079]\n",
      "Layer: Layer 1, Input: [0.8587989890536327, 0.9280745002118901, -0.7727033504824451, -0.8721971674905079], Output: [-0.9747999476574624, -0.6353348548633572, -0.7896319469838647, -0.5650296598653043]\n",
      "Layer: Layer 2, Input: [-0.9747999476574624, -0.6353348548633572, -0.7896319469838647, -0.5650296598653043], Output: [0.7362073112814596]\n",
      "Epoch 101/500, Loss: 0.6393198313291355, Accuracy: -1.328623615418357\n",
      "Power operation: base = -0.11529347198205375, power = 2, grad = 0.25\n",
      "Power operation: base = 1.510516809175234, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43902064554252895, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26379268871854045, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9864738674079303, 0.9378641128756816, -0.9702512159219585, -0.9950951122575523]\n",
      "Layer: Layer 1, Input: [0.9864738674079303, 0.9378641128756816, -0.9702512159219585, -0.9950951122575523], Output: [-0.9850327209771504, -0.6965096153119588, -0.850092790199726, -0.6264276059654281]\n",
      "Layer: Layer 2, Input: [-0.9850327209771504, -0.6965096153119588, -0.850092790199726, -0.6264276059654281], Output: [0.8856326731569109]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977633560915942, 0.8967211150315405, 0.07386789546404916, -0.8874653312555677]\n",
      "Layer: Layer 1, Input: [0.9977633560915942, 0.8967211150315405, 0.07386789546404916, -0.8874653312555677], Output: [-0.9752280484595245, -0.49122767967708597, -0.7189830159650822, -0.6184501277702863]\n",
      "Layer: Layer 2, Input: [-0.9752280484595245, -0.49122767967708597, -0.7189830159650822, -0.6184501277702863], Output: [0.5071440960144273]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9180195869608543, -0.43043797923247035, 0.47898663336340114, -0.800822206973984]\n",
      "Layer: Layer 1, Input: [0.9180195869608543, -0.43043797923247035, 0.47898663336340114, -0.800822206973984], Output: [-0.5646194127290172, 0.19940469659280333, -0.3216433813917591, 0.027265402138615565]\n",
      "Layer: Layer 2, Input: [-0.5646194127290172, 0.19940469659280333, -0.3216433813917591, 0.027265402138615565], Output: [-1.4403069190387219]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8592164131143286, 0.9293688743828604, -0.7729692336246848, -0.8732861933278342]\n",
      "Layer: Layer 1, Input: [0.8592164131143286, 0.9293688743828604, -0.7729692336246848, -0.8732861933278342], Output: [-0.9754768380705549, -0.6353853062200587, -0.7906601557318387, -0.5670346001250754]\n",
      "Layer: Layer 2, Input: [-0.9754768380705549, -0.6353853062200587, -0.7906601557318387, -0.5670346001250754], Output: [0.7363074749800473]\n",
      "Epoch 102/500, Loss: 0.6369917855762873, Accuracy: -1.3255108669161908\n",
      "Power operation: base = -0.11436732684308915, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5071440960144273, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4403069190387219, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26369252501995266, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9865227838167119, 0.9390067546187785, -0.9702929486131467, -0.9951425268060482]\n",
      "Layer: Layer 1, Input: [0.9865227838167119, 0.9390067546187785, -0.9702929486131467, -0.9951425268060482], Output: [-0.9853919628174398, -0.697136474369733, -0.8508437638612361, -0.6279048926275215]\n",
      "Layer: Layer 2, Input: [-0.9853919628174398, -0.697136474369733, -0.8508437638612361, -0.6279048926275215], Output: [0.8866640352073332]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977697527452206, 0.898521183437818, 0.07324378226849083, -0.8883713573051407]\n",
      "Layer: Layer 1, Input: [0.9977697527452206, 0.898521183437818, 0.07324378226849083, -0.8883713573051407], Output: [-0.9758771898715395, -0.4893420135415652, -0.719820591642312, -0.6200315200828699]\n",
      "Layer: Layer 2, Input: [-0.9758771898715395, -0.4893420135415652, -0.719820591642312, -0.6200315200828699], Output: [0.5038099229524495]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9182311130394046, -0.42291540003234995, 0.4785175105106671, -0.8023062838843575]\n",
      "Layer: Layer 1, Input: [0.9182311130394046, -0.42291540003234995, 0.4785175105106671, -0.8023062838843575], Output: [-0.5775890205911685, 0.20719012421258037, -0.32219875818993954, 0.022671752449631138]\n",
      "Layer: Layer 2, Input: [-0.5775890205911685, 0.20719012421258037, -0.32219875818993954, 0.022671752449631138], Output: [-1.441854708286054]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8596251525503567, 0.9306345405761002, -0.7732330873515076, -0.8743448661230807]\n",
      "Layer: Layer 1, Input: [0.8596251525503567, 0.9306345405761002, -0.7732330873515076, -0.8743448661230807], Output: [-0.9761257363217775, -0.6354155308799591, -0.7916985140443393, -0.5690392345672133]\n",
      "Layer: Layer 2, Input: [-0.9761257363217775, -0.6354155308799591, -0.7916985140443393, -0.5690392345672133], Output: [0.7364827789386705]\n",
      "Epoch 103/500, Loss: 0.6347415585790441, Accuracy: -1.3225178170924998\n",
      "Power operation: base = -0.11333596479266683, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5038099229524495, power = 2, grad = 0.25\n",
      "Power operation: base = -0.441854708286054, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26351722106132947, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9865706050134312, 0.9401226615405628, -0.9703343027997532, -0.9951885164345541]\n",
      "Layer: Layer 1, Input: [0.9865706050134312, 0.9401226615405628, -0.9703343027997532, -0.9951885164345541], Output: [-0.9857376734838995, -0.6977487758433646, -0.8516064203565812, -0.6293995445744549]\n",
      "Layer: Layer 2, Input: [-0.9857376734838995, -0.6977487758433646, -0.8516064203565812, -0.6293995445744549], Output: [0.887796159261022]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977760208732535, 0.9002834304866049, 0.0726233958257541, -0.8892531061811401]\n",
      "Layer: Layer 1, Input: [0.9977760208732535, 0.9002834304866049, 0.0726233958257541, -0.8892531061811401], Output: [-0.9765002241152173, -0.48741811898007026, -0.7206771001511115, -0.6216100879708356]\n",
      "Layer: Layer 2, Input: [-0.9765002241152173, -0.48741811898007026, -0.7206771001511115, -0.6216100879708356], Output: [0.5005116918810986]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9184385693694127, -0.4153672064152415, 0.4780507602875917, -0.8037524352763212]\n",
      "Layer: Layer 1, Input: [0.9184385693694127, -0.4153672064152415, 0.4780507602875917, -0.8037524352763212], Output: [-0.5901892012125523, 0.21494405770344951, -0.3228127342222632, 0.01806356579115839]\n",
      "Layer: Layer 2, Input: [-0.5901892012125523, 0.21494405770344951, -0.3228127342222632, 0.01806356579115839], Output: [-1.443653665322332]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8600254963245851, 0.9318721721390986, -0.7734949198378727, -0.8753744632784103]\n",
      "Layer: Layer 1, Input: [0.8600254963245851, 0.9318721721390986, -0.7734949198378727, -0.8753744632784103], Output: [-0.9767481376078988, -0.6354241372278336, -0.7927477623905496, -0.5710446189508709]\n",
      "Layer: Layer 2, Input: [-0.9767481376078988, -0.6354241372278336, -0.7927477623905496, -0.5710446189508709], Output: [0.7367304539181436]\n",
      "Epoch 104/500, Loss: 0.6325661169991352, Accuracy: -1.3196387440242647\n",
      "Power operation: base = -0.11220384073897804, power = 2, grad = 0.25\n",
      "Power operation: base = 1.5005116918810986, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44365366532233197, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2632695460818564, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9866173683111302, 0.9412125343500868, -0.9703752814330585, -0.9952331444986653]\n",
      "Layer: Layer 1, Input: [0.9866173683111302, 0.9412125343500868, -0.9703752814330585, -0.9952331444986653], Output: [-0.9860705109235183, -0.6983449533097097, -0.8523810224141027, -0.6309117284050549]\n",
      "Layer: Layer 2, Input: [-0.9860705109235183, -0.6983449533097097, -0.8523810224141027, -0.6309117284050549], Output: [0.8890246419229357]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977821646828762, 0.9020086301567058, 0.07200674415217659, -0.8901115644797913]\n",
      "Layer: Layer 1, Input: [0.9977821646828762, 0.9020086301567058, 0.07200674415217659, -0.8901115644797913], Output: [-0.9770984949969147, -0.48545439951880953, -0.7215536367757956, -0.6231868350483216]\n",
      "Layer: Layer 2, Input: [-0.9770984949969147, -0.48545439951880953, -0.7215536367757956, -0.6231868350483216], Output: [0.4972466804021378]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9186420867243675, -0.4077951220180605, 0.4775863981354723, -0.8051621431901254]\n",
      "Layer: Layer 1, Input: [0.9186420867243675, -0.4077951220180605, 0.4775863981354723, -0.8051621431901254], Output: [-0.6024271909820321, 0.22266510574883686, -0.32348861831092995, 0.013439358443217761]\n",
      "Layer: Layer 2, Input: [-0.6024271909820321, 0.22266510574883686, -0.32348861831092995, 0.013439358443217761], Output: [-1.4456935937057085]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8604177185084696, 0.9330824176133717, -0.7737547383761267, -0.8763761856322897]\n",
      "Layer: Layer 1, Input: [0.8604177185084696, 0.9330824176133717, -0.7737547383761267, -0.8763761856322897], Output: [-0.9773454372208452, -0.6354096863119645, -0.7938086072595669, -0.5730517418023852]\n",
      "Layer: Layer 2, Input: [-0.9773454372208452, -0.6354096863119645, -0.7938086072595669, -0.5730517418023852], Output: [0.7370476448160566]\n",
      "Epoch 105/500, Loss: 0.6304624681606614, Accuracy: -1.316867987368854\n",
      "Power operation: base = -0.11097535807706427, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4972466804021378, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4456935937057085, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26295235518394344, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9866631091367085, 0.9422770441417675, -0.9704158872711265, -0.9952764704219872]\n",
      "Layer: Layer 1, Input: [0.9866631091367085, 0.9422770441417675, -0.9704158872711265, -0.9952764704219872], Output: [-0.9863910925518788, -0.6989234433320635, -0.8531678200653323, -0.632441589759063]\n",
      "Layer: Layer 2, Input: [-0.9863910925518788, -0.6989234433320635, -0.8531678200653323, -0.632441589759063], Output: [0.8903451555617545]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977881881563466, 0.9036975302550184, 0.07139383782119378, -0.8909476598467696]\n",
      "Layer: Layer 1, Input: [0.9977881881563466, 0.9036975302550184, 0.07139383782119378, -0.8909476598467696], Output: [-0.9776732594941936, -0.4834491697865762, -0.7224512650406527, -0.6247627169917017]\n",
      "Layer: Layer 2, Input: [-0.9776732594941936, -0.4834491697865762, -0.7224512650406527, -0.6247627169917017], Output: [0.49401206964426336]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9188417887472777, -0.4002009420797225, 0.4771244414337756, -0.806536802547456]\n",
      "Layer: Layer 1, Input: [0.9188417887472777, -0.4002009420797225, 0.4771244414337756, -0.806536802547456], Output: [-0.6143102501940616, 0.23035217202573385, -0.32422961873592343, 0.008797748948833513]\n",
      "Layer: Layer 2, Input: [-0.6143102501940616, 0.23035217202573385, -0.32422961873592343, 0.008797748948833513], Output: [-1.4479644673693444]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8608020789942398, 0.9342659010967977, -0.7740125491243215, -0.8773511622621484]\n",
      "Layer: Layer 1, Input: [0.8608020789942398, 0.9342659010967977, -0.7740125491243215, -0.8773511622621484], Output: [-0.9779189380312343, -0.6353706986950123, -0.7948817229347757, -0.5750615295172029]\n",
      "Layer: Layer 2, Input: [-0.9779189380312343, -0.6353706986950123, -0.7948817229347757, -0.5750615295172029], Output: [0.7374314415879639]\n",
      "Epoch 106/500, Loss: 0.6284276652608964, Accuracy: -1.3141999398638893\n",
      "Power operation: base = -0.10965484443824547, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4940120696442634, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44796446736934437, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2625685584120361, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.986707861134513, 0.9433168335661235, -0.97045612285702, -0.9953185499721109]\n",
      "Layer: Layer 1, Input: [0.986707861134513, 0.9433168335661235, -0.97045612285702, -0.9953185499721109], Output: [-0.9866999980605936, -0.6994826893987828, -0.8539670511622678, -0.633989255523375]\n",
      "Layer: Layer 2, Input: [-0.9866999980605936, -0.6994826893987828, -0.8539670511622678, -0.633989255523375], Output: [0.8917534670781015]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977940950625236, 0.9053508528860166, 0.07078469038007167, -0.8917622647628761]\n",
      "Layer: Layer 1, Input: [0.9977940950625236, 0.9053508528860166, 0.07078469038007167, -0.8917622647628761], Output: [-0.9782256941218711, -0.48140066092791656, -0.7233710174724086, -0.6263386449766554]\n",
      "Layer: Layer 2, Input: [-0.9782256941218711, -0.48140066092791656, -0.7233710174724086, -0.6263386449766554], Output: [0.49080496660950645]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9190377923039801, -0.39258653710448826, 0.4766649098312367, -0.8078777265070968]\n",
      "Layer: Layer 1, Input: [0.9190377923039801, -0.39258653710448826, 0.4766649098312367, -0.8078777265070968], Output: [-0.6258456461084815, 0.23800444829326253, -0.3250388412875378, 0.004137457994318325]\n",
      "Layer: Layer 2, Input: [-0.6258456461084815, 0.23800444829326253, -0.3250388412875378, 0.004137457994318325], Output: [-1.4504564430933682]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8611788242253093, 0.9354232229563441, -0.7742683569471338, -0.8783004551565795]\n",
      "Layer: Layer 1, Input: [0.8611788242253093, 0.9354232229563441, -0.7742683569471338, -0.8783004551565795], Output: [-0.978469857479481, -0.6353056598200513, -0.7959677529246502, -0.5770748512002365]\n",
      "Layer: Layer 2, Input: [-0.978469857479481, -0.6353056598200513, -0.7959677529246502, -0.5770748512002365], Output: [0.7378789043876139]\n",
      "Epoch 107/500, Loss: 0.6264588090616374, Accuracy: -1.3116290382371592\n",
      "Power operation: base = -0.10824653292189845, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4908049666095065, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4504564430933682, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26212109561238606, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9867516562678685, 0.9443325181907422, -0.9704959905079998, -0.9953594355212879]\n",
      "Layer: Layer 1, Input: [0.9867516562678685, 0.9443325181907422, -0.9704959905079998, -0.9953594355212879], Output: [-0.9869977720687575, -0.7000211446038582, -0.8547789416590652, -0.6355548358594739]\n",
      "Layer: Layer 2, Input: [-0.9869977720687575, -0.7000211446038582, -0.8547789416590652, -0.6355548358594739], Output: [0.893245452030563]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9977998889686022, 0.9069692953368884, 0.07017931857420763, -0.8925562002163124]\n",
      "Layer: Layer 1, Input: [0.9977998889686022, 0.9069692953368884, 0.07017931857420763, -0.8925562002163124], Output: [-0.9787569008908085, -0.4793070248123855, -0.7243138960626635, -0.6279154889594819]\n",
      "Layer: Layer 2, Input: [-0.9787569008908085, -0.4793070248123855, -0.7243138960626635, -0.6279154889594819], Output: [0.48762242177729753]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9192302078487635, -0.38495385458713255, 0.4762078254270597, -0.8091861517297823]\n",
      "Layer: Layer 1, Input: [0.9192302078487635, -0.38495385458713255, 0.4762078254270597, -0.8091861517297823], Output: [-0.6370406404529216, 0.24562140696279033, -0.32591928749685445, -0.0005426925969096953]\n",
      "Layer: Layer 2, Input: [-0.6370406404529216, 0.24562140696279033, -0.32591928749685445, -0.0005426925969096953], Output: [-1.4531598679272535]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8615481879328456, 0.9365549608029388, -0.7745221653341205, -0.8792250637192872]\n",
      "Layer: Layer 1, Input: [0.8615481879328456, 0.9365549608029388, -0.7745221653341205, -0.8792250637192872], Output: [-0.9789993340809471, -0.6352130240969691, -0.7970673110803581, -0.5790925232232809]\n",
      "Layer: Layer 2, Input: [-0.9789993340809471, -0.6352130240969691, -0.7970673110803581, -0.5790925232232809], Output: [0.7383870837188415]\n",
      "Epoch 108/500, Loss: 0.6245530467879222, Accuracy: -1.3091497539551464\n",
      "Power operation: base = -0.10675454796943695, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4876224217772975, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4531598679272535, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26161291628115846, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9867945249178445, 0.9453246879887084, -0.9705354923137722, -0.9953991762915905]\n",
      "Layer: Layer 1, Input: [0.9867945249178445, 0.9453246879887084, -0.9705354923137722, -0.9953991762915905], Output: [-0.9872849266143787, -0.700537273279199, -0.8556037056900926, -0.637138426056092]\n",
      "Layer: Layer 2, Input: [-0.9872849266143787, -0.700537273279199, -0.8556037056900926, -0.637138426056092], Output: [0.894817104876211]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978055732518718, 0.908553531269466, 0.06957774241183795, -0.8933302392334207]\n",
      "Layer: Layer 1, Input: [0.9978055732518718, 0.908553531269466, 0.06957774241183795, -0.8933302392334207], Output: [-0.9792679128618781, -0.47716633720877705, -0.7252808724519221, -0.6294940807790288]\n",
      "Layer: Layer 2, Input: [-0.9792679128618781, -0.47716633720877705, -0.7252808724519221, -0.6294940807790288], Output: [0.48446144264019786]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9194191397952163, -0.3773049189948754, 0.47575321282750194, -0.8104632434950279]\n",
      "Layer: Layer 1, Input: [0.9194191397952163, -0.3773049189948754, 0.47575321282750194, -0.8104632434950279], Output: [-0.6479024803244139, 0.2532027931330178, -0.32687385301210425, -0.005243781639452044]\n",
      "Layer: Layer 2, Input: [-0.6479024803244139, 0.2532027931330178, -0.32687385301210425, -0.005243781639452044], Output: [-1.4560652826742695]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8619103918686475, 0.9376616706538492, -0.7747739763817225, -0.8801259290779018]\n",
      "Layer: Layer 1, Input: [0.8619103918686475, 0.9376616706538492, -0.7747739763817225, -0.8801259290779018], Output: [-0.9795084334586598, -0.6350912178990058, -0.7981809824304014, -0.5811153134881941]\n",
      "Layer: Layer 2, Input: [-0.9795084334586598, -0.6350912178990058, -0.7981809824304014, -0.5811153134881941], Output: [0.738953036324979]\n",
      "Epoch 109/500, Loss: 0.6227075688541871, Accuracy: -1.3067565841132773\n",
      "Power operation: base = -0.10518289512378898, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4844614426401979, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4560652826742695, power = 2, grad = 0.25\n",
      "Power operation: base = -0.261046963675021, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9868364959787156, 0.9462939089022252, -0.9705746301420688, -0.9954378185846049]\n",
      "Layer: Layer 1, Input: [0.9868364959787156, 0.9462939089022252, -0.9705746301420688, -0.9954378185846049], Output: [-0.9875619434854133, -0.7010295517660287, -0.8564415454736249, -0.6387401082135914]\n",
      "Layer: Layer 2, Input: [-0.9875619434854133, -0.7010295517660287, -0.8564415454736249, -0.6387401082135914], Output: [0.8964645459988372]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997811151111347, 0.9101042121270829, 0.06897998509831327, -0.8940851102481401]\n",
      "Layer: Layer 1, Input: [0.997811151111347, 0.9101042121270829, 0.06897998509831327, -0.8940851102481401], Output: [-0.9797596993041651, -0.47497660008234205, -0.726272887857476, -0.6310752170641096]\n",
      "Layer: Layer 2, Input: [-0.9797596993041651, -0.47497660008234205, -0.726272887857476, -0.6310752170641096], Output: [0.48131900378593295]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9196046868865236, -0.3696418301957757, 0.47530109910032164, -0.8117101006276299]\n",
      "Layer: Layer 1, Input: [0.9196046868865236, -0.3696418301957757, 0.47530109910032164, -0.8117101006276299], Output: [-0.6584383916160715, 0.2607486160724215, -0.3279053260951129, -0.009966791024573696]\n",
      "Layer: Layer 2, Input: [-0.6584383916160715, 0.2607486160724215, -0.3279053260951129, -0.009966791024573696], Output: [-1.4591634223560535]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8622656465263826, 0.9387438882199978, -0.7750237908270152, -0.8810039381796354]\n",
      "Layer: Layer 1, Input: [0.8622656465263826, 0.9387438882199978, -0.7750237908270152, -0.8810039381796354], Output: [-0.9799981539221218, -0.6349386416423636, -0.7993093237615582, -0.5831439453922961]\n",
      "Layer: Layer 2, Input: [-0.9799981539221218, -0.6349386416423636, -0.7993093237615582, -0.5831439453922961], Output: [0.7395738374714909]\n",
      "Epoch 110/500, Loss: 0.6209196039429062, Accuracy: -1.3044440426716584\n",
      "Power operation: base = -0.10353545400116282, power = 2, grad = 0.25\n",
      "Power operation: base = 1.481319003785933, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45916342235605345, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26042616252850914, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9868775969497029, 0.9472407244383729, -0.9706134056500549, -0.9954754059959315]\n",
      "Layer: Layer 1, Input: [0.9868775969497029, 0.9472407244383729, -0.9706134056500549, -0.9954754059959315], Output: [-0.9878292763927654, -0.7014964684909769, -0.8572926510676765, -0.640359952768166]\n",
      "Layer: Layer 2, Input: [-0.9878292763927654, -0.7014964684909769, -0.8572926510676765, -0.640359952768166], Output: [0.8981840261170833]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978166255791514, 0.9116219686795298, 0.06838607286569984, -0.8948215002972125]\n",
      "Layer: Layer 1, Input: [0.9978166255791514, 0.9116219686795298, 0.06838607286569984, -0.8948215002972125], Output: [-0.9802331704712264, -0.47273574316078254, -0.7272908527672203, -0.6326596619379822]\n",
      "Layer: Layer 2, Input: [-0.9802331704712264, -0.47273574316078254, -0.7272908527672203, -0.6326596619379822], Output: [0.47819205407943643]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9197869425605715, -0.3619667605171502, 0.4748515136469765, -0.8129277602036767]\n",
      "Layer: Layer 1, Input: [0.9197869425605715, -0.3619667605171502, 0.4748515136469765, -0.8129277602036767], Output: [-0.668655574246332, 0.2682591401335252, -0.32901638621626267, -0.014712608727102198]\n",
      "Layer: Layer 2, Input: [-0.668655574246332, 0.2682591401335252, -0.32901638621626267, -0.014712608727102198], Output: [-1.4624452144071969]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8626141518448633, 0.9398021302662513, -0.7752716081226395, -0.8818599276628241]\n",
      "Layer: Layer 1, Input: [0.8626141518448633, 0.9398021302662513, -0.7752716081226395, -0.8818599276628241], Output: [-0.9804694316140917, -0.6347536711045181, -0.8004528639738361, -0.5851791014982658]\n",
      "Layer: Layer 2, Input: [-0.9804694316140917, -0.6347536711045181, -0.8004528639738361, -0.5851791014982658], Output: [0.7402465902070618]\n",
      "Epoch 111/500, Loss: 0.6191864128771217, Accuracy: -1.3022066521624884\n",
      "Power operation: base = -0.10181597388291674, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4781920540794364, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4624452144071969, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25975340979293815, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9869178540226993, 0.9481656572619794, -0.9706518203002428, -0.9955119796149079]\n",
      "Layer: Layer 1, Input: [0.9869178540226993, 0.9481656572619794, -0.9706518203002428, -0.9955119796149079], Output: [-0.9880873529896805, -0.7019365234917307, -0.8581572000016321, -0.641998019864911]\n",
      "Layer: Layer 2, Input: [-0.9880873529896805, -0.7019365234917307, -0.8581572000016321, -0.641998019864911], Output: [0.8999719285879793]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978219995315606, 0.9131074126424982, 0.06779603472034058, -0.8955400580335785]\n",
      "Layer: Layer 1, Input: [0.9978219995315606, 0.9131074126424982, 0.06779603472034058, -0.8955400580335785], Output: [-0.9806891820125132, -0.47044162490206615, -0.7283356464206929, -0.6342481495166149]\n",
      "Layer: Layer 2, Input: [-0.9806891820125132, -0.47044162490206615, -0.7283356464206929, -0.6342481495166149], Output: [0.4750775214383749]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9199659953061722, -0.3542819506108474, 0.47440448801007773, -0.8141172020157725]\n",
      "Layer: Layer 1, Input: [0.9199659953061722, -0.3542819506108474, 0.47440448801007773, -0.8141172020157725], Output: [-0.6785611986027047, 0.2757348750876038, -0.330209602729038, -0.019482032293814684]\n",
      "Layer: Layer 2, Input: [-0.6785611986027047, 0.2757348750876038, -0.330209602729038, -0.019482032293814684], Output: [-1.4659017752047103]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.862956097888429, 0.9408368960020139, -0.7755174265436677, -0.8826946874990508]\n",
      "Layer: Layer 1, Input: [0.862956097888429, 0.9408368960020139, -0.7755174265436677, -0.8826946874990508], Output: [-0.980923145249307, -0.6345346581198688, -0.8016121042352201, -0.5872214269151027]\n",
      "Layer: Layer 2, Input: [-0.980923145249307, -0.6345346581198688, -0.8016121042352201, -0.5872214269151027], Output: [0.7409684321199577]\n",
      "Epoch 112/500, Loss: 0.6175052816551203, Accuracy: -1.3000389359351483\n",
      "Power operation: base = -0.10002807141202075, power = 2, grad = 0.25\n",
      "Power operation: base = 1.475077521438375, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4659017752047103, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25903156788004233, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9869572921657752, 0.9490692107575456, -0.9706898753797639, -0.9955475782100953]\n",
      "Layer: Layer 1, Input: [0.9869572921657752, 0.9490692107575456, -0.9706898753797639, -0.9955475782100953], Output: [-0.9883365767434127, -0.7023482275179258, -0.8590353568046151, -0.6436543605892064]\n",
      "Layer: Layer 2, Input: [-0.9883365767434127, -0.7023482275179258, -0.8590353568046151, -0.6436543605892064], Output: [0.9018247700502369]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978272756996325, 0.9145611383194767, 0.0672099021281756, -0.8962413965546979]\n",
      "Layer: Layer 1, Input: [0.9978272756996325, 0.9145611383194767, 0.0672099021281756, -0.8962413965546979], Output: [-0.9811285390391918, -0.468092032984526, -0.7294081160974766, -0.6358413862014024]\n",
      "Layer: Layer 2, Input: [-0.9811285390391918, -0.468092032984526, -0.7294081160974766, -0.6358413862014024], Output: [0.4719723156379674]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9201419290075408, -0.34658970429499714, 0.47396005563143656, -0.815279352785109]\n",
      "Layer: Layer 1, Input: [0.9201419290075408, -0.34658970429499714, 0.47396005563143656, -0.815279352785109], Output: [-0.688162402730004, 0.2831765658737435, -0.33148743360665117, -0.024275772733636004]\n",
      "Layer: Layer 2, Input: [-0.688162402730004, 0.2831765658737435, -0.33148743360665117, -0.024275772733636004], Output: [-1.4695244054128933]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.863291665500679, 0.941848668467534, -0.7757612433183654, -0.883508964404966]\n",
      "Layer: Layer 1, Input: [0.863291665500679, 0.941848668467534, -0.7757612433183654, -0.883508964404966], Output: [-0.9813601204702329, -0.6342799307751841, -0.8027875179598989, -0.5892715323997111]\n",
      "Layer: Layer 2, Input: [-0.9813601204702329, -0.6342799307751841, -0.8027875179598989, -0.5892715323997111], Output: [0.7417365400416895]\n",
      "Epoch 113/500, Loss: 0.6158735139520645, Accuracy: -1.2979354109589343\n",
      "Power operation: base = -0.09817522994976313, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4719723156379674, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4695244054128933, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25826345995831046, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9869959352023419, 0.9499518705381776, -0.9707275720220081, -0.9955822384011432]\n",
      "Layer: Layer 1, Input: [0.9869959352023419, 0.9499518705381776, -0.9707275720220081, -0.9955822384011432], Output: [-0.9885773286660585, -0.7027301008154797, -0.859927272448917, -0.6453290180658522]\n",
      "Layer: Layer 2, Input: [-0.9885773286660585, -0.7027301008154797, -0.859927272448917, -0.6453290180658522], Output: [0.9037391997865116]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978324566793717, 0.9159837242241462, 0.06662770865503509, -0.8969260960459065]\n",
      "Layer: Layer 1, Input: [0.9978324566793717, 0.9159837242241462, 0.06662770865503509, -0.8969260960459065], Output: [-0.9815519998648344, -0.465684684427747, -0.7305090762317176, -0.6374400527698864]\n",
      "Layer: Layer 2, Input: [-0.9815519998648344, -0.465684684427747, -0.7305090762317176, -0.6374400527698864], Output: [0.46887332952700067]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.920314823274839, -0.3388923825342929, 0.4735182515740688, -0.8164150901143504]\n",
      "Layer: Layer 1, Input: [0.920314823274839, -0.3388923825342929, 0.4735182515740688, -0.8164150901143504], Output: [-0.6974662898956965, 0.2905851817619879, -0.33285222422377275, -0.029094458735932482]\n",
      "Layer: Layer 2, Input: [-0.6974662898956965, 0.2905851817619879, -0.33285222422377275, -0.029094458735932482], Output: [-1.4733045845182093]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8636210269287962, 0.9428379158883465, -0.7760030547758808, -0.8843034650263693]\n",
      "Layer: Layer 1, Input: [0.8636210269287962, 0.9428379158883465, -0.7760030547758808, -0.8843034650263693], Output: [-0.9817811338452862, -0.6339877932122878, -0.8039795506314725, -0.5913299971906716]\n",
      "Layer: Layer 2, Input: [-0.9817811338452862, -0.6339877932122878, -0.8039795506314725, -0.5913299971906716], Output: [0.7425481330897812]\n",
      "Epoch 114/500, Loss: 0.6142884233387474, Accuracy: -1.2958905811689174\n",
      "Power operation: base = -0.09626080021348837, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4688733295270007, power = 2, grad = 0.25\n",
      "Power operation: base = -0.47330458451820934, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2574518669102188, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9870338058859158, 0.9508141058846449, -0.9707649112297739, -0.9956159948177056]\n",
      "Layer: Layer 1, Input: [0.9870338058859158, 0.9508141058846449, -0.9707649112297739, -0.9956159948177056], Output: [-0.9888099689121028, -0.7030806716869632, -0.8608330837243985, -0.647022028435076]\n",
      "Layer: Layer 2, Input: [-0.9888099689121028, -0.7030806716869632, -0.8608330837243985, -0.647022028435076], Output: [0.9057119981251822]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978375449413898, 0.9173757346500567, 0.06604948957678758, -0.8975947062415189]\n",
      "Layer: Layer 1, Input: [0.9978375449413898, 0.9173757346500567, 0.06604948957678758, -0.8975947062415189], Output: [-0.9819602794420028, -0.4632172254416945, -0.7316393073700256, -0.6390448062700991]\n",
      "Layer: Layer 2, Input: [-0.9819602794420028, -0.4632172254416945, -0.7316393073700256, -0.6390448062700991], Output: [0.46577743898735857]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9204847537591833, -0.3311923967129926, 0.4730791122197347, -0.8175252461803043]\n",
      "Layer: Layer 1, Input: [0.9204847537591833, -0.3311923967129926, 0.4730791122197347, -0.8175252461803043], Output: [-0.7064799262533629, 0.2979619049361227, -0.3343062061663065, -0.03393864114820719]\n",
      "Layer: Layer 2, Input: [-0.7064799262533629, 0.2979619049361227, -0.3343062061663065, -0.03393864114820719], Output: [-1.477233964839201]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8639443464165316, 0.943805092976314, -0.7762428565048883, -0.88507885889975]\n",
      "Layer: Layer 1, Input: [0.8639443464165316, 0.943805092976314, -0.7762428565048883, -0.88507885889975], Output: [-0.9821869165347981, -0.6336565251317875, -0.8051886194905047, -0.5933973715869395]\n",
      "Layer: Layer 2, Input: [-0.9821869165347981, -0.6336565251317875, -0.8051886194905047, -0.5933973715869395], Output: [0.7434004743864442]\n",
      "Epoch 115/500, Loss: 0.6127473254207827, Accuracy: -1.2938989313149332\n",
      "Power operation: base = -0.09428800187481778, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4657774389873586, power = 2, grad = 0.25\n",
      "Power operation: base = -0.477233964839201, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2565995256135558, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9870709259704844, 0.9516563711020918, -0.9708018938992057, -0.9956488802461039]\n",
      "Layer: Layer 1, Input: [0.9870709259704844, 0.9516563711020918, -0.9708018938992057, -0.9956488802461039], Output: [-0.9890348382505769, -0.7033984749068466, -0.8617529125575656, -0.6487334217139542]\n",
      "Layer: Layer 2, Input: [-0.9890348382505769, -0.7033984749068466, -0.8617529125575656, -0.6487334217139542], Output: [0.9077400741498152]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978425428400358, 0.9187377211619244, 0.06547528147212099, -0.8982477487083821]\n",
      "Layer: Layer 1, Input: [0.9978425428400358, 0.9187377211619244, 0.06547528147212099, -0.8982477487083821], Output: [-0.9823540525157692, -0.4606872310916452, -0.7327995549885218, -0.6406562817255472]\n",
      "Layer: Layer 2, Input: [-0.9823540525157692, -0.4606872310916452, -0.7327995549885218, -0.6406562817255472], Output: [0.4626815019246484]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9206517924509958, -0.3234922013466778, 0.47264267495198303, -0.8186106111692667]\n",
      "Layer: Layer 1, Input: [0.9206517924509958, -0.3234922013466778, 0.47264267495198303, -0.8186106111692667], Output: [-0.7152103384005704, 0.3053081185070821, -0.3358514960516573, -0.03880879764883697]\n",
      "Layer: Layer 2, Input: [-0.7152103384005704, 0.3053081185070821, -0.3358514960516573, -0.03880879764883697], Output: [-1.4813043652212965]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8642617807646302, 0.9447506421609179, -0.7764806435180709, -0.8858357811984527]\n",
      "Layer: Layer 1, Input: [0.8642617807646302, 0.9447506421609179, -0.7764806435180709, -0.8858357811984527], Output: [-0.9825781576493787, -0.6332843810795061, -0.8064151131037182, -0.5954741792847735]\n",
      "Layer: Layer 2, Input: [-0.9825781576493787, -0.6332843810795061, -0.8064151131037182, -0.5954741792847735], Output: [0.7442908717403354]\n",
      "Epoch 116/500, Loss: 0.611247530061705, Accuracy: -1.2919549212557944\n",
      "Power operation: base = -0.09225992585018483, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4626815019246484, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4813043652212965, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25570912825966463, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9871073162765144, 0.9524791067856874, -0.970838520843902, -0.9956809257644603]\n",
      "Layer: Layer 1, Input: [0.9871073162765144, 0.9524791067856874, -0.970838520843902, -0.9956809257644603], Output: [-0.9892522594198759, -0.7036820500585538, -0.8626868652870242, -0.6504632225510784]\n",
      "Layer: Layer 2, Input: [-0.9892522594198759, -0.7036820500585538, -0.8626868652870242, -0.6504632225510784], Output: [0.9098204629383417]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997847452621984, 0.9200702239893642, 0.06490512180883969, -0.8988857189580636]\n",
      "Layer: Layer 1, Input: [0.997847452621984, 0.9200702239893642, 0.06490512180883969, -0.8988857189580636], Output: [-0.9827339565148717, -0.4580922048578255, -0.7339905281833324, -0.6422750936586995]\n",
      "Layer: Layer 2, Input: [-0.9827339565148717, -0.4580922048578255, -0.7339905281833324, -0.6422750936586995], Output: [0.4595823565376791]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9208160079609843, -0.3157942863703995, 0.47220897783321136, -0.8196719364609518]\n",
      "Layer: Layer 1, Input: [0.9208160079609843, -0.3157942863703995, 0.47220897783321136, -0.8196719364609518], Output: [-0.7236645106908843, 0.31262539397274786, -0.3374900943412661, -0.0437053375542806]\n",
      "Layer: Layer 2, Input: [-0.7236645106908843, 0.31262539397274786, -0.3374900943412661, -0.0437053375542806], Output: [-1.4855077645638264]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8645734798580504, 0.9456749947388862, -0.7767164104181352, -0.8865748352720723]\n",
      "Layer: Layer 1, Input: [0.8645734798580504, 0.9456749947388862, -0.7767164104181352, -0.8865748352720723], Output: [-0.9829555073244665, -0.6328695895866507, -0.8076593908302198, -0.5975609194862394]\n",
      "Layer: Layer 2, Input: [-0.9829555073244665, -0.6328695895866507, -0.8076593908302198, -0.5975609194862394], Output: [0.7452166775343869]\n",
      "Epoch 117/500, Loss: 0.6097863338197801, Accuracy: -1.2900529806287766\n",
      "Power operation: base = -0.09017953706165827, power = 2, grad = 0.25\n",
      "Power operation: base = 1.459582356537679, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4855077645638264, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2547833224656131, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9871429967526867, 0.9532827409896591, -0.9708747928186822, -0.9957121608670101]\n",
      "Layer: Layer 1, Input: [0.9871429967526867, 0.9532827409896591, -0.9708747928186822, -0.9957121608670101], Output: [-0.9894625383732593, -0.7039299398500666, -0.8636350319052647, -0.6522114508814247]\n",
      "Layer: Layer 2, Input: [-0.9894625383732593, -0.7039299398500666, -0.8636350319052647, -0.6522114508814247], Output: [0.911950322513587]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978522764342714, 0.9213737733094207, 0.0643390485328589, -0.8995090883949284]\n",
      "Layer: Layer 1, Input: [0.9978522764342714, 0.9213737733094207, 0.0643390485328589, -0.8995090883949284], Output: [-0.983100594200558, -0.4554295781613131, -0.7352128982474845, -0.643901837441253]\n",
      "Layer: Layer 2, Input: [-0.983100594200558, -0.4554295781613131, -0.7352128982474845, -0.643901837441253], Output: [0.4564768190795703]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9209774657833724, -0.3081011691321845, 0.4717780592829501, -0.8207099375691916]\n",
      "Layer: Layer 1, Input: [0.9209774657833724, -0.3081011691321845, 0.4717780592829501, -0.8207099375691916], Output: [-0.7318493822124404, 0.31991547814392324, -0.339223884126445, -0.04862860670358547]\n",
      "Layer: Layer 2, Input: [-0.7318493822124404, 0.31991547814392324, -0.339223884126445, -0.04862860670358547], Output: [-1.4898362952752118]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8648795871598228, 0.946578571934004, -0.7769501515617374, -0.887296594988694]\n",
      "Layer: Layer 1, Input: [0.8648795871598228, 0.946578571934004, -0.7769501515617374, -0.887296594988694], Output: [-0.9833195795337503, -0.6324103522256452, -0.8089217821983813, -0.5996580687923245]\n",
      "Layer: Layer 2, Input: [-0.9833195795337503, -0.6324103522256452, -0.8089217821983813, -0.5996580687923245], Output: [0.7461752880237653]\n",
      "Epoch 118/500, Loss: 0.6083610127000919, Accuracy: -1.2881875038174297\n",
      "Power operation: base = -0.08804967748641301, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4564768190795703, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4898362952752118, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2538247119762347, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9871779865334659, 0.9540676902968177, -0.9709107105425883, -0.9957426135783066]\n",
      "Layer: Layer 1, Input: [0.9871779865334659, 0.9540676902968177, -0.9709107105425883, -0.9957426135783066], Output: [-0.9896659654229037, -0.7041406884562842, -0.8645974852751724, -0.6539781224874691]\n",
      "Layer: Layer 2, Input: [-0.9896659654229037, -0.7041406884562842, -0.8645974852751724, -0.6539781224874691], Output: [0.9141269306518591]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978570163317898, 0.9226488904089568, 0.0637770996675466, -0.9001183061081032]\n",
      "Layer: Layer 1, Input: [0.9978570163317898, 0.9226488904089568, 0.0637770996675466, -0.9001183061081032], Output: [-0.9834545360923439, -0.4526967099216945, -0.7364672971459072, -0.6455370904795363]\n",
      "Layer: Layer 2, Input: [-0.9834545360923439, -0.4526967099216945, -0.7364672971459072, -0.6455370904795363], Output: [0.4533616812929724]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9211362285412803, -0.3004153862119816, 0.47134995776339905, -0.8217252968492781]\n",
      "Layer: Layer 1, Input: [0.9211362285412803, -0.3004153862119816, 0.47134995776339905, -0.8217252968492781], Output: [-0.7397718433886504, 0.32718027955936435, -0.34105462986791557, -0.05357889236617348]\n",
      "Layer: Layer 2, Input: [-0.7397718433886504, 0.32718027955936435, -0.34105462986791557, -0.05357889236617348], Output: [-1.494282236710571]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8651802401717835, 0.94746178586213, -0.777181861218344, -0.8880016068902417]\n",
      "Layer: Layer 1, Input: [0.8651802401717835, 0.94746178586213, -0.777181861218344, -0.8880016068902417], Output: [-0.9836709546629522, -0.6319048426358815, -0.8102025862054333, -0.6017660828930758]\n",
      "Layer: Layer 2, Input: [-0.9836709546629522, -0.6319048426358815, -0.8102025862054333, -0.6017660828930758], Output: [0.7471641422141002]\n",
      "Epoch 119/500, Loss: 0.6069688152999856, Accuracy: -1.2863528451375843\n",
      "Power operation: base = -0.08587306934814087, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4533616812929724, power = 2, grad = 0.25\n",
      "Power operation: base = -0.49428223671057103, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2528358577858998, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9872123039926393, 0.954834360787881, -0.9709462747207797, -0.9957723105580087]\n",
      "Layer: Layer 1, Input: [0.9872123039926393, 0.954834360787881, -0.9709462747207797, -0.9957723105580087], Output: [-0.989862816290133, -0.7043128399292979, -0.8655742803283503, -0.6557632494716064]\n",
      "Layer: Layer 2, Input: [-0.989862816290133, -0.7043128399292979, -0.8655742803283503, -0.6557632494716064], Output: [0.9163476816663509]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978616742842367, 0.9238960887219313, 0.0632193129297097, -0.9007138005157923]\n",
      "Layer: Layer 1, Input: [0.9978616742842367, 0.9238960887219313, 0.0632193129297097, -0.9007138005157923], Output: [-0.9837963226889463, -0.4498908862071727, -0.7377543158991824, -0.6471814132431922]\n",
      "Layer: Layer 2, Input: [-0.9837963226889463, -0.4498908862071727, -0.7377543158991824, -0.6471814132431922], Output: [0.4502337076760128]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9212923562143831, -0.2927394851770306, 0.4709247114771999, -0.822718665983008]\n",
      "Layer: Layer 1, Input: [0.9212923562143831, -0.2927394851770306, 0.4709247114771999, -0.822718665983008], Output: [-0.7474387321912379, 0.3344218544149733, -0.34298397606899017, -0.058556428121857525]\n",
      "Layer: Layer 2, Input: [-0.7474387321912379, 0.3344218544149733, -0.34298397606899017, -0.058556428121857525], Output: [-1.4988380086128883]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.865475570862748, 0.9483250403990967, -0.777411533721601, -0.8886903921715873]\n",
      "Layer: Layer 1, Input: [0.865475570862748, 0.9483250403990967, -0.777411533721601, -0.8886903921715873], Output: [-0.9840101818641633, -0.6313512055673541, -0.8115020705504497, -0.6038853980663569]\n",
      "Layer: Layer 2, Input: [-0.9840101818641633, -0.6313512055673541, -0.8115020705504497, -0.6038853980663569], Output: [0.7481807204608297]\n",
      "Epoch 120/500, Loss: 0.605606956406702, Accuracy: -1.2845433141617204\n",
      "Power operation: base = -0.08365231833364906, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4502337076760128, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4988380086128883, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25181927953917027, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9872459667929779, 0.9555831489117239, -0.9709814860650487, -0.9958012771969187]\n",
      "Layer: Layer 1, Input: [0.9872459667929779, 0.9555831489117239, -0.9709814860650487, -0.9958012771969187], Output: [-0.9900533530691432, -0.704444936712055, -0.8665654532512134, -0.6575668406439446]\n",
      "Layer: Layer 2, Input: [-0.9900533530691432, -0.704444936712055, -0.8665654532512134, -0.6575668406439446], Output: [0.9186100832565667]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978662521825405, 0.9251158747398982, 0.0626657253672829, -0.9012959808706805]\n",
      "Layer: Layer 1, Input: [0.9978662521825405, 0.9251158747398982, 0.0626657253672829, -0.9012959808706805], Output: [-0.9841264665016092, -0.4470093200342249, -0.7390745028857646, -0.6488353501448824]\n",
      "Layer: Layer 2, Input: [-0.9841264665016092, -0.4470093200342249, -0.7390745028857646, -0.6488353501448824], Output: [0.44708963271383384]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.921445906349161, -0.2850760163753576, 0.4705023580814762, -0.8236906682532904]\n",
      "Layer: Layer 1, Input: [0.921445906349161, -0.2850760163753576, 0.4705023580814762, -0.8236906682532904], Output: [-0.754856829982952, 0.3416423920335858, -0.3450134458621698, -0.06356139866493517]\n",
      "Layer: Layer 2, Input: [-0.754856829982952, 0.3416423920335858, -0.3450134458621698, -0.06356139866493517], Output: [-1.5034961645530909]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8657657060649487, 0.9491687319513694, -0.7776391636112846, -0.889363448494227]\n",
      "Layer: Layer 1, Input: [0.8657657060649487, 0.9491687319513694, -0.7776391636112846, -0.889363448494227], Output: [-0.9843377812096112, -0.6307475559851031, -0.812820470810216, -0.6060164324958346]\n",
      "Layer: Layer 2, Input: [-0.9843377812096112, -0.6307475559851031, -0.812820470810216, -0.6060164324958346], Output: [0.7492225429055024]\n",
      "Epoch 121/500, Loss: 0.6042726110904544, Accuracy: -1.2827531711048556\n",
      "Power operation: base = -0.08138991674343332, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4470896327138338, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5034961645530909, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2507774570944976, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9872789919321846, 0.956314442259142, -0.9710163453127502, -0.9958295377049178]\n",
      "Layer: Layer 1, Input: [0.9872789919321846, 0.956314442259142, -0.9710163453127502, -0.9958295377049178], Output: [-0.9902378251111794, -0.7045355182864347, -0.8675710206638978, -0.6593889018285424]\n",
      "Layer: Layer 2, Input: [-0.9902378251111794, -0.7045355182864347, -0.8675710206638978, -0.6593889018285424], Output: [0.920911753493542]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978707518447754, 0.9263087487967959, 0.062116373022718864, -0.901865238635236]\n",
      "Layer: Layer 1, Input: [0.9978707518447754, 0.9263087487967959, 0.062116373022718864, -0.901865238635236], Output: [-0.9844454539159488, -0.44404915137141254, -0.7404283620716549, -0.6504994302781812]\n",
      "Layer: Layer 2, Input: [-0.9844454539159488, -0.44404915137141254, -0.7404283620716549, -0.6504994302781812], Output: [0.4439261581925744]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9215969342522038, -0.2774275248596941, 0.4700829344213469, -0.8246419006206419]\n",
      "Layer: Layer 1, Input: [0.9215969342522038, -0.2774275248596941, 0.4700829344213469, -0.8246419006206419], Output: [-0.7620328570279136, 0.3488441999023406, -0.3471444394890989, -0.06859394448705208]\n",
      "Layer: Layer 2, Input: [-0.7620328570279136, 0.3488441999023406, -0.3471444394890989, -0.06859394448705208], Output: [-1.5082493853451153]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.86605076783977, 0.9499932501311396, -0.7778647457643502, -0.8900212516453171]\n",
      "Layer: Layer 1, Input: [0.86605076783977, 0.9499932501311396, -0.7778647457643502, -0.8900212516453171], Output: [-0.9846542456624274, -0.6300919782735375, -0.8141579895664867, -0.608159587417723]\n",
      "Layer: Layer 2, Input: [-0.9846542456624274, -0.6300919782735375, -0.8141579895664867, -0.608159587417723], Output: [0.7502871678437981]\n",
      "Epoch 122/500, Loss: 0.6029629093238481, Accuracy: -1.2809766222003494\n",
      "Power operation: base = -0.07908824650645796, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4439261581925744, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5082493853451153, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24971283215620188, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9873113957853041, 0.957028620243888, -0.9710508532439885, -0.9958571151914116]\n",
      "Layer: Layer 1, Input: [0.9873113957853041, 0.957028620243888, -0.9710508532439885, -0.9958571151914116], Output: [-0.9904164698357416, -0.7045831199833887, -0.8685909787962993, -0.6612294360901925]\n",
      "Layer: Layer 2, Input: [-0.9904164698357416, -0.7045831199833887, -0.8685909787962993, -0.6612294360901925], Output: [0.9232504179926821]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978751750215846, 0.9274752057313103, 0.061571290625093915, -0.9024219487356974]\n",
      "Layer: Layer 1, Input: [0.9978751750215846, 0.9274752057313103, 0.061571290625093915, -0.9024219487356974], Output: [-0.9847537468973528, -0.44100744740050274, -0.7418163511759673, -0.652174168020132]\n",
      "Layer: Layer 2, Input: [-0.9847537468973528, -0.44100744740050274, -0.7418163511759673, -0.652174168020132], Output: [0.44073995069809113]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9217454931671515, -0.2697965425246273, 0.4696664762853583, -0.8255729356141219]\n",
      "Layer: Layer 1, Input: [0.9217454931671515, -0.2697965425246273, 0.4696664762853583, -0.8255729356141219], Output: [-0.7689734677224959, 0.3560296883044619, -0.34937823265437373, -0.07365416639639286]\n",
      "Layer: Layer 2, Input: [-0.7689734677224959, 0.3560296883044619, -0.34937823265437373, -0.07365416639639286], Output: [-1.513090472398313]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.866330873813976, 0.9507989783389706, -0.7780882755139767, -0.8906642570527117]\n",
      "Layer: Layer 1, Input: [0.866330873813976, 0.9507989783389706, -0.7780882755139767, -0.8906642570527117], Output: [-0.9849600428806785, -0.6293825255768711, -0.8155147954923359, -0.6103152481046699]\n",
      "Layer: Layer 2, Input: [-0.9849600428806785, -0.6293825255768711, -0.8155147954923359, -0.6103152481046699], Output: [0.7513721901023476]\n",
      "Epoch 123/500, Loss: 0.6016749311490658, Accuracy: -1.2792078150013744\n",
      "Power operation: base = -0.07674958200731785, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4407399506980911, power = 2, grad = 0.25\n",
      "Power operation: base = -0.513090472398313, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24862780989765243, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987343194143779, 0.9577260546956415, -0.9710850106969625, -0.9958840317388696]\n",
      "Layer: Layer 1, Input: [0.987343194143779, 0.9577260546956415, -0.9710850106969625, -0.9958840317388696], Output: [-0.9905895134749877, -0.7045862719803853, -0.8696253026649898, -0.6630884438828939]\n",
      "Layer: Layer 2, Input: [-0.9905895134749877, -0.7045862719803853, -0.8696253026649898, -0.6630884438828939], Output: [0.9256239073112482]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978795234011357, 0.9286157354318704, 0.06103051131311518, -0.9029664707033657]\n",
      "Layer: Layer 1, Input: [0.9978795234011357, 0.9286157354318704, 0.06103051131311518, -0.9029664707033657], Output: [-0.9850517845538722, -0.43788120308751416, -0.7432388797804493, -0.6538600635041593]\n",
      "Layer: Layer 2, Input: [-0.9850517845538722, -0.43788120308751416, -0.7432388797804493, -0.6538600635041593], Output: [0.4375276393902152]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9218916344359428, -0.2621855805302904, 0.4692530181846326, -0.8264843230492578]\n",
      "Layer: Layer 1, Input: [0.9218916344359428, -0.2621855805302904, 0.4692530181846326, -0.8264843230492578], Output: [-0.7756852456097534, 0.36320135457159636, -0.35171597473469635, -0.07874212983361505]\n",
      "Layer: Layer 2, Input: [-0.7756852456097534, 0.36320135457159636, -0.35171597473469635, -0.07874212983361505], Output: [-1.5180123409606645]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8666061374877451, 0.9515862942582552, -0.7783097487558498, -0.8912929011663879]\n",
      "Layer: Layer 1, Input: [0.8666061374877451, 0.9515862942582552, -0.7783097487558498, -0.8912929011663879], Output: [-0.9852556168696786, -0.6286172193100475, -0.8168910224046981, -0.6124837846939746]\n",
      "Layer: Layer 2, Input: [-0.9852556168696786, -0.6286172193100475, -0.8168910224046981, -0.6124837846939746], Output: [0.7524752394869934]\n",
      "Epoch 124/500, Loss: 0.6004057024072549, Accuracy: -1.277440833552638\n",
      "Power operation: base = -0.07437609268875178, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4375276393902152, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5180123409606645, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24752476051300665, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9873744022513353, 0.9584071103702468, -0.9711188185813998, -0.9959103084700129]\n",
      "Layer: Layer 1, Input: [0.9873744022513353, 0.9584071103702468, -0.9711188185813998, -0.9959103084700129], Output: [-0.990757171757106, -0.7045434985098131, -0.8706739452543726, -0.6649659231202701]\n",
      "Layer: Layer 2, Input: [-0.990757171757106, -0.7045434985098131, -0.8706739452543726, -0.6649659231202701], Output: [0.9280301545954646]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978837986136283, 0.9297308232707072, 0.0604940663904523, -0.9034991497116063]\n",
      "Layer: Layer 1, Input: [0.9978837986136283, 0.9297308232707072, 0.0604940663904523, -0.9034991497116063], Output: [-0.9853399845694812, -0.4346673421165914, -0.7446963073908359, -0.655557602968203]\n",
      "Layer: Layer 2, Input: [-0.9853399845694812, -0.4346673421165914, -0.7446963073908359, -0.655557602968203], Output: [0.4342858141345247]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9220354076451137, -0.25459712207645474, 0.4688425931569422, -0.8273765915853639]\n",
      "Layer: Layer 1, Input: [0.9220354076451137, -0.25459712207645474, 0.4688425931569422, -0.8273765915853639], Output: [-0.782174698246415, 0.37036176698174594, -0.35415868682631313, -0.08385786894785315]\n",
      "Layer: Layer 2, Input: [-0.782174698246415, 0.37036176698174594, -0.35415868682631313, -0.08385786894785315], Output: [-1.5230080132015977]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8668766685159216, 0.9523555702666083, -0.7785291620412177, -0.8919076027163074]\n",
      "Layer: Layer 1, Input: [0.8668766685159216, 0.9523555702666083, -0.7785291620412177, -0.8919076027163074], Output: [-0.9855413894963981, -0.6277940488734578, -0.818286768289754, -0.6146655528661533]\n",
      "Layer: Layer 2, Input: [-0.9855413894963981, -0.6277940488734578, -0.818286768289754, -0.6146655528661533], Output: [0.7535939793533317]\n",
      "Epoch 125/500, Loss: 0.5991521910397745, Accuracy: -1.2756696933873264\n",
      "Power operation: base = -0.07196984540453544, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4342858141345247, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5230080132015977, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24640602064666828, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9874050348368858, 0.959072145383032, -0.9711522778900603, -0.9959359656091687]\n",
      "Layer: Layer 1, Input: [0.9874050348368858, 0.959072145383032, -0.9711522778900603, -0.9959359656091687], Output: [-0.9909196505340165, -0.7044533173011399, -0.8717368367051838, -0.6668618691673137]\n",
      "Layer: Layer 2, Input: [-0.9909196505340165, -0.7044533173011399, -0.8717368367051838, -0.6668618691673137], Output: [0.9304671934924862]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978880022353822, 0.9308209504344401, 0.05996198511418832, -0.9040203175166681]\n",
      "Layer: Layer 1, Input: [0.9978880022353822, 0.9308209504344401, 0.05996198511418832, -0.9040203175166681], Output: [-0.9856187445195644, -0.4313627182406046, -0.746188941457917, -0.6572672589820662]\n",
      "Layer: Layer 2, Input: [-0.9856187445195644, -0.4313627182406046, -0.746188941457917, -0.6572672589820662], Output: [0.43101102406724534]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9221768607579368, -0.24703361558156303, 0.4684352325964117, -0.8282502501343715]\n",
      "Layer: Layer 1, Input: [0.9221768607579368, -0.24703361558156303, 0.4684352325964117, -0.8282502501343715], Output: [-0.7884482519940684, 0.3775135483265119, -0.35670725961557614, -0.08900139039903926]\n",
      "Layer: Layer 2, Input: [-0.7884482519940684, 0.3775135483265119, -0.35670725961557614, -0.08900139039903926], Output: [-1.5280706110820688]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8671425729639457, 0.9531071737699582, -0.7787465126565128, -0.8925087638563637]\n",
      "Layer: Layer 1, Input: [0.8671425729639457, 0.9531071737699582, -0.7787465126565128, -0.8925087638563637], Output: [-0.9858177618786351, -0.6269109716044321, -0.8197020943075519, -0.6168608943786763]\n",
      "Layer: Layer 2, Input: [-0.9858177618786351, -0.6269109716044321, -0.8197020943075519, -0.6168608943786763], Output: [0.7547261053410059]\n",
      "Epoch 126/500, Loss: 0.5979113039681446, Accuracy: -1.2738883363158218\n",
      "Power operation: base = -0.06953280650751381, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4310110240672453, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5280706110820688, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24527389465899407, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9874351061446371, 0.9597215115713281, -0.9711853897083104, -0.9959610225382823]\n",
      "Layer: Layer 1, Input: [0.9874351061446371, 0.9597215115713281, -0.9711853897083104, -0.9959610225382823], Output: [-0.9910771463583656, -0.7043142392793401, -0.872813883513346, -0.6687762747520666]\n",
      "Layer: Layer 2, Input: [-0.9910771463583656, -0.7043142392793401, -0.872813883513346, -0.6687762747520666], Output: [0.9329331563347498]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997892135792528, 0.9318865941593846, 0.05943429451660358, -0.9045302933100886]\n",
      "Layer: Layer 1, Input: [0.997892135792528, 0.9318865941593846, 0.05943429451660358, -0.9045302933100886], Output: [-0.9858884430794937, -0.4279641171039583, -0.7477170353663725, -0.6589894905571022]\n",
      "Layer: Layer 2, Input: [-0.9858884430794937, -0.4279641171039583, -0.7477170353663725, -0.6589894905571022], Output: [0.42769977666451364]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9223160402332262, -0.23949746831213162, 0.46803096610911027, -0.8291057891329048]\n",
      "Layer: Layer 1, Input: [0.9223160402332262, -0.23949746831213162, 0.46803096610911027, -0.8291057891329048], Output: [-0.7945122468059643, 0.3846593591699928, -0.35936245105987324, -0.09417267685573132]\n",
      "Layer: Layer 2, Input: [-0.7945122468059643, 0.3846593591699928, -0.35936245105987324, -0.09417267685573132], Output: [-1.5331933489615974]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8674039535399635, 0.9538414674655289, -0.7789617986895486, -0.8930967712036357]\n",
      "Layer: Layer 1, Input: [0.8674039535399635, 0.9538414674655289, -0.7789617986895486, -0.8930967712036357], Output: [-0.9860851156605386, -0.625965912998776, -0.8211370237821558, -0.6190701374585742]\n",
      "Layer: Layer 2, Input: [-0.9860851156605386, -0.625965912998776, -0.8211370237821558, -0.6190701374585742], Output: [0.7558693443060016]\n",
      "Epoch 127/500, Loss: 0.5966798845583966, Accuracy: -1.2720906249853594\n",
      "Power operation: base = -0.06706684366525018, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4276997766645136, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5331933489615974, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2441306556939984, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9874646299615842, 0.9603555547924694, -0.9712181552217982, -0.9959854978480398]\n",
      "Layer: Layer 1, Input: [0.9874646299615842, 0.9603555547924694, -0.9712181552217982, -0.9959854978480398], Output: [-0.9912298470143975, -0.7041247685423402, -0.8739049677421993, -0.6707091297950974]\n",
      "Layer: Layer 2, Input: [-0.9912298470143975, -0.7041247685423402, -0.8739049677421993, -0.6707091297950974], Output: [0.9354262725982521]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9978962007643273, 0.9329282278802485, 0.058911019260036335, -0.905029384490095]\n",
      "Layer: Layer 1, Input: [0.9978962007643273, 0.9329282278802485, 0.058911019260036335, -0.905029384490095], Output: [-0.9861494411362467, -0.4244682585951419, -0.7492807863997871, -0.6607247431404913]\n",
      "Layer: Layer 2, Input: [-0.9861494411362467, -0.4244682585951419, -0.7492807863997871, -0.6607247431404913], Output: [0.42434853738465117]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9224529911316487, -0.23199104049910516, 0.46762982139441484, -0.8299436816888823]\n",
      "Layer: Layer 1, Input: [0.9224529911316487, -0.23199104049910516, 0.46762982139441484, -0.8299436816888823], Output: [-0.8003729310784456, 0.3918018808204445, -0.3621248838690142, -0.09937169016057888]\n",
      "Layer: Layer 2, Input: [-0.8003729310784456, 0.3918018808204445, -0.3621248838690142, -0.09937169016057888], Output: [-1.5383695258966044]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8676609098046293, 0.9545588095401669, -0.7791750190824864, -0.8936719967816875]\n",
      "Layer: Layer 1, Input: [0.8676609098046293, 0.9545588095401669, -0.7791750190824864, -0.8936719967816875], Output: [-0.9863438141850632, -0.624956767236402, -0.8225915411836451, -0.6212935970565133]\n",
      "Layer: Layer 2, Input: [-0.9863438141850632, -0.624956767236402, -0.8225915411836451, -0.6212935970565133], Output: [0.7570214534796444]\n",
      "Epoch 128/500, Loss: 0.5954547106759074, Accuracy: -1.270270337203359\n",
      "Power operation: base = -0.06457372740174794, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4243485373846512, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5383695258966044, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24297854652035555, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9874936196425727, 0.960974615163591, -0.9712505757222881, -0.9960094093845312]\n",
      "Layer: Layer 1, Input: [0.9874936196425727, 0.960974615163591, -0.9712505757222881, -0.9960094093845312], Output: [-0.9913779320069137, -0.7038834026408409, -0.875009946251278, -0.6726604211539999]\n",
      "Layer: Layer 2, Input: [-0.9913779320069137, -0.7038834026408409, -0.875009946251278, -0.6726604211539999], Output: [0.9379448676316535]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979001985861483, 0.9339463213011296, 0.058392181524157837, -0.9055178873590115]\n",
      "Layer: Layer 1, Input: [0.9979001985861483, 0.9339463213011296, 0.058392181524157837, -0.9055178873590115], Output: [-0.9864020828121327, -0.4208717997889602, -0.7508803336907758, -0.6624734484955418]\n",
      "Layer: Layer 2, Input: [-0.9864020828121327, -0.4208717997889602, -0.7508803336907758, -0.6624734484955418], Output: [0.4209537299509143]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9225877572103921, -0.22451663996925322, 0.46723182415170017, -0.8307643846134101]\n",
      "Layer: Layer 1, Input: [0.9225877572103921, -0.22451663996925322, 0.46723182415170017, -0.8307643846134101], Output: [-0.8060364566318571, 0.39894379803489416, -0.3649950427804958, -0.10459837413849558]\n",
      "Layer: Layer 2, Input: [-0.8060364566318571, 0.39894379803489416, -0.3649950427804958, -0.10459837413849558], Output: [-1.5435925175913863]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8679135383601129, 0.9552595538105756, -0.7793861736719304, -0.8942347988761833]\n",
      "Layer: Layer 1, Input: [0.8679135383601129, 0.9552595538105756, -0.7793861736719304, -0.8942347988761833], Output: [-0.9865942035729822, -0.6238813980463342, -0.8240655911084911, -0.6235315749639232]\n",
      "Layer: Layer 2, Input: [-0.9865942035729822, -0.6238813980463342, -0.8240655911084911, -0.6235315749639232], Output: [0.7581802198790499]\n",
      "Epoch 129/500, Loss: 0.5942324933384389, Accuracy: -1.2684211600315973\n",
      "Power operation: base = -0.06205513236834648, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4209537299509143, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5435925175913863, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24181978012095007, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9875220881331037, 0.9615790272494791, -0.9712826526117179, -0.9960327742918466]\n",
      "Layer: Layer 1, Input: [0.9875220881331037, 0.9615790272494791, -0.9712826526117179, -0.9960327742918466], Output: [-0.9915215730121814, -0.703588633184795, -0.8761286499450389, -0.6746301322795535]\n",
      "Layer: Layer 2, Input: [-0.9915215730121814, -0.703588633184795, -0.8761286499450389, -0.6746301322795535], Output: [0.9404873616497267]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979041306521201, 0.9349413403977943, 0.05787780092464768, -0.9059960877532908]\n",
      "Layer: Layer 1, Input: [0.9979041306521201, 0.9349413403977943, 0.05787780092464768, -0.9059960877532908], Output: [-0.9866466964088825, -0.41717133854098837, -0.7525157561658431, -0.6642360244686423]\n",
      "Layer: Layer 2, Input: [-0.9866466964088825, -0.41717133854098837, -0.7525157561658431, -0.6642360244686423], Output: [0.4175117373421795]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9227203810070366, -0.21707651731160857, 0.4668369980116413, -0.8315683393481866]\n",
      "Layer: Layer 1, Input: [0.9227203810070366, -0.21707651731160857, 0.4668369980116413, -0.8315683393481866], Output: [-0.8115088738803308, 0.4060877814764966, -0.3679732716258469, -0.10985265702551315]\n",
      "Layer: Layer 2, Input: [-0.8115088738803308, 0.4060877814764966, -0.3679732716258469, -0.10985265702551315], Output: [-1.5488557679720585]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8681619330197979, 0.955944049812011, -0.7795952632166193, -0.8947855228105798]\n",
      "Layer: Layer 1, Input: [0.8681619330197979, 0.955944049812011, -0.7795952632166193, -0.8947855228105798], Output: [-0.9868366137172137, -0.6227376399478577, -0.825559077265148, -0.6257843597938121]\n",
      "Layer: Layer 2, Input: [-0.9868366137172137, -0.6227376399478577, -0.825559077265148, -0.6257843597938121], Output: [0.7593434599910442]\n",
      "Epoch 130/500, Loss: 0.5930098759778837, Accuracy: -1.266536683673467\n",
      "Power operation: base = -0.05951263835027332, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4175117373421795, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5488557679720585, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24065654000895575, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9875500479900503, 0.9621691202045746, -0.9713143874045711, -0.996055609050973]\n",
      "Layer: Layer 1, Input: [0.9875500479900503, 0.9621691202045746, -0.9713143874045711, -0.996055609050973], Output: [-0.9916609342943198, -0.703238946801922, -0.8772608830452925, -0.6766182427797195]\n",
      "Layer: Layer 2, Input: [-0.9916609342943198, -0.703238946801922, -0.8772608830452925, -0.6766182427797195], Output: [0.9430522689821079]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979079983174929, 0.935913747360113, 0.057367894461989026, -0.9064642616123674]\n",
      "Layer: Layer 1, Input: [0.9979079983174929, 0.935913747360113, 0.057367894461989026, -0.9064642616123674], Output: [-0.9868835952795958, -0.4133634177994535, -0.7541870704954401, -0.6660128746427816]\n",
      "Layer: Layer 2, Input: [-0.9868835952795958, -0.4133634177994535, -0.7541870704954401, -0.6660128746427816], Output: [0.4140189035597941]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9228509039134623, -0.20967286159132423, 0.46644536449118457, -0.8323559727980632]\n",
      "Layer: Layer 1, Input: [0.9228509039134623, -0.20967286159132423, 0.46644536449118457, -0.8323559727980632], Output: [-0.8167961272434977, 0.4132364699447143, -0.37105977018946446, -0.11513445349915168]\n",
      "Layer: Layer 2, Input: [-0.8167961272434977, 0.4132364699447143, -0.37105977018946446, -0.11513445349915168], Output: [-1.5541527803645543]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8684061849601349, 0.9566126428418719, -0.7798022894133086, -0.8953245016491761]\n",
      "Layer: Layer 1, Input: [0.8684061849601349, 0.9566126428418719, -0.7798022894133086, -0.8953245016491761], Output: [-0.9870713592003977, -0.6215232999063268, -0.8270718614721366, -0.6280522268250713]\n",
      "Layer: Layer 2, Input: [-0.9870713592003977, -0.6215232999063268, -0.8270718614721366, -0.6280522268250713], Output: [0.7605090197498345]\n",
      "Epoch 131/500, Loss: 0.5917834343248699, Accuracy: -1.2646103951924061\n",
      "Power operation: base = -0.05694773101789208, power = 2, grad = 0.25\n",
      "Power operation: base = 1.414018903559794, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5541527803645543, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23949098025016546, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9875775114004477, 0.9627452178750151, -0.971345781728658, -0.996077929515334]\n",
      "Layer: Layer 1, Input: [0.9875775114004477, 0.9627452178750151, -0.971345781728658, -0.996077929515334], Output: [-0.9917961730903843, -0.7028328264748666, -0.8784064223915159, -0.6786247278872605]\n",
      "Layer: Layer 2, Input: [-0.9917961730903843, -0.7028328264748666, -0.8784064223915159, -0.6786247278872605], Output: [0.9456381975665686]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979118029007255, 0.9368640004833089, 0.056862476498864716, -0.9069226754921397]\n",
      "Layer: Layer 1, Input: [0.9979118029007255, 0.9368640004833089, 0.056862476498864716, -0.9069226754921397], Output: [-0.987113078635334, -0.4094445307023311, -0.755894229060664, -0.6678043878769057]\n",
      "Layer: Layer 2, Input: [-0.987113078635334, -0.4094445307023311, -0.755894229060664, -0.6678043878769057], Output: [0.4104715362402125]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9229793662406096, -0.20230779661620552, 0.46605694297106504, -0.8331276980778186]\n",
      "Layer: Layer 1, Input: [0.9229793662406096, -0.20230779661620552, 0.46605694297106504, -0.8331276980778186], Output: [-0.8219040508462341, 0.42039245239954864, -0.3742545908659803, -0.12044366629397377]\n",
      "Layer: Layer 2, Input: [-0.8219040508462341, 0.42039245239954864, -0.3742545908659803, -0.12044366629397377], Output: [-1.559477108270092]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8686463828560637, 0.9572656739644227, -0.7800072549015014, -0.8958520568343041]\n",
      "Layer: Layer 1, Input: [0.8686463828560637, 0.9572656739644227, -0.7800072549015014, -0.8958520568343041], Output: [-0.9872987401429147, -0.6202361594439448, -0.8286037626764473, -0.6303354377093219]\n",
      "Layer: Layer 2, Input: [-0.9872987401429147, -0.6202361594439448, -0.8286037626764473, -0.6303354377093219], Output: [0.7616747748277732]\n",
      "Epoch 132/500, Loss: 0.5905496769348233, Accuracy: -1.2626356721159628\n",
      "Power operation: base = -0.05436180243343136, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4104715362402125, power = 2, grad = 0.25\n",
      "Power operation: base = -0.559477108270092, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23832522517222676, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9876044901985128, 0.9633076388663279, -0.971376837324409, -0.9960997509432786]\n",
      "Layer: Layer 1, Input: [0.9876044901985128, 0.9633076388663279, -0.971376837324409, -0.9960997509432786], Output: [-0.9919274399670706, -0.7023687532848188, -0.8795650167737142, -0.6806495578265075]\n",
      "Layer: Layer 2, Input: [-0.9919274399670706, -0.7023687532848188, -0.8795650167737142, -0.6806495578265075], Output: [0.9482438486747431]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979155456853263, 0.9377925540163413, 0.05636155876446504, -0.9073715870284765]\n",
      "Layer: Layer 1, Input: [0.9979155456853263, 0.9377925540163413, 0.05636155876446504, -0.9073715870284765], Output: [-0.9873354322925052, -0.40541112652975586, -0.7576371179491845, -0.6696109377298303]\n",
      "Layer: Layer 2, Input: [-0.9873354322925052, -0.40541112652975586, -0.7576371179491845, -0.6696109377298303], Output: [0.4068659101846519]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.923105807274886, -0.1949833777546069, 0.4656717506945924, -0.833883915181625]\n",
      "Layer: Layer 1, Input: [0.923105807274886, -0.1949833777546069, 0.4656717506945924, -0.833883915181625], Output: [-0.8268383645453428, 0.4275582498032248, -0.37755763512721807, -0.12578018738875255]\n",
      "Layer: Layer 2, Input: [-0.8268383645453428, 0.4275582498032248, -0.37755763512721807, -0.12578018738875255], Output: [-1.5648223457452242]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8688826130013769, 0.9579034799826164, -0.7802101632577543, -0.8963684987639687]\n",
      "Layer: Layer 1, Input: [0.8688826130013769, 0.9579034799826164, -0.7802101632577543, -0.8963684987639687], Output: [-0.9875190429878469, -0.6188739772476548, -0.8301545560007385, -0.6326342400387573]\n",
      "Layer: Layer 2, Input: [-0.9875190429878469, -0.6188739772476548, -0.8301545560007385, -0.6326342400387573], Output: [0.7628386312582349]\n",
      "Epoch 133/500, Loss: 0.5893050463790743, Accuracy: -1.2606057759968983\n",
      "Power operation: base = -0.051756151325256905, power = 2, grad = 0.25\n",
      "Power operation: base = 1.406865910184652, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5648223457452242, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23716136874176508, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9876309958810404, 0.9638566965820717, -0.971407556042794, -0.9961210880278146]\n",
      "Layer: Layer 1, Input: [0.9876309958810404, 0.9638566965820717, -0.971407556042794, -0.9961210880278146], Output: [-0.9920548791516981, -0.7018452085905615, -0.8807363863030666, -0.6826926970746526]\n",
      "Layer: Layer 2, Input: [-0.9920548791516981, -0.7018452085905615, -0.8807363863030666, -0.6826926970746526], Output: [0.950868016857354]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997919227921467, 0.9386998579753367, 0.055865150383881956, -0.9078112453557569]\n",
      "Layer: Layer 1, Input: [0.997919227921467, 0.9386998579753367, 0.055865150383881956, -0.9078112453557569], Output: [-0.9875509293665798, -0.40125961758369777, -0.7594155549942019, -0.6714328817669968]\n",
      "Layer: Layer 2, Input: [-0.9875509293665798, -0.40125961758369777, -0.7594155549942019, -0.6714328817669968], Output: [0.4031982718785292]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9232302653269784, -0.18770158929737246, 0.465289802786327, -0.8346250115830928]\n",
      "Layer: Layer 1, Input: [0.9232302653269784, -0.18770158929737246, 0.465289802786327, -0.8346250115830928], Output: [-0.8316046703147904, 0.4347362968060775, -0.3809686498151693, -0.13114389875441645]\n",
      "Layer: Layer 2, Input: [-0.8316046703147904, 0.4347362968060775, -0.3809686498151693, -0.13114389875441645], Output: [-1.5701821174085824]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8691149594153362, 0.9585263933826716, -0.7804110189803324, -0.8968741273157836]\n",
      "Layer: Layer 1, Input: [0.8691149594153362, 0.9585263933826716, -0.7804110189803324, -0.8968741273157836], Output: [-0.9877325412287514, -0.6174344923179481, -0.8317239718285315, -0.6349488667729668]\n",
      "Layer: Layer 2, Input: [-0.9877325412287514, -0.6174344923179481, -0.8317239718285315, -0.6349488667729668], Output: [0.7639985264096008]\n",
      "Epoch 134/500, Loss: 0.5880459211299486, Accuracy: -1.2585138460201568\n",
      "Power operation: base = -0.049131983142645996, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4031982718785292, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5701821174085824, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23600147359039925, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987657039621315, 0.964392699238388, -0.9714379398419823, -0.9961419549238452]\n",
      "Layer: Layer 1, Input: [0.987657039621315, 0.964392699238388, -0.9714379398419823, -0.9961419549238452], Output: [-0.9921786288398796, -0.7012606766728333, -0.8819202218261954, -0.6847541035129379]\n",
      "Layer: Layer 2, Input: [-0.9921786288398796, -0.7012606766728333, -0.8819202218261954, -0.6847541035129379], Output: [0.9535095900953108]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979228508273933, 0.9395863579295048, 0.05537325793066945, -0.9082418914850727]\n",
      "Layer: Layer 1, Input: [0.9979228508273933, 0.9395863579295048, 0.05537325793066945, -0.9082418914850727], Output: [-0.9877598309171439, -0.396986387068075, -0.761229287871606, -0.6732705607480577]\n",
      "Layer: Layer 2, Input: [-0.9877598309171439, -0.396986387068075, -0.761229287871606, -0.6732705607480577], Output: [0.39946484507465563]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9233527777738094, -0.1804643423510872, 0.46491111228917387, -0.8353513627732215]\n",
      "Layer: Layer 1, Input: [0.9233527777738094, -0.1804643423510872, 0.46491111228917387, -0.8353513627732215], Output: [-0.83620844901399, 0.44192892330802325, -0.3844872232831223, -0.13653467265461253]\n",
      "Layer: Layer 2, Input: [-0.83620844901399, 0.44192892330802325, -0.3844872232831223, -0.13653467265461253], Output: [-1.5755500681125898]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8693435039367959, 0.9591347422567013, -0.7806098274650117, -0.8973692323225982]\n",
      "Layer: Layer 1, Input: [0.8693435039367959, 0.9591347422567013, -0.7806098274650117, -0.8973692323225982], Output: [-0.9879394960855487, -0.6159154277038195, -0.8333116949374032, -0.6372795355224024]\n",
      "Layer: Layer 2, Input: [-0.9879394960855487, -0.6159154277038195, -0.8333116949374032, -0.6372795355224024], Output: [0.765152430329564]\n",
      "Epoch 135/500, Loss: 0.5867686181743632, Accuracy: -1.2563528927623708\n",
      "Power operation: base = -0.04649040990468922, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3994648450746556, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5755500681125898, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23484756967043596, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9876826322816706, 0.9649159498590552, -0.9714679907828573, -0.9961623652731535]\n",
      "Layer: Layer 1, Input: [0.9876826322816706, 0.9649159498590552, -0.9714679907828573, -0.9961623652731535], Output: [-0.992298821482046, -0.7006136478745435, -0.883116184389544, -0.6868337274632508]\n",
      "Layer: Layer 2, Input: [-0.992298821482046, -0.7006136478745435, -0.883116184389544, -0.6868337274632508], Output: [0.9561675501423768]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.99792641559065, 0.9404524947664661, 0.054885885500576555, -0.90866375864637]\n",
      "Layer: Layer 1, Input: [0.99792641559065, 0.9404524947664661, 0.054885885500576555, -0.90866375864637], Output: [-0.9879623865487933, -0.3925877980428284, -0.7630779922719332, -0.6751242976931203]\n",
      "Layer: Layer 2, Input: [-0.9879623865487933, -0.3925877980428284, -0.7630779922719332, -0.6751242976931203], Output: [0.3956618375146861]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9234733810943317, -0.1732734732450674, 0.4645356902183669, -0.8360633327430268]\n",
      "Layer: Layer 1, Input: [0.9234733810943317, -0.1732734732450674, 0.4645356902183669, -0.8360633327430268], Output: [-0.8406550575567893, 0.4491383359330361, -0.3881127814130592, -0.1419523714934118]\n",
      "Layer: Layer 2, Input: [-0.8406550575567893, 0.4491383359330361, -0.3881127814130592, -0.1419523714934118], Output: [-1.5809198523356143]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8695683263070269, 0.9597288502083086, -0.7808065949728461, -0.8978540940047948]\n",
      "Layer: Layer 1, Input: [0.8695683263070269, 0.9597288502083086, -0.7808065949728461, -0.8978540940047948], Output: [-0.9881401571332911, -0.6143144948701407, -0.8349173636910341, -0.6396264476860266]\n",
      "Layer: Layer 2, Input: [-0.9881401571332911, -0.6143144948701407, -0.8349173636910341, -0.6396264476860266], Output: [0.7662983474791805]\n",
      "Epoch 136/500, Loss: 0.5854693963959963, Accuracy: -1.2541157922287431\n",
      "Power operation: base = -0.043832449857623246, power = 2, grad = 0.25\n",
      "Power operation: base = 1.395661837514686, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5809198523356143, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23370165252081954, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9877077844248225, 0.9654267462552775, -0.9714977110235075, -0.9961823322273575]\n",
      "Layer: Layer 1, Input: [0.9877077844248225, 0.9654267462552775, -0.9714977110235075, -0.9961823322273575], Output: [-0.9924155840507994, -0.6999026222675947, -0.8843239047610196, -0.6889315106059346]\n",
      "Layer: Layer 2, Input: [-0.9924155840507994, -0.6999026222675947, -0.8843239047610196, -0.6889315106059346], Output: [0.9588409730444525]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979299233691422, 0.9412987044433699, 0.05440303480443198, -0.9090770725984471]\n",
      "Layer: Layer 1, Input: [0.9979299233691422, 0.9412987044433699, 0.05440303480443198, -0.9090770725984471], Output: [-0.9881588349719184, -0.3880602035246998, -0.7649612701652142, -0.6769943968254899]\n",
      "Layer: Layer 2, Input: [-0.9881588349719184, -0.3880602035246998, -0.7649612701652142, -0.6769943968254899], Output: [0.39178544886277455]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9235921108998258, -0.1661307424302782, 0.4641635456307829, -0.8367612744170925]\n",
      "Layer: Layer 1, Input: [0.9235921108998258, -0.1661307424302782, 0.4641635456307829, -0.8367612744170925], Output: [-0.8449497264923979, 0.45636659946155966, -0.39184458354366336, -0.14739684720734]\n",
      "Layer: Layer 2, Input: [-0.8449497264923979, 0.45636659946155966, -0.39184458354366336, -0.14739684720734], Output: [-1.586285123368255]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8697895042423661, 0.9603090362456762, -0.7810013285907287, -0.8983289833638199]\n",
      "Layer: Layer 1, Input: [0.8697895042423661, 0.9603090362456762, -0.7810013285907287, -0.8983289833638199], Output: [-0.9883347628881176, -0.6126293987442089, -0.8365405693018486, -0.6419897874407257]\n",
      "Layer: Layer 2, Input: [-0.9883347628881176, -0.6126293987442089, -0.8365405693018486, -0.6419897874407257], Output: [0.7674343188760631]\n",
      "Epoch 137/500, Loss: 0.5841444607714132, Accuracy: -1.251795280310514\n",
      "Power operation: base = -0.04115902695554752, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3917854488627746, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5862851233682549, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23256568112393694, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9877325063240856, 0.9659253809940621, -0.9715271028128081, -0.9962018684690348]\n",
      "Layer: Layer 1, Input: [0.9877325063240856, 0.9659253809940621, -0.9715271028128081, -0.9962018684690348], Output: [-0.9925290382908609, -0.699126113876751, -0.8855429830167291, -0.691047384775115]\n",
      "Layer: Layer 2, Input: [-0.9925290382908609, -0.699126113876751, -0.8855429830167291, -0.691047384775115], Output: [0.9615290298195895]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979333752920497, 0.9421254177296333, 0.05392470527814036, -0.9094820519104199]\n",
      "Layer: Layer 1, Input: [0.9979333752920497, 0.9421254177296333, 0.05392470527814036, -0.9094820519104199], Output: [-0.9883494045270277, -0.3833999578053525, -0.7668786481783538, -0.6788811423889592]\n",
      "Layer: Layer 2, Input: [-0.9883494045270277, -0.3833999578053525, -0.7668786481783538, -0.6788811423889592], Output: [0.3878318799235352]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9237090019593301, -0.15903783384467987, 0.4637946857079989, -0.8374455300437884]\n",
      "Layer: Layer 1, Input: [0.9237090019593301, -0.15903783384467987, 0.4637946857079989, -0.8374455300437884], Output: [-0.8490975580035762, 0.4636156182748035, -0.3956817183496956, -0.15286794020163716]\n",
      "Layer: Layer 2, Input: [-0.8490975580035762, 0.4636156182748035, -0.3956817183496956, -0.15286794020163716], Output: [-1.5916395223865065]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.870007113497759, 0.9608756146662684, -0.7811940361855666, -0.8987941625411475]\n",
      "Layer: Layer 1, Input: [0.870007113497759, 0.9608756146662684, -0.7811940361855666, -0.8987941625411475], Output: [-0.9885235413542621, -0.6108578434880365, -0.8381808551769001, -0.6443697205803397]\n",
      "Layer: Layer 2, Input: [-0.9885235413542621, -0.6108578434880365, -0.8381808551769001, -0.6443697205803397], Output: [0.7685584246657964]\n",
      "Epoch 138/500, Loss: 0.5827899674304068, Accuracy: -1.249383947824656\n",
      "Power operation: base = -0.03847097018041046, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3878318799235352, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5916395223865065, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23144157533420362, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9877568079725895, 0.9664121413586718, -0.9715561684832101, -0.9962209862312058]\n",
      "Layer: Layer 1, Input: [0.9877568079725895, 0.9664121413586718, -0.9715561684832101, -0.9962209862312058], Output: [-0.9926393009532102, -0.6982826554900148, -0.8867729882013083, -0.693181270628509]\n",
      "Layer: Layer 2, Input: [-0.9926393009532102, -0.6982826554900148, -0.8867729882013083, -0.693181270628509], Output: [0.9642309872816757]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997936772460611, 0.9429330599465666, 0.05345089420774735, -0.9098789082179471]\n",
      "Layer: Layer 1, Input: [0.997936772460611, 0.9429330599465666, 0.05345089420774735, -0.9098789082179471], Output: [-0.9885343136758867, -0.37860342905371036, -0.7688295761062233, -0.6807847973380846]\n",
      "Layer: Layer 2, Input: [-0.9885343136758867, -0.37860342905371036, -0.7688295761062233, -0.6807847973380846], Output: [0.38379734321278347]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.923824088220796, -0.1519963547163889, 0.4634291158515082, -0.8381164315474254]\n",
      "Layer: Layer 1, Input: [0.923824088220796, -0.1519963547163889, 0.4634291158515082, -0.8381164315474254], Output: [-0.8531035243220458, 0.4708871178754235, -0.3996230997200308, -0.15836547783341137]\n",
      "Layer: Layer 2, Input: [-0.8531035243220458, 0.4708871178754235, -0.3996230997200308, -0.15836547783341137], Output: [-1.5969766675243944]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8702212279221919, 0.9614288949368726, -0.781384726352889, -0.8992498851465054]\n",
      "Layer: Layer 1, Input: [0.8702212279221919, 0.9614288949368726, -0.781384726352889, -0.8992498851465054], Output: [-0.9887067105355993, -0.608997539041893, -0.8398377163605472, -0.6467663932026569]\n",
      "Layer: Layer 2, Input: [-0.9887067105355993, -0.608997539041893, -0.8398377163605472, -0.6467663932026569], Output: [0.7696687871396968]\n",
      "Epoch 139/500, Loss: 0.5814020296349579, Accuracy: -1.2468742363158052\n",
      "Power operation: base = -0.03576901271832433, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3837973432127835, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5969766675243944, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23033121286030322, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9877806990915905, 0.9668873093042831, -0.9715849104428487, -0.9962396973153418]\n",
      "Layer: Layer 1, Input: [0.9877806990915905, 0.9668873093042831, -0.9715849104428487, -0.9962396973153418], Output: [-0.9927464840148573, -0.6973708040831978, -0.8880134580709892, -0.695333076189586]\n",
      "Layer: Layer 2, Input: [-0.9927464840148573, -0.6973708040831978, -0.8880134580709892, -0.695333076189586], Output: [0.9669462089891403]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979401159487938, 0.9437220507086093, 0.05298159686755805, -0.9102678464572321]\n",
      "Layer: Layer 1, Input: [0.9979401159487938, 0.9437220507086093, 0.05298159686755805, -0.9102678464572321], Output: [-0.988713771462416, -0.37366701326371615, -0.7708134255791862, -0.6827056019005229]\n",
      "Layer: Layer 2, Input: [-0.988713771462416, -0.37366701326371615, -0.7708134255791862, -0.6827056019005229], Output: [0.3796780749438504]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9239374028285238, -0.1450078357734239, 0.463066839788512, -0.8387743008471727]\n",
      "Layer: Layer 1, Input: [0.9239374028285238, -0.1450078357734239, 0.463066839788512, -0.8387743008471727], Output: [-0.8569724665563246, 0.47818262656109195, -0.4036674626882432, -0.1638892724472603]\n",
      "Layer: Layer 2, Input: [-0.8569724665563246, 0.47818262656109195, -0.4036674626882432, -0.1638892724472603], Output: [-1.6022901430790375]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8704319195069552, 0.9619691815723137, -0.7815734083606857, -0.899696396558874]\n",
      "Layer: Layer 1, Input: [0.8704319195069552, 0.9619691815723137, -0.7815734083606857, -0.899696396558874], Output: [-0.9888844789148618, -0.607046208482509, -0.8415105990883426, -0.6491799302434649]\n",
      "Layer: Layer 2, Input: [-0.9888844789148618, -0.607046208482509, -0.8415105990883426, -0.6491799302434649], Output: [0.7707635742154322]\n",
      "Epoch 140/500, Loss: 0.5799767247344024, Accuracy: -1.2442584348183154\n",
      "Power operation: base = -0.0330537910108597, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3796780749438504, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6022901430790375, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22923642578456782, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9878041891379739, 0.9673511614116346, -0.9716133311670825, -0.9962580131080508]\n",
      "Layer: Layer 1, Input: [0.9878041891379739, 0.9673511614116346, -0.9716133311670825, -0.9962580131080508], Output: [-0.9928506948855425, -0.6963891468836682, -0.8892638989291491, -0.697502695261058]\n",
      "Layer: Layer 2, Input: [-0.9928506948855425, -0.6963891468836682, -0.8892638989291491, -0.697502695261058], Output: [0.9696741562979714]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979434068038678, 0.9444928036703619, 0.05251680666931007, -0.9106490650795529]\n",
      "Layer: Layer 1, Input: [0.9979434068038678, 0.9444928036703619, 0.05251680666931007, -0.9106490650795529], Output: [-0.9888879779459968, -0.36858714960084327, -0.7728294889112455, -0.6846437720113684]\n",
      "Layer: Layer 2, Input: [-0.9888879779459968, -0.36858714960084327, -0.7728294889112455, -0.6846437720113684], Output: [0.3754703484840589]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9240489781374075, -0.13807373182671437, 0.46270785968672334, -0.8394194501471514]\n",
      "Layer: Layer 1, Input: [0.9240489781374075, -0.13807373182671437, 0.46270785968672334, -0.8394194501471514], Output: [-0.8607090939230423, 0.48550345734087524, -0.4078133594761977, -0.16943911897194758]\n",
      "Layer: Layer 2, Input: [-0.8607090939230423, 0.48550345734087524, -0.4078133594761977, -0.16943911897194758], Output: [-1.6075734890019153]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8706392584276164, 0.9624967740157988, -0.7817600920892653, -0.9001339342034584]\n",
      "Layer: Layer 1, Input: [0.8706392584276164, 0.9624967740157988, -0.7817600920892653, -0.9001339342034584], Output: [-0.9890570459033529, -0.6050015962360388, -0.8431989004673791, -0.6516104338577645]\n",
      "Layer: Layer 2, Input: [-0.9890570459033529, -0.6050015962360388, -0.8431989004673791, -0.6516104338577645], Output: [0.7718410033944711]\n",
      "Epoch 141/500, Loss: 0.5785101021562751, Accuracy: -1.2415286777935317\n",
      "Power operation: base = -0.03032584370202862, power = 2, grad = 0.25\n",
      "Power operation: base = 1.375470348484059, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6075734890019153, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22815899660552885, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987827287311037, 0.9678039688411199, -0.9716414331895715, -0.9962759445965822]\n",
      "Layer: Layer 1, Input: [0.987827287311037, 0.9678039688411199, -0.9716414331895715, -0.9962759445965822], Output: [-0.9929520366025277, -0.6953363080944621, -0.8905237855646276, -0.699690005710053]\n",
      "Layer: Layer 2, Input: [-0.9929520366025277, -0.6953363080944621, -0.8905237855646276, -0.699690005710053], Output: [0.9724143894956891]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979466460468911, 0.9452457262830934, 0.05205651532044795, -0.9110227562488338]\n",
      "Layer: Layer 1, Input: [0.9979466460468911, 0.9452457262830934, 0.05205651532044795, -0.9110227562488338], Output: [-0.9890571246095665, -0.3633603371903142, -0.77487697815438, -0.6865994976205595]\n",
      "Layer: Layer 2, Input: [-0.9890571246095665, -0.3633603371903142, -0.77487697815438, -0.6865994976205595], Output: [0.3711704893250394]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9241588457244754, -0.13119542269139334, 0.4623521762766395, -0.8400521822017354]\n",
      "Layer: Layer 1, Input: [0.9241588457244754, -0.13119542269139334, 0.4623521762766395, -0.8400521822017354], Output: [-0.8643179833692414, 0.49285069019896044, -0.41205915571754076, -0.1750147920899904]\n",
      "Layer: Layer 2, Input: [-0.8643179833692414, 0.49285069019896044, -0.41205915571754076, -0.1750147920899904], Output: [-1.612820190850957]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.870843313080526, 0.9630119665234899, -0.7819447879678981, -0.9005627278075541]\n",
      "Layer: Layer 1, Input: [0.870843313080526, 0.9630119665234899, -0.7819447879678981, -0.9005627278075541], Output: [-0.9892246022636978, -0.602861477181143, -0.8449019682990707, -0.6540579816495511]\n",
      "Layer: Layer 2, Input: [-0.9892246022636978, -0.602861477181143, -0.8449019682990707, -0.6540579816495511], Output: [0.7728993462067084]\n",
      "Epoch 142/500, Loss: 0.5769981924926767, Accuracy: -1.2386769444735988\n",
      "Power operation: base = -0.027585610504310853, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3711704893250394, power = 2, grad = 0.25\n",
      "Power operation: base = -0.612820190850957, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22710065379329158, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9878500025586319, 0.9682459972894742, -0.9716692190929986, -0.9962935023832787]\n",
      "Layer: Layer 1, Input: [0.9878500025586319, 0.9682459972894742, -0.9716692190929986, -0.9962935023832787], Output: [-0.9930506080145353, -0.6942109562949564, -0.8917925613035478, -0.701894867626934]\n",
      "Layer: Layer 2, Input: [-0.9930506080145353, -0.6942109562949564, -0.8917925613035478, -0.701894867626934], Output: [0.9751665689896711]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979498346731265, 0.945981219563914, 0.05160071298957291, -0.9113891060245458]\n",
      "Layer: Layer 1, Input: [0.9979498346731265, 0.945981219563914, 0.05160071298957291, -0.9113891060245458], Output: [-0.9892213947446503, -0.35798315337681796, -0.7769550243858615, -0.6885729408758161]\n",
      "Layer: Layer 2, Input: [-0.9892213947446503, -0.35798315337681796, -0.7769550243858615, -0.6885729408758161], Output: [0.3667748915963269]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.924267036398191, -0.12437421441019082, 0.46199978897976457, -0.840672790559742]\n",
      "Layer: Layer 1, Input: [0.924267036398191, -0.12437421441019082, 0.46199978897976457, -0.840672790559742], Output: [-0.8678035795702214, 0.5002251548259196, -0.4164030269341989, -0.18061604299547268]\n",
      "Layer: Layer 2, Input: [-0.8678035795702214, 0.5002251548259196, -0.4164030269341989, -0.18061604299547268], Output: [-1.6180236703987052]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8710441501146259, 0.9635150480555643, -0.7821275069089846, -0.9009829996379723]\n",
      "Layer: Layer 1, Input: [0.8710441501146259, 0.9635150480555643, -0.7821275069089846, -0.9009829996379723], Output: [-0.9893873305079256, -0.6006236666712126, -0.8466191010609805, -0.6565226247531748]\n",
      "Layer: Layer 2, Input: [-0.9893873305079256, -0.6006236666712126, -0.8466191010609805, -0.6565226247531748], Output: [0.7739369331478128]\n",
      "Epoch 143/500, Loss: 0.5754370177403999, Accuracy: -1.2356950598575485\n",
      "Power operation: base = -0.024833431010328866, power = 2, grad = 0.25\n",
      "Power operation: base = 1.366774891596327, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6180236703987052, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22606306685218724, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9878723435827461, 0.9686775069509119, -0.9716966914995325, -0.99631069669909]\n",
      "Layer: Layer 1, Input: [0.9878723435827461, 0.9686775069509119, -0.9716966914995325, -0.99631069669909], Output: [-0.993146503955781, -0.6930118125279499, -0.8930696381857244, -0.7041171213616226]\n",
      "Layer: Layer 2, Input: [-0.993146503955781, -0.6930118125279499, -0.8930696381857244, -0.7041171213616226], Output: [0.9779304565193505]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979529736523984, 0.9466996778803513, 0.05114938847719661, -0.9117482945320273]\n",
      "Layer: Layer 1, Input: [0.9979529736523984, 0.9466996778803513, 0.05114938847719661, -0.9117482945320273], Output: [-0.9893809638152619, -0.3524522734693278, -0.7790626772563876, -0.6905642341852636]\n",
      "Layer: Layer 2, Input: [-0.9893809638152619, -0.3524522734693278, -0.7790626772563876, -0.6905642341852636], Output: [0.3622800361341043]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9243735802059434, -0.1176113407419224, 0.4616506960412939, -0.8412815597908709]\n",
      "Layer: Layer 1, Input: [0.9243735802059434, -0.1176113407419224, 0.4616506960412939, -0.8412815597908709], Output: [-0.8711701952850849, 0.507627413954073, -0.42084295534484056, -0.18624259575918015]\n",
      "Layer: Layer 2, Input: [-0.8711701952850849, 0.507627413954073, -0.42084295534484056, -0.18624259575918015], Output: [-1.6231772771117317]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8712418344592825, 0.9640063021757032, -0.7823082602404762, -0.9013949647224585]\n",
      "Layer: Layer 1, Input: [0.8712418344592825, 0.9640063021757032, -0.7823082602404762, -0.9013949647224585], Output: [-0.9895454052729539, -0.5982860314966181, -0.8483495480647816, -0.6590043857711954]\n",
      "Layer: Layer 2, Input: [-0.9895454052729539, -0.5982860314966181, -0.8483495480647816, -0.6590043857711954], Output: [0.7749521591085817]\n",
      "Epoch 144/500, Loss: 0.5738226027493154, Accuracy: -1.232574697617904\n",
      "Power operation: base = -0.02206954348064949, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3622800361341043, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6231772771117317, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22504784089141827, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9878943188445926, 0.969098752484305, -0.9717238530611336, -0.9963275374162539]\n",
      "Layer: Layer 1, Input: [0.9878943188445926, 0.969098752484305, -0.9717238530611336, -0.9963275374162539], Output: [-0.9932398154109596, -0.6917376590751853, -0.8943543972769638, -0.7063565854434528]\n",
      "Layer: Layer 2, Input: [-0.9932398154109596, -0.6917376590751853, -0.8943543972769638, -0.7063565854434528], Output: [0.9807059163571861]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979560639294018, 0.9474014887526468, 0.050702529389961004, -0.9121004961221281]\n",
      "Layer: Layer 1, Input: [0.9979560639294018, 0.9474014887526468, 0.050702529389961004, -0.9121004961221281], Output: [-0.9895359998024196, -0.3467644919651384, -0.7811989048276504, -0.6925734781658666]\n",
      "Layer: Layer 2, Input: [-0.9895359998024196, -0.3467644919651384, -0.7811989048276504, -0.6925734781658666], Output: [0.3576825100955414]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9244785064401337, -0.11090796487761914, 0.46130489466579994, -0.8418787656974622]\n",
      "Layer: Layer 1, Input: [0.9244785064401337, -0.11090796487761914, 0.46130489466579994, -0.8418787656974622], Output: [-0.8744220120502778, 0.5150577474502362, -0.4253767270896064, -0.19189414332423207]\n",
      "Layer: Layer 2, Input: [-0.8744220120502778, 0.5150577474502362, -0.4253767270896064, -0.19189414332423207], Output: [-1.6282742807351709]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8714364293488197, 0.9644860069606529, -0.7824870596372514, -0.9017988310573222]\n",
      "Layer: Layer 1, Input: [0.8714364293488197, 0.9644860069606529, -0.7824870596372514, -0.9017988310573222], Output: [-0.989698993675348, -0.5958465017977852, -0.8500925098077493, -0.6615032565759021]\n",
      "Layer: Layer 2, Input: [-0.989698993675348, -0.5958465017977852, -0.8500925098077493, -0.6615032565759021], Output: [0.7759434892879513]\n",
      "Epoch 145/500, Loss: 0.5721509879271751, Accuracy: -1.229307385185575\n",
      "Power operation: base = -0.01929408364281393, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3576825100955414, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6282742807351709, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22405651071204868, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9879159365692745, 0.9695099829877496, -0.9717507064497993, -0.9963440340602461]\n",
      "Layer: Layer 1, Input: [0.9879159365692745, 0.9695099829877496, -0.9717507064497993, -0.9963440340602461], Output: [-0.9933306296719615, -0.6903873489139621, -0.8956461891286109, -0.7086130543930182]\n",
      "Layer: Layer 2, Input: [-0.9933306296719615, -0.6903873489139621, -0.8956461891286109, -0.7086130543930182], Output: [0.9834929164580934]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979591064239742, 0.9480870326756935, 0.0502601223165309, -0.9124458795219215]\n",
      "Layer: Layer 1, Input: [0.9979591064239742, 0.9480870326756935, 0.0502601223165309, -0.9124458795219215], Output: [-0.9896866635308608, -0.34091674522434373, -0.78336259372844, -0.6946007394860734]\n",
      "Layer: Layer 2, Input: [-0.9896866635308608, -0.34091674522434373, -0.78336259372844, -0.6946007394860734], Output: [0.3529790280838849]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9245818436432358, -0.10426518134672765, 0.460962381154489, -0.8424646755143775]\n",
      "Layer: Layer 1, Input: [0.9245818436432358, -0.10426518134672765, 0.460962381154489, -0.8424646755143775], Output: [-0.8775630811900217, 0.5225161373357764, -0.43000192996011133, -0.19757034315982372]\n",
      "Layer: Layer 2, Input: [-0.8775630811900217, 0.5225161373357764, -0.43000192996011133, -0.19757034315982372], Output: [-1.6333078652330666]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8716279963443851, 0.9649544349212372, -0.7826639170521248, -0.9021947998033116]\n",
      "Layer: Layer 1, Input: [0.8716279963443851, 0.9649544349212372, -0.7826639170521248, -0.9021947998033116], Output: [-0.9898482556470518, -0.5933030839276782, -0.851847138535257, -0.6640191959842136]\n",
      "Layer: Layer 2, Input: [-0.9898482556470518, -0.5933030839276782, -0.851847138535257, -0.6640191959842136], Output: [0.7769094655719795]\n",
      "Epoch 146/500, Loss: 0.5704182432398294, Accuracy: -1.2258845112868788\n",
      "Power operation: base = -0.016507083541906553, power = 2, grad = 0.25\n",
      "Power operation: base = 1.352979028083885, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6333078652330666, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22309053442802051, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9879372047500908, 0.9699114419816359, -0.9717772543478345, -0.9963601958210809]\n",
      "Layer: Layer 1, Input: [0.9879372047500908, 0.9699114419816359, -0.9717772543478345, -0.9963601958210809], Output: [-0.9934190304870196, -0.6889598158364493, -0.8969443343955791, -0.7108862964371881]\n",
      "Layer: Layer 2, Input: [-0.9934190304870196, -0.6889598158364493, -0.8969443343955791, -0.7108862964371881], Output: [0.9862915295110888]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979621020313415, 0.9487566829621782, 0.049822153003409766, -0.9127846079780713]\n",
      "Layer: Layer 1, Input: [0.9979621020313415, 0.9487566829621782, 0.049822153003409766, -0.9127846079780713], Output: [-0.9898331089793859, -0.33490613553950976, -0.7855525496584989, -0.6966460486136288]\n",
      "Layer: Layer 2, Input: [-0.9898331089793859, -0.33490613553950976, -0.7855525496584989, -0.6966460486136288], Output: [0.34816645472006424]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9246836196121871, -0.09768401807601217, 0.46062315104262685, -0.8430395480995678]\n",
      "Layer: Layer 1, Input: [0.9246836196121871, -0.09768401807601217, 0.46062315104262685, -0.8430395480995678], Output: [-0.8805973251215748, 0.5300022539199284, -0.4347159517275819, -0.20327081260548194]\n",
      "Layer: Layer 2, Input: [-0.8805973251215748, 0.5300022539199284, -0.4347159517275819, -0.20327081260548194], Output: [-1.6382711243494874]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8718165953537488, 0.9654118529359422, -0.7828388446471554, -0.9025830654715888]\n",
      "Layer: Layer 1, Input: [0.8718165953537488, 0.9654118529359422, -0.7828388446471554, -0.9025830654715888], Output: [-0.9899933442536311, -0.5906538742478377, -0.8536125390315942, -0.6665521273185666]\n",
      "Layer: Layer 2, Input: [-0.9899933442536311, -0.5906538742478377, -0.8536125390315942, -0.6665521273185666], Output: [0.7778487133501959]\n",
      "Epoch 147/500, Loss: 0.5686204835335337, Accuracy: -1.2222973362082672\n",
      "Power operation: base = -0.013708470488911217, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3481664547200642, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6382711243494874, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2221512866498041, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9879581311525387, 0.970303367401138, -0.9718034994382454, -0.9963760315640513]\n",
      "Layer: Layer 1, Input: [0.9879581311525387, 0.970303367401138, -0.9718034994382454, -0.9963760315640513], Output: [-0.9935050982029335, -0.6874540852006115, -0.8982481246237718, -0.7131760511414433]\n",
      "Layer: Layer 2, Input: [-0.9935050982029335, -0.6874540852006115, -0.8982481246237718, -0.7131760511414433], Output: [0.9891019338405589]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979650516223462, 0.9494108056081659, 0.04938860652896231, -0.9131168393943143]\n",
      "Layer: Layer 1, Input: [0.9979650516223462, 0.9494108056081659, 0.04938860652896231, -0.9131168393943143], Output: [-0.9899754835761332, -0.3287299565153258, -0.7877674982690235, -0.6987093974823504]\n",
      "Layer: Layer 2, Input: [-0.9899754835761332, -0.3287299565153258, -0.7877674982690235, -0.6987093974823504], Output: [0.343241828563253]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9247838614024461, -0.09116543856427045, 0.46028719923576006, -0.8436036341176739]\n",
      "Layer: Layer 1, Input: [0.9247838614024461, -0.09116543856427045, 0.46028719923576006, -0.8436036341176739], Output: [-0.883528538932693, 0.5375154432470987, -0.4395159791648506, -0.20899512394340056]\n",
      "Layer: Layer 2, Input: [-0.883528538932693, 0.5375154432470987, -0.4395159791648506, -0.20899512394340056], Output: [-1.6431570590660844]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8720022846495936, 0.9658585221979753, -0.7830118547258968, -0.9029638161015126]\n",
      "Layer: Layer 1, Input: [0.8720022846495936, 0.9658585221979753, -0.7830118547258968, -0.9029638161015126], Output: [-0.9901344059964285, -0.5878970738254212, -0.8553877696559478, -0.669101935869584]\n",
      "Layer: Layer 2, Input: [-0.9901344059964285, -0.5878970738254212, -0.8553877696559478, -0.669101935869584], Output: [0.7787599487282311]\n",
      "Epoch 148/500, Loss: 0.5667538851903092, Accuracy: -1.2185370050605475\n",
      "Power operation: base = -0.010898066159441111, power = 2, grad = 0.25\n",
      "Power operation: base = 1.343241828563253, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6431570590660844, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22124005127176893, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987978723318073, 0.9706859915988455, -0.9718294443953397, -0.9963915498399786]\n",
      "Layer: Layer 1, Input: [0.987978723318073, 0.9706859915988455, -0.9718294443953397, -0.9963915498399786], Output: [-0.9935889099009498, -0.6858692852672649, -0.8995568232172287, -0.7154820269768754]\n",
      "Layer: Layer 2, Input: [-0.9935889099009498, -0.6858692852672649, -0.8995568232172287, -0.7154820269768754], Output: [0.9919244140976153]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979679560436676, 0.950049759182058, 0.048959467473974526, -0.9134427264643887]\n",
      "Layer: Layer 1, Input: [0.9979679560436676, 0.950049759182058, 0.048959467473974526, -0.9134427264643887], Output: [-0.9901139284799743, -0.3223857196395904, -0.7900060864478907, -0.7007907370947566]\n",
      "Layer: Layer 2, Input: [-0.9901139284799743, -0.3223857196395904, -0.7900060864478907, -0.7007907370947566], Output: [0.3382023872455995]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9248825953320275, -0.08471034413674887, 0.45995452014338817, -0.8441571762188109]\n",
      "Layer: Layer 1, Input: [0.9248825953320275, -0.08471034413674887, 0.45995452014338817, -0.8441571762188109], Output: [-0.8863603922084001, 0.5450547160717771, -0.4443989978595659, -0.21474279924192513]\n",
      "Layer: Layer 2, Input: [-0.8863603922084001, 0.5450547160717771, -0.4443989978595659, -0.21474279924192513], Output: [-1.6479585772382783]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8721851208868336, 0.9662946981764872, -0.7831829596672171, -0.9033372334317881]\n",
      "Layer: Layer 1, Input: [0.8721851208868336, 0.9662946981764872, -0.7831829596672171, -0.9033372334317881], Output: [-0.9902715810999103, -0.5850310039796519, -0.857171843639608, -0.6716684662797657]\n",
      "Layer: Layer 2, Input: [-0.9902715810999103, -0.5850310039796519, -0.857171843639608, -0.6716684662797657], Output: [0.7796419860814225]\n",
      "Epoch 149/500, Loss: 0.5648147041080704, Accuracy: -1.2145945643048401\n",
      "Power operation: base = -0.008075585902384663, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3382023872455995, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6479585772382783, power = 2, grad = 0.25\n",
      "Power operation: base = -0.22035801391857746, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9879989885676741, 0.9710595413580937, -0.9718550918756182, -0.9964067588950422]\n",
      "Layer: Layer 1, Input: [0.9879989885676741, 0.9710595413580937, -0.9718550918756182, -0.9964067588950422], Output: [-0.9936705395268336, -0.6842046590618254, -0.9008696665945156, -0.7178038988425954]\n",
      "Layer: Layer 2, Input: [-0.9936705395268336, -0.6842046590618254, -0.9008696665945156, -0.7178038988425954], Output: [0.9947593616749697]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.997970816118042, 0.950673894737587, 0.04853472008711415, -0.9137624168016313]\n",
      "Layer: Layer 1, Input: [0.997970816118042, 0.950673894737587, 0.04853472008711415, -0.9137624168016313], Output: [-0.990248578849108, -0.31587118189034236, -0.7922668840363218, -0.7028899750807359]\n",
      "Layer: Layer 2, Input: [-0.990248578849108, -0.31587118189034236, -0.7922668840363218, -0.7028899750807359], Output: [0.3330455936457044]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9249798469858131, -0.07831957624415933, 0.45962510780877214, -0.844700409214496]\n",
      "Layer: Layer 1, Input: [0.9249798469858131, -0.07831957624415933, 0.45962510780877214, -0.844700409214496], Output: [-0.8890964310842333, 0.5526187385848731, -0.44936179291620787, -0.22051330501905425]\n",
      "Layer: Layer 2, Input: [-0.8890964310842333, 0.5526187385848731, -0.44936179291620787, -0.22051330501905425], Output: [-1.652668495693272]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.872365159119459, 0.966720630592462, -0.7833521718612945, -0.9037034930664222]\n",
      "Layer: Layer 1, Input: [0.872365159119459, 0.966720630592462, -0.7833521718612945, -0.9037034930664222], Output: [-0.9904050037853681, -0.5820541226048915, -0.8589637306592857, -0.6742515198711588]\n",
      "Layer: Layer 2, Input: [-0.9904050037853681, -0.5820541226048915, -0.8589637306592857, -0.6742515198711588], Output: [0.7804937458786494]\n",
      "Epoch 150/500, Loss: 0.5627992949742969, Accuracy: -1.2104609817853573\n",
      "Power operation: base = -0.0052406383250303, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3330455936457044, power = 2, grad = 0.25\n",
      "Power operation: base = -0.652668495693272, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2195062541213506, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9880189340052775, 0.9714242379173895, -0.9718804445090444, -0.9964216666802551]\n",
      "Layer: Layer 1, Input: [0.9880189340052775, 0.9714242379173895, -0.9718804445090444, -0.9964216666802551], Output: [-0.9937500580156187, -0.6824595766818868, -0.9021858655427661, -0.7201413055678421]\n",
      "Layer: Layer 2, Input: [-0.9937500580156187, -0.6824595766818868, -0.9021858655427661, -0.7201413055678421], Output: [0.997607274771628]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979736326444911, 0.9512835557512546, 0.048114348443693736, -0.9140760530663614]\n",
      "Layer: Layer 1, Input: [0.9979736326444911, 0.9512835557512546, 0.048114348443693736, -0.9140760530663614], Output: [-0.9903795640978469, -0.30918437418467426, -0.794548386001698, -0.7050069732359302]\n",
      "Layer: Layer 2, Input: [-0.9903795640978469, -0.30918437418467426, -0.794548386001698, -0.7050069732359302], Output: [0.3277691628818573]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9250756412204112, -0.07199391877249163, 0.4592989560335901, -0.8452335602525234]\n",
      "Layer: Layer 1, Input: [0.9250756412204112, -0.07199391877249163, 0.4592989560335901, -0.8452335602525234], Output: [-0.8917400805033899, 0.5602058251220343, -0.4544009506431039, -0.22630604678088861]\n",
      "Layer: Layer 2, Input: [-0.8917400805033899, 0.5602058251220343, -0.4544009506431039, -0.22630604678088861], Output: [-1.6572795450678044]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8725424528173896, 0.9671365634096035, -0.7835195036483869, -0.9040627646368017]\n",
      "Layer: Layer 1, Input: [0.8725424528173896, 0.9671365634096035, -0.7835195036483869, -0.9040627646368017], Output: [-0.9905348025320485, -0.5789650411742969, -0.8607623586998732, -0.6768508519438331]\n",
      "Layer: Layer 2, Input: [-0.9905348025320485, -0.5789650411742969, -0.8607623586998732, -0.6768508519438331], Output: [0.7813142626889111]\n",
      "Epoch 151/500, Loss: 0.5607041317754602, Accuracy: -1.2061271704891228\n",
      "Power operation: base = -0.0023927252283719724, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3277691628818573, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6572795450678044, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21868573731108887, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9880385665211147, 0.9717802970061875, -0.9719055048907697, -0.9964362808606398]\n",
      "Layer: Layer 1, Input: [0.9880385665211147, 0.9717802970061875, -0.9719055048907697, -0.9964362808606398], Output: [-0.9938275334114838, -0.6806335479531523, -0.9035046067763839, -0.7224938474217001]\n",
      "Layer: Layer 2, Input: [-0.9938275334114838, -0.6806335479531523, -0.9035046067763839, -0.7224938474217001], Output: [1.0004687580268459]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979764063985664, 0.951879078084395, 0.04769833659619122, -0.9143837730920734]\n",
      "Layer: Layer 1, Input: [0.9979764063985664, 0.951879078084395, 0.04769833659619122, -0.9143837730920734], Output: [-0.9905070081425, -0.3023236304334143, -0.7968490150885826, -0.7071415450670836]\n",
      "Layer: Layer 2, Input: [-0.9905070081425, -0.3023236304334143, -0.7968490150885826, -0.7071415450670836], Output: [0.3223710898604426]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9251700021698267, -0.06573410033134772, 0.4589760584961939, -0.8457568489924168]\n",
      "Layer: Layer 1, Input: [0.9251700021698267, -0.06573410033134772, 0.4589760584961939, -0.8457568489924168], Output: [-0.8942946466556685, 0.567813933086977, -0.4595128613174299, -0.23212036349613877]\n",
      "Layer: Layer 2, Input: [-0.8942946466556685, 0.567813933086977, -0.4595128613174299, -0.23212036349613877], Output: [-1.6617843776509054]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8727170538837885, 0.9675427348403904, -0.7836849672609454, -0.9044152119611041]\n",
      "Layer: Layer 1, Input: [0.8727170538837885, 0.9675427348403904, -0.7836849672609454, -0.9044152119611041], Output: [-0.9906611003266816, -0.5757625423030268, -0.8625666162179756, -0.6794661690759942]\n",
      "Layer: Layer 2, Input: [-0.9906611003266816, -0.5757625423030268, -0.8625666162179756, -0.6794661690759942], Output: [0.7821026932656197]\n",
      "Epoch 152/500, Loss: 0.5585258294544189, Accuracy: -1.2025215322725744\n",
      "Power operation: base = 0.0004687580268458724, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3223710898604426, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6617843776509054, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21789730673438035, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988057892795013, 0.9721279288921388, -0.971930275573397, -0.9964506088241633]\n",
      "Layer: Layer 1, Input: [0.988057892795013, 0.9721279288921388, -0.971930275573397, -0.9964506088241633], Output: [-0.9939030309831641, -0.678726235316737, -0.9048250547056905, -0.7248610836619678]\n",
      "Layer: Layer 2, Input: [-0.9939030309831641, -0.678726235316737, -0.9048250547056905, -0.7248610836619678], Output: [1.0033445216366337]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979791381326154, 0.9524607899698249, 0.047286668715019624, -0.9146857100113629]\n",
      "Layer: Layer 1, Input: [0.9979791381326154, 0.9524607899698249, 0.047286668715019624, -0.9146857100113629], Output: [-0.9906310296371814, -0.2952876169232727, -0.7991671249666246, -0.7092934533752162]\n",
      "Layer: Layer 2, Input: [-0.9906310296371814, -0.2952876169232727, -0.7991671249666246, -0.7092934533752162], Output: [0.31684967706821654]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9252629532521789, -0.059540796490316815, 0.45865640886224907, -0.8462704877829432]\n",
      "Layer: Layer 1, Input: [0.9252629532521789, -0.059540796490316815, 0.45865640886224907, -0.8462704877829432], Output: [-0.8967633195767077, 0.5754406603201837, -0.4646937231159657, -0.23795552207403595]\n",
      "Layer: Layer 2, Input: [-0.8967633195767077, 0.5754406603201837, -0.4646937231159657, -0.23795552207403595], Output: [-1.6661755784757963]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8728890126732632, 0.9679393773673265, -0.7838485747696291, -0.9047609932021434]\n",
      "Layer: Layer 1, Input: [0.8728890126732632, 0.9679393773673265, -0.7838485747696291, -0.9047609932021434], Output: [-0.990784014902313, -0.5724455977236597, -0.8643753546150962, -0.6820971264605764]\n",
      "Layer: Layer 2, Input: [-0.990784014902313, -0.5724455977236597, -0.8643753546150962, -0.6820971264605764], Output: [0.7828583245856899]\n",
      "Epoch 153/500, Loss: 0.5562611665947349, Accuracy: -1.2035114525949568\n",
      "Power operation: base = 0.0033445216366336794, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3168496770682165, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6661755784757963, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21714167541431006, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988076919299701, 0.9724673384398103, -0.9719547590598553, -0.9964646576904769]\n",
      "Layer: Layer 1, Input: [0.988076919299701, 0.9724673384398103, -0.9719547590598553, -0.9964646576904769], Output: [-0.9939766133352734, -0.6767374668109156, -0.9061463534187758, -0.7272425301582408]\n",
      "Layer: Layer 2, Input: [-0.9939766133352734, -0.6767374668109156, -0.9061463534187758, -0.7272425301582408], Output: [1.0062353798609123]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979818285760775, 0.9530290120228474, 0.046879329218100695, -0.914981992382428]\n",
      "Layer: Layer 1, Input: [0.9979818285760775, 0.9530290120228474, 0.046879329218100695, -0.914981992382428], Output: [-0.9907517422003057, -0.2880753617052959, -0.80150100388988, -0.7114624079110331]\n",
      "Layer: Layer 2, Input: [-0.9907517422003057, -0.2880753617052959, -0.80150100388988, -0.7114624079110331], Output: [0.31120356225090395]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9253545171776889, -0.05341463193496185, 0.458340000886593, -0.8467746818430202]\n",
      "Layer: Layer 1, Input: [0.9253545171776889, -0.05341463193496185, 0.458340000886593, -0.8467746818430202], Output: [-0.8991491758867478, 0.5830832451348021, -0.4699395472919646, -0.24381071191908232]\n",
      "Layer: Layer 2, Input: [-0.8991491758867478, 0.5830832451348021, -0.4699395472919646, -0.24381071191908232], Output: [-1.6704456798748724]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8730583780113627, 0.968326717779274, -0.7840103380337538, -0.9051002610246592]\n",
      "Layer: Layer 1, Input: [0.8730583780113627, 0.968326717779274, -0.7840103380337538, -0.9051002610246592], Output: [-0.9909036589672541, -0.5690133864993949, -0.8661873910264324, -0.6847433253171024]\n",
      "Layer: Layer 2, Input: [-0.9909036589672541, -0.5690133864993949, -0.8661873910264324, -0.6847433253171024], Output: [0.7835805817027719]\n",
      "Epoch 154/500, Loss: 0.5539071089751151, Accuracy: -1.2043040402839167\n",
      "Power operation: base = 0.006235379860912271, power = 2, grad = 0.25\n",
      "Power operation: base = 1.311203562250904, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6704456798748724, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2164194182972281, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9880956523041634, 0.9727987251807555, -0.9719789577969603, -0.9964784343195089]\n",
      "Layer: Layer 1, Input: [0.9880956523041634, 0.9727987251807555, -0.9719789577969603, -0.9964784343195089], Output: [-0.9940483405158812, -0.6746672489905216, -0.9074676288774338, -0.7296376571276071]\n",
      "Layer: Layer 2, Input: [-0.9940483405158812, -0.6746672489905216, -0.9074676288774338, -0.7296376571276071], Output: [1.0091422488257886]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979844784358145, 0.9535840572761826, 0.0464763028878699, -0.9152727443168923]\n",
      "Layer: Layer 1, Input: [0.9979844784358145, 0.9535840572761826, 0.0464763028878699, -0.9152727443168923], Output: [-0.9908692546324648, -0.28068628362677633, -0.8038488788772006, -0.7136480631403337]\n",
      "Layer: Layer 2, Input: [-0.9908692546324648, -0.28068628362677633, -0.8038488788772006, -0.7136480631403337], Output: [0.3054317455759801]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9254447159581393, -0.047356182516294, 0.4580268285052, -0.8472696294471926]\n",
      "Layer: Layer 1, Input: [0.9254447159581393, -0.047356182516294, 0.4580268285052, -0.8472696294471926], Output: [-0.9014551816489254, 0.5907385692264556, -0.4752461646688062, -0.24968503964186978]\n",
      "Layer: Layer 2, Input: [-0.9014551816489254, 0.5907385692264556, -0.4752461646688062, -0.24968503964186978], Output: [-1.6745871796715446]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8732251972157472, 0.9687049772226306, -0.7841702686566827, -0.9054331627529532]\n",
      "Layer: Layer 1, Input: [0.8732251972157472, 0.9687049772226306, -0.7841702686566827, -0.9054331627529532], Output: [-0.9910201404249085, -0.5654653132734514, -0.868001511427854, -0.6874043104213305]\n",
      "Layer: Layer 2, Input: [-0.9910201404249085, -0.5654653132734514, -0.868001511427854, -0.6874043104213305], Output: [0.7842690352571702]\n",
      "Epoch 155/500, Loss: 0.551460833799306, Accuracy: -1.204892138816143\n",
      "Power operation: base = 0.009142248825788624, power = 2, grad = 0.25\n",
      "Power operation: base = 1.30543174557598, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6745871796715446, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21573096474282982, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.98811409787709, 0.9731222833947073, -0.9720028741697316, -0.9964919453199504]\n",
      "Layer: Layer 1, Input: [0.98811409787709, 0.9731222833947073, -0.9720028741697316, -0.9964919453199504], Output: [-0.9941182701206542, -0.6725157796080863, -0.908787991325411, -0.7320458870243325]\n",
      "Layer: Layer 2, Input: [-0.9941182701206542, -0.6725157796080863, -0.908787991325411, -0.7320458870243325], Output: [1.0120661435238518]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979870883964816, 0.9541262312382209, 0.046077574974409084, -0.9155580856096013]\n",
      "Layer: Layer 1, Input: [0.9979870883964816, 0.9541262312382209, 0.046077574974409084, -0.9155580856096013], Output: [-0.9909836711263181, -0.27312022060470825, -0.8062089204176628, -0.7158500161602556]\n",
      "Layer: Layer 2, Input: [-0.9909836711263181, -0.27312022060470825, -0.8062089204176628, -0.7158500161602556], Output: [0.2995336158368551]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9255335709179835, -0.04136597717018885, 0.45771688591620385, -0.8477555221167008]\n",
      "Layer: Layer 1, Input: [0.9255335709179835, -0.04136597717018885, 0.45771688591620385, -0.8477555221167008], Output: [-0.9036841953279727, 0.5984031636414212, -0.4806092335089919, -0.25557752401046036]\n",
      "Layer: Layer 2, Input: [-0.9036841953279727, 0.5984031636414212, -0.4806092335089919, -0.25557752401046036], Output: [-1.678592563132261]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8733895161193866, 0.9690743712669834, -0.7843283779466353, -0.9057598405296715]\n",
      "Layer: Layer 1, Input: [0.8733895161193866, 0.9690743712669834, -0.7843283779466353, -0.9057598405296715], Output: [-0.9911335625851561, -0.5618010263266591, -0.8698164740597778, -0.6900795677985891]\n",
      "Layer: Layer 2, Input: [-0.9911335625851561, -0.5618010263266591, -0.8698164740597778, -0.6900795677985891], Output: [0.7849234084697985]\n",
      "Epoch 156/500, Loss: 0.5489197543680525, Accuracy: -1.2052689140231694\n",
      "Power operation: base = 0.012066143523851824, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2995336158368551, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6785925631322609, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21507659153020153, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9881322618904567, 0.9734382022015517, -0.972026510496528, -0.9965051970576704]\n",
      "Layer: Layer 1, Input: [0.9881322618904567, 0.9734382022015517, -0.972026510496528, -0.9965051970576704], Output: [-0.9941864573938486, -0.6702834598631403, -0.9101065379042067, -0.734466592627434]\n",
      "Layer: Layer 2, Input: [-0.9941864573938486, -0.6702834598631403, -0.9101065379042067, -0.734466592627434], Output: [1.0150081739162995]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979896591209445, 0.9546558319738166, 0.04568313128351068, -0.9158381318709611]\n",
      "Layer: Layer 1, Input: [0.9979896591209445, 0.9546558319738166, 0.04568313128351068, -0.9158381318709611], Output: [-0.9910950914690677, -0.2653774567040223, -0.8085792476986166, -0.7180678048098141]\n",
      "Layer: Layer 2, Input: [-0.9910950914690677, -0.2653774567040223, -0.8085792476986166, -0.7180678048098141], Output: [0.29350897522054664]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9256211027072644, -0.03544449968603729, 0.45741016764901254, -0.8482325448170018]\n",
      "Layer: Layer 1, Input: [0.9256211027072644, -0.03544449968603729, 0.45741016764901254, -0.8482325448170018], Output: [-0.9058389708310401, 0.6060732179578558, -0.4860242488024945, -0.26148709123134434]\n",
      "Layer: Layer 2, Input: [-0.9058389708310401, 0.6060732179578558, -0.4860242488024945, -0.26148709123134434], Output: [-1.6824543287412501]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8735513790961075, 0.9694351099847606, -0.7844846768833547, -0.906080431476442]\n",
      "Layer: Layer 1, Input: [0.8735513790961075, 0.9694351099847606, -0.7844846768833547, -0.906080431476442], Output: [-0.9912440243679209, -0.5580204351905729, -0.8716310131623676, -0.692768522629603]\n",
      "Layer: Layer 2, Input: [-0.9912440243679209, -0.5580204351905729, -0.8716310131623676, -0.692768522629603], Output: [0.7855435834350111]\n",
      "Epoch 157/500, Loss: 0.5462815449209943, Accuracy: -1.2054278944430852\n",
      "Power operation: base = 0.015008173916299494, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2935089752205466, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6824543287412501, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21445641656498893, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9881501500232788, 0.9737466656636411, -0.9720498690250648, -0.9965181956640943]\n",
      "Layer: Layer 1, Input: [0.9881501500232788, 0.9737466656636411, -0.9720498690250648, -0.9965181956640943], Output: [-0.9942529553264016, -0.6679709060107273, -0.9114223554684567, -0.7368990953719428]\n",
      "Layer: Layer 2, Input: [-0.9942529553264016, -0.6679709060107273, -0.9114223554684567, -0.7368990953719428], Output: [1.0179695400447741]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979921912507439, 0.9551731502066678, 0.0452929582485902, -0.9161129946622739]\n",
      "Layer: Layer 1, Input: [0.9979921912507439, 0.9551731502066678, 0.0452929582485902, -0.9161129946622739], Output: [-0.991203611238037, -0.25745874755501147, -0.8109579343468287, -0.720300906020226]\n",
      "Layer: Layer 2, Input: [-0.991203611238037, -0.25745874755501147, -0.8109579343468287, -0.720300906020226], Output: [0.2873580621337277]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9257073313164713, -0.029592190307015286, 0.45710666862064125, -0.8487008761624306]\n",
      "Layer: Layer 1, Input: [0.9257073313164713, -0.029592190307015286, 0.45710666862064125, -0.8487008761624306], Output: [-0.9079221606132459, 0.6137445927973179, -0.491486553001557, -0.26741257065248825]\n",
      "Layer: Layer 2, Input: [-0.9079221606132459, 0.6137445927973179, -0.491486553001557, -0.26741257065248825], Output: [-1.6861650177896512]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8737108290887814, 0.9697873980442764, -0.7846391760910306, -0.906395067856947]\n",
      "Layer: Layer 1, Input: [0.8737108290887814, 0.9697873980442764, -0.7846391760910306, -0.906395067856947], Output: [-0.991351620499488, -0.5541237275415338, -0.8734438430117983, -0.6954705374198263]\n",
      "Layer: Layer 2, Input: [-0.991351620499488, -0.5541237275415338, -0.8734438430117983, -0.6954705374198263], Output: [0.7861296065180108]\n",
      "Epoch 158/500, Loss: 0.5435441653391352, Accuracy: -1.2053630134501425\n",
      "Power operation: base = 0.017969540044774135, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2873580621337277, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6861650177896512, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21387039348198922, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9881677677655719, 0.9740478528978996, -0.9720729519293633, -0.996530947044572]\n",
      "Layer: Layer 1, Input: [0.9881677677655719, 0.9740478528978996, -0.9720729519293633, -0.996530947044572], Output: [-0.9943178147513498, -0.6655789601079592, -0.9127345235894712, -0.739342663970777]\n",
      "Layer: Layer 2, Input: [-0.9943178147513498, -0.6655789601079592, -0.9127345235894712, -0.739342663970777], Output: [1.0209515260684325]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979946854066158, 0.9556784694421651, 0.044907042985501244, -0.9163827816344317]\n",
      "Layer: Layer 1, Input: [0.9979946854066158, 0.9556784694421651, 0.044907042985501244, -0.9163827816344317], Output: [-0.9913093219898113, -0.2493653436234538, -0.813343014665506, -0.722548734451817]\n",
      "Layer: Layer 2, Input: [-0.9913093219898113, -0.2493653436234538, -0.813343014665506, -0.722548734451817], Output: [0.28108157156484026]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9257922760934397, -0.023809447147715178, 0.456806384178504, -0.8491606886285085]\n",
      "Layer: Layer 1, Input: [0.9257922760934397, -0.023809447147715178, 0.456806384178504, -0.8491606886285085], Output: [-0.9099363188314115, 0.6214128357388683, -0.4969913482097791, -0.2733526909832052]\n",
      "Layer: Layer 2, Input: [-0.9099363188314115, 0.6214128357388683, -0.4969913482097791, -0.2733526909832052], Output: [-1.6897172476906295]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8738679076404067, 0.9701314348154575, -0.7847918858178269, -0.9067038772429169]\n",
      "Layer: Layer 1, Input: [0.8738679076404067, 0.9701314348154575, -0.7847918858178269, -0.9067038772429169], Output: [-0.9914564417020667, -0.5501113850831869, -0.8752536622423153, -0.6981849104847051]\n",
      "Layer: Layer 2, Input: [-0.9914564417020667, -0.5501113850831869, -0.8752536622423153, -0.6981849104847051], Output: [0.7866816926579943]\n",
      "Epoch 159/500, Loss: 0.5407058853642083, Accuracy: -1.2050686526659078\n",
      "Power operation: base = 0.020951526068432536, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2810815715648403, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6897172476906295, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21331830734200574, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9881851204225528, 0.9743419381970732, -0.9720957613076758, -0.9965434568867594]\n",
      "Layer: Layer 1, Input: [0.9881851204225528, 0.9743419381970732, -0.9720957613076758, -0.9965434568867594], Output: [-0.9943810844367649, -0.6631086996692747, -0.914042117731892, -0.7417965133743543]\n",
      "Layer: Layer 2, Input: [-0.9943810844367649, -0.6631086996692747, -0.914042117731892, -0.7417965133743543], Output: [1.0239554931534225]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979971421890645, 0.9561720661094212, 0.044525373329467786, -0.9166475966702141]\n",
      "Layer: Layer 1, Input: [0.9979971421890645, 0.9561720661094212, 0.044525373329467786, -0.9166475966702141], Output: [-0.9914123114433413, -0.2410990108357268, -0.8157324903417725, -0.7248106414647254]\n",
      "Layer: Layer 2, Input: [-0.9914123114433413, -0.2410990108357268, -0.8157324903417725, -0.7248106414647254], Output: [0.2746806724548696]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9258759557623666, -0.018096627418445442, 0.45650931012903173, -0.8496121487722178]\n",
      "Layer: Layer 1, Input: [0.9258759557623666, -0.018096627418445442, 0.45650931012903173, -0.8496121487722178], Output: [-0.9118839045302816, 0.6290732006560216, -0.5025337098120383, -0.27930607712626165]\n",
      "Layer: Layer 2, Input: [-0.9118839045302816, 0.6290732006560216, -0.5025337098120383, -0.27930607712626165], Output: [-1.6931037488440606]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8740226549282925, 0.970467414487426, -0.7849428159222944, -0.9070069826833919]\n",
      "Layer: Layer 1, Input: [0.8740226549282925, 0.970467414487426, -0.7849428159222944, -0.9070069826833919], Output: [-0.9915585748770511, -0.5459841981121436, -0.8770591584335431, -0.700910874803679]\n",
      "Layer: Layer 2, Input: [-0.9915585748770511, -0.5459841981121436, -0.8770591584335431, -0.700910874803679], Output: [0.7872002283789832]\n",
      "Epoch 160/500, Loss: 0.5377653079614674, Accuracy: -1.2045396860733693\n",
      "Power operation: base = 0.02395549315342249, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2746806724548696, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6931037488440606, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21279977162101682, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882022131191067, 0.9746290911593787, -0.9721182991814291, -0.9965557306690302]\n",
      "Layer: Layer 1, Input: [0.9882022131191067, 0.9746290911593787, -0.9721182991814291, -0.9965557306690302], Output: [-0.9944428111763729, -0.6605614459977948, -0.915344212584747, -0.7442598041142324]\n",
      "Layer: Layer 2, Input: [-0.9944428111763729, -0.6605614459977948, -0.915344212584747, -0.7442598041142324], Output: [1.0269828711579314]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9979995621789949, 0.9566542097210394, 0.044147937853527615, -0.9169075400303232]\n",
      "Layer: Layer 1, Input: [0.9979995621789949, 0.9566542097210394, 0.044147937853527615, -0.9169075400303232], Output: [-0.9915126636573612, -0.2326620480614807, -0.8181243375906355, -0.7270859144700006]\n",
      "Layer: Layer 2, Input: [-0.9915126636573612, -0.2326620480614807, -0.8181243375906355, -0.7270859144700006], Output: [0.2681570215583631]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9259583884449806, -0.012454048449293246, 0.45621544275163395, -0.8500554174603532]\n",
      "Layer: Layer 1, Input: [0.9259583884449806, -0.012454048449293246, 0.45621544275163395, -0.8500554174603532], Output: [-0.9137672848463504, 0.6367206704385553, -0.5081086015086607, -0.2852712477164788]\n",
      "Layer: Layer 2, Input: [-0.9137672848463504, 0.6367206704385553, -0.5081086015086607, -0.2852712477164788], Output: [-1.6963174047803686]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8741751098015115, 0.9707955261970008, -0.7850919758668969, -0.9073045028774859]\n",
      "Layer: Layer 1, Input: [0.8741751098015115, 0.9707955261970008, -0.7850919758668969, -0.9073045028774859], Output: [-0.9916581032823626, -0.5417432784550027, -0.8788590129370838, -0.7036475972949768]\n",
      "Layer: Layer 2, Input: [-0.9916581032823626, -0.5417432784550027, -0.8788590129370838, -0.7036475972949768], Output: [0.7876857733173801]\n",
      "Epoch 161/500, Loss: 0.5347213914289026, Accuracy: -1.2037715241792828\n",
      "Power operation: base = 0.02698287115793141, power = 2, grad = 0.25\n",
      "Power operation: base = 1.268157021558363, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6963174047803686, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2123142266826199, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882190508045484, 0.9749094768257136, -0.9721405674952031, -0.996567773668933]\n",
      "Layer: Layer 1, Input: [0.9882190508045484, 0.9749094768257136, -0.9721405674952031, -0.996567773668933], Output: [-0.9945030398779884, -0.6579387709626363, -0.916639885524462, -0.7467316420750192]\n",
      "Layer: Layer 2, Input: [-0.9945030398779884, -0.6579387709626363, -0.916639885524462, -0.7467316420750192], Output: [1.0300351490765247]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998001945938402, 0.957125163049017, 0.04377472586809411, -0.9171627085031594]\n",
      "Layer: Layer 1, Input: [0.998001945938402, 0.957125163049017, 0.04377472586809411, -0.9171627085031594], Output: [-0.9916104592024099, -0.22405730096965595, -0.820516514692738, -0.7293737767059311]\n",
      "Layer: Layer 2, Input: [-0.9916104592024099, -0.22405730096965595, -0.820516514692738, -0.7293737767059311], Output: [0.26151277330085154]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.926039591683872, -0.006881988510977965, 0.4559247787976892, -0.8504906501058569]\n",
      "Layer: Layer 1, Input: [0.926039591683872, -0.006881988510977965, 0.4559247787976892, -0.8504906501058569], Output: [-0.9155887382152081, 0.6443499829978737, -0.5137108916927565, -0.2912466134569184]\n",
      "Layer: Layer 2, Input: [-0.9155887382152081, 0.6443499829978737, -0.5137108916927565, -0.2912466134569184], Output: [-1.699351295215465]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8743253098217295, 0.9711159541670801, -0.785239374718783, -0.9075965523507384]\n",
      "Layer: Layer 1, Input: [0.8743253098217295, 0.9711159541670801, -0.785239374718783, -0.9075965523507384], Output: [-0.9917551067042049, -0.5373900704658173, -0.8806519059109876, -0.7063941785611974]\n",
      "Layer: Layer 2, Input: [-0.9917551067042049, -0.5373900704658173, -0.8806519059109876, -0.7063941785611974], Output: [0.7881390600892821]\n",
      "Epoch 162/500, Loss: 0.531573469840164, Accuracy: -1.2027601575035591\n",
      "Power operation: base = 0.030035149076524714, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2615127733008515, power = 2, grad = 0.25\n",
      "Power operation: base = -0.699351295215465, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21186093991071786, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882356382576928, 0.9751832558234923, -0.972162568117766, -0.9965795909716962]\n",
      "Layer: Layer 1, Input: [0.9882356382576928, 0.9751832558234923, -0.972162568117766, -0.9965795909716962], Output: [-0.9945618136498684, -0.6552425020008689, -0.9179282201837979, -0.7492110787354903]\n",
      "Layer: Layer 2, Input: [-0.9945618136498684, -0.6552425020008689, -0.9179282201837979, -0.7492110787354903], Output: [1.0331138642324134]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980042940111185, 0.9575851823150372, 0.0434057274014669, -0.917413195558229]\n",
      "Layer: Layer 1, Input: [0.9980042940111185, 0.9575851823150372, 0.0434057274014669, -0.917413195558229], Output: [-0.9917057753276972, -0.215288171801, -0.8229069698745005, -0.7316733874814225]\n",
      "Layer: Layer 2, Input: [-0.9917057753276972, -0.215288171801, -0.8229069698745005, -0.7316733874814225], Output: [0.2547505851801888]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9261195824679482, -0.0013806874335709582, 0.4556373154744335, -0.8509179969118182]\n",
      "Layer: Layer 1, Input: [0.9261195824679482, -0.0013806874335709582, 0.4556373154744335, -0.8509179969118182], Output: [-0.9173504575690828, 0.6519556603877962, -0.5193353710841951, -0.2972304763382969]\n",
      "Layer: Layer 2, Input: [-0.9173504575690828, 0.6519556603877962, -0.5193353710841951, -0.2972304763382969], Output: [-1.7021987415505313]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.874473291307468, 0.9714288778537622, -0.7853850211578685, -0.9078832416350119]\n",
      "Layer: Layer 1, Input: [0.874473291307468, 0.9714288778537622, -0.7853850211578685, -0.9078832416350119], Output: [-0.9918496616235055, -0.5329263597823036, -0.8824365215253449, -0.7091496531522017]\n",
      "Layer: Layer 2, Input: [-0.9918496616235055, -0.5329263597823036, -0.8824365215253449, -0.7091496531522017], Output: [0.7885609923420236]\n",
      "Epoch 163/500, Loss: 0.528321271402242, Accuracy: -1.2015021986211099\n",
      "Power operation: base = 0.03311386423241336, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2547505851801888, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7021987415505313, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2114390076579764, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882519800922496, 0.9754505845160971, -0.9721843028441638, -0.9965911874787861]\n",
      "Layer: Layer 1, Input: [0.9882519800922496, 0.9754505845160971, -0.9721843028441638, -0.9965911874787861], Output: [-0.9946191738850573, -0.6524747251385127, -0.9192083100972502, -0.7516971119152076]\n",
      "Layer: Layer 2, Input: [-0.9946191738850573, -0.6524747251385127, -0.9192083100972502, -0.7516971119152076], Output: [1.036220590235538]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998006606923619, 0.9580345173932661, 0.04304093316137092, -0.9176590915029305]\n",
      "Layer: Layer 1, Input: [0.998006606923619, 0.9580345173932661, 0.04304093316137092, -0.9176590915029305], Output: [-0.9917986861229969, -0.20635862464241142, -0.8252936494708132, -0.7339838429238991]\n",
      "Layer: Layer 2, Input: [-0.9917986861229969, -0.20635862464241142, -0.8252936494708132, -0.7339838429238991], Output: [0.24787361831785582]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9261983772599426, 0.004049652971752694, 0.4553530504138159, -0.8513376031226025]\n",
      "Layer: Layer 1, Input: [0.9261983772599426, 0.004049652971752694, 0.4553530504138159, -0.8513376031226025], Output: [-0.9190545535120247, 0.6595320408041938, -0.5249767715079463, -0.3032210298194697]\n",
      "Layer: Layer 2, Input: [-0.9190545535120247, 0.6595320408041938, -0.5249767715079463, -0.3032210298194697], Output: [-1.7048533542548459]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8746190893817907, 0.9717344721009722, -0.7855289234921882, -0.90816467745174]\n",
      "Layer: Layer 1, Input: [0.8746190893817907, 0.9717344721009722, -0.7855289234921882, -0.90816467745174], Output: [-0.9919418413772589, -0.5283542795572631, -0.884211553297143, -0.7119129903868927]\n",
      "Layer: Layer 2, Input: [-0.9919418413772589, -0.5283542795572631, -0.884211553297143, -0.7119129903868927], Output: [0.7889526408633589]\n",
      "Epoch 164/500, Loss: 0.5249649343133915, Accuracy: -1.1999949219448807\n",
      "Power operation: base = 0.03622059023553792, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2478736183178558, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7048533542548459, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21104735913664108, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882680807625487, 0.9757116151568523, -0.9722057733988513, -0.9966025679165114]\n",
      "Layer: Layer 1, Input: [0.9882680807625487, 0.9757116151568523, -0.9722057733988513, -0.9966025679165114], Output: [-0.9946751603437621, -0.6496377858477946, -0.9204792623903517, -0.7541886870569163]\n",
      "Layer: Layer 2, Input: [-0.9946751603437621, -0.6496377858477946, -0.9204792623903517, -0.7541886870569163], Output: [1.0393569237571838]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980088851858789, 0.958473412023642, 0.04268033447787101, -0.9179004836423508]\n",
      "Layer: Layer 1, Input: [0.9980088851858789, 0.958473412023642, 0.04268033447787101, -0.9179004836423508], Output: [-0.9918892626756979, -0.19727318584565084, -0.8276745063024962, -0.7363041772635273]\n",
      "Layer: Layer 2, Input: [-0.9918892626756979, -0.19727318584565084, -0.8276745063024962, -0.7363041772635273], Output: [0.24088553284183867]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9262759920258605, 0.009408868678705678, 0.45507198162660534, -0.8517496092813435]\n",
      "Layer: Layer 1, Input: [0.9262759920258605, 0.009408868678705678, 0.45507198162660534, -0.8517496092813435], Output: [-0.9207030574609093, 0.6670733131589743, -0.5306297856790696, -0.3092163600365445]\n",
      "Layer: Layer 2, Input: [-0.9207030574609093, 0.6670733131589743, -0.5306297856790696, -0.3092163600365445], Output: [-1.707309081480887]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8747627380233406, 0.9720329073012746, -0.7856710896803879, -0.9084409628981929]\n",
      "Layer: Layer 1, Input: [0.8747627380233406, 0.9720329073012746, -0.7856710896803879, -0.9084409628981929], Output: [-0.9920317163149361, -0.523676313909267, -0.8859757095078832, -0.7146830957689948]\n",
      "Layer: Layer 2, Input: [-0.9920317163149361, -0.523676313909267, -0.8859757095078832, -0.7146830957689948], Output: [0.7893152376580508]\n",
      "Epoch 165/500, Loss: 0.5215050197230555, Accuracy: -1.1982363004218586\n",
      "Power operation: base = 0.039356923757183804, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2408855328418387, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7073090814808869, power = 2, grad = 0.25\n",
      "Power operation: base = -0.21068476234194922, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882839445695941, 0.9759664960463654, -0.9722269814398381, -0.9966137368446617]\n",
      "Layer: Layer 1, Input: [0.9882839445695941, 0.9759664960463654, -0.9722269814398381, -0.9966137368446617], Output: [-0.9947298112337744, -0.6467342875877602, -0.9217402014776264, -0.7566846990676768]\n",
      "Layer: Layer 2, Input: [-0.9947298112337744, -0.6467342875877602, -0.9217402014776264, -0.7566846990676768], Output: [1.0425244702075487]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980111292922832, 0.9589021040335499, 0.04232392322828333, -0.9181374564415661]\n",
      "Layer: Layer 1, Input: [0.9980111292922832, 0.9589021040335499, 0.04232392322828333, -0.9181374564415661], Output: [-0.9919775732230984, -0.18803693930461057, -0.8300475081935906, -0.7386333646785446]\n",
      "Layer: Layer 2, Input: [-0.9919775732230984, -0.18803693930461057, -0.8300475081935906, -0.7386333646785446], Output: [0.23379047787409402]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9263524422662127, 0.014696833386453279, 0.45479410744225324, -0.8521541514928186]\n",
      "Layer: Layer 1, Input: [0.9263524422662127, 0.014696833386453279, 0.45479410744225324, -0.8521541514928186], Output: [-0.9222979247411968, 0.6745735538588866, -0.5362890878322638, -0.31521444809547905]\n",
      "Layer: Layer 2, Input: [-0.9222979247411968, 0.6745735538588866, -0.5362890878322638, -0.31521444809547905], Output: [-1.709560258182218]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8749042701205848, 0.9723243495614858, -0.7858115273611109, -0.908712197636274]\n",
      "Layer: Layer 1, Input: [0.8749042701205848, 0.9723243495614858, -0.7858115273611109, -0.908712197636274], Output: [-0.9921193539500711, -0.5188952983735915, -0.8877277186533553, -0.7174588130240078]\n",
      "Layer: Layer 2, Input: [-0.9921193539500711, -0.5188952983735915, -0.8877277186533553, -0.7174588130240078], Output: [0.7896501679447101]\n",
      "Epoch 166/500, Loss: 0.5179425214241306, Accuracy: -1.1962250383191506\n",
      "Power operation: base = 0.04252447020754868, power = 2, grad = 0.25\n",
      "Power operation: base = 1.233790477874094, power = 2, grad = 0.25\n",
      "Power operation: base = -0.709560258182218, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2103498320552899, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882995756674416, 0.976215371692029, -0.9722479285638085, -0.9966246986651677]\n",
      "Layer: Layer 1, Input: [0.9882995756674416, 0.976215371692029, -0.9722479285638085, -0.9966246986651677], Output: [-0.9947831632889163, -0.6437670879119575, -0.9229902727317969, -0.759183994733127]\n",
      "Layer: Layer 2, Input: [-0.9947831632889163, -0.6437670879119575, -0.9229902727317969, -0.759183994733127], Output: [1.045724828440207]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980133397225818, 0.9593208255656822, 0.041971691744990595, -0.9183700916898235]\n",
      "Layer: Layer 1, Input: [0.9980133397225818, 0.9593208255656822, 0.041971691744990595, -0.9183700916898235], Output: [-0.992063683299972, -0.1786555163903232, -0.8324106465473933, -0.7409703217182242]\n",
      "Layer: Layer 2, Input: [-0.992063683299972, -0.1786555163903232, -0.8324106465473933, -0.7409703217182242], Output: [0.226593076000988]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9264277430488375, 0.01991345861784883, 0.45451942643524573, -0.852551361690518]\n",
      "Layer: Layer 1, Input: [0.9264277430488375, 0.01991345861784883, 0.45451942643524573, -0.852551361690518], Output: [-0.9238410376271343, 0.6820267653599206, -0.541949355011298, -0.3212131734879689]\n",
      "Layer: Layer 2, Input: [-0.9238410376271343, 0.6820267653599206, -0.541949355011298, -0.3212131734879689], Output: [-1.7116016549401982]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8750437175290567, 0.9726089608716392, -0.7859502438889419, -0.9089784780832325]\n",
      "Layer: Layer 1, Input: [0.8750437175290567, 0.9726089608716392, -0.7859502438889419, -0.9089784780832325], Output: [-0.9922048191070834, -0.5140144171803375, -0.8894663348716357, -0.72023892677518]\n",
      "Layer: Layer 2, Input: [-0.9922048191070834, -0.5140144171803375, -0.8894663348716357, -0.72023892677518], Output: [0.7899589600746002]\n",
      "Epoch 167/500, Loss: 0.5142788719490061, Accuracy: -1.1939605993067932\n",
      "Power operation: base = 0.04572482844020698, power = 2, grad = 0.25\n",
      "Power operation: base = 1.226593076000988, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7116016549401982, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2100410399253998, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9883149780698818, 0.976458382968439, -0.9722686163121523, -0.9966354576307562]\n",
      "Layer: Layer 1, Input: [0.9883149780698818, 0.976458382968439, -0.9722686163121523, -0.9966354576307562], Output: [-0.9948352518454726, -0.6407392920694857, -0.9242286460853224, -0.7616853757096219]\n",
      "Layer: Layer 2, Input: [-0.9948352518454726, -0.6407392920694857, -0.9242286460853224, -0.7616853757096219], Output: [1.0489595746452607]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980155169428846, 0.9597298033098366, 0.041623632707343365, -0.9185984686658678]\n",
      "Layer: Layer 1, Input: [0.9980155169428846, 0.9597298033098366, 0.041623632707343365, -0.9185984686658678], Output: [-0.9921476558814011, -0.16913508043924627, -0.8347619448953025, -0.7433139103106509]\n",
      "Layer: Layer 2, Input: [-0.9921476558814011, -0.16913508043924627, -0.8347619448953025, -0.7433139103106509], Output: [0.2192984022215878]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9265019090430807, 0.025058693955004655, 0.45424793733890145, -0.8529413679065203]\n",
      "Layer: Layer 1, Input: [0.9265019090430807, 0.025058693955004655, 0.45424793733890145, -0.8529413679065203], Output: [-0.9253342083168831, 0.6894269160161596, -0.5476052888136554, -0.32721031865326783]\n",
      "Layer: Layer 2, Input: [-0.9253342083168831, 0.6894269160161596, -0.5476052888136554, -0.32721031865326783], Output: [-1.7134285256588375]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8751811111313115, 0.97288689927582, -0.7860872463764494, -0.9092398976035364]\n",
      "Layer: Layer 1, Input: [0.8751811111313115, 0.97288689927582, -0.7860872463764494, -0.9092398976035364], Output: [-0.9922881740633531, -0.5090371972407013, -0.8911903432929454, -0.7230221658657746]\n",
      "Layer: Layer 2, Input: [-0.9922881740633531, -0.5090371972407013, -0.8911903432929454, -0.7230221658657746], Output: [0.7902432734272313]\n",
      "Epoch 168/500, Loss: 0.5105159447939569, Accuracy: -1.1914432290984545\n",
      "Power operation: base = 0.048959574645260684, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2192984022215878, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7134285256588375, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20975672657276867, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9883301556574063, 0.976695667277468, -0.972289046177838, -0.9966460178535766]\n",
      "Layer: Layer 1, Input: [0.9883301556574063, 0.976695667277468, -0.972289046177838, -0.9966460178535766], Output: [-0.9948861109165372, -0.6376542440732473, -0.925454519524568, -0.7641876020884819]\n",
      "Layer: Layer 2, Input: [-0.9948861109165372, -0.6376542440732473, -0.925454519524568, -0.7641876020884819], Output: [1.052230245629758]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980176614066905, 0.9601292587363737, 0.041279739019114726, -0.9188226643035677]\n",
      "Layer: Layer 1, Input: [0.9980176614066905, 0.9601292587363737, 0.041279739019114726, -0.9188226643035677], Output: [-0.9922295515208273, -0.1594823057954886, -0.8370994673291867, -0.7456629413522037]\n",
      "Layer: Layer 2, Input: [-0.9922295515208273, -0.1594823057954886, -0.8370994673291867, -0.7456629413522037], Output: [0.2119119574926045]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9265749545550672, 0.03013252738883244, 0.45397963894779336, -0.853324294542615]\n",
      "Layer: Layer 1, Input: [0.9265749545550672, 0.03013252738883244, 0.45397963894779336, -0.853324294542615], Output: [-0.9267791818338502, 0.6967679807000711, -0.5532516373690186, -0.33320357468962153]\n",
      "Layer: Layer 2, Input: [-0.9267791818338502, 0.6967679807000711, -0.5532516373690186, -0.33320357468962153], Output: [-1.715036653261401]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8753164808992459, 0.9731583190433678, -0.7862225417417824, -0.90949654670103]\n",
      "Layer: Layer 1, Input: [0.8753164808992459, 0.9731583190433678, -0.7862225417417824, -0.90949654670103], Output: [-0.9923694786865228, -0.5039674987832153, -0.8928985652536094, -0.7258072073233367]\n",
      "Layer: Layer 2, Input: [-0.9923694786865228, -0.5039674987832153, -0.8928985652536094, -0.7258072073233367], Output: [0.7905048843931923]\n",
      "Epoch 169/500, Loss: 0.506656052560619, Accuracy: -1.1886739719905712\n",
      "Power operation: base = 0.05223024562975809, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2119119574926045, power = 2, grad = 0.25\n",
      "Power operation: base = -0.715036653261401, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20949511560680767, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988345112184427, 0.9769273587067318, -0.9723092196130382, -0.9966563833137624]\n",
      "Layer: Layer 1, Input: [0.988345112184427, 0.9769273587067318, -0.9723092196130382, -0.9966563833137624], Output: [-0.9949357732641867, -0.6345155152603559, -0.9266671224369144, -0.7666893965154474]\n",
      "Layer: Layer 2, Input: [-0.9949357732641867, -0.6345155152603559, -0.9266671224369144, -0.7666893965154474], Output: [1.0555383217178647]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998019773555941, 0.9605194083290667, 0.0409400036732262, -0.919042753356921]\n",
      "Layer: Layer 1, Input: [0.998019773555941, 0.9605194083290667, 0.0409400036732262, -0.919042753356921], Output: [-0.9923094284832382, -0.14970435151839379, -0.8394213267263608, -0.7480161788647126]\n",
      "Layer: Layer 2, Input: [-0.9923094284832382, -0.14970435151839379, -0.8394213267263608, -0.7480161788647126], Output: [0.20443963711598157]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9266468935637612, 0.03513498575664559, 0.45371453001017725, -0.8537002626409739]\n",
      "Layer: Layer 1, Input: [0.9266468935637612, 0.03513498575664559, 0.45371453001017725, -0.8537002626409739], Output: [-0.9281776388463692, 0.7040439816413688, -0.5588832173175539, -0.3391905481986628]\n",
      "Layer: Layer 2, Input: [-0.9281776388463692, 0.7040439816413688, -0.5588832173175539, -0.3391905481986628], Output: [-1.7164223925199287]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8754498559583711, 0.9734233708389506, -0.7863561367611566, -0.9097485132104068]\n",
      "Layer: Layer 1, Input: [0.8754498559583711, 0.9734233708389506, -0.7863561367611566, -0.9097485132104068], Output: [-0.9924487905669631, -0.49880950264771656, -0.8945898633161091, -0.728592680949368]\n",
      "Layer: Layer 2, Input: [-0.9924487905669631, -0.49880950264771656, -0.8945898633161091, -0.728592680949368], Output: [0.7907456706105984]\n",
      "Epoch 170/500, Loss: 0.5027019408768753, Accuracy: -1.1856546807431765\n",
      "Power operation: base = 0.05553832171786466, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2044396371159816, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7164223925199287, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20925432938940158, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9883598512867078, 0.9771535881852113, -0.9723291380374063, -0.996666557867898]\n",
      "Layer: Layer 1, Input: [0.9883598512867078, 0.9771535881852113, -0.9723291380374063, -0.996666557867898], Output: [-0.9949842704693753, -0.6313268904226668, -0.9278657187719886, -0.7691894488370202]\n",
      "Layer: Layer 2, Input: [-0.9949842704693753, -0.6313268904226668, -0.9278657187719886, -0.7691894488370202], Output: [1.0588852095326655]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980218538220915, 0.9609004638151181, 0.04060441960569261, -0.9192588085634379]\n",
      "Layer: Layer 1, Input: [0.9980218538220915, 0.9609004638151181, 0.04060441960569261, -0.9192588085634379], Output: [-0.992387342873384, -0.13980882997952226, -0.8417256926764695, -0.7503723446949542]\n",
      "Layer: Layer 2, Input: [-0.992387342873384, -0.13980882997952226, -0.8417256926764695, -0.7503723446949542], Output: [0.19688769434071274]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9267177397574924, 0.04006613523995386, 0.45345260911199026, -0.8540693901525528]\n",
      "Layer: Layer 1, Input: [0.9267177397574924, 0.04006613523995386, 0.45345260911199026, -0.8540693901525528], Output: [-0.9295311983987601, 0.7112490289153376, -0.564494935545838, -0.345168769224913]\n",
      "Layer: Layer 2, Input: [-0.9295311983987601, 0.7112490289153376, -0.564494935545838, -0.345168769224913], Output: [-1.7175827091713842]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8755812646535628, 0.9736822018900411, -0.7864880381255015, -0.9099958824869285]\n",
      "Layer: Layer 1, Input: [0.8755812646535628, 0.9736822018900411, -0.7864880381255015, -0.9099958824869285], Output: [-0.992526165145314, -0.4935676943136973, -0.896263146038213, -0.7313771745051353]\n",
      "Layer: Layer 2, Input: [-0.992526165145314, -0.4935676943136973, -0.896263146038213, -0.7313771745051353], Output: [0.7909675936754557]\n",
      "Epoch 171/500, Loss: 0.49865677804037656, Accuracy: -1.1823880193693066\n",
      "Power operation: base = 0.05888520953266552, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1968876943407127, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7175827091713842, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20903240632454434, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9883743764889649, 0.9773744836348368, -0.9723488028468894, -0.9966765452573438]\n",
      "Layer: Layer 1, Input: [0.9883743764889649, 0.9773744836348368, -0.9723488028468894, -0.9966765452573438], Output: [-0.9950316329994322, -0.6280923516385232, -0.9290496099799351, -0.7716864212339887]\n",
      "Layer: Layer 2, Input: [-0.9950316329994322, -0.6280923516385232, -0.9290496099799351, -0.7716864212339887], Output: [1.0622722249445369]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980239026271901, 0.961272632390201, 0.040272979540946795, -0.9194709008048612]\n",
      "Layer: Layer 1, Input: [0.9980239026271901, 0.961272632390201, 0.040272979540946795, -0.9194709008048612], Output: [-0.9924633487588972, -0.12980377068365465, -0.8440107990217371, -0.7527301237198336]\n",
      "Layer: Layer 2, Input: [-0.9924633487588972, -0.12980377068365465, -0.8440107990217371, -0.7527301237198336], Output: [0.18926269966953813]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9267875065706019, 0.04492608189324659, 0.45319387455415056, -0.8544317922013347]\n",
      "Layer: Layer 1, Input: [0.9267875065706019, 0.04492608189324659, 0.45319387455415056, -0.8544317922013347], Output: [-0.9308414205477353, 0.7183773600099145, -0.5700818104352143, -0.35113570023107094]\n",
      "Layer: Layer 2, Input: [-0.9308414205477353, 0.7183773600099145, -0.5700818104352143, -0.35113570023107094], Output: [-1.7185152145221834]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8757107346157693, 0.9739349561503828, -0.7866182525004446, -0.9102387375932679]\n",
      "Layer: Layer 1, Input: [0.8757107346157693, 0.9739349561503828, -0.7866182525004446, -0.9102387375932679], Output: [-0.9926016558349885, -0.48824684480921265, -0.8979173724364096, -0.7341592394516488]\n",
      "Layer: Layer 2, Input: [-0.9926016558349885, -0.48824684480921265, -0.8979173724364096, -0.7341592394516488], Output: [0.7911726805956305]\n",
      "Epoch 172/500, Loss: 0.49452414041357373, Accuracy: -1.1788774585406276\n",
      "Power operation: base = 0.06227222494453688, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1892626996695381, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7185152145221834, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2088273194043695, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9883886912125835, 0.9775901701169063, -0.972368215422956, -0.9966863491163857]\n",
      "Layer: Layer 1, Input: [0.9883886912125835, 0.9775901701169063, -0.972368215422956, -0.9966863491163857], Output: [-0.9950778902730357, -0.6248160599880435, -0.9302181376922575, -0.7741789537915003]\n",
      "Layer: Layer 2, Input: [-0.9950778902730357, -0.6248160599880435, -0.9302181376922575, -0.7741789537915003], Output: [1.0657005764864689]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998025920384953, 0.9616361169365012, 0.03994567583085844, -0.9196790992641547]\n",
      "Layer: Layer 1, Input: [0.998025920384953, 0.9616361169365012, 0.03994567583085844, -0.9196790992641547], Output: [-0.9925374982881803, -0.1196975797528679, -0.8462749509261999, -0.7550881695096194]\n",
      "Layer: Layer 2, Input: [-0.9925374982881803, -0.1196975797528679, -0.8462749509261999, -0.7550881695096194], Output: [0.18157149646882464]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.926856207219847, 0.04971497217394053, 0.4529383242250073, -0.854787581342494]\n",
      "Layer: Layer 1, Input: [0.926856207219847, 0.04971497217394053, 0.4529383242250073, -0.854787581342494], Output: [-0.9321098088991022, 0.7254233779142957, -0.5756389923796544, -0.3570887460286844]\n",
      "Layer: Layer 2, Input: [-0.9321098088991022, 0.7254233779142957, -0.5756389923796544, -0.3570887460286844], Output: [-1.7192181948155603]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.875838292829117, 0.9741817744581117, -0.7867467865887529, -0.9104771594823161]\n",
      "Layer: Layer 1, Input: [0.875838292829117, 0.9741817744581117, -0.7867467865887529, -0.9104771594823161], Output: [-0.9926753141395134, -0.4828519887141571, -0.8995515560923873, -0.7369373971895965]\n",
      "Layer: Layer 2, Input: [-0.9926753141395134, -0.4828519887141571, -0.8995515560923873, -0.7369373971895965], Output: [0.791363004300778]\n",
      "Epoch 173/500, Loss: 0.4903079936865956, Accuracy: -1.1751272634700758\n",
      "Power operation: base = 0.06570057648646888, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1815714964688246, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7192181948155603, power = 2, grad = 0.25\n",
      "Power operation: base = -0.208636995699222, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988402798783395, 0.9778007699722983, -0.9723873771421053, -0.9966959729801615]\n",
      "Layer: Layer 1, Input: [0.988402798783395, 0.9778007699722983, -0.9723873771421053, -0.9966959729801615], Output: [-0.9951230707225307, -0.621502335381704, -0.9313706861141922, -0.7766656704449]\n",
      "Layer: Layer 2, Input: [-0.9951230707225307, -0.621502335381704, -0.9313706861141922, -0.7766656704449], Output: [1.0691713495430144]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980279075018291, 0.9619911162318898, 0.039622500289877356, -0.9198834715776948]\n",
      "Layer: Layer 1, Input: [0.9980279075018291, 0.9619911162318898, 0.039622500289877356, -0.9198834715776948], Output: [-0.992609841802921, -0.10949899560711049, -0.848516531395587, -0.7574451103913244]\n",
      "Layer: Layer 2, Input: [-0.992609841802921, -0.10949899560711049, -0.848516531395587, -0.7574451103913244], Output: [0.17382115357157568]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9269238547402028, 0.05443299344373854, 0.45268595546988744, -0.8551368678125674]\n",
      "Layer: Layer 1, Input: [0.9269238547402028, 0.05443299344373854, 0.45268595546988744, -0.8551368678125674], Output: [-0.9333378130407165, 0.732381687200209, -0.581161783337928, -0.3630252645637534]\n",
      "Layer: Layer 2, Input: [-0.9333378130407165, 0.732381687200209, -0.581161783337928, -0.3630252645637534], Output: [-1.719690634732164]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8759639656978174, 0.9744227946873011, -0.7868736471943107, -0.9107112271747814]\n",
      "Layer: Layer 1, Input: [0.8759639656978174, 0.9744227946873011, -0.7868736471943107, -0.9107112271747814], Output: [-0.9927471897645761, -0.4773883995348999, -0.9011647688560218, -0.7397101457335492]\n",
      "Layer: Layer 2, Input: [-0.9927471897645761, -0.4773883995348999, -0.9011647688560218, -0.7397101457335492], Output: [0.7915406635541085]\n",
      "Epoch 174/500, Loss: 0.4860126702105883, Accuracy: -1.1711424742926457\n",
      "Power operation: base = 0.0691713495430144, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1738211535715757, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7196906347321641, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20845933644589154, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884167024394511, 0.9780064029545497, -0.972406289385524, -0.9967054202923228]\n",
      "Layer: Layer 1, Input: [0.9884167024394511, 0.9780064029545497, -0.972406289385524, -0.9967054202923228], Output: [-0.9951672018534663, -0.6181556347737257, -0.9325066841017638, -0.7791451852315813]\n",
      "Layer: Layer 2, Input: [-0.9951672018534663, -0.6181556347737257, -0.9325066841017638, -0.7791451852315813], Output: [1.0726854916162112]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980298643780411, 0.9623378251485508, 0.03930344402880678, -0.9200840839816207]\n",
      "Layer: Layer 1, Input: [0.9980298643780411, 0.9623378251485508, 0.03930344402880678, -0.9200840839816207], Output: [-0.9926804279451008, -0.0992170414553971, -0.8507340071774228, -0.7597995558451308]\n",
      "Layer: Layer 2, Input: [-0.9926804279451008, -0.0992170414553971, -0.8507340071774228, -0.7597995558451308], Output: [0.16601891563533977]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9269904620196973, 0.05908037441247372, 0.4524367649597322, -0.8554797597697787]\n",
      "Layer: Layer 1, Input: [0.9269904620196973, 0.05908037441247372, 0.4524367649597322, -0.8554797597697787], Output: [-0.9345268308686872, 0.7392471276093538, -0.5866456551980191, -0.3689425784384955]\n",
      "Layer: Layer 2, Input: [-0.9345268308686872, 0.7392471276093538, -0.5866456551980191, -0.3689425784384955], Output: [-1.7199322345101447]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8760877791122744, 0.9746581518918305, -0.7869988412866796, -0.9109410179304251]\n",
      "Layer: Layer 1, Input: [0.8760877791122744, 0.9746581518918305, -0.7869988412866796, -0.9109410179304251], Output: [-0.9928173307246511, -0.47186156278363234, -0.9027561441041662, -0.7424759667445734]\n",
      "Layer: Layer 2, Input: [-0.9928173307246511, -0.47186156278363234, -0.9027561441041662, -0.7424759667445734], Output: [0.7917077626347591]\n",
      "Epoch 175/500, Loss: 0.481642842686073, Accuracy: -1.1669288791269365\n",
      "Power operation: base = 0.07268549161621118, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1660189156353398, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7199322345101447, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20829223736524094, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884304053387359, 0.9782071863549917, -0.9724249535487487, -0.9967146944123924]\n",
      "Layer: Layer 1, Input: [0.9884304053387359, 0.9782071863549917, -0.9724249535487487, -0.9967146944123924], Output: [-0.995210310301231, -0.6147805290662869, -0.9336256069015062, -0.7816161087716454]\n",
      "Layer: Layer 2, Input: [-0.995210310301231, -0.6147805290662869, -0.9336256069015062, -0.7816161087716454], Output: [1.0762437989582128]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980317914085945, 0.9626764348395987, 0.03898849728971785, -0.9202810014513577]\n",
      "Layer: Layer 1, Input: [0.9980317914085945, 0.9626764348395987, 0.03898849728971785, -0.9202810014513577], Output: [-0.9927493037583788, -0.08886097527578977, -0.8529259339804144, -0.7621501031589599]\n",
      "Layer: Layer 2, Input: [-0.9927493037583788, -0.08886097527578977, -0.8529259339804144, -0.7621501031589599], Output: [0.15817215206569335]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.927056041832926, 0.06365738549701266, 0.4521907485608264, -0.8558163635227577]\n",
      "Layer: Layer 1, Input: [0.927056041832926, 0.06365738549701266, 0.4521907485608264, -0.8558163635227577], Output: [-0.9356782108048752, 0.7460148047154255, -0.5920862667499107, -0.37483798703451143]\n",
      "Layer: Layer 2, Input: [-0.9356782108048752, 0.7460148047154255, -0.5920862667499107, -0.37483798703451143], Output: [-1.7199434203032458]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.876209758513776, 0.9748879784406176, -0.7871223760652845, -0.9111666074118325]\n",
      "Layer: Layer 1, Input: [0.876209758513776, 0.9748879784406176, -0.7871223760652845, -0.9111666074118325], Output: [-0.9928857834440846, -0.4662771471431581, -0.9043248795213401, -0.7452333328367776]\n",
      "Layer: Layer 2, Input: [-0.9928857834440846, -0.4662771471431581, -0.9043248795213401, -0.7452333328367776], Output: [0.7918663911702777]\n",
      "Epoch 176/500, Loss: 0.4772034945656199, Accuracy: -1.1624929801568742\n",
      "Power operation: base = 0.07624379895821276, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1581721520656933, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7199434203032458, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20813360882972232, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884439105667477, 0.9784032351192774, -0.9724433710511996, -0.9967237986227753]\n",
      "Layer: Layer 1, Input: [0.9884439105667477, 0.9784032351192774, -0.9724433710511996, -0.9967237986227753], Output: [-0.9952524218846772, -0.611381679036467, -0.934726977536187, -0.7840770548944695]\n",
      "Layer: Layer 2, Input: [-0.9952524218846772, -0.611381679036467, -0.934726977536187, -0.7840770548944695], Output: [1.079846904836708]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980336889842445, 0.9630071329124721, 0.03867764928447689, -0.9204742878333958]\n",
      "Layer: Layer 1, Input: [0.9980336889842445, 0.9630071329124721, 0.03867764928447689, -0.9204742878333958], Output: [-0.9928165147837495, -0.0784402380074345, -0.8550909609630882, -0.7644953442601903]\n",
      "Layer: Layer 2, Input: [-0.9928165147837495, -0.0784402380074345, -0.8550909609630882, -0.7644953442601903], Output: [0.1502883053401618]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9271206068729162, 0.06816433906997285, 0.4519479012075853, -0.8561467837460396]\n",
      "Layer: Layer 1, Input: [0.9271206068729162, 0.06816433906997285, 0.4519479012075853, -0.8561467837460396], Output: [-0.9367932539047796, 0.7526801172945606, -0.5974794790857161, -0.38070877908951817]\n",
      "Layer: Layer 2, Input: [-0.9367932539047796, 0.7526801172945606, -0.5974794790857161, -0.38070877908951817], Output: [-1.7197253475391407]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.876329928957172, 0.975112404143423, -0.7872442590222825, -0.9113880698396796]\n",
      "Layer: Layer 1, Input: [0.876329928957172, 0.975112404143423, -0.7872442590222825, -0.9113880698396796], Output: [-0.9929525928525448, -0.4606409741345196, -0.9058702393760105, -0.7479807150666644]\n",
      "Layer: Layer 2, Input: [-0.9929525928525448, -0.4606409741345196, -0.9058702393760105, -0.7479807150666644], Output: [0.7920186044967932]\n",
      "Epoch 177/500, Loss: 0.4726998875950355, Accuracy: -1.1578419532192177\n",
      "Power operation: base = 0.07984690483670809, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1502883053401618, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7197253475391407, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20798139550320682, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884572211438882, 0.9785946619547875, -0.9724615433454485, -0.9967327361353887]\n",
      "Layer: Layer 1, Input: [0.9884572211438882, 0.9785946619547875, -0.9724615433454485, -0.9967327361353887], Output: [-0.9952935616566463, -0.6079638106342925, -0.9358103678256041, -0.7865266473246201]\n",
      "Layer: Layer 2, Input: [-0.9952935616566463, -0.6079638106342925, -0.9358103678256041, -0.7865266473246201], Output: [1.0834952696663183]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980355574924115, 0.9633301035881461, 0.0383708880392694, -0.920664005968507]\n",
      "Layer: Layer 1, Input: [0.9980355574924115, 0.9633301035881461, 0.0383708880392694, -0.920664005968507], Output: [-0.9928821051494074, -0.06796440070270944, -0.8572278344535884, -0.7668338726393428]\n",
      "Layer: Layer 2, Input: [-0.9928821051494074, -0.06796440070270944, -0.8572278344535884, -0.7668338726393428], Output: [0.14237483956621633]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9271841697810302, 0.07260158957576054, 0.4517082167802879, -0.8564711236809074]\n",
      "Layer: Layer 1, Input: [0.9271841697810302, 0.07260158957576054, 0.4517082167802879, -0.8564711236809074], Output: [-0.9378732158559273, 0.7592387811115436, -0.6028213692729162, -0.3865522455700834]\n",
      "Layer: Layer 2, Input: [-0.9378732158559273, 0.7592387811115436, -0.6028213692729162, -0.3865522455700834], Output: [-1.7192798971903542]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8764483151709649, 0.9753315563666106, -0.7873644980032088, -0.9116054781385705]\n",
      "Layer: Layer 1, Input: [0.8764483151709649, 0.9753315563666106, -0.7873644980032088, -0.9116054781385705], Output: [-0.9930178024747575, -0.45495898672957646, -0.9073915562743085, -0.7507165905096759]\n",
      "Layer: Layer 2, Input: [-0.9930178024747575, -0.45495898672957646, -0.9073915562743085, -0.7507165905096759], Output: [0.7921664049097861]\n",
      "Epoch 178/500, Loss: 0.4681375269702199, Accuracy: -1.1529836015131028\n",
      "Power operation: base = 0.08349526966631826, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1423748395662163, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7192798971903542, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20783359509021393, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884703400325959, 0.9787815774285568, -0.9724794719260955, -0.9967415100978771]\n",
      "Layer: Layer 1, Input: [0.9884703400325959, 0.9787815774285568, -0.9724794719260955, -0.9967415100978771], Output: [-0.9953337539513213, -0.6045316900067331, -0.9368753990374415, -0.7889635263390107]\n",
      "Layer: Layer 2, Input: [-0.9953337539513213, -0.6045316900067331, -0.9368753990374415, -0.7889635263390107], Output: [1.087189173197944]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980373973180376, 0.9636455278454832, 0.03806820024735005, -0.920850217805702]\n",
      "Layer: Layer 1, Input: [0.9980373973180376, 0.9636455278454832, 0.03806820024735005, -0.920850217805702], Output: [-0.9929461176547758, -0.05744311139154571, -0.8593354008752304, -0.7691642902784352]\n",
      "Layer: Layer 2, Input: [-0.9929461176547758, -0.05744311139154571, -0.8593354008752304, -0.7691642902784352], Output: [0.13443919008081462]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9272467431746331, 0.07696953349469238, 0.45147168798952664, -0.8567894853203497]\n",
      "Layer: Layer 1, Input: [0.9272467431746331, 0.07696953349469238, 0.45147168798952664, -0.8567894853203497], Output: [-0.9389193088678665, 0.7656868489079653, -0.6081082421764357, -0.39236569267676824]\n",
      "Layer: Layer 2, Input: [-0.9389193088678665, 0.7656868489079653, -0.6081082421764357, -0.39236569267676824], Output: [-1.7186096650211253]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.876564941614275, 0.9755455601384263, -0.7874831012645401, -0.9118189040726263]\n",
      "Layer: Layer 1, Input: [0.876564941614275, 0.9755455601384263, -0.7874831012645401, -0.9118189040726263], Output: [-0.9930814545144931, -0.44923721736269956, -0.9088882323815439, -0.7534394498261909]\n",
      "Layer: Layer 2, Input: [-0.9930814545144931, -0.44923721736269956, -0.9088882323815439, -0.7534394498261909], Output: [0.792311724141586]\n",
      "Epoch 179/500, Loss: 0.4635221246262426, Accuracy: -1.1479263041582977\n",
      "Power operation: base = 0.08718917319794395, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1344391900808146, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7186096650211253, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20768827585841398, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884832701441661, 0.9789640900555248, -0.9724971583381338, -0.996750123599388]\n",
      "Layer: Layer 1, Input: [0.9884832701441661, 0.9789640900555248, -0.9724971583381338, -0.996750123599388], Output: [-0.9953730224283658, -0.6010900985990834, -0.9379217421691362, -0.7913863553078508]\n",
      "Layer: Layer 2, Input: [-0.9953730224283658, -0.6010900985990834, -0.9379217421691362, -0.7913863553078508], Output: [1.0909287089103858]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980392088443768, 0.9639535835503162, 0.03776957113206524, -0.9210329845063538]\n",
      "Layer: Layer 1, Input: [0.9980392088443768, 0.9639535835503162, 0.03776957113206524, -0.9210329845063538], Output: [-0.9930085938487068, -0.04688604239370749, -0.8614126088654434, -0.7714852144967405]\n",
      "Layer: Layer 2, Input: [-0.9930085938487068, -0.04688604239370749, -0.8614126088654434, -0.7714852144967405], Output: [0.12648871484978796]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9273083396722863, 0.08126860913960436, 0.45123830626898725, -0.857101969577147]\n",
      "Layer: Layer 1, Input: [0.9273083396722863, 0.08126860913960436, 0.45123830626898725, -0.857101969577147], Output: [-0.9399327034557966, 0.7720207264598735, -0.613336640337531, -0.3981464548159348]\n",
      "Layer: Layer 2, Input: [-0.9399327034557966, 0.7720207264598735, -0.613336640337531, -0.3981464548159348], Output: [-1.717717944020022]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8766798325301876, 0.9757545382435523, -0.7876000775273996, -0.9120284183701579]\n",
      "Layer: Layer 1, Input: [0.8766798325301876, 0.9757545382435523, -0.7876000775273996, -0.9120284183701579], Output: [-0.9931435899327941, -0.4434817557951046, -0.9103597401104577, -0.756147804719506]\n",
      "Layer: Layer 2, Input: [-0.9931435899327941, -0.4434817557951046, -0.9103597401104577, -0.756147804719506], Output: [0.7924564073641469]\n",
      "Epoch 180/500, Loss: 0.4588595612001402, Accuracy: -1.142678960416049\n",
      "Power operation: base = 0.09092870891038585, power = 2, grad = 0.25\n",
      "Power operation: base = 1.126488714849788, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7177179440200221, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2075435926358531, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884960143452023, 0.9791423063770733, -0.9725146041847006, -0.9967585796758821]\n",
      "Layer: Layer 1, Input: [0.9884960143452023, 0.9791423063770733, -0.9725146041847006, -0.9967585796758821], Output: [-0.9954113901138234, -0.5976438086722343, -0.9389491178675194, -0.7937938270347511]\n",
      "Layer: Layer 2, Input: [-0.9954113901138234, -0.5976438086722343, -0.9389491178675194, -0.7937938270347511], Output: [1.0947137806961225]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998040992453712, 0.964254445569134, 0.03747498432195728, -0.9212123665380634]\n",
      "Layer: Layer 1, Input: [0.998040992453712, 0.964254445569134, 0.03747498432195728, -0.9212123665380634], Output: [-0.9930695741018882, -0.03630283877963955, -0.8634585105887349, -0.7737952846288113]\n",
      "Layer: Layer 2, Input: [-0.9930695741018882, -0.03630283877963955, -0.8634585105887349, -0.7737952846288113], Output: [0.11853064835574889]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.927368971916276, 0.08549929627326466, 0.45100806167798607, -0.8574086764343518]\n",
      "Layer: Layer 1, Input: [0.927368971916276, 0.08549929627326466, 0.45100806167798607, -0.8574086764343518], Output: [-0.9409145301207122, 0.7782371846534573, -0.6185033518509728, -0.40389190737425207]\n",
      "Layer: Layer 2, Input: [-0.9409145301207122, 0.7782371846534573, -0.6185033518509728, -0.40389190737425207], Output: [-1.7166087003650756]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8767930119950635, 0.9759586113068695, -0.7877154360267019, -0.9122340908369031]\n",
      "Layer: Layer 1, Input: [0.8767930119950635, 0.9759586113068695, -0.7877154360267019, -0.9122340908369031], Output: [-0.993204248520478, -0.43769871727245796, -0.9118056222835955, -0.7588401951910179]\n",
      "Layer: Layer 2, Input: [-0.993204248520478, -0.43769871727245796, -0.9118056222835955, -0.7588401951910179], Output: [0.7926021989691261]\n",
      "Epoch 181/500, Loss: 0.4541558472190625, Accuracy: -1.1372509304478209\n",
      "Power operation: base = 0.09471378069612246, power = 2, grad = 0.25\n",
      "Power operation: base = 1.118530648355749, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7166087003650756, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2073978010308739, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885085754636501, 0.9793163310299644, -0.9725318111341156, -0.9967668813149676]\n",
      "Layer: Layer 1, Input: [0.9885085754636501, 0.9793163310299644, -0.9725318111341156, -0.9967668813149676], Output: [-0.9954488794377929, -0.594197559552859, -0.9399572959985062, -0.7961846698161811]\n",
      "Layer: Layer 2, Input: [-0.9954488794377929, -0.594197559552859, -0.9399572959985062, -0.7961846698161811], Output: [1.0985441018784377]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980427485279947, 0.9645482858675025, 0.03718442173950425, -0.9213884237579902]\n",
      "Layer: Layer 1, Input: [0.9980427485279947, 0.9645482858675025, 0.03718442173950425, -0.9213884237579902], Output: [-0.9931290976735481, -0.025703068628543196, -0.865472262256932, -0.7760931684538178]\n",
      "Layer: Layer 2, Input: [-0.9931290976735481, -0.025703068628543196, -0.865472262256932, -0.7760931684538178], Output: [0.11057205857703467]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9274286525923227, 0.08966211553896308, 0.45078094281498476, -0.8577097050776937]\n",
      "Layer: Layer 1, Input: [0.9274286525923227, 0.08966211553896308, 0.45078094281498476, -0.8577097050776937], Output: [-0.9418658809297091, 0.7843333676053125, -0.6236054162158159, -0.40959947913751826]\n",
      "Layer: Layer 2, Input: [-0.9418658809297091, 0.7843333676053125, -0.6236054162158159, -0.40959947913751826], Output: [-1.715286543391101]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8769045039634434, 0.9761578978665433, -0.7878291865551489, -0.9124359904574766]\n",
      "Layer: Layer 1, Input: [0.8769045039634434, 0.9761578978665433, -0.7878291865551489, -0.9124359904574766], Output: [-0.9932634689649942, -0.4318942113922726, -0.913225491785221, -0.7615151965027546]\n",
      "Layer: Layer 2, Input: [-0.9932634689649942, -0.4318942113922726, -0.913225491785221, -0.7615151965027546], Output: [0.792750730323907]\n",
      "Epoch 182/500, Loss: 0.44941708406118097, Accuracy: -1.1316519735226667\n",
      "Power operation: base = 0.09854410187843765, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1105720585770347, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7152865433911011, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20724926967609303, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885209562943754, 0.9794862668059385, -0.9725487809261321, -0.9967750314602437]\n",
      "Layer: Layer 1, Input: [0.9885209562943754, 0.9794862668059385, -0.9725487809261321, -0.9967750314602437], Output: [-0.9954855122689121, -0.5907560349046008, -0.9409460948841682, -0.7985576531471532]\n",
      "Layer: Layer 2, Input: [-0.9954855122689121, -0.5907560349046008, -0.9409460948841682, -0.7985576531471532], Output: [1.1024191965419603]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980444774494039, 0.9648352735936025, 0.036897863504753596, -0.9215612154855221]\n",
      "Layer: Layer 1, Input: [0.9980444774494039, 0.9648352735936025, 0.036897863504753596, -0.9215612154855221], Output: [-0.9931872027725762, -0.015096175666364684, -0.867453123881824, -0.7783775683012308]\n",
      "Layer: Layer 2, Input: [-0.9931872027725762, -0.015096175666364684, -0.867453123881824, -0.7783775683012308], Output: [0.10261980756139133]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9274873944463741, 0.09375762770072855, 0.45055693674306635, -0.8580051540097137]\n",
      "Layer: Layer 1, Input: [0.9274873944463741, 0.09375762770072855, 0.45055693674306635, -0.8580051540097137], Output: [-0.942787811000751, 0.7903067969264533, -0.6286401281681735, -0.41526666420456887]\n",
      "Layer: Layer 2, Input: [-0.942787811000751, 0.7903067969264533, -0.6286401281681735, -0.41526666420456887], Output: [-1.7137566901341943]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8770143323082696, 0.976352514436711, -0.7879413395015809, -0.9126341854848388]\n",
      "Layer: Layer 1, Input: [0.8770143323082696, 0.976352514436711, -0.7879413395015809, -0.9126341854848388], Output: [-0.9933212889117494, -0.42607431206375074, -0.9146190307256206, -0.7641714257644137]\n",
      "Layer: Layer 2, Input: [-0.9933212889117494, -0.42607431206375074, -0.9146190307256206, -0.7641714257644137], Output: [0.7929035096445944]\n",
      "Epoch 183/500, Loss: 0.44464942521896683, Accuracy: -1.1258921845929515\n",
      "Power operation: base = 0.1024191965419603, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1026198075613913, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7137566901341943, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20709649035540556, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885331596042498, 0.979652214702359, -0.9725655153773417, -0.9967830330151553]\n",
      "Layer: Layer 1, Input: [0.9885331596042498, 0.979652214702359, -0.9725655153773417, -0.9967830330151553], Output: [-0.9955213099457181, -0.5873238412735329, -0.9419153802289989, -0.800911593008234]\n",
      "Layer: Layer 2, Input: [-0.9955213099457181, -0.5873238412735329, -0.9419153802289989, -0.800911593008234], Output: [1.1063384031056773]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980461796008221, 0.9651155751474854, 0.036615287854812516, -0.9217308005643116]\n",
      "Layer: Layer 1, Input: [0.9980461796008221, 0.9651155751474854, 0.036615287854812516, -0.9217308005643116], Output: [-0.9932439266132405, -0.004491434789577975, -0.8694004582961729, -0.7806472267655015]\n",
      "Layer: Layer 2, Input: [-0.9932439266132405, -0.004491434789577975, -0.8694004582961729, -0.7806472267655015], Output: [0.09468051599150851]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9275452102984271, 0.09778643269360289, 0.45033602892812047, -0.8582951211456881]\n",
      "Layer: Layer 1, Input: [0.9275452102984271, 0.09778643269360289, 0.45033602892812047, -0.8582951211456881], Output: [-0.9436813398967465, 0.7961553722945156, -0.6336050395359193, -0.42089103325936494]\n",
      "Layer: Layer 2, Input: [-0.9436813398967465, 0.7961553722945156, -0.6336050395359193, -0.42089103325936494], Output: [-1.7120249251133952]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.877122520856213, 0.9765425755601995, -0.7880519058833185, -0.9128287435177747]\n",
      "Layer: Layer 1, Input: [0.877122520856213, 0.9765425755601995, -0.7880519058833185, -0.9128287435177747], Output: [-0.993377745020059, -0.42024502890093285, -0.9159859891472761, -0.7668075480708387]\n",
      "Layer: Layer 2, Input: [-0.993377745020059, -0.42024502890093285, -0.9159859891472761, -0.7668075480708387], Output: [0.7930619140676805]\n",
      "Epoch 184/500, Loss: 0.43985903836464224, Accuracy: -1.1199819301429006\n",
      "Power operation: base = 0.10633840310567733, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0946805159915085, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7120249251133952, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20693808593231955, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885451881367204, 0.979814273964404, -0.9725820163856825, -0.9967908888463592]\n",
      "Layer: Layer 1, Input: [0.9885451881367204, 0.979814273964404, -0.9725820163856825, -0.9967908888463592], Output: [-0.9955562933049745, -0.5839054881219723, -0.9428650637609907, -0.8032453566784684]\n",
      "Layer: Layer 2, Input: [-0.9955562933049745, -0.5839054881219723, -0.9428650637609907, -0.8032453566784684], Output: [1.110300880018357]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980478553662254, 0.9653893542368489, 0.036336671079849676, -0.9218972374138457]\n",
      "Layer: Layer 1, Input: [0.9980478553662254, 0.9653893542368489, 0.036336671079849676, -0.9218972374138457], Output: [-0.9932993054656937, 0.006102089103686578, -0.8713137294885868, -0.7829009319712854]\n",
      "Layer: Layer 2, Input: [-0.9932993054656937, 0.006102089103686578, -0.8713137294885868, -0.7829009319712854], Output: [0.08676053202930234]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9276021130533741, 0.10174916848816991, 0.4501182031902382, -0.8585797038916669]\n",
      "Layer: Layer 1, Input: [0.9276021130533741, 0.10174916848816991, 0.4501182031902382, -0.8585797038916669], Output: [-0.9445474529342117, 0.8018773685550113, -0.6384979591843694, -0.4264702440793725]\n",
      "Layer: Layer 2, Input: [-0.9445474529342117, 0.8018773685550113, -0.6384979591843694, -0.4264702440793725], Output: [-1.7100975560726128]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8772290934179867, 0.9767281938518337, -0.7881608973722339, -0.9130197315665142]\n",
      "Layer: Layer 1, Input: [0.8772290934179867, 0.9767281938518337, -0.7881608973722339, -0.9130197315665142], Output: [-0.9934328730139261, -0.4144122803422185, -0.9173261833080838, -0.7694222821260899]\n",
      "Layer: Layer 2, Input: [-0.9934328730139261, -0.4144122803422185, -0.9173261833080838, -0.7694222821260899], Output: [0.7932271839435159]\n",
      "Epoch 185/500, Loss: 0.4350520686774156, Accuracy: -1.1139317841767564\n",
      "Power operation: base = 0.11030088001835692, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0867605320293023, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7100975560726128, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20677281605648412, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885570446158468, 0.9799725421194039, -0.9725982859340282, -0.9967986017866111]\n",
      "Layer: Layer 1, Input: [0.9885570446158468, 0.9799725421194039, -0.9725982859340282, -0.9967986017866111], Output: [-0.9955904827070843, -0.5805053695229395, -0.9437951016161982, -0.8055578670291779]\n",
      "Layer: Layer 2, Input: [-0.9955904827070843, -0.5805053695229395, -0.9437951016161982, -0.8055578670291779], Output: [1.1143056134128986]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980495051309927, 0.9656567719203012, 0.03606198747595361, -0.9220605840708556]\n",
      "Layer: Layer 1, Input: [0.9980495051309927, 0.9656567719203012, 0.03606198747595361, -0.9220605840708556], Output: [-0.9933533747015258, 0.016675578641990135, -0.8731925003058252, -0.7851375223406463]\n",
      "Layer: Layer 2, Input: [-0.9933533747015258, 0.016675578641990135, -0.8731925003058252, -0.7851375223406463], Output: [0.07886590461659404]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9276581157089099, 0.10564650977701018, 0.4499034416685759, -0.858858999205168]\n",
      "Layer: Layer 1, Input: [0.9276581157089099, 0.10564650977701018, 0.4499034416685759, -0.858858999205168], Output: [-0.9453871024121012, 0.8074714296190231, -0.6433169511480247, -0.4320020511754997]\n",
      "Layer: Layer 2, Input: [-0.9453871024121012, 0.8074714296190231, -0.6433169511480247, -0.4320020511754997], Output: [-1.7079813664465107]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8773340738135927, 0.9769094800330074, -0.7882683263144157, -0.9132072161067949]\n",
      "Layer: Layer 1, Input: [0.8773340738135927, 0.9769094800330074, -0.7882683263144157, -0.9132072161067949], Output: [-0.9934867077278736, -0.408581868737719, -0.9186394935814254, -0.7720144053015318]\n",
      "Layer: Layer 2, Input: [-0.9934867077278736, -0.408581868737719, -0.9186394935814254, -0.7720144053015318], Output: [0.7934004193191959]\n",
      "Epoch 186/500, Loss: 0.4302346038437084, Accuracy: -1.1077524651568074\n",
      "Power operation: base = 0.11430561341289858, power = 2, grad = 0.25\n",
      "Power operation: base = 1.078865904616594, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7079813664465107, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20659958068080408, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885687317497972, 0.9801271150039957, -0.972614326092844, -0.9968061746371907]\n",
      "Layer: Layer 1, Input: [0.9885687317497972, 0.9801271150039957, -0.972614326092844, -0.9968061746371907], Output: [-0.9956238980587281, -0.5771277476447113, -0.944705492497735, -0.807848106264519]\n",
      "Layer: Layer 2, Input: [-0.9956238980587281, -0.5771277476447113, -0.944705492497735, -0.807848106264519], Output: [1.1183514265197165]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980511292821296, 0.9659179866392076, 0.03579120931490807, -0.9222208982209873]\n",
      "Layer: Layer 1, Input: [0.9980511292821296, 0.9659179866392076, 0.03579120931490807, -0.9222208982209873], Output: [-0.9934061688346222, 0.02722049762448013, -0.8750364295825328, -0.7873558908241712]\n",
      "Layer: Layer 2, Input: [-0.9934061688346222, 0.02722049762448013, -0.8750364295825328, -0.7873558908241712], Output: [0.07100236130520265]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9277132313605837, 0.10947916649383088, 0.4496917247997129, -0.8591331036392952]\n",
      "Layer: Layer 1, Input: [0.9277132313605837, 0.10947916649383088, 0.4496917247997129, -0.8591331036392952], Output: [-0.9462012087665752, 0.812936559460854, -0.6480603310658951, -0.4374843144775294]\n",
      "Layer: Layer 2, Input: [-0.9462012087665752, 0.812936559460854, -0.6480603310658951, -0.4374843144775294], Output: [-1.7056835653325357]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8774374858925426, 0.9770865429582752, -0.7883742057433983, -0.9133912631227986]\n",
      "Layer: Layer 1, Input: [0.8774374858925426, 0.9770865429582752, -0.7883742057433983, -0.9133912631227986], Output: [-0.9935392831480994, -0.40275945759248855, -0.9199258620164341, -0.7745827580873109]\n",
      "Layer: Layer 2, Input: [-0.9935392831480994, -0.40275945759248855, -0.9199258620164341, -0.7745827580873109], Output: [0.7935825785281483]\n",
      "Epoch 187/500, Loss: 0.4254126410870247, Accuracy: -1.1014547746293069\n",
      "Power operation: base = 0.11835142651971653, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0710023613052027, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7056835653325357, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20641742147185171, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885802522338033, 0.980278086784827, -0.9726301390219156, -0.9968136101698837]\n",
      "Layer: Layer 1, Input: [0.9885802522338033, 0.980278086784827, -0.9726301390219156, -0.9968136101698837], Output: [-0.995656558832886, -0.5737767381125907, -0.9455962756416395, -0.8101151190857643]\n",
      "Layer: Layer 2, Input: [-0.995656558832886, -0.5737767381125907, -0.9455962756416395, -0.8101151190857643], Output: [1.122436990610732]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980527282084158, 0.9661731542393222, 0.03552430683066098, -0.9223782372212673]\n",
      "Layer: Layer 1, Input: [0.9980527282084158, 0.9661731542393222, 0.03552430683066098, -0.9223782372212673], Output: [-0.9934577215576317, 0.03772862062360539, -0.8768452687631912, -0.7895549885687151]\n",
      "Layer: Layer 2, Input: [-0.9934577215576317, 0.03772862062360539, -0.8768452687631912, -0.7895549885687151], Output: [0.0631752905926759]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9277674732041116, 0.11324788217868154, 0.449483031309313, -0.8594021133712175]\n",
      "Layer: Layer 1, Input: [0.9277674732041116, 0.11324788217868154, 0.449483031309313, -0.8594021133712175], Output: [-0.9469906616575489, 0.8182721105447867, -0.6527266610564073, -0.44291500699856157]\n",
      "Layer: Layer 2, Input: [-0.9469906616575489, 0.8182721105447867, -0.6527266610564073, -0.44291500699856157], Output: [-1.7032117357488996]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8775393535491463, 0.977259489634793, -0.7884785493870342, -0.9135719381395132]\n",
      "Layer: Layer 1, Input: [0.8775393535491463, 0.977259489634793, -0.7884785493870342, -0.9135719381395132], Output: [-0.9935906324492357, -0.3969505511003716, -0.9211852896041925, -0.7771262479087927]\n",
      "Layer: Layer 2, Input: [-0.9935906324492357, -0.3969505511003716, -0.9211852896041925, -0.7771262479087927], Output: [0.7937744787597327]\n",
      "Epoch 188/500, Loss: 0.4205920565256084, Accuracy: -1.095049538192575\n",
      "Power operation: base = 0.1224369906107321, power = 2, grad = 0.25\n",
      "Power operation: base = 1.063175290592676, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7032117357488996, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20622552124026727, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9885916087525831, 0.9804255499735732, -0.9726457269711684, -0.9968209111285425]\n",
      "Layer: Layer 1, Input: [0.9885916087525831, 0.9804255499735732, -0.9726457269711684, -0.9968209111285425], Output: [-0.9956884840864153, -0.5704562972945006, -0.9464675286227506, -0.8123580152672155]\n",
      "Layer: Layer 2, Input: [-0.9956884840864153, -0.5704562972945006, -0.9464675286227506, -0.8123580152672155], Output: [1.1265608372254667]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980543023004749, 0.9664224279834654, 0.03526124822201783, -0.9225326581139789]\n",
      "Layer: Layer 1, Input: [0.9980543023004749, 0.9664224279834654, 0.03526124822201783, -0.9225326581139789], Output: [-0.9935080657743625, 0.048192058472483396, -0.8786188580841608, -0.7917338280052161]\n",
      "Layer: Layer 2, Input: [-0.9935080657743625, 0.048192058472483396, -0.8786188580841608, -0.7917338280052161], Output: [0.05538972865358671]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9278208545351027, 0.11695343220482785, 0.449277338216697, -0.859666124216107]\n",
      "Layer: Layer 1, Input: [0.9278208545351027, 0.11695343220482785, 0.449277338216697, -0.859666124216107], Output: [-0.9477563209928379, 0.8234777700256205, -0.6573147431822349, -0.4482922214318453]\n",
      "Layer: Layer 2, Input: [-0.9477563209928379, 0.8234777700256205, -0.6573147431822349, -0.4482922214318453], Output: [-1.7005737819370612]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8776397007330469, 0.9774284252354717, -0.7885813716681851, -0.9137493062451858]\n",
      "Layer: Layer 1, Input: [0.8776397007330469, 0.9774284252354717, -0.7885813716681851, -0.9137493062451858], Output: [-0.993640788027028, -0.3911604760517508, -0.9224178332968872, -0.7796438522916307]\n",
      "Layer: Layer 2, Input: [-0.993640788027028, -0.3911604760517508, -0.9224178332968872, -0.7796438522916307], Output: [0.7939767984460429]\n",
      "Epoch 189/500, Loss: 0.4157785770957105, Accuracy: -1.0885475493700718\n",
      "Power operation: base = 0.12656083722546674, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0553897286535867, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7005737819370612, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20602320155395715, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886028039822461, 0.980569595437057, -0.9726610922806114, -0.9968280802302593]\n",
      "Layer: Layer 1, Input: [0.9886028039822461, 0.980569595437057, -0.9726610922806114, -0.9968280802302593], Output: [-0.9957196924753746, -0.5671702115194341, -0.9473193650337223, -0.8145759716421128]\n",
      "Layer: Layer 2, Input: [-0.9957196924753746, -0.5671702115194341, -0.9473193650337223, -0.8145759716421128], Output: [1.1307213714190616]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980558519507737, 0.9666659585565457, 0.03500199967086682, -0.9226842176326414]\n",
      "Layer: Layer 1, Input: [0.9980558519507737, 0.9666659585565457, 0.03500199967086682, -0.9226842176326414], Output: [-0.9935572336284292, 0.058603279638779766, -0.8803571223851917, -0.7938914853503943]\n",
      "Layer: Layer 2, Input: [-0.9935572336284292, 0.058603279638779766, -0.8803571223851917, -0.7938914853503943], Output: [0.04765035028200959]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9278733887463753, 0.12059662188454678, 0.4490746208517622, -0.8599252316277469]\n",
      "Layer: Layer 1, Input: [0.9278733887463753, 0.12059662188454678, 0.4490746208517622, -0.8599252316277469], Output: [-0.9484990178955883, 0.828553544073708, -0.6618236116655397, -0.45361417565295364]\n",
      "Layer: Layer 2, Input: [-0.9484990178955883, 0.828553544073708, -0.6618236116655397, -0.45361417565295364], Output: [-1.6977778764295697]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8777385514552211, 0.977593453106739, -0.7886826876994899, -0.9139234321046058]\n",
      "Layer: Layer 1, Input: [0.8777385514552211, 0.977593453106739, -0.7886826876994899, -0.9139234321046058], Output: [-0.9936897815272528, -0.385394366150287, -0.9236236028271821, -0.7821346213707925]\n",
      "Layer: Layer 2, Input: [-0.9936897815272528, -0.385394366150287, -0.9236236028271821, -0.7821346213707925], Output: [0.7941900812752221]\n",
      "Epoch 190/500, Loss: 0.4109777552179393, Accuracy: -1.0819595168554188\n",
      "Power operation: base = 0.1307213714190616, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0476503502820096, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6977778764295697, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20580991872477794, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886138405917019, 0.9807103124032529, -0.972676237379448, -0.9968351201661761]\n",
      "Layer: Layer 1, Input: [0.9886138405917019, 0.9807103124032529, -0.972676237379448, -0.9968351201661761], Output: [-0.9957502022682846, -0.5639220882039273, -0.9481519320696247, -0.8167682335066458]\n",
      "Layer: Layer 2, Input: [-0.9957502022682846, -0.5639220882039273, -0.9481519320696247, -0.8167682335066458], Output: [1.1349168857684808]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980573775535561, 0.9669038940642226, 0.03474652537504558, -0.9228329722008318]\n",
      "Layer: Layer 1, Input: [0.9980573775535561, 0.9669038940642226, 0.03474652537504558, -0.9228329722008318], Output: [-0.9936052565284945, 0.06895512755486305, -0.8820600666197477, -0.7960271025258895]\n",
      "Layer: Layer 2, Input: [-0.9936052565284945, 0.06895512755486305, -0.8820600666197477, -0.7960271025258895], Output: [0.03996146379965415]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9279250893230663, 0.12417828447228042, 0.4488748528835296, -0.8601795306871113]\n",
      "Layer: Layer 1, Input: [0.9279250893230663, 0.12417828447228042, 0.4488748528835296, -0.8601795306871113], Output: [-0.9492195556204718, 0.8334997406727654, -0.6662525240202024, -0.45887921711904206]\n",
      "Layer: Layer 2, Input: [-0.9492195556204718, 0.8334997406727654, -0.6662525240202024, -0.45887921711904206], Output: [-1.6948324075529149]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8778359297897282, 0.9777546747717952, -0.7887825132725454, -0.9140943799640302]\n",
      "Layer: Layer 1, Input: [0.8778359297897282, 0.9777546747717952, -0.7887825132725454, -0.9140943799640302], Output: [-0.9937376438712036, -0.379657148729858, -0.9248027573743435, -0.7845976797497657]\n",
      "Layer: Layer 2, Input: [-0.9937376438712036, -0.379657148729858, -0.9248027573743435, -0.7845976797497657], Output: [0.7944147416209986]\n",
      "Epoch 191/500, Loss: 0.4061949463255813, Accuracy: -1.0752960155000513\n",
      "Power operation: base = 0.13491688576848082, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0399614637996542, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6948324075529149, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20558525837900143, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886247212436016, 0.9808477884639493, -0.9726911647844056, -0.9968420336019701]\n",
      "Layer: Layer 1, Input: [0.9886247212436016, 0.9808477884639493, -0.9726911647844056, -0.9968420336019701], Output: [-0.9957800313575234, -0.5607153488322824, -0.9489654080493215, -0.8189341154589665]\n",
      "Layer: Layer 2, Input: [-0.9957800313575234, -0.5607153488322824, -0.9489654080493215, -0.8189341154589665], Output: [1.1391455748771007]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998058879504716, 0.9671363800264906, 0.034494787594815265, -0.9229789779246288]\n",
      "Layer: Layer 1, Input: [0.998058879504716, 0.9671363800264906, 0.034494787594815265, -0.9229789779246288], Output: [-0.9936521651704426, 0.07924083403277593, -0.8837277711321193, -0.7981398885073084]\n",
      "Layer: Layer 2, Input: [-0.9936521651704426, 0.07924083403277593, -0.8837277711321193, -0.7981398885073084], Output: [0.032327009636430315]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9279759698357473, 0.1276992790843026, 0.44867800635948285, -0.8604291160802738]\n",
      "Layer: Layer 1, Input: [0.9279759698357473, 0.1276992790843026, 0.44867800635948285, -0.8604291160802738], Output: [-0.9499187104238499, 0.8383169512288973, -0.670600951269863, -0.46408582617447003]\n",
      "Layer: Layer 2, Input: [-0.9499187104238499, 0.8383169512288973, -0.670600951269863, -0.46408582617447003], Output: [-1.6917459279732485]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8779318598715206, 0.9779121899302406, -0.7888808648418936, -0.914262213648601]\n",
      "Layer: Layer 1, Input: [0.8779318598715206, 0.9779121899302406, -0.7888808648418936, -0.914262213648601], Output: [-0.9937844052780862, -0.37395353382423935, -0.925955502122072, -0.7870322277260914]\n",
      "Layer: Layer 2, Input: [-0.9937844052780862, -0.37395353382423935, -0.925955502122072, -0.7870322277260914], Output: [0.7946510711669514]\n",
      "Epoch 192/500, Loss: 0.40143528931830613, Accuracy: -1.068567441319828\n",
      "Power operation: base = 0.13914557487710066, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0323270096364303, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6917459279732485, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20534892883304856, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886354485948405, 0.9809821095748095, -0.972705877097349, -0.9968488231780444]\n",
      "Layer: Layer 1, Input: [0.9886354485948405, 0.9809821095748095, -0.972705877097349, -0.9968488231780444], Output: [-0.9958091972690604, -0.5575532237114043, -0.94975999990306, -0.8210730016978144]\n",
      "Layer: Layer 2, Input: [-0.9958091972690604, -0.5575532237114043, -0.94975999990306, -0.8210730016978144], Output: [1.1434055501284006]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980603582016175, 0.9673635593674101, 0.03424674671176954, -0.9231222905794668]\n",
      "Layer: Layer 1, Input: [0.9980603582016175, 0.9673635593674101, 0.03424674671176954, -0.9231222905794668], Output: [-0.9936979895568177, 0.08945402894181978, -0.885360386766721, -0.8002291201235567]\n",
      "Layer: Layer 2, Input: [-0.9936979895568177, 0.08945402894181978, -0.885360386766721, -0.8002291201235567], Output: [0.02475056225554617]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9280260439317776, 0.1311604885543033, 0.44848405175475986, -0.8606740820670288]\n",
      "Layer: Layer 1, Input: [0.9280260439317776, 0.1311604885543033, 0.44848405175475986, -0.8606740820670288], Output: [-0.9505972323927862, 0.8430060313132833, -0.6748685674193352, -0.4692326182880234]\n",
      "Layer: Layer 2, Input: [-0.9505972323927862, 0.8430060313132833, -0.6748685674193352, -0.4692326182880234], Output: [-1.688527104823519]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8780263658906653, 0.9780660964549142, -0.788977759504257, -0.9144269965531359]\n",
      "Layer: Layer 1, Input: [0.8780263658906653, 0.9780660964549142, -0.788977759504257, -0.9144269965531359], Output: [-0.9938300952846464, -0.3682880055089975, -0.9270820847506833, -0.789437541908134]\n",
      "Layer: Layer 2, Input: [-0.9938300952846464, -0.3682880055089975, -0.9270820847506833, -0.789437541908134], Output: [0.7948992465002473]\n",
      "Epoch 193/500, Loss: 0.3967036899533777, Accuracy: -1.0617839707072187\n",
      "Power operation: base = 0.14340555012840062, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0247505622555462, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6885271048235191, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20510075349975265, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886460252966609, 0.9811133600535346, -0.972720377002238, -0.996855491509462]\n",
      "Layer: Layer 1, Input: [0.9886460252966609, 0.9811133600535346, -0.972720377002238, -0.996855491509462], Output: [-0.9958377171707189, -0.5544387484011052, -0.9505359406535672, -0.8231843458118787]\n",
      "Layer: Layer 2, Input: [-0.9958377171707189, -0.5544387484011052, -0.9505359406535672, -0.8231843458118787], Output: [1.147694854455417]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980618140428675, 0.9675855724021496, 0.03400236129892405, -0.9232629655922021]\n",
      "Layer: Layer 1, Input: [0.9980618140428675, 0.9675855724021496, 0.03400236129892405, -0.9232629655922021], Output: [-0.9937427590138568, 0.0995887463660289, -0.8869581298714091, -0.8022941423336283]\n",
      "Layer: Layer 2, Input: [-0.9937427590138568, 0.0995887463660289, -0.8869581298714091, -0.8022941423336283], Output: [0.01723533507305275]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9280753253251264, 0.13456281724414848, 0.44829295803019226, -0.8609145224416039]\n",
      "Layer: Layer 1, Input: [0.9280753253251264, 0.13456281724414848, 0.44829295803019226, -0.8609145224416039], Output: [-0.9512558462374074, 0.8475680808401062, -0.679055238342605, -0.4743183452610742]\n",
      "Layer: Layer 2, Input: [-0.9512558462374074, 0.8475680808401062, -0.679055238342605, -0.4743183452610742], Output: [-1.6851846718766608]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.878119472083348, 0.978216490386738, -0.7890732149734996, -0.9145887916271748]\n",
      "Layer: Layer 1, Input: [0.878119472083348, 0.978216490386738, -0.7890732149734996, -0.9145887916271748], Output: [-0.9938747427623593, -0.3626648154078027, -0.9281827919033877, -0.7918129752554588]\n",
      "Layer: Layer 2, Input: [-0.9938747427623593, -0.3626648154078027, -0.9281827919033877, -0.7918129752554588], Output: [0.7951593374526107]\n",
      "Epoch 194/500, Loss: 0.39200480714034336, Accuracy: -1.0549555239525201\n",
      "Power operation: base = 0.14769485445541708, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0172353350730527, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6851846718766608, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2048406625473893, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886564539943893, 0.9812416225767782, -0.9727346672615059, -0.9968620411856558]\n",
      "Layer: Layer 1, Input: [0.9886564539943893, 0.9812416225767782, -0.9727346672615059, -0.9968620411856558], Output: [-0.9958656078791625, -0.5513747617053685, -0.9512934869155002, -0.8252676700962782]\n",
      "Layer: Layer 2, Input: [-0.9958656078791625, -0.5513747617053685, -0.9512934869155002, -0.8252676700962782], Output: [1.15201147691308]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980632474280459, 0.9678025568224189, 0.03376158820067625, -0.9234010580191662]\n",
      "Layer: Layer 1, Input: [0.9980632474280459, 0.9678025568224189, 0.03376158820067625, -0.9234010580191662], Output: [-0.9937865022064305, 0.10963942748898785, -0.8885212772522902, -0.804334368013634]\n",
      "Layer: Layer 2, Input: [-0.9937865022064305, 0.10963942748898785, -0.8885212772522902, -0.804334368013634], Output: [0.00978418801061487]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.928123827784897, 0.1379071888285629, 0.4481046926981432, -0.8611505304868242]\n",
      "Layer: Layer 1, Input: [0.928123827784897, 0.1379071888285629, 0.4481046926981432, -0.8611505304868242], Output: [-0.9518952520507277, 0.852004423956764, -0.6831610102436293, -0.4793418954580925]\n",
      "Layer: Layer 2, Input: [-0.9518952520507277, 0.852004423956764, -0.6831610102436293, -0.4793418954580925], Output: [-1.681727384153516]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8782112027200384, 0.9783634659283105, -0.7891672495518157, -0.9147476613551588]\n",
      "Layer: Layer 1, Input: [0.8782112027200384, 0.9783634659283105, -0.7891672495518157, -0.9147476613551588], Output: [-0.9939183759324942, -0.3570879782339303, -0.9292579456630577, -0.7941579565813119]\n",
      "Layer: Layer 2, Input: [-0.9939183759324942, -0.3570879782339303, -0.9292579456630577, -0.7941579565813119], Output: [0.7954313159752027]\n",
      "Epoch 195/500, Loss: 0.38734304206449643, Accuracy: -1.0480917331020083\n",
      "Power operation: base = 0.15201147691308003, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0097841880106149, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6817273841535161, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20456868402479733, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886667373268503, 0.9813669781764128, -0.9727487507119295, -0.996868474769951]\n",
      "Layer: Layer 1, Input: [0.9886667373268503, 0.9813669781764128, -0.9727487507119295, -0.996868474769951], Output: [-0.995892885865787, -0.5483639050991518, -0.9520329164354578, -0.8273225644365813]\n",
      "Layer: Layer 2, Input: [-0.995892885865787, -0.5483639050991518, -0.9520329164354578, -0.8273225644365813], Output: [1.15635336686401]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980646587574038, 0.9680146476812796, 0.03352438262128986, -0.9235366225209686]\n",
      "Layer: Layer 1, Input: [0.9980646587574038, 0.9680146476812796, 0.03352438262128986, -0.9235366225209686], Output: [-0.9938292471511921, 0.11960092047466692, -0.890050161132539, -0.8063492772912875]\n",
      "Layer: Layer 2, Input: [-0.9938292471511921, 0.11960092047466692, -0.890050161132539, -0.8063492772912875], Output: [0.0023996373191486065]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.928171565122787, 0.14119454407166318, 0.4479192218950731, -0.8613821989230331]\n",
      "Layer: Layer 1, Input: [0.928171565122787, 0.14119454407166318, 0.4479192218950731, -0.8613821989230331], Output: [-0.9525161260396263, 0.856316588896399, -0.6871860978369857, -0.4843022931208777]\n",
      "Layer: Layer 2, Input: [-0.9525161260396263, 0.856316588896399, -0.6871860978369857, -0.4843022931208777], Output: [-1.6781639752786666]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.87830158209121, 0.9785071154369177, -0.7892598820976534, -0.9149036677325959]\n",
      "Layer: Layer 1, Input: [0.87830158209121, 0.9785071154369177, -0.7892598820976534, -0.9149036677325959], Output: [-0.9939610223793459, -0.3515612692217463, -0.9303079000722145, -0.7964719895604541]\n",
      "Layer: Layer 2, Input: [-0.9939610223793459, -0.3515612692217463, -0.9303079000722145, -0.7964719895604541], Output: [0.7957150653474341]\n",
      "Epoch 196/500, Loss: 0.38272253002975987, Accuracy: -1.0412019141143913\n",
      "Power operation: base = 0.15635336686401002, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0023996373191486, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6781639752786666, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20428493465256592, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886768779254965, 0.9814895062356804, -0.9727626302600618, -0.9968747947989297]\n",
      "Layer: Layer 1, Input: [0.9886768779254965, 0.9814895062356804, -0.9727626302600618, -0.9968747947989297], Output: [-0.9959195672616944, -0.5454086234584719, -0.9527545256919975, -0.8293486848035848]\n",
      "Layer: Layer 2, Input: [-0.9959195672616944, -0.5454086234584719, -0.9527545256919975, -0.8293486848035848], Output: [1.1607184476139758]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980660484315321, 0.9682219773782184, 0.033290698220565774, -0.9236697133347688]\n",
      "Layer: Layer 1, Input: [0.9980660484315321, 0.9682219773782184, 0.033290698220565774, -0.9236697133347688], Output: [-0.9938710212282095, 0.1294684776261844, -0.8915451641623701, -0.8083384164683003]\n",
      "Layer: Layer 2, Input: [-0.9938710212282095, 0.1294684776261844, -0.8915451641623701, -0.8083384164683003], Output: [-0.004916132682025953]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9282185511797044, 0.1444258386122041, 0.44773651045976454, -0.8616096198530185]\n",
      "Layer: Layer 1, Input: [0.9282185511797044, 0.1444258386122041, 0.44773651045976454, -0.8616096198530185], Output: [-0.9531191212302743, 0.8605062880143297, -0.6911308723845936, -0.48919869683571193]\n",
      "Layer: Layer 2, Input: [-0.9531191212302743, 0.8605062880143297, -0.6911308723845936, -0.48919869683571193], Output: [-1.6745031178240761]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8783906344909953, 0.9786475294175739, -0.789351131990886, -0.9150568722390274]\n",
      "Layer: Layer 1, Input: [0.8783906344909953, 0.9786475294175739, -0.789351131990886, -0.9150568722390274], Output: [-0.9940027090619203, -0.3460882232921501, -0.9313330377250882, -0.7987546512890242]\n",
      "Layer: Layer 2, Input: [-0.9940027090619203, -0.3460882232921501, -0.9313330377250882, -0.7987546512890242], Output: [0.7960103895368484]\n",
      "Epoch 197/500, Loss: 0.3781471348828124, Accuracy: -1.0342950432191778\n",
      "Power operation: base = 0.1607184476139758, power = 2, grad = 0.25\n",
      "Power operation: base = 0.995083867317974, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6745031178240761, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20398961046315156, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988686878413294, 0.9816092844856997, -0.9727763088773055, -0.9968810037816733]\n",
      "Layer: Layer 1, Input: [0.988686878413294, 0.9816092844856997, -0.9727763088773055, -0.9968810037816733], Output: [-0.9959456678619051, -0.5425111669583171, -0.9534586275723089, -0.8313457514037714]\n",
      "Layer: Layer 2, Input: [-0.9959456678619051, -0.5425111669583171, -0.9534586275723089, -0.8313457514037714], Output: [1.1651046293597833]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998067416851009, 0.9684246756452585, 0.0330604872153743, -0.9238003842446947]\n",
      "Layer: Layer 1, Input: [0.998067416851009, 0.9684246756452585, 0.0330604872153743, -0.9238003842446947], Output: [-0.9939118511913463, 0.13923775011036874, -0.8930067145217349, -0.8103013965732927]\n",
      "Layer: Layer 2, Input: [-0.9939118511913463, 0.13923775011036874, -0.8930067145217349, -0.8103013965732927], Output: [-0.012161256291912004]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9282647998117571, 0.14760204077312813, 0.44755652201615187, -0.8618328847041096]\n",
      "Layer: Layer 1, Input: [0.9282647998117571, 0.14760204077312813, 0.44755652201615187, -0.8618328847041096], Output: [-0.9537048681508768, 0.8645753982010375, -0.694995849712675, -0.4940303972283918]\n",
      "Layer: Layer 2, Input: [-0.9537048681508768, 0.8645753982010375, -0.694995849712675, -0.4940303972283918], Output: [-1.6707533868112059]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8784783841991562, 0.9787847965166192, -0.7894410190957387, -0.9152073358085697]\n",
      "Layer: Layer 1, Input: [0.8784783841991562, 0.9787847965166192, -0.7894410190957387, -0.9152073358085697], Output: [-0.9940434623243298, -0.34067213578972305, -0.9323337664566853, -0.8010055904452769]\n",
      "Layer: Layer 2, Input: [-0.9940434623243298, -0.34067213578972305, -0.9323337664566853, -0.8010055904452769], Output: [0.7963170225466554]\n",
      "Epoch 198/500, Loss: 0.373620445857442, Accuracy: -1.0273797373324216\n",
      "Power operation: base = 0.16510462935978332, power = 2, grad = 0.25\n",
      "Power operation: base = 0.987838743708088, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6707533868112059, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20368297745334463, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886967414034035, 0.981726389002739, -0.9727897895946942, -0.996887104198908]\n",
      "Layer: Layer 1, Input: [0.9886967414034035, 0.981726389002739, -0.9727897895946942, -0.996887104198908], Output: [-0.9959712031289634, -0.539673594002845, -0.9541455491394422, -0.8333135465309864]\n",
      "Layer: Layer 2, Input: [-0.9959712031289634, -0.539673594002845, -0.9541455491394422, -0.8333135465309864], Output: [1.1695098213389388]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980687644160305, 0.9686228695347834, 0.032833700485776836, -0.9239286885510389]\n",
      "Layer: Layer 1, Input: [0.9980687644160305, 0.9686228695347834, 0.032833700485776836, -0.9239286885510389], Output: [-0.9939517631776238, 0.14890478053580597, -0.8944352811516421, -0.8122378915889267]\n",
      "Layer: Layer 2, Input: [-0.9939517631776238, 0.14890478053580597, -0.8944352811516421, -0.8122378915889267], Output: [-0.019334171862818827]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9283103248758146, 0.15072412940959992, 0.44737921905974465, -0.8620520841685203]\n",
      "Layer: Layer 1, Input: [0.9283103248758146, 0.15072412940959992, 0.44737921905974465, -0.8620520841685203], Output: [-0.954273975494229, 0.8685259418357065, -0.6987816783202918, -0.4987968139658753]\n",
      "Layer: Layer 2, Input: [-0.954273975494229, 0.8685259418357065, -0.6987816783202918, -0.4987968139658753], Output: [-1.6669232264781266]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8785648554617295, 0.9789190035163374, -0.7895295637219496, -0.915355118798749]\n",
      "Layer: Layer 1, Input: [0.8785648554617295, 0.9789190035163374, -0.7895295637219496, -0.915355118798749], Output: [-0.9940833079051341, -0.3353160646271275, -0.9333105161498753, -0.8032245251010497]\n",
      "Layer: Layer 2, Input: [-0.9940833079051341, -0.3353160646271275, -0.9333105161498753, -0.8032245251010497], Output: [0.7966346376084186]\n",
      "Epoch 199/500, Loss: 0.369145776660749, Accuracy: -1.020464238345828\n",
      "Power operation: base = 0.16950982133893877, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9806658281371812, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6669232264781266, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20336536239158143, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887064694976964, 0.9818408942065969, -0.972803075497453, -0.9968930985020835]\n",
      "Layer: Layer 1, Input: [0.9887064694976964, 0.9818408942065969, -0.972803075497453, -0.9968930985020835], Output: [-0.9959961881960694, -0.5368977750549133, -0.954815629501312, -0.835251912164621]\n",
      "Layer: Layer 2, Input: [-0.9959961881960694, -0.5368977750549133, -0.954815629501312, -0.835251912164621], Output: [1.1739319430963788]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998070091526032, 0.9688166834096312, 0.03261028768451345, -0.9240546790388041]\n",
      "Layer: Layer 1, Input: [0.998070091526032, 0.9688166834096312, 0.03261028768451345, -0.9240546790388041], Output: [-0.9939907827157787, 0.15846599366662123, -0.8958313691444237, -0.8141476363971576]\n",
      "Layer: Layer 2, Input: [-0.9939907827157787, 0.15846599366662123, -0.8958313691444237, -0.8141476363971576], Output: [-0.026433606282971756]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9283551402148289, 0.1537930918082051, 0.4472045630466735, -0.8622673081429288]\n",
      "Layer: Layer 1, Input: [0.9283551402148289, 0.1537930918082051, 0.4472045630466735, -0.8622673081429288], Output: [-0.954827030762193, 0.8723600684166024, -0.7024891276775955, -0.5034974921452756]\n",
      "Layer: Layer 2, Input: [-0.954827030762193, 0.8723600684166024, -0.7024891276775955, -0.5034974921452756], Output: [-1.6630209203600128]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8786500724706924, 0.9790502353309789, -0.7896167865846391, -0.9155002809582892]\n",
      "Layer: Layer 1, Input: [0.8786500724706924, 0.9790502353309789, -0.7896167865846391, -0.9155002809582892], Output: [-0.9941222709458498, -0.33002283367353813, -0.9342637356777086, -0.8054112402337877]\n",
      "Layer: Layer 2, Input: [-0.9941222709458498, -0.33002283367353813, -0.9342637356777086, -0.8054112402337877], Output: [0.7969628560989483]\n",
      "Epoch 200/500, Loss: 0.36472616661074914, Accuracy: -1.0135564010744718\n",
      "Power operation: base = 0.17393194309637883, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9735663937170282, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6630209203600128, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20303714390105165, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887160652851401, 0.9819528728603745, -0.9728161697194002, -0.9968989891124094]\n",
      "Layer: Layer 1, Input: [0.9887160652851401, 0.9819528728603745, -0.9728161697194002, -0.9968989891124094], Output: [-0.9960206378698592, -0.5341853972366534, -0.9554692177901887, -0.8371607473584972]\n",
      "Layer: Layer 2, Input: [-0.9960206378698592, -0.5341853972366534, -0.9554692177901887, -0.8371607473584972], Output: [1.1783689348080082]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980713985793025, 0.9690062389359242, 0.03239019734871662, -0.9241784079461165]\n",
      "Layer: Layer 1, Input: [0.9980713985793025, 0.9690062389359242, 0.03239019734871662, -0.9241784079461165], Output: [-0.994028934734211, 0.16791818554456947, -0.8971955153178625, -0.8160304244858712]\n",
      "Layer: Layer 2, Input: [-0.994028934734211, 0.16791818554456947, -0.8971955153178625, -0.8160304244858712], Output: [-0.033458558780639525]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9283992596430878, 0.1568099216484309, 0.4470325144844505, -0.8624786456681668]\n",
      "Layer: Layer 1, Input: [0.9283992596430878, 0.1568099216484309, 0.4470325144844505, -0.8624786456681668], Output: [-0.9553646008938733, 0.8760800369782956, -0.7061190767986788, -0.5081320981512555]\n",
      "Layer: Layer 2, Input: [-0.9553646008938733, 0.8760800369782956, -0.7061190767986788, -0.5081320981512555], Output: [-1.6590545646798653]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8787340593429698, 0.9791785750045053, -0.7897027087633174, -0.9156428813944512]\n",
      "Layer: Layer 1, Input: [0.8787340593429698, 0.9791785750045053, -0.7897027087633174, -0.9156428813944512], Output: [-0.9941603759988137, -0.32479503722793435, -0.9351938899945644, -0.8075655849880286]\n",
      "Layer: Layer 2, Input: [-0.9941603759988137, -0.32479503722793435, -0.9351938899945644, -0.8075655849880286], Output: [0.797301256081735]\n",
      "Epoch 201/500, Loss: 0.3603643836275878, Accuracy: -1.006663684625499\n",
      "Power operation: base = 0.1783689348080082, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9665414412193605, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6590545646798653, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20269874391826503, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887255313400879, 0.9820623960718611, -0.9728290754372528, -0.9969047784198712]\n",
      "Layer: Layer 1, Input: [0.9887255313400879, 0.9820623960718611, -0.9728290754372528, -0.9969047784198712], Output: [-0.9960445666329454, -0.5315379695791681, -0.9561066712590228, -0.8390400054629215]\n",
      "Layer: Layer 2, Input: [-0.9960445666329454, -0.5315379695791681, -0.9561066712590228, -0.8390400054629215], Output: [1.182818766623491]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998072685972599, 0.9691916550789892, 0.03217337701278323, -0.9242999269329654]\n",
      "Layer: Layer 1, Input: [0.998072685972599, 0.9691916550789892, 0.03217337701278323, -0.9242999269329654], Output: [-0.9940662435684848, 0.17725851127901146, -0.8985282839929664, -0.817886105458862]\n",
      "Layer: Layer 2, Input: [-0.9940662435684848, 0.17725851127901146, -0.8985282839929664, -0.817886105458862], Output: [-0.040408284296734376]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9284426969315521, 0.15977561703598608, 0.4468630330236011, -0.8626861848698045]\n",
      "Layer: Layer 1, Input: [0.9284426969315521, 0.15977561703598608, 0.4468630330236011, -0.8626861848698045], Output: [-0.9558872328789483, 0.879688199381266, -0.7096725031609359, -0.5127004150618065]\n",
      "Layer: Layer 2, Input: [-0.9558872328789483, 0.879688199381266, -0.7096725031609359, -0.5127004150618065], Output: [-1.6550320450014866]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8788168400990755, 0.9793041037103054, -0.7897873516604418, -0.9157829785404598]\n",
      "Layer: Layer 1, Input: [0.8788168400990755, 0.9793041037103054, -0.7897873516604418, -0.9157829785404598], Output: [-0.9941976470345759, -0.31963504542438353, -0.9361014573863358, -0.8096874697335567]\n",
      "Layer: Layer 2, Input: [-0.9941976470345759, -0.31963504542438353, -0.9361014573863358, -0.8096874697335567], Output: [0.797649380393846]\n",
      "Epoch 202/500, Loss: 0.35606292887747387, Accuracy: -0.9997931469343972\n",
      "Power operation: base = 0.18281876662349106, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9595917157032656, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6550320450014866, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20235061960615397, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887348702205053, 0.9821695332967053, -0.9728417958648913, -0.9969104687822457]\n",
      "Layer: Layer 1, Input: [0.9887348702205053, 0.9821695332967053, -0.9728417958648913, -0.9969104687822457], Output: [-0.9960679886463071, -0.528956828806976, -0.9567283534988151, -0.8408896912200989]\n",
      "Layer: Layer 2, Input: [-0.9960679886463071, -0.528956828806976, -0.9567283534988151, -0.8408896912200989], Output: [1.1872794470111203]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980739541007639, 0.9693730481026449, 0.03195977332143071, -0.9244192870506708]\n",
      "Layer: Layer 1, Input: [0.9980739541007639, 0.9693730481026449, 0.03195977332143071, -0.9244192870506708], Output: [-0.994102732968534, 0.18648447174885124, -0.8998302629904071, -0.8197145823892287]\n",
      "Layer: Layer 2, Input: [-0.994102732968534, 0.18648447174885124, -0.8998302629904071, -0.8197145823892287], Output: [-0.04728227664535334]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9284854657934152, 0.16269117861596816, 0.4466960775493925, -0.8628900129003121]\n",
      "Layer: Layer 1, Input: [0.9284854657934152, 0.16269117861596816, 0.4466960775493925, -0.8628900129003121], Output: [-0.9563954543573296, 0.883186984537015, -0.7131504720303627, -0.5172023376800925]\n",
      "Layer: Layer 2, Input: [-0.9563954543573296, 0.883186984537015, -0.7131504720303627, -0.5172023376800925], Output: [-1.6509610160587556]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8788984386416623, 0.9794269007530693, -0.7898707369598892, -0.9159206301234825]\n",
      "Layer: Layer 1, Input: [0.8788984386416623, 0.9794269007530693, -0.7898707369598892, -0.9159206301234825], Output: [-0.9942341074489682, -0.314545010424456, -0.936986926886753, -0.8117768629651387]\n",
      "Layer: Layer 2, Input: [-0.9942341074489682, -0.314545010424456, -0.936986926886753, -0.8117768629651387], Output: [0.7980067442184233]\n",
      "Epoch 203/500, Loss: 0.35182404286908525, Accuracy: -0.9929514422060992\n",
      "Power operation: base = 0.18727944701112031, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9527177233546467, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6509610160587556, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20199325578157667, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887440844661615, 0.9822743523434871, -0.9728543342476315, -0.9969160625241347]\n",
      "Layer: Layer 1, Input: [0.9887440844661615, 0.9822743523434871, -0.9728543342476315, -0.9969160625241347], Output: [-0.9960909177516154, -0.5264431455512409, -0.9573346327793067, -0.8427098577704226]\n",
      "Layer: Layer 2, Input: [-0.9960909177516154, -0.5264431455512409, -0.9573346327793067, -0.8427098577704226], Output: [1.191749030105747]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980752033563488, 0.9695505315720353, 0.03174933214206315, -0.9245365387124254]\n",
      "Layer: Layer 1, Input: [0.9980752033563488, 0.9695505315720353, 0.03174933214206315, -0.9245365387124254], Output: [-0.9941384261056918, 0.19559389944329258, -0.9011020598562449, -0.8215158090539381]\n",
      "Layer: Layer 2, Input: [-0.9941384261056918, 0.19559389944329258, -0.9011020598562449, -0.8215158090539381], Output: [-0.05408025165456953]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9285275798700062, 0.16555760777239817, 0.4465316062729647, -0.8630902158833709]\n",
      "Layer: Layer 1, Input: [0.9285275798700062, 0.16555760777239817, 0.4465316062729647, -0.8630902158833709], Output: [-0.9568897742060749, 0.8865788836116208, -0.716554126240429, -0.5216378672667206]\n",
      "Layer: Layer 2, Input: [-0.9568897742060749, 0.8865788836116208, -0.716554126240429, -0.5216378672667206], Output: [-1.6468488846438505]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8789788787342177, 0.9795470435729517, -0.7899528865856864, -0.9160558931335756]\n",
      "Layer: Layer 1, Input: [0.8789788787342177, 0.9795470435729517, -0.7899528865856864, -0.9160558931335756], Output: [-0.9942697800699769, -0.3095268732611785, -0.9378507958641323, -0.8138337880859596]\n",
      "Layer: Layer 2, Input: [-0.9942697800699769, -0.3095268732611785, -0.9378507958641323, -0.8138337880859596], Output: [0.7983728421006857]\n",
      "Epoch 204/500, Loss: 0.3476497128059814, Accuracy: -0.9861448209943422\n",
      "Power operation: base = 0.19174903010574695, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9459197483454305, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6468488846438505, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2016271578993143, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887531765968113, 0.9823769193807673, -0.9728666938565553, -0.9969215619360308]\n",
      "Layer: Layer 1, Input: [0.9887531765968113, 0.9823769193807673, -0.9728666938565553, -0.9969215619360308], Output: [-0.9961133674735628, -0.5239979308946988, -0.9579258805135563, -0.8445006036041759]\n",
      "Layer: Layer 2, Input: [-0.9961133674735628, -0.5239979308946988, -0.9579258805135563, -0.8445006036041759], Output: [1.1962256220761889]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980764341292481, 0.9697242163601227, 0.03154199867565198, -0.9246517316651954]\n",
      "Layer: Layer 1, Input: [0.9980764341292481, 0.9697242163601227, 0.03154199867565198, -0.9246517316651954], Output: [-0.9941733455796538, 0.20458494364996807, -0.9023442983236142, -0.8232897870846506]\n",
      "Layer: Layer 2, Input: [-0.9941733455796538, 0.20458494364996807, -0.9023442983236142, -0.8232897870846506], Output: [-0.06080213045346383]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9285690527171394, 0.16837590491922189, 0.4463695768212393, -0.8632868788608304]\n",
      "Layer: Layer 1, Input: [0.9285690527171394, 0.16837590491922189, 0.4463695768212393, -0.8632868788608304], Output: [-0.9573706831142598, 0.8898664362327476, -0.7198846764612002, -0.5260071060427091]\n",
      "Layer: Layer 2, Input: [-0.9573706831142598, 0.8898664362327476, -0.7198846764612002, -0.5260071060427091], Output: [-1.6427027954119302]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8790581839801214, 0.9796646077521015, -0.7900338226612916, -0.916188823793933]\n",
      "Layer: Layer 1, Input: [0.8790581839801214, 0.9796646077521015, -0.7900338226612916, -0.916188823793933], Output: [-0.9943046871645267, -0.30458237120895293, -0.9386935677803392, -0.8158583201137315]\n",
      "Layer: Layer 2, Input: [-0.9943046871645267, -0.30458237120895293, -0.9386935677803392, -0.8158583201137315], Output: [0.7987471543810756]\n",
      "Epoch 205/500, Loss: 0.34354168100499094, Accuracy: -0.9793791326535797\n",
      "Power operation: base = 0.19622562207618888, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9391978695465362, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6427027954119302, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20125284561892443, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887621491103925, 0.9824772989461459, -0.9728788779829315, -0.9969269692734278]\n",
      "Layer: Layer 1, Input: [0.9887621491103925, 0.9824772989461459, -0.9728788779829315, -0.9969269692734278], Output: [-0.9961353510222524, -0.5216220431602783, -0.9585024698454963, -0.8462620694900234]\n",
      "Layer: Layer 2, Input: [-0.9961353510222524, -0.5216220431602783, -0.9585024698454963, -0.8462620694900234], Output: [1.2007073865415956]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980776468063464, 0.9698942106578784, 0.03133771756544952, -0.9247649149632264]\n",
      "Layer: Layer 1, Input: [0.9980776468063464, 0.9698942106578784, 0.03133771756544952, -0.9247649149632264], Output: [-0.9942075134254591, 0.2134560551801515, -0.9035576150135303, -0.8250365630670218]\n",
      "Layer: Layer 2, Input: [-0.9942075134254591, 0.2134560551801515, -0.9035576150135303, -0.8250365630670218], Output: [-0.06744802304635567]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9286098977919968, 0.17114706788654416, 0.446209946325059, -0.8634800857427006]\n",
      "Layer: Layer 1, Input: [0.9286098977919968, 0.17114706788654416, 0.446209946325059, -0.8634800857427006], Output: [-0.9578386541463245, 0.8930522177094776, -0.7231433919853477, -0.5303102515287051]\n",
      "Layer: Layer 2, Input: [-0.9578386541463245, 0.8930522177094776, -0.7231433919853477, -0.5303102515287051], Output: [-1.6385296194404786]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8791363778022518, 0.9797796670235891, -0.7901135674696945, -0.916319477532735]\n",
      "Layer: Layer 1, Input: [0.8791363778022518, 0.9797796670235891, -0.7901135674696945, -0.916319477532735], Output: [-0.9943388504452654, -0.29971304556441253, -0.93951575012157, -0.8178505823450875]\n",
      "Layer: Layer 2, Input: [-0.9943388504452654, -0.29971304556441253, -0.93951575012157, -0.8178505823450875], Output: [0.7991291530332028]\n",
      "Epoch 206/500, Loss: 0.33950145419911715, Accuracy: -0.9726598299025158\n",
      "Power operation: base = 0.2007073865415956, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9325519769536443, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6385296194404786, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20087084696679725, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988771004481257, 0.982575553957327, -0.9728908899327708, -0.9969322867559887]\n",
      "Layer: Layer 1, Input: [0.988771004481257, 0.982575553957327, -0.9728908899327708, -0.9969322867559887], Output: [-0.9961568812956938, -0.5193161948645253, -0.9590647743582946, -0.8479944354084171]\n",
      "Layer: Layer 2, Input: [-0.9961568812956938, -0.5193161948645253, -0.9590647743582946, -0.8479944354084171], Output: [1.2051925490769562]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980788417711794, 0.9700606199881546, 0.03113643300293101, -0.9248761369433368]\n",
      "Layer: Layer 1, Input: [0.9980788417711794, 0.9700606199881546, 0.03113643300293101, -0.9248761369433368], Output: [-0.9942409511205589, 0.22220597080187152, -0.904742656374899, -0.8267562256176607]\n",
      "Layer: Layer 2, Input: [-0.9942409511205589, 0.22220597080187152, -0.904742656374899, -0.8267562256176607], Output: [-0.07401821229185401]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9286501284406169, 0.17387209040463877, 0.4460526715050868, -0.8636699192604972]\n",
      "Layer: Layer 1, Input: [0.9286501284406169, 0.17387209040463877, 0.4460526715050868, -0.8636699192604972], Output: [-0.9582941432942578, 0.8961388272608849, -0.7263315920486343, -0.5345475907808656]\n",
      "Layer: Layer 2, Input: [-0.9582941432942578, 0.8961388272608849, -0.7263315920486343, -0.5345475907808656], Output: [-1.6343359453674755]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8792134834232962, 0.9798922932827256, -0.7901921434145605, -0.9164479089568216]\n",
      "Layer: Layer 1, Input: [0.8792134834232962, 0.9798922932827256, -0.7901921434145605, -0.9164479089568216], Output: [-0.9943722910774222, -0.29492024973382147, -0.9403178524986835, -0.819810743010346]\n",
      "Layer: Layer 2, Input: [-0.9943722910774222, -0.29492024973382147, -0.9403178524986835, -0.819810743010346], Output: [0.7995183069061524]\n",
      "Epoch 207/500, Loss: 0.3355303135537244, Accuracy: -0.9659919752464252\n",
      "Power operation: base = 0.20519254907695617, power = 2, grad = 0.25\n",
      "Power operation: base = 0.925981787708146, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6343359453674755, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20048169309384756, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887797451584552, 0.9826717457251586, -0.9729027330215374, -0.9969375165667759]\n",
      "Layer: Layer 1, Input: [0.9887797451584552, 0.9826717457251586, -0.9729027330215374, -0.9969375165667759], Output: [-0.996177970882445, -0.5170809597657354, -0.9596131669002965, -0.8496979175147715]\n",
      "Layer: Layer 2, Input: [-0.996177970882445, -0.5170809597657354, -0.9596131669002965, -0.8496979175147715], Output: [1.2096794008561167]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980800194036127, 0.9702235472231686, 0.030938088830460495, -0.9249854452021521]\n",
      "Layer: Layer 1, Input: [0.9980800194036127, 0.9702235472231686, 0.030938088830460495, -0.9249854452021521], Output: [-0.9942736795920261, 0.2308336975331733, -0.9059000758611853, -0.8284489024648609]\n",
      "Layer: Layer 2, Input: [-0.9942736795920261, 0.2308336975331733, -0.9059000758611853, -0.8284489024648609], Output: [-0.08051313838282903]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9286897578860477, 0.176551960687153, 0.4458977087550603, -0.8638564609241741]\n",
      "Layer: Layer 1, Input: [0.9286897578860477, 0.176551960687153, 0.4458977087550603, -0.8638564609241741], Output: [-0.958737590018846, 0.8991288772379299, -0.7294506376944122, -0.5387194945784292]\n",
      "Layer: Layer 2, Input: [-0.958737590018846, 0.8991288772379299, -0.7294506376944122, -0.5387194945784292], Output: [-1.6301280729232799]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8792895238469033, 0.980002556600729, -0.7902695729826119, -0.9165741718273763]\n",
      "Layer: Layer 1, Input: [0.8792895238469033, 0.980002556600729, -0.7902695729826119, -0.9165741718273763], Output: [-0.9944050296857924, -0.2902051575331975, -0.9411003849132409, -0.821739011947194]\n",
      "Layer: Layer 2, Input: [-0.9944050296857924, -0.2902051575331975, -0.9411003849132409, -0.821739011947194], Output: [0.7999140863807082]\n",
      "Epoch 208/500, Loss: 0.3316293252362119, Accuracy: -0.9593802490158594\n",
      "Power operation: base = 0.2096794008561167, power = 2, grad = 0.25\n",
      "Power operation: base = 0.919486861617171, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6301280729232799, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20008591361929184, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887883735640873, 0.9827659339685879, -0.9729144105690491, -0.9969426608515536]\n",
      "Layer: Layer 1, Input: [0.9887883735640873, 0.9827659339685879, -0.9729144105690491, -0.9969426608515536], Output: [-0.9961986320644235, -0.5149167799452705, -0.9601480185244707, -0.8513727651540437]\n",
      "Layer: Layer 2, Input: [-0.9961986320644235, -0.5149167799452705, -0.9601480185244707, -0.8513727651540437], Output: [1.2141663014870256]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980811800795382, 0.9703830926054856, 0.0307426286402547, -0.9250928865753791]\n",
      "Layer: Layer 1, Input: [0.9980811800795382, 0.9703830926054856, 0.0307426286402547, -0.9250928865753791], Output: [-0.9943057192239492, 0.23933849692977552, -0.90703053133896, -0.8301147575561469]\n",
      "Layer: Layer 2, Input: [-0.9943057192239492, 0.23933849692977552, -0.90703053133896, -0.8301147575561469], Output: [-0.0869333839038462]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9287287992172067, 0.17918766011392548, 0.4457450142220668, -0.8640397909828165]\n",
      "Layer: Layer 1, Input: [0.9287287992172067, 0.17918766011392548, 0.4457450142220668, -0.8640397909828165], Output: [-0.9591694177801128, 0.9020249833138619, -0.7325019241846207, -0.5428264116124737]\n",
      "Layer: Layer 2, Input: [-0.9591694177801128, 0.9020249833138619, -0.7325019241846207, -0.5428264116124737], Output: [-1.625912008665943]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8793645218397844, 0.9801105252406657, -0.7903458787074107, -0.9166983190377558]\n",
      "Layer: Layer 1, Input: [0.8793645218397844, 0.9801105252406657, -0.7903458787074107, -0.9166983190377558], Output: [-0.9944370863618983, -0.28556877161761596, -0.9418638561841073, -0.823635637318318]\n",
      "Layer: Layer 2, Input: [-0.9944370863618983, -0.28556877161761596, -0.9418638561841073, -0.823635637318318], Output: [0.8003159674573204]\n",
      "Epoch 209/500, Loss: 0.32779935139166355, Accuracy: -0.9528289587918022\n",
      "Power operation: base = 0.21416630148702565, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9130666160961538, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6259120086659431, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19968403254267963, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887968920917339, 0.9828581768314527, -0.9729259258945799, -0.9969477217181659]\n",
      "Layer: Layer 1, Input: [0.9887968920917339, 0.9828581768314527, -0.9729259258945799, -0.9969477217181659], Output: [-0.9962188768199094, -0.5128239728685339, -0.9606696975366036, -0.8530192579452524]\n",
      "Layer: Layer 2, Input: [-0.9962188768199094, -0.5128239728685339, -0.9606696975366036, -0.8530192579452524], Output: [1.2186516810981498]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980823241705898, 0.970539353772355, 0.03054999586929977, -0.9251985071191946]\n",
      "Layer: Layer 1, Input: [0.9980823241705898, 0.970539353772355, 0.03054999586929977, -0.9251985071191946], Output: [-0.994337089865035, 0.24771986948423314, -0.9081346827217214, -0.8317539882126886]\n",
      "Layer: Layer 2, Input: [-0.994337089865035, 0.24771986948423314, -0.9081346827217214, -0.8317539882126886], Output: [-0.09327965952505846]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.928767265378482, 0.18178016201294062, 0.4455945438835678, -0.8642199883891936]\n",
      "Layer: Layer 1, Input: [0.928767265378482, 0.18178016201294062, 0.4455945438835678, -0.8642199883891936], Output: [-0.959590034556996, 0.9048297556107437, -0.7354868739536882, -0.5468688627198366]\n",
      "Layer: Layer 2, Input: [-0.959590034556996, 0.9048297556107437, -0.7354868739536882, -0.5468688627198366], Output: [-1.621693463728148]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8794384999148503, 0.9802162656755729, -0.7904210831346657, -0.9168204025935576]\n",
      "Layer: Layer 1, Input: [0.8794384999148503, 0.9802162656755729, -0.7904210831346657, -0.9168204025935576], Output: [-0.9944684806713491, -0.2810119319659937, -0.9426087725284494, -0.8255009023945974]\n",
      "Layer: Layer 2, Input: [-0.9944684806713491, -0.2810119319659937, -0.9426087725284494, -0.8255009023945974], Output: [0.8007234352999841]\n",
      "Epoch 210/500, Loss: 0.32404106138974564, Accuracy: -0.9463420500012552\n",
      "Power operation: base = 0.2186516810981498, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9067203404749415, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6216934637281479, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19927656470001587, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888053031049775, 0.982948530901012, -0.9729372823121885, -0.9969527012359931]\n",
      "Layer: Layer 1, Input: [0.9888053031049775, 0.982948530901012, -0.9729372823121885, -0.9969527012359931], Output: [-0.996238716826754, -0.5108027383796278, -0.961178568646983, -0.854637702951511]\n",
      "Layer: Layer 2, Input: [-0.996238716826754, -0.5108027383796278, -0.961178568646983, -0.854637702951511], Output: [1.2231340417377017]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980834520438805, 0.9706924257832219, 0.030360133889953806, -0.9253023520937809]\n",
      "Layer: Layer 1, Input: [0.9980834520438805, 0.9706924257832219, 0.030360133889953806, -0.9253023520937809], Output: [-0.994367810836441, 0.25597753923754396, -0.9092131898209025, -0.8333668223477578]\n",
      "Layer: Layer 2, Input: [-0.994367810836441, 0.25597753923754396, -0.9092131898209025, -0.8333668223477578], Output: [-0.09955279037595322]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9288051691600947, 0.1843304305401689, 0.44544625362095797, -0.8643971307682256]\n",
      "Layer: Layer 1, Input: [0.9288051691600947, 0.1843304305401689, 0.44544625362095797, -0.8643971307682256], Output: [-0.9599998333562413, 0.9075457907237581, -0.7384069300966004, -0.5508474352007541]\n",
      "Layer: Layer 2, Input: [-0.9599998333562413, 0.9075457907237581, -0.7384069300966004, -0.5508474352007541], Output: [-1.6174778533853522]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8795114803154482, 0.9803198426086438, -0.7904952087891759, -0.9169404735949855]\n",
      "Layer: Layer 1, Input: [0.8795114803154482, 0.9803198426086438, -0.7904952087891759, -0.9169404735949855], Output: [-0.9944992316614253, -0.27653532435697614, -0.943335636290149, -0.8273351224222076]\n",
      "Layer: Layer 2, Input: [-0.9944992316614253, -0.27653532435697614, -0.943335636290149, -0.8273351224222076], Output: [0.8011359872652766]\n",
      "Epoch 211/500, Loss: 0.3203549432210683, Accuracy: -0.9399231174818241\n",
      "Power operation: base = 0.22313404173770168, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9004472096240468, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6174778533853522, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19886401273472343, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888136089360202, 0.9830370512281061, -0.9729484831262785, -0.9969576014354907]\n",
      "Layer: Layer 1, Input: [0.9888136089360202, 0.9830370512281061, -0.9729484831262785, -0.9969576014354907], Output: [-0.9962581634657957, -0.5088531655906543, -0.9616749922199447, -0.8562284319483688]\n",
      "Layer: Layer 2, Input: [-0.9962581634657957, -0.5088531655906543, -0.9616749922199447, -0.8562284319483688], Output: [1.2276119581484481]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980845640617582, 0.9708424011502179, 0.030172986096029045, -0.9254044659490205]\n",
      "Layer: Layer 1, Input: [0.9980845640617582, 0.9708424011502179, 0.030172986096029045, -0.9254044659490205], Output: [-0.9943979009398439, 0.26411143868907205, -0.910266710404837, -0.8349535157636716]\n",
      "Layer: Layer 2, Input: [-0.9943979009398439, 0.26411143868907205, -0.910266710404837, -0.8349535157636716], Output: [-0.10575370312871613]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9288425231892342, 0.18683941965537046, 0.4453000992894997, -0.8645712943893675]\n",
      "Layer: Layer 1, Input: [0.9288425231892342, 0.18683941965537046, 0.4453000992894997, -0.8645712943893675], Output: [-0.9603991927104509, 0.9101756646004723, -0.7412635503780948, -0.5547627772535285]\n",
      "Layer: Layer 2, Input: [-0.9603991927104509, 0.9101756646004723, -0.7412635503780948, -0.5547627772535285], Output: [-1.6132702982587717]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8795834850007495, 0.9804213189953487, -0.7905682781434763, -0.9170585822215322]\n",
      "Layer: Layer 1, Input: [0.8795834850007495, 0.9804213189953487, -0.7905682781434763, -0.9170585822215322], Output: [-0.9945293578688954, -0.27213948878024596, -0.9440449448080759, -0.8291386415888916]\n",
      "Layer: Layer 2, Input: [-0.9945293578688954, -0.27213948878024596, -0.9440449448080759, -0.8291386415888916], Output: [0.8015531354491952]\n",
      "Epoch 212/500, Loss: 0.31674131493415586, Accuracy: -0.9335754178293085\n",
      "Power operation: base = 0.22761195814844815, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8942462968712839, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6132702982587717, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19844686455080485, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888218118844055, 0.9831237913488268, -0.9729595316274062, -0.9969624243078079]\n",
      "Layer: Layer 1, Input: [0.9888218118844055, 0.9831237913488268, -0.9729595316274062, -0.9969624243078079], Output: [-0.9962772278244907, -0.5069752396329653, -0.9621593236154224, -0.857791798800693]\n",
      "Layer: Layer 2, Input: [-0.9962772278244907, -0.5069752396329653, -0.9621593236154224, -0.857791798800693], Output: [1.232084077980839]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980856605815841, 0.9709893698714167, 0.029988495984212826, -0.9255048923123338]\n",
      "Layer: Layer 1, Input: [0.9980856605815841, 0.9709893698714167, 0.029988495984212826, -0.9255048923123338], Output: [-0.9944273784657475, 0.2721216940767254, -0.9112958984555946, -0.836514349539115]\n",
      "Layer: Layer 2, Input: [-0.9944273784657475, 0.2721216940767254, -0.9112958984555946, -0.836514349539115], Output: [-0.11188341380904454]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9288793399219695, 0.18930807219137352, 0.44515603678452087, -0.8647425541428683]\n",
      "Layer: Layer 1, Input: [0.9288793399219695, 0.18930807219137352, 0.44515603678452087, -0.8647425541428683], Output: [-0.9607884771652035, 0.9127219262290355, -0.7440582017464695, -0.5586155925545385]\n",
      "Layer: Layer 2, Input: [-0.9607884771652035, 0.9127219262290355, -0.7440582017464695, -0.5586155925545385], Output: [-1.6090756269727347]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8796545356323131, 0.9805207560673463, -0.7906403135882478, -0.9171747777189777]\n",
      "Layer: Layer 1, Input: [0.8796545356323131, 0.9805207560673463, -0.7906403135882478, -0.9171747777189777], Output: [-0.994558877328068, -0.26782482773564237, -0.944737189416262, -0.8309118301017949]\n",
      "Layer: Layer 2, Input: [-0.994558877328068, -0.26782482773564237, -0.944737189416262, -0.8309118301017949], Output: [0.8019744087868919]\n",
      "Epoch 213/500, Loss: 0.31320033601680597, Accuracy: -0.9273018823576373\n",
      "Power operation: base = 0.23208407798083908, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8881165861909555, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6090756269727347, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19802559121310814, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888299142158472, 0.9832088033075693, -0.9729704310883361, -0.9969671718044902]\n",
      "Layer: Layer 1, Input: [0.9888299142158472, 0.9832088033075693, -0.9729704310883361, -0.9969671718044902], Output: [-0.9962959207007509, -0.5051688482434447, -0.9626319126165213, -0.85932817695596]\n",
      "Layer: Layer 2, Input: [-0.9962959207007509, -0.5051688482434447, -0.9626319126165213, -0.85932817695596], Output: [1.2365491215060902]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980867419555314, 0.9711334194666283, 0.029806607230743753, -0.9256036739786198]\n",
      "Layer: Layer 1, Input: [0.9980867419555314, 0.9711334194666283, 0.029806607230743753, -0.9256036739786198], Output: [-0.9944562612020217, 0.2800086110866256, -0.9123014026130036, -0.8380496275163795]\n",
      "Layer: Layer 2, Input: [-0.9944562612020217, 0.2800086110866256, -0.9123014026130036, -0.8380496275163795], Output: [-0.11794301634214532]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9289156316359313, 0.1917373190138739, 0.4450140221038083, -0.864910983519832]\n",
      "Layer: Layer 1, Input: [0.9289156316359313, 0.1917373190138739, 0.4450140221038083, -0.864910983519832], Output: [-0.9611680377551318, 0.9151870920872041, -0.7467923553327335, -0.5624066350072098]\n",
      "Layer: Layer 2, Input: [-0.9611680377551318, 0.9151870920872041, -0.7467923553327335, -0.5624066350072098], Output: [-1.6048983800935652]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8797246535618434, 0.980618213358042, -0.7907113374045167, -0.9172891083886727]\n",
      "Layer: Layer 1, Input: [0.8797246535618434, 0.980618213358042, -0.7907113374045167, -0.9172891083886727], Output: [-0.9945878075790763, -0.26359161437984713, -0.9454128545677829, -0.832655081386613]\n",
      "Layer: Layer 2, Input: [-0.9945878075790763, -0.26359161437984713, -0.9454128545677829, -0.832655081386613], Output: [0.8023993547415755]\n",
      "Epoch 214/500, Loss: 0.30973201863781524, Accuracy: -0.9211051305159346\n",
      "Power operation: base = 0.2365491215060902, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8820569836578547, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6048983800935652, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19760064525842447, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888379181611683, 0.9832921376813376, -0.9729811847603503, -0.9969718458372593]\n",
      "Layer: Layer 1, Input: [0.9888379181611683, 0.9832921376813376, -0.9729811847603503, -0.9969718458372593], Output: [-0.9963142526069845, -0.503433788164043, -0.9630931029371017, -0.8608379570597056]\n",
      "Layer: Layer 2, Input: [-0.9963142526069845, -0.503433788164043, -0.9630931029371017, -0.8608379570597056], Output: [1.2410058808889417]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980878085304042, 0.9712746350155027, 0.029627263763299033, -0.9257008529022503]\n",
      "Layer: Layer 1, Input: [0.9980878085304042, 0.9712746350155027, 0.029627263763299033, -0.9257008529022503], Output: [-0.9944845664426643, 0.28777266103993127, -0.9132838647948163, -0.8395596738958945]\n",
      "Layer: Layer 2, Input: [-0.9944845664426643, 0.28777266103993127, -0.9132838647948163, -0.8395596738958945], Output: [-0.12393367183295467]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9289514104237543, 0.19412807826841996, 0.44487401140616645, -0.865076654595978]\n",
      "Layer: Layer 1, Input: [0.9289514104237543, 0.19412807826841996, 0.44487401140616645, -0.865076654595978], Output: [-0.961538212468858, 0.917573641302974, -0.7494674819137237, -0.5661367036791785]\n",
      "Layer: Layer 2, Input: [-0.961538212468858, 0.917573641302974, -0.7494674819137237, -0.5661367036791785], Output: [-1.6007428151858856]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8797938598201398, 0.9807137487296334, -0.7907813717376584, -0.9174016215790562]\n",
      "Layer: Layer 1, Input: [0.8797938598201398, 0.9807137487296334, -0.7907813717376584, -0.9174016215790562], Output: [-0.994616165676384, -0.25944000048713733, -0.9460724170740626, -0.8343688094153949]\n",
      "Layer: Layer 2, Input: [-0.994616165676384, -0.25944000048713733, -0.9460724170740626, -0.8343688094153949], Output: [0.8028275406193597]\n",
      "Epoch 215/500, Loss: 0.3063362386767043, Accuracy: -0.9149874836225129\n",
      "Power operation: base = 0.2410058808889417, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8760663281670453, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6007428151858856, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19717245938064032, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888458259153499, 0.9833738436051688, -0.9729917958698128, -0.9969764482778742]\n",
      "Layer: Layer 1, Input: [0.9888458259153499, 0.9833738436051688, -0.9729917958698128, -0.9969764482778742], Output: [-0.9963322337743287, -0.5017697713374348, -0.9635432318034218, -0.8623215446969696]\n",
      "Layer: Layer 2, Input: [-0.9963322337743287, -0.5017697713374348, -0.9635432318034218, -0.8623215446969696], Output: [1.2454532190772594]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998088860647478, 0.9714130991977067, 0.029450409828104842, -0.9257964701910485]\n",
      "Layer: Layer 1, Input: [0.998088860647478, 0.9714130991977067, 0.029450409828104842, -0.9257964701910485], Output: [-0.9945123109967702, 0.29541446759408085, -0.9142439189817823, -0.8410448309434844]\n",
      "Layer: Layer 2, Input: [-0.9945123109967702, 0.29541446759408085, -0.9142439189817823, -0.8410448309434844], Output: [-0.12985659857242915]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9289866881872616, 0.19648125471095243, 0.4447359610661475, -0.8652396380189706]\n",
      "Layer: Layer 1, Input: [0.9289866881872616, 0.19648125471095243, 0.4447359610661475, -0.8652396380189706], Output: [-0.9618993267026755, 0.9198840114772888, -0.7520850478162918, -0.5698066379428607]\n",
      "Layer: Layer 2, Input: [-0.9618993267026755, 0.9198840114772888, -0.7520850478162918, -0.5698066379428607], Output: [-1.5966129128318702]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8798621751072327, 0.9808074184014938, -0.7908504385732044, -0.917512363679342]\n",
      "Layer: Layer 1, Input: [0.8798621751072327, 0.9808074184014938, -0.7908504385732044, -0.917512363679342], Output: [-0.9946439681975006, -0.2553700241967635, -0.9467163454513333, -0.8360534461681964]\n",
      "Layer: Layer 2, Input: [-0.9946439681975006, -0.2553700241967635, -0.9467163454513333, -0.8360534461681964], Output: [0.8032585545464976]\n",
      "Epoch 216/500, Loss: 0.3030127464800485, Accuracy: -0.9089509787902028\n",
      "Power operation: base = 0.24545321907725937, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8701434014275709, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5966129128318702, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19674144545350236, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888536396366917, 0.9834539687985457, -0.9730022676149844, -0.9969809809580666]\n",
      "Layer: Layer 1, Input: [0.9888536396366917, 0.9834539687985457, -0.9730022676149844, -0.9969809809580666], Output: [-0.9963498741570634, -0.5001764308856802, -0.9639826296039911, -0.8637793582618931]\n",
      "Layer: Layer 2, Input: [-0.9963498741570634, -0.5001764308856802, -0.9639826296039911, -0.8637793582618931], Output: [1.2498900683625496]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980898986423589, 0.9715488923349427, 0.029275990052309256, -0.9258905661021667]\n",
      "Layer: Layer 1, Input: [0.9980898986423589, 0.9715488923349427, 0.029275990052309256, -0.9258905661021667], Output: [-0.9945395111976892, 0.30293479398647716, -0.9151821901564047, -0.8425054568140369]\n",
      "Layer: Layer 2, Input: [-0.9945395111976892, 0.30293479398647716, -0.9151821901564047, -0.8425054568140369], Output: [-0.1357130627558587]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9290214766323722, 0.1987977391180455, 0.44459982772498574, -0.8654000029991706]\n",
      "Layer: Layer 1, Input: [0.9290214766323722, 0.1987977391180455, 0.44459982772498574, -0.8654000029991706], Output: [-0.9622516937028862, 0.9221205951196737, -0.7546465112386596, -0.573417312830974]\n",
      "Layer: Layer 2, Input: [-0.9622516937028862, 0.9221205951196737, -0.7546465112386596, -0.573417312830974], Output: [-1.5925123834691317]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8799296197836811, 0.9808992769797348, -0.7909185597144316, -0.9176213801152892]\n",
      "Layer: Layer 1, Input: [0.8799296197836811, 0.9808992769797348, -0.7909185597144316, -0.9176213801152892], Output: [-0.9946712312518874, -0.25138161752492216, -0.9473450993661094, -0.8377094392318414]\n",
      "Layer: Layer 2, Input: [-0.9946712312518874, -0.25138161752492216, -0.9473450993661094, -0.8377094392318414], Output: [0.8036920061445154]\n",
      "Epoch 217/500, Loss: 0.2997611772932336, Accuracy: -0.9029973829313072\n",
      "Power operation: base = 0.24989006836254957, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8642869372441413, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5925123834691317, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19630799385548459, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888613614460809, 0.983532559592666, -0.973012603163089, -0.9969854456695483]\n",
      "Layer: Layer 1, Input: [0.9888613614460809, 0.983532559592666, -0.973012603163089, -0.9969854456695483], Output: [-0.9963671834371923, -0.49865332686240105, -0.9644116196019723, -0.8652118269561503]\n",
      "Layer: Layer 2, Input: [-0.9963671834371923, -0.49865332686240105, -0.9644116196019723, -0.8652118269561503], Output: [1.2543154286621148]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980909228448622, 0.9716820924345779, 0.029103949501691227, -0.9259831800397845]\n",
      "Layer: Layer 1, Input: [0.9980909228448622, 0.9716820924345779, 0.029103949501691227, -0.9259831800397845], Output: [-0.9945661829123503, 0.31033453084037194, -0.9160992933842647, -0.8439419234937376]\n",
      "Layer: Layer 2, Input: [-0.9945661829123503, 0.31033453084037194, -0.9160992933842647, -0.8439419234937376], Output: [-0.14150436989425508]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9290557872647036, 0.20107840777284175, 0.4444655683377954, -0.8655578173036484]\n",
      "Layer: Layer 1, Input: [0.9290557872647036, 0.20107840777284175, 0.4444655683377954, -0.8655578173036484], Output: [-0.9625956149967148, 0.9242857366485636, -0.7571533189644554, -0.5769696346152454]\n",
      "Layer: Layer 2, Input: [-0.9625956149967148, 0.9242857366485636, -0.7571533189644554, -0.5769696346152454], Output: [-1.5884446749134262]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8799962138630066, 0.9809893774877978, -0.7909857567617079, -0.9177287153469688]\n",
      "Layer: Layer 1, Input: [0.8799962138630066, 0.9809893774877978, -0.7909857567617079, -0.9177287153469688], Output: [-0.9946979704900346, -0.24747461362416429, -0.9479591291717412, -0.8393372495373711]\n",
      "Layer: Layer 2, Input: [-0.9946979704900346, -0.24747461362416429, -0.9479591291717412, -0.8393372495373711], Output: [0.8041275269375081]\n",
      "Epoch 218/500, Loss: 0.29658106132595996, Accuracy: -0.8971282067437778\n",
      "Power operation: base = 0.25431542866211476, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8584956301057449, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5884446749134262, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1958724730624919, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888689934263678, 0.9836096609584419, -0.9730228056476224, -0.9969898441640893]\n",
      "Layer: Layer 1, Input: [0.9888689934263678, 0.9836096609584419, -0.9730228056476224, -0.9969898441640893], Output: [-0.9963841710291734, -0.497199951772046, -0.9648305177046683, -0.8666193889156317]\n",
      "Layer: Layer 2, Input: [-0.9963841710291734, -0.497199951772046, -0.9648305177046683, -0.8666193889156317], Output: [1.2587283655699006]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998091933578911, 0.9718127752346625, 0.028934233733806106, -0.9260743505545207]\n",
      "Layer: Layer 1, Input: [0.998091933578911, 0.9718127752346625, 0.028934233733806106, -0.9260743505545207], Output: [-0.9945923415507356, 0.3176146845455297, -0.916995833027047, -0.8453546148616643]\n",
      "Layer: Layer 2, Input: [-0.9945923415507356, 0.3176146845455297, -0.916995833027047, -0.8453546148616643], Output: [-0.1472318568961266]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9290896313858439, 0.20332412202257422, 0.44433314021711207, -0.8657131472532845]\n",
      "Layer: Layer 1, Input: [0.9290896313858439, 0.20332412202257422, 0.44433314021711207, -0.8657131472532845], Output: [-0.9629313808117436, 0.9263817299094718, -0.7596069034447599, -0.5804645366135971]\n",
      "Layer: Layer 2, Input: [-0.9629313808117436, 0.9263817299094718, -0.7596069034447599, -0.5804645366135971], Output: [-1.5844129804429072]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8800619770052275, 0.9810777713979253, -0.7910520510935498, -0.9178344128684228]\n",
      "Layer: Layer 1, Input: [0.8800619770052275, 0.9810777713979253, -0.7910520510935498, -0.9178344128684228], Output: [-0.9947242011126921, -0.24364875377731585, -0.9485588755283616, -0.8409373492362883]\n",
      "Layer: Layer 2, Input: [-0.9947242011126921, -0.24364875377731585, -0.9485588755283616, -0.8409373492362883], Output: [0.8045647705241223]\n",
      "Epoch 219/500, Loss: 0.2934718334184378, Accuracy: -0.8913447185925589\n",
      "Power operation: base = 0.25872836556990064, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8527681431038734, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5844129804429072, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19543522947587766, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888765376218461, 0.9836853165351076, -0.9730328781658978, -0.9969941781536601]\n",
      "Layer: Layer 1, Input: [0.9888765376218461, 0.9836853165351076, -0.9730328781658978, -0.9969941781536601], Output: [-0.9964008460847882, -0.49581573585249805, -0.9652396322848785, -0.8680024894637085]\n",
      "Layer: Layer 2, Input: [-0.9964008460847882, -0.49581573585249805, -0.9652396322848785, -0.8680024894637085], Output: [1.2631280082193315]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980929311624503, 0.9719410142501177, 0.028766788846696933, -0.9261641153444675]\n",
      "Layer: Layer 1, Input: [0.9980929311624503, 0.9719410142501177, 0.028766788846696933, -0.9261641153444675], Output: [-0.9946180020754735, 0.32477636621993816, -0.9178724020767255, -0.846743924870381]\n",
      "Layer: Layer 2, Input: [-0.9946180020754735, 0.32477636621993816, -0.9178724020767255, -0.846743924870381], Output: [-0.15289688479401375]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9291230200902622, 0.20553572790352498, 0.44420250107287795, -0.8658660577227741]\n",
      "Layer: Layer 1, Input: [0.9291230200902622, 0.20553572790352498, 0.44420250107287795, -0.8658660577227741], Output: [-0.9632592704838359, 0.9284108161658585, -0.7620086802235944, -0.5839029752284922]\n",
      "Layer: Layer 2, Input: [-0.9632592704838359, 0.9284108161658585, -0.7620086802235944, -0.5839029752284922], Output: [-1.5804202473311784]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.880126928511453, 0.9811645086633682, -0.7911174638493498, -0.9179385152091091]\n",
      "Layer: Layer 1, Input: [0.880126928511453, 0.9811645086633682, -0.7911174638493498, -0.9179385152091091], Output: [-0.9947499378802211, -0.23990369411675794, -0.9491447690988759, -0.842510219714443]\n",
      "Layer: Layer 2, Input: [-0.9947499378802211, -0.23990369411675794, -0.9491447690988759, -0.842510219714443], Output: [0.8050034125448442]\n",
      "Epoch 220/500, Loss: 0.29043284228307537, Accuracy: -0.8856479582116519\n",
      "Power operation: base = 0.26312800821933147, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8471031152059862, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5804202473311784, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1949965874551558, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888839960378333, 0.9837595686593156, -0.9730428237768248, -0.996998449310637]\n",
      "Layer: Layer 1, Input: [0.9888839960378333, 0.9837595686593156, -0.9730428237768248, -0.996998449310637], Output: [-0.9964172174981282, -0.4945000521196047, -0.9656392640491746, -0.869361579488509]\n",
      "Layer: Layer 2, Input: [-0.9964172174981282, -0.4945000521196047, -0.9656392640491746, -0.869361579488509], Output: [1.267513546997706]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.99809391590738, 0.9720668808198913, 0.0286015615233039, -0.9262525112577384]\n",
      "Layer: Layer 1, Input: [0.99809391590738, 0.9720668808198913, 0.0286015615233039, -0.9262525112577384], Output: [-0.9946431790115318, 0.3318207812534167, -0.9187295816007666, -0.8481102558441781]\n",
      "Layer: Layer 2, Input: [-0.9946431790115318, 0.3318207812534167, -0.9187295816007666, -0.8481102558441781], Output: [-0.15850083208794574]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9291559642628251, 0.2077140558292673, 0.4440736090489799, -0.8660166121433576]\n",
      "Layer: Layer 1, Input: [0.9291559642628251, 0.2077140558292673, 0.4440736090489799, -0.8660166121433576], Output: [-0.9635795528535352, 0.9303751825195405, -0.7643600456826728, -0.5872859262168426]\n",
      "Layer: Layer 2, Input: [-0.9635795528535352, 0.9303751825195405, -0.7643600456826728, -0.5872859262168426], Output: [-1.5764691857266306]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8801910873194905, 0.9812496377511938, -0.7911820159137113, -0.9180410639370212]\n",
      "Layer: Layer 1, Input: [0.8801910873194905, 0.9812496377511938, -0.7911820159137113, -0.9180410639370212], Output: [-0.9947751951220577, -0.23623901206314235, -0.94971723031397, -0.8440563497413421]\n",
      "Layer: Layer 2, Input: [-0.9947751951220577, -0.23623901206314235, -0.94971723031397, -0.8440563497413421], Output: [0.8054431504731197]\n",
      "Epoch 221/500, Loss: 0.28746335930353073, Accuracy: -0.8800387501632712\n",
      "Power operation: base = 0.2675135469977059, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8414991679120543, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5764691857266306, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19455684952688035, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888913706403469, 0.9838324583946124, -0.9730526454989069, -0.9970026592680629]\n",
      "Layer: Layer 1, Input: [0.9888913706403469, 0.9838324583946124, -0.9730526454989069, -0.9970026592680629], Output: [-0.9964332939106856, -0.49325222117410866, -0.966029705948418, -0.8706971139408849]\n",
      "Layer: Layer 2, Input: [-0.9964332939106856, -0.49325222117410866, -0.966029705948418, -0.8706971139408849], Output: [1.271884231147888]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980948881195021, 0.9721904441548797, 0.028438499071737445, -0.926339574296429]\n",
      "Layer: Layer 1, Input: [0.9980948881195021, 0.9721904441548797, 0.028438499071737445, -0.926339574296429], Output: [-0.9946678864559862, 0.3387492194293277, -0.919567940288653, -0.849454016892762]\n",
      "Layer: Layer 2, Input: [-0.9946678864559862, 0.3387492194293277, -0.919567940288653, -0.849454016892762], Output: [-0.16404508867650858]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9291884745768869, 0.20985992033807244, 0.44394642275646873, -0.8661648725080798]\n",
      "Layer: Layer 1, Input: [0.9291884745768869, 0.20985992033807244, 0.44394642275646873, -0.8661648725080798], Output: [-0.9638924866509607, 0.9322769607196487, -0.7666623750818117, -0.5906143811899232]\n",
      "Layer: Layer 2, Input: [-0.9638924866509607, 0.9322769607196487, -0.7666623750818117, -0.5906143811899232], Output: [-1.5725622777855093]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8802544720004204, 0.981333205675561, -0.7912457279023388, -0.9181420996633737]\n",
      "Layer: Layer 1, Input: [0.8802544720004204, 0.981333205675561, -0.7912457279023388, -0.9181420996633737], Output: [-0.9947999867462495, -0.23265421248050525, -0.9502766691995085, -0.8455762337517819]\n",
      "Layer: Layer 2, Input: [-0.9947999867462495, -0.23265421248050525, -0.9502766691995085, -0.8455762337517819], Output: [0.8058837032567392]\n",
      "Epoch 222/500, Loss: 0.28456258687924824, Accuracy: -0.8745177170001495\n",
      "Power operation: base = 0.27188423114788796, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8359549113234914, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5725622777855093, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1941162967432608, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9888986633558735, 0.9839040255611872, -0.973062346308455, -0.9970068096199632]\n",
      "Layer: Layer 1, Input: [0.9888986633558735, 0.9839040255611872, -0.973062346308455, -0.9970068096199632], Output: [-0.9964490837165293, -0.4920715157731168, -0.9664112431261389, -0.8720095504491515]\n",
      "Layer: Layer 2, Input: [-0.9964490837165293, -0.4920715157731168, -0.9664112431261389, -0.8720095504491515], Output: [1.2762393662894476]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980958480984853, 0.9723117713864345, 0.02827754946157552, -0.9264253396218821]\n",
      "Layer: Layer 1, Input: [0.9980958480984853, 0.9723117713864345, 0.02827754946157552, -0.9264253396218821], Output: [-0.99469213808784, 0.3455630456166673, -0.9203880340905255, -0.8507756224375106]\n",
      "Layer: Layer 2, Input: [-0.99469213808784, 0.3455630456166673, -0.9203880340905255, -0.8507756224375106], Output: [-0.16953105034520854]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.929220561492919, 0.21197411989543896, 0.44382090130358803, -0.8663108993794013]\n",
      "Layer: Layer 1, Input: [0.929220561492919, 0.21197411989543896, 0.44382090130358803, -0.8663108993794013], Output: [-0.9641983208692402, 0.9341182263214273, -0.7689170208721667, -0.5938893443400524]\n",
      "Layer: Layer 2, Input: [-0.9641983208692402, 0.9341182263214273, -0.7689170208721667, -0.5938893443400524], Output: [-1.5687017869756392]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8803171007560864, 0.981415258031344, -0.7913086201494103, -0.9182416620487319]\n",
      "Layer: Layer 1, Input: [0.8803171007560864, 0.981415258031344, -0.7913086201494103, -0.9182416620487319], Output: [-0.9948243262490554, -0.2291487335470753, -0.9508234852600602, -0.8470703702559673]\n",
      "Layer: Layer 2, Input: [-0.9948243262490554, -0.2291487335470753, -0.9508234852600602, -0.8470703702559673], Output: [0.806324810833567]\n",
      "Epoch 223/500, Loss: 0.28172966630916674, Accuracy: -0.8690852920863112\n",
      "Power operation: base = 0.27623936628944756, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8304689496547915, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5687017869756392, power = 2, grad = 0.25\n",
      "Power operation: base = -0.193675189166433, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889058760712237, 0.9839743087657942, -0.9730719291380029, -0.9970109019217095]\n",
      "Layer: Layer 1, Input: [0.9889058760712237, 0.9839743087657942, -0.9730719291380029, -0.9970109019217095], Output: [-0.996464595067551, -0.4909571651696033, -0.9667841529006769, -0.873299348046207]\n",
      "Layer: Layer 2, Input: [-0.996464595067551, -0.4909571651696033, -0.9667841529006769, -0.873299348046207], Output: [1.2805783118878695]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980967961378416, 0.9724309276152797, 0.028118661356364837, -0.9265098415611566]\n",
      "Layer: Layer 1, Input: [0.9980967961378416, 0.9724309276152797, 0.028118661356364837, -0.9265098415611566], Output: [-0.9947159471778693, 0.35226369102154914, -0.9211904059392413, -0.8520754908468587]\n",
      "Layer: Layer 2, Input: [-0.9947159471778693, 0.35226369102154914, -0.9211904059392413, -0.8520754908468587], Output: [-0.1749601137814003]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9292522352576458, 0.2140574367477862, 0.4436970043227561, -0.866454751898969]\n",
      "Layer: Layer 1, Input: [0.9292522352576458, 0.2140574367477862, 0.4436970043227561, -0.866454751898969], Output: [-0.9644972951265487, 0.9359009981585386, -0.7711253112603316, -0.5971118293893942]\n",
      "Layer: Layer 2, Input: [-0.9644972951265487, 0.9359009981585386, -0.7711253112603316, -0.5971118293893942], Output: [-1.5648897674767963]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8803789914174484, 0.9814958390279854, -0.791370712696371, -0.9183397898104803]\n",
      "Layer: Layer 1, Input: [0.8803789914174484, 0.9814958390279854, -0.791370712696371, -0.9183397898104803], Output: [-0.994848226724575, -0.22572195234322306, -0.9513580674127085, -0.8485392603737193]\n",
      "Layer: Layer 2, Input: [-0.994848226724575, -0.22572195234322306, -0.9513580674127085, -0.8485392603737193], Output: [0.8067662335436827]\n",
      "Epoch 224/500, Loss: 0.2789636852130825, Accuracy: -0.8637417320395828\n",
      "Power operation: base = 0.2805783118878695, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8250398862185997, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5648897674767963, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1932337664563173, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889130106334703, 0.9840433454317592, -0.9730813968749178, -0.9970149376904286]\n",
      "Layer: Layer 1, Input: [0.9889130106334703, 0.9840433454317592, -0.9730813968749178, -0.9970149376904286], Output: [-0.9964798358787663, -0.48990835922451875, -0.967148704777276, -0.874566966004289]\n",
      "Layer: Layer 2, Input: [-0.9964798358787663, -0.48990835922451875, -0.967148704777276, -0.874566966004289], Output: [1.284900478697053]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980977325249175, 0.9725479759606748, 0.027961784142502187, -0.9265931136145974]\n",
      "Layer: Layer 1, Input: [0.9980977325249175, 0.9725479759606748, 0.027961784142502187, -0.9265931136145974], Output: [-0.9947393265984779, 0.3588526449843769, -0.9219755855476768, -0.8533540431769197]\n",
      "Layer: Layer 2, Input: [-0.9947393265984779, 0.3588526449843769, -0.9219755855476768, -0.8533540431769197], Output: [-0.18033367208486295]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9292835059036519, 0.21611063682347573, 0.44357469199464084, -0.8665964877993706]\n",
      "Layer: Layer 1, Input: [0.9292835059036519, 0.21611063682347573, 0.44357469199464084, -0.8665964877993706], Output: [-0.9647896400168444, 0.9376272380949154, -0.7732885490023224, -0.6002828567550637]\n",
      "Layer: Layer 2, Input: [-0.9647896400168444, 0.9376272380949154, -0.7732885490023224, -0.6002828567550637], Output: [-1.561128073612207]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8804401614437442, 0.9815749915234754, -0.7914320252820752, -0.9184365207315123]\n",
      "Layer: Layer 1, Input: [0.8804401614437442, 0.9815749915234754, -0.7914320252820752, -0.9184365207315123], Output: [-0.9948717008743932, -0.22237319015965976, -0.9518807939656775, -0.8499834064879067]\n",
      "Layer: Layer 2, Input: [-0.9948717008743932, -0.22237319015965976, -0.9518807939656775, -0.8499834064879067], Output: [0.8072077514576828]\n",
      "Epoch 225/500, Loss: 0.27626368449336103, Accuracy: -0.8584871287667144\n",
      "Power operation: base = 0.28490047869705304, power = 2, grad = 0.25\n",
      "Power operation: base = 0.819666327915137, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5611280736122071, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19279224854231725, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889200688499634, 0.9841111718289832, -0.9730907523601944, -0.9970189184054522]\n",
      "Layer: Layer 1, Input: [0.9889200688499634, 0.9841111718289832, -0.9730907523601944, -0.9970189184054522], Output: [-0.996494813833653, -0.4889242522970104, -0.9675051604866147, -0.8758128627723631]\n",
      "Layer: Layer 2, Input: [-0.996494813833653, -0.4889242522970104, -0.9675051604866147, -0.8758128627723631], Output: [1.2892053261972438]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980986575408969, 0.9726629776096788, 0.02780686795468735, -0.9266751884644068]\n",
      "Layer: Layer 1, Input: [0.9980986575408969, 0.9726629776096788, 0.02780686795468735, -0.9266751884644068], Output: [-0.9947622888335332, 0.36533144730683836, -0.9227440892736285, -0.8546117020131255]\n",
      "Layer: Layer 2, Input: [-0.9947622888335332, 0.36533144730683836, -0.9227440892736285, -0.8546117020131255], Output: [-0.18565311074342583]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9293143832494285, 0.21813446967745917, 0.4434539250694773, -0.8667361634176917]\n",
      "Layer: Layer 1, Input: [0.9293143832494285, 0.21813446967745917, 0.4434539250694773, -0.8667361634176917], Output: [-0.9650755774494177, 0.9392988510245903, -0.7754080104075178, -0.603403450923787]\n",
      "Layer: Layer 2, Input: [-0.9650755774494177, 0.9392988510245903, -0.7754080104075178, -0.603403450923787], Output: [-1.5574183692536083]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8805006279224123, 0.9816527570583548, -0.791492577334207, -0.9185318916700363]\n",
      "Layer: Layer 1, Input: [0.8805006279224123, 0.9816527570583548, -0.791492577334207, -0.9185318916700363], Output: [-0.9948947610172153, -0.21910171753051116, -0.9523920326367168, -0.8514033110119248]\n",
      "Layer: Layer 2, Input: [-0.9948947610172153, -0.21910171753051116, -0.9523920326367168, -0.8514033110119248], Output: [0.8076491636390197]\n",
      "Epoch 226/500, Loss: 0.27362866484320847, Accuracy: -0.8533214210684066\n",
      "Power operation: base = 0.2892053261972438, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8143468892565742, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5574183692536083, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19235083636098027, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988927052488417, 0.9841778231038665, -0.9730999983874216, -0.9970228455088053]\n",
      "Layer: Layer 1, Input: [0.988927052488417, 0.9841778231038665, -0.9730999983874216, -0.9970228455088053], Output: [-0.9965095363895154, -0.4880039669189451, -0.9678537740465175, -0.8770374950109868]\n",
      "Layer: Layer 2, Input: [-0.9965095363895154, -0.4880039669189451, -0.9678537740465175, -0.8770374950109868], Output: [1.2934923600475638]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9980995714608162, 0.9727759918663745, 0.02765386369812265, -0.926756097984121]\n",
      "Layer: Layer 1, Input: [0.9980995714608162, 0.9727759918663745, 0.02765386369812265, -0.926756097984121], Output: [-0.9947848459881693, 0.37170168109112883, -0.9234964200451861, -0.8558488904084159]\n",
      "Layer: Layer 2, Input: [-0.9947848459881693, 0.37170168109112883, -0.9234964200451861, -0.8558488904084159], Output: [-0.19091980404350295]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.929344876899825, 0.22012966847599078, 0.44333466488577156, -0.8668738337107109]\n",
      "Layer: Layer 1, Input: [0.929344876899825, 0.22012966847599078, 0.44333466488577156, -0.8668738337107109], Output: [-0.9653553209773938, 0.9409176850902675, -0.7774849445337078, -0.6064746380286058]\n",
      "Layer: Layer 2, Input: [-0.9653553209773938, 0.9409176850902675, -0.7774849445337078, -0.6064746380286058], Output: [-1.5537621371497021]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.880560407569714, 0.9817291758896535, -0.7915523879619075, -0.9186259385703893]\n",
      "Layer: Layer 1, Input: [0.880560407569714, 0.9817291758896535, -0.7915523879619075, -0.9186259385703893], Output: [-0.9949174190984705, -0.2159067589970185, -0.9528921406065578, -0.8527994752657987]\n",
      "Layer: Layer 2, Input: [-0.9949174190984705, -0.2159067589970185, -0.9528921406065578, -0.8527994752657987], Output: [0.808090287356082]\n",
      "Epoch 227/500, Loss: 0.2710575928107423, Accuracy: -0.848244405797681\n",
      "Power operation: base = 0.29349236004756385, power = 2, grad = 0.25\n",
      "Power operation: base = 0.809080195956497, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5537621371497021, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19190971264391798, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988933963277063, 0.9842433333090822, -0.9731091377019165, -0.9970267204057239]\n",
      "Layer: Layer 1, Input: [0.988933963277063, 0.9842433333090822, -0.9731091377019165, -0.9970267204057239], Output: [-0.9965240107828587, -0.48714659726046095, -0.9681947918438712, -0.8782413167193838]\n",
      "Layer: Layer 2, Input: [-0.9965240107828587, -0.48714659726046095, -0.9681947918438712, -0.8782413167193838], Output: [1.2977611295695564]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998100474553589, 0.9728870762009265, 0.027502723067653202, -0.9268358732489007]\n",
      "Layer: Layer 1, Input: [0.998100474553589, 0.9728870762009265, 0.027502723067653202, -0.9268358732489007], Output: [-0.9948070097985334, 0.37796496607249985, -0.9242330673399702, -0.8570660309133399]\n",
      "Layer: Layer 2, Input: [-0.9948070097985334, 0.37796496607249985, -0.9242330673399702, -0.8570660309133399], Output: [-0.1961351118861323]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9293749962468759, 0.22209695001800572, 0.44321687338654114, -0.8670095522715644]\n",
      "Layer: Layer 1, Input: [0.9293749962468759, 0.22209695001800572, 0.44321687338654114, -0.8670095522715644], Output: [-0.9656290761153367, 0.9424855320936778, -0.779520572555514, -0.6094974436195612]\n",
      "Layer: Layer 2, Input: [-0.9656290761153367, 0.9424855320936778, -0.779520572555514, -0.6094974436195612], Output: [-1.5501606881346799]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8806195167320104, 0.9818042870246794, -0.7916114759495405, -0.9187186964747575]\n",
      "Layer: Layer 1, Input: [0.8806195167320104, 0.9818042870246794, -0.7916114759495405, -0.9187186964747575], Output: [-0.9949396866998723, -0.21278749760864016, -0.9533814646031308, -0.8541723984553553]\n",
      "Layer: Layer 2, Input: [-0.9949396866998723, -0.21278749760864016, -0.9533814646031308, -0.8541723984553553], Output: [0.8085309572580606]\n",
      "Epoch 228/500, Loss: 0.2685494064305496, Accuracy: -0.8432557485600434\n",
      "Power operation: base = 0.29776112956955636, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8038648881138677, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5501606881346799, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19146904274193943, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889408029048679, 0.9843077354331342, -0.9731181730000078, -0.9970305444652056]\n",
      "Layer: Layer 1, Input: [0.9889408029048679, 0.9843077354331342, -0.9731181730000078, -0.9970305444652056], Output: [-0.9965382440347608, -0.4863512123936946, -0.9685284527340122, -0.8794247784494581]\n",
      "Layer: Layer 2, Input: [-0.9965382440347608, -0.4863512123936946, -0.9685284527340122, -0.8794247784494581], Output: [1.3020112252756633]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981013670820414, 0.9729962862983617, 0.027353398564025338, -0.9269145445465465]\n",
      "Layer: Layer 1, Input: [0.9981013670820414, 0.9729962862983617, 0.027353398564025338, -0.9269145445465465], Output: [-0.9948287916414621, 0.38412295242526934, -0.9249545072121222, -0.8582635446933387]\n",
      "Layer: Layer 2, Input: [-0.9948287916414621, 0.38412295242526934, -0.9249545072121222, -0.8582635446933387], Output: [-0.20130037698001546]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9294047504709694, 0.2240370147899214, 0.443100513133234, -0.8671433713477272]\n",
      "Layer: Layer 1, Input: [0.9294047504709694, 0.2240370147899214, 0.443100513133234, -0.8671433713477272], Output: [-0.9658970406461427, 0.9440041280729597, -0.7815160872895573, -0.6124728906198684]\n",
      "Layer: Layer 2, Input: [-0.9658970406461427, 0.9440041280729597, -0.7815160872895573, -0.6124728906198684], Output: [-1.5466151701797273]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8806779713876395, 0.9818781282545838, -0.7916698597515233, -0.9188101995357056]\n",
      "Layer: Layer 1, Input: [0.8806779713876395, 0.9818781282545838, -0.7916698597515233, -0.9188101995357056], Output: [-0.994961575048909, -0.2097430791690586, -0.953860341012588, -0.8555225767488394]\n",
      "Layer: Layer 2, Input: [-0.994961575048909, -0.2097430791690586, -0.953860341012588, -0.8555225767488394], Output: [0.8089710245267661]\n",
      "Epoch 229/500, Loss: 0.26610302043643463, Accuracy: -0.838354993948609\n",
      "Power operation: base = 0.30201122527566326, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7986996230199845, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5466151701797273, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19102897547323394, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889475730218046, 0.9843710614296414, -0.9731271069284672, -0.9970343190205845]\n",
      "Layer: Layer 1, Input: [0.9889475730218046, 0.9843710614296414, -0.9731271069284672, -0.9970343190205845], Output: [-0.9965522429562297, -0.4856168593621199, -0.9688549881551013, -0.8805883266015002]\n",
      "Layer: Layer 2, Input: [-0.9965522429562297, -0.4856168593621199, -0.9688549881551013, -0.8805883266015002], Output: [1.306242276454356]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981022493029558, 0.9731036761069649, 0.02720584350744334, -0.9269921413891559]\n",
      "Layer: Layer 1, Input: [0.9981022493029558, 0.9731036761069649, 0.02720584350744334, -0.9269921413891559], Output: [-0.9948502025440699, 0.3901773150217648, -0.9256612023614156, -0.8594418507284497]\n",
      "Layer: Layer 2, Input: [-0.9948502025440699, 0.3901773150217648, -0.9256612023614156, -0.8594418507284497], Output: [-0.20641692238400688]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9294341485423311, 0.22595054705078918, 0.4429855473174718, -0.8672753418601596]\n",
      "Layer: Layer 1, Input: [0.9294341485423311, 0.22595054705078918, 0.4429855473174718, -0.8672753418601596], Output: [-0.9661594049174022, 0.9454751540244078, -0.7834726528608504, -0.6154019974588321]\n",
      "Layer: Layer 2, Input: [-0.9661594049174022, 0.9454751540244078, -0.7834726528608504, -0.6154019974588321], Output: [-1.5431265772561806]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8807357871493445, 0.9819507361876336, -0.7917275574881572, -0.9189004810294222]\n",
      "Layer: Layer 1, Input: [0.8807357871493445, 0.9819507361876336, -0.7917275574881572, -0.9189004810294222], Output: [-0.9949830950282561, -0.20677261623522147, -0.9543290960135157, -0.8568505024453448]\n",
      "Layer: Layer 2, Input: [-0.9949830950282561, -0.20677261623522147, -0.9543290960135157, -0.8568505024453448], Output: [0.8094103560150931]\n",
      "Epoch 230/500, Loss: 0.2637173310706813, Accuracy: -0.8335415753114366\n",
      "Power operation: base = 0.306242276454356, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7935830776159931, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5431265772561806, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19058964398490685, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889542752391788, 0.9844333422462961, -0.9731359420840728, -0.997038045370129]\n",
      "Layer: Layer 1, Input: [0.9889542752391788, 0.9844333422462961, -0.9731359420840728, -0.997038045370129], Output: [-0.996566014153537, -0.4849425660630723, -0.9691746222552269, -0.8817324027964112]\n",
      "Layer: Layer 2, Input: [-0.996566014153537, -0.4849425660630723, -0.9691746222552269, -0.8817324027964112], Output: [1.3104539488213867]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981031214671222, 0.9732092978862007, 0.027060012048602634, -0.9270686925253412]\n",
      "Layer: Layer 1, Input: [0.9981031214671222, 0.9732092978862007, 0.027060012048602634, -0.9270686925253412], Output: [-0.9948712531932333, 0.3961297481233059, -0.9263536022393236, -0.8606013650906693]\n",
      "Layer: Layer 2, Input: [-0.9948712531932333, 0.3961297481233059, -0.9263536022393236, -0.8606013650906693], Output: [-0.2114860493727253]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9294631992227912, 0.22783821494489004, 0.4428719397707549, -0.8674055134234807]\n",
      "Layer: Layer 1, Input: [0.9294631992227912, 0.22783821494489004, 0.4428719397707549, -0.8674055134234807], Output: [-0.9664163521274423, 0.9469002367479304, -0.785391404495967, -0.6182857763725793]\n",
      "Layer: Layer 2, Input: [-0.9664163521274423, 0.9469002367479304, -0.785391404495967, -0.6182857763725793], Output: [-1.5396957579841977]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8807929792672076, 0.9820221462821314, -0.7917845869423885, -0.9189895733695916]\n",
      "Layer: Layer 1, Input: [0.8807929792672076, 0.9820221462821314, -0.7917845869423885, -0.9189895733695916], Output: [-0.9950042571850913, -0.20387519187796774, -0.9547880457310404, -0.858156663229489]\n",
      "Layer: Layer 2, Input: [-0.9950042571850913, -0.20387519187796774, -0.9547880457310404, -0.858156663229489], Output: [0.8098488333812401]\n",
      "Epoch 231/500, Loss: 0.26139122050630936, Accuracy: -0.8288148240516189\n",
      "Power operation: base = 0.31045394882138666, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7885139506272747, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5396957579841977, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19015116661875986, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889609111300008, 0.9844946078534511, -0.9731446810132981, -0.9970417247776577]\n",
      "Layer: Layer 1, Input: [0.9889609111300008, 0.9844946078534511, -0.9731446810132981, -0.9970417247776577], Output: [-0.9965795640335127, -0.48432734395117755, -0.9694875720301867, -0.8828574433193913]\n",
      "Layer: Layer 2, Input: [-0.9965795640335127, -0.48432734395117755, -0.9694875720301867, -0.8828574433193913], Output: [1.3146459422449377]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981039838193984, 0.9733132022540746, 0.026915859177364842, -0.9271442259529361]\n",
      "Layer: Layer 1, Input: [0.9981039838193984, 0.9733132022540746, 0.026915859177364842, -0.9271442259529361], Output: [-0.9948919539449625, 0.4019819604821604, -0.9270321431873064, -0.8617425002942833]\n",
      "Layer: Layer 2, Input: [-0.9948919539449625, 0.4019819604821604, -0.9270321431873064, -0.8617425002942833], Output: [-0.2165090356000441]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9294919110678116, 0.22970067063903682, 0.44275965497226577, -0.8675339343670366]\n",
      "Layer: Layer 1, Input: [0.9294919110678116, 0.22970067063903682, 0.44275965497226577, -0.8675339343670366], Output: [-0.9666680586012676, 0.9482809497974499, -0.7872734484295987, -0.6211252318636508]\n",
      "Layer: Layer 2, Input: [-0.9666680586012676, 0.9482809497974499, -0.7872734484295987, -0.6211252318636508], Output: [-1.536323424045496]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8808495626320377, 0.9820923928789266, -0.7918409655574377, -0.9190775081218103]\n",
      "Layer: Layer 1, Input: [0.8808495626320377, 0.9820923928789266, -0.7918409655574377, -0.9190775081218103], Output: [-0.9950250717402989, -0.201049863213104, -0.9552374964078396, -0.8594415415068464]\n",
      "Layer: Layer 2, Input: [-0.9950250717402989, -0.201049863213104, -0.9552374964078396, -0.8594415415068464], Output: [0.8102863522265178]\n",
      "Epoch 232/500, Loss: 0.25912356089974586, Accuracy: -0.8241739784638717\n",
      "Power operation: base = 0.3146459422449377, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7834909643999559, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5363234240454959, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1897136477734822, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889674822294022, 0.9845548872722943, -0.9731533262121183, -0.9970453584731743]\n",
      "Layer: Layer 1, Input: [0.9889674822294022, 0.9845548872722943, -0.9731533262121183, -0.9970453584731743], Output: [-0.9965928988087985, -0.4837701905704013, -0.9697940474701086, -0.8839638786301809]\n",
      "Layer: Layer 2, Input: [-0.9965928988087985, -0.4837701905704013, -0.9697940474701086, -0.8839638786301809], Output: [1.3188179885507139]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981048365987746, 0.9734154382338643, 0.026773340729245105, -0.9272187689321162]\n",
      "Layer: Layer 1, Input: [0.9981048365987746, 0.9734154382338643, 0.026773340729245105, -0.9272187689321162], Output: [-0.9949123148336407, 0.40773567083343587, -0.9276972486030051, -0.8628656647145593]\n",
      "Layer: Layer 2, Input: [-0.9949123148336407, 0.40773567083343587, -0.9276972486030051, -0.8628656647145593], Output: [-0.22148713353648697]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9295202924287437, 0.23153855048200883, 0.4426486580549017, -0.8676606517567352]\n",
      "Layer: Layer 1, Input: [0.9295202924287437, 0.23153855048200883, 0.4426486580549017, -0.8676606517567352], Output: [-0.9669146940566241, 0.9496188145192535, -0.7891198619121085, -0.6239213593105095]\n",
      "Layer: Layer 2, Input: [-0.9669146940566241, 0.9496188145192535, -0.7891198619121085, -0.6239213593105095], Output: [-1.5330101583429543]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8809055517791766, 0.9821615092334719, -0.7918967104352305, -0.9191643160184682]\n",
      "Layer: Layer 1, Input: [0.8809055517791766, 0.9821615092334719, -0.7918967104352305, -0.9191643160184682], Output: [-0.9950455485975543, -0.1982956647120354, -0.9556777445893456, -0.8607056138147988]\n",
      "Layer: Layer 2, Input: [-0.9950455485975543, -0.1982956647120354, -0.9556777445893456, -0.8607056138147988], Output: [0.8107228212433797]\n",
      "Epoch 233/500, Loss: 0.2569132180919014, Accuracy: -0.8196181921138015\n",
      "Power operation: base = 0.31881798855071386, power = 2, grad = 0.25\n",
      "Power operation: base = 0.778512866463513, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5330101583429543, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1892771787566203, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.98897399003509, 0.9846142086025738, -0.9731618801259211, -0.9970489476535128]\n",
      "Layer: Layer 1, Input: [0.98897399003509, 0.9846142086025738, -0.9731618801259211, -0.9970489476535128], Output: [-0.9966060245030449, -0.48327009192238596, -0.9700942517132447, -0.8850521329351059]\n",
      "Layer: Layer 2, Input: [-0.9966060245030449, -0.48327009192238596, -0.9700942517132447, -0.8850521329351059], Output: [1.3229698494114879]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981056800384465, 0.9735160533001536, 0.026632413389866768, -0.9272923479988726]\n",
      "Layer: Layer 1, Input: [0.9981056800384465, 0.9735160533001536, 0.026632413389866768, -0.9272923479988726], Output: [-0.9949323455811295, 0.41339260375608566, -0.9283493291304099, -0.8639712620703088]\n",
      "Layer: Layer 2, Input: [-0.9949323455811295, 0.41339260375608566, -0.9283493291304099, -0.8639712620703088], Output: [-0.22642156915781664]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9295483514552941, 0.23335247518371158, 0.44253891480966423, -0.8677857114175355]\n",
      "Layer: Layer 1, Input: [0.9295483514552941, 0.23335247518371158, 0.44253891480966423, -0.8677857114175355], Output: [-0.9671564218604256, 0.9509153011629661, -0.7909316933066707, -0.6266751437181374]\n",
      "Layer: Layer 2, Input: [-0.9671564218604256, 0.9509153011629661, -0.7909316933066707, -0.6266751437181374], Output: [-1.529756422893668]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8809609608926732, 0.9822295275473824, -0.7919518383355736, -0.9192500269740207]\n",
      "Layer: Layer 1, Input: [0.8809609608926732, 0.9822295275473824, -0.7919518383355736, -0.9192500269740207], Output: [-0.9950656973522749, -0.1956116113011007, -0.9561090773207024, -0.8619493503036151]\n",
      "Layer: Layer 2, Input: [-0.9950656973522749, -0.1956116113011007, -0.9561090773207024, -0.8619493503036151], Output: [0.8111581613791432]\n",
      "Epoch 234/500, Loss: 0.2547590549759836, Accuracy: -0.815146541768196\n",
      "Power operation: base = 0.3229698494114879, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7735784308421834, power = 2, grad = 0.25\n",
      "Power operation: base = -0.529756422893668, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1888418386208568, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889804360078365, 0.9846725990498447, -0.9731703451495204, -0.9970524934829961]\n",
      "Layer: Layer 1, Input: [0.9889804360078365, 0.9846725990498447, -0.9731703451495204, -0.9970524934829961], Output: [-0.9966189469560484, -0.48282602467867036, -0.9703883812054553, -0.8861226238163705]\n",
      "Layer: Layer 2, Input: [-0.9966189469560484, -0.48282602467867036, -0.9703883812054553, -0.8861226238163705], Output: [1.3271013143243984]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981065143658907, 0.9736150934241147, 0.026493034697536447, -0.9273649889787735]\n",
      "Layer: Layer 1, Input: [0.9981065143658907, 0.9736150934241147, 0.026493034697536447, -0.9273649889787735], Output: [-0.9949520556057226, 0.4189544858825207, -0.9289887828704448, -0.8650596909659767]\n",
      "Layer: Layer 2, Input: [-0.9949520556057226, 0.4189544858825207, -0.9289887828704448, -0.8650596909659767], Output: [-0.23131354086333644]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9295760960981768, 0.23514305001181082, 0.4424303916885244, -0.8679091579564809]\n",
      "Layer: Layer 1, Input: [0.9295760960981768, 0.23514305001181082, 0.4424303916885244, -0.8679091579564809], Output: [-0.9673933992757887, 0.9521718300513647, -0.7927099622655002, -0.6293875586010602]\n",
      "Layer: Layer 2, Input: [-0.9673933992757887, 0.9521718300513647, -0.7927099622655002, -0.6293875586010602], Output: [-1.5265625664453677]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8810158038097923, 0.9822964789994603, -0.7920063656760169, -0.9193346701005862]\n",
      "Layer: Layer 1, Input: [0.8810158038097923, 0.9822964789994603, -0.7920063656760169, -0.9193346701005862], Output: [-0.9950855273004285, -0.1929967012588488, -0.9565317723532781, -0.8631732142827577]\n",
      "Layer: Layer 2, Input: [-0.9950855273004285, -0.1929967012588488, -0.9565317723532781, -0.8631732142827577], Output: [0.8115923050199472]\n",
      "Epoch 235/500, Loss: 0.25265993455050983, Accuracy: -0.8107580348864825\n",
      "Power operation: base = 0.3271013143243984, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7686864591366636, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5265625664453677, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18840769498005283, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889868215719989, 0.9847300849522119, -0.9731787236272569, -0.9970559970941012]\n",
      "Layer: Layer 1, Input: [0.9889868215719989, 0.9847300849522119, -0.9731787236272569, -0.9970559970941012], Output: [-0.99663167182882, -0.4824369582442616, -0.9706766258640533, -0.8871757619142351]\n",
      "Layer: Layer 2, Input: [-0.99663167182882, -0.4824369582442616, -0.9706766258640533, -0.8871757619142351], Output: [1.3312121986780925]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981073398029477, 0.973712603117991, 0.026355163044089035, -0.927436717000959]\n",
      "Layer: Layer 1, Input: [0.9981073398029477, 0.973712603117991, 0.026355163044089035, -0.927436717000959], Output: [-0.994971454030947, 0.42442304243677675, -0.9296159956087402, -0.8661313444890697]\n",
      "Layer: Layer 2, Input: [-0.994971454030947, 0.42442304243677675, -0.9296159956087402, -0.8661313444890697], Output: [-0.23616421860367787]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.929603534111926, 0.23691086500374545, 0.44232305580588427, -0.8680310347861762]\n",
      "Layer: Layer 1, Input: [0.929603534111926, 0.23691086500374545, 0.44232305580588427, -0.8680310347861762], Output: [-0.9676257776999203, 0.953389772796689, -0.7944556599755508, -0.6320595649903485]\n",
      "Layer: Layer 2, Input: [-0.9676257776999203, 0.953389772796689, -0.7944556599755508, -0.6320595649903485], Output: [-1.5234288318091642]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8810700940258164, 0.9823623937761555, -0.7920603085323455, -0.9194182737238007]\n",
      "Layer: Layer 1, Input: [0.8810700940258164, 0.9823623937761555, -0.7920603085323455, -0.9194182737238007], Output: [-0.9951050474471922, -0.19044991892040763, -0.9569460983587638, -0.8643776618276211]\n",
      "Layer: Layer 2, Input: [-0.9951050474471922, -0.19044991892040763, -0.9569460983587638, -0.8643776618276211], Output: [0.8120251951986086]\n",
      "Epoch 236/500, Loss: 0.25061472267593343, Accuracy: -0.8064516166849702\n",
      "Power operation: base = 0.3312121986780925, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7638357813963221, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5234288318091642, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1879748048013914, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889931481160676, 0.9847866918065432, -0.9731870178531855, -0.9970594595881334]\n",
      "Layer: Layer 1, Input: [0.9889931481160676, 0.9847866918065432, -0.9731870178531855, -0.9970594595881334], Output: [-0.996644204608581, -0.4821018566798374, -0.9709591692448247, -0.8882119506579251]\n",
      "Layer: Layer 2, Input: [-0.996644204608581, -0.4821018566798374, -0.9709591692448247, -0.8882119506579251], Output: [1.335302341910833]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981081565659068, 0.9738086254787387, 0.02621875767413121, -0.9275075565123153]\n",
      "Layer: Layer 1, Input: [0.9981081565659068, 0.9738086254787387, 0.02621875767413121, -0.9275075565123153], Output: [-0.9949905496941964, 0.42979999408170333, -0.9302313410576882, -0.8671866098589045]\n",
      "Layer: Layer 2, Input: [-0.9949905496941964, 0.42979999408170333, -0.9302313410576882, -0.8671866098589045], Output: [-0.2409747431991094]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9296306730578536, 0.23865649519216972, 0.4422168749387397, -0.8681513841486141]\n",
      "Layer: Layer 1, Input: [0.9296306730578536, 0.23865649519216972, 0.4422168749387397, -0.8681513841486141], Output: [-0.9678537028931194, 0.9545704535524309, -0.7961697494648878, -0.6346921105564052]\n",
      "Layer: Layer 2, Input: [-0.9678537028931194, 0.9545704535524309, -0.7961697494648878, -0.6346921105564052], Output: [-1.5203553629041364]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.881123844699109, 0.9824273011014351, -0.7921136826396502, -0.9195008653988735]\n",
      "Layer: Layer 1, Input: [0.881123844699109, 0.9824273011014351, -0.7921136826396502, -0.9195008653988735], Output: [-0.9951242665154523, -0.18797023719802547, -0.9573523151490995, -0.8655631414421077]\n",
      "Layer: Layer 2, Input: [-0.9951242665154523, -0.18797023719802547, -0.9573523151490995, -0.8655631414421077], Output: [0.812456784829251]\n",
      "Epoch 237/500, Loss: 0.2486222905530561, Accuracy: -0.802226176786609\n",
      "Power operation: base = 0.33530234191083297, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7590252568008906, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5203553629041364, power = 2, grad = 0.25\n",
      "Power operation: base = -0.187543215170749, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889994169932368, 0.9848424442941385, -0.9731952300713371, -0.9970628820359003]\n",
      "Layer: Layer 1, Input: [0.9889994169932368, 0.9848424442941385, -0.9731952300713371, -0.9970628820359003], Output: [-0.9966565506136775, -0.4818196804897067, -0.9712361887111808, -0.8892315860413285]\n",
      "Layer: Layer 2, Input: [-0.9966565506136775, -0.4818196804897067, -0.9712361887111808, -0.8892315860413285], Output: [1.3393716057598137]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981089648655952, 0.9739032022307934, 0.02608377868283081, -0.9275775312917802]\n",
      "Layer: Layer 1, Input: [0.9981089648655952, 0.9739032022307934, 0.02608377868283081, -0.9275775312917802], Output: [-0.9950093511552018, 0.4350870540562639, -0.9308351811101693, -0.8682258681228399]\n",
      "Layer: Layer 2, Input: [-0.9950093511552018, 0.4350870540562639, -0.9308351811101693, -0.8682258681228399], Output: [-0.24574622583056183]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9296575203071303, 0.24038050084202325, 0.44211181752565554, -0.8682702471392684]\n",
      "Layer: Layer 1, Input: [0.9296575203071303, 0.24038050084202325, 0.44211181752565554, -0.8682702471392684], Output: [-0.9680773151991406, 0.9557151502908089, -0.7978531659617083, -0.637286128839628]\n",
      "Layer: Layer 2, Input: [-0.9680773151991406, 0.9557151502908089, -0.7978531659617083, -0.637286128839628], Output: [-1.5173422115116324]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8811770686564009, 0.982491229266039, -0.7921665033939259, -0.9195824719267897]\n",
      "Layer: Layer 1, Input: [0.8811770686564009, 0.982491229266039, -0.7921665033939259, -0.9195824719267897], Output: [-0.9951431929541418, -0.18555661992669129, -0.9577506739006639, -0.8667300937726807]\n",
      "Layer: Layer 2, Input: [-0.9951431929541418, -0.18555661992669129, -0.9577506739006639, -0.8667300937726807], Output: [0.812887035970908]\n",
      "Epoch 238/500, Loss: 0.2466815169410838, Accuracy: -0.7980805554699764\n",
      "Power operation: base = 0.33937160575981373, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7542537741694382, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5173422115116324, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18711296402909205, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989005629521996, 0.9848973663058378, -0.9732033624760492, -0.9970662654783927]\n",
      "Layer: Layer 1, Input: [0.989005629521996, 0.9848973663058378, -0.9732033624760492, -0.9970662654783927], Output: [-0.9966687149984119, -0.4815893882824236, -0.9715078556045161, -0.8902350564397519]\n",
      "Layer: Layer 2, Input: [-0.9966687149984119, -0.4815893882824236, -0.9715078556045161, -0.8902350564397519], Output: [1.343419872601241]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981097649074705, 0.9739963737679344, 0.025950187012362094, -0.9276466644647364]\n",
      "Layer: Layer 1, Input: [0.9981097649074705, 0.9739963737679344, 0.025950187012362094, -0.9276466644647364], Output: [-0.9950278667043215, 0.440285925584679, -0.9314278661026003, -0.8692494938963411]\n",
      "Layer: Layer 2, Input: [-0.9950278667043215, 0.440285925584679, -0.9314278661026003, -0.8692494938963411], Output: [-0.25047974768677683]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9296840830439725, 0.2420834276975568, 0.44200785266464954, -0.8683876637313687]\n",
      "Layer: Layer 1, Input: [0.9296840830439725, 0.2420834276975568, 0.44200785266464954, -0.8683876637313687], Output: [-0.9682967497571869, 0.9568250960972539, -0.7995068172987115, -0.6398425385813538]\n",
      "Layer: Layer 2, Input: [-0.9682967497571869, 0.9568250960972539, -0.7995068172987115, -0.6398425385813538], Output: [-1.514389343739098]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8812297783982755, 0.9825542056561071, -0.7922187858541533, -0.9196631193706069]\n",
      "Layer: Layer 1, Input: [0.8812297783982755, 0.9825542056561071, -0.7922187858541533, -0.9196631193706069], Output: [-0.9951618349464075, -0.18320802404359943, -0.9581414173813382, -0.8678789513697494]\n",
      "Layer: Layer 2, Input: [-0.9951618349464075, -0.18320802404359943, -0.9581414173813382, -0.8678789513697494], Output: [0.8133159191217558]\n",
      "Epoch 239/500, Loss: 0.24479129013270629, Accuracy: -0.7940135495318064\n",
      "Power operation: base = 0.34341987260124096, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7495202523132232, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5143893437390981, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18668408087824417, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890117869867392, 0.9849514809665584, -0.9732114172123618, -0.9970696109274628]\n",
      "Layer: Layer 1, Input: [0.9890117869867392, 0.9849514809665584, -0.9732114172123618, -0.9970696109274628], Output: [-0.9966807027577875, -0.4814099383107304, -0.9717743354149574, -0.8912227424642248]\n",
      "Layer: Layer 2, Input: [-0.9966807027577875, -0.4814099383107304, -0.9717743354149574, -0.8912227424642248], Output: [1.347447043880043]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981105568917154, 0.9740881791942236, 0.02581794444713512, -0.9277149785174483]\n",
      "Layer: Layer 1, Input: [0.9981105568917154, 0.9740881791942236, 0.02581794444713512, -0.9277149785174483], Output: [-0.995046104370658, 0.44539829953984733, -0.932009735085215, -0.870257855143413]\n",
      "Layer: Layer 2, Input: [-0.995046104370658, 0.44539829953984733, -0.932009735085215, -0.870257855143413], Output: [-0.2551763597520811]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9297103682689195, 0.2437658072377777, 0.44190495011008013, -0.8685036728002926]\n",
      "Layer: Layer 1, Input: [0.9297103682689195, 0.2437658072377777, 0.44190495011008013, -0.8685036728002926], Output: [-0.9685121367057813, 0.9579014804742574, -0.8011315843561919, -0.6423622431478068]\n",
      "Layer: Layer 2, Input: [-0.9685121367057813, 0.9579014804742574, -0.8011315843561919, -0.6423622431478068], Output: [-1.51149664619503]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8812819861048169, 0.9826162567811596, -0.7922705447448145, -0.919742833071804]\n",
      "Layer: Layer 1, Input: [0.8812819861048169, 0.9826162567811596, -0.7922705447448145, -0.919742833071804], Output: [-0.9951802004176056, -0.18092340160994277, -0.9585247801792157, -0.8690101384924723]\n",
      "Layer: Layer 2, Input: [-0.9951802004176056, -0.18092340160994277, -0.9585247801792157, -0.8690101384924723], Output: [0.8137434125449983]\n",
      "Epoch 240/500, Loss: 0.2429505097030721, Accuracy: -0.7900239177779937\n",
      "Power operation: base = 0.347447043880043, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7448236402479189, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5114966461950301, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18625658745500173, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890178906383887, 0.9850048106592504, -0.9732193963764664, -0.9970729193665024]\n",
      "Layer: Layer 1, Input: [0.9890178906383887, 0.9850048106592504, -0.9732193963764664, -0.9970729193665024], Output: [-0.99669251873216, -0.48128028989729166, -0.9720357879517922, -0.8921950168500447]\n",
      "Layer: Layer 2, Input: [-0.99669251873216, -0.48128028989729166, -0.9720357879517922, -0.8921950168500447], Output: [1.3514530386276231]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981113410133343, 0.9741786563640034, 0.02568701360791704, -0.9277824953115108]\n",
      "Layer: Layer 1, Input: [0.9981113410133343, 0.9741786563640034, 0.02568701360791704, -0.9277824953115108], Output: [-0.9950640719299904, 0.4504258523442122, -0.9325811160977043, -0.8712513129941283]\n",
      "Layer: Layer 2, Input: [-0.9950640719299904, 0.4504258523442122, -0.9325811160977043, -0.8712513129941283], Output: [-0.2598370827204257]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9297363828021845, 0.24542815693889608, 0.44180308026862863, -0.868618312148001]\n",
      "Layer: Layer 1, Input: [0.9297363828021845, 0.24542815693889608, 0.44180308026862863, -0.868618312148001], Output: [-0.9687236013787807, 0.9589454506478752, -0.8027283215378557, -0.6448461300401154]\n",
      "Layer: Layer 2, Input: [-0.9687236013787807, 0.9589454506478752, -0.8027283215378557, -0.6448461300401154], Output: [-1.5086639318780715]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8813337036413992, 0.982677408301425, -0.7923217944588051, -0.9198216376666356]\n",
      "Layer: Layer 1, Input: [0.8813337036413992, 0.982677408301425, -0.7923217944588051, -0.9198216376666356], Output: [-0.9951982970431177, -0.1787017016833428, -0.9589009889318848, -0.8701240709532903]\n",
      "Layer: Layer 2, Input: [-0.9951982970431177, -0.1787017016833428, -0.9589009889318848, -0.8701240709532903], Output: [0.8141695016271351]\n",
      "Epoch 241/500, Loss: 0.24115808804889155, Accuracy: -0.7861103861581338\n",
      "Power operation: base = 0.3514530386276231, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7401629172795743, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5086639318780715, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18583049837286492, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890239416950304, 0.9850573770482675, -0.9732273020162105, -0.9970761917511187]\n",
      "Layer: Layer 1, Input: [0.9890239416950304, 0.9850573770482675, -0.9732273020162105, -0.9970761917511187], Output: [-0.9967041676117956, -0.481199404752417, -0.9722923675129601, -0.8931522443764699]\n",
      "Layer: Layer 2, Input: [-0.9967041676117956, -0.481199404752417, -0.9722923675129601, -0.8931522443764699], Output: [1.3554377920656058]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981121174622525, 0.9742678419209382, 0.02555735794494947, -0.927849236098269]\n",
      "Layer: Layer 1, Input: [0.9981121174622525, 0.9742678419209382, 0.02555735794494947, -0.927849236098269], Output: [-0.995081776912526, 0.45537024409197124, -0.9331423264485605, -0.872230221596162]\n",
      "Layer: Layer 2, Input: [-0.995081776912526, 0.45537024409197124, -0.9331423264485605, -0.872230221596162], Output: [-0.264462907022295]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9297621332870676, 0.24707098054247537, 0.4417022141944581, -0.8687316185274622]\n",
      "Layer: Layer 1, Input: [0.9297621332870676, 0.24707098054247537, 0.4417022141944581, -0.8687316185274622], Output: [-0.9689312644937856, 0.9599581128710254, -0.8042978572739444, -0.6472950704838026]\n",
      "Layer: Layer 2, Input: [-0.9689312644937856, 0.9599581128710254, -0.8042978572739444, -0.6472950704838026], Output: [-1.505890945784559]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8813849425645905, 0.9827376850545038, -0.7923725490607022, -0.9198995571024576]\n",
      "Layer: Layer 1, Input: [0.8813849425645905, 0.9827376850545038, -0.7923725490607022, -0.9198995571024576], Output: [-0.9952161322559911, -0.17654187204894087, -0.9592702625553335, -0.8712211559987185]\n",
      "Layer: Layer 2, Input: [-0.9952161322559911, -0.17654187204894087, -0.9592702625553335, -0.8712211559987185], Output: [0.8145941782688726]\n",
      "Epoch 242/500, Loss: 0.23941295173328903, Accuracy: -0.7822716525589972\n",
      "Power operation: base = 0.3554377920656058, power = 2, grad = 0.25\n",
      "Power operation: base = 0.735537092977705, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5058909457845591, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1854058217311274, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890299413425588, 0.9851092011021475, -0.9732351361316433, -0.9970794290098055]\n",
      "Layer: Layer 1, Input: [0.9890299413425588, 0.9851092011021475, -0.9732351361316433, -0.9970794290098055], Output: [-0.9967156539413338, -0.48116624818974496, -0.9725442230530698, -0.8940947818146644]\n",
      "Layer: Layer 2, Input: [-0.9967156539413338, -0.48116624818974496, -0.9725442230530698, -0.8940947818146644], Output: [1.3594012542931946]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981128864234151, 0.9743557713360959, 0.025428941730163173, -0.9279152215331851]\n",
      "Layer: Layer 1, Input: [0.9981128864234151, 0.9743557713360959, 0.025428941730163173, -0.9279152215331851], Output: [-0.9950992266104646, 0.46023311687729285, -0.9336936729966585, -0.873194927997434]\n",
      "Layer: Layer 2, Input: [-0.9950992266104646, 0.46023311687729285, -0.9336936729966585, -0.873194927997434], Output: [-0.2690547929521614]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.929787626193415, 0.24869476832809484, 0.44160232358362944, -0.8688436276670072]\n",
      "Layer: Layer 1, Input: [0.929787626193415, 0.24869476832809484, 0.44160232358362944, -0.8688436276670072], Output: [-0.9691352423332009, 0.9609405337184941, -0.8058409945467816, -0.6497099190915004]\n",
      "Layer: Layer 2, Input: [-0.9691352423332009, 0.9609405337184941, -0.8058409945467816, -0.6497099190915004], Output: [-1.5031773702398574]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8814357141281459, 0.9827971110813669, -0.792422822290349, -0.9199766146539892]\n",
      "Layer: Layer 1, Input: [0.8814357141281459, 0.9827971110813669, -0.792422822290349, -0.9199766146539892], Output: [-0.9952337132543965, -0.1744428608168809, -0.9596328124716568, -0.8723017922231494]\n",
      "Layer: Layer 2, Input: [-0.9952337132543965, -0.1744428608168809, -0.9596328124716568, -0.8723017922231494], Output: [0.8150174403086057]\n",
      "Epoch 243/500, Loss: 0.237714042651302, Accuracy: -0.7785063912722849\n",
      "Power operation: base = 0.3594012542931946, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7309452070478386, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5031773702398574, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18498255969139432, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890358907353299, 0.9851603031158024, -0.9732429006756049, -0.997082632044611]\n",
      "Layer: Layer 1, Input: [0.9890358907353299, 0.9851603031158024, -0.9732429006756049, -0.997082632044611], Output: [-0.99672698212415, -0.481179790245603, -0.9727914983494784, -0.895022977901193]\n",
      "Layer: Layer 2, Input: [-0.99672698212415, -0.481179790245603, -0.9727914983494784, -0.895022977901193], Output: [1.3633433890554594]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998113648076889, 0.9744424789450601, 0.02530173004858037, -0.9279804716901202]\n",
      "Layer: Layer 1, Input: [0.998113648076889, 0.9744424789450601, 0.02530173004858037, -0.9279804716901202], Output: [-0.9951164280853771, 0.465016093313949, -0.9342354524337784, -0.8741457720571322]\n",
      "Layer: Layer 2, Input: [-0.9951164280853771, 0.465016093313949, -0.9342354524337784, -0.8741457720571322], Output: [-0.27361367088505384]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9298128678211149, 0.25029999738943687, 0.4415033807678474, -0.8689543742945681]\n",
      "Layer: Layer 1, Input: [0.9298128678211149, 0.25029999738943687, 0.4415033807678474, -0.8689543742945681], Output: [-0.9693356469181944, 0.9618937413692636, -0.807358511434357, -0.6520915135929735]\n",
      "Layer: Layer 2, Input: [-0.9693356469181944, 0.9618937413692636, -0.807358511434357, -0.6520915135929735], Output: [-1.5005228299597242]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8814860292890738, 0.9828557096516843, -0.7924726275667255, -0.9200528329394764]\n",
      "Layer: Layer 1, Input: [0.8814860292890738, 0.9828557096516843, -0.7924726275667255, -0.9200528329394764], Output: [-0.9952510470089039, -0.17240361789367223, -0.9599888428348534, -0.8733663695126281]\n",
      "Layer: Layer 2, Input: [-0.9952510470089039, -0.17240361789367223, -0.9599888428348534, -0.8733663695126281], Output: [0.8154392909782224]\n",
      "Epoch 244/500, Loss: 0.2360603190302265, Accuracy: -0.7748132571519073\n",
      "Power operation: base = 0.3633433890554594, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7263863291149462, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5005228299597242, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18456070902177757, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890417909968183, 0.9852107027321181, -0.973250597554352, -0.9970858017317968]\n",
      "Layer: Layer 1, Input: [0.9890417909968183, 0.9852107027321181, -0.973250597554352, -0.9970858017317968], Output: [-0.9967381564266218, -0.4812390067075315, -0.9730343321660458, -0.8959371733345594]\n",
      "Layer: Layer 2, Input: [-0.9967381564266218, -0.4812390067075315, -0.9730343321660458, -0.8959371733345594], Output: [1.3672641725896955]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981144025979638, 0.9745279979840766, 0.025175688788992415, -0.9280450060755087]\n",
      "Layer: Layer 1, Input: [0.9981144025979638, 0.9745279979840766, 0.025175688788992415, -0.9280450060755087], Output: [-0.9951333881753998, 0.46972077523252476, -0.9347679515669346, -0.8750830863825746]\n",
      "Layer: Layer 2, Input: [-0.9951333881753998, 0.46972077523252476, -0.9347679515669346, -0.8750830863825746], Output: [-0.2781404415717148]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9298378643036174, 0.2518871319128101, 0.44140535870760733, -0.8690638921617546]\n",
      "Layer: Layer 1, Input: [0.9298378643036174, 0.2518871319128101, 0.44140535870760733, -0.8690638921617546], Output: [-0.9695325861758064, 0.9628187268724027, -0.8088511616680171, -0.6544406746268882]\n",
      "Layer: Layer 2, Input: [-0.9695325861758064, 0.9628187268724027, -0.8088511616680171, -0.6544406746268882], Output: [-1.4979268968486021]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8815358987137494, 0.9829135032884867, -0.7925219779920709, -0.9201282339367343]\n",
      "Layer: Layer 1, Input: [0.8815358987137494, 0.9829135032884867, -0.7925219779920709, -0.9201282339367343], Output: [-0.9952681402695763, -0.17042309633459626, -0.9603385507540979, -0.8744152690157612]\n",
      "Layer: Layer 2, Input: [-0.9952681402695763, -0.17042309633459626, -0.9603385507540979, -0.8744152690157612], Output: [0.8158597383906243]\n",
      "Epoch 245/500, Loss: 0.23445075627828008, Accuracy: -0.7711908894759585\n",
      "Power operation: base = 0.36726417258969546, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7218595584282852, power = 2, grad = 0.25\n",
      "Power operation: base = -0.49792689684860214, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1841402616093757, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890476432202783, 0.9852604189629673, -0.9732582286282112, -0.997088938922493]\n",
      "Layer: Layer 1, Input: [0.9890476432202783, 0.9852604189629673, -0.9732582286282112, -0.997088938922493], Output: [-0.9967491809822917, -0.4813428800571998, -0.9732728584142253, -0.8968377007924476]\n",
      "Layer: Layer 2, Input: [-0.9967491809822917, -0.4813428800571998, -0.9732728584142253, -0.8968377007924476], Output: [1.3711635925468215]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981151501572542, 0.974612360625233, 0.0250507846339923, -0.9281088436423997]\n",
      "Layer: Layer 1, Input: [0.9981151501572542, 0.974612360625233, 0.0250507846339923, -0.9281088436423997], Output: [-0.9951501135022396, 0.47434874254209974, -0.9352914475995183, -0.8760071962895293]\n",
      "Layer: Layer 2, Input: [-0.9951501135022396, 0.47434874254209974, -0.9352914475995183, -0.8760071962895293], Output: [-0.2826359765026689]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9298626216114697, 0.2534566234572086, 0.44130823098480537, -0.8691722140677297]\n",
      "Layer: Layer 1, Input: [0.9298626216114697, 0.2534566234572086, 0.44130823098480537, -0.8691722140677297], Output: [-0.9697261640994457, 0.9637164453933302, -0.8103196752007442, -0.6567582055890834]\n",
      "Layer: Layer 2, Input: [-0.9697261640994457, 0.9637164453933302, -0.8103196752007442, -0.6567582055890834], Output: [-1.4953890945423796]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8815853327840633, 0.9829705137921588, -0.7925708863562246, -0.9202028389990398]\n",
      "Layer: Layer 1, Input: [0.8815853327840633, 0.9829705137921588, -0.7925708863562246, -0.9202028389990398], Output: [-0.9952849995728813, -0.16850025358405873, -0.9606821265139617, -0.8754488631391214]\n",
      "Layer: Layer 2, Input: [-0.9952849995728813, -0.16850025358405873, -0.9606821265139617, -0.8754488631391214], Output: [0.8162787950583175]\n",
      "Epoch 246/500, Loss: 0.23288434769432118, Accuracy: -0.7676379155282147\n",
      "Power operation: base = 0.3711635925468215, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7173640234973311, power = 2, grad = 0.25\n",
      "Power operation: base = -0.49538909454237956, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18372120494168254, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890534484694057, 0.9853094702096383, -0.9732657957122647, -0.9970920444433421]\n",
      "Layer: Layer 1, Input: [0.9890534484694057, 0.9853094702096383, -0.9732657957122647, -0.9970920444433421], Output: [-0.996760059795931, -0.4814904003327191, -0.973507206311218, -0.8977248849675107]\n",
      "Layer: Layer 2, Input: [-0.996760059795931, -0.4814904003327191, -0.973507206311218, -0.8977248849675107], Output: [1.3750416469846671]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981158909208018, 0.9746955980106788, 0.024926985049437616, -0.9281720028043511]\n",
      "Layer: Layer 1, Input: [0.9981158909208018, 0.9746955980106788, 0.024926985049437616, -0.9281720028043511], Output: [-0.9951666104779961, 0.47890155224401737, -0.9358062084103896, -0.8769184197837772]\n",
      "Layer: Layer 2, Input: [-0.9951666104779961, 0.47890155224401737, -0.9358062084103896, -0.8769184197837772], Output: [-0.28710111833229846]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.929887145555857, 0.2550089112350887, 0.44121197179487526, -0.8692793718828479]\n",
      "Layer: Layer 1, Input: [0.929887145555857, 0.2550089112350887, 0.44121197179487526, -0.8692793718828479], Output: [-0.969916480903016, 0.9645878174377702, -0.811764758782896, -0.6590448925324233]\n",
      "Layer: Layer 2, Input: [-0.969916480903016, 0.9645878174377702, -0.811764758782896, -0.6590448925324233], Output: [-1.4929089027035327]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8816343416035846, 0.9830267622637737, -0.7926193651411663, -0.9202766688708524]\n",
      "Layer: Layer 1, Input: [0.8816343416035846, 0.9830267622637737, -0.7926193651411663, -0.9202766688708524], Output: [-0.9953016312484203, -0.16663405261048078, -0.9610197537911443, -0.8764675155646985]\n",
      "Layer: Layer 2, Input: [-0.9953016312484203, -0.16663405261048078, -0.9610197537911443, -0.8764675155646985], Output: [0.8166964774421821]\n",
      "Epoch 247/500, Loss: 0.23136010505063406, Accuracy: -0.7641529539137193\n",
      "Power operation: base = 0.37504164698466713, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7128988816677015, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4929089027035327, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1833035225578179, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890592077790011, 0.9853578742826857, -0.9732733005770572, -0.9970951190971375]\n",
      "Layer: Layer 1, Input: [0.9890592077790011, 0.9853578742826857, -0.9732733005770572, -0.9970951190971375], Output: [-0.9967707967475019, -0.48168056591511627, -0.973737500534959, -0.898599042619706]\n",
      "Layer: Layer 2, Input: [-0.9967707967475019, -0.48168056591511627, -0.973737500534959, -0.898599042619706], Output: [1.3788983434299489]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981166250501776, 0.974777740285891, 0.024804258273413843, -0.928234501449154]\n",
      "Layer: Layer 1, Input: [0.9981166250501776, 0.974777740285891, 0.024804258273413843, -0.928234501449154], Output: [-0.9951828853117984, 0.48338073758607164, -0.9363124928301749, -0.8778170675618568]\n",
      "Layer: Layer 2, Input: [-0.9951828853117984, 0.48338073758607164, -0.9363124928301749, -0.8778170675618568], Output: [-0.2915366813548008]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9299114417921407, 0.2565444223931318, 0.44111655593850474, -0.8693853965720262]\n",
      "Layer: Layer 1, Input: [0.9299114417921407, 0.2565444223931318, 0.44111655593850474, -0.8693853965720262], Output: [-0.9701036331689009, 0.9654337300511702, -0.8131870965426199, -0.6613015041136311]\n",
      "Layer: Layer 2, Input: [-0.9701036331689009, 0.9654337300511702, -0.8131870965426199, -0.6613015041136311], Output: [-1.4904857610769446]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8816829350037261, 0.9830822691277676, -0.7926674265257183, -0.9203497437033447]\n",
      "Layer: Layer 1, Input: [0.8816829350037261, 0.9830822691277676, -0.7926674265257183, -0.9203497437033447], Output: [-0.9953180414254781, -0.16482346294202507, -0.9613516098673346, -0.8774715812871171]\n",
      "Layer: Layer 2, Input: [-0.9953180414254781, -0.16482346294202507, -0.9613516098673346, -0.8774715812871171], Output: [0.8171128055294297]\n",
      "Epoch 248/500, Loss: 0.22987705906006856, Accuracy: -0.760734617622663\n",
      "Power operation: base = 0.3788983434299489, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7084633186451992, power = 2, grad = 0.25\n",
      "Power operation: base = -0.49048576107694464, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18288719447057034, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890649221556304, 0.98540564842121, -0.9732807449493227, -0.9970981636634508]\n",
      "Layer: Layer 1, Input: [0.9890649221556304, 0.98540564842121, -0.9732807449493227, -0.9970981636634508], Output: [-0.99678139559602, -0.4819123842435108, -0.9739638613757482, -0.899460482643329]\n",
      "Layer: Layer 2, Input: [-0.99678139559602, -0.4819123842435108, -0.9739638613757482, -0.899460482643329], Output: [1.382733698005696]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981173527025836, 0.974858816631998, 0.024682573304766215, -0.9282963569523736]\n",
      "Layer: Layer 1, Input: [0.9981173527025836, 0.974858816631998, 0.024682573304766215, -0.9282963569523736], Output: [-0.9951989440162602, 0.48778780734611676, -0.9368105509141248, -0.878703443029081]\n",
      "Layer: Layer 2, Input: [-0.9951989440162602, 0.48778780734611676, -0.9368105509141248, -0.878703443029081], Output: [-0.29594345202457273]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9299355158233857, 0.25806357229232296, 0.4410219588129879, -0.8694903182178186]\n",
      "Layer: Layer 1, Input: [0.9299355158233857, 0.25806357229232296, 0.4410219588129879, -0.8694903182178186], Output: [-0.9702877139900369, 0.9662550379917633, -0.814587350568477, -0.663528791582795]\n",
      "Layer: Layer 2, Input: [-0.9702877139900369, 0.9662550379917633, -0.814587350568477, -0.663528791582795], Output: [-1.4881190733149148]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8817311225498963, 0.9831370541539686, -0.7927150823903962, -0.9204220830697253]\n",
      "Layer: Layer 1, Input: [0.8817311225498963, 0.9831370541539686, -0.7927150823903962, -0.9204220830697253], Output: [-0.9953342360393922, -0.16306746160919156, -0.961677865837901, -0.8784614066685246]\n",
      "Layer: Layer 2, Input: [-0.9953342360393922, -0.16306746160919156, -0.961677865837901, -0.8784614066685246], Output: [0.8175278024397254]\n",
      "Epoch 249/500, Loss: 0.22843425973811934, Accuracy: -0.7573815168563125\n",
      "Power operation: base = 0.3827336980056959, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7040565479754273, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4881190733149148, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18247219756027455, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890705925782821, 0.9854528093115728, -0.9732881305127294, -0.9971011788992491]\n",
      "Layer: Layer 1, Input: [0.9890705925782821, 0.9854528093115728, -0.9732881305127294, -0.9971011788992491], Output: [-0.9967918599833135, -0.4821848724633095, -0.9741864048843809, -0.9003095061470493]\n",
      "Layer: Layer 2, Input: [-0.9967918599833135, -0.4821848724633095, -0.9741864048843809, -0.9003095061470493], Output: [1.3865477346208817]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981180740309538, 0.9749388552971686, 0.02456189989125305, -0.9283575861906955]\n",
      "Layer: Layer 1, Input: [0.9981180740309538, 0.9749388552971686, 0.02456189989125305, -0.9283575861906955], Output: [-0.9952147924137538, 0.4921242452347583, -0.9373006242109896, -0.8795778423330487]\n",
      "Layer: Layer 2, Input: [-0.9952147924137538, 0.4921242452347583, -0.9373006242109896, -0.8795778423330487], Output: [-0.3003221895142154]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9299593730038729, 0.25956676478675494, 0.4409281564032577, -0.869594166043172]\n",
      "Layer: Layer 1, Input: [0.9299593730038729, 0.25956676478675494, 0.4409281564032577, -0.869594166043172], Output: [-0.9704688131062971, 0.9670525648758138, -0.8159661614921035, -0.6657274888115334]\n",
      "Layer: Layer 2, Input: [-0.9704688131062971, 0.9670525648758138, -0.8159661614921035, -0.6657274888115334], Output: [-1.4858082105800081]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8817789135476276, 0.9831911364789818, -0.7927623443223784, -0.9204937059803385]\n",
      "Layer: Layer 1, Input: [0.8817789135476276, 0.9831911364789818, -0.7927623443223784, -0.9204937059803385], Output: [-0.9953502208377458, -0.161365034000009, -0.961998686816155, -0.879437329509201]\n",
      "Layer: Layer 2, Input: [-0.9953502208377458, -0.161365034000009, -0.961998686816155, -0.879437329509201], Output: [0.8179414940583039]\n",
      "Epoch 250/500, Loss: 0.22703077666984728, Accuracy: -0.7540922616283705\n",
      "Power operation: base = 0.38654773462088166, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6996778104857846, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4858082105800081, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18205850594169615, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890762199990227, 0.9854993731055565, -0.973295458908639, -0.9971041655395035]\n",
      "Layer: Layer 1, Input: [0.9890762199990227, 0.9854993731055565, -0.973295458908639, -0.9971041655395035], Output: [-0.9968021934376855, -0.482497058011535, -0.9744052430166616, -0.9011464065453832]\n",
      "Layer: Layer 2, Input: [-0.9968021934376855, -0.482497058011535, -0.9744052430166616, -0.9011464065453832], Output: [1.3903404842190428]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998118789184055, 0.9750178836270845, 0.024442208517383726, -0.9284182055550612]\n",
      "Layer: Layer 1, Input: [0.998118789184055, 0.9750178836270845, 0.024442208517383726, -0.9284182055550612], Output: [-0.9952304361425055, 0.4963915094074381, -0.9377829460274494, -0.8804405544110185]\n",
      "Layer: Layer 2, Input: [-0.9952304361425055, 0.4963915094074381, -0.9377829460274494, -0.8804405544110185], Output: [-0.30467362630399375]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9299830185425865, 0.26105439250062157, 0.4408351252726472, -0.8696969684338379]\n",
      "Layer: Layer 1, Input: [0.9299830185425865, 0.26105439250062157, 0.4408351252726472, -0.8696969684338379], Output: [-0.9706470170353977, 0.9678271042939056, -0.8173241490689951, -0.6678983123560779]\n",
      "Layer: Layer 2, Input: [-0.9706470170353977, 0.9678271042939056, -0.8173241490689951, -0.6678983123560779], Output: [-1.4835525149345097]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.881826317048668, 0.9832445346269453, -0.7928092236205773, -0.9205646308975254]\n",
      "Layer: Layer 1, Input: [0.881826317048668, 0.9832445346269453, -0.7928092236205773, -0.9205646308975254], Output: [-0.995366001386384, -0.1597151746332907, -0.9623142321329887, -0.8803996791321016]\n",
      "Layer: Layer 2, Input: [-0.995366001386384, -0.1597151746332907, -0.9623142321329887, -0.8803996791321016], Output: [0.8183539086949354]\n",
      "Epoch 251/500, Loss: 0.22566569919087298, Accuracy: -0.7508654641546233\n",
      "Power operation: base = 0.39034048421904277, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6953263736960063, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4835525149345097, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1816460913050646, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890818053436445, 0.9855453554379789, -0.9733027317368754, -0.9971071242977851]\n",
      "Layer: Layer 1, Input: [0.9890818053436445, 0.9855453554379789, -0.9733027317368754, -0.9971071242977851], Output: [-0.9968123993774752, -0.48284797914317734, -0.9746204837742181, -0.9019714696601693]\n",
      "Layer: Layer 2, Input: [-0.9968123993774752, -0.48284797914317734, -0.9746204837742181, -0.9019714696601693], Output: [1.3941119840827398]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981194983065871, 0.9750959280945052, 0.024323470391988365, -0.9284782309635861]\n",
      "Layer: Layer 1, Input: [0.9981194983065871, 0.9750959280945052, 0.024323470391988365, -0.9284782309635861], Output: [-0.9952458806625171, 0.5005910320768213, -0.9382577416877124, -0.881291861049626]\n",
      "Layer: Layer 2, Input: [-0.9952458806625171, 0.5005910320768213, -0.9382577416877124, -0.881291861049626], Output: [-0.3089984687971268]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9300064575066743, 0.2625268371029259, 0.44074284255341883, -0.8697987529604287]\n",
      "Layer: Layer 1, Input: [0.9300064575066743, 0.2625268371029259, 0.44074284255341883, -0.8697987529604287], Output: [-0.9708224091985418, 0.9685794208974174, -0.8186619127557433, -0.6700419615517986]\n",
      "Layer: Layer 2, Input: [-0.9708224091985418, 0.9685794208974174, -0.8186619127557433, -0.6700419615517986], Output: [-1.4813513025252085]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8818733418570277, 0.9832972665296633, -0.7928557313007927, -0.9206348757502407]\n",
      "Layer: Layer 1, Input: [0.8818733418570277, 0.9832972665296633, -0.7928557313007927, -0.9206348757502407], Output: [-0.9953815830752597, -0.158116887855136, -0.9626246555317317, -0.8813487764796837]\n",
      "Layer: Layer 2, Input: [-0.9953815830752597, -0.158116887855136, -0.9626246555317317, -0.8813487764796837], Output: [0.8187650767675358]\n",
      "Epoch 252/500, Loss: 0.2243381364910353, Accuracy: -0.7476997410432857\n",
      "Power operation: base = 0.39411198408273984, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6910015312028732, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4813513025252085, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18123492323246415, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890873495123093, 0.98559077144377, -0.9733099505565039, -0.9971100558668522]\n",
      "Layer: Layer 1, Input: [0.9890873495123093, 0.98559077144377, -0.9733099505565039, -0.9971100558668522], Output: [-0.9968224811145218, -0.4832366854022729, -0.9748322313415577, -0.9027849738307288]\n",
      "Layer: Layer 2, Input: [-0.9968224811145218, -0.4832366854022729, -0.9748322313415577, -0.9027849738307288], Output: [1.3978622771907059]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981202015392808, 0.9751730143279449, 0.024205657435570578, -0.9285376778742537]\n",
      "Layer: Layer 1, Input: [0.9981202015392808, 0.9751730143279449, 0.024205657435570578, -0.9285376778742537], Output: [-0.9952611312613114, 0.5047242192169799, -0.9387252287879674, -0.8821320369555529]\n",
      "Layer: Layer 2, Input: [-0.9952611312613114, 0.5047242192169799, -0.9387252287879674, -0.8821320369555529], Output: [-0.31329739795581]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9300296948248742, 0.26398446957948185, 0.44065128593710223, -0.869899546400097]\n",
      "Layer: Layer 1, Input: [0.9300296948248742, 0.26398446957948185, 0.44065128593710223, -0.869899546400097], Output: [-0.9709950700409999, 0.9693102514545762, -0.8199800322822648, -0.6721591186359468]\n",
      "Layer: Layer 2, Input: [-0.9709950700409999, 0.9693102514545762, -0.8199800322822648, -0.6721591186359468], Output: [-1.4792038665722607]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8819199965349707, 0.9833493495461304, -0.7929018781009307, -0.9207044579484103]\n",
      "Layer: Layer 1, Input: [0.8819199965349707, 0.9833493495461304, -0.7929018781009307, -0.9207044579484103], Output: [-0.9953969711241063, -0.15656918846362233, -0.9629301053581103, -0.8822849342215016]\n",
      "Layer: Layer 2, Input: [-0.9953969711241063, -0.15656918846362233, -0.9629301053581103, -0.8822849342215016], Output: [0.8191750305091903]\n",
      "Epoch 253/500, Loss: 0.22304721764869812, Accuracy: -0.7445937152979663\n",
      "Power operation: base = 0.3978622771907059, power = 2, grad = 0.25\n",
      "Power operation: base = 0.68670260204419, power = 2, grad = 0.25\n",
      "Power operation: base = -0.47920386657226066, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18082496949080973, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890928533801839, 0.9856356357745243, -0.9733171168866172, -0.9971129609192233]\n",
      "Layer: Layer 1, Input: [0.9890928533801839, 0.9856356357745243, -0.9733171168866172, -0.9971129609192233], Output: [-0.9968324418575315, -0.48366223804122865, -0.9750405862193338, -0.9035871900315123]\n",
      "Layer: Layer 2, Input: [-0.9968324418575315, -0.48366223804122865, -0.9750405862193338, -0.9035871900315123], Output: [1.4015914116247203]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998120899018996, 0.9752491671394764, 0.02408874226748151, -0.9285965612973714]\n",
      "Layer: Layer 1, Input: [0.998120899018996, 0.9752491671394764, 0.02408874226748151, -0.9285965612973714], Output: [-0.9952761930595105, 0.50879245035142, -0.9391856174454255, -0.8829613498358616]\n",
      "Layer: Layer 2, Input: [-0.9952761930595105, 0.50879245035142, -0.9391856174454255, -0.8829613498358616], Output: [-0.31757106995337603]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9300527352909032, 0.2654276505018375, 0.44056043366467323, -0.8699993747578272]\n",
      "Layer: Layer 1, Input: [0.9300527352909032, 0.2654276505018375, 0.44056043366467323, -0.8699993747578272], Output: [-0.9711650771478272, 0.9700203058757012, -0.8212790682177679, -0.6742504488956222]\n",
      "Layer: Layer 2, Input: [-0.9711650771478272, 0.9700203058757012, -0.8212790682177679, -0.6742504488956222], Output: [-1.4771094801707254]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8819662894089427, 0.9834008004814566, -0.7929476744862689, -0.9207733943970243]\n",
      "Layer: Layer 1, Input: [0.8819662894089427, 0.9834008004814566, -0.7929476744862689, -0.9207733943970243], Output: [-0.9954121705879451, -0.15507110226635065, -0.9632307247452294, -0.8832084568711804]\n",
      "Layer: Layer 2, Input: [-0.9954121705879451, -0.15507110226635065, -0.9632307247452294, -0.8832084568711804], Output: [0.8195838036974119]\n",
      "Epoch 254/500, Loss: 0.22179209160309735, Accuracy: -0.7415460181446578\n",
      "Power operation: base = 0.40159141162472034, power = 2, grad = 0.25\n",
      "Power operation: base = 0.682428930046624, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4771094801707254, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1804161963025881, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890983177980696, 0.9856799626145376, -0.9733242322071224, -0.9971158401077412]\n",
      "Layer: Layer 1, Input: [0.9890983177980696, 0.9856799626145376, -0.9733242322071224, -0.9971158401077412], Output: [-0.9968422847153483, -0.4841237103917011, -0.9752456453538016, -0.9043783819961309]\n",
      "Layer: Layer 2, Input: [-0.9968422847153483, -0.4841237103917011, -0.9752456453538016, -0.9043783819961309], Output: [1.4052994400231915]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981215908788184, 0.9753244105516786, 0.023972698192961137, -0.9286548958077915]\n",
      "Layer: Layer 1, Input: [0.9981215908788184, 0.9753244105516786, 0.023972698192961137, -0.9286548958077915], Output: [-0.9952910710162459, 0.5127970784175506, -0.9396391105417591, -0.8837800604868173]\n",
      "Layer: Layer 2, Input: [-0.9952910710162459, 0.5127970784175506, -0.9396391105417591, -0.8837800604868173], Output: [-0.3218201168384498]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.930075583566805, 0.2668567302927925, 0.4404702645166097, -0.8700982632873285]\n",
      "Layer: Layer 1, Input: [0.930075583566805, 0.2668567302927925, 0.4404702645166097, -0.8700982632873285], Output: [-0.9713325053549081, 0.9707102682074388, -0.8225595625293622, -0.676316600838204]\n",
      "Layer: Layer 2, Input: [-0.9713325053549081, 0.9707102682074388, -0.8225595625293622, -0.676316600838204], Output: [-1.4750673989132976]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8820122285754327, 0.9834516356052065, -0.7929931306547583, -0.920841701509959]\n",
      "Layer: Layer 1, Input: [0.8820122285754327, 0.9834516356052065, -0.7929931306547583, -0.920841701509959], Output: [-0.9954271863624282, -0.15362166657527848, -0.9635266517935267, -0.8841196409114979]\n",
      "Layer: Layer 2, Input: [-0.9954271863624282, -0.15362166657527848, -0.9635266517935267, -0.8841196409114979], Output: [0.819991431404401]\n",
      "Epoch 255/500, Loss: 0.22057192707155232, Accuracy: -0.7385552906936383\n",
      "Power operation: base = 0.4052994400231915, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6781798831615502, power = 2, grad = 0.25\n",
      "Power operation: base = -0.47506739891329763, power = 2, grad = 0.25\n",
      "Power operation: base = -0.180008568595599, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891037435930212, 0.9857237656963409, -0.973331297959536, -0.9971186940661237]\n",
      "Layer: Layer 1, Input: [0.9891037435930212, 0.9857237656963409, -0.973331297959536, -0.9971186940661237], Output: [-0.9968520127001324, -0.4846201881901957, -0.9754475022624753, -0.905158806346771]\n",
      "Layer: Layer 2, Input: [-0.9968520127001324, -0.4846201881901957, -0.9754475022624753, -0.905158806346771], Output: [1.4089864190786865]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981222772481538, 0.9753987678237475, 0.02385749919008058, -0.928712695556885]\n",
      "Layer: Layer 1, Input: [0.9981222772481538, 0.9753987678237475, 0.02385749919008058, -0.928712695556885], Output: [-0.9953057699344057, 0.516739429700657, -0.940085903960769, -0.884588422890113]\n",
      "Layer: Layer 2, Input: [-0.9953057699344057, 0.516739429700657, -0.940085903960769, -0.884588422890113], Output: [-0.3260451472073522]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9300982441862528, 0.26827204948822697, 0.4403807578028525, -0.8701962365115238]\n",
      "Layer: Layer 1, Input: [0.9300982441862528, 0.26827204948822697, 0.4403807578028525, -0.8701962365115238], Output: [-0.9714974268555128, 0.9713807975959563, -0.8238220391323936, -0.6783582063816872]\n",
      "Layer: Layer 2, Input: [-0.9714974268555128, 0.9713807975959563, -0.8238220391323936, -0.6783582063816872], Output: [-1.4730768633425746]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8820578219067537, 0.9835018706691647, -0.7930382565423435, -0.9209093952235219]\n",
      "Layer: Layer 1, Input: [0.8820578219067537, 0.9835018706691647, -0.7930382565423435, -0.9209093952235219], Output: [-0.9954420231890193, -0.1522199306430477, -0.9638180197456743, -0.8850187749264076]\n",
      "Layer: Layer 2, Input: [-0.9954420231890193, -0.1522199306430477, -0.9638180197456743, -0.8850187749264076], Output: [0.8203979497671408]\n",
      "Epoch 256/500, Loss: 0.21938591241786548, Accuracy: -0.7356201854467681\n",
      "Power operation: base = 0.4089864190786865, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6739548527926478, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4730768633425746, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17960205023285924, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891091315689594, 0.9857670583157417, -0.9733383155477733, -0.9971215234095034]\n",
      "Layer: Layer 1, Input: [0.9891091315689594, 0.9857670583157417, -0.9733383155477733, -0.9971215234095034], Output: [-0.9968616287304437, -0.48515076986136146, -0.9756462471559969, -0.9059287127280865]\n",
      "Layer: Layer 2, Input: [-0.9968616287304437, -0.48515076986136146, -0.9756462471559969, -0.9059287127280865], Output: [1.4126524090766135]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981229582528234, 0.9754722614767873, 0.023743119896618925, -0.9287699742842702]\n",
      "Layer: Layer 1, Input: [0.9981229582528234, 0.9754722614767873, 0.023743119896618925, -0.9287699742842702], Output: [-0.9953202944657197, 0.5206208038309618, -0.9405261868201769, -0.8853866843155062]\n",
      "Layer: Layer 2, Input: [-0.9953202944657197, 0.5206208038309618, -0.9405261868201769, -0.8853866843155062], Output: [-0.3302467468814445]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.930120721557804, 0.269673938994991, 0.4402918933526986, -0.8702933182426194]\n",
      "Layer: Layer 1, Input: [0.930120721557804, 0.269673938994991, 0.4402918933526986, -0.8702933182426194], Output: [-0.9716599113025448, 0.9720325292192084, -0.8250670044317141, -0.6803758810625725]\n",
      "Layer: Layer 2, Input: [-0.9716599113025448, 0.9720325292192084, -0.8250670044317141, -0.6803758810625725], Output: [-1.471137101241014]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8821030770567478, 0.9835515209245413, -0.7930830618282929, -0.9209764910097165]\n",
      "Layer: Layer 1, Input: [0.8821030770567478, 0.9835515209245413, -0.7930830618282929, -0.9209764910097165], Output: [-0.9954566856600181, -0.15086495604475839, -0.9641049571564309, -0.8859061397389479]\n",
      "Layer: Layer 2, Input: [-0.9954566856600181, -0.15086495604475839, -0.9641049571564309, -0.8859061397389479], Output: [0.8208033957761791]\n",
      "Epoch 257/500, Loss: 0.2182332554776887, Accuracy: -0.7327393676600038\n",
      "Power operation: base = 0.4126524090766135, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6697532531185555, power = 2, grad = 0.25\n",
      "Power operation: base = -0.47113710124101393, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1791966042238209, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891144825072724, 0.9858098533463852, -0.9733452863389414, -0.9971243287349554]\n",
      "Layer: Layer 1, Input: [0.9891144825072724, 0.9858098533463852, -0.9733452863389414, -0.9971243287349554], Output: [-0.9968711356342361, -0.4857145667618007, -0.9758419670562528, -0.906688343944733]\n",
      "Layer: Layer 2, Input: [-0.9968711356342361, -0.4857145667618007, -0.9758419670562528, -0.906688343944733], Output: [1.4162974734724592]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981236340151545, 0.9755449133183025, 0.023629535596909577, -0.9288267453292912]\n",
      "Layer: Layer 1, Input: [0.9981236340151545, 0.9755449133183025, 0.023629535596909577, -0.9288267453292912], Output: [-0.9953346491156922, 0.5244424738377712, -0.9409601416974582, -0.8861750854289625]\n",
      "Layer: Layer 2, Input: [-0.9953346491156922, 0.5244424738377712, -0.9409601416974582, -0.8861750854289625], Output: [-0.334425479586379]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9301430199681058, 0.2710627203446474, 0.4402036515046541, -0.8703895316017598]\n",
      "Layer: Layer 1, Input: [0.9301430199681058, 0.2710627203446474, 0.4402036515046541, -0.8703895316017598], Output: [-0.9718200259066532, 0.9726660751885093, -0.826294947853232, -0.6823702242591351]\n",
      "Layer: Layer 2, Input: [-0.9718200259066532, 0.9726660751885093, -0.826294947853232, -0.6823702242591351], Output: [-1.4692473297665458]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8821480014664002, 0.9836006011386297, -0.7931275559405251, -0.9210430038892231]\n",
      "Layer: Layer 1, Input: [0.8821480014664002, 0.9836006011386297, -0.7931275559405251, -0.9210430038892231], Output: [-0.9954711782234288, -0.14955581700895457, -0.9643875880574635, -0.8867820085540646]\n",
      "Layer: Layer 2, Input: [-0.9954711782234288, -0.14955581700895457, -0.9643875880574635, -0.8867820085540646], Output: [0.8212078070819469]\n",
      "Epoch 258/500, Loss: 0.21711318334621352, Accuracy: -0.7299115165706791\n",
      "Power operation: base = 0.41629747347245916, power = 2, grad = 0.25\n",
      "Power operation: base = 0.665574520413621, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4692473297665458, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17879219291805315, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989119797167408, 0.9858521632538472, -0.973352211664128, -0.9971271106220119]\n",
      "Layer: Layer 1, Input: [0.989119797167408, 0.9858521632538472, -0.973352211664128, -0.9971271106220119], Output: [-0.9968805361517639, -0.48631070338706356, -0.9760347459107787, -0.9074379361018047]\n",
      "Layer: Layer 2, Input: [-0.9968805361517639, -0.48631070338706356, -0.9760347459107787, -0.9074379361018047], Output: [1.4199216785050597]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981243046540722, 0.9756167444659085, 0.023516722208678408, -0.9288830216422426]\n",
      "Layer: Layer 1, Input: [0.9981243046540722, 0.9756167444659085, 0.023516722208678408, -0.9288830216422426], Output: [-0.995348838248376, 0.5282056862551551, -0.9413879448496766, -0.8869538604054733]\n",
      "Layer: Layer 2, Input: [-0.995348838248376, 0.5282056862551551, -0.9413879448496766, -0.8869538604054733], Output: [-0.3385818876306512]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9301651435850464, 0.27243870594288633, 0.44011601309626686, -0.8704848990382593]\n",
      "Layer: Layer 1, Input: [0.9301651435850464, 0.27243870594288633, 0.44011601309626686, -0.8704848990382593], Output: [-0.9719778355303741, 0.9732820254197532, -0.827506342365202, -0.6843418194280845]\n",
      "Layer: Layer 2, Input: [-0.9719778355303741, 0.9732820254197532, -0.827506342365202, -0.6843418194280845], Output: [-1.4674067574415455]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8821926023693659, 0.9836491256109298, -0.793171748060923, -0.9211089484440959]\n",
      "Layer: Layer 1, Input: [0.8821926023693659, 0.9836491256109298, -0.793171748060923, -0.9211089484440959], Output: [-0.9954855051876785, -0.14829160070135403, -0.9646660321171734, -0.8876466471054696]\n",
      "Layer: Layer 2, Input: [-0.9954855051876785, -0.14829160070135403, -0.9646660321171734, -0.8876466471054696], Output: [0.8216112218175473]\n",
      "Epoch 259/500, Loss: 0.2160249421330468, Accuracy: -0.7271353264984066\n",
      "Power operation: base = 0.4199216785050597, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6614181123693488, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4674067574415455, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1783887781824527, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891250762874558, 0.9858940001092715, -0.9733590928191859, -0.997129869633167]\n",
      "Layer: Layer 1, Input: [0.9891250762874558, 0.9858940001092715, -0.9733590928191859, -0.997129869633167], Output: [-0.9968898329383965, -0.486938317544345, -0.9762246647035038, -0.9081777187474899]\n",
      "Layer: Layer 2, Input: [-0.9968898329383965, -0.486938317544345, -0.9762246647035038, -0.9081777187474899], Output: [1.4235250928435086]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981249702851888, 0.9756877753702812, 0.023404656269902492, -0.9289388157953451]\n",
      "Layer: Layer 1, Input: [0.9981249702851888, 0.9756877753702812, 0.023404656269902492, -0.9289388157953451], Output: [-0.9953628660910027, 0.5319116612739985, -0.9418097664272993, -0.8877232370457975]\n",
      "Layer: Layer 2, Input: [-0.9953628660910027, 0.5319116612739985, -0.9418097664272993, -0.8877232370457975], Output: [-0.3427164925810562]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9301870964608543, 0.27380219931445987, 0.44002895945396164, -0.8705794423484063]\n",
      "Layer: Layer 1, Input: [0.9301870964608543, 0.27380219931445987, 0.44002895945396164, -0.8705794423484063], Output: [-0.9721334027784642, 0.973880948474714, -0.8287016449888129, -0.6862912343527772]\n",
      "Layer: Layer 2, Input: [-0.9721334027784642, 0.973880948474714, -0.8287016449888129, -0.6862912343527772], Output: [-1.4656145860026948]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.882236886797403, 0.9836971081887526, -0.7932156471306253, -0.9211743388301707]\n",
      "Layer: Layer 1, Input: [0.882236886797403, 0.9836971081887526, -0.7932156471306253, -0.9211743388301707], Output: [-0.9954996707261883, -0.147071407464668, -0.9649404047955855, -0.8885003138057425]\n",
      "Layer: Layer 2, Input: [-0.9954996707261883, -0.147071407464668, -0.9649404047955855, -0.8885003138057425], Output: [0.822013678436945]\n",
      "Epoch 260/500, Loss: 0.21496779668876484, Accuracy: -0.7244095078282022\n",
      "Power operation: base = 0.4235250928435086, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6572835074189438, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4656145860026948, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17798632156305505, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891303205847188, 0.9859353756025615, -0.9733659310655133, -0.9971326063143677]\n",
      "Layer: Layer 1, Input: [0.9891303205847188, 0.9859353756025615, -0.9733659310655133, -0.9971326063143677], Output: [-0.9968990285673534, -0.4875965604932702, -0.9764118015618972, -0.9089079150173343]\n",
      "Layer: Layer 2, Input: [-0.9968990285673534, -0.4875965604932702, -0.9764118015618972, -0.9089079150173343], Output: [1.4271077872654199]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981256310208908, 0.9757580258373653, 0.02329331492571444, -0.928994139993466]\n",
      "Layer: Layer 1, Input: [0.9981256310208908, 0.9757580258373653, 0.02329331492571444, -0.928994139993466], Output: [-0.9953767367384616, 0.5355615929356423, -0.9422257706820054, -0.8884834368964349]\n",
      "Layer: Layer 2, Input: [-0.9953767367384616, 0.5355615929356423, -0.9422257706820054, -0.8884834368964349], Output: [-0.3468297959330022]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9302088825351391, 0.275153495343515, 0.4399424723828971, -0.8706731826938455]\n",
      "Layer: Layer 1, Input: [0.9302088825351391, 0.275153495343515, 0.4399424723828971, -0.8706731826938455], Output: [-0.9722867880845794, 0.9744633923729297, -0.829881297297724, -0.6882190214013092]\n",
      "Layer: Layer 2, Input: [-0.9722867880845794, 0.9744633923729297, -0.829881297297724, -0.6882190214013092], Output: [-1.4638700121189463]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8822808615857084, 0.9837445622823167, -0.7932592618552874, -0.9212391887891914]\n",
      "Layer: Layer 1, Input: [0.8822808615857084, 0.9837445622823167, -0.7932592618552874, -0.9212391887891914], Output: [-0.9955136788818006, -0.1458943510176736, -0.9652108174943603, -0.8893432598989454]\n",
      "Layer: Layer 2, Input: [-0.9955136788818006, -0.1458943510176736, -0.9652108174943603, -0.8893432598989454], Output: [0.8224152155675877]\n",
      "Epoch 261/500, Loss: 0.21394103030720613, Accuracy: -0.7217327878837763\n",
      "Power operation: base = 0.42710778726541987, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6531702040669978, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4638700121189463, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17758478443241232, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891355307562744, 0.9859763010551403, -0.9733727276308283, -0.9971353211954939]\n",
      "Layer: Layer 1, Input: [0.9891355307562744, 0.9859763010551403, -0.9733727276308283, -0.9971353211954939], Output: [-0.9969081255323511, -0.48828459705700145, -0.9765962318605791, -0.9096287417795652]\n",
      "Layer: Layer 2, Input: [-0.9969081255323511, -0.48828459705700145, -0.9765962318605791, -0.9096287417795652], Output: [1.4306698343643651]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981262869704253, 0.9758275150498609, 0.023182675915371, -0.9290490060845886]\n",
      "Layer: Layer 1, Input: [0.9981262869704253, 0.9758275150498609, 0.023182675915371, -0.9290490060845886], Output: [-0.9953904541576417, 0.539156649362697, -0.9426361161685157, -0.8892346753722138]\n",
      "Layer: Layer 2, Input: [-0.9953904541576417, 0.539156649362697, -0.9426361161685157, -0.8892346753722138], Output: [-0.3509222797738425]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9302305056378782, 0.2764928805092231, 0.4398565341568608, -0.8707661406195305]\n",
      "Layer: Layer 1, Input: [0.9302305056378782, 0.2764928805092231, 0.4398565341568608, -0.8707661406195305], Output: [-0.9724380497944504, 0.9750298853747418, -0.8310457259062828, -0.6901257177929446]\n",
      "Layer: Layer 2, Input: [-0.9724380497944504, 0.9750298853747418, -0.8310457259062828, -0.6901257177929446], Output: [-1.4621722289846022]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8823245333781543, 0.9837915008793517, -0.7933026007103052, -0.9213035116606442]\n",
      "Layer: Layer 1, Input: [0.8823245333781543, 0.9837915008793517, -0.7933026007103052, -0.9213035116606442], Output: [-0.9955275335710648, -0.14475955861648418, -0.9654773777020069, -0.8901757296151035]\n",
      "Layer: Layer 2, Input: [-0.9955275335710648, -0.14475955861648418, -0.9654773777020069, -0.8901757296151035], Output: [0.8228158718764211]\n",
      "Epoch 262/500, Loss: 0.21294394440723102, Accuracy: -0.7191039116987037\n",
      "Power operation: base = 0.4306698343643651, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6490777202261575, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4621722289846022, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17718412812357887, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989140707479524, 0.986016787432291, -0.9733794837099353, -0.9971380147908253]\n",
      "Layer: Layer 1, Input: [0.989140707479524, 0.986016787432291, -0.9733794837099353, -0.9971380147908253], Output: [-0.9969171262501716, -0.4890016057058097, -0.9767780283214699, -0.9103404097809795]\n",
      "Layer: Layer 2, Input: [-0.9969171262501716, -0.4890016057058097, -0.9767780283214699, -0.9103404097809795], Output: [1.4342113082844543]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981269382399841, 0.9758962615880067, 0.023072717559303162, -0.9291034255700309]\n",
      "Layer: Layer 1, Input: [0.9981269382399841, 0.9758962615880067, 0.023072717559303162, -0.9291034255700309], Output: [-0.9954040221916319, 0.5426979730229183, -0.9430409559404923, -0.8899771618809176]\n",
      "Layer: Layer 2, Input: [-0.9954040221916319, 0.5426979730229183, -0.9430409559404923, -0.8899771618809176], Output: [-0.354994407437621]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9302519694923433, 0.27782063311662997, 0.4397711275082189, -0.8708583360712575]\n",
      "Layer: Layer 1, Input: [0.9302519694923433, 0.27782063311662997, 0.4397711275082189, -0.8708583360712575], Output: [-0.9725872442456943, 0.975580936736108, -0.8321953429462308, -0.6920118458714871]\n",
      "Layer: Layer 2, Input: [-0.9725872442456943, 0.975580936736108, -0.8321953429462308, -0.6920118458714871], Output: [-1.460520427794235]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8823679086324263, 0.9838379365592231, -0.7933456719459945, -0.921367320393313]\n",
      "Layer: Layer 1, Input: [0.8823679086324263, 0.9838379365592231, -0.7933456719459945, -0.921367320393313], Output: [-0.995541238588389, -0.14366617118084468, -0.9657401891343843, -0.8909979603259612]\n",
      "Layer: Layer 2, Input: [-0.995541238588389, -0.14366617118084468, -0.9657401891343843, -0.8909979603259612], Output: [0.8232156859484574]\n",
      "Epoch 263/500, Loss: 0.21197585819732567, Accuracy: -0.7165216426926109\n",
      "Power operation: base = 0.4342113082844543, power = 2, grad = 0.25\n",
      "Power operation: base = 0.645005592562379, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46052042779423497, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1767843140515426, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891458514127321, 0.9860568453550875, -0.9733862004654844, -0.9971406875994997]\n",
      "Layer: Layer 1, Input: [0.9891458514127321, 0.9860568453550875, -0.9733862004654844, -0.9971406875994997], Output: [-0.9969260330631488, -0.4897467786150911, -0.9769572611105548, -0.9110431237929528]\n",
      "Layer: Layer 2, Input: [-0.9969260330631488, -0.4897467786150911, -0.9769572611105548, -0.9110431237929528], Output: [1.4377322844800826]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981275849327864, 0.9759642834496816, 0.022963418746271395, -0.9291574096144131]\n",
      "Layer: Layer 1, Input: [0.9981275849327864, 0.9759642834496816, 0.022963418746271395, -0.9291574096144131], Output: [-0.9954174445637867, 0.5461866810223952, -0.9434404377405754, -0.8907110999494473]\n",
      "Layer: Layer 2, Input: [-0.9954174445637867, 0.5461866810223952, -0.9434404377405754, -0.8907110999494473], Output: [-0.3590466241498875]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9302732777179683, 0.27913702352266684, 0.43968623561793385, -0.8709497884127705]\n",
      "Layer: Layer 1, Input: [0.9302732777179683, 0.27913702352266684, 0.43968623561793385, -0.8709497884127705], Output: [-0.9727344258444054, 0.9761170374358523, -0.8333305465317568, -0.6938779133842997]\n",
      "Layer: Layer 2, Input: [-0.9727344258444054, 0.9761170374358523, -0.8333305465317568, -0.6938779133842997], Output: [-1.4589137991059347]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8824109936250565, 0.98388388150659, -0.7933884835927176, -0.9214306275565489]\n",
      "Layer: Layer 1, Input: [0.8824109936250565, 0.98388388150659, -0.7933884835927176, -0.9214306275565489], Output: [-0.995554797610055, -0.1426133433880585, -0.9659993518705791, -0.8918101827014812]\n",
      "Layer: Layer 2, Input: [-0.995554797610055, -0.1426133433880585, -0.9659993518705791, -0.8918101827014812], Output: [0.8236146961769606]\n",
      "Epoch 264/500, Loss: 0.21103610832609893, Accuracy: -0.7139847632591692\n",
      "Power operation: base = 0.4377322844800826, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6409533758501125, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45891379910593466, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1763853038230394, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891509631955538, 0.9860964851119297, -0.9733928790287216, -0.9971433401059552]\n",
      "Layer: Layer 1, Input: [0.9891509631955538, 0.9860964851119297, -0.9733928790287216, -0.9971433401059552], Output: [-0.9969348482415786, -0.4905193216997219, -0.9771339979313411, -0.9117370827571764]\n",
      "Layer: Layer 2, Input: [-0.9969348482415786, -0.4905193216997219, -0.9771339979313411, -0.9117370827571764], Output: [1.4412328394990328]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981282271491594, 0.9760315980698415, 0.022854758920634377, -0.9292109690553797]\n",
      "Layer: Layer 1, Input: [0.9981282271491594, 0.9760315980698415, 0.022854758920634377, -0.9292109690553797], Output: [-0.9954307248816623, 0.5496238654245366, -0.9438347041846304, -0.8914366873510498]\n",
      "Layer: Layer 2, Input: [-0.9954307248816623, 0.5496238654245366, -0.9438347041846304, -0.8914366873510498], Output: [-0.3630793576613507]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9302944338331589, 0.28044231435728223, 0.4396018421056642, -0.8710405164424534]\n",
      "Layer: Layer 1, Input: [0.9302944338331589, 0.28044231435728223, 0.4396018421056642, -0.8710405164424534], Output: [-0.9728796471386525, 0.9766386608760437, -0.8344517212128293, -0.6957244137658163]\n",
      "Layer: Layer 2, Input: [-0.9728796471386525, 0.9766386608760437, -0.8344517212128293, -0.6957244137658163], Output: [-1.4573515340990881]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8824537944563547, 0.9839293475246099, -0.7934310434659572, -0.921493445351259]\n",
      "Layer: Layer 1, Input: [0.8824537944563547, 0.9839293475246099, -0.7934310434659572, -0.921493445351259], Output: [-0.9955682141981083, -0.14160024373704003, -0.96625496248426, -0.8926126208666157]\n",
      "Layer: Layer 2, Input: [-0.9955682141981083, -0.14160024373704003, -0.96625496248426, -0.8926126208666157], Output: [0.8240129406644434]\n",
      "Epoch 265/500, Loss: 0.21012404852145572, Accuracy: -0.7114920752723268\n",
      "Power operation: base = 0.4412328394990328, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6369206423386493, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45735153409908813, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17598705933555658, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891560434495515, 0.9861357166696928, -0.9733995205002308, -0.9971459727803645]\n",
      "Layer: Layer 1, Input: [0.9891560434495515, 0.9861357166696928, -0.9733995205002308, -0.9971459727803645], Output: [-0.9969435739860542, -0.4913184546265363, -0.9773083041150915, -0.9124224799307681]\n",
      "Layer: Layer 2, Input: [-0.9969435739860542, -0.4913184546265363, -0.9773083041150915, -0.9124224799307681], Output: [1.444713050787203]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981288649866179, 0.9760982223393138, 0.022746718069747495, -0.9292641144130758]\n",
      "Layer: Layer 1, Input: [0.9981288649866179, 0.9760982223393138, 0.022746718069747495, -0.9292641144130758], Output: [-0.9954438666408246, 0.5530105935916574, -0.9442238929403007, -0.8921541162331992]\n",
      "Layer: Layer 2, Input: [-0.9954438666408246, 0.5530105935916574, -0.9442238929403007, -0.8921541162331992], Output: [-0.36709301886937595]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9303154412580414, 0.2817367607396727, 0.4395179310199557, -0.8711305384096022]\n",
      "Layer: Layer 1, Input: [0.9303154412580414, 0.2817367607396727, 0.4395179310199557, -0.8711305384096022], Output: [-0.9730229588890159, 0.9771462635562245, -0.8355592384167768, -0.6975518264244808]\n",
      "Layer: Layer 2, Input: [-0.9730229588890159, 0.9771462635562245, -0.8355592384167768, -0.6975518264244808], Output: [-1.4558328257326476]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8824963170552352, 0.9839743460477058, -0.7934733591713274, -0.9215557856206191]\n",
      "Layer: Layer 1, Input: [0.8824963170552352, 0.9839743460477058, -0.7934733591713274, -0.9215557856206191], Output: [-0.9955814918041178, -0.14062605458481234, -0.966507114170615, -0.8934054925579198]\n",
      "Layer: Layer 2, Input: [-0.9955814918041178, -0.14062605458481234, -0.966507114170615, -0.8934054925579198], Output: [0.8244104571336912]\n",
      "Epoch 266/500, Loss: 0.20923904922093778, Accuracy: -0.7090424005167835\n",
      "Power operation: base = 0.444713050787203, power = 2, grad = 0.25\n",
      "Power operation: base = 0.632906981130624, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4558328257326476, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1755895428663088, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891610927786995, 0.9861745496845035, -0.9734061259506639, -0.9971485860790565]\n",
      "Layer: Layer 1, Input: [0.9891610927786995, 0.9861745496845035, -0.9734061259506639, -0.9971485860790565], Output: [-0.9969522124297246, -0.4921434108065851, -0.9774802427079168, -0.9130995030304467]\n",
      "Layer: Layer 2, Input: [-0.9969522124297246, -0.4921434108065851, -0.9774802427079168, -0.9130995030304467], Output: [1.4481729965132972]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981294985399413, 0.9761641726229636, 0.02263927671150801, -0.929316855899379]\n",
      "Layer: Layer 1, Input: [0.9981294985399413, 0.9761641726229636, 0.02263927671150801, -0.929316855899379], Output: [-0.9954568732285326, 0.5563479085462226, -0.9446081368999601, -0.8928635732457532]\n",
      "Layer: Layer 2, Input: [-0.9954568732285326, 0.5563479085462226, -0.9446081368999601, -0.8928635732457532], Output: [-0.3710880024265051]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9303363033171522, 0.28302061048959987, 0.43943448682853625, -0.8712198720302887]\n",
      "Layer: Layer 1, Input: [0.9303363033171522, 0.28302061048959987, 0.43943448682853625, -0.8712198720302887], Output: [-0.9731644101362814, 0.9776402857222249, -0.836653456878129, -0.6993606170321491]\n",
      "Layer: Layer 2, Input: [-0.9731644101362814, 0.9776402857222249, -0.836653456878129, -0.6993606170321491], Output: [-1.4543568698096108]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8825385671839385, 0.9840188881539041, -0.7935154381095209, -0.9216176598605106]\n",
      "Layer: Layer 1, Input: [0.8825385671839385, 0.9840188881539041, -0.7935154381095209, -0.9216176598605106], Output: [-0.9955946337728162, -0.1396899721576332, -0.9667558968689708, -0.8941890092796299]\n",
      "Layer: Layer 2, Input: [-0.9955946337728162, -0.1396899721576332, -0.9667558968689708, -0.8941890092796299], Output: [0.8248072828480488]\n",
      "Epoch 267/500, Loss: 0.20838049719546567, Accuracy: -0.7066345810483541\n",
      "Power operation: base = 0.44817299651329723, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6289119975734949, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45435686980961076, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17519271715195117, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891661117698777, 0.9862129935121542, -0.9734126964214617, -0.9971511804449271]\n",
      "Layer: Layer 1, Input: [0.9891661117698777, 0.9862129935121542, -0.9734126964214617, -0.9971511804449271], Output: [-0.9969607656404855, -0.49299343736876494, -0.9776498745548142, -0.9137683343754931]\n",
      "Layer: Layer 2, Input: [-0.9969607656404855, -0.49299343736876494, -0.9776498745548142, -0.9137683343754931], Output: [1.4516127554120013]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981301279012491, 0.976229464777256, 0.0225324158820475, -0.929369203426896]\n",
      "Layer: Layer 1, Input: [0.9981301279012491, 0.976229464777256, 0.0225324158820475, -0.929369203426896], Output: [-0.9954697479273017, 0.5596368293490002, -0.9449875643481754, -0.8935652396690507]\n",
      "Layer: Layer 2, Input: [-0.9954697479273017, 0.5596368293490002, -0.9449875643481754, -0.8935652396690507], Output: [-0.37506468733521103]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9303570232420668, 0.28429410433379965, 0.43935149440872273, -0.8713085345028161]\n",
      "Layer: Layer 1, Input: [0.9303570232420668, 0.28429410433379965, 0.43935149440872273, -0.8713085345028161], Output: [-0.9733040482664106, 0.9781211519903111, -0.8377347230567779, -0.7011512378150834]\n",
      "Layer: Layer 2, Input: [-0.9733040482664106, 0.9781211519903111, -0.8377347230567779, -0.7011512378150834], Output: [-1.452922865953127]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.882580550442649, 0.9840629845767611, -0.7935572874811864, -0.9216790792296856]\n",
      "Layer: Layer 1, Input: [0.882580550442649, 0.9840629845767611, -0.7935572874811864, -0.9216790792296856], Output: [-0.9956076433456207, -0.13879120653880228, -0.9670013973812127, -0.8949633764588671]\n",
      "Layer: Layer 2, Input: [-0.9956076433456207, -0.13879120653880228, -0.9670013973812127, -0.8949633764588671], Output: [0.8252034545402758]\n",
      "Epoch 268/500, Loss: 0.20754779516852634, Accuracy: -0.7042674794896415\n",
      "Power operation: base = 0.4516127554120013, power = 2, grad = 0.25\n",
      "Power operation: base = 0.624935312664789, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45292286595312703, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17479654545972423, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891711009933544, 0.9862510572181654, -0.9734192329255651, -0.9971537563078375]\n",
      "Layer: Layer 1, Input: [0.9891711009933544, 0.9862510572181654, -0.9734192329255651, -0.9971537563078375], Output: [-0.9969692356230957, -0.4938677951162977, -0.9778172583807369, -0.9144291510292547]\n",
      "Layer: Layer 2, Input: [-0.9969692356230957, -0.4938677951162977, -0.9778172583807369, -0.9144291510292547], Output: [1.455032406644162]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981307531600757, 0.9762941141672283, 0.022426117123592357, -0.9294211666177195]\n",
      "Layer: Layer 1, Input: [0.9981307531600757, 0.9762941141672283, 0.022426117123592357, -0.9294211666177195], Output: [-0.9954824939183509, 0.5628783514916682, -0.9453622991237903, -0.8942592915416471]\n",
      "Layer: Layer 2, Input: [-0.9954824939183509, 0.5628783514916682, -0.9453622991237903, -0.8942592915416471], Output: [-0.3790234375284056]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9303776041739695, 0.28555747610749876, 0.43926893903794734, -0.8713965425227752]\n",
      "Layer: Layer 1, Input: [0.9303776041739695, 0.28555747610749876, 0.43926893903794734, -0.8713965425227752], Output: [-0.973441919072904, 0.9785892719474237, -0.8388033715445403, -0.7029241278457538]\n",
      "Layer: Layer 2, Input: [-0.973441919072904, 0.9785892719474237, -0.8388033715445403, -0.7029241278457538], Output: [-1.451530018499461]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8826222722740072, 0.9841066457168866, -0.793598914291736, -0.9217400545596665]\n",
      "Layer: Layer 1, Input: [0.8826222722740072, 0.9841066457168866, -0.793598914291736, -0.9217400545596665], Output: [-0.9956205236640369, -0.1379289816350803, -0.967243699486109, -0.895728793599669]\n",
      "Layer: Layer 2, Input: [-0.9956205236640369, -0.1379289816350803, -0.967243699486109, -0.895728793599669], Output: [0.8255990083493279]\n",
      "Epoch 269/500, Loss: 0.20674036143256935, Accuracy: -0.7019399792658896\n",
      "Power operation: base = 0.455032406644162, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6209765624715944, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45153001849946106, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17440099165067213, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891760610032571, 0.986288749587509, -0.973425736448112, -0.9971563140850045]\n",
      "Layer: Layer 1, Input: [0.9891760610032571, 0.986288749587509, -0.973425736448112, -0.9971563140850045], Output: [-0.9969776243212304, -0.4947657584674552, -0.9779824508687798, -0.9150821249389838]\n",
      "Layer: Layer 2, Input: [-0.9969776243212304, -0.4947657584674552, -0.9779824508687798, -0.9150821249389838], Output: [1.4584320296726618]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981313744034415, 0.9763581356828921, 0.022320362472494082, -0.9294727548119542]\n",
      "Layer: Layer 1, Input: [0.9981313744034415, 0.9763581356828921, 0.022320362472494082, -0.9294727548119542], Output: [-0.9954951142849361, 0.5660734473015603, -0.9457324607767508, -0.8949458997874197]\n",
      "Layer: Layer 2, Input: [-0.9954951142849361, 0.5660734473015603, -0.9457324607767508, -0.8949458997874197], Output: [-0.3829646024351603]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9303980491661628, 0.28681095295106274, 0.4391868063844116, -0.8714839122977037]\n",
      "Layer: Layer 1, Input: [0.9303980491661628, 0.28681095295106274, 0.4391868063844116, -0.8714839122977037], Output: [-0.9735780668166578, 0.9790450407282645, -0.8398597254602361, -0.7046797133347305]\n",
      "Layer: Layer 2, Input: [-0.9735780668166578, 0.9790450407282645, -0.8398597254602361, -0.7046797133347305], Output: [-1.4501775373127672]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8826637379675181, 0.9841498816530805, -0.7936403253560775, -0.9218005963643803]\n",
      "Layer: Layer 1, Input: [0.8826637379675181, 0.9841498816530805, -0.7936403253560775, -0.9218005963643803], Output: [-0.9956332777729533, -0.13710253512352436, -0.9674828840496569, -0.8964854544355811]\n",
      "Layer: Layer 2, Input: [-0.9956332777729533, -0.13710253512352436, -0.9674828840496569, -0.8964854544355811], Output: [0.8259939797644149]\n",
      "Epoch 270/500, Loss: 0.20595762946425272, Accuracy: -0.6996509847858539\n",
      "Power operation: base = 0.45843202967266183, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6170353975648397, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4501775373127672, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1740060202355851, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891809923380325, 0.9863260791340004, -0.9734322079471255, -0.9971588541813767]\n",
      "Layer: Layer 1, Input: [0.9891809923380325, 0.9863260791340004, -0.9734322079471255, -0.9971588541813767], Output: [-0.9969859336194644, -0.4956866153818389, -0.9781455067355693, -0.9157274230738219]\n",
      "Layer: Layer 2, Input: [-0.9969859336194644, -0.4956866153818389, -0.9781455067355693, -0.9157274230738219], Output: [1.4618117041527032]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998131991715924, 0.9764215437550828, 0.022215134447435347, -0.9295239770760149]\n",
      "Layer: Layer 1, Input: [0.998131991715924, 0.9764215437550828, 0.022215134447435347, -0.9295239770760149], Output: [-0.9955076120155731, 0.5692230663564748, -0.9460981647197938, -0.8956252303418067]\n",
      "Layer: Layer 2, Input: [-0.9955076120155731, 0.5692230663564748, -0.9460981647197938, -0.8956252303418067], Output: [-0.38688851753133546]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9304183611865181, 0.2880547555018113, 0.43910508249787317, -0.8715706595613573]\n",
      "Layer: Layer 1, Input: [0.9304183611865181, 0.2880547555018113, 0.43910508249787317, -0.8715706595613573], Output: [-0.9737125342834249, 0.9794888395699871, -0.8409040968334234, -0.7064184079220317]\n",
      "Layer: Layer 2, Input: [-0.9737125342834249, 0.9794888395699871, -0.8409040968334234, -0.7064184079220317], Output: [-1.4488646385263948]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8827049526638546, 0.9841927021530914, -0.7936815273032696, -0.9218607148495359]\n",
      "Layer: Layer 1, Input: [0.8827049526638546, 0.9841927021530914, -0.7936815273032696, -0.9218607148495359], Output: [-0.9956459086238244, -0.1363111183804181, -0.9677190291315605, -0.8972335470805812]\n",
      "Layer: Layer 2, Input: [-0.9956459086238244, -0.1363111183804181, -0.9677190291315605, -0.8972335470805812], Output: [0.8263884035757663]\n",
      "Epoch 271/500, Loss: 0.20519904753993737, Accuracy: -0.6973994215719963\n",
      "Power operation: base = 0.46181170415270323, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6131114824686645, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4488646385263948, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17361159642423374, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891858955208949, 0.9863630541093727, -0.9734386483541885, -0.9971613769900042]\n",
      "Layer: Layer 1, Input: [0.9891858955208949, 0.9863630541093727, -0.9734386483541885, -0.9971613769900042], Output: [-0.9969941653451946, -0.4966296672734509, -0.9783064788039436, -0.9163652075607723]\n",
      "Layer: Layer 2, Input: [-0.9969941653451946, -0.4966296672734509, -0.9783064788039436, -0.9163652075607723], Output: [1.4651715098353488]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981326051797267, 0.9764843523707741, 0.022110416037825462, -0.9295748422106984]\n",
      "Layer: Layer 1, Input: [0.9981326051797267, 0.9764843523707741, 0.022110416037825462, -0.9295748422106984], Output: [-0.9955199900071549, 0.5723281359076294, -0.9464595223751235, -0.8962974442769635]\n",
      "Layer: Layer 2, Input: [-0.9955199900071549, 0.5723281359076294, -0.9464595223751235, -0.8962974442769635], Output: [-0.3907955048748293]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9304385431198676, 0.2892890980810448, 0.4390237538005714, -0.8716567995875988]\n",
      "Layer: Layer 1, Input: [0.9304385431198676, 0.2892890980810448, 0.4390237538005714, -0.8716567995875988], Output: [-0.9738453628389764, 0.9799210363452439, -0.8419367869769453, -0.7081406129673545]\n",
      "Layer: Layer 2, Input: [-0.9738453628389764, 0.9799210363452439, -0.8419367869769453, -0.7081406129673545], Output: [-1.4475905452152222]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8827459213590602, 0.9842351166840115, -0.7937225265810977, -0.9219204199217438]\n",
      "Layer: Layer 1, Input: [0.8827459213590602, 0.9842351166840115, -0.7937225265810977, -0.9219204199217438], Output: [-0.9956584190777502, -0.1355539963939001, -0.9679522100879561, -0.8979732541781283]\n",
      "Layer: Layer 2, Input: [-0.9956584190777502, -0.1355539963939001, -0.9679522100879561, -0.8979732541781283], Output: [0.8267823138315773]\n",
      "Epoch 272/500, Loss: 0.20446407835270358, Accuracy: -0.6951842363441645\n",
      "Power operation: base = 0.46517150983534883, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6092044951251707, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44759054521522224, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1732176861684227, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891907710602641, 0.986399682512042, -0.9734450585751067, -0.9971638828923942]\n",
      "Layer: Layer 1, Input: [0.9891907710602641, 0.986399682512042, -0.9734450585751067, -0.9971638828923942], Output: [-0.9970023212704971, -0.4975942289117084, -0.9784654180730045, -0.9169956358185233]\n",
      "Layer: Layer 2, Input: [-0.9970023212704971, -0.4975942289117084, -0.9784654180730045, -0.9169956358185233], Output: [1.4685115264831996]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981332148747457, 0.976546575087873, 0.02200619069238262, -0.929625358759036]\n",
      "Layer: Layer 1, Input: [0.9981332148747457, 0.976546575087873, 0.02200619069238262, -0.929625358759036], Output: [-0.9955322510679642, 0.5753895613090245, -0.9468166413162056, -0.8969626979256561]\n",
      "Layer: Layer 2, Input: [-0.9955322510679642, 0.5753895613090245, -0.9468166413162056, -0.8969626979256561], Output: [-0.39468587362530627]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9304585977703368, 0.29051418887633024, 0.43894280707829647, -0.8717423472039092]\n",
      "Layer: Layer 1, Input: [0.9304585977703368, 0.29051418887633024, 0.43894280707829647, -0.8717423472039092], Output: [-0.9739765924820603, 0.9803419860743313, -0.8429580868484706, -0.7098467178386699]\n",
      "Layer: Layer 2, Input: [-0.9739765924820603, 0.9803419860743313, -0.8429580868484706, -0.7098467178386699], Output: [-1.4463544880033066]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.882786648908646, 0.9842771344223176, -0.793763329460571, -0.9219797211973891]\n",
      "Layer: Layer 1, Input: [0.882786648908646, 0.9842771344223176, -0.793763329460571, -0.9219797211973891], Output: [-0.995670811908453, -0.1348304476617561, -0.9681824996704935, -0.8987047530481636]\n",
      "Layer: Layer 2, Input: [-0.995670811908453, -0.1348304476617561, -0.9681824996704935, -0.8987047530481636], Output: [0.8271757438005771]\n",
      "Epoch 273/500, Loss: 0.20375219863198857, Accuracy: -0.6930043970606228\n",
      "Power operation: base = 0.4685115264831996, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6053141263746937, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44635448800330657, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17282425619942288, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891956194501926, 0.9864359720955729, -0.9734514394905596, -0.9971663722588588]\n",
      "Layer: Layer 1, Input: [0.9891956194501926, 0.9864359720955729, -0.9734514394905596, -0.9971663722588588], Output: [-0.9970104031139257, -0.4985796283115069, -0.978622373785629, -0.9176188606890061]\n",
      "Layer: Layer 2, Input: [-0.9970104031139257, -0.4985796283115069, -0.978622373785629, -0.9176188606890061], Output: [1.4718318337972214]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981338208786356, 0.9766082250495141, 0.02190244230791175, -0.9296755350139283]\n",
      "Layer: Layer 1, Input: [0.9981338208786356, 0.9766082250495141, 0.02190244230791175, -0.9296755350139283], Output: [-0.9955443979205869, 0.5784082264516054, -0.9471696254048035, -0.8976211430037229]\n",
      "Layer: Layer 2, Input: [-0.9955443979205869, 0.5784082264516054, -0.9471696254048035, -0.8976211430037229], Output: [-0.39855992054826794]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.930478527863621, 0.2917302301191054, 0.43886222947160497, -0.8718273168045316]\n",
      "Layer: Layer 1, Input: [0.930478527863621, 0.2917302301191054, 0.43886222947160497, -0.8718273168045316], Output: [-0.974106261895247, 0.9807520314171694, -0.843968277401211, -0.7115371001987322]\n",
      "Layer: Layer 2, Input: [-0.974106261895247, 0.9807520314171694, -0.843968277401211, -0.7115371001987322], Output: [-1.445155705610897]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8828271400315898, 0.9843187642635709, -0.7938039420403377, -0.9220386280112571]\n",
      "Layer: Layer 1, Input: [0.8828271400315898, 0.9843187642635709, -0.7938039420403377, -0.9220386280112571], Output: [-0.9956830898051546, -0.13413976407577688, -0.9684099681218911, -0.8994282158319084]\n",
      "Layer: Layer 2, Input: [-0.9956830898051546, -0.13413976407577688, -0.9684099681218911, -0.8994282158319084], Output: [0.8275687259398072]\n",
      "Epoch 274/500, Loss: 0.20306289876682784, Accuracy: -0.6908588929200432\n",
      "Power operation: base = 0.4718318337972214, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6014400794517321, power = 2, grad = 0.25\n",
      "Power operation: base = -0.445155705610897, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17243127406019276, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892004411707807, 0.9864719303768554, -0.9734577919567393, -0.9971688454488529]\n",
      "Layer: Layer 1, Input: [0.9892004411707807, 0.9864719303768554, -0.9734577919567393, -0.9971688454488529], Output: [-0.9970184125422522, -0.49958520661331995, -0.9787773934935212, -0.9182350305665903]\n",
      "Layer: Layer 2, Input: [-0.9970184125422522, -0.49958520661331995, -0.9787773934935212, -0.9182350305665903], Output: [1.4751325113537312]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981344232668731, 0.9766693149978666, 0.02179915521828089, -0.9297253790255694]\n",
      "Layer: Layer 1, Input: [0.9981344232668731, 0.9766693149978666, 0.02179915521828089, -0.9297253790255694], Output: [-0.9955564332047283, 0.5813849942008094, -0.9475185749233929, -0.8982729267309651]\n",
      "Layer: Layer 2, Input: [-0.9955564332047283, 0.5813849942008094, -0.9475185749233929, -0.8982729267309651], Output: [-0.40241793050347274]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9304983360492032, 0.29293741825766173, 0.438782008467187, -0.8719117223632523]\n",
      "Layer: Layer 1, Input: [0.9304983360492032, 0.29293741825766173, 0.438782008467187, -0.8719117223632523], Output: [-0.974234408493752, 0.9811515031458352, -0.8449676299240281, -0.7132121262890904]\n",
      "Layer: Layer 2, Input: [-0.974234408493752, 0.9811515031458352, -0.8449676299240281, -0.7132121262890904], Output: [-1.4439934453446788]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8828673993142329, 0.9843600148317861, -0.7938443702510145, -0.9220971494249199]\n",
      "Layer: Layer 1, Input: [0.8828673993142329, 0.9843600148317861, -0.7938443702510145, -0.9220971494249199], Output: [-0.9956952553753586, -0.13348125079396828, -0.9686346832680685, -0.9001438096343328]\n",
      "Layer: Layer 2, Input: [-0.9956952553753586, -0.13348125079396828, -0.9686346832680685, -0.9001438096343328], Output: [0.8279612918671209]\n",
      "Epoch 275/500, Loss: 0.202395682433531, Accuracy: -0.6887467343278164\n",
      "Power operation: base = 0.47513251135373125, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5975820694965273, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44399344534467877, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17203870813287914, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892052366885821, 0.9865075646440019, -0.973464116805975, -0.9971713028113014]\n",
      "Layer: Layer 1, Input: [0.9892052366885821, 0.9865075646440019, -0.973464116805975, -0.9971713028113014], Output: [-0.997026351172148, -0.5006103179543256, -0.978930523119884, -0.9188442895248358]\n",
      "Layer: Layer 2, Input: [-0.997026351172148, -0.5006103179543256, -0.978930523119884, -0.9188442895248358], Output: [1.478413638550693]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981350221128191, 0.9767298572874732, 0.02169631418359958, -0.9297748986086604]\n",
      "Layer: Layer 1, Input: [0.9981350221128191, 0.9767298572874732, 0.02169631418359958, -0.9297748986086604], Output: [-0.9955683594799345, 0.5843207068361588, -0.9478635867030761, -0.898918191950341]\n",
      "Layer: Layer 2, Input: [-0.9955683594799345, 0.5843207068361588, -0.9478635867030761, -0.898918191950341], Output: [-0.4062601769177241]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9305180249025168, 0.29413594412557287, 0.4387021318893856, -0.8719955774458266]\n",
      "Layer: Layer 1, Input: [0.9305180249025168, 0.29413594412557287, 0.4387021318893856, -0.8719955774458266], Output: [-0.9743610684723188, 0.9815407205983578, -0.8459564063711339, -0.7148721512112453]\n",
      "Layer: Layer 2, Input: [-0.9743610684723188, 0.9815407205983578, -0.8459564063711339, -0.7148721512112453], Output: [-1.4428669635348847]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8829074312140783, 0.9844008944884804, -0.7938846198594371, -0.9221552942348861]\n",
      "Layer: Layer 1, Input: [0.8829074312140783, 0.9844008944884804, -0.7938846198594371, -0.9221552942348861], Output: [-0.9957073111475387, -0.13285422610182826, -0.9688567106069694, -0.9008516966641819]\n",
      "Layer: Layer 2, Input: [-0.9957073111475387, -0.13285422610182826, -0.9688567106069694, -0.9008516966641819], Output: [0.8283534723380033]\n",
      "Epoch 276/500, Loss: 0.20175006622852876, Accuracy: -0.6866669528298504\n",
      "Power operation: base = 0.47841363855069297, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5937398230822759, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44286696353488475, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17164652766199673, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892100064569992, 0.9865428819639737, -0.9734704148473479, -0.9971737446849182]\n",
      "Layer: Layer 1, Input: [0.9892100064569992, 0.9865428819639737, -0.9734704148473479, -0.9971737446849182], Output: [-0.9970342205718126, -0.5016543293314374, -0.979081807019795, -0.9194467774407348]\n",
      "Layer: Layer 2, Input: [-0.9970342205718126, -0.5016543293314374, -0.979081807019795, -0.9194467774407348], Output: [1.481675294562475]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981356174877793, 0.9767898638981324, 0.021593904379597923, -0.9298241013494238]\n",
      "Layer: Layer 1, Input: [0.9981356174877793, 0.9767898638981324, 0.021593904379597923, -0.9298241013494238], Output: [-0.9955801792282233, 0.5872161864917168, -0.9482047542471321, -0.8995570772453574]\n",
      "Layer: Layer 2, Input: [-0.9955801792282233, 0.5872161864917168, -0.9482047542471321, -0.8995570772453574], Output: [-0.4100869222420962]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9305375969270522, 0.29532599310564134, 0.43862258789187164, -0.8720788952220574]\n",
      "Layer: Layer 1, Input: [0.9305375969270522, 0.29532599310564134, 0.43862258789187164, -0.8720788952220574], Output: [-0.974486276850241, 0.9819199921144692, -0.846934859681612, -0.7165175192046336]\n",
      "Layer: Layer 2, Input: [-0.974486276850241, 0.9819199921144692, -0.846934859681612, -0.7165175192046336], Output: [-1.4417755259227705]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8829472400634932, 0.9844414113414128, -0.7939246964728224, -0.9222130709805216]\n",
      "Layer: Layer 1, Input: [0.8829472400634932, 0.9844414113414128, -0.7939246964728224, -0.9222130709805216], Output: [-0.9957192595737376, -0.13225802126381597, -0.9690761133941819, -0.9015520343714672]\n",
      "Layer: Layer 2, Input: [-0.9957192595737376, -0.13225802126381597, -0.9690761133941819, -0.9015520343714672], Output: [0.8287452972263365]\n",
      "Epoch 277/500, Loss: 0.20112557930702146, Accuracy: -0.6846186010168127\n",
      "Power operation: base = 0.48167529456247493, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5899130777579038, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4417755259227705, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1712547027736635, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989214750916667, 0.986577889189945, -0.9734766868672904, -0.9971761713985144]\n",
      "Layer: Layer 1, Input: [0.989214750916667, 0.986577889189945, -0.9734766868672904, -0.9971761713985144], Output: [-0.9970420222625469, -0.5027166204570801, -0.9792312880383575, -0.9200426301163968]\n",
      "Layer: Layer 2, Input: [-0.9970420222625469, -0.5027166204570801, -0.9792312880383575, -0.9200426301163968], Output: [1.4849175583023193]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981362094610636, 0.9768493464473423, 0.02149191138721369, -0.9298729946124143]\n",
      "Layer: Layer 1, Input: [0.9981362094610636, 0.9768493464473423, 0.02149191138721369, -0.9298729946124143], Output: [-0.9955918948566272, 0.590072235596346, -0.9485421678503245, -0.9001897170555677]\n",
      "Layer: Layer 2, Input: [-0.9955918948566272, 0.590072235596346, -0.9485421678503245, -0.9001897170555677], Output: [-0.41389841839376373]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9305570545564092, 0.2965077452894369, 0.4385433649494754, -0.8721616884775346]\n",
      "Layer: Layer 1, Input: [0.9305570545564092, 0.2965077452894369, 0.4385433649494754, -0.8721616884775346], Output: [-0.9746100675146027, 0.9822896154539836, -0.8479032340889839, -0.7181485639211637]\n",
      "Layer: Layer 2, Input: [-0.9746100675146027, 0.9822896154539836, -0.8479032340889839, -0.7181485639211637], Output: [-1.4407184080017035]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8829868300733132, 0.9844815732530252, -0.7939646055428499, -0.9222704879517435]\n",
      "Layer: Layer 1, Input: [0.8829868300733132, 0.9844815732530252, -0.7939646055428499, -0.9222704879517435], Output: [-0.9957311030320782, -0.13169198036608942, -0.9692929527254592, -0.9022449755823524]\n",
      "Layer: Layer 2, Input: [-0.9957311030320782, -0.13169198036608942, -0.9692929527254592, -0.9022449755823524], Output: [0.8291367955087532]\n",
      "Epoch 278/500, Loss: 0.2005217630279471, Accuracy: -0.6826007524015059\n",
      "Power operation: base = 0.4849175583023193, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5861015816062363, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4407184080017035, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1708632044912468, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892194704958276, 0.9866125929684164, -0.9734829336301749, -0.9971785832713003]\n",
      "Layer: Layer 1, Input: [0.9892194704958276, 0.9866125929684164, -0.9734829336301749, -0.9971785832713003], Output: [-0.9970497577202748, -0.5037965836085082, -0.9793790075667115, -0.9206319793981309]\n",
      "Layer: Layer 2, Input: [-0.9970497577202748, -0.5037965836085082, -0.9793790075667115, -0.9206319793981309], Output: [1.4881405083918242]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981367981000425, 0.9769083162023184, 0.021390321182385638, -0.9299215855471384]\n",
      "Layer: Layer 1, Input: [0.9981367981000425, 0.9769083162023184, 0.021390321182385638, -0.9299215855471384], Output: [-0.9956035086996515, 0.5928896373127872, -0.9488759147140997, -0.9008162417901004]\n",
      "Layer: Layer 2, Input: [-0.9956035086996515, 0.5928896373127872, -0.9488759147140997, -0.9008162417901004], Output: [-0.4176949071825753]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9305764001562955, 0.2976813756325015, 0.43846445185017785, -0.8722439696250404]\n",
      "Layer: Layer 1, Input: [0.9305764001562955, 0.2976813756325015, 0.43846445185017785, -0.8722439696250404], Output: [-0.9747324732618101, 0.9826498781984689, -0.8488617654210496, -0.7197656086960592]\n",
      "Layer: Layer 2, Input: [-0.9747324732618101, 0.9826498781984689, -0.8488617654210496, -0.7197656086960592], Output: [-1.4396948953149882]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8830262053363535, 0.9845213878485928, -0.7940043523696546, -0.9223275531964957]\n",
      "Layer: Layer 1, Input: [0.8830262053363535, 0.9845213878485928, -0.7940043523696546, -0.9223275531964957], Output: [-0.9957428438291918, -0.13115546015145924, -0.9695072876162457, -0.9029306686313657]\n",
      "Layer: Layer 2, Input: [-0.9957428438291918, -0.13115546015145924, -0.9695072876162457, -0.9029306686313657], Output: [0.8295279952522332]\n",
      "Epoch 279/500, Loss: 0.19993817060572983, Accuracy: -0.6806125012720039\n",
      "Power operation: base = 0.4881405083918242, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5823050928174247, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4396948953149882, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1704720047477668, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892241656106943, 0.9866469997460807, -0.9734891558788894, -0.9971809806131746]\n",
      "Layer: Layer 1, Input: [0.9892241656106943, 0.9866469997460807, -0.9734891558788894, -0.9971809806131746], Output: [-0.9970574283770168, -0.5048936234713809, -0.97952500559597, -0.9212149532929046]\n",
      "Layer: Layer 2, Input: [-0.9970574283770168, -0.5048936234713809, -0.97952500559597, -0.9212149532929046], Output: [1.4913442231367569]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981373834702041, 0.9769667840916008, 0.021289120126051927, -0.929969881094481]\n",
      "Layer: Layer 1, Input: [0.9981373834702041, 0.9769667840916008, 0.021289120126051927, -0.929969881094481], Output: [-0.9956150230216475, 0.5956691559746887, -0.9492060790577944, -0.9014367779391523]\n",
      "Layer: Layer 2, Input: [-0.9956150230216475, 0.5956691559746887, -0.9492060790577944, -0.9014367779391523], Output: [-0.42147662072260683]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9305956360264721, 0.298847054105307, 0.43838583768725853, -0.8723257507156293]\n",
      "Layer: Layer 1, Input: [0.9305956360264721, 0.298847054105307, 0.43838583768725853, -0.8723257507156293], Output: [-0.9748535258374857, 0.9830010581368471, -0.849810681390244, -0.7213689668148026]\n",
      "Layer: Layer 2, Input: [-0.9748535258374857, 0.9830010581368471, -0.849810681390244, -0.7213689668148026], Output: [-1.4387042837133581]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8830653698308267, 0.9845608625240967, -0.79404394210574, -0.9223842745280071]\n",
      "Layer: Layer 1, Input: [0.8830653698308267, 0.9845608625240967, -0.79404394210574, -0.9223842745280071], Output: [-0.9957544842025619, -0.1306478298475149, -0.9697191750783082, -0.9036092574908997]\n",
      "Layer: Layer 2, Input: [-0.9957544842025619, -0.1306478298475149, -0.9697191750783082, -0.9036092574908997], Output: [0.8299189236046667]\n",
      "Epoch 280/500, Loss: 0.19937436676916084, Accuracy: -0.6786529625228415\n",
      "Power operation: base = 0.49134422313675685, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5785233792773932, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4387042837133581, power = 2, grad = 0.25\n",
      "Power operation: base = -0.17008107639533332, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892288366658062, 0.986681115776455, -0.9734953543353995, -0.997183363725009]\n",
      "Layer: Layer 1, Input: [0.9892288366658062, 0.986681115776455, -0.9734953543353995, -0.997183363725009], Output: [-0.9970650356223116, -0.5060071569783137, -0.979669320769159, -0.9217916760821546]\n",
      "Layer: Layer 2, Input: [-0.9970650356223116, -0.5060071569783137, -0.979669320769159, -0.9217916760821546], Output: [1.4945287805086416]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981379656352081, 0.9770247607162638, 0.02118829495435796, -0.9300178879929496]\n",
      "Layer: Layer 1, Input: [0.9981379656352081, 0.9770247607162638, 0.02118829495435796, -0.9300178879929496], Output: [-0.9956264400191084, 0.5984115375208127, -0.9495327422259815, -0.9020514481833977]\n",
      "Layer: Layer 2, Input: [-0.9956264400191084, 0.5984115375208127, -0.9495327422259815, -0.9020514481833977], Output: [-0.42524378182891187]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9306147644026469, 0.3000049458400397, 0.4383075118516049, -0.8724070434493935]\n",
      "Layer: Layer 1, Input: [0.9306147644026469, 0.3000049458400397, 0.4383075118516049, -0.8724070434493935], Output: [-0.9749732559747922, 0.9833434236355488, -0.8507502018747342, -0.7229589417760011]\n",
      "Layer: Layer 2, Input: [-0.9749732559747922, 0.9833434236355488, -0.8507502018747342, -0.7229589417760011], Output: [-1.437745879574913]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.88310432742367, 0.9846000044538246, -0.7940833797598024, -0.9224406595318401]\n",
      "Layer: Layer 1, Input: [0.88310432742367, 0.9846000044538246, -0.7940833797598024, -0.9224406595318401], Output: [-0.995766026322793, -0.13016847098874276, -0.9699286701935712, -0.9042808818979556]\n",
      "Layer: Layer 2, Input: [-0.995766026322793, -0.13016847098874276, -0.9699286701935712, -0.9042808818979556], Output: [0.8303096067880666]\n",
      "Epoch 281/500, Loss: 0.19882992742773262, Accuracy: -0.676721271466576\n",
      "Power operation: base = 0.4945287805086416, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5747562181710881, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43774587957491295, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16969039321193335, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892334840543733, 0.986714947126284, -0.9735015297012996, -0.9971857328989228]\n",
      "Layer: Layer 1, Input: [0.9892334840543733, 0.986714947126284, -0.9735015297012996, -0.9971857328989228], Output: [-0.9970725808045934, -0.5071366131430127, -0.9798119904312286, -0.922362268432947]\n",
      "Layer: Layer 2, Input: [-0.9970725808045934, -0.5071366131430127, -0.9798119904312286, -0.922362268432947], Output: [1.4976942581315091]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981385446569384, 0.9770822563607413, 0.02108783276906918, -0.9300656127847335]\n",
      "Layer: Layer 1, Input: [0.9981385446569384, 0.9770822563607413, 0.02108783276906918, -0.9300656127847335], Output: [-0.9956377618228874, 0.6011175099257149, -0.9498559827920702, -0.9026603715012684]\n",
      "Layer: Layer 2, Input: [-0.9956377618228874, 0.6011175099257149, -0.9498559827920702, -0.9026603715012684], Output: [-0.4289966043997486]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9306337874583182, 0.30115521127330186, 0.4382294640241799, -0.8724878591859124]\n",
      "Layer: Layer 1, Input: [0.9306337874583182, 0.30115521127330186, 0.4382294640241799, -0.8724878591859124], Output: [-0.9750916934312513, 0.9836772339938258, -0.8516805391905078, -0.7245358275500213]\n",
      "Layer: Layer 2, Input: [-0.9750916934312513, 0.9836772339938258, -0.8516805391905078, -0.7245358275500213], Output: [-1.436818999990113]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8831430818737815, 0.9846388205977109, -0.794122670200474, -0.9224967155727355]\n",
      "Layer: Layer 1, Input: [0.8831430818737815, 0.9846388205977109, -0.794122670200474, -0.9224967155727355], Output: [-0.9957774722957988, -0.12971677723345942, -0.9701358261852513, -0.9049456774781133]\n",
      "Layer: Layer 2, Input: [-0.9957774722957988, -0.12971677723345942, -0.9701358261852513, -0.9049456774781133], Output: [0.8307000700942133]\n",
      "Epoch 282/500, Loss: 0.19830443934563927, Accuracy: -0.6748165836276603\n",
      "Power operation: base = 0.49769425813150914, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5710033956002514, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4368189999901131, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16929992990578668, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892381081586115, 0.9867484996817224, -0.9735076826583506, -0.9971880884185474]\n",
      "Layer: Layer 1, Input: [0.9892381081586115, 0.9867484996817224, -0.9735076826583506, -0.9971880884185474], Output: [-0.9970800652325218, -0.5082814328906158, -0.9799530506772064, -0.922926847506479]\n",
      "Layer: Layer 2, Input: [-0.9970800652325218, -0.5082814328906158, -0.9799530506772064, -0.922926847506479], Output: [1.5008407332733267]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981391205955552, 0.9771392810032814, 0.02098772102819175, -0.9301130618215905]\n",
      "Layer: Layer 1, Input: [0.9981391205955552, 0.9771392810032814, 0.02098772102819175, -0.9301130618215905], Output: [-0.9956489905003397, 0.6037877836262767, -0.9501758766582828, -0.9032636632740761]\n",
      "Layer: Layer 2, Input: [-0.9956489905003397, 0.6037877836262767, -0.9501758766582828, -0.9032636632740761], Output: [-0.43273529378457365]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9306527073065669, 0.30229800628480963, 0.43815168416864936, -0.8725682089544045]\n",
      "Layer: Layer 1, Input: [0.9306527073065669, 0.30229800628480963, 0.43815168416864936, -0.8725682089544045], Output: [-0.9752088670241187, 0.9840027397848062, -0.8526018983546788, -0.7260999088332656]\n",
      "Layer: Layer 2, Input: [-0.9752088670241187, 0.9840027397848062, -0.8526018983546788, -0.7260999088332656], Output: [-1.4359229729143257]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8831816368351704, 0.9846773177084259, -0.7941618181599821, -0.9225524498012555]\n",
      "Layer: Layer 1, Input: [0.8831816368351704, 0.9846773177084259, -0.7941618181599821, -0.9225524498012555], Output: [-0.9957888241649203, -0.12929215417627365, -0.9703406944863848, -0.9056037758667094]\n",
      "Layer: Layer 2, Input: [-0.9957888241649203, -0.12929215417627365, -0.9703406944863848, -0.9056037758667094], Output: [0.8310903378824426]\n",
      "Epoch 283/500, Loss: 0.1977974998236422, Accuracy: -0.6729380745206361\n",
      "Power operation: base = 0.5008407332733267, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5672647062154264, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4359229729143257, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16890966211755742, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892427093500686, 0.9867817791543044, -0.9735138138690055, -0.9971904305592875]\n",
      "Layer: Layer 1, Input: [0.9892427093500686, 0.9867817791543044, -0.9735138138690055, -0.9971904305592875], Output: [-0.9970874901762679, -0.5094410688847864, -0.9800925363985549, -0.9234855270639349]\n",
      "Layer: Layer 2, Input: [-0.9970874901762679, -0.5094410688847864, -0.9800925363985549, -0.9234855270639349], Output: [1.50396828284161]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981396935095447, 0.9771958443260425, 0.02088794753679765, -0.930160241270556]\n",
      "Layer: Layer 1, Input: [0.9981396935095447, 0.9771958443260425, 0.02088794753679765, -0.930160241270556], Output: [-0.9956601280573937, 0.6064230519435474, -0.9504924971521229, -0.9038614353889504]\n",
      "Layer: Layer 2, Input: [-0.9956601280573937, 0.6064230519435474, -0.9504924971521229, -0.9038614353889504], Output: [-0.4364600471381177]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9306715260018009, 0.3034334823321773, 0.4380741625241681, -0.8726481034635812]\n",
      "Layer: Layer 1, Input: [0.9306715260018009, 0.3034334823321773, 0.4380741625241681, -0.8726481034635812], Output: [-0.9753248046643771, 0.9843201831828609, -0.8535144773402523, -0.7276514612979867]\n",
      "Layer: Layer 2, Input: [-0.9753248046643771, 0.9843201831828609, -0.8535144773402523, -0.7276514612979867], Output: [-1.4350571372902352]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.88321999586002, 0.9847155023382186, -0.7942008282377246, -0.9226078691602315]\n",
      "Layer: Layer 1, Input: [0.88321999586002, 0.9847155023382186, -0.7942008282377246, -0.9226078691602315], Output: [-0.9958000839129684, -0.12889401915677742, -0.9705433248058392, -0.9062553048272185]\n",
      "Layer: Layer 2, Input: [-0.9958000839129684, -0.12889401915677742, -0.9705433248058392, -0.9062553048272185], Output: [0.8314804335793999]\n",
      "Epoch 284/500, Loss: 0.19730871638891379, Accuracy: -0.6710849394143277\n",
      "Power operation: base = 0.5039682828416101, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5635399528618823, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4350571372902352, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16851956642060006, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892472879899423, 0.986814791086708, -0.9735199239769228, -0.9971927595885691]\n",
      "Layer: Layer 1, Input: [0.9892472879899423, 0.986814791086708, -0.9735199239769228, -0.9971927595885691], Output: [-0.997094856868759, -0.510614985352091, -0.9802304813278034, -0.924038417569704]\n",
      "Layer: Layer 2, Input: [-0.997094856868759, -0.510614985352091, -0.9802304813278034, -0.924038417569704], Output: [1.5070769833828201]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981402634557679, 0.9772519557248417, 0.02078850043805545, -0.9302071571194893]\n",
      "Layer: Layer 1, Input: [0.9981402634557679, 0.9772519557248417, 0.02078850043805545, -0.9302071571194893], Output: [-0.9956711764405518, 0.6090239914993959, -0.9508059151194493, -0.90445379633958]\n",
      "Layer: Layer 2, Input: [-0.9956711764405518, 0.6090239914993959, -0.9508059151194493, -0.90445379633958], Output: [-0.44017105376082366]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9306902455414507, 0.30456178658186867, 0.4379968895983241, -0.8727275531112133]\n",
      "Layer: Layer 1, Input: [0.9306902455414507, 0.30456178658186867, 0.4379968895983241, -0.8727275531112133], Output: [-0.9754395333894003, 0.984629798277825, -0.8544184673225819, -0.7291907518375574]\n",
      "Layer: Layer 2, Input: [-0.9754395333894003, 0.984629798277825, -0.8544184673225819, -0.7291907518375574], Output: [-1.4342208431423256]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8832581624016667, 0.9847533808455265, -0.7942397049037639, -0.9226629803910236]\n",
      "Layer: Layer 1, Input: [0.8832581624016667, 0.9847533808455265, -0.7942397049037639, -0.9226629803910236], Output: [-0.9958112534642017, -0.12852180106509856, -0.9707437651918979, -0.9069003883668375]\n",
      "Layer: Layer 2, Input: [-0.9958112534642017, -0.12852180106509856, -0.9707437651918979, -0.9069003883668375], Output: [0.83187037968053]\n",
      "Epoch 285/500, Loss: 0.19683770649297216, Accuracy: -0.669256393083792\n",
      "Power operation: base = 0.5070769833828201, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5598289462391763, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43422084314232556, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16812962031946999, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892518444293873, 0.9868475408583202, -0.9735260136074676, -0.9971950757660856]\n",
      "Layer: Layer 1, Input: [0.9892518444293873, 0.9868475408583202, -0.9735260136074676, -0.9971950757660856], Output: [-0.99710216650688, -0.511802657904134, -0.980366918081512, -0.9245856262919808]\n",
      "Layer: Layer 2, Input: [-0.99710216650688, -0.511802657904134, -0.980366918081512, -0.9245856262919808], Output: [1.510166911085081]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981408304895081, 0.9773076243185709, 0.020689368204461975, -0.9302538151824516]\n",
      "Layer: Layer 1, Input: [0.9981408304895081, 0.9773076243185709, 0.020689368204461975, -0.9302538151824516], Output: [-0.9956821375388231, 0.6115912626275666, -0.9511161990142663, -0.905040851324745]\n",
      "Layer: Layer 2, Input: [-0.9956821375388231, 0.6115912626275666, -0.9511161990142663, -0.905040851324745], Output: [-0.4438684954260683]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9307088678676192, 0.30568306203640855, 0.4379198561602395, -0.872806567993416]\n",
      "Layer: Layer 1, Input: [0.9307088678676192, 0.30568306203640855, 0.4379198561602395, -0.872806567993416], Output: [-0.9755530793943483, 0.9849318113766087, -0.8553140529177524, -0.730718038807126]\n",
      "Layer: Layer 2, Input: [-0.9755530793943483, 0.9849318113766087, -0.8553140529177524, -0.730718038807126], Output: [-1.4334134516455173]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8832961398174967, 0.9847909594013573, -0.7942784525022389, -0.9227177900395923]\n",
      "Layer: Layer 1, Input: [0.8832961398174967, 0.9847909594013573, -0.7942784525022389, -0.9227177900395923], Output: [-0.995822334686234, -0.12817494014490152, -0.9709420620935012, -0.907539146849286]\n",
      "Layer: Layer 2, Input: [-0.995822334686234, -0.12817494014490152, -0.9709420620935012, -0.907539146849286], Output: [0.8322601977531239]\n",
      "Epoch 286/500, Loss: 0.19638409721771508, Accuracy: -0.6674516695514061\n",
      "Power operation: base = 0.510166911085081, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5561315045739317, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43341345164551726, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16773980224687612, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892563790098157, 0.9868800336906108, -0.9735320833682017, -0.997197379344031]\n",
      "Layer: Layer 1, Input: [0.9892563790098157, 0.9868800336906108, -0.9735320833682017, -0.997197379344031], Output: [-0.9971094202526354, -0.5130035733579071, -0.9805018782016289, -0.9251272574007692]\n",
      "Layer: Layer 2, Input: [-0.9971094202526354, -0.5130035733579071, -0.9805018782016289, -0.9251272574007692], Output: [1.513238141783904]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981413946645165, 0.9773628589582876, 0.020590539629275876, -0.9303002211049279]\n",
      "Layer: Layer 1, Input: [0.9981413946645165, 0.9773628589582876, 0.020590539629275876, -0.9303002211049279], Output: [-0.9956930131855921, 0.614125509778743, -0.9514234149853378, -0.9056227023446413]\n",
      "Layer: Layer 2, Input: [-0.9956930131855921, 0.614125509778743, -0.9514234149853378, -0.9056227023446413], Output: [-0.44755254669440836]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9307273948686839, 0.3067974476579332, 0.4378430532338272, -0.8728851579136604]\n",
      "Layer: Layer 1, Input: [0.9307273948686839, 0.3067974476579332, 0.4378430532338272, -0.8728851579136604], Output: [-0.9756654680623396, 0.9852264412927015, -0.8562014124131151, -0.7322335722596144]\n",
      "Layer: Layer 2, Input: [-0.9756654680623396, 0.9852264412927015, -0.8562014124131151, -0.7322335722596144], Output: [-1.4326343351699018]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8833339313717617, 0.9848282439954498, -0.7943170752546986, -0.922772304462391]\n",
      "Layer: Layer 1, Input: [0.8833339313717617, 0.9848282439954498, -0.7943170752546986, -0.922772304462391], Output: [-0.9958333293918802, -0.12785288779438927, -0.9711382604192301, -0.9081716971048305]\n",
      "Layer: Layer 2, Input: [-0.9958333293918802, -0.12785288779438927, -0.9711382604192301, -0.9081716971048305], Output: [0.832649908440767]\n",
      "Epoch 287/500, Loss: 0.1959475249896038, Accuracy: -0.6656700218186304\n",
      "Power operation: base = 0.513238141783904, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5524474533055916, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4326343351699018, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16735009155923297, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892608920631875, 0.9869122746523207, -0.9735381338493612, -0.9971996705673306]\n",
      "Layer: Layer 1, Input: [0.9892608920631875, 0.9869122746523207, -0.9735381338493612, -0.9971996705673306], Output: [-0.9971166192342736, -0.514217229554768, -0.9806353921953029, -0.9256634120633175]\n",
      "Layer: Layer 2, Input: [-0.9971166192342736, -0.514217229554768, -0.9806353921953029, -0.9256634120633175], Output: [1.5162907509705308]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981419560330574, 0.9774176682359942, 0.020492003818148415, -0.9303463803688906]\n",
      "Layer: Layer 1, Input: [0.9981419560330574, 0.9774176682359942, 0.020492003818148415, -0.9303463803688906], Output: [-0.9957038051604227, 0.6166273619193253, -0.9517276269597346, -0.9061994482949968]\n",
      "Layer: Layer 2, Input: [-0.9957038051604227, 0.6166273619193253, -0.9517276269597346, -0.9061994482949968], Output: [-0.45122337521531053]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9307458283808567, 0.3079050784881725, 0.43776647209120223, -0.8729633323915189]\n",
      "Layer: Layer 1, Input: [0.9307458283808567, 0.3079050784881725, 0.43776647209120223, -0.8729633323915189], Output: [-0.9757767239934548, 0.9855138996240684, -0.8570807179902055, -0.7337375941770182]\n",
      "Layer: Layer 2, Input: [-0.9757767239934548, 0.9855138996240684, -0.8570807179902055, -0.7337375941770182], Output: [-1.431882877303417]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8833715402383162, 0.9848652404422248, -0.794355577263353, -0.9228265298320831]\n",
      "Layer: Layer 1, Input: [0.8833715402383162, 0.9848652404422248, -0.794355577263353, -0.9228265298320831], Output: [-0.9958442393409354, -0.12755510636580275, -0.9713324035941098, -0.9087981525375598]\n",
      "Layer: Layer 2, Input: [-0.9958442393409354, -0.12755510636580275, -0.9713324035941098, -0.9087981525375598], Output: [0.8330395314690007]\n",
      "Epoch 288/500, Loss: 0.19552763530193992, Accuracy: -0.6639107215896365\n",
      "Power operation: base = 0.5162907509705308, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5487766247846895, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4318828773034169, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16696046853099933, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892653839122942, 0.986944268664471, -0.9735441656243216, -0.997201949673862]\n",
      "Layer: Layer 1, Input: [0.9892653839122942, 0.986944268664471, -0.9735441656243216, -0.997201949673862], Output: [-0.9971237645473724, -0.5154431351784423, -0.9807674895732036, -0.9261941885370165]\n",
      "Layer: Layer 2, Input: [-0.9971237645473724, -0.5154431351784423, -0.9807674895732036, -0.9261941885370165], Output: [1.5193248138026307]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981425146459519, 0.9774720604931166, 0.02039375018095506, -0.9303922982977143]\n",
      "Layer: Layer 1, Input: [0.9981425146459519, 0.9774720604931166, 0.02039375018095506, -0.9303922982977143], Output: [-0.9957145151908019, 0.6190974329236218, -0.9520288967234122, -0.9067711850589907]\n",
      "Layer: Layer 2, Input: [-0.9957145151908019, 0.6190974329236218, -0.9520288967234122, -0.9067711850589907], Output: [-0.4548811420166379]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.930764170189697, 0.3090060857649455, 0.4376901042462461, -0.8730411006711503]\n",
      "Layer: Layer 1, Input: [0.930764170189697, 0.3090060857649455, 0.4376901042462461, -0.8730411006711503], Output: [-0.9758868710326188, 0.9857943910199067, -0.8579521359402644, -0.7352303386969947]\n",
      "Layer: Layer 2, Input: [-0.9758868710326188, 0.9857943910199067, -0.8579521359402644, -0.7352303386969947], Output: [-1.4311584728541913]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.883408969503277, 0.9849019543865299, -0.794393962514248, -0.9228804721430862]\n",
      "Layer: Layer 1, Input: [0.883408969503277, 0.9849019543865299, -0.794393962514248, -0.9228804721430862], Output: [-0.9958550662418996, -0.1272810689638888, -0.9715245336143155, -0.9094186232299307]\n",
      "Layer: Layer 2, Input: [-0.9958550662418996, -0.1272810689638888, -0.9715245336143155, -0.9094186232299307], Output: [0.8334290856520781]\n",
      "Epoch 289/500, Loss: 0.19512408244522078, Accuracy: -0.6621730589881061\n",
      "Power operation: base = 0.5193248138026307, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5451188579833621, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4311584728541913, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16657091434792193, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892698548710328, 0.9869760205052006, -0.9735501792500534, -0.9972042168946706]\n",
      "Layer: Layer 1, Input: [0.9892698548710328, 0.9869760205052006, -0.9735501792500534, -0.9972042168946706], Output: [-0.9971308572558881, -0.5166808095723937, -0.9808981988864056, -0.9267196822597931]\n",
      "Layer: Layer 2, Input: [-0.9971308572558881, -0.5166808095723937, -0.9808981988864056, -0.9267196822597931], Output: [1.5223404051170055]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981430705526192, 0.9775260438286906, 0.020295768423815953, -0.9304379800609411]\n",
      "Layer: Layer 1, Input: [0.9981430705526192, 0.9775260438286906, 0.020295768423815953, -0.9304379800609411], Output: [-0.9957251449538255, 0.6215363219592416, -0.9523272839989244, -0.9073380055969836]\n",
      "Layer: Layer 2, Input: [-0.9957251449538255, 0.6215363219592416, -0.9523272839989244, -0.9073380055969836], Output: [-0.45852600178231473]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9307824220315845, 0.31010059703525683, 0.43761394144832216, -0.8731184717295329]\n",
      "Layer: Layer 1, Input: [0.9307824220315845, 0.31010059703525683, 0.43761394144832216, -0.8731184717295329], Output: [-0.975995932296406, 0.9860681134367241, -0.8588158268725813, -0.736712032334728]\n",
      "Layer: Layer 2, Input: [-0.975995932296406, 0.9860681134367241, -0.8588158268725813, -0.736712032334728], Output: [-1.4304605278341862]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8834462221676075, 0.9849383913091869, -0.7944322348803617, -0.922934137216952]\n",
      "Layer: Layer 1, Input: [0.8834462221676075, 0.9849383913091869, -0.7944322348803617, -0.922934137216952], Output: [-0.995865811753639, -0.12703025924376804, -0.9717146910998521, -0.9100332160446168]\n",
      "Layer: Layer 2, Input: [-0.995865811753639, -0.12703025924376804, -0.9717146910998521, -0.9100332160446168], Output: [0.8338185889006828]\n",
      "Epoch 290/500, Loss: 0.1947365292454724, Accuracy: -0.6604563422681942\n",
      "Power operation: base = 0.5223404051170055, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5414739982176853, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4304605278341862, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16618141109931717, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892743052446732, 0.987007534814436, -0.9735561752675653, -0.9972064724541779]\n",
      "Layer: Layer 1, Input: [0.9892743052446732, 0.987007534814436, -0.9735561752675653, -0.9972064724541779], Output: [-0.9971378983931716, -0.5179297825569219, -0.9810275477618924, -0.9272399859380378]\n",
      "Layer: Layer 2, Input: [-0.9971378983931716, -0.5179297825569219, -0.9810275477618924, -0.9272399859380378], Output: [1.5253375994441223]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981436238011184, 0.9775796261072677, 0.020198048541312123, -0.9304834306789053]\n",
      "Layer: Layer 1, Input: [0.9981436238011184, 0.9775796261072677, 0.020198048541312123, -0.9304834306789053], Output: [-0.9957356960778248, 0.6239446138654806, -0.9526228465203654, -0.9079000000340811]\n",
      "Layer: Layer 2, Input: [-0.9957356960778248, 0.6239446138654806, -0.9526228465203654, -0.9079000000340811], Output: [-0.46215810311850714]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9308005855951481, 0.3111887362650761, 0.43753797567613945, -0.8731954542844506]\n",
      "Layer: Layer 1, Input: [0.9308005855951481, 0.3111887362650761, 0.43753797567613945, -0.8731954542844506], Output: [-0.9761039301988128, 0.9863352583841734, -0.859671945915877, -0.7381828942000745]\n",
      "Layer: Layer 2, Input: [-0.9761039301988128, 0.9863352583841734, -0.859671945915877, -0.7381828942000745], Output: [-1.4297884594256534]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8834833011496293, 0.9849745565323487, -0.7944703981246258, -0.9229875307075825]\n",
      "Layer: Layer 1, Input: [0.8834833011496293, 0.9849745565323487, -0.7944703981246258, -0.9229875307075825], Output: [-0.9958764774869934, -0.12680217120860862, -0.971902915345283, -0.9106420347236908]\n",
      "Layer: Layer 2, Input: [-0.9958764774869934, -0.12680217120860862, -0.971902915345283, -0.9106420347236908], Output: [0.8342080582304945]\n",
      "Epoch 291/500, Loss: 0.19436464681049376, Accuracy: -0.658759897520774\n",
      "Power operation: base = 0.5253375994441223, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5378418968814929, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42978845942565336, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1657919417695055, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989278735330117, 0.9870388160984012, -0.9735621542023359, -0.9972087165703839]\n",
      "Layer: Layer 1, Input: [0.989278735330117, 0.9870388160984012, -0.9735621542023359, -0.9972087165703839], Output: [-0.9971448889629477, -0.5191895942462601, -0.9811555629367232, -0.927755189632103]\n",
      "Layer: Layer 2, Input: [-0.9971448889629477, -0.5191895942462601, -0.9811555629367232, -0.927755189632103], Output: [1.528316471024132]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981441744381884, 0.97763281496655, 0.020100580808889417, -0.9305286550272159]\n",
      "Layer: Layer 1, Input: [0.9981441744381884, 0.97763281496655, 0.020100580808889417, -0.9305286550272159], Output: [-0.9957461701439397, 0.6263228795245479, -0.9529156401056376, -0.9084572557455435]\n",
      "Layer: Layer 2, Input: [-0.9957461701439397, 0.6263228795245479, -0.9529156401056376, -0.9084572557455435], Output: [-0.46577758880870057]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9308186625226562, 0.3122706239458879, 0.43746219913176576, -0.87327205680224]\n",
      "Layer: Layer 1, Input: [0.9308186625226562, 0.3122706239458879, 0.43746219913176576, -0.87327205680224], Output: [-0.9762108864760416, 0.9865960111610704, -0.8605206429129324, -0.7396431362100008]\n",
      "Layer: Layer 2, Input: [-0.9762108864760416, 0.9865960111610704, -0.8605206429129324, -0.7396431362100008], Output: [-1.4291416959318735]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8835202092874611, 0.9850104552246713, -0.7945084559028699, -0.9230406581062898]\n",
      "Layer: Layer 1, Input: [0.8835202092874611, 0.9850104552246713, -0.7945084559028699, -0.9230406581062898], Output: [-0.9958870650063287, -0.12659630900743873, -0.9720892443685771, -0.9112451799851768]\n",
      "Layer: Layer 2, Input: [-0.9958870650063287, -0.12659630900743873, -0.9720892443685771, -0.9112451799851768], Output: [0.8345975097714504]\n",
      "Epoch 292/500, Loss: 0.19400811428388204, Accuracy: -0.6570830683758544\n",
      "Power operation: base = 0.5283164710241319, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5342224111912994, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42914169593187346, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16540249022854958, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892831454161497, 0.9870698687339708, -0.9735681165647356, -0.9972109494550634]\n",
      "Layer: Layer 1, Input: [0.9892831454161497, 0.9870698687339708, -0.9735681165647356, -0.9972109494550634], Output: [-0.9971518299402644, -0.5204597948659881, -0.9812822702909233, -0.9282653808394173]\n",
      "Layer: Layer 2, Input: [-0.9971518299402644, -0.5204597948659881, -0.9812822702909233, -0.9282653808394173], Output: [1.5312770938242517]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981447225092862, 0.9776856178247623, 0.020003355775448622, -0.9305736578411065]\n",
      "Layer: Layer 1, Input: [0.9981447225092862, 0.9776856178247623, 0.020003355775448622, -0.9305736578411065], Output: [-0.9957565686876386, 0.6286716762255001, -0.9532057187261371, -0.9090098574400693]\n",
      "Layer: Layer 2, Input: [-0.9957565686876386, 0.6286716762255001, -0.9532057187261371, -0.9090098574400693], Output: [-0.4693845960580125]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9308366544113647, 0.3133463771980916, 0.4373866042347842, -0.8733482875053055]\n",
      "Layer: Layer 1, Input: [0.9308366544113647, 0.3133463771980916, 0.4373866042347842, -0.8733482875053055], Output: [-0.9763168222103321, 0.986850551081997, -0.8613620626086752, -0.7410929632963382]\n",
      "Layer: Layer 2, Input: [-0.9763168222103321, 0.986850551081997, -0.8613620626086752, -0.7410929632963382], Output: [-1.4285196767134698]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8835569493413881, 0.9850460924063088, -0.7945464117666936, -0.9230935247467017]\n",
      "Layer: Layer 1, Input: [0.8835569493413881, 0.9850460924063088, -0.7945464117666936, -0.9230935247467017], Output: [-0.9958975758310371, -0.12641218673348295, -0.9722737149581463, -0.9118427496170127]\n",
      "Layer: Layer 2, Input: [-0.9958975758310371, -0.12641218673348295, -0.9722737149581463, -0.9118427496170127], Output: [0.8349869587776961]\n",
      "Epoch 293/500, Loss: 0.19366661860672793, Accuracy: -0.6554252157020128\n",
      "Power operation: base = 0.5312770938242517, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5306154039419875, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4285196767134698, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16501304122230387, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892875357836847, 0.9871006969728758, -0.9735740628504364, -0.9972131713139549]\n",
      "Layer: Layer 1, Input: [0.9892875357836847, 0.9871006969728758, -0.9735740628504364, -0.9972131713139549], Output: [-0.9971587222724082, -0.5217399445709976, -0.9814076948791352, -0.9287706445752526]\n",
      "Layer: Layer 2, Input: [-0.9971587222724082, -0.5217399445709976, -0.9814076948791352, -0.9287706445752526], Output: [1.5342195415572366]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981452680586246, 0.9777380418877718, 0.019906364256118386, -0.93061844371965]\n",
      "Layer: Layer 1, Input: [0.9981452680586246, 0.9777380418877718, 0.019906364256118386, -0.93061844371965], Output: [-0.9957668932001861, 0.6309915480207959, -0.9534931345739425, -0.9095578872409763]\n",
      "Layer: Layer 2, Input: [-0.9957668932001861, 0.6309915480207959, -0.9534931345739425, -0.9095578872409763], Output: [-0.472979256727152]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9308545628148283, 0.3144161098713348, 0.4373111836165937, -0.8734241543794067]\n",
      "Layer: Layer 1, Input: [0.9308545628148283, 0.3144161098713348, 0.4373111836165937, -0.8734241543794067], Output: [-0.9764217578528833, 0.9870990516948823, -0.8621963448319205, -0.7425325736088817]\n",
      "Layer: Layer 2, Input: [-0.9764217578528833, 0.9870990516948823, -0.8621963448319205, -0.7425325736088817], Output: [-1.4279218521116284]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8835935239961623, 0.985081472953736, -0.7945842691662659, -0.9231461358095194]\n",
      "Layer: Layer 1, Input: [0.8835935239961623, 0.985081472953736, -0.7945842691662659, -0.9231461358095194], Output: [-0.9959080114369852, -0.12624932822328275, -0.9724563627181335, -0.9124348385684597]\n",
      "Layer: Layer 2, Input: [-0.9959080114369852, -0.12624932822328275, -0.9724563627181335, -0.9124348385684597], Output: [0.8353764196380222]\n",
      "Epoch 294/500, Loss: 0.19333985428683303, Accuracy: -0.6537857173036907\n",
      "Power operation: base = 0.5342195415572366, power = 2, grad = 0.25\n",
      "Power operation: base = 0.527020743272848, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42792185211162836, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16462358036197777, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892919067060005, 0.9871313049457623, -0.9735799935408131, -0.9972153823469464]\n",
      "Layer: Layer 1, Input: [0.9892919067060005, 0.9871313049457623, -0.9735799935408131, -0.9972153823469464], Output: [-0.9971655668797905, -0.5230296132642662, -0.981531860961082, -0.9292710634511957]\n",
      "Layer: Layer 2, Input: [-0.9971655668797905, -0.5230296132642662, -0.981531860961082, -0.9292710634511957], Output: [1.5371438877008172]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981458111292091, 0.977790094155964, 0.01980959732521134, -0.9306630171298502]\n",
      "Layer: Layer 1, Input: [0.9981458111292091, 0.977790094155964, 0.01980959732521134, -0.9306630171298502], Output: [-0.9957771451300609, 0.6332830260753817, -0.9537779381265961, -0.9101014247653061]\n",
      "Layer: Layer 2, Input: [-0.9957771451300609, 0.6332830260753817, -0.9537779381265961, -0.9101014247653061], Output: [-0.4765616975563258]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9308723892441728, 0.3154799326418597, 0.43723593011485096, -0.8734996651807272]\n",
      "Layer: Layer 1, Input: [0.9308723892441728, 0.3154799326418597, 0.43723593011485096, -0.8734996651807272], Output: [-0.9765257132459012, 0.9873416809899347, -0.8630236246709666, -0.7439621587138685]\n",
      "Layer: Layer 2, Input: [-0.9765257132459012, 0.9873416809899347, -0.8630236246709666, -0.7439621587138685], Output: [-1.427347683359339]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8836299358632378, 0.9851166016044062, -0.794622031453052, -0.9231984963271297]\n",
      "Layer: Layer 1, Input: [0.8836299358632378, 0.9851166016044062, -0.794622031453052, -0.9231984963271297], Output: [-0.9959183732579153, -0.1261072668569148, -0.9726372221120201, -0.9130215390390067]\n",
      "Layer: Layer 2, Input: [-0.9959183732579153, -0.1261072668569148, -0.9726372221120201, -0.9130215390390067], Output: [0.8357659058868174]\n",
      "Epoch 295/500, Loss: 0.19302752317530877, Accuracy: -0.652163967617013\n",
      "Power operation: base = 0.5371438877008172, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5234383024436742, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42734768335933904, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16423409411318257, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892962584489717, 0.9871616966661112, -0.9735859091033319, -0.9972175827482529]\n",
      "Layer: Layer 1, Input: [0.9892962584489717, 0.9871616966661112, -0.9735859091033319, -0.9972175827482529], Output: [-0.9971723646568027, -0.5243283804166501, -0.9816547920308872, -0.9297667177513639]\n",
      "Layer: Layer 2, Input: [-0.9971723646568027, -0.5243283804166501, -0.9816547920308872, -0.9297667177513639], Output: [1.5400502055178844]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981463517628728, 0.9778417814308819, 0.019713046309354092, -0.9307073824106036]\n",
      "Layer: Layer 1, Input: [0.9981463517628728, 0.9778417814308819, 0.019713046309354092, -0.9307073824106036], Output: [-0.9957873258843284, 0.635546629008279, -0.9540601782095596, -0.9106405472008842]\n",
      "Layer: Layer 2, Input: [-0.9957873258843284, 0.635546629008279, -0.9540601782095596, -0.9106405472008842], Output: [-0.4801320403794995]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9308901351693307, 0.31653795310694377, 0.4371608367680502, -0.8735748274427276]\n",
      "Layer: Layer 1, Input: [0.9308901351693307, 0.31653795310694377, 0.4371608367680502, -0.8735748274427276], Output: [-0.9766287076438035, 0.9875786016002852, -0.863844032643235, -0.7453819037878817]\n",
      "Layer: Layer 2, Input: [-0.9766287076438035, 0.9875786016002852, -0.863844032643235, -0.7453819037878817], Output: [-1.4267966424818375]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.88366618748294, 0.9851514829612475, -0.7946597018824721, -0.9232506111880774]\n",
      "Layer: Layer 1, Input: [0.88366618748294, 0.9851514829612475, -0.7946597018824721, -0.9232506111880774], Output: [-0.9959286626867967, -0.12598554535955234, -0.9728163265046125, -0.9136029405648094]\n",
      "Layer: Layer 2, Input: [-0.9959286626867967, -0.12598554535955234, -0.9728163265046125, -0.9136029405648094], Output: [0.8361554302153813]\n",
      "Epoch 296/500, Loss: 0.1927293342503919, Accuracy: -0.650559377404841\n",
      "Power operation: base = 0.5400502055178844, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5198679596205005, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42679664248183746, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1638445697846187, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893005912712918, 0.9871918760340247, -0.9735918099919307, -0.9972197727065893]\n",
      "Layer: Layer 1, Input: [0.9893005912712918, 0.9871918760340247, -0.9735918099919307, -0.9972197727065893], Output: [-0.9971791164726451, -0.5256358348878962, -0.9817765108452903, -0.9302576855064129]\n",
      "Layer: Layer 2, Input: [-0.9971791164726451, -0.5256358348878962, -0.9817765108452903, -0.9302576855064129], Output: [1.5429385680773056]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981468900003113, 0.9778931103216387, 0.019616702780794165, -0.9307515437765445]\n",
      "Layer: Layer 1, Input: [0.9981468900003113, 0.9778931103216387, 0.019616702780794165, -0.9307515437765445], Output: [-0.9957974368299619, 0.6377828632266368, -0.9543399020564265, -0.9111753293813659]\n",
      "Layer: Layer 2, Input: [-0.9957974368299619, 0.6377828632266368, -0.9543399020564265, -0.9111753293813659], Output: [-0.48369040232933536]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9309078020202413, 0.3175902758765123, 0.4370858968102396, -0.8736496484827924]\n",
      "Layer: Layer 1, Input: [0.9309078020202413, 0.3175902758765123, 0.4370858968102396, -0.8736496484827924], Output: [-0.976730759733624, 0.9878099709946869, -0.8646576948591452, -0.7467919878072246]\n",
      "Layer: Layer 2, Input: [-0.976730759733624, 0.9878099709946869, -0.8646576948591452, -0.7467919878072246], Output: [-1.426268212187228]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8837022813265714, 0.9851861214970068, -0.7946972836164896, -0.9233024851414002]\n",
      "Layer: Layer 1, Input: [0.8837022813265714, 0.9851861214970068, -0.7946972836164896, -0.9233024851414002], Output: [-0.9959388810771339, -0.12588371560459705, -0.9729937082024663, -0.9141791301027131]\n",
      "Layer: Layer 2, Input: [-0.9959388810771339, -0.12588371560459705, -0.9729937082024663, -0.9141791301027131], Output: [0.8365450044835736]\n",
      "Epoch 297/500, Loss: 0.19244500340831228, Accuracy: -0.6489713734516247\n",
      "Power operation: base = 0.5429385680773056, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5163095976706646, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4262682121872281, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1634549955164264, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893049054246905, 0.9872218468398807, -0.9735976966473886, -0.997221952405339]\n",
      "Layer: Layer 1, Input: [0.9893049054246905, 0.9872218468398807, -0.9735976966473886, -0.997221952405339], Output: [-0.9971858231721252, -0.5269515747490632, -0.9818970394508034, -0.9307440425653845]\n",
      "Layer: Layer 2, Input: [-0.9971858231721252, -0.5269515747490632, -0.9818970394508034, -0.9307440425653845], Output: [1.5458090482752205]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981474258811157, 0.9779440872511111, 0.019520558550876834, -0.9307955053217706]\n",
      "Layer: Layer 1, Input: [0.9981474258811157, 0.9779440872511111, 0.019520558550876834, -0.9307955053217706], Output: [-0.9958074792951251, 0.6399922232522383, -0.9546171553669669, -0.9117058438592994]\n",
      "Layer: Layer 2, Input: [-0.9958074792951251, 0.6399922232522383, -0.9546171553669669, -0.9117058438592994], Output: [-0.4872368960331479]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9309253911880145, 0.3186370026619971, 0.43701110366587226, -0.8737241354086736]\n",
      "Layer: Layer 1, Input: [0.9309253911880145, 0.3186370026619971, 0.43701110366587226, -0.8737241354086736], Output: [-0.97683188765464, 0.9880359416626009, -0.8654647331804041, -0.7481925837328188]\n",
      "Layer: Layer 2, Input: [-0.97683188765464, 0.9880359416626009, -0.8654647331804041, -0.7481925837328188], Output: [-1.4257618857483032]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8837382197984573, 0.9852205215584432, -0.794734779726133, -0.9233541228008314]\n",
      "Layer: Layer 1, Input: [0.8837382197984573, 0.9852205215584432, -0.794734779726133, -0.9233541228008314], Output: [-0.9959490297442278, -0.1258013384186148, -0.9731693984928079, -0.9147501921119051]\n",
      "Layer: Layer 2, Input: [-0.9959490297442278, -0.1258013384186148, -0.9731693984928079, -0.9147501921119051], Output: [0.8369346397317337]\n",
      "Epoch 298/500, Loss: 0.19217425326104837, Accuracy: -0.6473993982586421\n",
      "Power operation: base = 0.5458090482752205, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5127631039668521, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4257618857483032, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16306536026826635, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893092011541448, 0.9872516127678633, -0.9736035694976859, -0.997224122022715]\n",
      "Layer: Layer 1, Input: [0.9893092011541448, 0.9872516127678633, -0.9736035694976859, -0.997224122022715], Output: [-0.9971924855764318, -0.5282752071065124, -0.9820163992098456, -0.9312258626654418]\n",
      "Layer: Layer 2, Input: [-0.9971924855764318, -0.5282752071065124, -0.9820163992098456, -0.9312258626654418], Output: [1.5486617188567058]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981479594438054, 0.9779947184619193, 0.019424605663689375, -0.9308392710234552]\n",
      "Layer: Layer 1, Input: [0.9981479594438054, 0.9779947184619193, 0.019424605663689375, -0.9308392710234552], Output: [-0.9958174545704058, 0.6421751920404917, -0.9548919823630826, -0.9122321609772419]\n",
      "Layer: Layer 2, Input: [-0.9958174545704058, 0.6421751920404917, -0.9548919823630826, -0.9122321609772419], Output: [-0.49077162980024847]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9309429040260628, 0.3196782323625216, 0.4369364509447869, -0.8737982951247395]\n",
      "Layer: Layer 1, Input: [0.9309429040260628, 0.3196782323625216, 0.4369364509447869, -0.8737982951247395], Output: [-0.9769321090172601, 0.9882566612919866, -0.8662652653728897, -0.7495838586906844]\n",
      "Layer: Layer 2, Input: [-0.9769321090172601, 0.9882566612919866, -0.8662652653728897, -0.7495838586906844], Output: [-1.4252771668764415]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8837740052379303, 0.9852546873703785, -0.7947721931939516, -0.9234055286488743]\n",
      "Layer: Layer 1, Input: [0.8837740052379303, 0.9852546873703785, -0.7947721931939516, -0.9234055286488743], Output: [-0.9959591099663959, -0.12573798338824463, -0.9733434276810068, -0.9153162086332438]\n",
      "Layer: Layer 2, Input: [-0.9959591099663959, -0.12573798338824463, -0.9733434276810068, -0.9153162086332438], Output: [0.8373243461928226]\n",
      "Epoch 299/500, Loss: 0.19191681294078383, Accuracy: -0.6458429097400762\n",
      "Power operation: base = 0.5486617188567058, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5092283701997515, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42527716687644146, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1626756538071774, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893134786980826, 0.9872811773993713, -0.9736094289583537, -0.9972262817319186]\n",
      "Layer: Layer 1, Input: [0.9893134786980826, 0.9872811773993713, -0.9736094289583537, -0.9972262817319186], Output: [-0.9971991044838807, -0.529606347927627, -0.9821346108258953, -0.9317032174995366]\n",
      "Layer: Layer 2, Input: [-0.9971991044838807, -0.529606347927627, -0.9821346108258953, -0.9317032174995366], Output: [1.5514966524376694]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981484907258592, 0.9780450100222043, 0.01932883638987307, -0.930882844745349]\n",
      "Layer: Layer 1, Input: [0.9981484907258592, 0.9780450100222043, 0.01932883638987307, -0.930882844745349], Output: [-0.9958273639100123, 0.6443322412919068, -0.9551644258427447, -0.9127543489369616]\n",
      "Layer: Layer 2, Input: [-0.9958273639100123, 0.6443322412919068, -0.9551644258427447, -0.9127543489369616], Output: [-0.4942947078009703]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9309603418511979, 0.3207140611484823, 0.4368619324373205, -0.8738721343380305]\n",
      "Layer: Layer 1, Input: [0.9309603418511979, 0.3207140611484823, 0.4368619324373205, -0.8738721343380305], Output: [-0.9770314409211981, 0.9884722729401009, -0.8670594052543008, -0.75096597414806]\n",
      "Layer: Layer 2, Input: [-0.9770314409211981, 0.9884722729401009, -0.8670594052543008, -0.75096597414806], Output: [-1.4248135695884647]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8838096399212566, 0.9852886230396086, -0.7948095269164066, -0.9234567070407506]\n",
      "Layer: Layer 1, Input: [0.8838096399212566, 0.9852886230396086, -0.7948095269164066, -0.9234567070407506], Output: [-0.9959691229861518, -0.12569322866928406, -0.973515825126651, -0.9158772593663136]\n",
      "Layer: Layer 2, Input: [-0.9959691229861518, -0.12569322866928406, -0.973515825126651, -0.9158772593663136], Output: [0.8377141333047371]\n",
      "Epoch 300/500, Loss: 0.1916724179108969, Accuracy: -0.6443013809204268\n",
      "Power operation: base = 0.5514966524376694, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5057052921990297, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4248135695884647, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1622858666952629, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893177382885815, 0.9873105442163103, -0.9736152754328166, -0.9972284317012912]\n",
      "Layer: Layer 1, Input: [0.9893177382885815, 0.9873105442163103, -0.9736152754328166, -0.9972284317012912], Output: [-0.9972056806706393, -0.5309446218683803, -0.982251694367695, -0.9321761767820599]\n",
      "Layer: Layer 2, Input: [-0.9972056806706393, -0.5309446218683803, -0.982251694367695, -0.9321761767820599], Output: [1.5543139215268953]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981490197637464, 0.9780949678312064, 0.01923324322059157, -0.930926230241174]\n",
      "Layer: Layer 1, Input: [0.9981490197637464, 0.9780949678312064, 0.01923324322059157, -0.930926230241174], Output: [-0.9958372085329262, 0.6464638317561222, -0.9554345272319851, -0.9132724738667631]\n",
      "Layer: Layer 2, Input: [-0.9958372085329262, 0.6464638317561222, -0.9554345272319851, -0.9132724738667631], Output: [-0.49780623023773307]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9309777059446959, 0.32174458254260196, 0.4367875421095446, -0.8739456595641321]\n",
      "Layer: Layer 1, Input: [0.9309777059446959, 0.32174458254260196, 0.4367875421095446, -0.8739456595641321], Output: [-0.9771298999729651, 0.9886829151975962, -0.8678472628367428, -0.7523390860852267]\n",
      "Layer: Layer 2, Input: [-0.9771298999729651, 0.9886829151975962, -0.8678472628367428, -0.7523390860852267], Output: [-1.4243706180672149]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8838451260635063, 0.9853223325586816, -0.7948467837061975, -0.9235076622082274]\n",
      "Layer: Layer 1, Input: [0.8838451260635063, 0.9853223325586816, -0.7948467837061975, -0.9235076622082274], Output: [-0.9959790700113428, -0.1256666607980656, -0.9736866192782823, -0.916433421744254]\n",
      "Layer: Layer 2, Input: [-0.9959790700113428, -0.1256666607980656, -0.9736866192782823, -0.916433421744254], Output: [0.8381040097227235]\n",
      "Epoch 301/500, Loss: 0.19144080978329298, Accuracy: -0.6427742996336536\n",
      "Power operation: base = 0.5543139215268953, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5021937697622669, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4243706180672149, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16189599027727652, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893219801515611, 0.987339716604272, -0.9736211093127233, -0.9972305720944625]\n",
      "Layer: Layer 1, Input: [0.9893219801515611, 0.987339716604272, -0.9736211093127233, -0.9972305720944625], Output: [-0.9972122148914224, -0.5322896621028979, -0.9823676692925476, -0.9326448083125237]\n",
      "Layer: Layer 2, Input: [-0.9972122148914224, -0.5322896621028979, -0.9823676692925476, -0.9326448083125237], Output: [1.5571135985481508]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981495465929555, 0.9781445976246541, 0.019137818861662725, -0.930969431157913]\n",
      "Layer: Layer 1, Input: [0.9981495465929555, 0.9781445976246541, 0.019137818861662725, -0.930969431157913], Output: [-0.9958469896240186, 0.6485704135285205, -0.9557023266350098, -0.9137865998869714]\n",
      "Layer: Layer 2, Input: [-0.9958469896240186, 0.6485704135285205, -0.9557023266350098, -0.9137865998869714], Output: [-0.5013062935084376]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.930994997553331, 0.3227698874985239, 0.43671327409862754, -0.8740188771328687]\n",
      "Layer: Layer 1, Input: [0.930994997553331, 0.3227698874985239, 0.43671327409862754, -0.8740188771328687], Output: [-0.9772275023027028, 0.988888722346199, -0.8686289444644124, -0.7537033451631056]\n",
      "Layer: Layer 2, Input: [-0.9772275023027028, 0.988888722346199, -0.8686289444644124, -0.7537033451631056], Output: [-1.4239478465166182]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8838804658203679, 0.9853558198095455, -0.7948839662945305, -0.9235583982633279]\n",
      "Layer: Layer 1, Input: [0.8838804658203679, 0.9853558198095455, -0.7948839662945305, -0.9235583982633279], Output: [-0.9959889522162502, -0.12565787450532476, -0.9738558377068339, -0.9169847710064133]\n",
      "Layer: Layer 2, Input: [-0.9959889522162502, -0.12565787450532476, -0.9738558377068339, -0.9169847710064133], Output: [0.8384939833319436]\n",
      "Epoch 302/500, Loss: 0.19122173614190582, Accuracy: -0.6412611682243878\n",
      "Power operation: base = 0.5571135985481508, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4986937064915624, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4239478465166182, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16150601666805642, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.98932620450697, 0.987368697855605, -0.97362693097827, -0.9972327030704935]\n",
      "Layer: Layer 1, Input: [0.98932620450697, 0.987368697855605, -0.97362693097827, -0.9972327030704935], Output: [-0.9972187078801674, -0.5336411101551012, -0.9824825544687339, -0.9331091780373177]\n",
      "Layer: Layer 2, Input: [-0.9972187078801674, -0.5336411101551012, -0.9824825544687339, -0.9331091780373177], Output: [1.5598957558622368]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981500712480242, 0.9781939049799692, 0.019042556227841963, -0.9310124510389985]\n",
      "Layer: Layer 1, Input: [0.9981500712480242, 0.9781939049799692, 0.019042556227841963, -0.9310124510389985], Output: [-0.9958567083351271, 0.6506524263395119, -0.9559678628825002, -0.91429678917361]\n",
      "Layer: Layer 2, Input: [-0.9958567083351271, 0.6506524263395119, -0.9559678628825002, -0.91429678917361], Output: [-0.5047949903625368]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9310122178903792, 0.3237900644770193, 0.4366391227083173, -0.8740917931938191]\n",
      "Layer: Layer 1, Input: [0.9310122178903792, 0.3237900644770193, 0.4366391227083173, -0.8740917931938191], Output: [-0.977324263580389, 0.9890898245102345, -0.8694045529465376, -0.7550588968866894]\n",
      "Layer: Layer 2, Input: [-0.977324263580389, 0.9890898245102345, -0.8694045529465376, -0.7550588968866894], Output: [-1.4235447990119252]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8839156612899092, 0.9853890885670726, -0.7949210773333198, -0.9236089192019252]\n",
      "Layer: Layer 1, Input: [0.8839156612899092, 0.9853890885670726, -0.7949210773333198, -0.9236089192019252], Output: [-0.9959987707426536, -0.12566647253261926, -0.9740235071378235, -0.9175313802688734]\n",
      "Layer: Layer 2, Input: [-0.9959987707426536, -0.12566647253261926, -0.9740235071378235, -0.9175313802688734], Output: [0.8388840612600363]\n",
      "Epoch 303/500, Loss: 0.19101495037217436, Accuracy: -0.6397615032515889\n",
      "Power operation: base = 0.5598957558622368, power = 2, grad = 0.25\n",
      "Power operation: base = 0.49520500963746317, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4235447990119252, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16111593873996366, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893304115689662, 0.9873974911723803, -0.9736327407985145, -0.9972348247840153]\n",
      "Layer: Layer 1, Input: [0.9893304115689662, 0.9873974911723803, -0.9736327407985145, -0.9972348247840153], Output: [-0.9972251603506874, -0.5349986157325543, -0.9825963681970878, -0.9335693501095914]\n",
      "Layer: Layer 2, Input: [-0.9972251603506874, -0.5349986157325543, -0.9825963681970878, -0.9335693501095914], Output: [1.5626604657889613]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981505937625663, 0.978242895321293, 0.018947448437257847, -0.9310552933274029]\n",
      "Layer: Layer 1, Input: [0.9981505937625663, 0.978242895321293, 0.018947448437257847, -0.9310552933274029], Output: [-0.9958663657860979, 0.6527102998365408, -0.9562311735781677, -0.9148031020203131]\n",
      "Layer: Layer 2, Input: [-0.9958663657860979, 0.6527102998365408, -0.9562311735781677, -0.9148031020203131], Output: [-0.5082724100500249]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9310293681365911, 0.3248051995198725, 0.4365650824045441, -0.8741644137216678]\n",
      "Layer: Layer 1, Input: [0.9310293681365911, 0.3248051995198725, 0.4365650824045441, -0.8741644137216678], Output: [-0.9774201990314361, 0.9892863478022552, -0.8701741876857337, -0.7564058817643866]\n",
      "Layer: Layer 2, Input: [-0.9774201990314361, 0.9892863478022552, -0.8701741876857337, -0.7564058817643866], Output: [-1.4231610293457528]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8839507145142855, 0.9854221425024633, -0.7949581193973361, -0.9236592289072277]\n",
      "Layer: Layer 1, Input: [0.8839507145142855, 0.9854221425024633, -0.7949581193973361, -0.9236592289072277], Output: [-0.9960085267008573, -0.1256920654514696, -0.9741896534823455, -0.9180733205928974]\n",
      "Layer: Layer 2, Input: [-0.9960085267008573, -0.1256920654514696, -0.9741896534823455, -0.9180733205928974], Output: [0.8392742498897627]\n",
      "Epoch 304/500, Loss: 0.19082021149632933, Accuracy: -0.6382748351949266\n",
      "Power operation: base = 0.5626604657889613, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4917275899499751, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42316102934575284, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16072575011023726, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893346015460938, 0.9874260996692555, -0.9736385391316829, -0.997236937385364]\n",
      "Layer: Layer 1, Input: [0.9893346015460938, 0.9874260996692555, -0.9736385391316829, -0.997236937385364], Output: [-0.9972315729973011, -0.5363618365625726, -0.982709128231761, -0.9340253869473097]\n",
      "Layer: Layer 2, Input: [-0.9972315729973011, -0.5363618365625726, -0.982709128231761, -0.9340253869473097], Output: [1.5654078006289218]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981511141692992, 0.9782915739243444, 0.018852488805998054, -0.9310979613686332]\n",
      "Layer: Layer 1, Input: [0.9981511141692992, 0.9782915739243444, 0.018852488805998054, -0.9310979613686332], Output: [-0.9958759630657913, 0.6547444538589292, -0.9564922951436196, -0.9153055968985072]\n",
      "Layer: Layer 2, Input: [-0.9958759630657913, 0.6547444538589292, -0.9564922951436196, -0.9153055968985072], Output: [-0.5117386384637199]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9310464494411369, 0.3258153763215153, 0.43649114781113957, -0.8742367445213874]\n",
      "Layer: Layer 1, Input: [0.9310464494411369, 0.3258153763215153, 0.43649114781113957, -0.8742367445213874], Output: [-0.9775153234517094, 0.9894784144630183, -0.8709379448019183, -0.7577444354633419]\n",
      "Layer: Layer 2, Input: [-0.9775153234517094, 0.9894784144630183, -0.8709379448019183, -0.7577444354633419], Output: [-1.4227961008705567]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8839856274813986, 0.9854549851865324, -0.7949950949862928, -0.9237093311531552]\n",
      "Layer: Layer 1, Input: [0.8839856274813986, 0.9854549851865324, -0.7949950949862928, -0.9237093311531552], Output: [-0.996018221170682, -0.12573427148528385, -0.974354301866908, -0.9186106610513478]\n",
      "Layer: Layer 2, Input: [-0.996018221170682, -0.12573427148528385, -0.974354301866908, -0.9186106610513478], Output: [0.8396645548716428]\n",
      "Epoch 305/500, Loss: 0.19063728401428776, Accuracy: -0.6368007081641158\n",
      "Power operation: base = 0.5654078006289218, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4882613615362801, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42279610087055675, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16033544512835718, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893387746414528, 0.9874545263762416, -0.9736443263254654, -0.9972390410207099]\n",
      "Layer: Layer 1, Input: [0.9893387746414528, 0.9874545263762416, -0.9736443263254654, -0.9972390410207099], Output: [-0.9972379464954421, -0.5377304382306893, -0.9828208518002027, -0.9344773492895249]\n",
      "Layer: Layer 2, Input: [-0.9972379464954421, -0.5377304382306893, -0.9828208518002027, -0.9344773492895249], Output: [1.5681378326850393]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981516325000702, 0.9783399459211091, 0.01875767084283652, -0.9311404584136337]\n",
      "Layer: Layer 1, Input: [0.9981516325000702, 0.9783399459211091, 0.01875767084283652, -0.9311404584136337], Output: [-0.9958855012330545, 0.6567552987056196, -0.9567512628616028, -0.9158043305158987]\n",
      "Layer: Layer 2, Input: [-0.9958855012330545, 0.6567552987056196, -0.9567512628616028, -0.9158043305158987], Output: [-0.5151937582750459]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9310634629225223, 0.32682067629847106, 0.4364173137056685, -0.8743087912332659]\n",
      "Layer: Layer 1, Input: [0.9310634629225223, 0.32682067629847106, 0.4364173137056685, -0.8743087912332659], Output: [-0.977609651221988, 0.9896661429960466, -0.8716959172519353, -0.7590746889608121]\n",
      "Layer: Layer 2, Input: [-0.977609651221988, 0.9896661429960466, -0.8716959172519353, -0.7590746889608121], Output: [-1.4224495863380686]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8840204021265046, 0.985487620092886, -0.7950320065268778, -0.9237592296076107]\n",
      "Layer: Layer 1, Input: [0.8840204021265046, 0.985487620092886, -0.7950320065268778, -0.9237592296076107], Output: [-0.9960278552024259, -0.1257927163341526, -0.9745174766621559, -0.9191434687931255]\n",
      "Layer: Layer 2, Input: [-0.9960278552024259, -0.1257927163341526, -0.9745174766621559, -0.9191434687931255], Output: [0.840054981136551]\n",
      "Epoch 306/500, Loss: 0.19046593774999068, Accuracy: -0.635338679611511\n",
      "Power operation: base = 0.5681378326850393, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4848062417249541, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4224495863380686, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15994501886344903, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893429310528647, 0.9874827742413758, -0.9736501027173077, -0.9972411358321847]\n",
      "Layer: Layer 1, Input: [0.9893429310528647, 0.9874827742413758, -0.9736501027173077, -0.9972411358321847], Output: [-0.9972442815022474, -0.5391040940215522, -0.9829315556223907, -0.9349252962509138]\n",
      "Layer: Layer 2, Input: [-0.9972442815022474, -0.5391040940215522, -0.9829315556223907, -0.9349252962509138], Output: [1.5708506342838495]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981521487858819, 0.9783880163043718, 0.018662988244107937, -0.9311827876215991]\n",
      "Layer: Layer 1, Input: [0.9981521487858819, 0.9783880163043718, 0.018662988244107937, -0.9311827876215991], Output: [-0.9958949813176617, 0.6587432353959392, -0.9570081109176747, -0.9162993578733056]\n",
      "Layer: Layer 2, Input: [-0.9958949813176617, 0.6587432353959392, -0.9570081109176747, -0.9162993578733056], Output: [-0.5186378490636558]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9310804096694781, 0.32782117865667654, 0.43634357501537463, -0.8743805593377753]\n",
      "Layer: Layer 1, Input: [0.9310804096694781, 0.32782117865667654, 0.43634357501537463, -0.8743805593377753], Output: [-0.9777031963218867, 0.9898496482969987, -0.872448194945027, -0.760396768691664]\n",
      "Layer: Layer 2, Input: [-0.9777031963218867, 0.9898496482969987, -0.872448194945027, -0.760396768691664], Output: [-1.4221210677362377]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8840550403337739, 0.985520050600988, -0.7950688563747282, -0.9238089278356517]\n",
      "Layer: Layer 1, Input: [0.8840550403337739, 0.985520050600988, -0.7950688563747282, -0.9238089278356517], Output: [-0.99603742981779, -0.1258670330026244, -0.9746792015105239, -0.9196718091056745]\n",
      "Layer: Layer 2, Input: [-0.99603742981779, -0.1258670330026244, -0.9746792015105239, -0.9196718091056745], Output: [0.8404455329083387]\n",
      "Epoch 307/500, Loss: 0.19030594770300563, Accuracy: -0.6338883200480927\n",
      "Power operation: base = 0.5708506342838495, power = 2, grad = 0.25\n",
      "Power operation: base = 0.48136215093634416, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4221210677362377, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15955446709166132, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989347070973033, 0.9875108461333019, -0.9736558686346899, -0.9972432219580031]\n",
      "Layer: Layer 1, Input: [0.989347070973033, 0.9875108461333019, -0.9736558686346899, -0.9972432219580031], Output: [-0.9972505786571282, -0.5404824847622751, -0.9830412559293376, -0.935369285374625]\n",
      "Layer: Layer 2, Input: [-0.9972505786571282, -0.5404824847622751, -0.9830412559293376, -0.935369285374625], Output: [1.5735462777964058]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981526630569167, 0.9784357899320947, 0.018568434888714333, -0.9312249520626997]\n",
      "Layer: Layer 1, Input: [0.9981526630569167, 0.9784357899320947, 0.018568434888714333, -0.9312249520626997], Output: [-0.9959044043212217, 0.6607086559234784, -0.9572628724403642, -0.9167907323198736]\n",
      "Layer: Layer 2, Input: [-0.9959044043212217, 0.6607086559234784, -0.9572628724403642, -0.9167907323198736], Output: [-0.5220709874411131]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9310972907418229, 0.32881696045674047, 0.43626992681323284, -0.8744520541602929]\n",
      "Layer: Layer 1, Input: [0.9310972907418229, 0.32881696045674047, 0.43626992681323284, -0.8744520541602929], Output: [-0.977795972343267, 0.990029041778065, -0.8731948648542934, -0.7617107966920764]\n",
      "Layer: Layer 2, Input: [-0.977795972343267, 0.990029041778065, -0.8731948648542934, -0.7617107966920764], Output: [-1.421810136124137]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8840895439378067, 0.9855522799991233, -0.795105646816353, -0.923858429302563]\n",
      "Layer: Layer 1, Input: [0.8840895439378067, 0.9855522799991233, -0.795105646816353, -0.923858429302563], Output: [-0.9960469460107745, -0.12595686163047895, -0.9748394993528554, -0.9201957454756056]\n",
      "Layer: Layer 2, Input: [-0.9960469460107745, -0.12595686163047895, -0.9748394993528554, -0.9201957454756056], Output: [0.8408362137163676]\n",
      "Epoch 308/500, Loss: 0.19015709390520733, Accuracy: -0.6324492127630621\n",
      "Power operation: base = 0.5735462777964058, power = 2, grad = 0.25\n",
      "Power operation: base = 0.47792901255888687, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4218101361241371, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15916378628363237, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893511945896981, 0.9875387448437654, -0.9736616243954024, -0.997245299532582]\n",
      "Layer: Layer 1, Input: [0.9893511945896981, 0.9875387448437654, -0.9736616243954024, -0.997245299532582], Output: [-0.9972568385823197, -0.5418652986683251, -0.9831499684809004, -0.9358093726834823]\n",
      "Layer: Layer 2, Input: [-0.9972568385823197, -0.5418652986683251, -0.9831499684809004, -0.9358093726834823], Output: [1.576224835658837]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981531753425615, 0.9784832715316455, 0.018474004833273657, -0.9312669547207238]\n",
      "Layer: Layer 1, Input: [0.9981531753425615, 0.9784832715316455, 0.018474004833273657, -0.9312669547207238], Output: [-0.995913771218056, 0.6626519435031996, -0.9575155795398709, -0.9172785056067071]\n",
      "Layer: Layer 2, Input: [-0.995913771218056, 0.6626519435031996, -0.9575155795398709, -0.9172785056067071], Output: [-0.5254932471689382]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9311141071712989, 0.3298080966772008, 0.43619636431411024, -0.874523280875676]\n",
      "Layer: Layer 1, Input: [0.9311141071712989, 0.3298080966772008, 0.43619636431411024, -0.874523280875676], Output: [-0.9778879925031512, 0.9902044314875922, -0.8739360111242676, -0.7630168907395107]\n",
      "Layer: Layer 2, Input: [-0.9778879925031512, 0.9902044314875922, -0.8739360111242676, -0.7630168907395107], Output: [-1.4215163914652997]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8841239147251002, 0.9855843114872604, -0.7951423800710014, -0.9239077373768334]\n",
      "Layer: Layer 1, Input: [0.8841239147251002, 0.9855843114872604, -0.7951423800710014, -0.9239077373768334], Output: [-0.9960564047485438, -0.1260618493265788, -0.9749983924540289, -0.9207153396474815]\n",
      "Layer: Layer 2, Input: [-0.9960564047485438, -0.1260618493265788, -0.9749983924540289, -0.9207153396474815], Output: [0.8412270264079815]\n",
      "Epoch 309/500, Loss: 0.19001916128237795, Accuracy: -0.6310209535472171\n",
      "Power operation: base = 0.5762248356588371, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4745067528310618, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42151639146529973, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15877297359201847, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893553020857893, 0.9875664730900213, -0.9736673703078105, -0.9972473686866541]\n",
      "Layer: Layer 1, Input: [0.9893553020857893, 0.9875664730900213, -0.9736673703078105, -0.9972473686866541], Output: [-0.9972630618834123, -0.5432522311919747, -0.9832577085829205, -0.9362456127295833]\n",
      "Layer: Layer 2, Input: [-0.9972630618834123, -0.5432522311919747, -0.9832577085829205, -0.9362456127295833], Output: [1.5788863803924746]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981536856714301, 0.9785304657038846, 0.018379692307394974, -0.9313087984956366]\n",
      "Layer: Layer 1, Input: [0.9981536856714301, 0.9785304657038846, 0.018379692307394974, -0.9313087984956366], Output: [-0.9959230829560469, 0.6645734728118861, -0.9577662633453592, -0.9177627279389591]\n",
      "Layer: Layer 2, Input: [-0.9959230829560469, 0.6645734728118861, -0.9577662633453592, -0.9177627279389591], Output: [-0.5289046992712301]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9311308599623849, 0.3307946602758414, 0.4361228828710293, -0.8745942445126956]\n",
      "Layer: Layer 1, Input: [0.9311308599623849, 0.3307946602758414, 0.4361228828710293, -0.8745942445126956], Output: [-0.9779792696561609, 0.9903759222251384, -0.8746717151747407, -0.7643151644890347]\n",
      "Layer: Layer 2, Input: [-0.9779792696561609, 0.9903759222251384, -0.8746717151747407, -0.7643151644890347], Output: [-1.4212394424598922]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8841581544354743, 0.9856161481798171, -0.7951790582924796, -0.9239568553330415]\n",
      "Layer: Layer 1, Input: [0.8841581544354743, 0.9856161481798171, -0.7951790582924796, -0.9239568553330415], Output: [-0.9960658069722641, -0.1261816500058486, -0.9751559024276288, -0.9212306516808149]\n",
      "Layer: Layer 2, Input: [-0.9960658069722641, -0.1261816500058486, -0.9751559024276288, -0.9212306516808149], Output: [0.8416179731609423]\n",
      "Epoch 310/500, Loss: 0.18989193952054997, Accuracy: -0.6296031504201944\n",
      "Power operation: base = 0.5788863803924746, power = 2, grad = 0.25\n",
      "Power operation: base = 0.47109530072876993, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4212394424598922, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15838202683905767, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893593936395702, 0.9875940335171626, -0.9736731066711135, -0.9972494295473798]\n",
      "Layer: Layer 1, Input: [0.9893593936395702, 0.9875940335171626, -0.9736731066711135, -0.9972494295473798], Output: [-0.997269249149868, -0.5446429848733424, -0.9833644911037165, -0.9366780586423465]\n",
      "Layer: Layer 2, Input: [-0.997269249149868, -0.5446429848733424, -0.9833644911037165, -0.9366780586423465], Output: [1.5815309846235275]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981541940713863, 0.9785773769271121, 0.018285491709087866, -0.9313504862060613]\n",
      "Layer: Layer 1, Input: [0.9981541940713863, 0.9785773769271121, 0.018285491709087866, -0.9313504862060613], Output: [-0.9959323404574577, 0.666473610222059, -0.9580149540408938, -0.9182434480264102]\n",
      "Layer: Layer 2, Input: [-0.9959323404574577, 0.666473610222059, -0.9580149540408938, -0.9182434480264102], Output: [-0.5323054121421502]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9311475500930828, 0.3317767222491241, 0.43604947797153454, -0.8746649499583338]\n",
      "Layer: Layer 1, Input: [0.9311475500930828, 0.3317767222491241, 0.43604947797153454, -0.8746649499583338], Output: [-0.978069816306501, 0.9905436156521441, -0.8754020558009571, -0.7656057276060662]\n",
      "Layer: Layer 2, Input: [-0.978069816306501, 0.9905436156521441, -0.8754020558009571, -0.7656057276060662], Output: [-1.4209789063761105]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8841922647634525, 0.9856477931083314, -0.7952156835709192, -0.9240057863546509]\n",
      "Layer: Layer 1, Input: [0.8841922647634525, 0.9856477931083314, -0.7952156835709192, -0.9240057863546509], Output: [-0.99607515359791, -0.12631592422939983, -0.9753120502596917, -0.9217417400053207]\n",
      "Layer: Layer 2, Input: [-0.99607515359791, -0.12631592422939983, -0.9753120502596917, -0.9217417400053207], Output: [0.8420090554957458]\n",
      "Epoch 311/500, Loss: 0.1897752229369264, Accuracy: -0.628195423361742\n",
      "Power operation: base = 0.5815309846235275, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4676945878578498, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42097890637611046, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15799094450425422, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893634694247812, 0.9876214287003676, -0.9736788337755963, -0.9972514822384552]\n",
      "Layer: Layer 1, Input: [0.9893634694247812, 0.9876214287003676, -0.9736788337755963, -0.9972514822384552], Output: [-0.9972754009555157, -0.5460372691940653, -0.9834703304899602, -0.9371067621750395]\n",
      "Layer: Layer 2, Input: [-0.9972754009555157, -0.5460372691940653, -0.9834703304899602, -0.9371067621750395], Output: [1.5841587211022947]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981547005695656, 0.9786240095608829, 0.01819139760029305, -0.9313920205916816]\n",
      "Layer: Layer 1, Input: [0.9981547005695656, 0.9786240095608829, 0.01819139760029305, -0.9313920205916816], Output: [-0.9959415446197245, 0.6683527140294702, -0.958261680900067, -0.9187207131325777]\n",
      "Layer: Layer 2, Input: [-0.9959415446197245, 0.6683527140294702, -0.958261680900067, -0.9187207131325777], Output: [-0.5356954516484551]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9311641785156817, 0.3327543516897915, 0.435976145234157, -0.8747354019619469]\n",
      "Layer: Layer 1, Input: [0.9311641785156817, 0.3327543516897915, 0.435976145234157, -0.8747354019619469], Output: [-0.9781596446195032, 0.9907076103984018, -0.8761271092703036, -0.7668886858956148]\n",
      "Layer: Layer 2, Input: [-0.9781596446195032, 0.9907076103984018, -0.8761271092703036, -0.7668886858956148], Output: [-1.420734408881139]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8842262473596036, 0.9856792492240438, -0.7952522579344943, -0.9240545335367183]\n",
      "Layer: Layer 1, Input: [0.8842262473596036, 0.9856792492240438, -0.7952522579344943, -0.9240545335367183], Output: [-0.9960844455170474, -0.126464339047844, -0.9754668563315686, -0.9222486614744743]\n",
      "Layer: Layer 2, Input: [-0.9960844455170474, -0.126464339047844, -0.9754668563315686, -0.9222486614744743], Output: [0.8424002742878907]\n",
      "Epoch 312/500, Loss: 0.18966881035522357, Accuracy: -0.6267974040470881\n",
      "Power operation: base = 0.5841587211022947, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4643045483515449, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4207344088811391, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15759972571210934, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893675296107767, 0.9876486611470736, -0.9736845519028741, -0.9972535268802152]\n",
      "Layer: Layer 1, Input: [0.9893675296107767, 0.9876486611470736, -0.9736845519028741, -0.9972535268802152], Output: [-0.9972815178590336, -0.5474348004335968, -0.9835752407819509, -0.9375317737498364]\n",
      "Layer: Layer 2, Input: [-0.9972815178590336, -0.5474348004335968, -0.9835752407819509, -0.9375317737498364], Output: [1.5867696627218324]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981552051923963, 0.9786703678496921, 0.01809740470253949, -0.9314334043155722]\n",
      "Layer: Layer 1, Input: [0.9981552051923963, 0.9786703678496921, 0.01809740470253949, -0.9314334043155722], Output: [-0.995950696316223, 0.6702111346743119, -0.958506472319364, -0.9191945691223896]\n",
      "Layer: Layer 2, Input: [-0.995950696316223, 0.6702111346743119, -0.958506472319364, -0.9191945691223896], Output: [-0.5390748812273589]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9311807461574985, 0.33372761584269994, 0.43590288040497616, -0.8748056051393025]\n",
      "Layer: Layer 1, Input: [0.9311807461574985, 0.33372761584269994, 0.43590288040497616, -0.8748056051393025], Output: [-0.9782487664327496, 0.9908680021644974, -0.8768469494156067, -0.7681641414280957]\n",
      "Layer: Layer 2, Input: [-0.9782487664327496, 0.9908680021644974, -0.8768469494156067, -0.7681641414280957], Output: [-1.4205055838720337]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8842601038318406, 0.9857105194003909, -0.7952887833510922, -0.9241030998885198]\n",
      "Layer: Layer 1, Input: [0.8842601038318406, 0.9857105194003909, -0.7952887833510922, -0.9241030998885198], Output: [-0.9960936835975879, -0.12662656784780976, -0.9756203404419324, -0.922751471417414]\n",
      "Layer: Layer 2, Input: [-0.9960936835975879, -0.12662656784780976, -0.9756203404419324, -0.922751471417414], Output: [0.8427916297800193]\n",
      "Epoch 313/500, Loss: 0.18957250498526218, Accuracy: -0.6254087355864879\n",
      "Power operation: base = 0.5867696627218324, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4609251187726411, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42050558387203374, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1572083702199807, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893715743626589, 0.987675733299075, -0.9736902613261287, -0.9972555635897355]\n",
      "Layer: Layer 1, Input: [0.9893715743626589, 0.987675733299075, -0.9736902613261287, -0.9972555635897355], Output: [-0.9972876004044131, -0.5488353015281734, -0.9836792356283179, -0.937953142501444]\n",
      "Layer: Layer 2, Input: [-0.9972876004044131, -0.5488353015281734, -0.9836792356283179, -0.937953142501444], Output: [1.589363882536131]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981557079656208, 0.9787164559265362, 0.018003507892720032, -0.9314746399664546]\n",
      "Layer: Layer 1, Input: [0.9981557079656208, 0.9787164559265362, 0.018003507892720032, -0.9314746399664546], Output: [-0.995959796397008, 0.672049214956253, -0.95874935585031, -0.9196650605084549]\n",
      "Layer: Layer 2, Input: [-0.995959796397008, 0.672049214956253, -0.95874935585031, -0.9196650605084549], Output: [-0.542443761979901]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9311972539215966, 0.3346965801589311, 0.4358296793542766, -0.8748755639764886]\n",
      "Layer: Layer 1, Input: [0.9311972539215966, 0.3346965801589311, 0.4358296793542766, -0.8748755639764886], Output: [-0.9783371932667893, 0.9910248838203868, -0.8775616477251557, -0.7694321926617872]\n",
      "Layer: Layer 2, Input: [-0.9783371932667893, 0.9910248838203868, -0.8775616477251557, -0.7694321926617872], Output: [-1.420292073306785]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8842938357466824, 0.9857416064354154, -0.7953252617299377, -0.9241514883360916]\n",
      "Layer: Layer 1, Input: [0.8842938357466824, 0.9857416064354154, -0.7953252617299377, -0.9241514883360916], Output: [-0.9961028686845188, -0.1268022902016759, -0.975772521827961, -0.9232502236892378]\n",
      "Layer: Layer 2, Input: [-0.9961028686845188, -0.1268022902016759, -0.975772521827961, -0.9232502236892378], Output: [0.8431831215939836]\n",
      "Epoch 314/500, Loss: 0.18948611430667278, Accuracy: -0.6240290722690314\n",
      "Power operation: base = 0.5893638825361309, power = 2, grad = 0.25\n",
      "Power operation: base = 0.45755623802009904, power = 2, grad = 0.25\n",
      "Power operation: base = -0.420292073306785, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15681687840601644, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989375603841407, 0.9877026475345524, -0.9736959623103416, -0.9972575924809304]\n",
      "Layer: Layer 1, Input: [0.989375603841407, 0.9877026475345524, -0.9736959623103416, -0.9972575924809304], Output: [-0.9972936491214093, -0.550238501932439, -0.9837823283001684, -0.9383709163193364]\n",
      "Layer: Layer 2, Input: [-0.9972936491214093, -0.550238501932439, -0.9837823283001684, -0.9383709163193364], Output: [1.5919414537777206]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981562089143144, 0.9787622778163558, 0.01790970219898472, -0.9315157300608841]\n",
      "Layer: Layer 1, Input: [0.9981562089143144, 0.9787622778163558, 0.01790970219898472, -0.9315157300608841], Output: [-0.99596884568953, 0.6738672902434394, -0.9589903582304444, -0.9201322304959719]\n",
      "Layer: Layer 2, Input: [-0.99596884568953, 0.6738672902434394, -0.9589903582304444, -0.9201322304959719], Output: [-0.5458021527600563]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.931213702687483, 0.3356613083482374, 0.4357565380732968, -0.8749452828337058]\n",
      "Layer: Layer 1, Input: [0.931213702687483, 0.3356613083482374, 0.4357565380732968, -0.8749452828337058], Output: [-0.9784249363354685, 0.9911783455002698, -0.8782712734295569, -0.7706929345620065]\n",
      "Layer: Layer 2, Input: [-0.9784249363354685, 0.9911783455002698, -0.8782712734295569, -0.7706929345620065], Output: [-1.4200935270358768]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8843274446304764, 0.985772513054095, -0.7953616949231708, -0.9241997017246966]\n",
      "Layer: Layer 1, Input: [0.8843274446304764, 0.985772513054095, -0.7953616949231708, -0.9241997017246966], Output: [-0.9961120016006086, -0.1269911917205392, -0.9759234191857319, -0.9237449707197363]\n",
      "Layer: Layer 2, Input: [-0.9961120016006086, -0.1269911917205392, -0.9759234191857319, -0.9237449707197363], Output: [0.8435747487428102]\n",
      "Epoch 315/500, Loss: 0.18940944995654962, Accuracy: -0.6226580793107308\n",
      "Power operation: base = 0.5919414537777206, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4541978472399437, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42009352703587677, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15642525125718976, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989379618204003, 0.9877294061700321, -0.9737016551125166, -0.9972596136646471]\n",
      "Layer: Layer 1, Input: [0.989379618204003, 0.9877294061700321, -0.9737016551125166, -0.9972596136646471], Output: [-0.9972996645259741, -0.5516441374837227, -0.9838845317047026, -0.9387851418886413]\n",
      "Layer: Layer 2, Input: [-0.9972996645259741, -0.5516441374837227, -0.9838845317047026, -0.9387851418886413], Output: [1.5945024498747085]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981567080629058, 0.9788078374393608, 0.017815982796746167, -0.931556677045369]\n",
      "Layer: Layer 1, Input: [0.9981567080629058, 0.9788078374393608, 0.017815982796746167, -0.931556677045369], Output: [-0.9959778449993262, 0.675665688675584, -0.9592295054131647, -0.9205961210263025]\n",
      "Layer: Layer 2, Input: [-0.9959778449993262, 0.675665688675584, -0.9592295054131647, -0.9205961210263025], Output: [-0.5491501102597782]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9312300933117839, 0.33662186242987097, 0.43568345267106706, -0.8750147659489379]\n",
      "Layer: Layer 1, Input: [0.9312300933117839, 0.33662186242987097, 0.43568345267106706, -0.8750147659489379], Output: [-0.9785120065558832, 0.9913284746939096, -0.8789758935855279, -0.7719464587170765]\n",
      "Layer: Layer 2, Input: [-0.9785120065558832, 0.9913284746939096, -0.8789758935855279, -0.7719464587170765], Output: [-1.4199096026345757]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8843609319705851, 0.9858032419105928, -0.7953980847273812, -0.92424774282121]\n",
      "Layer: Layer 1, Input: [0.8843609319705851, 0.9858032419105928, -0.7953980847273812, -0.92424774282121], Output: [-0.9961210831470891, -0.12719296391040286, -0.9760730506898513, -0.9242357635605993]\n",
      "Layer: Layer 2, Input: [-0.9961210831470891, -0.12719296391040286, -0.9760730506898513, -0.9242357635605993], Output: [0.8439665096425637]\n",
      "Epoch 316/500, Loss: 0.18934232762091294, Accuracy: -0.6212954326069422\n",
      "Power operation: base = 0.5945024498747085, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4508498897402218, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41990960263457566, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1560334903574363, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893836176035531, 0.9877560114622809, -0.973707339981899, -0.9972616272487576]\n",
      "Layer: Layer 1, Input: [0.9893836176035531, 0.9877560114622809, -0.973707339981899, -0.9972616272487576], Output: [-0.9973056471206779, -0.5530519502689947, -0.9839858583983176, -0.9391958647297093]\n",
      "Layer: Layer 2, Input: [-0.9973056471206779, -0.5530519502689947, -0.9839858583983176, -0.9391958647297093], Output: [1.5970469444672535]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998157205435195, 0.9788531386142455, 0.017722345004798575, -0.931597483298424]\n",
      "Layer: Layer 1, Input: [0.998157205435195, 0.9788531386142455, 0.017722345004798575, -0.931597483298424], Output: [-0.9959867951106902, 0.6774447313612783, -0.9594668225964766, -0.9210567728192505]\n",
      "Layer: Layer 2, Input: [-0.9959867951106902, 0.6774447313612783, -0.9594668225964766, -0.9210567728192505], Output: [-0.5524876890901762]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9312464266288998, 0.33757830278184586, 0.43561041937133627, -0.875084017441513]\n",
      "Layer: Layer 1, Input: [0.9312464266288998, 0.33757830278184586, 0.43561041937133627, -0.875084017441513], Output: [-0.9785984145579761, 0.9914753563345452, -0.8796755731567336, -0.773192853451153]\n",
      "Layer: Layer 2, Input: [-0.9785984145579761, 0.9914753563345452, -0.8796755731567336, -0.773192853451153], Output: [-1.419739965236185]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8843942992165361, 0.9858337955904322, -0.7954344328850999, -0.9242956143164333]\n",
      "Layer: Layer 1, Input: [0.8843942992165361, 0.9858337955904322, -0.7954344328850999, -0.9242956143164333], Output: [-0.9961301141043144, -0.12740730403159298, -0.9762214340123512, -0.924722651931148]\n",
      "Layer: Layer 2, Input: [-0.9961301141043144, -0.12740730403159298, -0.9762214340123512, -0.924722651931148], Output: [0.844358402124092]\n",
      "Epoch 317/500, Loss: 0.18928456692984355, Accuracy: -0.6199408184891704\n",
      "Power operation: base = 0.5970469444672535, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4475123109098238, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41973996523618506, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15564159787590803, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893876021894058, 0.9877824656101358, -0.973713017160187, -0.9972636333382484]\n",
      "Layer: Layer 1, Input: [0.9893876021894058, 0.9877824656101358, -0.973713017160187, -0.9972636333382484], Output: [-0.9973115973951153, -0.5544616884944598, -0.9840863205992169, -0.9396031292364135]\n",
      "Layer: Layer 2, Input: [-0.9973115973951153, -0.5544616884944598, -0.9840863205992169, -0.9396031292364135], Output: [1.5995750114234175]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981577010543723, 0.9788981850612949, 0.017628784281543134, -0.931638151132559]\n",
      "Layer: Layer 1, Input: [0.9981577010543723, 0.9788981850612949, 0.017628784281543134, -0.931638151132559], Output: [-0.9959956967873177, 0.6792047325696504, -0.9597023342506937, -0.9215142254140751]\n",
      "Layer: Layer 2, Input: [-0.9959956967873177, 0.6792047325696504, -0.9597023342506937, -0.9215142254140751], Output: [-0.5558149418590315]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9312627034516424, 0.3385306881886822, 0.4355374345095828, -0.8751530413155519]\n",
      "Layer: Layer 1, Input: [0.9312627034516424, 0.3385306881886822, 0.4355374345095828, -0.8751530413155519], Output: [-0.978684170693784, 0.9916190728835339, -0.8803703750917673, -0.7744322039339865]\n",
      "Layer: Layer 2, Input: [-0.978684170693784, 0.9916190728835339, -0.8803703750917673, -0.7744322039339865], Output: [-1.4195842873664808]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8844275477811382, 0.9858641766125987, -0.7954707410862483, -0.9243433188273363]\n",
      "Layer: Layer 1, Input: [0.8844275477811382, 0.9858641766125987, -0.7954707410862483, -0.9243433188273363], Output: [-0.996139095232398, -0.12763391496140142, -0.976368586340879, -0.9252056842626244]\n",
      "Layer: Layer 2, Input: [-0.996139095232398, -0.12763391496140142, -0.976368586340879, -0.9252056842626244], Output: [0.8447504234447107]\n",
      "Epoch 318/500, Loss: 0.18923599135613023, Accuracy: -0.6185939334861561\n",
      "Power operation: base = 0.5995750114234175, power = 2, grad = 0.25\n",
      "Power operation: base = 0.44418505814096854, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4195842873664808, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15524957655528926, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893915721072666, 0.987808770756274, -0.9737186868817392, -0.9972656320353063]\n",
      "Layer: Layer 1, Input: [0.9893915721072666, 0.987808770756274, -0.9737186868817392, -0.9972656320353063], Output: [-0.9973175158262977, -0.5558731063578017, -0.9841859301995464, -0.940006978713208]\n",
      "Layer: Layer 2, Input: [-0.9973175158262977, -0.5558731063578017, -0.9841859301995464, -0.940006978713208], Output: [1.602086724854435]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981581949430351, 0.9789429804053879, 0.01753529622132013, -0.9316786827962087]\n",
      "Layer: Layer 1, Input: [0.9981581949430351, 0.9789429804053879, 0.01753529622132013, -0.9316786827962087], Output: [-0.9960045507729323, 0.6809459999165031, -0.9599360641451233, -0.9219685172092736]\n",
      "Layer: Layer 2, Input: [-0.9960045507729323, 0.6809459999165031, -0.9599360641451233, -0.9219685172092736], Output: [-0.5591319192447903]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9312789245718504, 0.3394790758876761, 0.43546449453010955, -0.8752218414633113]\n",
      "Layer: Layer 1, Input: [0.9312789245718504, 0.3394790758876761, 0.43546449453010955, -0.8752218414633113], Output: [-0.978769285046355, 0.9917597044118593, -0.8810603603993649, -0.7756645922876846]\n",
      "Layer: Layer 2, Input: [-0.978769285046355, 0.9917597044118593, -0.8810603603993649, -0.7756645922876846], Output: [-1.4194422487795326]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8844606790415627, 0.9858943874315718, -0.7955070109695462, -0.9243908588992281]\n",
      "Layer: Layer 1, Input: [0.8844606790415627, 0.9858943874315718, -0.7955070109695462, -0.9243908588992281], Output: [-0.9961480272718295, -0.12787250505991607, -0.9765145243962068, -0.925684907741082]\n",
      "Layer: Layer 2, Input: [-0.9961480272718295, -0.12787250505991607, -0.9765145243962068, -0.925684907741082], Output: [0.8451425702997328]\n",
      "Epoch 319/500, Loss: 0.18919642811733167, Accuracy: -0.6172544840894445\n",
      "Power operation: base = 0.602086724854435, power = 2, grad = 0.25\n",
      "Power operation: base = 0.44086808075520967, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4194422487795326, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15485742970026717, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893955274993085, 0.9878349289889227, -0.9737243493737723, -0.9972676234394007]\n",
      "Layer: Layer 1, Input: [0.9893955274993085, 0.9878349289889227, -0.9737243493737723, -0.9972676234394007], Output: [-0.9973234028790336, -0.5572859639230544, -0.9842846987770736, -0.9404074554109888]\n",
      "Layer: Layer 2, Input: [-0.9973234028790336, -0.5572859639230544, -0.9842846987770736, -0.9404074554109888], Output: [1.6045821591293556]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998158687123206, 0.9789875281789001, 0.017441876550842037, -0.9317190804755989]\n",
      "Layer: Layer 1, Input: [0.998158687123206, 0.9789875281789001, 0.017441876550842037, -0.9317190804755989], Output: [-0.9960133577918896, 0.6826688345450579, -0.9601680353737722, -0.9224196855011636]\n",
      "Layer: Layer 2, Input: [-0.9960133577918896, 0.6826688345450579, -0.9601680353737722, -0.9224196855011636], Output: [-0.5624386700672579]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9312950907609873, 0.34042352161374617, 0.43539159598321986, -0.8752904216684231]\n",
      "Layer: Layer 1, Input: [0.9312950907609873, 0.34042352161374617, 0.43539159598321986, -0.8752904216684231], Output: [-0.9788537674383468, 0.9918973286786286, -0.8817455882209564, -0.7768900976905476]\n",
      "Layer: Layer 2, Input: [-0.9788537674383468, 0.9918973286786286, -0.8817455882209564, -0.7768900976905476], Output: [-1.4193135362950593]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.884493694340393, 0.985924430439288, -0.7955432441238819, -0.9244382370078622]\n",
      "Layer: Layer 1, Input: [0.884493694340393, 0.985924430439288, -0.7955432441238819, -0.9244382370078622], Output: [-0.9961569109440697, -0.12812278803905736, -0.9766592644490856, -0.9261603683489199]\n",
      "Layer: Layer 2, Input: [-0.9961569109440697, -0.12812278803905736, -0.9766592644490856, -0.9261603683489199], Output: [0.8455348388339488]\n",
      "Epoch 320/500, Loss: 0.18916570808108643, Accuracy: -0.6159221865232083\n",
      "Power operation: base = 0.6045821591293556, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4375613299327421, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4193135362950593, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15446516116605125, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893994685042801, 0.9878609423435116, -0.9737300048565578, -0.9972696076473667]\n",
      "Layer: Layer 1, Input: [0.9893994685042801, 0.9878609423435116, -0.9737300048565578, -0.9972696076473667], Output: [-0.9973292590062967, -0.5587000269980835, -0.9843826376064263, -0.9408046005617853]\n",
      "Layer: Layer 2, Input: [-0.9973292590062967, -0.5587000269980835, -0.9843826376064263, -0.9408046005617853], Output: [1.6070613888890755]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981591776163484, 0.9790318318245099, 0.017348521125729554, -0.9317593462965582]\n",
      "Layer: Layer 1, Input: [0.9981591776163484, 0.9790318318245099, 0.017348521125729554, -0.9317593462965582], Output: [-0.9960221185497619, 0.68437353130144, -0.9603982703801117, -0.9228677665212998]\n",
      "Layer: Layer 2, Input: [-0.9960221185497619, 0.68437353130144, -0.9603982703801117, -0.9228677665212998], Output: [-0.5657352413551315]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9313112027707222, 0.3413640796428948, 0.4353187355224717, -0.8753587856090341]\n",
      "Layer: Layer 1, Input: [0.9313112027707222, 0.3413640796428948, 0.4353187355224717, -0.8753587856090341], Output: [-0.9789376274403163, 0.9920320212066833, -0.8824261159006367, -0.7781087964780427]\n",
      "Layer: Layer 2, Input: [-0.9789376274403163, 0.9920320212066833, -0.8824261159006367, -0.7781087964780427], Output: [-1.4191978436375154]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8845265949866424, 0.9859543079670398, -0.7955794420896403, -0.9244854555614748]\n",
      "Layer: Layer 1, Input: [0.8845265949866424, 0.9859543079670398, -0.7955794420896403, -0.9244854555614748], Output: [-0.9961657469521262, -0.12838448283476658, -0.9768028223364682, -0.9266321109050919]\n",
      "Layer: Layer 2, Input: [-0.9961657469521262, -0.12838448283476658, -0.9768028223364682, -0.9266321109050919], Output: [0.8459272246529705]\n",
      "Epoch 321/500, Loss: 0.18914366567357457, Accuracy: -0.6145967665184888\n",
      "Power operation: base = 0.6070613888890755, power = 2, grad = 0.25\n",
      "Power operation: base = 0.43426475864486846, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41919784363751544, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15407277534702946, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894033952576093, 0.9878868128042715, -0.9737356535436104, -0.9972715847534814]\n",
      "Layer: Layer 1, Input: [0.9894033952576093, 0.9878868128042715, -0.9737356535436104, -0.9972715847534814], Output: [-0.9973350846495801, -0.5601150670146542, -0.9844797576699093, -0.9411984544123241]\n",
      "Layer: Layer 2, Input: [-0.9973350846495801, -0.5601150670146542, -0.9844797576699093, -0.9411984544123241], Output: [1.6095244890597398]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981596664433835, 0.9790758946979106, 0.017255225927139687, -0.9317994823262717]\n",
      "Layer: Layer 1, Input: [0.9981596664433835, 0.9790758946979106, 0.017255225927139687, -0.9317994823262717], Output: [-0.9960308337339036, 0.6860603789050181, -0.9606267909809324, -0.9233127954727506]\n",
      "Layer: Layer 2, Input: [-0.9960308337339036, 0.6860603789050181, -0.9606267909809324, -0.9233127954727506], Output: [-0.5690216784105209]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9313272613334913, 0.3423008028343327, 0.4352459099020091, -0.8754269368608483]\n",
      "Layer: Layer 1, Input: [0.9313272613334913, 0.3423008028343327, 0.4352459099020091, -0.8754269368608483], Output: [-0.9790208743787138, 0.99216385535544, -0.883101999052647, -0.7793207622409849]\n",
      "Layer: Layer 2, Input: [-0.9790208743787138, 0.99216385535544, -0.883101999052647, -0.7793207622409849], Output: [-1.419094871277022]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8845593822567407, 0.9859840222873099, -0.7956156063599976, -0.924532516902762]\n",
      "Layer: Layer 1, Input: [0.8845593822567407, 0.9859840222873099, -0.7956156063599976, -0.924532516902762], Output: [-0.9961745359811116, -0.1286573134823516, -0.9769452134771265, -0.9271001791040354]\n",
      "Layer: Layer 2, Input: [-0.9961745359811116, -0.1286573134823516, -0.9769452134771265, -0.9271001791040354], Output: [0.8463197228345187]\n",
      "Epoch 322/500, Loss: 0.189130138790996, Accuracy: -0.6132779590917221\n",
      "Power operation: base = 0.6095244890597398, power = 2, grad = 0.25\n",
      "Power operation: base = 0.43097832158947913, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41909487127702194, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15368027716548127, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894073078915052, 0.9879125423057784, -0.9737412956418713, -0.9972735548495415]\n",
      "Layer: Layer 1, Input: [0.9894073078915052, 0.9879125423057784, -0.9737412956418713, -0.9972735548495415], Output: [-0.9973408802392407, -0.5615308609110606, -0.9845760696679143, -0.9415890562564929]\n",
      "Layer: Layer 2, Input: [-0.9973408802392407, -0.5615308609110606, -0.9845760696679143, -0.9415890562564929], Output: [1.6119715348654955]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981601536247053, 0.979119720070433, 0.01716198705849531, -0.931839490574981]\n",
      "Layer: Layer 1, Input: [0.9981601536247053, 0.979119720070433, 0.01716198705849531, -0.931839490574981], Output: [-0.9960395040139968, 0.6877296601137546, -0.9608536183893223, -0.9237548065652712]\n",
      "Layer: Layer 2, Input: [-0.9960395040139968, 0.6877296601137546, -0.9608536183893223, -0.9237548065652712], Output: [-0.5722980248706735]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9313432671630439, 0.34323374267130397, 0.43517311597396896, -0.8754948789000757]\n",
      "Layer: Layer 1, Input: [0.9313432671630439, 0.34323374267130397, 0.43517311597396896, -0.8754948789000757], Output: [-0.9791035173435947, 0.9922929023910708, -0.8837732916264494, -0.7805260659209898]\n",
      "Layer: Layer 2, Input: [-0.9791035173435947, 0.9922929023910708, -0.8837732916264494, -0.7805260659209898], Output: [-1.4190043262722996]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.884592057395491, 0.9860135756155454, -0.7956517383821751, -0.9245794233107926]\n",
      "Layer: Layer 1, Input: [0.884592057395491, 0.9860135756155454, -0.7956517383821751, -0.9245794233107926], Output: [-0.9961832786987801, -0.12894100899492325, -0.9770864528866815, -0.9275646155533528]\n",
      "Layer: Layer 2, Input: [-0.9961832786987801, -0.12894100899492325, -0.9770864528866815, -0.9275646155533528], Output: [0.8467123279395636]\n",
      "Epoch 323/500, Loss: 0.18912496871394224, Accuracy: -0.6119655083275579\n",
      "Power operation: base = 0.6119715348654955, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4277019751293265, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41900432627229955, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15328767206043636, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894112065350557, 0.987938132734447, -0.9737469313518868, -0.9972755180249351]\n",
      "Layer: Layer 1, Input: [0.9894112065350557, 0.987938132734447, -0.9737469313518868, -0.9972755180249351], Output: [-0.9973466461948322, -0.5629471910172957, -0.9846715840289374, -0.9419764444667417]\n",
      "Layer: Layer 2, Input: [-0.9973466461948322, -0.5629471910172957, -0.9846715840289374, -0.9419764444667417], Output: [1.614402601840645]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981606391801962, 0.9791633111315816, 0.017068800742300803, -0.9318793729976315]\n",
      "Layer: Layer 1, Input: [0.9981606391801962, 0.9791633111315816, 0.017068800742300803, -0.9318793729976315], Output: [-0.9960481300425807, 0.6893816518846497, -0.9610787732368014, -0.9241938330493988]\n",
      "Layer: Layer 2, Input: [-0.9960481300425807, 0.6893816518846497, -0.9610787732368014, -0.9241938330493988], Output: [-0.5755643227669474]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9313592209549715, 0.34416294930065555, 0.435100350685959, -0.8755626151062911]\n",
      "Layer: Layer 1, Input: [0.9313592209549715, 0.34416294930065555, 0.435100350685959, -0.8755626151062911], Output: [-0.9791855651960563, 0.9924192315541314, -0.8844400459694797, -0.7817247759032648]\n",
      "Layer: Layer 2, Input: [-0.9791855651960563, 0.9924192315541314, -0.8844400459694797, -0.7817247759032648], Output: [-1.4189259221156947]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8846246216169976, 0.986042970111873, -0.7956878395586618, -0.9246261770028653]\n",
      "Layer: Layer 1, Input: [0.8846246216169976, 0.986042970111873, -0.7956878395586618, -0.9246261770028653], Output: [-0.9961919757560493, -0.12923530324494703, -0.9772265551920731, -0.9280254618102818]\n",
      "Layer: Layer 2, Input: [-0.9961919757560493, -0.12923530324494703, -0.9772265551920731, -0.9280254618102818], Output: [0.8471050340234418]\n",
      "Epoch 324/500, Loss: 0.18912800002457303, Accuracy: -0.6106591671659505\n",
      "Power operation: base = 0.614402601840645, power = 2, grad = 0.25\n",
      "Power operation: base = 0.42443567723305264, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4189259221156947, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15289496597655816, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894150913143224, 0.9879635859299749, -0.9737525608679822, -0.9972774743667143]\n",
      "Layer: Layer 1, Input: [0.9894150913143224, 0.9879635859299749, -0.9737525608679822, -0.9972774743667143], Output: [-0.9973523829254249, -0.5643638449427307, -0.9847663109192202, -0.9423606565244498]\n",
      "Layer: Layer 2, Input: [-0.9973523829254249, -0.5643638449427307, -0.9847663109192202, -0.9423606565244498], Output: [1.6168177658411373]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981611231292412, 0.9792066709914862, 0.01697566331705073, -0.9319191314954693]\n",
      "Layer: Layer 1, Input: [0.9981611231292412, 0.9792066709914862, 0.01697566331705073, -0.9319191314954693], Output: [-0.9960567124555625, 0.6910166255294438, -0.9613022755946403, -0.9246299072494998]\n",
      "Layer: Layer 2, Input: [-0.9960567124555625, 0.6910166255294438, -0.9613022755946403, -0.9246299072494998], Output: [-0.578820612581274]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9313751233872201, 0.34508847157118894, 0.4350276110786083, -0.875630148765202]\n",
      "Layer: Layer 1, Input: [0.9313751233872201, 0.34508847157118894, 0.4350276110786083, -0.875630148765202], Output: [-0.9792670265754133, 0.9925429101247388, -0.885102312887653, -0.7829169581067984]\n",
      "Layer: Layer 2, Input: [-0.9792670265754133, 0.9925429101247388, -0.885102312887653, -0.7829169581067984], Output: [-1.4188593785804224]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8846570761055669, 0.9860722078827571, -0.7957239112483986, -0.9246727801363044]\n",
      "Layer: Layer 1, Input: [0.8846570761055669, 0.9860722078827571, -0.7957239112483986, -0.9246727801363044], Output: [-0.9962006277875036, -0.12953993484881782, -0.9773655346454866, -0.92848275841699]\n",
      "Layer: Layer 2, Input: [-0.9962006277875036, -0.12953993484881782, -0.9773655346454866, -0.92848275841699], Output: [0.8474978346468349]\n",
      "Epoch 325/500, Loss: 0.18913908052646178, Accuracy: -0.6093586971934508\n",
      "Power operation: base = 0.6168177658411373, power = 2, grad = 0.25\n",
      "Power operation: base = 0.42117938741872596, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41885937858042244, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15250216535316508, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894189623524332, 0.9879889036867384, -0.9737581843784298, -0.9972794239596637]\n",
      "Layer: Layer 1, Input: [0.9894189623524332, 0.9879889036867384, -0.9737581843784298, -0.9972794239596637], Output: [-0.997358090829919, -0.5657806154662567, -0.984860260252027, -0.9427417290492931]\n",
      "Layer: Layer 2, Input: [-0.997358090829919, -0.5657806154662567, -0.984860260252027, -0.9427417290492931], Output: [1.61921710305542]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981616054907428, 0.9792498026832716, 0.016882571234224045, -0.9319587679175878]\n",
      "Layer: Layer 1, Input: [0.9981616054907428, 0.9792498026832716, 0.016882571234224045, -0.9319587679175878], Output: [-0.9960652518727113, 0.69263484686568, -0.9615241449943948, -0.9250630605957968]\n",
      "Layer: Layer 2, Input: [-0.9960652518727113, 0.69263484686568, -0.9615241449943948, -0.9250630605957968], Output: [-0.5820669333001884]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9313909751205885, 0.3460103570708312, 0.4349548942831852, -0.8756974830713347]\n",
      "Layer: Layer 1, Input: [0.9313909751205885, 0.3460103570708312, 0.4349548942831852, -0.8756974830713347], Output: [-0.9793479099061195, 0.9926640034853969, -0.8857601417037027, -0.7841026760720143]\n",
      "Layer: Layer 2, Input: [-0.9793479099061195, 0.9926640034853969, -0.8857601417037027, -0.7841026760720143], Output: [-1.418804421570118]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8846894220165787, 0.9861012909826031, -0.7957599547679303, -0.9247192348102037]\n",
      "Layer: Layer 1, Input: [0.8846894220165787, 0.9861012909826031, -0.7957599547679303, -0.9247192348102037], Output: [-0.9962092354118806, -0.12985464705446237, -0.9775034051377569, -0.9289365449347308]\n",
      "Layer: Layer 2, Input: [-0.9962092354118806, -0.12985464705446237, -0.9775034051377569, -0.9289365449347308], Output: [0.8478907228866817]\n",
      "Epoch 326/500, Loss: 0.18915806116701833, Accuracy: -0.6080638684386681\n",
      "Power operation: base = 0.6192171030554201, power = 2, grad = 0.25\n",
      "Power operation: base = 0.41793306669981156, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4188044215701181, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15210927711331834, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894228197696718, 0.9880140877551425, -0.9737638020656122, -0.9972813668863675]\n",
      "Layer: Layer 1, Input: [0.9894228197696718, 0.9880140877551425, -0.9737638020656122, -0.9972813668863675], Output: [-0.9973637702973441, -0.5671973004288888, -0.9849534416965765, -0.9431196978276397]\n",
      "Layer: Layer 2, Input: [-0.9973637702973441, -0.5671973004288888, -0.9849534416965765, -0.9431196978276397], Output: [1.621600690014687]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981620862831342, 0.979292709165352, 0.01678952105536363, -0.931998284062428]\n",
      "Layer: Layer 1, Input: [0.9981620862831342, 0.979292709165352, 0.01678952105536363, -0.931998284062428], Output: [-0.996073748898137, 0.6942365763632533, -0.9617444004476816, -0.9254933236554076]\n",
      "Layer: Layer 2, Input: [-0.996073748898137, 0.6942365763632533, -0.9617444004476816, -0.9254933236554076], Output: [-0.5853033224665687]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9314067767992109, 0.34692865216266744, 0.4348821975192829, -0.8757646211306362]\n",
      "Layer: Layer 1, Input: [0.9314067767992109, 0.34692865216266744, 0.4348821975192829, -0.8757646211306362], Output: [-0.9794282234044466, 0.9927825751815611, -0.8864135803134245, -0.7852819910459501]\n",
      "Layer: Layer 2, Input: [-0.9794282234044466, 0.9927825751815611, -0.8864135803134245, -0.7852819910459501], Output: [-1.4187607829707627]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8847216604773339, 0.9861302214153086, -0.7957959713925268, -0.9247655430671142]\n",
      "Layer: Layer 1, Input: [0.8847216604773339, 0.9861302214153086, -0.7957959713925268, -0.9247655430671142], Output: [-0.9962177992325426, -0.1301791876319134, -0.9776401802112724, -0.9293868599768876]\n",
      "Layer: Layer 2, Input: [-0.9962177992325426, -0.1301791876319134, -0.9776401802112724, -0.9293868599768876], Output: [0.8482836913470244]\n",
      "Epoch 327/500, Loss: 0.18918479596239324, Accuracy: -0.6067744591718567\n",
      "Power operation: base = 0.6216006900146871, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4146966775334313, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4187607829707627, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15171630865297558, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989426663683564, 0.988039139842927, -0.9737694141061821, -0.9972833032272737]\n",
      "Layer: Layer 1, Input: [0.989426663683564, 0.988039139842927, -0.9737694141061821, -0.9972833032272737], Output: [-0.99736942170715, -0.5686137026287569, -0.9850458646866316, -0.9434945978400038]\n",
      "Layer: Layer 2, Input: [-0.99736942170715, -0.5686137026287569, -0.9850458646866316, -0.9434945978400038], Output: [1.6239686036024388]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981625655243929, 0.9793353933236473, 0.016696509449237878, -0.9320376816792308]\n",
      "Layer: Layer 1, Input: [0.9981625655243929, 0.9793353933236473, 0.016696509449237878, -0.9320376816792308], Output: [-0.9960822041207523, 0.6958220692865617, -0.9619630604652283, -0.9259207261624154]\n",
      "Layer: Layer 2, Input: [-0.9960822041207523, 0.6958220692865617, -0.9619630604652283, -0.9259207261624154], Output: [-0.5885298162292028]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9314225290510242, 0.34784340201986375, 0.4348095180925702, -0.8758315659629965]\n",
      "Layer: Layer 1, Input: [0.9314225290510242, 0.34784340201986375, 0.4348095180925702, -0.8758315659629965], Output: [-0.9795079750849299, 0.9928986869800356, -0.8870626752398985, -0.7864549620650186]\n",
      "Layer: Layer 2, Input: [-0.9795079750849299, 0.9928986869800356, -0.8870626752398985, -0.7864549620650186], Output: [-1.4187282005050714]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8847537925878741, 0.9861590011357624, -0.7958319623572687, -0.9248117068946794]\n",
      "Layer: Layer 1, Input: [0.8847537925878741, 0.9861590011357624, -0.7958319623572687, -0.9248117068946794], Output: [-0.9962263198379318, -0.13051330876682382, -0.9777758730723927, -0.9298337412409463]\n",
      "Layer: Layer 2, Input: [-0.9962263198379318, -0.13051330876682382, -0.9777758730723927, -0.9298337412409463], Output: [0.8486767321697535]\n",
      "Epoch 328/500, Loss: 0.1892191419247477, Accuracy: -0.605490255708554\n",
      "Power operation: base = 0.6239686036024388, power = 2, grad = 0.25\n",
      "Power operation: base = 0.41147018377079725, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4187282005050714, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15132326783024652, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894304942089617, 0.9880640616164285, -0.9737750206712162, -0.9972852330607572]\n",
      "Layer: Layer 1, Input: [0.9894304942089617, 0.9880640616164285, -0.9737750206712162, -0.9972852330607572], Output: [-0.9973750454294903, -0.57002962971848, -0.985137538428772, -0.9438664632875893]\n",
      "Layer: Layer 2, Input: [-0.9973750454294903, -0.57002962971848, -0.985137538428772, -0.9438664632875893], Output: [1.6263209210634626]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998163043232054, 0.9793778579737278, 0.016603533189083336, -0.9320769624694467]\n",
      "Layer: Layer 1, Input: [0.998163043232054, 0.9793778579737278, 0.016603533189083336, -0.9320769624694467], Output: [-0.9960906181147208, 0.6973915758323861, -0.9621801430752147, -0.9263452970470046]\n",
      "Layer: Layer 2, Input: [-0.9960906181147208, 0.6973915758323861, -0.9621801430752147, -0.9263452970470046], Output: [-0.5917464493903131]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9314382324882223, 0.34875465065952177, 0.4347368533926047, -0.8758983205046917]\n",
      "Layer: Layer 1, Input: [0.9314382324882223, 0.34875465065952177, 0.4347368533926047, -0.8758983205046917], Output: [-0.9795871727665882, 0.9930123989252851, -0.8877074716857573, -0.7876216460354134]\n",
      "Layer: Layer 2, Input: [-0.9795871727665882, 0.9930123989252851, -0.8877074716857573, -0.7876216460354134], Output: [-1.4187064175894042]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8847858194217786, 0.9861876320512949, -0.7958679288581061, -0.9248577282272225]\n",
      "Layer: Layer 1, Input: [0.8847858194217786, 0.9861876320512949, -0.7958679288581061, -0.9248577282272225], Output: [-0.996234797802011, -0.13085676695686788, -0.9779104966034036, -0.9302772255394224]\n",
      "Layer: Layer 2, Input: [-0.996234797802011, -0.13085676695686788, -0.9779104966034036, -0.9302772255394224], Output: [0.8490698370453034]\n",
      "Epoch 329/500, Loss: 0.18926095899182105, Accuracy: -0.6042110522172504\n",
      "Power operation: base = 0.6263209210634626, power = 2, grad = 0.25\n",
      "Power operation: base = 0.40825355060968693, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4187064175894042, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15093016295469663, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894343114581244, 0.9880888547018023, -0.9737806219263662, -0.9972871564631811]\n",
      "Layer: Layer 1, Input: [0.9894343114581244, 0.9880888547018023, -0.9737806219263662, -0.9972871564631811], Output: [-0.9973806418254921, -0.5714448941048674, -0.9852284719103518, -0.9442353276179467]\n",
      "Layer: Layer 2, Input: [-0.9973806418254921, -0.5714448941048674, -0.9852284719103518, -0.9442353276179467], Output: [1.6286577200121268]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981635194232222, 0.9794201058628889, 0.016510589149922265, -0.9321161280880995]\n",
      "Layer: Layer 1, Input: [0.9981635194232222, 0.9794201058628889, 0.016510589149922265, -0.9321161280880995], Output: [-0.9960989914398884, 0.6989453412636077, -0.9623956658409415, -0.9267670644636832]\n",
      "Layer: Layer 2, Input: [-0.9960989914398884, 0.6989453412636077, -0.9623956658409415, -0.9267670644636832], Output: [-0.5949532554511494]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9314538877076967, 0.3496624409754956, 0.4346642008907085, -0.875964887610757]\n",
      "Layer: Layer 1, Input: [0.9314538877076967, 0.3496624409754956, 0.4346642008907085, -0.875964887610757], Output: [-0.9796658240789274, 0.9931237693937455, -0.8883480135835675, -0.7887820978112162]\n",
      "Layer: Layer 2, Input: [-0.9796658240789274, 0.9931237693937455, -0.8883480135835675, -0.7887820978112162], Output: [-1.4186951831932415]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8848177420269355, 0.9862161160230813, -0.7959038720528845, -0.9249036089472816]\n",
      "Layer: Layer 1, Input: [0.8848177420269355, 0.9862161160230813, -0.7959038720528845, -0.9249036089472816], Output: [-0.9962432336846897, -0.1312093229110001, -0.9780440633740206, -0.9307173488297755]\n",
      "Layer: Layer 2, Input: [-0.9962432336846897, -0.1312093229110001, -0.9780440633740206, -0.9307173488297755], Output: [0.8494629972232524]\n",
      "Epoch 330/500, Loss: 0.189310109958674, Accuracy: -0.6029366505309666\n",
      "Power operation: base = 0.6286577200121268, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4050467445488506, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4186951831932415, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15053700277674764, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894381155407989, 0.9881135206862033, -0.9737862180320033, -0.9972890735089549]\n",
      "Layer: Layer 1, Input: [0.9894381155407989, 0.9881135206862033, -0.9737862180320033, -0.9972890735089549], Output: [-0.9973862112475226, -0.5728593128509113, -0.9853186739071595, -0.9446012235497742]\n",
      "Layer: Layer 2, Input: [-0.9973862112475226, -0.5728593128509113, -0.9853186739071595, -0.9446012235497742], Output: [1.630979078440097]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981639941145848, 0.9794621396721576, 0.0164176743059593, -0.9321551801451113]\n",
      "Layer: Layer 1, Input: [0.9981639941145848, 0.9794621396721576, 0.0164176743059593, -0.9321551801451113], Output: [-0.9961073246422046, 0.7004836060388794, -0.9626096458778417, -0.9271860558186197]\n",
      "Layer: Layer 2, Input: [-0.9961073246422046, 0.7004836060388794, -0.9626096458778417, -0.9271860558186197], Output: [-0.5981502666557326]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9314694952914627, 0.35056681477020546, 0.43459155813790257, -0.8760312700572809]\n",
      "Layer: Layer 1, Input: [0.9314694952914627, 0.35056681477020546, 0.43459155813790257, -0.8760312700572809], Output: [-0.9797439364677365, 0.993232855146211, -0.8889843436443908, -0.7899363702702602]\n",
      "Layer: Layer 2, Input: [-0.9797439364677365, 0.993232855146211, -0.8889843436443908, -0.7899363702702602], Output: [-1.4186942517012775]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8848495614262903, 0.9862444548674985, -0.795939793062342, -0.9249493508871008]\n",
      "Layer: Layer 1, Input: [0.8848495614262903, 0.9862444548674985, -0.795939793062342, -0.9249493508871008], Output: [-0.9962516280322372, -0.131570741451518, -0.9781765856524652, -0.9311541462433442]\n",
      "Layer: Layer 2, Input: [-0.9962516280322372, -0.131570741451518, -0.9781765856524652, -0.9311541462433442], Output: [0.849856203522898]\n",
      "Epoch 331/500, Loss: 0.18936646041155575, Accuracy: -0.6016668599627439\n",
      "Power operation: base = 0.630979078440097, power = 2, grad = 0.25\n",
      "Power operation: base = 0.40184973334426743, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4186942517012775, power = 2, grad = 0.25\n",
      "Power operation: base = -0.15014379647710197, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894419065642945, 0.9881380611189292, -0.9737918091433604, -0.9972909842705922]\n",
      "Layer: Layer 1, Input: [0.9894419065642945, 0.9881380611189292, -0.9737918091433604, -0.9972909842705922], Output: [-0.9973917540394419, -0.5742727075800346, -0.98540815299079, -0.9449641830968893]\n",
      "Layer: Layer 2, Input: [-0.9973917540394419, -0.5742727075800346, -0.98540815299079, -0.9449641830968893], Output: [1.6332850747233838]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981644673224227, 0.9795039620182338, 0.01632478572804932, -0.9321941202065839]\n",
      "Layer: Layer 1, Input: [0.9981644673224227, 0.9795039620182338, 0.01632478572804932, -0.9321941202065839], Output: [-0.9961156182541248, 0.7020066059383602, -0.9628220998698639, -0.9276022977961182]\n",
      "Layer: Layer 2, Input: [-0.9961156182541248, 0.7020066059383602, -0.9628220998698639, -0.9276022977961182], Output: [-0.6013375140328803]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9314850558070747, 0.3514678127854783, 0.4345189227629, -0.8760974705436344]\n",
      "Layer: Layer 1, Input: [0.9314850558070747, 0.3514678127854783, 0.4345189227629, -0.8760974705436344], Output: [-0.9798215172006816, 0.9933397113783745, -0.889616503404585, -0.7910845143878065]\n",
      "Layer: Layer 2, Input: [-0.9798215172006816, 0.9933397113783745, -0.889616503404585, -0.7910845143878065], Output: [-1.4187033827781734]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8848812786185728, 0.9862726503574369, -0.7959756929710804, -0.9249949558300721]\n",
      "Layer: Layer 1, Input: [0.8848812786185728, 0.9862726503574369, -0.7959756929710804, -0.9249949558300721], Output: [-0.9962599813776803, -0.13194079141887607, -0.9783080754161211, -0.9315876521133248]\n",
      "Layer: Layer 2, Input: [-0.9962599813776803, -0.13194079141887607, -0.9783080754161211, -0.9315876521133248], Output: [0.8502494463437182]\n",
      "Epoch 332/500, Loss: 0.18942987866378358, Accuracy: -0.6004014971249587\n",
      "Power operation: base = 0.6332850747233838, power = 2, grad = 0.25\n",
      "Power operation: base = 0.39866248596711973, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4187033827781734, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14975055365628176, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989445684633559, 0.9881624775125257, -0.9737973954106701, -0.9972928888187651]\n",
      "Layer: Layer 1, Input: [0.989445684633559, 0.9881624775125257, -0.9737973954106701, -0.9972928888187651], Output: [-0.9973972705368511, -0.5756849043825445, -0.9854969175357368, -0.945324237591394]\n",
      "Layer: Layer 2, Input: [-0.9973972705368511, -0.5756849043825445, -0.9854969175357368, -0.945324237591394], Output: [1.635575787628782]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981649390626227, 0.9795455754553689, 0.016231920581236257, -0.9322329497960428]\n",
      "Layer: Layer 1, Input: [0.9981649390626227, 0.9795455754553689, 0.016231920581236257, -0.9322329497960428], Output: [-0.9961238727950048, 0.7035145721856307, -0.9630330440852479, -0.9280158163842561]\n",
      "Layer: Layer 2, Input: [-0.9961238727950048, 0.7035145721856307, -0.9630330440852479, -0.9280158163842561], Output: [-0.6045150274366033]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9315005698080268, 0.35236547473244983, 0.434446292470155, -0.8761634916946304]\n",
      "Layer: Layer 1, Input: [0.9315005698080268, 0.35236547473244983, 0.434446292470155, -0.8761634916946304], Output: [-0.9798985733727092, 0.9934443917695907, -0.890244533270906, -0.7922265793080892]\n",
      "Layer: Layer 2, Input: [-0.9798985733727092, 0.9934443917695907, -0.890244533270906, -0.7922265793080892], Output: [-1.4187223412359784]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8849128945789998, 0.9863007042235723, -0.7960115728285064, -0.925040425512136]\n",
      "Layer: Layer 1, Input: [0.8849128945789998, 0.9863007042235723, -0.7960115728285064, -0.925040425512136], Output: [-0.9962682942411901, -0.13231924557921876, -0.978438544361794, -0.932017900001828]\n",
      "Layer: Layer 2, Input: [-0.9962682942411901, -0.13231924557921876, -0.978438544361794, -0.932017900001828], Output: [0.8506427156758072]\n",
      "Epoch 333/500, Loss: 0.1895002356935635, Accuracy: -0.5991403857523498\n",
      "Power operation: base = 0.635575787628782, power = 2, grad = 0.25\n",
      "Power operation: base = 0.39548497256339665, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4187223412359784, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14935728432419282, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894494498512487, 0.9881867713438566, -0.9738029769792985, -0.9972947872223589]\n",
      "Layer: Layer 1, Input: [0.9894494498512487, 0.9881867713438566, -0.9738029769792985, -0.9972947872223589], Output: [-0.997402761067331, -0.57709573372426, -0.9855849757262226, -0.9456814177060617]\n",
      "Layer: Layer 2, Input: [-0.997402761067331, -0.57709573372426, -0.9855849757262226, -0.9456814177060617], Output: [1.6378512963197016]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981654093506879, 0.9795869824771827, 0.01613907612236181, -0.9322716703956434]\n",
      "Layer: Layer 1, Input: [0.9981654093506879, 0.9795869824771827, 0.01613907612236181, -0.9322716703956434], Output: [-0.9961320887714792, 0.7050077315658829, -0.9632424943917164, -0.9284266368997072]\n",
      "Layer: Layer 2, Input: [-0.9961320887714792, 0.7050077315658829, -0.9632424943917164, -0.9284266368997072], Output: [-0.6076828355849422]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9315160378341432, 0.35325983932055455, 0.4343736650379667, -0.8762293360626155]\n",
      "Layer: Layer 1, Input: [0.9315160378341432, 0.35325983932055455, 0.4343736650379667, -0.8762293360626155], Output: [-0.979975111911262, 0.9935469485299334, -0.8908684725639724, -0.793362612413778]\n",
      "Layer: Layer 2, Input: [-0.979975111911262, 0.9935469485299334, -0.8908684725639724, -0.793362612413778], Output: [-1.4187508969042724]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8849444102599588, 0.9863286181555927, -0.7960474336497468, -0.9250857616231377]\n",
      "Layer: Layer 1, Input: [0.8849444102599588, 0.9863286181555927, -0.7960474336497468, -0.9250857616231377], Output: [-0.9962765671304554, -0.13270588053457927, -0.9785680039155857, -0.9324449227260379]\n",
      "Layer: Layer 2, Input: [-0.9962765671304554, -0.13270588053457927, -0.9785680039155857, -0.9324449227260379], Output: [0.8510360011102573]\n",
      "Epoch 334/500, Loss: 0.18957740508368776, Accuracy: -0.5978833565287744\n",
      "Power operation: base = 0.6378512963197016, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3923171644150578, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41875089690427236, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14896399888974265, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894532023178, 0.9882109440551384, -0.9738085539898745, -0.9972966795485237]\n",
      "Layer: Layer 1, Input: [0.9894532023178, 0.9882109440551384, -0.9738085539898745, -0.9972966795485237], Output: [-0.9974082259506737, -0.578505030357263, -0.9856723355627676, -0.9460357534759698]\n",
      "Layer: Layer 2, Input: [-0.9974082259506737, -0.578505030357263, -0.9856723355627676, -0.9460357534759698], Output: [1.6401116803613753]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981658782017493, 0.9796281855184222, 0.016046249697742508, -0.9323102834473382]\n",
      "Layer: Layer 1, Input: [0.9981658782017493, 0.9796281855184222, 0.016046249697742508, -0.9323102834473382], Output: [-0.9961402666778287, 0.7064863065405106, -0.9634504662711003, -0.9288347840117757]\n",
      "Layer: Layer 2, Input: [-0.9961402666778287, 0.7064863065405106, -0.9634504662711003, -0.9288347840117757], Output: [-0.6108409660973777]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9315314604119559, 0.3541509442856346, 0.43430103831663636, -0.8762950061295023]\n",
      "Layer: Layer 1, Input: [0.9315314604119559, 0.3541509442856346, 0.43430103831663636, -0.8762950061295023], Output: [-0.9800511395813165, 0.9936474324456129, -0.8914883595601425, -0.7944926593934156]\n",
      "Layer: Layer 2, Input: [-0.9800511395813165, 0.9936474324456129, -0.8914883595601425, -0.7944926593934156], Output: [-1.4187888245030216]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8849758265916701, 0.986356393803389, -0.796083276416539, -0.925130965808142]\n",
      "Layer: Layer 1, Input: [0.8849758265916701, 0.986356393803389, -0.796083276416539, -0.925130965808142], Output: [-0.996284800541044, -0.13310047663568073, -0.9786964652423954, -0.9328687523835035]\n",
      "Layer: Layer 2, Input: [-0.996284800541044, -0.13310047663568073, -0.9786964652423954, -0.9328687523835035], Output: [0.8514292918494553]\n",
      "Epoch 335/500, Loss: 0.1896612629630157, Accuracy: -0.5966302469175639\n",
      "Power operation: base = 0.6401116803613753, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3891590339026223, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4187888245030216, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14857070815054474, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989456942131496, 0.9882349970549426, -0.9738141265784165, -0.9972985658627244]\n",
      "Layer: Layer 1, Input: [0.989456942131496, 0.9882349970549426, -0.9738141265784165, -0.9972985658627244], Output: [-0.9974136654991062, -0.5799126332327305, -0.9857590048685145, -0.9463872743193988]\n",
      "Layer: Layer 2, Input: [-0.9974136654991062, -0.5799126332327305, -0.9857590048685145, -0.9463872743193988], Output: [1.6423570197254502]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981663456305754, 0.9796691869566638, 0.01595343874090932, -0.9323487903540116]\n",
      "Layer: Layer 1, Input: [0.9981663456305754, 0.9796691869566638, 0.01595343874090932, -0.9323487903540116], Output: [-0.9961484069963356, 0.7079505153581798, -0.9636569748334238, -0.9292402817656595]\n",
      "Layer: Layer 2, Input: [-0.9961484069963356, 0.7079505153581798, -0.9636569748334238, -0.9292402817656595], Output: [-0.6139894455308426]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9315468380550719, 0.35503882641719675, 0.43422841022667574, -0.8763605043087352]\n",
      "Layer: Layer 1, Input: [0.9315468380550719, 0.35503882641719675, 0.43422841022667574, -0.8763605043087352], Output: [-0.9801266629902501, 0.9937458929228145, -0.8921042315318666, -0.7956167643068749]\n",
      "Layer: Layer 2, Input: [-0.9801266629902501, 0.9937458929228145, -0.8921042315318666, -0.7956167643068749], Output: [-1.418835903518167]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8850071444828286, 0.9863840327782047, -0.7961191020780944, -0.9251760396687077]\n",
      "Layer: Layer 1, Input: [0.8850071444828286, 0.9863840327782047, -0.7961191020780944, -0.9251760396687077], Output: [-0.9962929949567522, -0.1335028178973107, -0.9788239392550684, -0.9332894203765861]\n",
      "Layer: Layer 2, Input: [-0.9962929949567522, -0.1335028178973107, -0.9788239392550684, -0.9332894203765861], Output: [0.8518225767173631]\n",
      "Epoch 336/500, Loss: 0.18975168794967748, Accuracy: -0.5953809009954116\n",
      "Power operation: base = 0.6423570197254502, power = 2, grad = 0.25\n",
      "Power operation: base = 0.38601055446915744, power = 2, grad = 0.25\n",
      "Power operation: base = -0.418835903518167, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14817742328263694, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894606693885324, 0.9882589317191641, -0.9738196948764554, -0.99730044622879]\n",
      "Layer: Layer 1, Input: [0.9894606693885324, 0.9882589317191641, -0.9738196948764554, -0.99730044622879], Output: [-0.9974190800175063, -0.5813183854158103, -0.9858449912953149, -0.946736009058026]\n",
      "Layer: Layer 2, Input: [-0.9974190800175063, -0.5813183854158103, -0.9858449912953149, -0.946736009058026], Output: [1.6445873947939944]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981668116515834, 0.9797099891139601, 0.01586064077041252, -0.9323871924805772]\n",
      "Layer: Layer 1, Input: [0.9981668116515834, 0.9797099891139601, 0.01586064077041252, -0.9323871924805772], Output: [-0.996156510197628, 0.7094005721625036, -0.9638620348304624, -0.9296431536049695]\n",
      "Layer: Layer 2, Input: [-0.996156510197628, 0.7094005721625036, -0.9638620348304624, -0.9296431536049695], Output: [-0.6171282994144649]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9315621712645282, 0.35592352158484253, 0.43415577875706557, -0.876425832947202]\n",
      "Layer: Layer 1, Input: [0.9315621712645282, 0.35592352158484253, 0.43415577875706557, -0.876425832947202], Output: [-0.98020168859254, 0.9938423780300223, -0.8927161247865611, -0.7967349696488889]\n",
      "Layer: Layer 2, Input: [-0.98020168859254, 0.9938423780300223, -0.8927161247865611, -0.7967349696488889], Output: [-1.4188919180799555]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8850383648212273, 0.98641153665375, -0.7961549115519397, -0.9252209847641235]\n",
      "Layer: Layer 1, Input: [0.8850383648212273, 0.98641153665375, -0.7961549115519397, -0.9252209847641235], Output: [-0.9963011508499442, -0.1339126919162059, -0.9789504366231971, -0.9337069574360897]\n",
      "Layer: Layer 2, Input: [-0.9963011508499442, -0.1339126919162059, -0.9789504366231971, -0.9337069574360897], Output: [0.8522158441697352]\n",
      "Epoch 337/500, Loss: 0.18984856109593415, Accuracy: -0.5941351692897499\n",
      "Power operation: base = 0.6445873947939944, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3828717005855351, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4188919180799555, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14778415583026483, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989464384183081, 0.9882827493919606, -0.9738252590111524, -0.9973023207089606]\n",
      "Layer: Layer 1, Input: [0.989464384183081, 0.9882827493919606, -0.9738252590111524, -0.9973023207089606], Output: [-0.9974244698036139, -0.5827221340024855, -0.9859303023295853, -0.9470819859364313]\n",
      "Layer: Layer 2, Input: [-0.9974244698036139, -0.5827221340024855, -0.9859303023295853, -0.9470819859364313], Output: [1.6468028863628774]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998167276278848, 0.9797505942584344, 0.015767853387686426, -0.9324254911550439]\n",
      "Layer: Layer 1, Input: [0.998167276278848, 0.9797505942584344, 0.015767853387686426, -0.9324254911550439], Output: [-0.9961645767410124, 0.7108366870964, -0.9640656606687984, -0.9300434223935212]\n",
      "Layer: Layer 2, Input: [-0.9961645767410124, 0.7108366870964, -0.9640656606687984, -0.9300434223935212], Output: [-0.6202575522830776]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9315774605291379, 0.35680506476389995, 0.4340831419635628, -0.8764909943270828]\n",
      "Layer: Layer 1, Input: [0.9315774605291379, 0.35680506476389995, 0.4340831419635628, -0.8764909943270828], Output: [-0.9802762226943048, 0.9939369345388842, -0.8933240747040582, -0.797847316410704]\n",
      "Layer: Layer 2, Input: [-0.9802762226943048, 0.9939369345388842, -0.8933240747040582, -0.797847316410704], Output: [-1.4189566568440095]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8850694884743614, 0.9864389069672796, -0.7961907057247326, -0.9252658026126073]\n",
      "Layer: Layer 1, Input: [0.8850694884743614, 0.9864389069672796, -0.7961907057247326, -0.9252658026126073], Output: [-0.9963092686818789, -0.13432988979139773, -0.9790759677815943, -0.9341213936440999]\n",
      "Layer: Layer 2, Input: [-0.9963092686818789, -0.13432988979139773, -0.9790759677815943, -0.9341213936440999], Output: [0.8526090823042836]\n",
      "Epoch 338/500, Loss: 0.18995176583462087, Accuracy: -0.5928929086195258\n",
      "Power operation: base = 0.6468028863628774, power = 2, grad = 0.25\n",
      "Power operation: base = 0.37974244771692245, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4189566568440095, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14739091769571644, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894680866073519, 0.9883064513866597, -0.9738308191054171, -0.9973041893639332]\n",
      "Layer: Layer 1, Input: [0.9894680866073519, 0.9883064513866597, -0.9738308191054171, -0.9973041893639332], Output: [-0.9974298351482335, -0.5841237300383985, -0.9860149452979461, -0.9474252326409396]\n",
      "Layer: Layer 2, Input: [-0.9974298351482335, -0.5841237300383985, -0.9860149452979461, -0.9474252326409396], Output: [1.6490035756446026]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998167739526112, 0.9797910046058241, 0.015675074274976022, -0.9324636876695487]\n",
      "Layer: Layer 1, Input: [0.998167739526112, 0.9797910046058241, 0.015675074274976022, -0.9324636876695487], Output: [-0.9961726070747967, 0.7122590664032484, -0.9642678664223892, -0.9304411104364235]\n",
      "Layer: Layer 2, Input: [-0.9961726070747967, 0.7122590664032484, -0.9642678664223892, -0.9304411104364235], Output: [-0.6233772277095904]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9315927063258242, 0.3576834900602828, 0.43401049796705454, -0.8765559906676466]\n",
      "Layer: Layer 1, Input: [0.9315927063258242, 0.3576834900602828, 0.43401049796705454, -0.8765559906676466], Output: [-0.9803502714576919, 0.9940296079636741, -0.8939281157726799, -0.7989538441398972]\n",
      "Layer: Layer 2, Input: [-0.9803502714576919, 0.9940296079636741, -0.8939281157726799, -0.7989538441398972], Output: [-1.4190299128751263]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8851005162900139, 0.986466145220636, -0.7962264854530553, -0.9253104946924658]\n",
      "Layer: Layer 1, Input: [0.8851005162900139, 0.986466145220636, -0.7962264854530553, -0.9253104946924658], Output: [-0.9963173489030278, -0.13475420604696345, -0.9792005429384477, -0.9345327584560541]\n",
      "Layer: Layer 2, Input: [-0.9963173489030278, -0.13475420604696345, -0.9792005429384477, -0.9345327584560541], Output: [0.8530022788707985]\n",
      "Epoch 339/500, Loss: 0.1900611879271269, Accuracy: -0.59165398193934\n",
      "Power operation: base = 0.6490035756446026, power = 2, grad = 0.25\n",
      "Power operation: base = 0.37662277229040964, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41902991287512625, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1469977211292015, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894717767516523, 0.988330038986639, -0.9738363752780185, -0.9973060522529066]\n",
      "Layer: Layer 1, Input: [0.9894717767516523, 0.988330038986639, -0.9738363752780185, -0.9973060522529066], Output: [-0.9974351763354302, -0.5855230284395773, -0.9860989273726463, -0.9477657763178212]\n",
      "Layer: Layer 2, Input: [-0.9974351763354302, -0.5855230284395773, -0.9860989273726463, -0.9477657763178212], Output: [1.6511895442705127]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981682014067949, 0.979831222320975, 0.015582301193318188, -0.9325017832813587]\n",
      "Layer: Layer 1, Input: [0.9981682014067949, 0.979831222320975, 0.015582301193318188, -0.9325017832813587], Output: [-0.9961806016366023, 0.7136679125249232, -0.9644686658446661, -0.930836239500483]\n",
      "Layer: Layer 2, Input: [-0.9961806016366023, 0.7136679125249232, -0.9644686658446661, -0.930836239500483], Output: [-0.6264873483362772]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.931607909119946, 0.3585588307346014, 0.43393784495195803, -0.8766208241269915]\n",
      "Layer: Layer 1, Input: [0.931607909119946, 0.3585588307346014, 0.43393784495195803, -0.8766208241269915], Output: [-0.9804238409051176, 0.9941204425994056, -0.8945282816239848, -0.800054590998409]\n",
      "Layer: Layer 2, Input: [-0.9804238409051176, 0.9941204425994056, -0.8945282816239848, -0.800054590998409], Output: [-1.4191114835338086]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8851314490968242, 0.9864932528812601, -0.7962622515641872, -0.9253550624432242]\n",
      "Layer: Layer 1, Input: [0.8851314490968242, 0.9864932528812601, -0.7962622515641872, -0.9253550624432242], Output: [-0.9963253919533811, -0.13518543855715634, -0.9793241720831662, -0.9349410807220694]\n",
      "Layer: Layer 2, Input: [-0.9963253919533811, -0.13518543855715634, -0.9793241720831662, -0.9349410807220694], Output: [0.8533954212812604]\n",
      "Epoch 340/500, Loss: 0.19017671541282813, Accuracy: -0.5904182581867836\n",
      "Power operation: base = 0.6511895442705127, power = 2, grad = 0.25\n",
      "Power operation: base = 0.37351265166372283, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41911148353380856, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14660457871873955, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894754547044455, 0.9883535134461763, -0.9738419276436943, -0.9973079094336239]\n",
      "Layer: Layer 1, Input: [0.9894754547044455, 0.9883535134461763, -0.9738419276436943, -0.9973079094336239], Output: [-0.997440493642721, -0.5869198879150227, -0.9861822555767843, -0.9481036435908686]\n",
      "Layer: Layer 2, Input: [-0.997440493642721, -0.5869198879150227, -0.9861822555767843, -0.9481036435908686], Output: [1.6533608742924368]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981686619340019, 0.979871249519288, 0.015489531980581516, -0.9325397792138439]\n",
      "Layer: Layer 1, Input: [0.9981686619340019, 0.979871249519288, 0.015489531980581516, -0.9325397792138439], Output: [-0.9961885608536661, 0.7150634241968084, -0.9646680723801832, -0.931228830833943]\n",
      "Layer: Layer 2, Input: [-0.9961885608536661, 0.7150634241968084, -0.9646680723801832, -0.931228830833943], Output: [-0.6295879359050538]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9316230693656127, 0.3594311192255485, 0.43386518116466494, -0.8766854968037356]\n",
      "Layer: Layer 1, Input: [0.9316230693656127, 0.3594311192255485, 0.43386518116466494, -0.8766854968037356], Output: [-0.980496936923363, 0.9942094815586472, -0.8951246050662329, -0.8011495938188368]\n",
      "Layer: Layer 2, Input: [-0.980496936923363, 0.9942094815586472, -0.8951246050662329, -0.8011495938188368], Output: [-1.4192011703655147]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8851622877048396, 0.9865202313831686, -0.7962980048568526, -0.9253995072667154]\n",
      "Layer: Layer 1, Input: [0.8851622877048396, 0.9865202313831686, -0.7962980048568526, -0.9253995072667154], Output: [-0.9963333982627461, -0.135623388473806, -0.9794468649939353, -0.9353463887075458]\n",
      "Layer: Layer 2, Input: [-0.9963333982627461, -0.135623388473806, -0.9794468649939353, -0.9353463887075458], Output: [0.8537884966198535]\n",
      "Epoch 341/500, Loss: 0.190298238559939, Accuracy: -0.5891856121330443\n",
      "Power operation: base = 0.6533608742924368, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3704120640949462, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41920117036551474, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14621150338014655, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894791205524065, 0.9883768759912747, -0.9738474763132585, -0.9973097609624147]\n",
      "Layer: Layer 1, Input: [0.9894791205524065, 0.9883768759912747, -0.9738474763132585, -0.9973097609624147], Output: [-0.997445787341259, -0.5883141708911225, -0.9862649367893361, -0.9484388605783707]\n",
      "Layer: Layer 2, Input: [-0.997445787341259, -0.5883141708911225, -0.9862649367893361, -0.9484388605783707], Output: [1.6555176481837703]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998169121120533, 0.9799110882681197, 0.015396764549558715, -0.9325776766574171]\n",
      "Layer: Layer 1, Input: [0.998169121120533, 0.9799110882681197, 0.015396764549558715, -0.9325776766574171], Output: [-0.9961964851431329, 0.7164457965398797, -0.964866099175828, -0.9316189051855778]\n",
      "Layer: Layer 2, Input: [-0.9961964851431329, 0.7164457965398797, -0.964866099175828, -0.9316189051855778], Output: [-0.6326790112868004]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9316381875059906, 0.36030038717258717, 0.43379250491202764, -0.8767500107386544]\n",
      "Layer: Layer 1, Input: [0.9316381875059906, 0.36030038717258717, 0.43379250491202764, -0.8767500107386544], Output: [-0.9805695652675374, 0.9942967668070897, -0.895717118116614, -0.8022388881590301]\n",
      "Layer: Layer 2, Input: [-0.9805695652675374, 0.9942967668070897, -0.895717118116614, -0.8022388881590301], Output: [-1.419298778992589]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8851930329060502, 0.9865470821279012, -0.7963337461019522, -0.9254438305281419]\n",
      "Layer: Layer 1, Input: [0.8851930329060502, 0.9865470821279012, -0.7963337461019522, -0.9254438305281419], Output: [-0.9963413682510343, -0.1360678601560118, -0.9795686312449841, -0.9357487101130753]\n",
      "Layer: Layer 2, Input: [-0.9963413682510343, -0.1360678601560118, -0.9795686312449841, -0.9357487101130753], Output: [0.8541814916529837]\n",
      "Epoch 342/500, Loss: 0.19042564981771218, Accuracy: -0.5879559242365753\n",
      "Power operation: base = 0.6555176481837703, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3673209887131996, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41929877899258905, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14581850834701626, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894827743804766, 0.9884001278204602, -0.9738530213937038, -0.9973116068942358]\n",
      "Layer: Layer 1, Input: [0.9894827743804766, 0.9884001278204602, -0.9738530213937038, -0.9973116068942358], Output: [-0.9974510576960112, -0.5897057434378321, -0.9863469777499896, -0.9487714529095054]\n",
      "Layer: Layer 2, Input: [-0.9974510576960112, -0.5897057434378321, -0.9863469777499896, -0.9487714529095054], Output: [1.6576599488399753]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981695789788917, 0.9799507405881392, 0.01530399688611247, -0.9326154767704511]\n",
      "Layer: Layer 1, Input: [0.9981695789788917, 0.9799507405881392, 0.01530399688611247, -0.9326154767704511], Output: [-0.9962043749123395, 0.7178152211499401, -0.9650627590916163, -0.932006482823161]\n",
      "Layer: Layer 2, Input: [-0.9962043749123395, 0.7178152211499401, -0.9650627590916163, -0.932006482823161], Output: [-0.6357605945097724]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9316532639735994, 0.3611666654379586, 0.43371981455988873, -0.8768143679162707]\n",
      "Layer: Layer 1, Input: [0.9316532639735994, 0.3611666654379586, 0.43371981455988873, -0.8768143679162707], Output: [-0.9806417315649035, 0.9943823391979115, -0.8963058520322802, -0.8033225083550313]\n",
      "Layer: Layer 2, Input: [-0.9806417315649035, 0.9943823391979115, -0.8963058520322802, -0.8033225083550313], Output: [-1.4194041190088984]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8852236854749075, 0.9865738064854378, -0.7963694760432689, -0.9254880335571023]\n",
      "Layer: Layer 1, Input: [0.8852236854749075, 0.9865738064854378, -0.7963694760432689, -0.9254880335571023], Output: [-0.9963493023285407, -0.13651866110201238, -0.9796894802135817, -0.9361480720936685]\n",
      "Layer: Layer 2, Input: [-0.9963493023285407, -0.13651866110201238, -0.9796894802135817, -0.9361480720936685], Output: [0.8545743928392504]\n",
      "Epoch 343/500, Loss: 0.19055884376994406, Accuracy: -0.5867290804998508\n",
      "Power operation: base = 0.6576599488399753, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3642394054902276, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4194041190088984, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1454256071607496, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894864162719161, 0.9884232701055548, -0.9738585629883023, -0.9973134472827092]\n",
      "Layer: Layer 1, Input: [0.9894864162719161, 0.9884232701055548, -0.9738585629883023, -0.9973134472827092], Output: [-0.9974563049659331, -0.5910944751965929, -0.986428385063801, -0.9491014457401666]\n",
      "Layer: Layer 2, Input: [-0.9974563049659331, -0.5910944751965929, -0.986428385063801, -0.9491014457401666], Output: [1.659787859578544]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981700355212924, 0.9799902084546421, 0.01521122704737372, -0.9326531806801638]\n",
      "Layer: Layer 1, Input: [0.9981700355212924, 0.9799902084546421, 0.01521122704737372, -0.9326531806801638], Output: [-0.9962122305590897, 0.7191718861840994, -0.9652580647110792, -0.9323915835513233]\n",
      "Layer: Layer 2, Input: [-0.9962122305590897, 0.7191718861840994, -0.9652580647110792, -0.9323915835513233], Output: [-0.6388327047871831]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9316682991906009, 0.362029984128036, 0.4336471085316502, -0.8768785702663972]\n",
      "Layer: Layer 1, Input: [0.9316682991906009, 0.362029984128036, 0.4336471085316502, -0.8768785702663972], Output: [-0.9807134413185806, 0.994466238504987, -0.8968908373402276, -0.8044004875724079]\n",
      "Layer: Layer 2, Input: [-0.9807134413185806, 0.994466238504987, -0.8968908373402276, -0.8044004875724079], Output: [-1.4195170038771066]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8852542461688273, 0.9866004057950866, -0.7964051953981596, -0.9255321176485879]\n",
      "Layer: Layer 1, Input: [0.8852542461688273, 0.9866004057950866, -0.7964051953981596, -0.9255321176485879], Output: [-0.9963572008962136, -0.13697560188321461, -0.9798094210867715, -0.9365445012773294]\n",
      "Layer: Layer 2, Input: [-0.9963572008962136, -0.13697560188321461, -0.9798094210867715, -0.9365445012773294], Output: [0.8549671863393682]\n",
      "Epoch 344/500, Loss: 0.1906977170897306, Accuracy: -0.5855049723290993\n",
      "Power operation: base = 0.659787859578544, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3611672952128169, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41951700387710655, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1450328136606318, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894900463083561, 0.9884463039924247, -0.9738641011967031, -0.9973152821801621]\n",
      "Layer: Layer 1, Input: [0.9894900463083561, 0.9884463039924247, -0.9738641011967031, -0.9973152821801621], Output: [-0.9974615294041347, -0.5924802393099375, -0.9865091652056763, -0.949428863768245]\n",
      "Layer: Layer 2, Input: [-0.9974615294041347, -0.5924802393099375, -0.9865091652056763, -0.949428863768245], Output: [1.6619014641384]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981704907596688, 0.9800294937988229, 0.015118453159985628, -0.9326907894834795]\n",
      "Layer: Layer 1, Input: [0.9981704907596688, 0.9800294937988229, 0.015118453159985628, -0.9326907894834795], Output: [-0.9962200524719188, 0.7205159764445759, -0.9654520283512631, -0.9327742267288227]\n",
      "Layer: Layer 2, Input: [-0.9962200524719188, 0.7205159764445759, -0.9654520283512631, -0.9327742267288227], Output: [-0.6418953605439794]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9316832935690782, 0.3628903726140428, 0.43357438530688075, -0.8769426196656335]\n",
      "Layer: Layer 1, Input: [0.9316832935690782, 0.3628903726140428, 0.43357438530688075, -0.8769426196656335], Output: [-0.9807846999111235, 0.9945485034549827, -0.8974721038660656, -0.8054728578560113]\n",
      "Layer: Layer 2, Input: [-0.9807846999111235, 0.9945485034549827, -0.8974721038660656, -0.8054728578560113], Output: [-1.4196372508285826]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8852847157286788, 0.9866268813663439, -0.7964409048582232, -0.9255760840639504]\n",
      "Layer: Layer 1, Input: [0.8852847157286788, 0.9866268813663439, -0.7964409048582232, -0.9255760840639504], Output: [-0.9963650643459152, -0.1374384960803227, -0.9799284628678495, -0.9369380237829923]\n",
      "Layer: Layer 2, Input: [-0.9963650643459152, -0.1374384960803227, -0.9799284628678495, -0.9369380237829923], Output: [0.8553598580260635]\n",
      "Epoch 345/500, Loss: 0.19084216849542382, Accuracy: -0.5842834963969397\n",
      "Power operation: base = 0.6619014641384, power = 2, grad = 0.25\n",
      "Power operation: base = 0.35810463945602056, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4196372508285826, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1446401419739365, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894936645698474, 0.9884692306017062, -0.9738696361150274, -0.9973171116376625]\n",
      "Layer: Layer 1, Input: [0.9894936645698474, 0.9884692306017062, -0.9738696361150274, -0.9973171116376625], Output: [-0.9974667312580437, -0.593862912352741, -0.9865893245246826, -0.9497537312483807]\n",
      "Layer: Layer 2, Input: [-0.9974667312580437, -0.593862912352741, -0.9865893245246826, -0.9497537312483807], Output: [1.6640008466787695]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981709447056824, 0.980068598509008, 0.015025673418399329, -0.9327283042478636]\n",
      "Layer: Layer 1, Input: [0.9981709447056824, 0.980068598509008, 0.015025673418399329, -0.9327283042478636], Output: [-0.9962278410303524, 0.7218476734599089, -0.9656446620723532, -0.9331544312852382]\n",
      "Layer: Layer 2, Input: [-0.9962278410303524, 0.7218476734599089, -0.9656446620723532, -0.9331544312852382], Output: [-0.6449485794428664]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9316982475113074, 0.363747859552158, 0.4335016434199626, -0.8770065179388185]\n",
      "Layer: Layer 1, Input: [0.9316982475113074, 0.363747859552158, 0.4335016434199626, -0.8770065179388185], Output: [-0.980855512607983, 0.9946291717583808, -0.8980496807617121, -0.8065396501782056]\n",
      "Layer: Layer 2, Input: [-0.980855512607983, 0.9946291717583808, -0.8980496807617121, -0.8065396501782056], Output: [-1.4197646807659274]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8853150948792576, 0.986653234479728, -0.7964766050899529, -0.9256199340318391]\n",
      "Layer: Layer 1, Input: [0.8853150948792576, 0.986653234479728, -0.7964766050899529, -0.9256199340318391], Output: [-0.9963728930606764, -0.13790716022150779, -0.9800466143826012, -0.9373286652378441]\n",
      "Layer: Layer 2, Input: [-0.9963728930606764, -0.13790716022150779, -0.9800466143826012, -0.9373286652378441], Output: [0.8557523934939351]\n",
      "Epoch 346/500, Loss: 0.1909920987077527, Accuracy: -0.5830645545078954\n",
      "Power operation: base = 0.6640008466787695, power = 2, grad = 0.25\n",
      "Power operation: base = 0.35505142055713357, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41976468076592743, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14424760650606494, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894972711349092, 0.9884920510295073, -0.9738751678359613, -0.9973189357050548]\n",
      "Layer: Layer 1, Input: [0.9894972711349092, 0.9884920510295073, -0.9738751678359613, -0.9973189357050548], Output: [-0.9974719107695621, -0.5952423742650697, -0.9866688692481994, -0.9500760720062046]\n",
      "Layer: Layer 2, Input: [-0.9974719107695621, -0.5952423742650697, -0.9866688692481994, -0.9500760720062046], Output: [1.666086091777501]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981713973707285, 0.9801075244318498, 0.014932886083214383, -0.9327657260121326]\n",
      "Layer: Layer 1, Input: [0.9981713973707285, 0.9801075244318498, 0.014932886083214383, -0.9327657260121326], Output: [-0.9962355966051561, 0.7231671555636611, -0.9658359776869363, -0.9335322157371082]\n",
      "Layer: Layer 2, Input: [-0.9962355966051561, 0.7231671555636611, -0.9658359776869363, -0.9335322157371082], Output: [-0.6479923784096471]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9317131614100207, 0.36460247290302783, 0.4334288814587741, -0.8770702668604397]\n",
      "Layer: Layer 1, Input: [0.9317131614100207, 0.36460247290302783, 0.4334288814587741, -0.8770702668604397], Output: [-0.9809258845608533, 0.9947082801394713, -0.898623596532053, -0.8076008944856062]\n",
      "Layer: Layer 2, Input: [-0.9809258845608533, 0.9947082801394713, -0.898623596532053, -0.8076008944856062], Output: [-1.4198991181680611]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8853453843297453, 0.986679466387586, -0.7965122967353699, -0.9256636687491102]\n",
      "Layer: Layer 1, Input: [0.8853453843297453, 0.986679466387586, -0.7965122967353699, -0.9256636687491102], Output: [-0.9963806874149412, -0.13838141372257418, -0.9801638842853035, -0.9377164507940481]\n",
      "Layer: Layer 2, Input: [-0.9963806874149412, -0.13838141372257418, -0.9801638842853035, -0.9377164507940481], Output: [0.8561447780692681]\n",
      "Epoch 347/500, Loss: 0.19114741040804456, Accuracy: -0.581848053466647\n",
      "Power operation: base = 0.6660860917775011, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3520076215903529, power = 2, grad = 0.25\n",
      "Power operation: base = -0.41989911816806114, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14385522193073186, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895008660805753, 0.9885147663480891, -0.9738806964488449, -0.9973207544309957]\n",
      "Layer: Layer 1, Input: [0.9895008660805753, 0.9885147663480891, -0.9738806964488449, -0.9973207544309957], Output: [-0.9974770681752194, -0.5966185082866006, -0.9867478054859138, -0.950395909452085]\n",
      "Layer: Layer 2, Input: [-0.9974770681752194, -0.5966185082866006, -0.9867478054859138, -0.950395909452085], Output: [1.6681572844289043]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981718487659449, 0.9801462733734844, 0.014840089479563561, -0.9328030557872409]\n",
      "Layer: Layer 1, Input: [0.9981718487659449, 0.9801462733734844, 0.014840089479563561, -0.9328030557872409], Output: [-0.9962433195585765, 0.7244745979706771, -0.9660259867689134, -0.9339075982035299]\n",
      "Layer: Layer 2, Input: [-0.9962433195585765, 0.7244745979706771, -0.9660259867689134, -0.9339075982035299], Output: [-0.651026773657879]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9317280356486632, 0.3654542399507024, 0.4333560980634082, -0.8771338681560017]\n",
      "Layer: Layer 1, Input: [0.9317280356486632, 0.3654542399507024, 0.4333560980634082, -0.8771338681560017], Output: [-0.9809958208109106, 0.9947858643653507, -0.8991938790606019, -0.8086566197443636]\n",
      "Layer: Layer 2, Input: [-0.9809958208109106, 0.9947858643653507, -0.8991938790606019, -0.8086566197443636], Output: [-1.4200403909978636]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8853755847741557, 0.9867055783148763, -0.7965479804126389, -0.9257072893817117]\n",
      "Layer: Layer 1, Input: [0.8853755847741557, 0.9867055783148763, -0.7965479804126389, -0.9257072893817117], Output: [-0.996388447774804, -0.13886107882906862, -0.9802802810645006, -0.9381014051448936]\n",
      "Layer: Layer 2, Input: [-0.996388447774804, -0.13886107882906862, -0.9802802810645006, -0.9381014051448936], Output: [0.8565369968198251]\n",
      "Epoch 348/500, Loss: 0.19130800819753752, Accuracy: -0.5806339049490639\n",
      "Power operation: base = 0.6681572844289043, power = 2, grad = 0.25\n",
      "Power operation: base = 0.348973226342121, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4200403909978636, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1434630031801749, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895044494824401, 0.9885373776065248, -0.9738862220397594, -0.9973225678629872]\n",
      "Layer: Layer 1, Input: [0.9895044494824401, 0.9885373776065248, -0.9738862220397594, -0.9973225678629872], Output: [-0.99748220370632, -0.5979912008925528, -0.9868261392336664, -0.950713266594394]\n",
      "Layer: Layer 2, Input: [-0.99748220370632, -0.5979912008925528, -0.9868261392336664, -0.950713266594394], Output: [1.6702145100410206]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981722989022183, 0.9801848471006528, 0.014747281995543909, -0.9328402945570428]\n",
      "Layer: Layer 1, Input: [0.9981722989022183, 0.9801848471006528, 0.014747281995543909, -0.9328402945570428], Output: [-0.9962510102445764, 0.7257701728509925, -0.9662147006620803, -0.9342805964212305]\n",
      "Layer: Layer 2, Input: [-0.9962510102445764, 0.7257701728509925, -0.9662147006620803, -0.9342805964212305], Output: [-0.6540517807129183]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9317428706016405, 0.3663031873210176, 0.43328329192492543, -0.877197323503355]\n",
      "Layer: Layer 1, Input: [0.9317428706016405, 0.3663031873210176, 0.43328329192492543, -0.877197323503355], Output: [-0.9810653262919444, 0.9948619592739628, -0.8997605556341967, -0.8097068539840322]\n",
      "Layer: Layer 2, Input: [-0.9810653262919444, 0.9948619592739628, -0.8997605556341967, -0.8097068539840322], Output: [-1.4201883306123215]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8854056968917667, 0.9867315714599263, -0.7965836567166688, -0.9257507970655381]\n",
      "Layer: Layer 1, Input: [0.8854056968917667, 0.9867315714599263, -0.7965836567166688, -0.9257507970655381], Output: [-0.9963961744982411, -0.13934598056028724, -0.9803958130485624, -0.9384835525403818]\n",
      "Layer: Layer 2, Input: [-0.9963961744982411, -0.13934598056028724, -0.9803958130485624, -0.9384835525403818], Output: [0.8569290345646037]\n",
      "Epoch 349/500, Loss: 0.19147379855770352, Accuracy: -0.5794220253758202\n",
      "Power operation: base = 0.6702145100410206, power = 2, grad = 0.25\n",
      "Power operation: base = 0.34594821928708175, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4201883306123215, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14307096543539632, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895080214147014, 0.9885598858313394, -0.9738917446916128, -0.9973243760474088]\n",
      "Layer: Layer 1, Input: [0.9895080214147014, 0.9885598858313394, -0.9738917446916128, -0.9973243760474088], Output: [-0.9974873175890857, -0.5993603417310929, -0.9869038763771515, -0.9510281660523148]\n",
      "Layer: Layer 2, Input: [-0.9974873175890857, -0.5993603417310929, -0.9869038763771515, -0.9510281660523148], Output: [1.6722578544324218]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981727477901912, 0.9802232473417879, 0.01465446208068635, -0.9328774432790347]\n",
      "Layer: Layer 1, Input: [0.9981727477901912, 0.9802232473417879, 0.01465446208068635, -0.9328774432790347], Output: [-0.9962586690090617, 0.7270540494014501, -0.9664021304883798, -0.9346512277591342]\n",
      "Layer: Layer 2, Input: [-0.9962586690090617, 0.7270540494014501, -0.9664021304883798, -0.9346512277591342], Output: [-0.6570674144353807]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.93175766663456, 0.36714934099943786, 0.4332104617841399, -0.8772606345339845]\n",
      "Layer: Layer 1, Input: [0.93175766663456, 0.36714934099943786, 0.4332104617841399, -0.8772606345339845], Output: [-0.9811344058333894, 0.9949365988012189, -0.9003236529667614, -0.810751624340057]\n",
      "Layer: Layer 2, Input: [-0.9811344058333894, 0.9949365988012189, -0.9003236529667614, -0.810751624340057], Output: [-1.4203427716751547]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8854357213475411, 0.9867574469951672, -0.7966193262196953, -0.9257941929072623]\n",
      "Layer: Layer 1, Input: [0.8854357213475411, 0.9867574469951672, -0.7966193262196953, -0.9257941929072623], Output: [-0.9964038679353331, -0.13983594665511148, -0.9805104884110343, -0.9388629168022743]\n",
      "Layer: Layer 2, Input: [-0.9964038679353331, -0.13983594665511148, -0.9805104884110343, -0.9388629168022743], Output: [0.8573208758835378]\n",
      "Epoch 350/500, Loss: 0.19164468981157753, Accuracy: -0.5782123357886579\n",
      "Power operation: base = 0.6722578544324218, power = 2, grad = 0.25\n",
      "Power operation: base = 0.34293258556461925, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42034277167515466, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14267912411646222, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895115819502043, 0.9885822920271283, -0.9738972644842225, -0.9973261790295503]\n",
      "Layer: Layer 1, Input: [0.9895115819502043, 0.9885822920271283, -0.9738972644842225, -0.9973261790295503], Output: [-0.9974924100447948, -0.6007258235621924, -0.9869810226954812, -0.9513406300681958]\n",
      "Layer: Layer 2, Input: [-0.9974924100447948, -0.6007258235621924, -0.9869810226954812, -0.9513406300681958], Output: [1.6742874038285143]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981731954402688, 0.9802614757880678, 0.014561628244469743, -0.932914502885073]\n",
      "Layer: Layer 1, Input: [0.9981731954402688, 0.9802614757880678, 0.014561628244469743, -0.932914502885073], Output: [-0.9962662961901019, 0.7283263939151104, -0.9665882871558473, -0.9350195092324313]\n",
      "Layer: Layer 2, Input: [-0.9962662961901019, 0.7283263939151104, -0.9665882871558473, -0.9350195092324313], Output: [-0.6600736890440464]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.931772424104465, 0.3679927263483807, 0.43313760643043836, -0.8773238028342628]\n",
      "Layer: Layer 1, Input: [0.931772424104465, 0.3679927263483807, 0.43313760643043836, -0.8773238028342628], Output: [-0.9812030641632572, 0.9950098160072287, -0.9008831972221754, -0.8117909570949198]\n",
      "Layer: Layer 2, Input: [-0.9812030641632572, 0.9950098160072287, -0.9008831972221754, -0.8117909570949198], Output: [-1.4205035520718683]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8854656587925328, 0.9867832060678458, -0.7966549894718482, -0.9258374779851434]\n",
      "Layer: Layer 1, Input: [0.8854656587925328, 0.9867832060678458, -0.7966549894718482, -0.9258374779851434], Output: [-0.9964115284284809, -0.14033080751964547, -0.9806243151757863, -0.9392395213386127]\n",
      "Layer: Layer 2, Input: [-0.9964115284284809, -0.14033080751964547, -0.9806243151757863, -0.9392395213386127], Output: [0.8577125051271812]\n",
      "Epoch 351/500, Loss: 0.1918205920860406, Accuracy: -0.5770047617291549\n",
      "Power operation: base = 0.6742874038285143, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3399263109559536, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4205035520718683, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14228749487281878, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895151311604808, 0.9886045971771588, -0.9739027814943946, -0.9973279768536415]\n",
      "Layer: Layer 1, Input: [0.9895151311604808, 0.9886045971771588, -0.9739027814943946, -0.9973279768536415], Output: [-0.9974974812899171, -0.6020875421978662, -0.9870575838646137, -0.9516506805194763]\n",
      "Layer: Layer 2, Input: [-0.9974974812899171, -0.6020875421978662, -0.9870575838646137, -0.9516506805194763], Output: [1.6763032448573396]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981736418626252, 0.980299534094437, 0.014468779054872323, -0.9329514742820724]\n",
      "Layer: Layer 1, Input: [0.9981736418626252, 0.980299534094437, 0.014468779054872323, -0.9329514742820724], Output: [-0.9962738921181429, 0.7295873698485097, -0.9667731813662521, -0.9353854575161697]\n",
      "Layer: Layer 2, Input: [-0.9962738921181429, 0.7295873698485097, -0.9667731813662521, -0.9353854575161697], Output: [-0.6630706181382502]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9317871433600627, 0.3688333681240368, 0.4330647247006301, -0.8773868299466642]\n",
      "Layer: Layer 1, Input: [0.9317871433600627, 0.3688333681240368, 0.4330647247006301, -0.8773868299466642], Output: [-0.9812713059109757, 0.9950816431016763, -0.9014392140362701, -0.812824877717971]\n",
      "Layer: Layer 2, Input: [-0.9812713059109757, 0.9950816431016763, -0.9014392140362701, -0.812824877717971], Output: [-1.420670512827222]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8854955098642825, 0.9868088498007145, -0.7966906470017036, -0.9258806533498088]\n",
      "Layer: Layer 1, Input: [0.8854955098642825, 0.9868088498007145, -0.7966906470017036, -0.9258806533498088], Output: [-0.996419156312616, -0.14083039617659066, -0.9807373012219673, -0.9396133891577341]\n",
      "Layer: Layer 2, Input: [-0.996419156312616, -0.14083039617659066, -0.9807373012219673, -0.9396133891577341], Output: [0.8581039064263516]\n",
      "Epoch 352/500, Loss: 0.19200141727502174, Accuracy: -0.5757992331199597\n",
      "Power operation: base = 0.6763032448573396, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3369293818617498, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4206705128272219, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1418960935736484, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895186691157916, 0.9886268022439513, -0.9739082957960031, -0.9973297695628823]\n",
      "Layer: Layer 1, Input: [0.9895186691157916, 0.9886268022439513, -0.9739082957960031, -0.9973297695628823], Output: [-0.9975025315362432, -0.603445396443782, -0.9871335654606549, -0.9519583389301898]\n",
      "Layer: Layer 2, Input: [-0.9975025315362432, -0.603445396443782, -0.9871335654606549, -0.9519583389301898], Output: [1.6783054645449074]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981740870672103, 0.9803374238805966, 0.014375913136961984, -0.9329883583526836]\n",
      "Layer: Layer 1, Input: [0.9981740870672103, 0.9803374238805966, 0.014375913136961984, -0.9329883583526836], Output: [-0.9962814571162144, 0.7308371378868483, -0.9669568236224529, -0.935749088958382]\n",
      "Layer: Layer 2, Input: [-0.9962814571162144, 0.7308371378868483, -0.9669568236224529, -0.935749088958382], Output: [-0.6660582147197758]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9318018247419443, 0.3696712904927039, 0.43299181547782684, -0.877449717370947]\n",
      "Layer: Layer 1, Input: [0.9318018247419443, 0.3696712904927039, 0.43299181547782684, -0.877449717370947], Output: [-0.9813391356101354, 0.9951521114683716, -0.9019917285379953, -0.8138534109039884]\n",
      "Layer: Layer 2, Input: [-0.9813391356101354, 0.9951521114683716, -0.9019917285379953, -0.8138534109039884], Output: [-1.4208434980250453]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8855252751872013, 0.9868343792927005, -0.796726299316822, -0.9259237200250143]\n",
      "Layer: Layer 1, Input: [0.8855252751872013, 0.9868343792927005, -0.796726299316822, -0.9259237200250143], Output: [-0.9964267519154032, -0.1413345482163073, -0.9808494542887729, -0.9399845428817923]\n",
      "Layer: Layer 2, Input: [-0.9964267519154032, -0.1413345482163073, -0.9808494542887729, -0.9399845428817923], Output: [0.858495063701719]\n",
      "Epoch 353/500, Loss: 0.1921870790035907, Accuracy: -0.5745956841484579\n",
      "Power operation: base = 0.6783054645449074, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3339417852802242, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4208434980250453, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14150493629828098, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895221958851632, 0.9886489081698443, -0.9739138074600658, -0.9973315571994723]\n",
      "Layer: Layer 1, Input: [0.9895221958851632, 0.9886489081698443, -0.9739138074600658, -0.9973315571994723], Output: [-0.9975075609910118, -0.6047992880421833, -0.9872089729630353, -0.9522636264820642]\n",
      "Layer: Layer 2, Input: [-0.9975075609910118, -0.6047992880421833, -0.9872089729630353, -0.9522636264820642], Output: [1.6802941503100621]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981745310637549, 0.980375146731964, 0.014283029171524306, -0.9330251559559519]\n",
      "Layer: Layer 1, Input: [0.9981745310637549, 0.980375146731964, 0.014283029171524306, -0.9330251559559519], Output: [-0.996288991500131, 0.732075856007168, -0.9671392242354728, -0.9361104195927591]\n",
      "Layer: Layer 2, Input: [-0.996288991500131, 0.732075856007168, -0.9671392242354728, -0.9361104195927591], Output: [-0.6690364912142961]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9318164685827999, 0.3705065170466498, 0.43291887769035264, -0.8775124665653001]\n",
      "Layer: Layer 1, Input: [0.9318164685827999, 0.3705065170466498, 0.43291887769035264, -0.8775124665653001], Output: [-0.9814065577011498, 0.9952212516890059, -0.9025407653697726, -0.814876580610491]\n",
      "Layer: Layer 2, Input: [-0.9814065577011498, 0.9952212516890059, -0.9025407653697726, -0.814876580610491], Output: [-1.4210223547303813]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8855549553729425, 0.9868597956195546, -0.7967619469042705, -0.9259666790083834]\n",
      "Layer: Layer 1, Input: [0.8855549553729425, 0.9868597956195546, -0.7967619469042705, -0.9259666790083834], Output: [-0.9964343155574381, -0.14184310174953527, -0.980960781980035, -0.9403530047598039]\n",
      "Layer: Layer 2, Input: [-0.9964343155574381, -0.14184310174953527, -0.980960781980035, -0.9403530047598039], Output: [0.858885960673387]\n",
      "Epoch 354/500, Loss: 0.1923774925929055, Accuracy: -0.5733940531527604\n",
      "Power operation: base = 0.6802941503100621, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3309635087857039, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4210223547303813, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14111403932661304, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895257115364265, 0.9886709158775412, -0.9739193165548177, -0.9973333398046381]\n",
      "Layer: Layer 1, Input: [0.9895257115364265, 0.9886709158775412, -0.9739193165548177, -0.9973333398046381], Output: [-0.9975125698570316, -0.6061491216160922, -0.9872838117575694, -0.9525665640252302]\n",
      "Layer: Layer 2, Input: [-0.9975125698570316, -0.6061491216160922, -0.9872838117575694, -0.9525665640252302], Output: [1.6822693899588836]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981749738617774, 0.9804127042006041, 0.01419012589372606, -0.9330618679279566]\n",
      "Layer: Layer 1, Input: [0.9981749738617774, 0.9804127042006041, 0.01419012589372606, -0.9330618679279566], Output: [-0.9962964955786856, 0.7333036795395823, -0.9673203933313055, -0.936469465150888]\n",
      "Layer: Layer 2, Input: [-0.9962964955786856, 0.7333036795395823, -0.9673203933313055, -0.936469465150888], Output: [-0.6720054594923779]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9318310752076272, 0.3713390708195198, 0.43284591031068226, -0.8775750789474561]\n",
      "Layer: Layer 1, Input: [0.9318310752076272, 0.3713390708195198, 0.43284591031068226, -0.8775750789474561], Output: [-0.9814735765338302, 0.9952890935661431, -0.9030863487070775, -0.8158944100938414]\n",
      "Layer: Layer 2, Input: [-0.9814735765338302, 0.9952890935661431, -0.9030863487070775, -0.8158944100938414], Output: [-1.4212069329139]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8855845510207635, 0.9868850998344801, -0.7967975902311326, -0.9260095312721222]\n",
      "Layer: Layer 1, Input: [0.8855845510207635, 0.9868850998344801, -0.7967975902311326, -0.9260095312721222], Output: [-0.9964418475524375, -0.14235589736168405, -0.981071291768638, -0.9407187966802334]\n",
      "Layer: Layer 2, Input: [-0.9964418475524375, -0.14235589736168405, -0.981071291768638, -0.9407187966802334], Output: [0.8592765808703957]\n",
      "Epoch 355/500, Loss: 0.1925725750259836, Accuracy: -0.5721942825100101\n",
      "Power operation: base = 0.6822693899588836, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3279945405076221, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4212069329139001, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1407234191296043, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895292161362533, 0.9886928262706416, -0.9739248231457834, -0.9973351174186604]\n",
      "Layer: Layer 1, Input: [0.9895292161362533, 0.9886928262706416, -0.9739248231457834, -0.9973351174186604], Output: [-0.9975175583328004, -0.607494804614765, -0.9873580871393993, -0.9528671720885491]\n",
      "Layer: Layer 2, Input: [-0.9975175583328004, -0.607494804614765, -0.9873580871393993, -0.9528671720885491], Output: [1.6842312716786507]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981754154705899, 0.980450097806132, 0.014097202091813657, -0.9330984950824304]\n",
      "Layer: Layer 1, Input: [0.9981754154705899, 0.980450097806132, 0.014097202091813657, -0.9330984950824304], Output: [-0.9963039696538398, 0.7345207612266274, -0.9675003408574654, -0.9368262410740644]\n",
      "Layer: Layer 2, Input: [-0.9963039696538398, 0.7345207612266274, -0.9675003408574654, -0.9368262410740644], Output: [-0.6749651308900679]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9318456449339334, 0.37216897430130325, 0.4327729123544059, -0.8776375558957745]\n",
      "Layer: Layer 1, Input: [0.9318456449339334, 0.37216897430130325, 0.4327729123544059, -0.8776375558957745], Output: [-0.9815401963698785, 0.9953556661454714, -0.903628502277264, -0.8169069219441701]\n",
      "Layer: Layer 2, Input: [-0.9815401963698785, 0.9953556661454714, -0.903628502277264, -0.8169069219441701], Output: [-1.4213970853785587]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8856140627178757, 0.9869102929687429, -0.7968332297450036, -0.9260522777637169]\n",
      "Layer: Layer 1, Input: [0.8856140627178757, 0.9869102929687429, -0.7968332297450036, -0.9260522777637169], Output: [-0.9964493482074251, -0.14287277806869775, -0.9811809910007686, -0.941081940183132]\n",
      "Layer: Layer 2, Input: [-0.9964493482074251, -0.14287277806869775, -0.9811809910007686, -0.941081940183132], Output: [0.8596669076402152]\n",
      "Epoch 356/500, Loss: 0.19277224491427458, Accuracy: -0.5709963185269262\n",
      "Power operation: base = 0.6842312716786507, power = 2, grad = 0.25\n",
      "Power operation: base = 0.32503486910993207, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4213970853785587, power = 2, grad = 0.25\n",
      "Power operation: base = -0.14033309235978475, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895327097501907, 0.9887146402341555, -0.973930327295847, -0.9973368900809018]\n",
      "Layer: Layer 1, Input: [0.9895327097501907, 0.9887146402341555, -0.973930327295847, -0.9973368900809018], Output: [-0.9975225266126204, -0.6088362472603487, -0.9874318043158298, -0.9531654708895765]\n",
      "Layer: Layer 2, Input: [-0.9975225266126204, -0.6088362472603487, -0.9874318043158298, -0.9531654708895765], Output: [1.6861798840313629]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981758558993022, 0.9804873290365883, 0.01400425660584558, -0.9331350382113643]\n",
      "Layer: Layer 1, Input: [0.9981758558993022, 0.9804873290365883, 0.01400425660584558, -0.9331350382113643], Output: [-0.9963114140209053, 0.7357272512807884, -0.9676790765892866, -0.9371807625246928]\n",
      "Layer: Layer 2, Input: [-0.9963114140209053, 0.7357272512807884, -0.9676790765892866, -0.9371807625246928], Output: [-0.677915516229108]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9318601780719322, 0.37299624945287374, 0.4326998828792225, -0.8776998987502933]\n",
      "Layer: Layer 1, Input: [0.9318601780719322, 0.37299624945287374, 0.4326998828792225, -0.8776998987502933], Output: [-0.9816064213853027, 0.9954209977373426, -0.9041672493776691, -0.8179141381191469]\n",
      "Layer: Layer 2, Input: [-0.9816064213853027, 0.9954209977373426, -0.9041672493776691, -0.8179141381191469], Output: [-1.4215926676884507]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.885643491039785, 0.9869353760322629, -0.7968688658744738, -0.9260949194066078]\n",
      "Layer: Layer 1, Input: [0.885643491039785, 0.9869353760322629, -0.7968688658744738, -0.9260949194066078], Output: [-0.9964568178229108, -0.14339358927438914, -0.9812898869000061, -0.9414424564718452]\n",
      "Layer: Layer 2, Input: [-0.9964568178229108, -0.14339358927438914, -0.9812898869000061, -0.9414424564718452], Output: [0.8600569241581546]\n",
      "Epoch 357/500, Loss: 0.1929764224649994, Accuracy: -0.569800111332551\n",
      "Power operation: base = 0.6861798840313629, power = 2, grad = 0.25\n",
      "Power operation: base = 0.32208448377089205, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4215926676884507, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1399430758418454, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895361924426962, 0.9887363586350026, -0.9739358290653216, -0.9973386578298306]\n",
      "Layer: Layer 1, Input: [0.9895361924426962, 0.9887363586350026, -0.9739358290653216, -0.9973386578298306], Output: [-0.9975274748867096, -0.6101733624957135, -0.987504968409056, -0.9534614803441706]\n",
      "Layer: Layer 2, Input: [-0.9975274748867096, -0.6101733624957135, -0.987504968409056, -0.9534614803441706], Output: [1.6881153159468338]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981762951568294, 0.9805243993492895, 0.013911288326456698, -0.9331714980855919]\n",
      "Layer: Layer 1, Input: [0.9981762951568294, 0.9805243993492895, 0.013911288326456698, -0.9331714980855919], Output: [-0.9963188289687223, 0.7369232974402635, -0.9678566101359826, -0.9375330443972872]\n",
      "Layer: Layer 2, Input: [-0.9963188289687223, 0.7369232974402635, -0.9678566101359826, -0.9375330443972872], Output: [-0.6808566258367552]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.931874674924735, 0.37382091772011716, 0.4326268209839565, -0.8777621088137498]\n",
      "Layer: Layer 1, Input: [0.931874674924735, 0.37382091772011716, 0.4326268209839565, -0.8777621088137498], Output: [-0.981672255672755, 0.9954851159376251, -0.9047026128930178, -0.8189160799766356]\n",
      "Layer: Layer 2, Input: [-0.981672255672755, 0.9954851159376251, -0.9047026128930178, -0.8189160799766356], Output: [-1.4217935380997986]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8856728365506222, 0.9869603500141887, -0.7969044990295985, -0.9261374571008468]\n",
      "Layer: Layer 1, Input: [0.8856728365506222, 0.9869603500141887, -0.7969044990295985, -0.9261374571008468], Output: [-0.9964642566930649, -0.14391817872926038, -0.9813979865712583, -0.9418003664243024]\n",
      "Layer: Layer 2, Input: [-0.9964642566930649, -0.14391817872926038, -0.9813979865712583, -0.9418003664243024], Output: [0.8604466134367863]\n",
      "Epoch 358/500, Loss: 0.19318502944922997, Accuracy: -0.5686056147730909\n",
      "Power operation: base = 0.6881153159468338, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3191433741632448, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4217935380997986, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1395533865632137, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895396642771708, 0.9887579823224977, -0.9739413285120129, -0.9973404207030466]\n",
      "Layer: Layer 1, Input: [0.9895396642771708, 0.9887579823224977, -0.9739413285120129, -0.9973404207030466], Output: [-0.9975324033413107, -0.611506065933424, -0.9875775844587915, -0.9537552200757586]\n",
      "Layer: Layer 2, Input: [-0.9975324033413107, -0.611506065933424, -0.9875775844587915, -0.9537552200757586], Output: [1.6900376567153712]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981767332518953, 0.9805613101716512, 0.01381829619365485, -0.9332078754553602]\n",
      "Layer: Layer 1, Input: [0.9981767332518953, 0.9805613101716512, 0.01381829619365485, -0.9332078754553602], Output: [-0.9963262147798321, 0.7381090450230212, -0.9680329509464753, -0.9378831013290838]\n",
      "Layer: Layer 2, Input: [-0.9963262147798321, 0.7381090450230212, -0.9680329509464753, -0.9378831013290838], Output: [-0.6837884695652781]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9318891357885364, 0.37464300004766016, 0.43255372580760176, -0.8778241873525757]\n",
      "Layer: Layer 1, Input: [0.9318891357885364, 0.37464300004766016, 0.43255372580760176, -0.8778241873525757], Output: [-0.9817377032437979, 0.9955480476478954, -0.9052346153121524, -0.8199127683062567]\n",
      "Layer: Layer 2, Input: [-0.9817377032437979, 0.9955480476478954, -0.9052346153121524, -0.8199127683062567], Output: [-1.4219995574940616]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8857020998034637, 0.9869852158834538, -0.7969401296023558, -0.9261798917237344]\n",
      "Layer: Layer 1, Input: [0.8857020998034637, 0.9869852158834538, -0.7969401296023558, -0.9261798917237344], Output: [-0.9964716651058871, -0.14444639649070523, -0.9815052970045502, -0.942155690603902]\n",
      "Layer: Layer 2, Input: [-0.9964716651058871, -0.14444639649070523, -0.9815052970045502, -0.942155690603902], Output: [0.8608359583352545]\n",
      "Epoch 359/500, Loss: 0.1933979891706901, Accuracy: -0.5674127863089002\n",
      "Power operation: base = 0.6900376567153712, power = 2, grad = 0.25\n",
      "Power operation: base = 0.31621153043472194, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4219995574940616, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1391640416647455, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895431253159906, 0.9887795121288193, -0.9739468256912871, -0.9973421787373062]\n",
      "Layer: Layer 1, Input: [0.9895431253159906, 0.9887795121288193, -0.9739468256912871, -0.9973421787373062], Output: [-0.9975373121587963, -0.6128342758058134, -0.9876496574247953, -0.9540467094242732]\n",
      "Layer: Layer 2, Input: [-0.9975373121587963, -0.6128342758058134, -0.9876496574247953, -0.9540467094242732], Output: [1.69194699598006]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981771701930388, 0.9805980629019885, 0.013725279195647883, -0.933244171050882]\n",
      "Layer: Layer 1, Input: [0.9981771701930388, 0.9805980629019885, 0.013725279195647883, -0.933244171050882], Output: [-0.9963335717306437, 0.7392846369792115, -0.9682081083150009, -0.9382309477102794]\n",
      "Layer: Layer 2, Input: [-0.9963335717306437, 0.7392846369792115, -0.9682081083150009, -0.9382309477102794], Output: [-0.6867110568111086]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.931903560952795, 0.37546251689221233, 0.4324805965283875, -0.8778861355978604]\n",
      "Layer: Layer 1, Input: [0.931903560952795, 0.37546251689221233, 0.4324805965283875, -0.8778861355978604], Output: [-0.9818027680310994, 0.995609819094989, -0.9057632787441144, -0.8209042233598859]\n",
      "Layer: Layer 2, Input: [-0.9818027680310994, 0.995609819094989, -0.9057632787441144, -0.8209042233598859], Output: [-1.422210589313103]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8857312813406422, 0.9870099745893174, -0.7969757579670933, -0.9262222241304386]\n",
      "Layer: Layer 1, Input: [0.8857312813406422, 0.9870099745893174, -0.7969757579670933, -0.9262222241304386], Output: [-0.9964790433433709, -0.14497809488458394, -0.9816118250786688, -0.9425084492700055]\n",
      "Layer: Layer 2, Input: [-0.9964790433433709, -0.14497809488458394, -0.9816118250786688, -0.9425084492700055], Output: [0.8612249415685804]\n",
      "Epoch 360/500, Loss: 0.19361522643525078, Accuracy: -0.5662215869134739\n",
      "Power operation: base = 0.6919469959800599, power = 2, grad = 0.25\n",
      "Power operation: base = 0.31328894318889144, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42221058931310296, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13877505843141957, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895465756205388, 0.9888009488694668, -0.9739523206561311, -0.9973439319685444]\n",
      "Layer: Layer 1, Input: [0.9895465756205388, 0.9888009488694668, -0.9739523206561311, -0.9973439319685444], Output: [-0.9975422015177707, -0.6141579129161222, -0.9877211921893081, -0.9543359674547669]\n",
      "Layer: Layer 2, Input: [-0.9975422015177707, -0.6141579129161222, -0.9877211921893081, -0.9543359674547669], Output: [1.693843423728631]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981776059886179, 0.9806346589102922, 0.013632236367700775, -0.9332803855828734]\n",
      "Layer: Layer 1, Input: [0.9981776059886179, 0.9806346589102922, 0.013632236367700775, -0.9332803855828734], Output: [-0.9963409000915967, 0.7404502139419795, -0.9683820913865026, -0.9385765976939021]\n",
      "Layer: Layer 2, Input: [-0.9963409000915967, 0.7404502139419795, -0.9683820913865026, -0.9385765976939021], Output: [-0.6896243965336843]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9319179507004088, 0.37627948823553564, 0.43240743236287, -0.8779479547462917]\n",
      "Layer: Layer 1, Input: [0.9319179507004088, 0.37627948823553564, 0.43240743236287, -0.8779479547462917], Output: [-0.9818674538905596, 0.995670455849937, -0.9062886249335966, -0.8218904648811215]\n",
      "Layer: Layer 2, Input: [-0.9818674538905596, 0.995670455849937, -0.9062886249335966, -0.8218904648811215], Output: [-1.4224264994963667]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8857603816940492, 0.9870346270618886, -0.7970113844809623, -0.9262644551545975]\n",
      "Layer: Layer 1, Input: [0.8857603816940492, 0.9870346270618886, -0.7970113844809623, -0.9262644551545975], Output: [-0.9964863916816615, -0.14551312846811817, -0.9817175775646719, -0.9428586623880526]\n",
      "Layer: Layer 2, Input: [-0.9964863916816615, -0.14551312846811817, -0.9817175775646719, -0.9428586623880526], Output: [0.8616135457168994]\n",
      "Epoch 361/500, Loss: 0.19383666752108772, Accuracy: -0.565031980974414\n",
      "Power operation: base = 0.6938434237286311, power = 2, grad = 0.25\n",
      "Power operation: base = 0.31037560346631565, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4224264994963667, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1383864542831006, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895500152512353, 0.988822293343703, -0.9739578134572162, -0.9973456804318978]\n",
      "Layer: Layer 1, Input: [0.9895500152512353, 0.988822293343703, -0.9739578134572162, -0.9973456804318978], Output: [-0.9975470715931691, -0.6154769005906862, -0.9877921935593951, -0.9546230129657203]\n",
      "Layer: Layer 2, Input: [-0.9975470715931691, -0.6154769005906862, -0.9877921935593951, -0.9546230129657203], Output: [1.6957270302849627]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981780406468157, 0.9806710995389817, 0.013539166791019863, -0.9333165197430772]\n",
      "Layer: Layer 1, Input: [0.9981780406468157, 0.9806710995389817, 0.013539166791019863, -0.9333165197430772], Output: [-0.9963482001273176, 0.7416059142767317, -0.9685549091618153, -0.9389200652053317]\n",
      "Layer: Layer 2, Input: [-0.9963482001273176, 0.7416059142767317, -0.9685549091618153, -0.9389200652053317], Output: [-0.6925284972739858]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.931932305307886, 0.37709393359705046, 0.4323342325650442, -0.8780096459610666]\n",
      "Layer: Layer 1, Input: [0.931932305307886, 0.37709393359705046, 0.4323342325650442, -0.8780096459610666], Output: [-0.9819317646033725, 0.995729982846306, -0.9068106752757924, -0.8228715121337403]\n",
      "Layer: Layer 2, Input: [-0.9819317646033725, 0.995729982846306, -0.9068106752757924, -0.8228715121337403], Output: [-1.42264715642004]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8857894013854286, 0.9870591742126352, -0.797047009484342, -0.9263065856089021]\n",
      "Layer: Layer 1, Input: [0.8857894013854286, 0.9870591742126352, -0.797047009484342, -0.9263065856089021], Output: [-0.9964937103912118, -0.14605135399405503, -0.9818225611292646, -0.9432063496393108]\n",
      "Layer: Layer 2, Input: [-0.9964937103912118, -0.14605135399405503, -0.9818225611292646, -0.9432063496393108], Output: [0.8620017532346411]\n",
      "Epoch 362/500, Loss: 0.19406224014949636, Accuracy: -0.5638439361963759\n",
      "Power operation: base = 0.6957270302849627, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3074715027260142, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42264715642004, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13799824676535888, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895534442675665, 0.9888435463349831, -0.9739633041429563, -0.9973474241617277]\n",
      "Layer: Layer 1, Input: [0.9895534442675665, 0.9888435463349831, -0.9739633041429563, -0.9973474241617277], Output: [-0.9975519225563538, -0.6167911646321236, -0.9878626662692026, -0.9549078644970495]\n",
      "Layer: Layer 2, Input: [-0.9975519225563538, -0.6167911646321236, -0.9878626662692026, -0.9549078644970495], Output: [1.6975979063002171]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981784741756439, 0.9807073861036363, 0.01344606959166614, -0.9333525742047699]\n",
      "Layer: Layer 1, Input: [0.9981784741756439, 0.9807073861036363, 0.01344606959166614, -0.9333525742047699], Output: [-0.9963554720967744, 0.742751874128918, -0.9687265705026523, -0.939261363951475]\n",
      "Layer: Layer 2, Input: [-0.9963554720967744, 0.742751874128918, -0.9687265705026523, -0.939261363951475], Output: [-0.6954233671727845]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9319466250455098, 0.37790587204609377, 0.432260996425479, -0.8780712103727795]\n",
      "Layer: Layer 1, Input: [0.9319466250455098, 0.37790587204609377, 0.432260996425479, -0.8780712103727795], Output: [-0.9819957038780229, 0.9957884243979661, -0.9073294508306603, -0.8238473839291739]\n",
      "Layer: Layer 2, Input: [-0.9819957038780229, 0.9957884243979661, -0.9073294508306603, -0.8238473839291739], Output: [-1.42287243083813]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8858183409266609, 0.9870836169348782, -0.7970826333012518, -0.9263486162856667]\n",
      "Layer: Layer 1, Input: [0.8858183409266609, 0.9870836169348782, -0.7970826333012518, -0.9263486162856667], Output: [-0.9965009997369311, -0.14659263037606776, -0.9819267823380479, -0.9435515304302704]\n",
      "Layer: Layer 2, Input: [-0.9965009997369311, -0.14659263037606776, -0.9819267823380479, -0.9435515304302704], Output: [0.8623895464596645]\n",
      "Epoch 363/500, Loss: 0.1942918734563342, Accuracy: -0.5626574235058981\n",
      "Power operation: base = 0.6975979063002171, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3045766328272155, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42287243083813, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13761045354033552, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895568627281133, 0.9888647086113725, -0.9739687927595663, -0.997349163191641]\n",
      "Layer: Layer 1, Input: [0.9895568627281133, 0.9888647086113725, -0.9739687927595663, -0.997349163191641], Output: [-0.9975567545752076, -0.6181006332734924, -0.987932614982131, -0.9551905403378256]\n",
      "Layer: Layer 2, Input: [-0.9975567545752076, -0.6181006332734924, -0.987932614982131, -0.9551905403378256], Output: [1.699456142743589]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998178906582948, 0.9807435198937055, 0.013352943939495742, -0.933388549623257]\n",
      "Layer: Layer 1, Input: [0.998178906582948, 0.9807435198937055, 0.013352943939495742, -0.933388549623257], Output: [-0.9963627162534239, 0.7438882274703671, -0.9688970841364017, -0.9396005074296098]\n",
      "Layer: Layer 2, Input: [-0.9963627162534239, 0.7438882274703671, -0.9688970841364017, -0.9396005074296098], Output: [-0.6983090139886308]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9319609101775015, 0.3787153222138371, 0.43218772327047367, -0.8781326490802855]\n",
      "Layer: Layer 1, Input: [0.9319609101775015, 0.3787153222138371, 0.43218772327047367, -0.8781326490802855], Output: [-0.9820592753522237, 0.9958458042163036, -0.9078449723366275, -0.8248180986530278]\n",
      "Layer: Layer 2, Input: [-0.9820592753522237, 0.9958458042163036, -0.9078449723366275, -0.8248180986530278], Output: [-1.4231021958254368]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8858472008200401, 0.9871079561042707, -0.7971182562397555, -0.9263905479573787]\n",
      "Layer: Layer 1, Input: [0.8858472008200401, 0.9871079561042707, -0.7971182562397555, -0.9263905479573787], Output: [-0.9965082599783299, -0.14713681865533978, -0.9820302476586458, -0.9438942239016965]\n",
      "Layer: Layer 2, Input: [-0.9965082599783299, -0.14713681865533978, -0.9820302476586458, -0.9438942239016965], Output: [0.8627769076223064]\n",
      "Epoch 364/500, Loss: 0.19452549796406388, Accuracy: -0.5614724169580887\n",
      "Power operation: base = 0.699456142743589, power = 2, grad = 0.25\n",
      "Power operation: base = 0.30169098601136923, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42310219582543684, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1372230923776936, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895602706905787, 0.9888857809259521, -0.9739742793511196, -0.9973508975545107]\n",
      "Layer: Layer 1, Input: [0.9895602706905787, 0.9888857809259521, -0.9739742793511196, -0.9973508975545107], Output: [-0.9975615678142244, -0.6194052371334084, -0.9880020442929263, -0.9554710585337161]\n",
      "Layer: Layer 2, Input: [-0.9975615678142244, -0.6194052371334084, -0.9880020442929263, -0.9554710585337161], Output: [1.7013018308927448]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981793378764117, 0.9807795021731976, 0.013259789047124184, -0.933424446636352]\n",
      "Layer: Layer 1, Input: [0.9981793378764117, 0.9807795021731976, 0.013259789047124184, -0.933424446636352], Output: [-0.9963699328453555, 0.7450151061442258, -0.9690664586607346, -0.9399375089359064]\n",
      "Layer: Layer 2, Input: [-0.9963699328453555, 0.7450151061442258, -0.9690664586607346, -0.9399375089359064], Output: [-0.7011854451155566]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9319751609621755, 0.3795223023048779, 0.4321144124612332, -0.8781939631515393]\n",
      "Layer: Layer 1, Input: [0.9319751609621755, 0.3795223023048779, 0.4321144124612332, -0.8781939631515393], Output: [-0.982122482594794, 0.9959021454269004, -0.9083572602237486, -0.8257836742906696]\n",
      "Layer: Layer 2, Input: [-0.982122482594794, 0.9959021454269004, -0.9083572602237486, -0.8257836742906696], Output: [-1.423336326722347]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8858759815585419, 0.9871321925792641, -0.7971538785923515, -0.9264323813772368]\n",
      "Layer: Layer 1, Input: [0.8858759815585419, 0.9871321925792641, -0.7971538785923515, -0.9264323813772368], Output: [-0.9965154913696627, -0.14768378196829962, -0.9821329634637159, -0.9442344489373503]\n",
      "Layer: Layer 2, Input: [-0.9965154913696627, -0.14768378196829962, -0.9821329634637159, -0.9442344489373503], Output: [0.8631638188544102]\n",
      "Epoch 365/500, Loss: 0.19476304555439558, Accuracy: -0.5602888936451249\n",
      "Power operation: base = 0.7013018308927448, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2988145548844434, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4233363267223469, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13683618114558982, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989563668211815, 0.9889067640172106, -0.9739797639596023, -0.9973526272824969]\n",
      "Layer: Layer 1, Input: [0.989563668211815, 0.9889067640172106, -0.9739797639596023, -0.9973526272824969], Output: [-0.9975663624345967, -0.6207049091720608, -0.988070958729695, -0.9557494368941548]\n",
      "Layer: Layer 2, Input: [-0.9975663624345967, -0.6207049091720608, -0.988070958729695, -0.9557494368941548], Output: [1.7031350623238817]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981797680635611, 0.9808153341813501, 0.013166604168918176, -0.933460265864845]\n",
      "Layer: Layer 1, Input: [0.9981797680635611, 0.9808153341813501, 0.013166604168918176, -0.933460265864845], Output: [-0.9963771221154323, 0.7461326399085518, -0.9692347025480413, -0.9402723815736367]\n",
      "Layer: Layer 2, Input: [-0.9963771221154323, 0.7461326399085518, -0.9692347025480413, -0.9402723815736367], Output: [-0.7040526676005356]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9319893776520932, 0.3803268301085122, 0.43204106339306514, -0.8782551536244131]\n",
      "Layer: Layer 1, Input: [0.9319893776520932, 0.3803268301085122, 0.43204106339306514, -0.8782551536244131], Output: [-0.9821853291074786, 0.9959574705856956, -0.9088663346263439, -0.8267441284519125]\n",
      "Layer: Layer 2, Input: [-0.9821853291074786, 0.9959574705856956, -0.9088663346263439, -0.8267441284519125], Output: [-1.4235747010814364]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8859046836260847, 0.98715632720156, -0.797189500636358, -0.9264741172796723]\n",
      "Layer: Layer 1, Input: [0.8859046836260847, 0.98715632720156, -0.797189500636358, -0.9264741172796723], Output: [-0.9965226941600637, -0.14823338551546755, -0.9822349360338435, -0.9445722241723886]\n",
      "Layer: Layer 2, Input: [-0.9965226941600637, -0.14823338551546755, -0.9822349360338435, -0.9445722241723886], Output: [0.863550262198256]\n",
      "Epoch 366/500, Loss: 0.19500444944149023, Accuracy: -0.5591068336065264\n",
      "Power operation: base = 0.7031350623238817, power = 2, grad = 0.25\n",
      "Power operation: base = 0.29594733239946436, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42357470108143636, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13644973780174396, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895670553478492, 0.9889276586094268, -0.9739852466249681, -0.9973543524070656]\n",
      "Layer: Layer 1, Input: [0.9895670553478492, 0.9889276586094268, -0.9739852466249681, -0.9973543524070656], Output: [-0.9975711385943024, -0.6219995846481318, -0.9881393627558427, -0.9560256929992548]\n",
      "Layer: Layer 2, Input: [-0.9975711385943024, -0.6219995846481318, -0.9881393627558427, -0.9560256929992548], Output: [1.7049559289015077]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981801971517692, 0.9808510171332789, 0.013073388600011265, -0.9334960079129556]\n",
      "Layer: Layer 1, Input: [0.9981801971517692, 0.9808510171332789, 0.013073388600011265, -0.9334960079129556], Output: [-0.9963842843014267, 0.747240956478609, -0.9694018241496909, -0.9406051382610792]\n",
      "Layer: Layer 2, Input: [-0.9963842843014267, 0.747240956478609, -0.9694018241496909, -0.9406051382610792], Output: [-0.7069106881607023]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9320035604942104, 0.3811289230097018, 0.43196767549459514, -0.8783162215074892]\n",
      "Layer: Layer 1, Input: [0.9320035604942104, 0.3811289230097018, 0.43196767549459514, -0.8783162215074892], Output: [-0.9822478183267139, 0.996011801694651, -0.9093722153951297, -0.827699478394812]\n",
      "Layer: Layer 2, Input: [-0.9822478183267139, 0.996011801694651, -0.9093722153951297, -0.827699478394812], Output: [-1.423817198615815]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8859333074977825, 0.9871803607965496, -0.7972251226342851, -0.9265157563808558]\n",
      "Layer: Layer 1, Input: [0.8859333074977825, 0.9871803607965496, -0.7972251226342851, -0.9265157563808558], Output: [-0.9965298685936805, -0.1487854965313586, -0.98233617156033, -0.9449075680014549]\n",
      "Layer: Layer 2, Input: [-0.9965298685936805, -0.1487854965313586, -0.98233617156033, -0.9449075680014549], Output: [0.8639362196154368]\n",
      "Epoch 367/500, Loss: 0.19524964414572915, Accuracy: -0.5579262197411836\n",
      "Power operation: base = 0.7049559289015077, power = 2, grad = 0.25\n",
      "Power operation: base = 0.29308931183929765, power = 2, grad = 0.25\n",
      "Power operation: base = -0.423817198615815, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13606378038456324, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989570432153908, 0.9889484654130409, -0.9739907273851902, -0.9973560729590093]\n",
      "Layer: Layer 1, Input: [0.989570432153908, 0.9889484654130409, -0.9739907273851902, -0.9973560729590093], Output: [-0.9975758964481856, -0.6232892010765596, -0.9882072607719415, -0.9562998442064655]\n",
      "Layer: Layer 2, Input: [-0.9975758964481856, -0.6232892010765596, -0.9882072607719415, -0.9562998442064655], Output: [1.7067645227678598]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981806251482596, 0.9808865522206102, 0.012980141675340425, -0.933531673368776]\n",
      "Layer: Layer 1, Input: [0.9981806251482596, 0.9808865522206102, 0.012980141675340425, -0.933531673368776], Output: [-0.9963914196361515, 0.7483401815678936, -0.9695678317001298, -0.9409357917391331]\n",
      "Layer: Layer 2, Input: [-0.9963914196361515, 0.7483401815678936, -0.9695678317001298, -0.9409357917391331], Output: [-0.7097595132003258]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9320177097300224, 0.38192859799974355, 0.43189424822699957, -0.8783771677808362]\n",
      "Layer: Layer 1, Input: [0.9320177097300224, 0.38192859799974355, 0.43189424822699957, -0.8783771677808362], Output: [-0.9823099536253415, 0.9960651602169335, -0.909874922108866, -0.8286497410486071]\n",
      "Layer: Layer 2, Input: [-0.9823099536253415, 0.9960651602169335, -0.909874922108866, -0.8286497410486071], Output: [-1.4240637011491715]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8859618536401913, 0.9872042941737399, -0.7972607448341998, -0.9265572993791915]\n",
      "Layer: Layer 1, Input: [0.8859618536401913, 0.9872042941737399, -0.7972607448341998, -0.9265572993791915], Output: [-0.9965370149098032, -0.149339984255426, -0.9824366761478758, -0.9452404985864692]\n",
      "Layer: Layer 2, Input: [-0.9965370149098032, -0.149339984255426, -0.9824366761478758, -0.9452404985864692], Output: [0.8643216729956711]\n",
      "Epoch 368/500, Loss: 0.195498565468005, Accuracy: -0.5567470377210344\n",
      "Power operation: base = 0.7067645227678598, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2902404867996742, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42406370114917147, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1356783270043289, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895737986844426, 0.9889691851250145, -0.9739962062763128, -0.9973577889684642]\n",
      "Layer: Layer 1, Input: [0.9895737986844426, 0.9889691851250145, -0.9739962062763128, -0.9973577889684642], Output: [-0.9975806361480397, -0.6245736981871518, -0.9882746571175296, -0.9565719076569917]\n",
      "Layer: Layer 2, Input: [-0.9975806361480397, -0.6245736981871518, -0.9882746571175296, -0.9565719076569917], Output: [1.708560936332069]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981810520601103, 0.9809219406120935, 0.012886862768710214, -0.9335672628047011]\n",
      "Layer: Layer 1, Input: [0.9981810520601103, 0.9809219406120935, 0.012886862768710214, -0.9335672628047011], Output: [-0.9963985283475897, 0.7494304389279548, -0.9697327333208197, -0.9412643545786454]\n",
      "Layer: Layer 2, Input: [-0.9963985283475897, 0.7494304389279548, -0.9697327333208197, -0.9412643545786454], Output: [-0.7125991488275538]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9320318255957036, 0.3827258716866497, 0.43182078108325844, -0.8784379933967591]\n",
      "Layer: Layer 1, Input: [0.9320318255957036, 0.3827258716866497, 0.43182078108325844, -0.8784379933967591], Output: [-0.9823717383142672, 0.9961175670916341, -0.9103744740855316, -0.8295949330358222]\n",
      "Layer: Layer 2, Input: [-0.9823717383142672, 0.9961175670916341, -0.9103744740855316, -0.8295949330358222], Output: [-1.4243140925674829]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.885990322511547, 0.9872281281271684, -0.7972963674700811, -0.9265987469557951]\n",
      "Layer: Layer 1, Input: [0.885990322511547, 0.9872281281271684, -0.7972963674700811, -0.9265987469557951], Output: [-0.9965441333429897, -0.1498967199039798, -0.9825364558171592, -0.9455710338641281]\n",
      "Layer: Layer 2, Input: [-0.9965441333429897, -0.1498967199039798, -0.9825364558171592, -0.9455710338641281], Output: [0.8647066041655123]\n",
      "Epoch 369/500, Loss: 0.1957511504645547, Accuracy: -0.5555692759064859\n",
      "Power operation: base = 0.7085609363320691, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2874008511724462, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42431409256748287, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13529339583448774, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895771549931519, 0.9889898184291809, -0.9740016833325001, -0.9973595004649283]\n",
      "Layer: Layer 1, Input: [0.9895771549931519, 0.9889898184291809, -0.9740016833325001, -0.9973595004649283], Output: [-0.997585357842684, -0.6258530178839886, -0.9883415560728411, -0.956841900281974]\n",
      "Layer: Layer 2, Input: [-0.997585357842684, -0.6258530178839886, -0.9883415560728411, -0.956841900281974], Output: [1.7103452622589934]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981814778942583, 0.9809571834541986, 0.012793551291873392, -0.9336027767778459]\n",
      "Layer: Layer 1, Input: [0.9981814778942583, 0.9809571834541986, 0.012793551291873392, -0.9336027767778459], Output: [-0.9964056106590177, 0.7505118503870327, -0.9698965370240242, -0.9415908391874626]\n",
      "Layer: Layer 2, Input: [-0.9964056106590177, 0.7505118503870327, -0.9698965370240242, -0.9415908391874626], Output: [-0.7154296008709409]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932045908322245, 0.38352076030525223, 0.4317472735874238, -0.878498699280534]\n",
      "Layer: Layer 1, Input: [0.932045908322245, 0.38352076030525223, 0.4317472735874238, -0.878498699280534], Output: [-0.9824331756440738, 0.9961690427480376, -0.910870890393049, -0.8305350706935548]\n",
      "Layer: Layer 2, Input: [-0.9824331756440738, 0.9961690427480376, -0.910870890393049, -0.8305350706935548], Output: [-1.4245682587723398]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886018714561998, 0.9872518634358057, -0.7973319907621677, -0.926640099774963]\n",
      "Layer: Layer 1, Input: [0.886018714561998, 0.9872518634358057, -0.7973319907621677, -0.926640099774963], Output: [-0.9965512241231883, -0.15045557664307427, -0.9826355165073241, -0.9458991915531267]\n",
      "Layer: Layer 2, Input: [-0.9965512241231883, -0.15045557664307427, -0.9826355165073241, -0.9458991915531267], Output: [0.8650909948970416]\n",
      "Epoch 370/500, Loss: 0.1960073374222792, Accuracy: -0.5543929252633508\n",
      "Power operation: base = 0.7103452622589934, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2845703991290591, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42456825877233983, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13490900510295845, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895805011330053, 0.9890103659965848, -0.9740071585860872, -0.9973612074772801]\n",
      "Layer: Layer 1, Input: [0.9895805011330053, 0.9890103659965848, -0.9740071585860872, -0.9973612074772801], Output: [-0.9975900616780401, -0.6271271042056212, -0.9884079618604754, -0.9571098388084444]\n",
      "Layer: Layer 2, Input: [-0.9975900616780401, -0.6271271042056212, -0.9884079618604754, -0.9571098388084444], Output: [1.7121175934578021]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981819026575027, 0.980992281871694, 0.01270020669363724, -0.9336382158304546]\n",
      "Layer: Layer 1, Input: [0.9981819026575027, 0.980992281871694, 0.01270020669363724, -0.9336382158304546], Output: [-0.9964126667891279, 0.7515845358875645, -0.970059250716447, -0.9419152578172165]\n",
      "Layer: Layer 2, Input: [-0.9964126667891279, 0.7515845358875645, -0.970059250716447, -0.9419152578172165], Output: [-0.7182508748957437]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9320599581355866, 0.38431327972703416, 0.4316737252939056, -0.8785592863311207]\n",
      "Layer: Layer 1, Input: [0.9320599581355866, 0.38431327972703416, 0.4316737252939056, -0.8785592863311207], Output: [-0.9824942688065849, 0.9962196071194587, -0.9113641898595721, -0.8314701700939694]\n",
      "Layer: Layer 2, Input: [-0.9824942688065849, 0.9962196071194587, -0.9113641898595721, -0.8314701700939694], Output: [-1.424826087635847]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8860470302338302, 0.9872755008639466, -0.7973676149172956, -0.9266813584846229]\n",
      "Layer: Layer 1, Input: [0.8860470302338302, 0.9872755008639466, -0.7973676149172956, -0.9266813584846229], Output: [-0.9965582874758544, -0.15101642956229308, -0.9827338640783677, -0.9462249891611055]\n",
      "Layer: Layer 2, Input: [-0.9965582874758544, -0.15101642956229308, -0.9827338640783677, -0.9462249891611055], Output: [0.865474826916409]\n",
      "Epoch 371/500, Loss: 0.19626706583457393, Accuracy: -0.5532179792814964\n",
      "Power operation: base = 0.7121175934578021, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2817491251042563, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42482608763584695, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13452517308359102, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895838371562652, 0.9890308284858133, -0.974012632067625, -0.9973629100337944]\n",
      "Layer: Layer 1, Input: [0.9895838371562652, 0.9890308284858133, -0.974012632067625, -0.9973629100337944], Output: [-0.9975947477972061, -0.6283959032860194, -0.9884738786470022, -0.9573757397650633]\n",
      "Layer: Layer 2, Input: [-0.9975947477972061, -0.6283959032860194, -0.9884738786470022, -0.9573757397650633], Output: [1.7138780230702952]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981823263565085, 0.9810272369682097, 0.012606828458989626, -0.933673580490295]\n",
      "Layer: Layer 1, Input: [0.9981823263565085, 0.9810272369682097, 0.012606828458989626, -0.933673580490295], Output: [-0.9964196969521456, 0.7526486135225975, -0.9702208822027292, -0.9422376225698501]\n",
      "Layer: Layer 2, Input: [-0.9964196969521456, 0.7526486135225975, -0.9702208822027292, -0.9422376225698501], Output: [-0.7210629762200202]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932073975256747, 0.3851034454697023, 0.4316001357867738, -0.878619755421857]\n",
      "Layer: Layer 1, Input: [0.932073975256747, 0.3851034454697023, 0.4316001357867738, -0.878619755421857], Output: [-0.9825550209363815, 0.9962692796566588, -0.9118543910833538, -0.8324002470640214]\n",
      "Layer: Layer 2, Input: [-0.9825550209363815, 0.9962692796566588, -0.9118543910833538, -0.8324002470640214], Output: [-1.4250874689570363]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8860752699616863, 0.9872990411615896, -0.7974032401292303, -0.9267225237167775]\n",
      "Layer: Layer 1, Input: [0.8860752699616863, 0.9872990411615896, -0.7974032401292303, -0.9267225237167775], Output: [-0.9965653236220681, -0.1515791556494322, -0.9828315043134439, -0.94654844399134]\n",
      "Layer: Layer 2, Input: [-0.9965653236220681, -0.1515791556494322, -0.9828315043134439, -0.94654844399134], Output: [0.8658580819123634]\n",
      "Epoch 372/500, Loss: 0.19653027637762888, Accuracy: -0.552044433894948\n",
      "Power operation: base = 0.7138780230702952, power = 2, grad = 0.25\n",
      "Power operation: base = 0.27893702377997975, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4250874689570363, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13414191808763665, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989587163114508, 0.9890512065433172, -0.9740181038059286, -0.9973646081621602]\n",
      "Layer: Layer 1, Input: [0.989587163114508, 0.9890512065433172, -0.9740181038059286, -0.9973646081621602], Output: [-0.9975994163405286, -0.6296593633162552, -0.9885393105445079, -0.9576396194876452]\n",
      "Layer: Layer 2, Input: [-0.9975994163405286, -0.6296593633162552, -0.9885393105445079, -0.9576396194876452], Output: [1.715626644458946]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981827489978105, 0.9810620498267852, 0.012513416108241209, -0.9337088712710465]\n",
      "Layer: Layer 1, Input: [0.9981827489978105, 0.9810620498267852, 0.012513416108241209, -0.9337088712710465], Output: [-0.9964267013579429, 0.7537041995711344, -0.9703814391888101, -0.9425579454038922]\n",
      "Layer: Layer 2, Input: [-0.9964267013579429, 0.7537041995711344, -0.9703814391888101, -0.9425579454038922], Output: [-0.7238659099305025]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9320879599019495, 0.38589127270650503, 0.4315265046790758, -0.878680107401136]\n",
      "Layer: Layer 1, Input: [0.9320879599019495, 0.38589127270650503, 0.4315265046790758, -0.878680107401136], Output: [-0.9826154351122753, 0.9963180793408591, -0.9123415124422082, -0.8333253172044248]\n",
      "Layer: Layer 2, Input: [-0.9826154351122753, 0.9963180793408591, -0.9123415124422082, -0.8333253172044248], Output: [-1.4253522944197945]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8861034341727774, 0.987322485064808, -0.7974388665789884, -0.926763596087934]\n",
      "Layer: Layer 1, Input: [0.8861034341727774, 0.987322485064808, -0.7974388665789884, -0.926763596087934], Output: [-0.9965723327786441, -0.15214363376601034, -0.9829284429210761, -0.9468695731491734]\n",
      "Layer: Layer 2, Input: [-0.9965723327786441, -0.15214363376601034, -0.9829284429210761, -0.9468695731491734], Output: [0.86624074154465]\n",
      "Epoch 373/500, Loss: 0.19679691088719722, Accuracy: -0.5508722874035881\n",
      "Power operation: base = 0.7156266444589461, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2761340900694975, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4253522944197945, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13375925845534997, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895904790586453, 0.9890715008037233, -0.9740235738281211, -0.9973663018894952]\n",
      "Layer: Layer 1, Input: [0.9895904790586453, 0.9890715008037233, -0.9740235738281211, -0.9973663018894952], Output: [-0.9976040674456716, -0.6309174345068959, -0.9886042616120867, -0.9579014941244788]\n",
      "Layer: Layer 2, Input: [-0.9976040674456716, -0.6309174345068959, -0.9886042616120867, -0.9579014941244788], Output: [1.717363551194727]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998183170587816, 0.9810967215104004, 0.012419969196193613, -0.9337440886726743]\n",
      "Layer: Layer 1, Input: [0.998183170587816, 0.9810967215104004, 0.012419969196193613, -0.9337440886726743], Output: [-0.9964336802121518, 0.7547514085324669, -0.9705409292851561, -0.9428762381404897]\n",
      "Layer: Layer 2, Input: [-0.9964336802121518, 0.7547514085324669, -0.9705409292851561, -0.9428762381404897], Output: [-0.7266596808982735]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9321019122827445, 0.38667677627530633, 0.4314528316121695, -0.8787403430930651]\n",
      "Layer: Layer 1, Input: [0.9321019122827445, 0.38667677627530633, 0.4314528316121695, -0.8787403430930651], Output: [-0.982675514358738, 0.996366024696362, -0.912825572102582, -0.834245395907895]\n",
      "Layer: Layer 2, Input: [-0.982675514358738, 0.996366024696362, -0.912825572102582, -0.834245395907895], Output: [-1.4256204575522102]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8861315232870901, 0.9873458332961076, -0.7974744944351548, -0.9268045761995205]\n",
      "Layer: Layer 1, Input: [0.8861315232870901, 0.9873458332961076, -0.7974744944351548, -0.9268045761995205], Output: [-0.9965793151582408, -0.1527097446236002, -0.9830246855372895, -0.9471883935482068]\n",
      "Layer: Layer 2, Input: [-0.9965793151582408, -0.1527097446236002, -0.9830246855372895, -0.9471883935482068], Output: [0.8666227874523385]\n",
      "Epoch 374/500, Loss: 0.19706691233582002, Accuracy: -0.5497015403963252\n",
      "Power operation: base = 0.717363551194727, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2733403191017265, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42562045755221023, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13337721254766155, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895937850389436, 0.9890917118901374, -0.9740290421596789, -0.9973679912423629]\n",
      "Layer: Layer 1, Input: [0.9895937850389436, 0.9890917118901374, -0.9740290421596789, -0.9973679912423629], Output: [-0.9976087012476861, -0.6321700690510876, -0.9886687358572734, -0.9581613796414528]\n",
      "Layer: Layer 2, Input: [-0.9976087012476861, -0.6321700690510876, -0.9886687358572734, -0.9581613796414528], Output: [1.7190888370447075]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998183591132809, 0.9811312530624932, 0.012326487311320975, -0.9337792331817961]\n",
      "Layer: Layer 1, Input: [0.998183591132809, 0.9811312530624932, 0.012326487311320975, -0.9337792331817961], Output: [-0.9964406337162706, 0.7557903531595158, -0.9706993600098641, -0.9431925124692039]\n",
      "Layer: Layer 2, Input: [-0.9964406337162706, 0.7557903531595158, -0.9706993600098641, -0.9431925124692039], Output: [-0.7294442937942343]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9321158326061294, 0.3874599706874207, 0.43137911625507097, -0.8788004632981071]\n",
      "Layer: Layer 1, Input: [0.9321158326061294, 0.3874599706874207, 0.43137911625507097, -0.8788004632981071], Output: [-0.9827352616472891, 0.9964131338027934, -0.9133065880282492, -0.8351604983766733]\n",
      "Layer: Layer 2, Input: [-0.9827352616472891, 0.9964131338027934, -0.9133065880282492, -0.8351604983766733], Output: [-1.4258918536873342]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8861595377175875, 0.9873690865647767, -0.7975101238541894, -0.926845464638295]\n",
      "Layer: Layer 1, Input: [0.8861595377175875, 0.9873690865647767, -0.7975101238541894, -0.926845464638295], Output: [-0.9965862709694673, -0.15327737076093514, -0.9831202377276612, -0.9475049219162518]\n",
      "Layer: Layer 2, Input: [-0.9965862709694673, -0.15327737076093514, -0.9831202377276612, -0.9475049219162518], Output: [0.8670042012620751]\n",
      "Epoch 375/500, Loss: 0.1973402248104957, Accuracy: -0.5485321956757323\n",
      "Power operation: base = 0.7190888370447075, power = 2, grad = 0.25\n",
      "Power operation: base = 0.27055570620576574, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4258918536873342, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1329957987379249, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895970811050444, 0.9891118404144406, -0.9740345088244737, -0.9973696762467866]\n",
      "Layer: Layer 1, Input: [0.9895970811050444, 0.9891118404144406, -0.9740345088244737, -0.9973696762467866], Output: [-0.9976133178790739, -0.6334172210882995, -0.9887327372374273, -0.9584192918269885]\n",
      "Layer: Layer 2, Input: [-0.9976133178790739, -0.6334172210882995, -0.9887327372374273, -0.9584192918269885], Output: [1.7208025959594107]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981840106389527, 0.9811656455074621, 0.012232970074970923, -0.9338143052720382]\n",
      "Layer: Layer 1, Input: [0.9981840106389527, 0.9811656455074621, 0.012232970074970923, -0.9338143052720382], Output: [-0.9964475620677702, 0.7568211444912193, -0.9708567387916419, -0.9435067799535792]\n",
      "Layer: Layer 2, Input: [-0.9964475620677702, 0.7568211444912193, -0.9708567387916419, -0.9435067799535792], Output: [-0.732219753104375]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9321297210746643, 0.3882408701362194, 0.4313053583038158, -0.8788604687937073]\n",
      "Layer: Layer 1, Input: [0.9321297210746643, 0.3882408701362194, 0.4313053583038158, -0.8788604687937073], Output: [-0.9827946798978427, 0.9964594243069811, -0.9137845779886425, -0.8360706396393621]\n",
      "Layer: Layer 2, Input: [-0.9827946798978427, 0.9964594243069811, -0.9137845779886425, -0.8360706396393621], Output: [-1.426166379925303]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886187477870403, 0.9873922455672254, -0.7975457549807287, -0.9268862619767394]\n",
      "Layer: Layer 1, Input: [0.886187477870403, 0.9873922455672254, -0.7975457549807287, -0.9268862619767394], Output: [-0.9965932004169838, -0.1538463965217499, -0.983215104989295, -0.9478191748010559]\n",
      "Layer: Layer 2, Input: [-0.9965932004169838, -0.1538463965217499, -0.983215104989295, -0.9478191748010559], Output: [0.8673849645962113]\n",
      "Epoch 376/500, Loss: 0.1976167934907733, Accuracy: -0.5473642581841274\n",
      "Power operation: base = 0.7208025959594107, power = 2, grad = 0.25\n",
      "Power operation: base = 0.26778024689562496, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42616637992530304, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13261503540378872, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896003673059823, 0.9891318869775749, -0.9740399738448154, -0.9973713569282658]\n",
      "Layer: Layer 1, Input: [0.9896003673059823, 0.9891318869775749, -0.9740399738448154, -0.9973713569282658], Output: [-0.9976179174698541, -0.634658846668725, -0.9887962696610617, -0.9586752462967912]\n",
      "Layer: Layer 2, Input: [-0.9976179174698541, -0.634658846668725, -0.9887962696610617, -0.9586752462967912], Output: [1.7225049220600068]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981844291122934, 0.9811998998511554, 0.01213941714058458, -0.9338493054043832]\n",
      "Layer: Layer 1, Input: [0.9981844291122934, 0.9811998998511554, 0.01213941714058458, -0.9338493054043832], Output: [-0.9964544654601959, 0.757843891884002, -0.9710130729726731, -0.9438190520364907]\n",
      "Layer: Layer 2, Input: [-0.9964544654601959, 0.757843891884002, -0.9710130729726731, -0.9438190520364907], Output: [-0.7349860631448379]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932143577886586, 0.38901948850551327, 0.43123155748083464, -0.8789203603349008]\n",
      "Layer: Layer 1, Input: [0.932143577886586, 0.38901948850551327, 0.43123155748083464, -0.8789203603349008], Output: [-0.9828537719800174, 0.9965049134344794, -0.9142595595668348, -0.8369758345670865]\n",
      "Layer: Layer 2, Input: [-0.9828537719800174, 0.9965049134344794, -0.9142595595668348, -0.8369758345670865], Output: [-1.4264439350967777]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8862153441450309, 0.9874153109873156, -0.7975813879478805, -0.9269269687734466]\n",
      "Layer: Layer 1, Input: [0.8862153441450309, 0.9874153109873156, -0.7975813879478805, -0.9269269687734466], Output: [-0.9966001037016035, -0.15441670803334717, -0.983309292752721, -0.9481311685758055]\n",
      "Layer: Layer 2, Input: [-0.9966001037016035, -0.15441670803334717, -0.983309292752721, -0.9481311685758055], Output: [0.8677650590808668]\n",
      "Epoch 377/500, Loss: 0.19789656462727995, Accuracy: -0.5461977349310798\n",
      "Power operation: base = 0.7225049220600068, power = 2, grad = 0.25\n",
      "Power operation: base = 0.26501393685516206, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4264439350967777, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13223494091913324, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896036436902045, 0.989151852169824, -0.9740454372414931, -0.9973730333117892]\n",
      "Layer: Layer 1, Input: [0.9896036436902045, 0.989151852169824, -0.9740454372414931, -0.9973730333117892], Output: [-0.9976225001476233, -0.6358949037182974, -0.9888593369891274, -0.9589292584984244]\n",
      "Layer: Layer 2, Input: [-0.9976225001476233, -0.6358949037182974, -0.9888593369891274, -0.9589292584984244], Output: [1.7241959096252755]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981848465587632, 0.9812340170813466, 0.012045828192932075, -0.9338842340275071]\n",
      "Layer: Layer 1, Input: [0.9981848465587632, 0.9812340170813466, 0.012045828192932075, -0.9338842340275071], Output: [-0.9964613440832676, 0.7588587030423555, -0.9711683698113667, -0.9441293400452764]\n",
      "Layer: Layer 2, Input: [-0.9964613440832676, 0.7588587030423555, -0.9711683698113667, -0.9441293400452764], Output: [-0.7377432280767868]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9321574032359177, 0.3897958393777186, 0.43115771353434273, -0.8789801386549092]\n",
      "Layer: Layer 1, Input: [0.9321574032359177, 0.3897958393777186, 0.43115771353434273, -0.8789801386549092], Output: [-0.9829125407144057, 0.9965496180007515, -0.9147315501671829, -0.8378760978889968]\n",
      "Layer: Layer 2, Input: [-0.9829125407144057, 0.9965496180007515, -0.9147315501671829, -0.8378760978889968], Output: [-1.4267244197276643]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8862431369345093, 0.9874382834966827, -0.7976170228775118, -0.9269675855734948]\n",
      "Layer: Layer 1, Input: [0.8862431369345093, 0.9874382834966827, -0.7976170228775118, -0.9269675855734948], Output: [-0.9966069810203885, -0.154988193185836, -0.9834028063837242, -0.9484409194444157]\n",
      "Layer: Layer 2, Input: [-0.9966069810203885, -0.154988193185836, -0.9834028063837242, -0.9484409194444157], Output: [0.8681444663538791]\n",
      "Epoch 378/500, Loss: 0.19817948552064488, Accuracy: -0.5450326349222738\n",
      "Power operation: base = 0.7241959096252755, power = 2, grad = 0.25\n",
      "Power operation: base = 0.26225677192321317, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4267244197276643, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1318555336461209, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989606910305587, 0.9891717365710836, -0.9740508990338147, -0.9973747054218487]\n",
      "Layer: Layer 1, Input: [0.989606910305587, 0.9891717365710836, -0.9740508990338147, -0.9973747054218487], Output: [-0.9976270660376177, -0.6371253520043241, -0.9889219430362466, -0.95918134371571]\n",
      "Layer: Layer 2, Input: [-0.9976270660376177, -0.6371253520043241, -0.9889219430362466, -0.95918134371571], Output: [1.725875653078428]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981852629841828, 0.9812679981681969, 0.01195220294736438, -0.9339190915781097]\n",
      "Layer: Layer 1, Input: [0.9981852629841828, 0.9812679981681969, 0.01195220294736438, -0.9339190915781097], Output: [-0.9964681981229756, 0.7598656840485623, -0.971322636485, -0.9444376551966656]\n",
      "Layer: Layer 2, Input: [-0.9964681981229756, 0.7598656840485623, -0.971322636485, -0.9444376551966656], Output: [-0.7404912519210791]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9321711973125767, 0.39056993604181506, 0.43108382623774044, -0.8790398044657183]\n",
      "Layer: Layer 1, Input: [0.9321711973125767, 0.39056993604181506, 0.43108382623774044, -0.8790398044657183], Output: [-0.9829709888738088, 0.9965935544220219, -0.9152005670226476, -0.8387714442071366]\n",
      "Layer: Layer 2, Input: [-0.9829709888738088, 0.9965935544220219, -0.9152005670226476, -0.8387714442071366], Output: [-1.4270077360050761]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8862708566255998, 0.9874611637550476, -0.7976526598805301, -0.9270081129088131]\n",
      "Layer: Layer 1, Input: [0.8862708566255998, 0.9874611637550476, -0.7976526598805301, -0.9270081129088131], Output: [-0.9966138325667449, -0.15556074161202552, -0.9834956511851032, -0.948748443446617]\n",
      "Layer: Layer 2, Input: [-0.9966138325667449, -0.15556074161202552, -0.9834956511851032, -0.948748443446617], Output: [0.8685231680726639]\n",
      "Epoch 379/500, Loss: 0.19846550450083827, Accuracy: -0.5438689690897611\n",
      "Power operation: base = 0.725875653078428, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2595087480789209, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42700773600507613, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13147683192733606, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896101671994534, 0.9891915407511259, -0.9740563592396467, -0.9973763732824544]\n",
      "Layer: Layer 1, Input: [0.9896101671994534, 0.9891915407511259, -0.9740563592396467, -0.9973763732824544], Output: [-0.9976316152627724, -0.6383501531016926, -0.9889840915719041, -0.9594315170729679]\n",
      "Layer: Layer 2, Input: [-0.9976316152627724, -0.6383501531016926, -0.9889840915719041, -0.9594315170729679], Output: [1.7275442469737312]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981856783942646, 0.9813018440647053, 0.011858541149082798, -0.9339538784812358]\n",
      "Layer: Layer 1, Input: [0.9981856783942646, 0.9813018440647053, 0.011858541149082798, -0.9339538784812358], Output: [-0.9964750277616767, 0.7608649393915942, -0.9714758800922563, -0.9447440086015032]\n",
      "Layer: Layer 2, Input: [-0.9964750277616767, 0.7608649393915942, -0.9714758800922563, -0.9447440086015032], Output: [-0.7432301385727325]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9321849603024795, 0.3913417915010991, 0.43100989538902856, -0.8790993584586424]\n",
      "Layer: Layer 1, Input: [0.9321849603024795, 0.3913417915010991, 0.43100989538902856, -0.8790993584586424], Output: [-0.9830291191844353, 0.9966367387258098, -0.9156666272017985, -0.8396618880106881]\n",
      "Layer: Layer 2, Input: [-0.9830291191844353, 0.9966367387258098, -0.9156666272017985, -0.8396618880106881], Output: [-1.427293787744497]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8862985035989605, 0.9874839524105201, -0.7976882990571575, -0.9270485512985381]\n",
      "Layer: Layer 1, Input: [0.8862985035989605, 0.9874839524105201, -0.7976882990571575, -0.9270485512985381], Output: [-0.9966206585305146, -0.15613424466793, -0.9835878323983659, -0.9490537564628386]\n",
      "Layer: Layer 2, Input: [-0.9966206585305146, -0.15613424466793, -0.9835878323983659, -0.9490537564628386], Output: [0.8689011459219529]\n",
      "Epoch 380/500, Loss: 0.19875457090689203, Accuracy: -0.5427067502235428\n",
      "Power operation: base = 0.7275442469737312, power = 2, grad = 0.25\n",
      "Power operation: base = 0.25676986142726754, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4272937877444969, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1310988540780471, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896134144185904, 0.9892112652698568, -0.9740618178754523, -0.9973780369171463]\n",
      "Layer: Layer 1, Input: [0.9896134144185904, 0.9892112652698568, -0.9740618178754523, -0.9973780369171463], Output: [-0.9976361479437776, -0.6395692703596697, -0.9890457863215929, -0.959679793539093]\n",
      "Layer: Layer 2, Input: [-0.9976361479437776, -0.6395692703596697, -0.9890457863215929, -0.959679793539093], Output: [1.7292017859829976]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981860927946162, 0.9813355557071467, 0.011764842572420896, -0.9339885951505872]\n",
      "Layer: Layer 1, Input: [0.9981860927946162, 0.9813355557071467, 0.011764842572420896, -0.9339885951505872], Output: [-0.996481833178184, 0.7618565719952093, -0.9716281076556615, -0.9450484112692807]\n",
      "Layer: Layer 2, Input: [-0.996481833178184, 0.7618565719952093, -0.9716281076556615, -0.9450484112692807], Output: [-0.7459598918152066]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9321986923876435, 0.3921114184807409, 0.43093592081023363, -0.879158801304876]\n",
      "Layer: Layer 1, Input: [0.9321986923876435, 0.3921114184807409, 0.43093592081023363, -0.879158801304876], Output: [-0.9830869343270661, 0.9966791865611526, -0.9161297476155175, -0.840547443689615]\n",
      "Layer: Layer 2, Input: [-0.9830869343270661, 0.9966791865611526, -0.9161297476155175, -0.840547443689615], Output: [-1.4275824803581099]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8863260782293153, 0.9875066500998957, -0.797723940497202, -0.92708890124936]\n",
      "Layer: Layer 1, Input: [0.8863260782293153, 0.9875066500998957, -0.797723940497202, -0.92708890124936], Output: [-0.9966274590980646, -0.1567085954138871, -0.9836793552053573, -0.9493568742189022]\n",
      "Layer: Layer 2, Input: [-0.9966274590980646, -0.1567085954138871, -0.9836793552053573, -0.9493568742189022], Output: [0.8692783816214567]\n",
      "Epoch 381/500, Loss: 0.19904663506700845, Accuracy: -0.5415459929044442\n",
      "Power operation: base = 0.7292017859829976, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2540401081847934, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42758248035810986, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13072161837854335, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896166520092643, 0.9892309106775657, -0.9740672749563282, -0.9973796963490081]\n",
      "Layer: Layer 1, Input: [0.9896166520092643, 0.9892309106775657, -0.9740672749563282, -0.9973796963490081], Output: [-0.9976406641991353, -0.6407826688692311, -0.9891070309679189, -0.9599261879314798]\n",
      "Layer: Layer 2, Input: [-0.9976406641991353, -0.6407826688692311, -0.9891070309679189, -0.9599261879314798], Output: [1.7308483648819255]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981865061907421, 0.9813691340154974, 0.011671107020144528, -0.934023241988829]\n",
      "Layer: Layer 1, Input: [0.9981865061907421, 0.9813691340154974, 0.011671107020144528, -0.934023241988829], Output: [-0.9964886145478571, 0.7628406832452798, -0.9717793261239237, -0.945350874112482]\n",
      "Layer: Layer 2, Input: [-0.9964886145478571, 0.7628406832452798, -0.9717793261239237, -0.945350874112482], Output: [-0.7486805153344687]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9322123937462865, 0.3928788294351502, 0.4308619023468467, -0.8792181336560306]\n",
      "Layer: Layer 1, Input: [0.9322123937462865, 0.3928788294351502, 0.4308619023468467, -0.8792181336560306], Output: [-0.9831444369381865, 0.9967209132085312, -0.9165899450234124, -0.8414281255477168]\n",
      "Layer: Layer 2, Input: [-0.9831444369381865, 0.9967209132085312, -0.9165899450234124, -0.8414281255477168], Output: [-1.4278737208242465]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886353580885618, 0.987529257448942, -0.7977595842803189, -0.9271291632558604]\n",
      "Layer: Layer 1, Input: [0.886353580885618, 0.987529257448942, -0.7977595842803189, -0.9271291632558604], Output: [-0.9966342344523738, -0.15728368859621156, -0.9837702247298304, -0.9496578122905303]\n",
      "Layer: Layer 2, Input: [-0.9966342344523738, -0.15728368859621156, -0.9837702247298304, -0.9496578122905303], Output: [0.86965485693338]\n",
      "Epoch 382/500, Loss: 0.1993416482790438, Accuracy: -0.5403867134383233\n",
      "Power operation: base = 0.7308483648819255, power = 2, grad = 0.25\n",
      "Power operation: base = 0.25131948466553133, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42787372082424646, power = 2, grad = 0.25\n",
      "Power operation: base = -0.13034514306662004, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896198800172369, 0.989250477515169, -0.9740727304960425, -0.9973813516006799]\n",
      "Layer: Layer 1, Input: [0.9896198800172369, 0.989250477515169, -0.9740727304960425, -0.9973813516006799], Output: [-0.9976451641452136, -0.6419903154309451, -0.9891678291516649, -0.9601707149197984]\n",
      "Layer: Layer 2, Input: [-0.9976451641452136, -0.6419903154309451, -0.9891678291516649, -0.9601707149197984], Output: [1.7324840785363183]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998186918588047, 0.9814025798938504, 0.011577334322765307, -0.9340578193878856]\n",
      "Layer: Layer 1, Input: [0.998186918588047, 0.9814025798938504, 0.011577334322765307, -0.9340578193878856], Output: [-0.9964953720426891, 0.763817373016382, -0.9719295423741805, -0.9456514079507423]\n",
      "Layer: Layer 2, Input: [-0.9964953720426891, 0.763817373016382, -0.9719295423741805, -0.9456514079507423], Output: [-0.7513920127328806]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9322260645529237, 0.3936440365551575, 0.43078783986727237, -0.8792773561446573]\n",
      "Layer: Layer 1, Input: [0.9322260645529237, 0.3936440365551575, 0.43078783986727237, -0.8792773561446573], Output: [-0.9832016296110858, 0.9967619335895055, -0.917047236039949, -0.8423039478151152]\n",
      "Layer: Layer 2, Input: [-0.9832016296110858, 0.9967619335895055, -0.917047236039949, -0.8423039478151152], Output: [-1.4281674176579315]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8863810119312114, 0.9875517750726799, -0.7977952304762692, -0.927169337800841]\n",
      "Layer: Layer 1, Input: [0.8863810119312114, 0.9875517750726799, -0.7977952304762692, -0.927169337800841], Output: [-0.9966409847731177, -0.15785942062941766, -0.9838604460389552, -0.9499565861076735]\n",
      "Layer: Layer 2, Input: [-0.9966409847731177, -0.15785942062941766, -0.9838604460389552, -0.9499565861076735], Output: [0.8700305536698725]\n",
      "Epoch 383/500, Loss: 0.19963956279135722, Accuracy: -0.5392289297914967\n",
      "Power operation: base = 0.7324840785363183, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2486079872671194, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42816741765793154, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12996944633012752, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896230984877804, 0.9892699663144465, -0.9740781845070691, -0.9973830026943687]\n",
      "Layer: Layer 1, Input: [0.9896230984877804, 0.9892699663144465, -0.9740781845070691, -0.9973830026943687], Output: [-0.9976496478962994, -0.6431921785233667, -0.9892281844728162, -0.9604133890296279]\n",
      "Layer: Layer 2, Input: [-0.9976496478962994, -0.6431921785233667, -0.9892281844728162, -0.9604133890296279], Output: [1.734109021888175]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981873299918382, 0.9814358942308186, 0.011483524337866157, -0.934092327729232]\n",
      "Layer: Layer 1, Input: [0.9981873299918382, 0.9814358942308186, 0.011483524337866157, -0.934092327729232], Output: [-0.9965021058313913, 0.7647867396976643, -0.9720787632141545, -0.9459500235148347]\n",
      "Layer: Layer 2, Input: [-0.9965021058313913, 0.7647867396976643, -0.9720787632141545, -0.9459500235148347], Output: [-0.7540943875428736]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9322397049784624, 0.394407051775015, 0.4307137332622888, -0.8793364693847593]\n",
      "Layer: Layer 1, Input: [0.9322397049784624, 0.394407051775015, 0.4307137332622888, -0.8793364693847593], Output: [-0.9832585148969266, 0.9968022622760705, -0.9175016371403131, -0.843174924660182]\n",
      "Layer: Layer 2, Input: [-0.9832585148969266, 0.9968022622760705, -0.9175016371403131, -0.843174924660182], Output: [-1.4284634808824719]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886408371723983, 0.9875742035756548, -0.7978308791451721, -0.9272094253556451]\n",
      "Layer: Layer 1, Input: [0.886408371723983, 0.9875742035756548, -0.7978308791451721, -0.9272094253556451], Output: [-0.9966477102367512, -0.15843568957892323, -0.9839500241447721, -0.950253210958667]\n",
      "Layer: Layer 2, Input: [-0.9966477102367512, -0.15843568957892323, -0.9839500241447721, -0.950253210958667], Output: [0.8704054537003181]\n",
      "Epoch 384/500, Loss: 0.19994033178401804, Accuracy: -0.5380726615274551\n",
      "Power operation: base = 0.734109021888175, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2459056124571264, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4284634808824719, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12959454629968192, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896263074656917, 0.9892893775982724, -0.9740836370006232, -0.9973846496518634]\n",
      "Layer: Layer 1, Input: [0.9896263074656917, 0.9892893775982724, -0.9740836370006232, -0.9973846496518634], Output: [-0.9976541155646507, -0.6443882282719425, -0.9892881004915487, -0.9606542246459525]\n",
      "Layer: Layer 2, Input: [-0.9976541155646507, -0.6443882282719425, -0.9892881004915487, -0.9606542246459525], Output: [1.7357232899416921]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981877404073287, 0.9814690778999274, 0.011389676949442524, -0.9341267673841757]\n",
      "Layer: Layer 1, Input: [0.9981877404073287, 0.9814690778999274, 0.011389676949442524, -0.9341267673841757], Output: [-0.9965088160794752, 0.7657488802180226, -0.9722269953842249, -0.9462467314504858]\n",
      "Layer: Layer 2, Input: [-0.9965088160794752, 0.7657488802180226, -0.9722269953842249, -0.9462467314504858], Output: [-0.7567876432404148]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9322533151902941, 0.3951678867792224, 0.4306395824445187, -0.879395473972289]\n",
      "Layer: Layer 1, Input: [0.9322533151902941, 0.3951678867792224, 0.4306395824445187, -0.879395473972289], Output: [-0.9833150953057829, 0.9968419134997413, -0.917953164666013, -0.84404107020093]\n",
      "Layer: Layer 2, Input: [-0.9833150953057829, 0.9968419134997413, -0.917953164666013, -0.84404107020093], Output: [-1.4287618220020732]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8864356606165145, 0.9875965435522029, -0.7978665303377521, -0.9272494263804687]\n",
      "Layer: Layer 1, Input: [0.8864356606165145, 0.9875965435522029, -0.7978665303377521, -0.9272494263804687], Output: [-0.9966544110165884, -0.1590123951442612, -0.9840389640055911, -0.9505477019942175]\n",
      "Layer: Layer 2, Input: [-0.9966544110165884, -0.1590123951442612, -0.9840389640055911, -0.9505477019942175], Output: [0.8707795389585424]\n",
      "Epoch 385/500, Loss: 0.2002439093503708, Accuracy: -0.5369179297448081\n",
      "Power operation: base = 0.7357232899416921, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2432123567595852, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42876182200207325, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12922046104145757, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896295069953075, 0.9893087118808392, -0.9740890879866962, -0.9973862924945426]\n",
      "Layer: Layer 1, Input: [0.9896295069953075, 0.9893087118808392, -0.9740890879866962, -0.9973862924945426], Output: [-0.9976585672605457, -0.6455784364184062, -0.9893475807291802, -0.9608932360165218]\n",
      "Layer: Layer 2, Input: [-0.9976585672605457, -0.6455784364184062, -0.9893475807291802, -0.9608932360165218], Output: [1.7373269777491593]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981881498396389, 0.981502131759998, 0.011295792067257173, -0.9341611387141323]\n",
      "Layer: Layer 1, Input: [0.9981881498396389, 0.981502131759998, 0.011295792067257173, -0.9341611387141323], Output: [-0.9965155029493329, 0.766703890070616, -0.9723742455594121, -0.9465415423220245]\n",
      "Layer: Layer 2, Input: [-0.9965155029493329, 0.766703890070616, -0.9723742455594121, -0.9465415423220245], Output: [-0.7594717832582969]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9322668953523839, 0.3959265530091849, 0.4305653873479111, -0.8794543704856355]\n",
      "Layer: Layer 1, Input: [0.9322668953523839, 0.3959265530091849, 0.4305653873479111, -0.8794543704856355], Output: [-0.9833713733076517, 0.9968809011603762, -0.918401834830231, -0.8449023985158804]\n",
      "Layer: Layer 2, Input: [-0.9833713733076517, 0.9968809011603762, -0.918401834830231, -0.8449023985158804], Output: [-1.4290623539754246]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8864628789562297, 0.9876187955867087, -0.7979021840955793, -0.9272893413246659]\n",
      "Layer: Layer 1, Input: [0.8864628789562297, 0.9876187955867087, -0.7979021840955793, -0.9272893413246659], Output: [-0.9966610872828803, -0.15958943864274594, -0.9841272705273381, -0.9508400742312313]\n",
      "Layer: Layer 2, Input: [-0.9966610872828803, -0.15958943864274594, -0.9841272705273381, -0.9508400742312313], Output: [0.8711527914498962]\n",
      "Epoch 386/500, Loss: 0.20055025047893485, Accuracy: -0.5357647570163908\n",
      "Power operation: base = 0.7373269777491593, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2405282167417031, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4290623539754246, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1288472085501038, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989632697120517, 0.9893279696678768, -0.9740945374740878, -0.9973879312433894]\n",
      "Layer: Layer 1, Input: [0.989632697120517, 0.9893279696678768, -0.9740945374740878, -0.9973879312433894], Output: [-0.9976630030923324, -0.6467627762906497, -0.9894066286690895, -0.9611304372550868]\n",
      "Layer: Layer 2, Input: [-0.9976630030923324, -0.6467627762906497, -0.9894066286690895, -0.9611304372550868], Output: [1.7389201803967884]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981885582937994, 0.9815350566555187, 0.011201869626207159, -0.9341954420708957]\n",
      "Layer: Layer 1, Input: [0.9981885582937994, 0.9815350566555187, 0.011201869626207159, -0.9341954420708957], Output: [-0.9965221666003157, 0.7676518633367324, -0.9725205203512866, -0.9468344666158733]\n",
      "Layer: Layer 2, Input: [-0.9965221666003157, 0.7676518633367324, -0.9725205203512866, -0.9468344666158733], Output: [-0.7621468109991909]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932280445625359, 0.39668306166970596, 0.4304911479272323, -0.8795131594860988]\n",
      "Layer: Layer 1, Input: [0.932280445625359, 0.39668306166970596, 0.4304911479272323, -0.8795131594860988], Output: [-0.9834273513334333, 0.9969192388347459, -0.918847663722933, -0.8457589236544174]\n",
      "Layer: Layer 2, Input: [-0.9834273513334333, 0.9969192388347459, -0.918847663722933, -0.8457589236544174], Output: [-1.4293649911902357]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8864900270855356, 0.9876409602538566, -0.7979378404513078, -0.9273291706270455]\n",
      "Layer: Layer 1, Input: [0.8864900270855356, 0.9876409602538566, -0.7979378404513078, -0.9273291706270455], Output: [-0.9966677392028916, -0.16016672299357523, -0.9842149485648511, -0.9511303425564859]\n",
      "Layer: Layer 2, Input: [-0.9966677392028916, -0.16016672299357523, -0.9842149485648511, -0.9511303425564859], Output: [0.8715251932582255]\n",
      "Epoch 387/500, Loss: 0.2008593110356511, Accuracy: -0.5346131673296077\n",
      "Power operation: base = 0.7389201803967884, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2378531890008091, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42936499119023575, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12847480674177447, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896358778847761, 0.9893471514568644, -0.9740999854704392, -0.9973895659189999]\n",
      "Layer: Layer 1, Input: [0.9896358778847761, 0.9893471514568644, -0.9740999854704392, -0.9973895659189999], Output: [-0.9976674231664756, -0.6479412227730532, -0.9894652477575989, -0.9613658423445085]\n",
      "Layer: Layer 2, Input: [-0.9976674231664756, -0.6479412227730532, -0.9894652477575989, -0.9613658423445085], Output: [1.7405029929904412]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981889657747536, 0.981567853417008, 0.011107909585700512, -0.9342296777968988]\n",
      "Layer: Layer 1, Input: [0.9981889657747536, 0.981567853417008, 0.011107909585700512, -0.9342296777968988], Output: [-0.9965288071888093, 0.7685928927090401, -0.9726658263097974, -0.9471255147438847]\n",
      "Layer: Layer 2, Input: [-0.9965288071888093, 0.7685928927090401, -0.9726658263097974, -0.9471255147438847], Output: [-0.7648127298485292]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9322939661665935, 0.39743742373532054, 0.43041686415756636, -0.8795718415183529]\n",
      "Layer: Layer 1, Input: [0.9322939661665935, 0.39743742373532054, 0.43041686415756636, -0.8795718415183529], Output: [-0.9834830317758873, 0.9969569397848573, -0.919290667315747, -0.8466106596466512]\n",
      "Layer: Layer 2, Input: [-0.9834830317758873, 0.9969569397848573, -0.919290667315747, -0.8466106596466512], Output: [-1.429669649438698]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8865171053419616, 0.9876630381188758, -0.7979734994289069, -0.9273689147161596]\n",
      "Layer: Layer 1, Input: [0.8865171053419616, 0.9876630381188758, -0.7979734994289069, -0.9273689147161596], Output: [-0.9966743669409741, -0.1607441527023342, -0.9843020029231272, -0.9514185217301504]\n",
      "Layer: Layer 2, Input: [-0.9966743669409741, -0.1607441527023342, -0.9843020029231272, -0.9514185217301504], Output: [0.8718967265526691]\n",
      "Epoch 388/500, Loss: 0.2011710477464494, Accuracy: -0.5334631860279408\n",
      "Power operation: base = 0.7405029929904412, power = 2, grad = 0.25\n",
      "Power operation: base = 0.23518727015147078, power = 2, grad = 0.25\n",
      "Power operation: base = -0.429669649438698, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12810327344733086, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896390493311198, 0.9893662577372379, -0.9741054319822657, -0.9973911965415947]\n",
      "Layer: Layer 1, Input: [0.9896390493311198, 0.9893662577372379, -0.9741054319822657, -0.9973911965415947], Output: [-0.9976718275876042, -0.6491137522772816, -0.9895234414048286, -0.9615994651397504]\n",
      "Layer: Layer 2, Input: [-0.9976718275876042, -0.6491137522772816, -0.9895234414048286, -0.9615994651397504], Output: [1.7420755106413663]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981893722873597, 0.9816005228613679, 0.011013911929050806, -0.9342638462254707]\n",
      "Layer: Layer 1, Input: [0.9981893722873597, 0.9816005228613679, 0.011013911929050806, -0.9342638462254707], Output: [-0.996535424868309, 0.7695270695142351, -0.9728101699250269, -0.9474146970465281]\n",
      "Layer: Layer 2, Input: [-0.996535424868309, 0.7695270695142351, -0.9728101699250269, -0.9474146970465281], Output: [-0.7674695431871497]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9323074571302922, 0.3981896499564738, 0.43034253603382644, -0.8796304171108994]\n",
      "Layer: Layer 1, Input: [0.9323074571302922, 0.3981896499564738, 0.43034253603382644, -0.8796304171108994], Output: [-0.9835384169905609, 0.9969940169660393, -0.9197308614666152, -0.8474576205127982]\n",
      "Layer: Layer 2, Input: [-0.9835384169905609, 0.9969940169660393, -0.9197308614666152, -0.8474576205127982], Output: [-1.4299762458938035]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8865441140582937, 0.9876850297377782, -0.798009161043888, -0.927408574010586]\n",
      "Layer: Layer 1, Input: [0.8865441140582937, 0.9876850297377782, -0.798009161043888, -0.927408574010586], Output: [-0.9966809706586388, -0.1613216338459172, -0.9843884383585232, -0.9517046263891629]\n",
      "Layer: Layer 2, Input: [-0.9966809706586388, -0.1613216338459172, -0.9843884383585232, -0.9517046263891629], Output: [0.8722673735944158]\n",
      "Epoch 389/500, Loss: 0.20148541818015864, Accuracy: -0.5323148397536044\n",
      "Power operation: base = 0.7420755106413663, power = 2, grad = 0.25\n",
      "Power operation: base = 0.23253045681285034, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42997624589380345, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12773262640558425, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896422115021746, 0.9893852889905919, -0.9741108770149874, -0.9973928231310295]\n",
      "Layer: Layer 1, Input: [0.9896422115021746, 0.9893852889905919, -0.9741108770149874, -0.9973928231310295], Output: [-0.9976762164585551, -0.6502803427134987, -0.9895812129855157, -0.9618313193707525]\n",
      "Layer: Layer 2, Input: [-0.9976762164585551, -0.6502803427134987, -0.9895812129855157, -0.9618313193707525], Output: [1.74363782845181]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998189777836393, 0.9816330657922273, 0.010919876662877517, -0.9342979476810862]\n",
      "Layer: Layer 1, Input: [0.998189777836393, 0.9816330657922273, 0.010919876662877517, -0.9342979476810862], Output: [-0.996542019789492, 0.7704544837351173, -0.9729535576288761, -0.9477020237959326]\n",
      "Layer: Layer 2, Input: [-0.996542019789492, 0.7704544837351173, -0.9729535576288761, -0.9477020237959326], Output: [-0.7701172544037442]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9323209186675714, 0.3989397508655487, 0.43026816357027337, -0.8796888867765075]\n",
      "Layer: Layer 1, Input: [0.9323209186675714, 0.3989397508655487, 0.43026816357027337, -0.8796888867765075], Output: [-0.9835935092966915, 0.9970304830347984, -0.9201682619242332, -0.8482998202720948]\n",
      "Layer: Layer 2, Input: [-0.9835935092966915, 0.9970304830347984, -0.9201682619242332, -0.8482998202720948], Output: [-1.4302846990865339]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8865710535627053, 0.9877069356575909, -0.7980448253035275, -0.9274481489192037]\n",
      "Layer: Layer 1, Input: [0.8865710535627053, 0.9877069356575909, -0.7980448253035275, -0.9274481489192037], Output: [-0.9966875505146263, -0.16189907405779919, -0.9844742595799129, -0.9519886710504661]\n",
      "Layer: Layer 2, Input: [-0.9966875505146263, -0.16189907405779919, -0.9844742595799129, -0.9519886710504661], Output: [0.8726371167432792]\n",
      "Epoch 390/500, Loss: 0.20180238073171264, Accuracy: -0.5311681563913204\n",
      "Power operation: base = 0.7436378284518099, power = 2, grad = 0.25\n",
      "Power operation: base = 0.22988274559625577, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4302846990865339, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12736288325672085, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896453644401708, 0.9894042456908758, -0.9741163205729596, -0.9973944457068045]\n",
      "Layer: Layer 1, Input: [0.9896453644401708, 0.9894042456908758, -0.9741163205729596, -0.9973944457068045], Output: [-0.9976805898804182, -0.6514409734620203, -0.9896385658398089, -0.9620614186451985]\n",
      "Layer: Layer 2, Input: [-0.9976805898804182, -0.6514409734620203, -0.9896385658398089, -0.9620614186451985], Output: [1.7451900415006536]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998190182426548, 0.9816654830002771, 0.010825803816521198, -0.9343319824796094]\n",
      "Layer: Layer 1, Input: [0.998190182426548, 0.9816654830002771, 0.010825803816521198, -0.9343319824796094], Output: [-0.9965485921002861, 0.7713752240321081, -0.973095995796678, -0.9479875051987907]\n",
      "Layer: Layer 2, Input: [-0.9965485921002861, 0.7713752240321081, -0.973095995796678, -0.9479875051987907], Output: [-0.7727558669071062]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9323343509265388, 0.39968773678274805, 0.43019374680004485, -0.8797472510126464]\n",
      "Layer: Layer 1, Input: [0.9323343509265388, 0.39968773678274805, 0.43019374680004485, -0.8797472510126464], Output: [-0.9836483109780854, 0.9970663503564516, -0.9206028843322801, -0.8491372729512584]\n",
      "Layer: Layer 2, Input: [-0.9836483109780854, 0.9970663503564516, -0.9206028843322801, -0.8491372729512584], Output: [-1.4305949288838509]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8865979241788845, 0.9877287564165824, -0.7980804922070857, -0.9274876398414601]\n",
      "Layer: Layer 1, Input: [0.8865979241788845, 0.9877287564165824, -0.7980804922070857, -0.9274876398414601], Output: [-0.996694106664975, -0.16247638251366, -0.9845594712497971, -0.9522706701141103]\n",
      "Layer: Layer 2, Input: [-0.996694106664975, -0.16247638251366, -0.9845594712497971, -0.9522706701141103], Output: [0.8730059384641491]\n",
      "Epoch 391/500, Loss: 0.2021218946056867, Accuracy: -0.5300231650132492\n",
      "Power operation: base = 0.7451900415006536, power = 2, grad = 0.25\n",
      "Power operation: base = 0.22724413309289382, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43059492888385087, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1269940615358509, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896485081869544, 0.9894231283045851, -0.9741217626595033, -0.9973960642880755]\n",
      "Layer: Layer 1, Input: [0.9896485081869544, 0.9894231283045851, -0.9741217626595033, -0.9973960642880755], Output: [-0.9976849479525786, -0.6525956253453824, -0.9896955032740293, -0.9622897764511728]\n",
      "Layer: Layer 2, Input: [-0.9976849479525786, -0.6525956253453824, -0.9896955032740293, -0.9622897764511728], Output: [1.746732244829003]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981905860624408, 0.9816977752635966, 0.01073169344146889, -0.9343659509285313]\n",
      "Layer: Layer 1, Input: [0.9981905860624408, 0.9816977752635966, 0.01073169344146889, -0.9343659509285313], Output: [-0.9965551419459407, 0.772289377764234, -0.9732374907487477, -0.9482711513991262]\n",
      "Layer: Layer 2, Input: [-0.9965551419459407, 0.772289377764234, -0.9732374907487477, -0.9482711513991262], Output: [-0.7753853841381524]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9323477540523709, 0.40043361782183406, 0.4301192857746917, -0.8798055103019058]\n",
      "Layer: Layer 1, Input: [0.9323477540523709, 0.40043361782183406, 0.4301192857746917, -0.8798055103019058], Output: [-0.9837028242839712, 0.9971016310125432, -0.9210347442334478, -0.849969992592505]\n",
      "Layer: Layer 2, Input: [-0.9837028242839712, 0.9971016310125432, -0.9210347442334478, -0.849969992592505], Output: [-1.4309068564674856]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8866247262261574, 0.9877504925444826, -0.7981161617460186, -0.927527047167633]\n",
      "Layer: Layer 1, Input: [0.8866247262261574, 0.9877504925444826, -0.7981161617460186, -0.927527047167633], Output: [-0.9967006392630879, -0.16305346991733144, -0.9846440779853769, -0.9525506378662245]\n",
      "Layer: Layer 2, Input: [-0.9967006392630879, -0.16305346991733144, -0.9846440779853769, -0.9525506378662245], Output: [0.8733738213333151]\n",
      "Epoch 392/500, Loss: 0.20244391980013623, Accuracy: -0.5288798958250212\n",
      "Power operation: base = 0.746732244829003, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2246146158618476, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4309068564674856, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1266261786666849, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896516427839976, 0.9894419372909482, -0.9741272032769343, -0.9973976788936618]\n",
      "Layer: Layer 1, Input: [0.9896516427839976, 0.9894419372909482, -0.9741272032769343, -0.9973976788936618], Output: [-0.9976892907727585, -0.6537442806008092, -0.9897520285614089, -0.9625164061597163]\n",
      "Layer: Layer 2, Input: [-0.9976892907727585, -0.6537442806008092, -0.9897520285614089, -0.9625164061597163], Output: [1.748264533425779]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981909887486111, 0.9817299433479713, 0.01063754561079037, -0.9343998533272035]\n",
      "Layer: Layer 1, Input: [0.9981909887486111, 0.9817299433479713, 0.01063754561079037, -0.9343998533272035], Output: [-0.9965616694690925, 0.7731970310095895, -0.9733780487518666, -0.9485529724809331]\n",
      "Layer: Layer 2, Input: [-0.9965616694690925, 0.7731970310095895, -0.9733780487518666, -0.9485529724809331], Output: [-0.7780058095817202]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9323611281873884, 0.4011774038957299, 0.430044780563724, -0.8798636651124079]\n",
      "Layer: Layer 1, Input: [0.9323611281873884, 0.4011774038957299, 0.430044780563724, -0.8798636651124079], Output: [-0.9837570514298328, 0.9971363368080524, -0.9214638570732799, -0.8507979932611455]\n",
      "Layer: Layer 2, Input: [-0.9837570514298328, 0.9971363368080524, -0.9214638570732799, -0.8507979932611455], Output: [-1.4312204043134633]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8866514600196087, 0.9877721445626967, -0.7981518339041894, -0.9275663712790857]\n",
      "Layer: Layer 1, Input: [0.8866514600196087, 0.9877721445626967, -0.7981518339041894, -0.9275663712790857], Output: [-0.996707148459797, -0.1636302484870725, -0.9847280843595827, -0.952828588481864]\n",
      "Layer: Layer 2, Input: [-0.996707148459797, -0.1636302484870725, -0.9847280843595827, -0.952828588481864], Output: [0.8737407480446917]\n",
      "Epoch 393/500, Loss: 0.20276841709073673, Accuracy: -0.5277383801128304\n",
      "Power operation: base = 0.7482645334257789, power = 2, grad = 0.25\n",
      "Power operation: base = 0.22199419041827984, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4312204043134633, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1262592519553083, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896547682724111, 0.9894606731021073, -0.9741326424265918, -0.9973992895420568]\n",
      "Layer: Layer 1, Input: [0.9896547682724111, 0.9894606731021073, -0.9741326424265918, -0.9973992895420568], Output: [-0.9976936184370576, -0.6548869228530774, -0.989808144942798, -0.9627413210272827]\n",
      "Layer: Layer 2, Input: [-0.9976936184370576, -0.6548869228530774, -0.989808144942798, -0.9627413210272827], Output: [1.749787002213285]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981913904895239, 0.9817619880072025, 0.0105433604185838, -0.9344336899670628]\n",
      "Layer: Layer 1, Input: [0.9981913904895239, 0.9817619880072025, 0.0105433604185838, -0.9344336899670628], Output: [-0.996568174809831, 0.7740982685853057, -0.973517676020707, -0.9488329784706875]\n",
      "Layer: Layer 2, Input: [-0.996568174809831, 0.7740982685853057, -0.973517676020707, -0.9488329784706875], Output: [-0.780617146778174]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9323744734711299, 0.4019191047219871, 0.4299702312541641, -0.8799217158982084]\n",
      "Layer: Layer 1, Input: [0.9323744734711299, 0.4019191047219871, 0.4299702312541641, -0.8799217158982084], Output: [-0.9838109945982162, 0.9971704792783976, -0.921890238203825, -0.851621289052759]\n",
      "Layer: Layer 2, Input: [-0.9838109945982162, 0.9971704792783976, -0.921890238203825, -0.851621289052759], Output: [-1.4315354961723807]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8866781258701987, 0.9877937129845157, -0.7981875086580736, -0.9276056125485149]\n",
      "Layer: Layer 1, Input: [0.8866781258701987, 0.9877937129845157, -0.7981875086580736, -0.9276056125485149], Output: [-0.9967136344034272, -0.16420663194211285, -0.9848114949020684, -0.9531045360277344]\n",
      "Layer: Layer 2, Input: [-0.9967136344034272, -0.16420663194211285, -0.9848114949020684, -0.9531045360277344], Output: [0.8741067014158634]\n",
      "Epoch 394/500, Loss: 0.20309534801521786, Accuracy: -0.5265986501916284\n",
      "Power operation: base = 0.7497870022132851, power = 2, grad = 0.25\n",
      "Power operation: base = 0.21938285322182605, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43153549617238074, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12589329858413656, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896578846929528, 0.9894793361832959, -0.974138080108867, -0.9974008962514367]\n",
      "Layer: Layer 1, Input: [0.9896578846929528, 0.9894793361832959, -0.974138080108867, -0.9974008962514367], Output: [-0.9976979310399938, -0.6560235370877656, -0.9898638556273507, -0.9629645341980985]\n",
      "Layer: Layer 2, Input: [-0.9976979310399938, -0.6560235370877656, -0.9898638556273507, -0.9629645341980985], Output: [1.7512997460328181]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981917912895717, 0.9817939099834089, 0.01044913797943223, -0.9344674611318545]\n",
      "Layer: Layer 1, Input: [0.9981917912895717, 0.9817939099834089, 0.01044913797943223, -0.9344674611318545], Output: [-0.9965746581057612, 0.7749931740670382, -0.973656378719197, -0.9491111793397383]\n",
      "Layer: Layer 2, Input: [-0.9965746581057612, 0.7749931740670382, -0.973656378719197, -0.9491111793397383], Output: [-0.7832193993347758]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932387790040424, 0.4026587298281214, 0.42989563795010766, -0.8799796630996899]\n",
      "Layer: Layer 1, Input: [0.932387790040424, 0.4026587298281214, 0.42989563795010766, -0.8799796630996899], Output: [-0.9838646559395168, 0.9972040696962464, -0.9223139028871089, -0.8524398940999713]\n",
      "Layer: Layer 2, Input: [-0.9838646559395168, 0.9972040696962464, -0.9223139028871089, -0.8524398940999713], Output: [-1.431852057050354]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8867047240848761, 0.9878151983153186, -0.7982231859769595, -0.9276447713401949]\n",
      "Layer: Layer 1, Input: [0.8867047240848761, 0.9878151983153186, -0.7982231859769595, -0.9276447713401949], Output: [-0.9967200972398568, -0.16478253548947538, -0.9848943141001649, -0.9533784944648025]\n",
      "Layer: Layer 2, Input: [-0.9967200972398568, -0.16478253548947538, -0.9848943141001649, -0.9533784944648025], Output: [0.8744716643940107]\n",
      "Epoch 395/500, Loss: 0.20342467485809612, Accuracy: -0.5254607393543855\n",
      "Power operation: base = 0.7512997460328181, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2167806006652242, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4318520570503539, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1255283356059893, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896609920860401, 0.989497926973011, -0.9741435163232304, -0.997402499039669]\n",
      "Layer: Layer 1, Input: [0.9896609920860401, 0.989497926973011, -0.9741435163232304, -0.997402499039669], Output: [-0.9977022286745403, -0.6571541096248773, -0.9899191637931845, -0.9631860587064325]\n",
      "Layer: Layer 2, Input: [-0.9977022286745403, -0.6571541096248773, -0.9899191637931845, -0.9631860587064325], Output: [1.7528028596302807]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981921911530768, 0.9818257100073211, 0.010354878427871512, -0.9345011670978468]\n",
      "Layer: Layer 1, Input: [0.9981921911530768, 0.9818257100073211, 0.010354878427871512, -0.9345011670978468], Output: [-0.9965811194920675, 0.77588182980799, -0.9737941629618277, -0.9493875850065809]\n",
      "Layer: Layer 2, Input: [-0.9965811194920675, 0.77588182980799, -0.9737941629618277, -0.9493875850065809], Output: [-0.7858125709368258]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.93240107802946, 0.4033962885568235, 0.42982100077229385, -0.8800375071439446]\n",
      "Layer: Layer 1, Input: [0.93240107802946, 0.4033962885568235, 0.42982100077229385, -0.8800375071439446], Output: [-0.9839180375727458, 0.9972371190781331, -0.9227348662984396, -0.8532538225788384]\n",
      "Layer: Layer 2, Input: [-0.9839180375727458, 0.9972371190781331, -0.9227348662984396, -0.8532538225788384], Output: [-1.4321700131906567]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8867312549666894, 0.9878366010527718, -0.7982588658231476, -0.9276838480102128]\n",
      "Layer: Layer 1, Input: [0.8867312549666894, 0.9878366010527718, -0.7982588658231476, -0.9276838480102128], Output: [-0.9967265371125791, -0.1653578758110626, -0.9849765463998017, -0.9536504776507921]\n",
      "Layer: Layer 2, Input: [-0.9967265371125791, -0.1653578758110626, -0.9849765463998017, -0.9536504776507921], Output: [0.8748356200617327]\n",
      "Epoch 396/500, Loss: 0.20375636063569094, Accuracy: -0.524324681822379\n",
      "Power operation: base = 0.7528028596302807, power = 2, grad = 0.25\n",
      "Power operation: base = 0.21418742906317423, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43217001319065673, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12516437993826734, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896640904917583, 0.9895164459031811, -0.9741489510682578, -0.9974040979243219]\n",
      "Layer: Layer 1, Input: [0.9896640904917583, 0.9895164459031811, -0.9741489510682578, -0.9974040979243219], Output: [-0.9977065114321639, -0.6582786280928317, -0.9899740725880164, -0.9634059074787756]\n",
      "Layer: Layer 2, Input: [-0.9977065114321639, -0.6582786280928317, -0.9899740725880164, -0.9634059074787756], Output: [1.7542964376418224]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981925900842923, 0.9818573887985678, 0.010260581917864895, -0.9345348081340435]\n",
      "Layer: Layer 1, Input: [0.9981925900842923, 0.9818573887985678, 0.010260581917864895, -0.9345348081340435], Output: [-0.9965875591015723, 0.7767643169574912, -0.9739310348149088, -0.949662205339016]\n",
      "Layer: Layer 2, Input: [-0.9965875591015723, 0.7767643169574912, -0.9739310348149088, -0.949662205339016], Output: [-0.7883966653586096]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932414337569856, 0.4041317900710446, 0.4297463198576808, -0.8800952484451497]\n",
      "Layer: Layer 1, Input: [0.932414337569856, 0.4041317900710446, 0.4297463198576808, -0.8800952484451497], Output: [-0.983971141586274, 0.997269638190893, -0.9231531435295444, -0.8540630887148537]\n",
      "Layer: Layer 2, Input: [-0.983971141586274, 0.997269638190893, -0.9231531435295444, -0.8540630887148537], Output: [-1.4324892920559904]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8867577188148938, 0.9878579216870219, -0.7982945481521433, -0.9277228429067005]\n",
      "Layer: Layer 1, Input: [0.8867577188148938, 0.9878579216870219, -0.7982945481521433, -0.9277228429067005], Output: [-0.9967329541627599, -0.1659325710509662, -0.9850581962063903, -0.9539204993425738]\n",
      "Layer: Layer 2, Input: [-0.9967329541627599, -0.1659325710509662, -0.9850581962063903, -0.9539204993425738], Output: [0.8751985516426828]\n",
      "Epoch 397/500, Loss: 0.20409036908141898, Accuracy: -0.5231905126965204\n",
      "Power operation: base = 0.7542964376418224, power = 2, grad = 0.25\n",
      "Power operation: base = 0.21160333464139036, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4324892920559904, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12480144835731721, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896671799498706, 0.9895348933993298, -0.9741543843416588, -0.9974056929226717]\n",
      "Layer: Layer 1, Input: [0.9896671799498706, 0.9895348933993298, -0.9741543843416588, -0.9974056929226717], Output: [-0.9977107794028629, -0.6593970814028076, -0.9900285851297762, -0.9636240933359345]\n",
      "Layer: Layer 2, Input: [-0.9977107794028629, -0.6593970814028076, -0.9900285851297762, -0.9636240933359345], Output: [1.7557805745795365]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981929880874049, 0.9818889470659549, 0.01016624862228762, -0.9345683845023888]\n",
      "Layer: Layer 1, Input: [0.9981929880874049, 0.9818889470659549, 0.01016624862228762, -0.9345683845023888], Output: [-0.9965939770647959, 0.7776407154791434, -0.9740670002977675, -0.9499350501562003]\n",
      "Layer: Layer 2, Input: [-0.9965939770647959, 0.7776407154791434, -0.9740670002977675, -0.9499350501562003], Output: [-0.7909716864740828]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9324275687907261, 0.4048652433589617, 0.4296715953590298, -0.8801528874049331]\n",
      "Layer: Layer 1, Input: [0.9324275687907261, 0.4048652433589617, 0.4296715953590298, -0.8801528874049331], Output: [-0.9840239700385579, 0.9973016375579183, -0.9235687495915481, -0.8548677067885856]\n",
      "Layer: Layer 2, Input: [-0.9840239700385579, 0.9973016375579183, -0.9235687495915481, -0.8548677067885856], Output: [-1.4328098223113654]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8867841159250565, 0.9878791607008846, -0.7983302329128471, -0.9277617563700601]\n",
      "Layer: Layer 1, Input: [0.8867841159250565, 0.9878791607008846, -0.7983302329128471, -0.9277617563700601], Output: [-0.9967393485292944, -0.16650654080300145, -0.9851392678856786, -0.9541885731984484]\n",
      "Layer: Layer 2, Input: [-0.9967393485292944, -0.16650654080300145, -0.9851392678856786, -0.9541885731984484], Output: [0.8755604425070898]\n",
      "Epoch 398/500, Loss: 0.2044266646313726, Accuracy: -0.5220582679097294\n",
      "Power operation: base = 0.7557805745795365, power = 2, grad = 0.25\n",
      "Power operation: base = 0.20902831352591722, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43280982231136544, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12443955749291025, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989670260499828, 0.9895532698807354, -0.9741598161403007, -0.9974072840517118]\n",
      "Layer: Layer 1, Input: [0.989670260499828, 0.9895532698807354, -0.9741598161403007, -0.9974072840517118], Output: [-0.9977150326752006, -0.660509459723443, -0.9900827045071995, -0.9638406289950454]\n",
      "Layer: Layer 2, Input: [-0.9977150326752006, -0.660509459723443, -0.9900827045071995, -0.9638406289950454], Output: [1.7572553648172011]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998193385166536, 0.9819203855077382, 0.010071878732424265, -0.9346018964579692]\n",
      "Layer: Layer 1, Input: [0.998193385166536, 0.9819203855077382, 0.010071878732424265, -0.9346018964579692], Output: [-0.9966003735100138, 0.7785111041685578, -0.9742020653839004, -0.9502061292305916]\n",
      "Layer: Layer 2, Input: [-0.9966003735100138, 0.7785111041685578, -0.9742020653839004, -0.9502061292305916], Output: [-0.7935376382673542]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9324407718187459, 0.40559665723882715, 0.42959682744449695, -0.8802104244127321]\n",
      "Layer: Layer 1, Input: [0.9324407718187459, 0.40559665723882715, 0.42959682744449695, -0.8802104244127321], Output: [-0.9840765249588456, 0.9973331274652404, -0.9239816994178004, -0.8556676911409635]\n",
      "Layer: Layer 2, Input: [-0.9840765249588456, 0.9973331274652404, -0.9239816994178004, -0.8556676911409635], Output: [-1.4331315338075852]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886810446589157, 0.9879003185700278, -0.7983659200477423, -0.9278005887331828]\n",
      "Layer: Layer 1, Input: [0.886810446589157, 0.9879003185700278, -0.7983659200477423, -0.9278005887331828], Output: [-0.9967457203488633, -0.16707970609846254, -0.9852197657645702, -0.9544547127803322]\n",
      "Layer: Layer 2, Input: [-0.9967457203488633, -0.16707970609846254, -0.9852197657645702, -0.9544547127803322], Output: [0.8759212761771584]\n",
      "Epoch 399/500, Loss: 0.20476521241016765, Accuracy: -0.5209279841802736\n",
      "Power operation: base = 0.7572553648172011, power = 2, grad = 0.25\n",
      "Power operation: base = 0.20646236173264576, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4331315338075852, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12407872382284157, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989673332180777, 0.9895715757605869, -0.9741652464602348, -0.99740887132816]\n",
      "Layer: Layer 1, Input: [0.989673332180777, 0.9895715757605869, -0.9741652464602348, -0.99740887132816], Output: [-0.9977192713363416, -0.6616157544558741, -0.9901364337803981, -0.964055527071506]\n",
      "Layer: Layer 2, Input: [-0.9977192713363416, -0.6616157544558741, -0.9901364337803981, -0.964055527071506], Output: [1.7587209025760933]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981937813257435, 0.9819517048118884, 0.009977472457468915, -0.9346353442492101]\n",
      "Layer: Layer 1, Input: [0.9981937813257435, 0.9819517048118884, 0.009977472457468915, -0.9346353442492101], Output: [-0.9966067485633135, 0.7793755606706859, -0.9743362360020763, -0.9504754522897894]\n",
      "Layer: Layer 2, Input: [-0.9966067485633135, 0.7793755606706859, -0.9743362360020763, -0.9504754522897894], Output: [-0.7960945248429354]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9324539467782161, 0.40632604036370246, 0.4295220162972298, -0.8802678598461421]\n",
      "Layer: Layer 1, Input: [0.9324539467782161, 0.40632604036370246, 0.4295220162972298, -0.8802678598461421], Output: [-0.9841288083478635, 0.9973641179674438, -0.9243920078665548, -0.8564630561782145]\n",
      "Layer: Layer 2, Input: [-0.9841288083478635, 0.9973641179674438, -0.9243920078665548, -0.8564630561782145], Output: [-1.4334543575652772]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886836711095687, 0.9879213957631515, -0.798401609493077, -0.9278393403216648]\n",
      "Layer: Layer 1, Input: [0.886836711095687, 0.9879213957631515, -0.798401609493077, -0.9278393403216648], Output: [-0.9967520697559873, -0.1676519893940373, -0.9852996941319148, -0.9547189315558439]\n",
      "Layer: Layer 2, Input: [-0.9967520697559873, -0.1676519893940373, -0.9852996941319148, -0.9547189315558439], Output: [0.8762810363322817]\n",
      "Epoch 400/500, Loss: 0.2051059782170628, Accuracy: -0.5197996989661533\n",
      "Power operation: base = 0.7587209025760933, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2039054751570646, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43345435756527717, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12371896366771828, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896763950315697, 0.9895898114461343, -0.9741706752967213, -0.9974104547684671]\n",
      "Layer: Layer 1, Input: [0.9896763950315697, 0.9895898114461343, -0.9741706752967213, -0.9974104547684671], Output: [-0.9977234954720867, -0.662715958209104, -0.9901897759814098, -0.9642688000808335]\n",
      "Layer: Layer 2, Input: [-0.9977234954720867, -0.662715958209104, -0.9901897759814098, -0.9642688000808335], Output: [1.7601772819108508]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981941765690241, 0.9819829056563499, 0.009883030024038803, -0.9346687281180684]\n",
      "Layer: Layer 1, Input: [0.9981941765690241, 0.9819829056563499, 0.009883030024038803, -0.9346687281180684], Output: [-0.9966131023486476, 0.780234161496766, -0.9744695180373895, -0.9507430290182809]\n",
      "Layer: Layer 2, Input: [-0.9966131023486476, 0.780234161496766, -0.9744695180373895, -0.9507430290182809], Output: [-0.7986423504357463]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9324670937911259, 0.40705340122608313, 0.4294471621149726, -0.8803251940712596]\n",
      "Layer: Layer 1, Input: [0.9324670937911259, 0.40705340122608313, 0.4294471621149726, -0.8803251940712596], Output: [-0.9841808221784848, 0.9973946188934193, -0.9247996897235065, -0.8572538163764705]\n",
      "Layer: Layer 2, Input: [-0.9841808221784848, 0.9973946188934193, -0.9247996897235065, -0.8572538163764705], Output: [-1.4337782257594824]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886862909729746, 0.9879423927421616, -0.798437301179045, -0.9278780114540165]\n",
      "Layer: Layer 1, Input: [0.886862909729746, 0.9879423927421616, -0.798437301179045, -0.9278780114540165], Output: [-0.9967583968830789, -0.16822331455993697, -0.9853790572392703, -0.9549812429002993]\n",
      "Layer: Layer 2, Input: [-0.9967583968830789, -0.16822331455993697, -0.9853790572392703, -0.9549812429002993], Output: [0.8766397068141671]\n",
      "Epoch 401/500, Loss: 0.2054489285123373, Accuracy: -0.5186734504204198\n",
      "Power operation: base = 0.7601772819108508, power = 2, grad = 0.25\n",
      "Power operation: base = 0.20135764956425373, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43377822575948244, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12336029318583286, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989679449090771, 0.9896079773388382, -0.9741761026442537, -0.9974120343888234]\n",
      "Layer: Layer 1, Input: [0.989679449090771, 0.9896079773388382, -0.9741761026442537, -0.9974120343888234], Output: [-0.9977277051669037, -0.6638100647757098, -0.9902427341147316, -0.9644804604404488]\n",
      "Layer: Layer 2, Input: [-0.9977277051669037, -0.6638100647757098, -0.9902427341147316, -0.9644804604404488], Output: [1.7616245966954507]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998194570900314, 0.9820139887092927, 0.009788551675694484, -0.9347020483002189]\n",
      "Layer: Layer 1, Input: [0.998194570900314, 0.9820139887092927, 0.009788551675694484, -0.9347020483002189], Output: [-0.9966194349878889, 0.7810869820409029, -0.9746019173322723, -0.9510088690590889]\n",
      "Layer: Layer 2, Input: [-0.9966194349878889, 0.7810869820409029, -0.9746019173322723, -0.9510088690590889], Output: [-0.8011811194209022]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9324802129772128, 0.407778748162413, 0.4293722651096771, -0.880382427443016]\n",
      "Layer: Layer 1, Input: [0.9324802129772128, 0.407778748162413, 0.4293722651096771, -0.880382427443016], Output: [-0.9842325683963816, 0.9974246398519567, -0.9252047597041945, -0.8580399862860475]\n",
      "Layer: Layer 2, Input: [-0.9842325683963816, 0.9974246398519567, -0.9252047597041945, -0.8580399862860475], Output: [-1.4341030717047474]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8868890427731352, 0.98796330996234, -0.7984729950299614, -0.9279166024418662]\n",
      "Layer: Layer 1, Input: [0.8868890427731352, 0.98796330996234, -0.7984729950299614, -0.9279166024418662], Output: [-0.996764701860495, -0.16879360686815928, -0.9854578593016332, -0.9552416600986158]\n",
      "Layer: Layer 2, Input: [-0.996764701860495, -0.16879360686815928, -0.9854578593016332, -0.9552416600986158], Output: [0.8769972716317778]\n",
      "Epoch 402/500, Loss: 0.2057940304039393, Accuracy: -0.5175492773475181\n",
      "Power operation: base = 0.7616245966954507, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1988188805790978, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4341030717047474, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12300272836822224, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896824943966672, 0.9896260738345121, -0.9741815284965819, -0.9974136102051674]\n",
      "Layer: Layer 1, Input: [0.9896824943966672, 0.9896260738345121, -0.9741815284965819, -0.9974136102051674], Output: [-0.9977319005039615, -0.6648980691078581, -0.9902953111578314, -0.9646905204713883]\n",
      "Layer: Layer 2, Input: [-0.9977319005039615, -0.6648980691078581, -0.9902953111578314, -0.9646905204713883], Output: [1.7630629406092497]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981949643234914, 0.9820449546293583, 0.009694037672468247, -0.9347353050252386]\n",
      "Layer: Layer 1, Input: [0.9981949643234914, 0.9820449546293583, 0.009694037672468247, -0.9347353050252386], Output: [-0.9966257466008814, 0.7819340965962873, -0.9747334396874613, -0.9512729820153287]\n",
      "Layer: Layer 2, Input: [-0.9966257466008814, 0.7819340965962873, -0.9747334396874613, -0.9512729820153287], Output: [-0.8037108363232601]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932493304454023, 0.40850208935749455, 0.429297325507121, -0.8804395603055047]\n",
      "Layer: Layer 1, Input: [0.932493304454023, 0.40850208935749455, 0.429297325507121, -0.8804395603055047], Output: [-0.9842840489206585, 0.9974541902371872, -0.9256072324562743, -0.8588215805354165]\n",
      "Layer: Layer 2, Input: [-0.9842840489206585, 0.9974541902371872, -0.9256072324562743, -0.8588215805354165], Output: [-1.4344288298407069]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8869151105044475, 0.9879841478725113, -0.7985086909644363, -0.9279551135901615]\n",
      "Layer: Layer 1, Input: [0.8869151105044475, 0.9879841478725113, -0.7985086909644363, -0.9279551135901615], Output: [-0.9967709848165873, -0.16936279298091592, -0.9855361044981462, -0.9555001963471325]\n",
      "Layer: Layer 2, Input: [-0.9967709848165873, -0.16936279298091592, -0.9855361044981462, -0.9555001963471325], Output: [0.8773537149661674]\n",
      "Epoch 403/500, Loss: 0.20614125163437885, Accuracy: -0.516427219160529\n",
      "Power operation: base = 0.7630629406092497, power = 2, grad = 0.25\n",
      "Power operation: base = 0.19628916367673988, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43442882984070685, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12264628503383257, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896855309872741, 0.9896441013234639, -0.9741869528467361, -0.9974151822331911]\n",
      "Layer: Layer 1, Input: [0.9896855309872741, 0.9896441013234639, -0.9741869528467361, -0.9974151822331911], Output: [-0.9977360815651619, -0.665979967293642, -0.9903475100616432, -0.9648989923999508]\n",
      "Layer: Layer 2, Input: [-0.9977360815651619, -0.665979967293642, -0.9903475100616432, -0.9648989923999508], Output: [1.764492407123134]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981953568423775, 0.9820758040658994, 0.009599488290400084, -0.9347684985167858]\n",
      "Layer: Layer 1, Input: [0.9981953568423775, 0.9820758040658994, 0.009599488290400084, -0.9347684985167858], Output: [-0.9966320373054919, 0.7827755783710652, -0.9748640908629232, -0.9515353774516792]\n",
      "Layer: Layer 2, Input: [-0.9966320373054919, 0.7827755783710652, -0.9748640908629232, -0.9515353774516792], Output: [-0.8062315058267275]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932506368336969, 0.4092234328487969, 0.4292223435465303, -0.8804965929923004]\n",
      "Layer: Layer 1, Input: [0.932506368336969, 0.4092234328487969, 0.4292223435465303, -0.8804965929923004], Output: [-0.98433526564447, 0.9974832792338753, -0.9260071225616634, -0.8595986138348685]\n",
      "Layer: Layer 2, Input: [-0.98433526564447, 0.9974832792338753, -0.9260071225616634, -0.8595986138348685], Output: [-1.4347554357181487]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8869411131991569, 0.9880049069152037, -0.7985443888955455, -0.9279935451973617]\n",
      "Layer: Layer 1, Input: [0.8869411131991569, 0.9880049069152037, -0.7985443888955455, -0.9279935451973617], Output: [-0.99677724587775, -0.16993080093919719, -0.9856137969727758, -0.9557568647553438]\n",
      "Layer: Layer 2, Input: [-0.99677724587775, -0.16993080093919719, -0.9856137969727758, -0.9557568647553438], Output: [0.8777090211751357]\n",
      "Epoch 404/500, Loss: 0.2064905605678805, Accuracy: -0.5153073158394195\n",
      "Power operation: base = 0.764492407123134, power = 2, grad = 0.25\n",
      "Power operation: base = 0.19376849417327247, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4347554357181487, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12229097882486428, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896885589003438, 0.9896620601906326, -0.9741923756870505, -0.9974167504883492]\n",
      "Layer: Layer 1, Input: [0.9896885589003438, 0.9896620601906326, -0.9741923756870505, -0.9974167504883492], Output: [-0.9977402484311694, -0.6670557565337251, -0.9903993337510442, -0.965105888359277]\n",
      "Layer: Layer 2, Input: [-0.9977402484311694, -0.6670557565337251, -0.9903993337510442, -0.965105888359277], Output: [1.7659130894857773]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998195748460738, 0.982106537659214, 0.009504903821082714, -0.9348016289927745]\n",
      "Layer: Layer 1, Input: [0.998195748460738, 0.982106537659214, 0.009504903821082714, -0.9348016289927745], Output: [-0.9966383072176591, 0.7836114995038844, -0.9749938765787406, -0.9517960648957643]\n",
      "Layer: Layer 2, Input: [-0.9966383072176591, 0.7836114995038844, -0.9749938765787406, -0.9517960648957643], Output: [-0.8087431327833405]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9325194047393869, 0.4099427865306624, 0.4291473194802104, -0.8805535258267718]\n",
      "Layer: Layer 1, Input: [0.9325194047393869, 0.4099427865306624, 0.4291473194802104, -0.8805535258267718], Output: [-0.9843862204356214, 0.997511915822568, -0.926404444538567, -0.8603711009798867]\n",
      "Layer: Layer 2, Input: [-0.9843862204356214, 0.997511915822568, -0.926404444538567, -0.8603711009798867], Output: [-1.4350828259855177]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.886967051129704, 0.9880255875268068, -0.798580088730996, -0.9280318975556305]\n",
      "Layer: Layer 1, Input: [0.886967051129704, 0.9880255875268068, -0.798580088730996, -0.9280318975556305], Output: [-0.9967834851684692, -0.1704975601514498, -0.985690940834968, -0.9560116783475574]\n",
      "Layer: Layer 2, Input: [-0.9967834851684692, -0.1704975601514498, -0.985690940834968, -0.9560116783475574], Output: [0.8780631747977568]\n",
      "Epoch 405/500, Loss: 0.2068419261777815, Accuracy: -0.5141896078901977\n",
      "Power operation: base = 0.7659130894857773, power = 2, grad = 0.25\n",
      "Power operation: base = 0.19125686721665947, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43508282598551773, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12193682520224325, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896915781733728, 0.9896799508157218, -0.9741977970091844, -0.9974183149858638]\n",
      "Layer: Layer 1, Input: [0.9896915781733728, 0.9896799508157218, -0.9741977970091844, -0.9974183149858638], Output: [-0.9977444011814411, -0.668125435118295, -0.9904507851253165, -0.9653112203908677]\n",
      "Layer: Layer 2, Input: [-0.9977444011814411, -0.668125435118295, -0.9904507851253165, -0.9653112203908677], Output: [1.767325080710033]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981961391822853, 0.9821371560407721, 0.009410284571214443, -0.9348346966655469]\n",
      "Layer: Layer 1, Input: [0.9981961391822853, 0.9821371560407721, 0.009410284571214443, -0.9348346966655469], Output: [-0.996644556451442, 0.7844419310791105, -0.97512280251596, -0.9520550538394577]\n",
      "Layer: Layer 2, Input: [-0.996644556451442, 0.7844419310791105, -0.97512280251596, -0.9520550538394577], Output: [-0.8112457222220897]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932532413772592, 0.4106601581584169, 0.42907225357318113, -0.8806103591223873]\n",
      "Layer: Layer 1, Input: [0.932532413772592, 0.4106601581584169, 0.42907225357318113, -0.8806103591223873], Output: [-0.9844369151371549, 0.997540108784605, -0.926799212843389, -0.8611390568542375]\n",
      "Layer: Layer 2, Input: [-0.9844369151371549, 0.997540108784605, -0.926799212843389, -0.8611390568542375], Output: [-1.4354109383758473]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8869929245655791, 0.9880461901377257, -0.7986157903732917, -0.9280701709510204]\n",
      "Layer: Layer 1, Input: [0.8869929245655791, 0.9880461901377257, -0.7986157903732917, -0.9280701709510204], Output: [-0.9967897028113686, -0.171063001382394, -0.9857675401602769, -0.9562646500644725]\n",
      "Layer: Layer 2, Input: [-0.9967897028113686, -0.171063001382394, -0.9857675401602769, -0.9562646500644725], Output: [0.878416160558789]\n",
      "Epoch 406/500, Loss: 0.2071953180341803, Accuracy: -0.5130741363050015\n",
      "Power operation: base = 0.7673250807100329, power = 2, grad = 0.25\n",
      "Power operation: base = 0.18875427777791032, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4354109383758473, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12158383944121098, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896945888436086, 0.9896977735733296, -0.974203216804145, -0.9974198757407327]\n",
      "Layer: Layer 1, Input: [0.9896945888436086, 0.9896977735733296, -0.974203216804145, -0.9974198757407327], Output: [-0.9977485398942576, -0.6691890024043013, -0.9905018670585912, -0.9655150004460404]\n",
      "Layer: Layer 2, Input: [-0.9977485398942576, -0.6691890024043013, -0.9905018670585912, -0.9655150004460404], Output: [1.768728473559415]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998196529010679, 0.9821676598334395, 0.009315630862156784, -0.9348677017420386]\n",
      "Layer: Layer 1, Input: [0.998196529010679, 0.9821676598334395, 0.009315630862156784, -0.9348677017420386], Output: [-0.9966507851190674, 0.7852669431417385, -0.975250874317402, -0.9523123537401038]\n",
      "Layer: Layer 2, Input: [-0.9966507851190674, 0.7852669431417385, -0.975250874317402, -0.9523123537401038], Output: [-0.8137392793575149]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9325453955459327, 0.4113755553523832, 0.42899714610281864, -0.880667093183013]\n",
      "Layer: Layer 1, Input: [0.9325453955459327, 0.4113755553523832, 0.42899714610281864, -0.880667093183013], Output: [-0.9844873515679191, 0.9975678667069914, -0.9271914418725296, -0.8619024964327842]\n",
      "Layer: Layer 2, Input: [-0.9844873515679191, 0.9975678667069914, -0.9271914418725296, -0.8619024964327842], Output: [-1.4357397116941026]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8870187337734045, 0.9880667151725303, -0.7986514937198934, -0.9281083656636541]\n",
      "Layer: Layer 1, Input: [0.8870187337734045, 0.9880667151725303, -0.7986514937198934, -0.9281083656636541], Output: [-0.9967958989272553, -0.17162705674191736, -0.9858435989909725, -0.9565157927646852]\n",
      "Layer: Layer 2, Input: [-0.9967958989272553, -0.17162705674191736, -0.9858435989909725, -0.9565157927646852], Output: [0.8787679633728889]\n",
      "Epoch 407/500, Loss: 0.20755070629181577, Accuracy: -0.511960942523114\n",
      "Power operation: base = 0.7687284735594151, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1862607206424851, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43573971169410264, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12123203662711113, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896975909480564, 0.9897155288330759, -0.974208635062309, -0.9974214327677351]\n",
      "Layer: Layer 1, Input: [0.9896975909480564, 0.9897155288330759, -0.974208635062309, -0.9974214327677351], Output: [-0.9977526646467499, -0.6702464587930007, -0.9905525824002793, -0.9657172403873285]\n",
      "Layer: Layer 2, Input: [-0.9977526646467499, -0.6702464587930007, -0.9905525824002793, -0.9657172403873285], Output: [1.7701233605347557]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998196917949528, 0.9821980496516929, 0.009220943029503091, -0.9349006444239435]\n",
      "Layer: Layer 1, Input: [0.998196917949528, 0.9821980496516929, 0.009220943029503091, -0.9349006444239435], Output: [-0.9966569933309762, 0.7860866047120064, -0.9753780975884359, -0.9525679740216666]\n",
      "Layer: Layer 2, Input: [-0.9966569933309762, 0.7860866047120064, -0.9753780975884359, -0.9525679740216666], Output: [-0.8162238095980641]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9325583501668441, 0.41208898560180307, 0.42892199735850345, -0.8807237283032063]\n",
      "Layer: Layer 1, Input: [0.9325583501668441, 0.41208898560180307, 0.42892199735850345, -0.8807237283032063], Output: [-0.9845375315231245, 0.9975951979871414, -0.9275811459640781, -0.8626614347840392]\n",
      "Layer: Layer 2, Input: [-0.9845375315231245, 0.9975951979871414, -0.9275811459640781, -0.8626614347840392], Output: [-1.4360690858049]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8870444790170124, 0.9880871630501022, -0.7986871986633783, -0.9281464819679017]\n",
      "Layer: Layer 1, Input: [0.8870444790170124, 0.9880871630501022, -0.7986871986633783, -0.9281464819679017], Output: [-0.9968020736351645, -0.17218965967408492, -0.9859191213366245, -0.956765119226124]\n",
      "Layer: Layer 2, Input: [-0.9968020736351645, -0.17218965967408492, -0.9859191213366245, -0.956765119226124], Output: [0.8791185683487353]\n",
      "Epoch 408/500, Loss: 0.20790806167819362, Accuracy: -0.5108500683928563\n",
      "Power operation: base = 0.7701233605347557, power = 2, grad = 0.25\n",
      "Power operation: base = 0.18377619040193593, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4360690858048999, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12088143165126475, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897005845234862, 0.9897332169597258, -0.9742140517734442, -0.9974229860814375]\n",
      "Layer: Layer 1, Input: [0.9897005845234862, 0.9897332169597258, -0.9742140517734442, -0.9974229860814375], Output: [-0.9977567755149285, -0.671297805707774, -0.9906029339754847, -0.9659179519898257]\n",
      "Layer: Layer 2, Input: [-0.9977567755149285, -0.671297805707774, -0.9906029339754847, -0.9659179519898257], Output: [1.7715098338609607]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981973060023918, 0.982228326101832, 0.00912622142265163, -0.934933524907873]\n",
      "Layer: Layer 1, Input: [0.9981973060023918, 0.982228326101832, 0.00912622142265163, -0.934933524907873], Output: [-0.9966631811958684, 0.7869009837997196, -0.9755044778977221, -0.9528219240758026]\n",
      "Layer: Layer 2, Input: [-0.9966631811958684, 0.7869009837997196, -0.9755044778977221, -0.9528219240758026], Output: [-0.8186993185541951]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9325712777408993, 0.412800456268667, 0.4288468076412724, -0.8807802647685006]\n",
      "Layer: Layer 1, Input: [0.9325712777408993, 0.412800456268667, 0.4288468076412724, -0.8807802647685006], Output: [-0.9845874567748844, 0.9976221108374934, -0.9279683393994024, -0.863415887072459]\n",
      "Layer: Layer 2, Input: [-0.9845874567748844, 0.9976221108374934, -0.9279683393994024, -0.863415887072459], Output: [-1.43639900162061]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.887070160557523, 0.9881075341837767, -0.7987229050915937, -0.9281845201325547]\n",
      "Layer: Layer 1, Input: [0.887070160557523, 0.9881075341837767, -0.7987229050915937, -0.9281845201325547], Output: [-0.9968082270524029, -0.17275074494621914, -0.9859941111746664, -0.9570126421474152]\n",
      "Layer: Layer 2, Input: [-0.9968082270524029, -0.17275074494621914, -0.9859941111746664, -0.9570126421474152], Output: [0.8794679607929696]\n",
      "Epoch 409/500, Loss: 0.20826735548193773, Accuracy: -0.5097415561344061\n",
      "Power operation: base = 0.7715098338609607, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1813006814458049, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43639900162061007, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12053203920703037, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897035696064386, 0.9897508383133109, -0.9742194669267286, -0.9974245356962013]\n",
      "Layer: Layer 1, Input: [0.9897035696064386, 0.9897508383133109, -0.9742194669267286, -0.9974245356962013], Output: [-0.99776087257371, -0.6723430455722479, -0.9906529245854064, -0.9661171469424745]\n",
      "Layer: Layer 2, Input: [-0.99776087257371, -0.6723430455722479, -0.9906529245854064, -0.9661171469424745], Output: [1.7728879854739539]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981976931727814, 0.9822584897821854, 0.009031466404386852, -0.9349663433855115]\n",
      "Layer: Layer 1, Input: [0.9981976931727814, 0.9822584897821854, 0.009031466404386852, -0.9349663433855115], Output: [-0.9966693488207463, 0.7877101474182977, -0.975630020777919, -0.9530742132628649]\n",
      "Layer: Layer 2, Input: [-0.9966693488207463, 0.7877101474182977, -0.975630020777919, -0.9530742132628649], Output: [-0.8211658120462451]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9325841783718605, 0.4135099745914575, 0.42877157726347764, -0.8808367028556853]\n",
      "Layer: Layer 1, Input: [0.9325841783718605, 0.4135099745914575, 0.42877157726347764, -0.8808367028556853], Output: [-0.9846371290727418, 0.9976486132900018, -0.9283530364046401, -0.864165868560492]\n",
      "Layer: Layer 2, Input: [-0.9846371290727418, 0.9976486132900018, -0.9283530364046401, -0.864165868560492], Output: [-1.4367294010897877]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8870957786534182, 0.988127828981482, -0.7987586128878111, -0.9282224804209924]\n",
      "Layer: Layer 1, Input: [0.8870957786534182, 0.988127828981482, -0.7987586128878111, -0.9282224804209924], Output: [-0.9968143592945898, -0.17331024863805417, -0.986068572450936, -0.9572583741491857]\n",
      "Layer: Layer 2, Input: [-0.9968143592945898, -0.17331024863805417, -0.986068572450936, -0.9572583741491857], Output: [0.8798161262140054]\n",
      "Epoch 410/500, Loss: 0.20862855954137957, Accuracy: -0.5086354483034912\n",
      "Power operation: base = 0.7728879854739539, power = 2, grad = 0.25\n",
      "Power operation: base = 0.17883418795375494, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43672940108978775, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1201838737859946, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897065462332312, 0.9897683932492463, -0.9742248805107732, -0.9974260816261866]\n",
      "Layer: Layer 1, Input: [0.9897065462332312, 0.9897683932492463, -0.9742248805107732, -0.9974260816261866], Output: [-0.9977649558969438, -0.6733821817886717, -0.9907025570077247, -0.9663148368493066]\n",
      "Layer: Layer 2, Input: [-0.9977649558969438, -0.6733821817886717, -0.9907025570077247, -0.9663148368493066], Output: [1.7742579070077484]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981980794641611, 0.9822885412833118, 0.008936678350467096, -0.9349991000437703]\n",
      "Layer: Layer 1, Input: [0.9981980794641611, 0.9822885412833118, 0.008936678350467096, -0.9349991000437703], Output: [-0.996675496310958, 0.7885141615985557, -0.9757547317263611, -0.9533248509128391]\n",
      "Layer: Layer 2, Input: [-0.996675496310958, 0.7885141615985557, -0.9757547317263611, -0.9533248509128391], Output: [-0.8236232961120571]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9325970521617283, 0.41421754768880353, 0.4286963065484503, -0.8808930428330792]\n",
      "Layer: Layer 1, Input: [0.9325970521617283, 0.41421754768880353, 0.4286963065484503, -0.8808930428330792], Output: [-0.9846865501441826, 0.997674713200508, -0.9287352511520948, -0.8649113946103896]\n",
      "Layer: Layer 2, Input: [-0.9846865501441826, 0.997674713200508, -0.9287352511520948, -0.8649113946103896], Output: [-1.4370602271859552]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8871213335606147, 0.9881480478458744, -0.7987943219308755, -0.9282603630913494]\n",
      "Layer: Layer 1, Input: [0.8871213335606147, 0.9881480478458744, -0.7987943219308755, -0.9282603630913494], Output: [-0.9968204704757004, -0.17386810813097356, -0.9861425090801996, -0.9575023277752988]\n",
      "Layer: Layer 2, Input: [-0.9968204704757004, -0.17386810813097356, -0.9861425090801996, -0.9575023277752988], Output: [0.8801630503257121]\n",
      "Epoch 411/500, Loss: 0.2089916462333677, Accuracy: -0.5075317877559344\n",
      "Power operation: base = 0.7742579070077484, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1763767038879429, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43706022718595516, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11983694967428793, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897095144399647, 0.9897858821184459, -0.9742302925136399, -0.9974276238853605]\n",
      "Layer: Layer 1, Input: [0.9897095144399647, 0.9897858821184459, -0.9742302925136399, -0.9974276238853605], Output: [-0.9977690255574382, -0.6744152187165886, -0.9907518339969744, -0.9665110332306306]\n",
      "Layer: Layer 2, Input: [-0.9977690255574382, -0.6744152187165886, -0.9907518339969744, -0.9665110332306306], Output: [1.7756196897816983]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981984648799496, 0.9823184811881949, 0.00884185764921996, -0.9350317950649352]\n",
      "Layer: Layer 1, Input: [0.9981984648799496, 0.9823184811881949, 0.00884185764921996, -0.9350317950649352], Output: [-0.9966816237702395, 0.7893130914022236, -0.9758786162057049, -0.9535738463262138]\n",
      "Layer: Layer 2, Input: [-0.9966816237702395, 0.7893130914022236, -0.9758786162057049, -0.9535738463262138], Output: [-0.8260717770143451]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326098992107902, 0.4149231825630524, 0.4286209958301697, -0.8809492849607978]\n",
      "Layer: Layer 1, Input: [0.9326098992107902, 0.4149231825630524, 0.4286209958301697, -0.8809492849607978], Output: [-0.9847357216951348, 0.9977004182529972, -0.9291149977615434, -0.8656524806857863]\n",
      "Layer: Layer 2, Input: [-0.9847357216951348, 0.9977004182529972, -0.9291149977615434, -0.8656524806857863], Output: [-1.4373914238966838]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8871468255325353, 0.9881681911744713, -0.7988300320953532, -0.9282981683966751]\n",
      "Layer: Layer 1, Input: [0.8871468255325353, 0.9881681911744713, -0.7988300320953532, -0.9282981683966751], Output: [-0.9968265607081044, -0.17442426209728265, -0.9862159249466546, -0.9577445154940348]\n",
      "Layer: Layer 2, Input: [-0.9968265607081044, -0.17442426209728265, -0.9862159249466546, -0.9577445154940348], Output: [0.8805087190509173]\n",
      "Epoch 412/500, Loss: 0.20935658846230668, Accuracy: -0.5064306176131197\n",
      "Power operation: base = 0.7756196897816983, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1739282229856549, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43739142389668384, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11949128094908268, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989712474262528, 0.9898033052674339, -0.9742357029228627, -0.9974291624875007]\n",
      "Layer: Layer 1, Input: [0.989712474262528, 0.9898033052674339, -0.9742357029228627, -0.9974291624875007], Output: [-0.9977730816269856, -0.6754421616517675, -0.9908007582849072, -0.9667057475241745]\n",
      "Layer: Layer 2, Input: [-0.9977730816269856, -0.6754421616517675, -0.9908007582849072, -0.9667057475241745], Output: [1.7769734247879079]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981988494235212, 0.982348310072436, 0.008747004701142137, -0.935064428626813]\n",
      "Layer: Layer 1, Input: [0.9981988494235212, 0.982348310072436, 0.008747004701142137, -0.935064428626813], Output: [-0.9966877313007556, 0.7901070009352203, -0.9760016796445472, -0.9538212087747894]\n",
      "Layer: Layer 2, Input: [-0.9966877313007556, 0.7901070009352203, -0.9760016796445472, -0.9538212087747894], Output: [-0.82851126124784]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326227196176681, 0.41562688610375753, 0.42854564545293694, -0.8810054294910152]\n",
      "Layer: Layer 1, Input: [0.9326227196176681, 0.41562688610375753, 0.42854564545293694, -0.8810054294910152], Output: [-0.9847846454104565, 0.9977257359637386, -0.9294922903014555, -0.8663891423530589]\n",
      "Layer: Layer 2, Input: [-0.9847846454104565, 0.9977257359637386, -0.9294922903014555, -0.8663891423530589], Output: [-1.4377229362129702]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8871722548201761, 0.9881882593597792, -0.7988657432516764, -0.9283358965850912]\n",
      "Layer: Layer 1, Input: [0.8871722548201761, 0.9881882593597792, -0.7988657432516764, -0.9283358965850912], Output: [-0.9968326301026057, -0.17497865048954986, -0.9862888239044142, -0.9579849496992093]\n",
      "Layer: Layer 2, Input: [-0.9968326301026057, -0.17497865048954986, -0.9862888239044142, -0.9579849496992093], Output: [0.8808531185248079]\n",
      "Epoch 413/500, Loss: 0.2097233596494062, Accuracy: -0.5053319812282302\n",
      "Power operation: base = 0.7769734247879079, power = 2, grad = 0.25\n",
      "Power operation: base = 0.17148873875215997, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4377229362129702, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11914688147519215, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897154257366042, 0.9898206630384546, -0.9742411117254651, -0.9974306974462022]\n",
      "Layer: Layer 1, Input: [0.9897154257366042, 0.9898206630384546, -0.9742411117254651, -0.9974306974462022], Output: [-0.9977771241763879, -0.6764630168054064, -0.990849332580839, -0.9668989910861819]\n",
      "Layer: Layer 2, Input: [-0.9977771241763879, -0.6764630168054064, -0.990849332580839, -0.9668989910861819], Output: [1.7783192026788326]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981992330982076, 0.982378028504439, 0.008652119918508483, -0.9350970009028738]\n",
      "Layer: Layer 1, Input: [0.9981992330982076, 0.982378028504439, 0.008652119918508483, -0.9350970009028738], Output: [-0.9966938190031396, 0.790895953360686, -0.9761239274380145, -0.9540669475024255]\n",
      "Layer: Layer 2, Input: [-0.9966938190031396, 0.790895953360686, -0.9761239274380145, -0.9540669475024255], Output: [-0.8309417555461724]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326355134793644, 0.41632866509108724, 0.4284702557710548, -0.8810614766682197]\n",
      "Layer: Layer 1, Input: [0.9326355134793644, 0.41632866509108724, 0.4284702557710548, -0.8810614766682197], Output: [-0.9848333229544096, 0.9977506736853198, -0.9298671427901286, -0.8671213952824718]\n",
      "Layer: Layer 2, Input: [-0.9848333229544096, 0.9977506736853198, -0.9298671427901286, -0.8671213952824718], Output: [-1.4380547101189087]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8871976216721753, 0.9882082527894199, -0.7989014552662853, -0.9283735478999448]\n",
      "Layer: Layer 1, Input: [0.8871976216721753, 0.9882082527894199, -0.7989014552662853, -0.9283735478999448], Output: [-0.9968386787684815, -0.17553121452998263, -0.9863612097779756, -0.9582236427112383]\n",
      "Layer: Layer 2, Input: [-0.9968386787684815, -0.17553121452998263, -0.9863612097779756, -0.9582236427112383], Output: [0.8811962350981553]\n",
      "Epoch 414/500, Loss: 0.21009193372215945, Accuracy: -0.5042359221534136\n",
      "Power operation: base = 0.7783192026788326, power = 2, grad = 0.25\n",
      "Power operation: base = 0.16905824445382756, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43805471011890873, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11880376490184474, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897183688976761, 0.9898379557695781, -0.9742465189079815, -0.9974322287748822]\n",
      "Layer: Layer 1, Input: [0.9897183688976761, 0.9898379557695781, -0.9742465189079815, -0.9974322287748822], Output: [-0.9977811532754794, -0.6774777912835976, -0.9908975595719884, -0.9670907751924643]\n",
      "Layer: Layer 2, Input: [-0.9977811532754794, -0.6774777912835976, -0.9908975595719884, -0.9670907751924643], Output: [1.779657113755042]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981996159072978, 0.9824076370455932, 0.008557203724984815, -0.9351295120623909]\n",
      "Layer: Layer 1, Input: [0.9981996159072978, 0.9824076370455932, 0.008557203724984815, -0.9351295120623909], Output: [-0.9966998869765316, 0.7916800109117804, -0.9762453649483264, -0.9543110717257322]\n",
      "Layer: Layer 2, Input: [-0.9966998869765316, 0.7916800109117804, -0.9762453649483264, -0.9543110717257322], Output: [-0.8333632668885098]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326482808913068, 0.4170285261991534, 0.42839482714851135, -0.8811174267294641]\n",
      "Layer: Layer 1, Input: [0.9326482808913068, 0.4170285261991534, 0.42839482714851135, -0.8811174267294641], Output: [-0.9848817559711222, 0.9977752386105715, -0.9302395691967462, -0.8678492552491175]\n",
      "Layer: Layer 2, Input: [-0.9848817559711222, 0.9977752386105715, -0.9302395691967462, -0.8678492552491175], Output: [-1.4383866925816102]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8872229263348764, 0.9882281718462533, -0.798937168001768, -0.9284111225799596]\n",
      "Layer: Layer 1, Input: [0.8872229263348764, 0.9882281718462533, -0.798937168001768, -0.9284111225799596], Output: [-0.9968447068135187, -0.17608189669984145, -0.9864330863626697, -0.9584606067781499]\n",
      "Layer: Layer 2, Input: [-0.9968447068135187, -0.17608189669984145, -0.9864330863626697, -0.9584606067781499], Output: [0.8815380553404255]\n",
      "Epoch 415/500, Loss: 0.21046228510402099, Accuracy: -0.503142484107717\n",
      "Power operation: base = 0.7796571137550421, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1666367331114902, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4383866925816102, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11846194465957449, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897213037810306, 0.9898551837948047, -0.9742519244564735, -0.9974337564867862]\n",
      "Layer: Layer 1, Input: [0.9897213037810306, 0.9898551837948047, -0.9742519244564735, -0.9974337564867862], Output: [-0.9977851689931512, -0.6784864930670568, -0.9909454419238014, -0.967281111039413]\n",
      "Layer: Layer 2, Input: [-0.9977851689931512, -0.6784864930670568, -0.9909454419238014, -0.967281111039413], Output: [1.7809872479531883]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9981999978540406, 0.98243713625045, 0.008462256555248836, -0.9351619622705755]\n",
      "Layer: Layer 1, Input: [0.9981999978540406, 0.98243713625045, 0.008462256555248836, -0.9351619622705755], Output: [-0.9967059353186182, 0.7924592349042605, -0.9763659975053331, -0.9545535906347054]\n",
      "Layer: Layer 2, Input: [-0.9967059353186182, 0.7924592349042605, -0.9763659975053331, -0.9545535906347054], Output: [-0.8357758025059603]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326610219473938, 0.4177264759992637, 0.42831935995866965, -0.8811732799046107]\n",
      "Layer: Layer 1, Input: [0.9326610219473938, 0.4177264759992637, 0.42831935995866965, -0.8811732799046107], Output: [-0.9849299460850387, 0.9977994377763912, -0.9306095834423574, -0.8685727381336588]\n",
      "Layer: Layer 2, Input: [-0.9849299460850387, 0.9977994377763912, -0.9306095834423574, -0.8685727381336588], Output: [-1.4387188315413786]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8872481690523927, 0.9882480169084964, -0.7989728813169978, -0.9284486208593813]\n",
      "Layer: Layer 1, Input: [0.8872481690523927, 0.9882480169084964, -0.7989728813169978, -0.9284486208593813], Output: [-0.9968507143440516, -0.17663064072888288, -0.9865044574250957, -0.9586958540765447]\n",
      "Layer: Layer 2, Input: [-0.9968507143440516, -0.17663064072888288, -0.9865044574250957, -0.9586958540765447], Output: [0.8818785660427215]\n",
      "Epoch 416/500, Loss: 0.21083438870430313, Accuracy: -0.5020517109458851\n",
      "Power operation: base = 0.7809872479531883, power = 2, grad = 0.25\n",
      "Power operation: base = 0.16422419749403971, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4387188315413786, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11812143395727848, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897242304217644, 0.9898723474441661, -0.9742573283565481, -0.9974352805949913]\n",
      "Layer: Layer 1, Input: [0.9897242304217644, 0.9898723474441661, -0.9742573283565481, -0.9974352805949913], Output: [-0.9977891713973742, -0.6794891309911052, -0.9909929822802677, -0.9674700097449684]\n",
      "Layer: Layer 2, Input: [-0.9977891713973742, -0.6794891309911052, -0.9909929822802677, -0.9674700097449684], Output: [1.782309694834165]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998200378941645, 0.9824665266668959, 0.008367278854617227, -0.9351943516887105]\n",
      "Layer: Layer 1, Input: [0.998200378941645, 0.9824665266668959, 0.008367278854617227, -0.9351943516887105], Output: [-0.9967119641256681, 0.7932336857488406, -0.9764858304070283, -0.9547945133933069]\n",
      "Layer: Layer 2, Input: [-0.9967119641256681, 0.7932336857488406, -0.9764858304070283, -0.9547945133933069], Output: [-0.8381793698877251]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326737367400361, 0.4184225209630983, 0.42824385458396097, -0.8812290364165708]\n",
      "Layer: Layer 1, Input: [0.9326737367400361, 0.4184225209630983, 0.42824385458396097, -0.8812290364165708], Output: [-0.9849778949013586, 0.9978232780674645, -0.9309771994007848, -0.8692918599228808]\n",
      "Layer: Layer 2, Input: [-0.9849778949013586, 0.9978232780674645, -0.9309771994007848, -0.8692918599228808], Output: [-1.439051075902123]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.887273350066668, 0.9882677883498405, -0.7990085950672688, -0.9284860429681209]\n",
      "Layer: Layer 1, Input: [0.887273350066668, 0.9882677883498405, -0.7990085950672688, -0.9284860429681209], Output: [-0.9968567014649958, -0.1771773915848332, -0.9865753267035395, -0.9589293967125062]\n",
      "Layer: Layer 2, Input: [-0.9968567014649958, -0.1771773915848332, -0.9865753267035395, -0.9589293967125062], Output: [0.8822177542206111]\n",
      "Epoch 417/500, Loss: 0.21120821990827654, Accuracy: -0.5009636466279517\n",
      "Power operation: base = 0.782309694834165, power = 2, grad = 0.25\n",
      "Power operation: base = 0.16182063011227488, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4390510759021229, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1177822457793889, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897271488547879, 0.9898894470438235, -0.9742627305933774, -0.9974368011124137]\n",
      "Layer: Layer 1, Input: [0.9897271488547879, 0.9898894470438235, -0.9742627305933774, -0.9974368011124137], Output: [-0.9977931605552214, -0.6804857147259148, -0.9910401832642235, -0.967657482349553]\n",
      "Layer: Layer 2, Input: [-0.9977931605552214, -0.6804857147259148, -0.9910401832642235, -0.967657482349553], Output: [1.783624543571455]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982007591732817, 0.982495808836321, 0.008272271078675852, -0.9352266804742811]\n",
      "Layer: Layer 1, Input: [0.9982007591732817, 0.982495808836321, 0.008272271078675852, -0.9352266804742811], Output: [-0.9967179734925697, 0.7940034229633407, -0.9766048689200383, -0.9550338491399983]\n",
      "Layer: Layer 2, Input: [-0.9967179734925697, 0.7940034229633407, -0.9766048689200383, -0.9550338491399983], Output: [-0.840573976786998]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326864253602006, 0.4191166674658127, 0.42816831141558337, -0.8812846964815387]\n",
      "Layer: Layer 1, Input: [0.9326864253602006, 0.4191166674658127, 0.42816831141558337, -0.8812846964815387], Output: [-0.9850256040064641, 0.9978467662198903, -0.9313424308994607, -0.87000663671006]\n",
      "Layer: Layer 2, Input: [-0.9850256040064641, 0.9978467662198903, -0.9313424308994607, -0.87000663671006], Output: [-1.4393833755219898]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8872984696175368, 0.9882874865395646, -0.799044309104427, -0.9285233891318936]\n",
      "Layer: Layer 1, Input: [0.8872984696175368, 0.9882874865395646, -0.799044309104427, -0.9285233891318936], Output: [-0.9968626682798859, -0.17772209546286608, -0.9866456979083772, -0.9591612467224667]\n",
      "Layer: Layer 2, Input: [-0.9968626682798859, -0.17772209546286608, -0.9866456979083772, -0.9591612467224667], Output: [0.8825556071167888]\n",
      "Epoch 418/500, Loss: 0.211583754567472, Accuracy: -0.4998783351896581\n",
      "Power operation: base = 0.7836245435714551, power = 2, grad = 0.25\n",
      "Power operation: base = 0.15942602321300203, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4393833755219898, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11744439288321118, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897300591148307, 0.989906482916165, -0.9742681311517144, -0.9974383180518112]\n",
      "Layer: Layer 1, Input: [0.9897300591148307, 0.989906482916165, -0.9742681311517144, -0.9974383180518112], Output: [-0.9977971365328897, -0.6814762547569927, -0.9910870474776481, -0.9678435398169658]\n",
      "Layer: Layer 2, Input: [-0.9977971365328897, -0.6814762547569927, -0.9910870474776481, -0.9678435398169658], Output: [1.7849318829396967]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982011385520838, 0.9825249832937838, 0.008177233692919741, -0.9352589487811012]\n",
      "Layer: Layer 1, Input: [0.9982011385520838, 0.9825249832937838, 0.008177233692919741, -0.9352589487811012], Output: [-0.9967239635128659, 0.7947685051846385, -0.9767231182800891, -0.9552716069882207]\n",
      "Layer: Layer 2, Input: [-0.9967239635128659, 0.7947685051846385, -0.9767231182800891, -0.9552716069882207], Output: [-0.8429596312266323]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9326990878974506, 0.4198089217890692, 0.42809273085320526, -0.8813402603092214]\n",
      "Layer: Layer 1, Input: [0.9326990878974506, 0.4198089217890692, 0.42809273085320526, -0.8813402603092214], Output: [-0.9850730749683365, 0.9978699088247107, -0.9317052917201986, -0.8707170846951572]\n",
      "Layer: Layer 2, Input: [-0.9850730749683365, 0.9978699088247107, -0.9317052917201986, -0.8707170846951572], Output: [-1.4397156812041967]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8873235279427819, 0.9883071118426461, -0.7990800232770024, -0.9285606595723567]\n",
      "Layer: Layer 1, Input: [0.8873235279427819, 0.9883071118426461, -0.7990800232770024, -0.9285606595723567], Output: [-0.9968686148909058, -0.17826469977511447, -0.9867155747224637, -0.9593914160740264]\n",
      "Layer: Layer 2, Input: [-0.9968686148909058, -0.17826469977511447, -0.9867155747224637, -0.9593914160740264], Output: [0.882892112203626]\n",
      "Epoch 419/500, Loss: 0.211960968990183, Accuracy: -0.49879582071363515\n",
      "Power operation: base = 0.7849318829396967, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1570403687733677, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4397156812041967, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11710788779637404, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897329612364455, 0.9899234553798986, -0.9742735300159101, -0.9974398314257897]\n",
      "Layer: Layer 1, Input: [0.9897329612364455, 0.9899234553798986, -0.9742735300159101, -0.9974398314257897], Output: [-0.9978010993957214, -0.6824607623659306, -0.9911335775019473, -0.968028193035243]\n",
      "Layer: Layer 2, Input: [-0.9978010993957214, -0.6824607623659306, -0.9911335775019473, -0.968028193035243], Output: [1.786231801303452]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982015170811481, 0.9825540505681711, 0.008082167172397552, -0.9352911567594377]\n",
      "Layer: Layer 1, Input: [0.9982015170811481, 0.9825540505681711, 0.008082167172397552, -0.9352911567594377], Output: [-0.9967299342787882, 0.7955289901804203, -0.9768405836924499, -0.9555077960268314]\n",
      "Layer: Layer 2, Input: [-0.9967299342787882, 0.7955289901804203, -0.9768405836924499, -0.9555077960268314], Output: [-0.8453363415045638]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9327117244399866, 0.42049929012399695, 0.42801711330467274, -0.8813957281030622]\n",
      "Layer: Layer 1, Input: [0.9327117244399866, 0.42049929012399695, 0.42801711330467274, -0.8813957281030622], Output: [-0.9851203093369617, 0.997892712331349, -0.9320657955998987, -0.8714232201848426]\n",
      "Layer: Layer 2, Input: [-0.9851203093369617, 0.997892712331349, -0.9320657955998987, -0.8714232201848426], Output: [-1.440047944688068]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8873485252781913, 0.9883266646198697, -0.7991157374303356, -0.9285978545072412]\n",
      "Layer: Layer 1, Input: [0.8873485252781913, 0.9883266646198697, -0.7991157374303356, -0.9285978545072412], Output: [-0.9968745413989252, -0.17880515314017806, -0.986784960801508, -0.9596199166667309]\n",
      "Layer: Layer 2, Input: [-0.9968745413989252, -0.17880515314017806, -0.986784960801508, -0.9596199166667309], Output: [0.8832272571855695]\n",
      "Epoch 420/500, Loss: 0.21233983993216543, Accuracy: -0.4977161473013867\n",
      "Power operation: base = 0.7862318013034519, power = 2, grad = 0.25\n",
      "Power operation: base = 0.15466365849543617, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44004794468806807, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11677274281443051, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897358552540122, 0.9899403647501442, -0.9742789271699317, -0.9974413412468066]\n",
      "Layer: Layer 1, Input: [0.9897358552540122, 0.9899403647501442, -0.9742789271699317, -0.9974413412468066], Output: [-0.9978050492082255, -0.6834392496113859, -0.99117977589823, -0.9682114528174837]\n",
      "Layer: Layer 2, Input: [-0.9978050492082255, -0.6834392496113859, -0.99117977589823, -0.9682114528174837], Output: [1.7875243866061883]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982018947635362, 0.9825830111823547, 0.007987072001359317, -0.9353233045561324]\n",
      "Layer: Layer 1, Input: [0.9982018947635362, 0.9825830111823547, 0.007987072001359317, -0.9353233045561324], Output: [-0.9967358858812916, 0.7962849348607492, -0.9769572703323587, -0.9557424253204951]\n",
      "Layer: Layer 2, Input: [-0.9967358858812916, 0.7962849348607492, -0.9769572703323587, -0.9557424253204951], Output: [-0.8477041161989778]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9327243350746857, 0.421187778574083, 0.42794145918572185, -0.8814511000604601]\n",
      "Layer: Layer 1, Input: [0.9327243350746857, 0.421187778574083, 0.42794145918572185, -0.8814511000604601], Output: [-0.9851673086447261, 0.9979151830509589, -0.9324239562311939, -0.8721250595923583]\n",
      "Layer: Layer 2, Input: [-0.9851673086447261, 0.9979151830509589, -0.9324239562311939, -0.8721250595923583], Output: [-1.4403801186402525]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.887373461857613, 0.9883461452279324, -0.7991514514067045, -0.9286349741504833]\n",
      "Layer: Layer 1, Input: [0.887373461857613, 0.9883461452279324, -0.7991514514067045, -0.9286349741504833], Output: [-0.9968804479035298, -0.17934340537263585, -0.9868538597744354, -0.9598467603328055]\n",
      "Layer: Layer 2, Input: [-0.9968804479035298, -0.17934340537263585, -0.9868538597744354, -0.9598467603328055], Output: [0.8835610300013998]\n",
      "Epoch 421/500, Loss: 0.21272034458753133, Accuracy: -0.49663935904606316\n",
      "Power operation: base = 0.7875243866061883, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1522958838010222, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4403801186402525, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11643896999860015, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897387412017425, 0.9899572113385229, -0.9742843225973773, -0.9974428475271763]\n",
      "Layer: Layer 1, Input: [0.9897387412017425, 0.9899572113385229, -0.9742843225973773, -0.9974428475271763], Output: [-0.9978089860340978, -0.6844117293103184, -0.9912256452075743, -0.968393329902643]\n",
      "Layer: Layer 2, Input: [-0.9978089860340978, -0.6844117293103184, -0.9912256452075743, -0.968393329902643], Output: [1.7888097263594789]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982022716022751, 0.9826118656533436, 0.007891948672914192, -0.93535539231472]\n",
      "Layer: Layer 1, Input: [0.9982022716022751, 0.9826118656533436, 0.007891948672914192, -0.93535539231472], Output: [-0.9967418184100869, 0.7970363952894473, -0.9770731833454258, -0.9559755039100305]\n",
      "Layer: Layer 2, Input: [-0.9967418184100869, 0.7970363952894473, -0.9770731833454258, -0.9559755039100305], Output: [-0.8500629641732553]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.93273691988714, 0.42187439315799635, 0.4278657689196955, -0.8815063763729846]\n",
      "Layer: Layer 1, Input: [0.93273691988714, 0.42187439315799635, 0.4278657689196955, -0.8815063763729846], Output: [-0.985214074406801, 0.9979373271596856, -0.9327797872630356, -0.8728226194372254]\n",
      "Layer: Layer 2, Input: [-0.985214074406801, 0.9979373271596856, -0.9327797872630356, -0.8728226194372254], Output: [-1.4407121566461054]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.887398337913008, 0.9883655540195462, -0.7991871650454473, -0.9286720187123496]\n",
      "Layer: Layer 1, Input: [0.887398337913008, 0.9883655540195462, -0.7991871650454473, -0.9286720187123496], Output: [-0.9968863345030546, -0.17987940747255182, -0.9869222752437361, -0.960071958837854]\n",
      "Layer: Layer 2, Input: [-0.9968863345030546, -0.17987940747255182, -0.9869222752437361, -0.960071958837854], Output: [0.8838934188263394]\n",
      "Epoch 422/500, Loss: 0.2131024605798309, Accuracy: -0.49556550000598953\n",
      "Power operation: base = 0.7888097263594789, power = 2, grad = 0.25\n",
      "Power operation: base = 0.14993703582674467, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4407121566461054, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11610658117366057, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897416191136833, 0.9899739954532438, -0.974289716281493, -0.997444350279074]\n",
      "Layer: Layer 1, Input: [0.9897416191136833, 0.9899739954532438, -0.974289716281493, -0.997444350279074], Output: [-0.9978129099362402, -0.6853782150194673, -0.9912711879512859, -0.9685738349562956]\n",
      "Layer: Layer 2, Input: [-0.9978129099362402, -0.6853782150194673, -0.9912711879512859, -0.9685738349562956], Output: [1.7900879076324259]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982026476003588, 0.982640614492433, 0.007796797688690627, -0.9353874201755444]\n",
      "Layer: Layer 1, Input: [0.9982026476003588, 0.982640614492433, 0.007796797688690627, -0.9353874201755444], Output: [-0.9967477319536738, 0.7977834266953008, -0.9771883278480185, -0.9562070408127186]\n",
      "Layer: Layer 2, Input: [-0.9967477319536738, 0.7977834266953008, -0.9771883278480185, -0.9562070408127186], Output: [-0.8524128945806497]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932749478961695, 0.4225591398123455, 0.42779004293726436, -0.8815615572265844]\n",
      "Layer: Layer 1, Input: [0.932749478961695, 0.4225591398123455, 0.42779004293726436, -0.8815615572265844], Output: [-0.9852606081215189, 0.9979591507018442, -0.9331333023012262, -0.8735159163448032]\n",
      "Layer: Layer 2, Input: [-0.9852606081215189, 0.9979591507018442, -0.9331333023012262, -0.8735159163448032], Output: [-1.4410440132012265]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8874231536745028, 0.9883848913435387, -0.7992228781830844, -0.9287089883995626]\n",
      "Layer: Layer 1, Input: [0.8874231536745028, 0.9883848913435387, -0.7992228781830844, -0.9287089883995626], Output: [-0.996892201294613, -0.18041311161501508, -0.9869902107858013, -0.9602955238815163]\n",
      "Layer: Layer 2, Input: [-0.996892201294613, -0.18041311161501508, -0.9869902107858013, -0.9602955238815163], Output: [0.8842244120740945]\n",
      "Epoch 423/500, Loss: 0.21348616595331998, Accuracy: -0.49449461417890817\n",
      "Power operation: base = 0.7900879076324259, power = 2, grad = 0.25\n",
      "Power operation: base = 0.14758710541935027, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44104401320122655, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11577558792590548, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897444890237209, 0.9899907173991896, -0.974295108205189, -0.9974458495145397]\n",
      "Layer: Layer 1, Input: [0.9897444890237209, 0.9899907173991896, -0.974295108205189, -0.9974458495145397], Output: [-0.9978168209767809, -0.6863387210170605, -0.991316406631148, -0.9687529785713674]\n",
      "Layer: Layer 2, Input: [-0.9978168209767809, -0.6863387210170605, -0.991316406631148, -0.9687529785713674], Output: [1.7913590170413087]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982030227607487, 0.9826692582053494, 0.007701619558501725, -0.9354193882758726]\n",
      "Layer: Layer 1, Input: [0.9982030227607487, 0.9826692582053494, 0.007701619558501725, -0.9354193882758726], Output: [-0.9967536265993707, 0.7985260834830982, -0.9773027089276272, -0.9564370450225694]\n",
      "Layer: Layer 2, Input: [-0.9967536265993707, 0.7985260834830982, -0.9773027089276272, -0.9564370450225694], Output: [-0.8547539168687583]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9327620123814856, 0.4232420243943711, 0.4277142816761514, -0.881616642801794]\n",
      "Layer: Layer 1, Input: [0.9327620123814856, 0.4232420243943711, 0.4277142816761514, -0.881616642801794], Output: [-0.9853069112707391, 0.997980659593015, -0.9334845149088951, -0.8742049670457058]\n",
      "Layer: Layer 2, Input: [-0.9853069112707391, 0.997980659593015, -0.9334845149088951, -0.8742049670457058], Output: [-1.44137564370316]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.887447909370439, 0.9884041575449507, -0.7992585906534377, -0.9287458834154207]\n",
      "Layer: Layer 1, Input: [0.887447909370439, 0.9884041575449507, -0.7992585906534377, -0.9287458834154207], Output: [-0.9968980483741282, -0.18094447113961734, -0.9870576699512492, -0.9605174670980924]\n",
      "Layer: Layer 2, Input: [-0.9968980483741282, -0.18094447113961734, -0.9870576699512492, -0.9605174670980924], Output: [0.8845539983986637]\n",
      "Epoch 424/500, Loss: 0.2138714391644171, Accuracy: -0.4934267454770467\n",
      "Power operation: base = 0.7913590170413087, power = 2, grad = 0.25\n",
      "Power operation: base = 0.14524608313124165, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44137564370315996, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11544600160133633, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897473509655844, 0.9900073774779986, -0.9743004983510551, -0.9974473452454835]\n",
      "Layer: Layer 1, Input: [0.9897473509655844, 0.9900073774779986, -0.9743004983510551, -0.9974473452454835], Output: [-0.9978207192170939, -0.6872932622847793, -0.9913613037296635, -0.9689307712688412]\n",
      "Layer: Layer 2, Input: [-0.9978207192170939, -0.6872932622847793, -0.9913613037296635, -0.9689307712688412], Output: [1.7926231407394786]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982033970863748, 0.9826977972923916, 0.007606414800018515, -0.9354512967500046]\n",
      "Layer: Layer 1, Input: [0.9982033970863748, 0.9826977972923916, 0.007606414800018515, -0.9354512967500046], Output: [-0.9967595024333477, 0.7992644192445003, -0.9774163316432163, -0.9566655255105544]\n",
      "Layer: Layer 2, Input: [-0.9967595024333477, 0.7992644192445003, -0.9774163316432163, -0.9566655255105544], Output: [-0.8570860407837202]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9327745202284728, 0.4239230526845752, 0.4276384855808624, -0.881671633273933]\n",
      "Layer: Layer 1, Input: [0.9327745202284728, 0.4239230526845752, 0.4276384855808624, -0.881671633273933], Output: [-0.9853529853202031, 0.9980018596230599, -0.9338334386069268, -0.8748897883750821]\n",
      "Layer: Layer 2, Input: [-0.9853529853202031, 0.9980018596230599, -0.9338334386069268, -0.8748897883750821], Output: [-1.4417070044432183]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8874726052274232, 0.9884233529651322, -0.7992943022877479, -0.9287827039599178]\n",
      "Layer: Layer 1, Input: [0.8874726052274232, 0.9884233529651322, -0.7992943022877479, -0.9287827039599178], Output: [-0.9969038758363623, -0.1814734405399685, -0.9871246562652378, -0.9607378000571316]\n",
      "Layer: Layer 2, Input: [-0.9969038758363623, -0.1814734405399685, -0.9871246562652378, -0.9607378000571316], Output: [0.8848821666961024]\n",
      "Epoch 425/500, Loss: 0.21425825907334323, Accuracy: -0.4923619377028743\n",
      "Power operation: base = 0.7926231407394786, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1429139592162798, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4417070044432183, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11511783330389758, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897502049728493, 0.990023975988146, -0.9743058867013746, -0.997448837483688]\n",
      "Layer: Layer 1, Input: [0.9897502049728493, 0.990023975988146, -0.9743058867013746, -0.997448837483688], Output: [-0.9978246047178163, -0.6882418544899307, -0.9914058817102892, -0.9691072234984329]\n",
      "Layer: Layer 2, Input: [-0.9978246047178163, -0.6882418544899307, -0.9914058817102892, -0.9691072234984329], Output: [1.7938803644074328]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982037705801367, 0.9827262322485687, 0.007511183938447329, -0.9354831457293823]\n",
      "Layer: Layer 1, Input: [0.9982037705801367, 0.9827262322485687, 0.007511183938447329, -0.9354831457293823], Output: [-0.9967653595406545, 0.7999984867687541, -0.9775292010255534, -0.9568924912247992]\n",
      "Layer: Layer 2, Input: [-0.9967653595406545, 0.7999984867687541, -0.9775292010255534, -0.9568924912247992], Output: [-0.8594092763742154]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9327870025834787, 0.4246022303892876, 0.4275626551024196, -0.8817265288133032]\n",
      "Layer: Layer 1, Input: [0.9327870025834787, 0.4246022303892876, 0.4275626551024196, -0.8817265288133032], Output: [-0.9853988317198835, 0.9980227564590614, -0.9341800868743391, -0.8755703972717669]\n",
      "Layer: Layer 2, Input: [-0.9853988317198835, 0.9980227564590614, -0.9341800868743391, -0.8755703972717669], Output: [-1.4420380525984395]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8874972414703735, 0.9884424779418343, -0.7993300129147892, -0.9288194502298563]\n",
      "Layer: Layer 1, Input: [0.8874972414703735, 0.9884424779418343, -0.7993300129147892, -0.9288194502298563], Output: [-0.9969096837749448, -0.18199997545316773, -0.9871911732277675, -0.9609565342639883]\n",
      "Layer: Layer 2, Input: [-0.9969096837749448, -0.18199997545316773, -0.9871911732277675, -0.9609565342639883], Output: [0.8852089061060857]\n",
      "Epoch 426/500, Loss: 0.2146466049359206, Accuracy: -0.49130023452557126\n",
      "Power operation: base = 0.7938803644074328, power = 2, grad = 0.25\n",
      "Power operation: base = 0.14059072362578462, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44203805259843953, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11479109389391429, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897530510789405, 0.9900405132250221, -0.9743112732381409, -0.9974503262408141]\n",
      "Layer: Layer 1, Input: [0.9897530510789405, 0.9900405132250221, -0.9743112732381409, -0.9974503262408141], Output: [-0.997828477538867, -0.6891845139678914, -0.9914501430176627, -0.9692823456392434]\n",
      "Layer: Layer 2, Input: [-0.997828477538867, -0.6891845139678914, -0.9914501430176627, -0.9692823456392434], Output: [1.795130773243196]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998204143244904, 0.9827545635637346, 0.007415927506210416, -0.9355149353426954]\n",
      "Layer: Layer 1, Input: [0.998204143244904, 0.9827545635637346, 0.007415927506210416, -0.9355149353426954], Output: [-0.996771198005251, 0.8007283380532433, -0.9776413220775283, -0.9571179510907468]\n",
      "Layer: Layer 2, Input: [-0.996771198005251, 0.8007283380532433, -0.9776413220775283, -0.9571179510907468], Output: [-0.8617236339951813]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.932799459526221, 0.4252795631431726, 0.4274867906980981, -0.8817813295853796]\n",
      "Layer: Layer 1, Input: [0.932799459526221, 0.4252795631431726, 0.4274867906980981, -0.8817813295853796], Output: [-0.9854444519043211, 0.9980433556481857, -0.9345244731486155, -0.8762468107773066]\n",
      "Layer: Layer 2, Input: [-0.9854444519043211, 0.9980433556481857, -0.9345244731486155, -0.8762468107773066], Output: [-1.4423687462236536]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8875218183225668, 0.9884615328093008, -0.7993657223609829, -0.9288561224189623]\n",
      "Layer: Layer 1, Input: [0.8875218183225668, 0.9884615328093008, -0.7993657223609829, -0.9288561224189623], Output: [-0.9969154722824008, -0.18252403264928996, -0.9872572243139736, -0.9611736811603485]\n",
      "Layer: Layer 2, Input: [-0.9969154722824008, -0.18252403264928996, -0.9872572243139736, -0.9611736811603485], Output: [0.8855342060134195]\n",
      "Epoch 427/500, Loss: 0.21503645639557176, Accuracy: -0.4902416794582489\n",
      "Power operation: base = 0.795130773243196, power = 2, grad = 0.25\n",
      "Power operation: base = 0.13827636600481874, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44236874622365363, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11446579398658052, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897558893171364, 0.99005698948101, -0.9743166579430717, -0.9974518115284035]\n",
      "Layer: Layer 1, Input: [0.9897558893171364, 0.99005698948101, -0.9743166579430717, -0.9974518115284035], Output: [-0.9978323377394649, -0.6901212577047512, -0.9914940900778227, -0.969456148000386]\n",
      "Layer: Layer 2, Input: [-0.9978323377394649, -0.6901212577047512, -0.9914940900778227, -0.969456148000386], Output: [1.7963744519528904]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982045150835179, 0.9827827917227192, 0.007320646042636019, -0.9355466657159835]\n",
      "Layer: Layer 1, Input: [0.9982045150835179, 0.9827827917227192, 0.007320646042636019, -0.9355466657159835], Output: [-0.996777017910036, 0.8014540243139014, -0.9777526997744519, -0.9573419140112847]\n",
      "Layer: Layer 2, Input: [-0.996777017910036, 0.8014540243139014, -0.9777526997744519, -0.9573419140112847], Output: [-0.8640291243113447]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328118911353466, 0.4259550565116752, 0.4274108928311699, -0.8818360357509987]\n",
      "Layer: Layer 1, Input: [0.9328118911353466, 0.4259550565116752, 0.4274108928311699, -0.8818360357509987], Output: [-0.9854898472929551, 0.9980636626204737, -0.9348666108259945, -0.8769190460348674]\n",
      "Layer: Layer 2, Input: [-0.9854898472929551, 0.9980636626204737, -0.9348666108259945, -0.8769190460348674], Output: [-1.4426990442436738]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8875463360056832, 0.9884805178983563, -0.7994014304505086, -0.9288927207179934]\n",
      "Layer: Layer 1, Input: [0.8875463360056832, 0.9884805178983563, -0.7994014304505086, -0.9288927207179934], Output: [-0.9969212414501788, -0.183045570020827, -0.9873228129744082, -0.9613892521247256]\n",
      "Layer: Layer 2, Input: [-0.9969212414501788, -0.183045570020827, -0.9873228129744082, -0.9613892521247256], Output: [0.8858580560493445]\n",
      "Epoch 428/500, Loss: 0.21542779347547575, Accuracy: -0.4891863158358749\n",
      "Power operation: base = 0.7963744519528904, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1359708756886553, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4426990442436738, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11414194395065547, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897587197205712, 0.9900734050455594, -0.9743220407976223, -0.9974532933578827]\n",
      "Layer: Layer 1, Input: [0.9897587197205712, 0.9900734050455594, -0.9743220407976223, -0.9974532933578827], Output: [-0.997836185378145, -0.6910521033202053, -0.9915377252984228, -0.9696286408215881]\n",
      "Layer: Layer 2, Input: [-0.997836185378145, -0.6910521033202053, -0.9915377252984228, -0.9696286408215881], Output: [1.7976114847415579]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982048860987914, 0.9828109172054558, 0.007225340093648529, -0.9355783369727395]\n",
      "Layer: Layer 1, Input: [0.9982048860987914, 0.9828109172054558, 0.007225340093648529, -0.9355783369727395], Output: [-0.9967828193368742, 0.802175595995468, -0.9778633390643431, -0.9575643888668444]\n",
      "Layer: Layer 2, Input: [-0.9967828193368742, 0.802175595995468, -0.9778633390643431, -0.9575643888668444], Output: [-0.8663257583004889]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328242974884647, 0.4266287159934083, 0.4273349619706479, -0.8818906474665406]\n",
      "Layer: Layer 1, Input: [0.9328242974884647, 0.4266287159934083, 0.4273349619706479, -0.8818906474665406], Output: [-0.9855350192904446, 0.9980836826915607, -0.9352065132617146, -0.8775871202880314]\n",
      "Layer: Layer 2, Input: [-0.9855350192904446, 0.9980836826915607, -0.9352065132617146, -0.8775871202880314], Output: [-1.4430289064455737]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8875707947398498, 0.9884994335364924, -0.7994371370054132, -0.9289292453148474]\n",
      "Layer: Layer 1, Input: [0.8875707947398498, 0.9884994335364924, -0.7994371370054132, -0.9289292453148474], Output: [-0.9969269913686756, -0.18356454657213317, -0.9873879426353125, -0.9616032584729274]\n",
      "Layer: Layer 2, Input: [-0.9969269913686756, -0.18356454657213317, -0.9873879426353125, -0.9616032584729274], Output: [0.8861804460927702]\n",
      "Epoch 429/500, Loss: 0.21582059657089334, Accuracy: -0.48813418679387244\n",
      "Power operation: base = 0.7976114847415579, power = 2, grad = 0.25\n",
      "Power operation: base = 0.13367424169951114, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4430289064455737, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11381955390722975, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897615423222379, 0.9900897602052601, -0.9743274217830019, -0.9974547717405673]\n",
      "Layer: Layer 1, Input: [0.9897615423222379, 0.9900897602052601, -0.9743274217830019, -0.9974547717405673], Output: [-0.9978400205127761, -0.6919770690506704, -0.9915810510689367, -0.9697998342737716]\n",
      "Layer: Layer 2, Input: [-0.9978400205127761, -0.6919770690506704, -0.9915810510689367, -0.9697998342737716], Output: [1.7988419553042307]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982052562935106, 0.9828389404871057, 0.007130010211468462, -0.9356099492340052]\n",
      "Layer: Layer 1, Input: [0.9982052562935106, 0.9828389404871057, 0.007130010211468462, -0.9356099492340052], Output: [-0.9967886023666244, 0.8028931027816101, -0.9779732448681996, -0.9577853845154687]\n",
      "Layer: Layer 2, Input: [-0.9967886023666244, 0.8028931027816101, -0.9779732448681996, -0.9577853845154687], Output: [-0.8686135472565066]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328366786621788, 0.42730054702248316, 0.427258998591037, -0.8819451648841101]\n",
      "Layer: Layer 1, Input: [0.9328366786621788, 0.42730054702248316, 0.427258998591037, -0.8819451648841101], Output: [-0.9855799692869812, 0.9981034210653266, -0.9355441937702238, -0.8782510508794842]\n",
      "Layer: Layer 2, Input: [-0.9855799692869812, 0.9981034210653266, -0.9355441937702238, -0.8782510508794842], Output: [-1.4433582934710563]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8875951947436824, 0.9885182800479513, -0.7994728418457185, -0.9289656963946666]\n",
      "Layer: Layer 1, Input: [0.8875951947436824, 0.9885182800479513, -0.7994728418457185, -0.9289656963946666], Output: [-0.9969327221272655, -0.18408092240883667, -0.9874526166988811, -0.961815711458498]\n",
      "Layer: Layer 2, Input: [-0.9969327221272655, -0.18408092240883667, -0.9874526166988811, -0.961815711458498], Output: [0.8865013662713706]\n",
      "Epoch 430/500, Loss: 0.2162148464416594, Accuracy: -0.4870853352474098\n",
      "Power operation: base = 0.7988419553042307, power = 2, grad = 0.25\n",
      "Power operation: base = 0.13138645274349336, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44335829347105626, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11349863372862945, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897643571549918, 0.990106055243913, -0.974332800880185, -0.9974562466876651]\n",
      "Layer: Layer 1, Input: [0.9897643571549918, 0.990106055243913, -0.974332800880185, -0.9974562466876651], Output: [-0.9978438432005775, -0.6928961737326316, -0.9916240697608607, -0.9699697384596138]\n",
      "Layer: Layer 2, Input: [-0.9978438432005775, -0.6928961737326316, -0.9916240697608607, -0.9699697384596138], Output: [1.8000659468172513]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982056256704351, 0.9828668620381801, 0.007034656954314146, -0.93564150261847]\n",
      "Layer: Layer 1, Input: [0.9982056256704351, 0.9828668620381801, 0.007034656954314146, -0.93564150261847], Output: [-0.9967943670791658, 0.8036065936049059, -0.9780824220802575, -0.958004909792854]\n",
      "Layer: Layer 2, Input: [-0.9967943670791658, 0.8036065936049059, -0.9780824220802575, -0.958004909792854], Output: [-0.8708925027922163]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328490347321183, 0.4279705549707836, 0.4271830031720876, -0.8819995881517108]\n",
      "Layer: Layer 1, Input: [0.9328490347321183, 0.4279705549707836, 0.4271830031720876, -0.8819995881517108], Output: [-0.985624698658594, 0.9981228828364799, -0.9358796656253475, -0.8789108552496011]\n",
      "Layer: Layer 2, Input: [-0.985624698658594, 0.9981228828364799, -0.9358796656253475, -0.8789108552496011], Output: [-1.4436871668089166]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8876195362343284, 0.9885370577538084, -0.7995085447895259, -0.9290020741399398]\n",
      "Layer: Layer 1, Input: [0.8876195362343284, 0.9885370577538084, -0.7995085447895259, -0.9290020741399398], Output: [-0.9969384338143221, -0.18459465872724243, -0.987516838543515, -0.962026622273132]\n",
      "Layer: Layer 2, Input: [-0.9969384338143221, -0.18459465872724243, -0.987516838543515, -0.962026622273132], Output: [0.8868208069625405]\n",
      "Epoch 431/500, Loss: 0.21661052420484414, Accuracy: -0.4860398038714111\n",
      "Power operation: base = 0.8000659468172513, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1291074972077837, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4436871668089166, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11317919303745949, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897671642515524, 0.9901222904425996, -0.9743381780699264, -0.997457718210279]\n",
      "Layer: Layer 1, Input: [0.9897671642515524, 0.9901222904425996, -0.9743381780699264, -0.997457718210279], Output: [-0.997847653498134, -0.6938094367862081, -0.9916667837279066, -0.970138363414083]\n",
      "Layer: Layer 2, Input: [-0.997847653498134, -0.6938094367862081, -0.9916667837279066, -0.970138363414083], Output: [1.8012835419298128]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982059942322992, 0.9828946823246575, 0.006939280886109761, -0.9356729972425649]\n",
      "Layer: Layer 1, Input: [0.9982059942322992, 0.9828946823246575, 0.006939280886109761, -0.9356729972425649], Output: [-0.9968001135534239, 0.8043161166566919, -0.9781908755682364, -0.9582229735123645]\n",
      "Layer: Layer 2, Input: [-0.9968001135534239, 0.8043161166566919, -0.9781908755682364, -0.9582229735123645], Output: [-0.8731626368419629]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328613657729691, 0.42863874515018474, 0.4271069761985535, -0.8820539174134155]\n",
      "Layer: Layer 1, Input: [0.9328613657729691, 0.42863874515018474, 0.4271069761985535, -0.8820539174134155], Output: [-0.9856692087674478, 0.9981420729930754, -0.9362129420604226, -0.8795665509349379]\n",
      "Layer: Layer 2, Input: [-0.9856692087674478, 0.9981420729930754, -0.9362129420604226, -0.8795665509349379], Output: [-1.4440154887875716]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8876438194275048, 0.9885557669720516, -0.7995442456531205, -0.9290383787306018]\n",
      "Layer: Layer 1, Input: [0.8876438194275048, 0.9885557669720516, -0.7995442456531205, -0.9290383787306018], Output: [-0.9969441265172468, -0.18510571780369456, -0.9875806115240692, -0.9622360020470675]\n",
      "Layer: Layer 2, Input: [-0.9969441265172468, -0.18510571780369456, -0.9875806115240692, -0.9622360020470675], Output: [0.8871387587942481]\n",
      "Epoch 432/500, Loss: 0.2170076113275597, Accuracy: -0.48499763508117333\n",
      "Power operation: base = 0.8012835419298128, power = 2, grad = 0.25\n",
      "Power operation: base = 0.12683736315803706, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4440154887875716, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11286124120575192, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897699636445069, 0.9901384660797489, -0.9743435533327744, -0.9974591863194116]\n",
      "Layer: Layer 1, Input: [0.9897699636445069, 0.9901384660797489, -0.9743435533327744, -0.9974591863194116], Output: [-0.9978514514614124, -0.694716878198956, -0.9917091953061918, -0.970305719104959]\n",
      "Layer: Layer 2, Input: [-0.9978514514614124, -0.694716878198956, -0.9917091953061918, -0.970305719104959], Output: [1.8024948227557855]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982063619818119, 0.9829224018081001, 0.006843882576196728, -0.9357044332205525]\n",
      "Layer: Layer 1, Input: [0.9982063619818119, 0.9829224018081001, 0.006843882576196728, -0.9357044332205525], Output: [-0.9968058418673963, 0.8050217193967871, -0.9782986101735721, -0.9584395844650219]\n",
      "Layer: Layer 2, Input: [-0.9968058418673963, 0.8050217193967871, -0.9782986101735721, -0.9584395844650219], Output: [-0.8754239616639854]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328736718585037, 0.4293051228147168, 0.4270309181599527, -0.8821081528095359]\n",
      "Layer: Layer 1, Input: [0.9328736718585037, 0.4293051228147168, 0.4270309181599527, -0.8821081528095359], Output: [-0.9857135009621312, 0.9981609964189696, -0.9365440362683976, -0.8802181555666282]\n",
      "Layer: Layer 2, Input: [-0.9857135009621312, 0.9981609964189696, -0.9365440362683976, -0.8802181555666282], Output: [-1.444343222567662]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8876680445375383, 0.9885744080176594, -0.7995799442510724, -0.9290746103441317]\n",
      "Layer: Layer 1, Input: [0.8876680445375383, 0.9885744080176594, -0.7995799442510724, -0.9290746103441317], Output: [-0.9969498003224898, -0.1856140629839421, -0.9876439389720887, -0.9624438618494523]\n",
      "Layer: Layer 2, Input: [-0.9969498003224898, -0.1856140629839421, -0.9876439389720887, -0.9624438618494523], Output: [0.887455212645774]\n",
      "Epoch 433/500, Loss: 0.21740608961993962, Accuracy: -0.4839588710136882\n",
      "Power operation: base = 0.8024948227557855, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1245760383360146, power = 2, grad = 0.25\n",
      "Power operation: base = -0.444343222567662, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11254478735422602, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897727553663118, 0.9901545824312041, -0.9743489266490828, -0.9974606510259675]\n",
      "Layer: Layer 1, Input: [0.9897727553663118, 0.9901545824312041, -0.9743489266490828, -0.9974606510259675], Output: [-0.997855237145777, -0.6956185185098801, -0.991751306814422, -0.9704718154333337]\n",
      "Layer: Layer 2, Input: [-0.997855237145777, -0.6956185185098801, -0.991751306814422, -0.9704718154333337], Output: [1.8036998708657634]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982067289216588, 0.982950020945765, 0.00674846259905322, -0.9357358106646193]\n",
      "Layer: Layer 1, Input: [0.9982067289216588, 0.982950020945765, 0.00674846259905322, -0.9357358106646193], Output: [-0.9968115520981772, 0.8057234485630855, -0.9784056307116389, -0.9586547514194717]\n",
      "Layer: Layer 2, Input: [-0.9968115520981772, 0.8057234485630855, -0.9784056307116389, -0.9586547514194717], Output: [-0.8776764898425755]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328859530616105, 0.4299696931626778, 0.4269548295503341, -0.8821622944767841]\n",
      "Layer: Layer 1, Input: [0.9328859530616105, 0.4299696931626778, 0.4269548295503341, -0.8821622944767841], Output: [-0.9857575765779396, 0.9981796578962133, -0.9368729614019004, -0.8808656868686953]\n",
      "Layer: Layer 2, Input: [-0.9857575765779396, 0.9981796578962133, -0.9368729614019004, -0.8808656868686953], Output: [-1.4446703321347174]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8876922117774027, 0.9885929812026762, -0.7996156403963361, -0.9291107691556469]\n",
      "Layer: Layer 1, Input: [0.8876922117774027, 0.9885929812026762, -0.7996156403963361, -0.9291107691556469], Output: [-0.9969554553155757, -0.18611965867245842, -0.9877068241960404, -0.9626502126886924]\n",
      "Layer: Layer 2, Input: [-0.9969554553155757, -0.18611965867245842, -0.9877068241960404, -0.9626502126886924], Output: [0.8877701596483139]\n",
      "Epoch 434/500, Loss: 0.21780594122826083, Accuracy: -0.4829235535095915\n",
      "Power operation: base = 0.8036998708657634, power = 2, grad = 0.25\n",
      "Power operation: base = 0.12232351015742449, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4446703321347174, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11222984035168615, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897755394492962, 0.9901706397702862, -0.974354297999025, -0.9974621123407569]\n",
      "Layer: Layer 1, Input: [0.9897755394492962, 0.9901706397702862, -0.974354297999025, -0.9974621123407569], Output: [-0.9978590106060033, -0.6965143787936763, -0.9917931205540684, -0.9706366622340921]\n",
      "Layer: Layer 2, Input: [-0.9978590106060033, -0.6965143787936763, -0.9917931205540684, -0.9706366622340921], Output: [1.804898767279365]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982070950545021, 0.9829775401907147, 0.0066530215340148465, -0.935767129684961]\n",
      "Layer: Layer 1, Input: [0.9982070950545021, 0.9829775401907147, 0.0066530215340148465, -0.935767129684961], Output: [-0.9968172443219816, 0.8064213501810327, -0.9785119419719597, -0.9588684831219266]\n",
      "Layer: Layer 2, Input: [-0.9968172443219816, 0.8064213501810327, -0.9785119419719597, -0.9588684831219266], Output: [-0.8799202342900081]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9328982094543226, 0.43063246133869193, 0.4268787108680457, -0.882216342548433]\n",
      "Layer: Layer 1, Input: [0.9328982094543226, 0.43063246133869193, 0.4268787108680457, -0.882216342548433], Output: [-0.9858014369371497, 0.9981980621073853, -0.9371997305732753, -0.8815091626562827]\n",
      "Layer: Layer 2, Input: [-0.9858014369371497, 0.9981980621073853, -0.9371997305732753, -0.8815091626562827], Output: [-1.4449967822918763]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8877163213587554, 0.988611486836287, -0.7996513339003495, -0.9291468553379957]\n",
      "Layer: Layer 1, Input: [0.8877163213587554, 0.988611486836287, -0.7996513339003495, -0.9291468553379957], Output: [-0.9969610915811261, -0.18662247032174778, -0.9877692704815346, -0.9628550655127762]\n",
      "Layer: Layer 2, Input: [-0.9969610915811261, -0.18662247032174778, -0.9877692704815346, -0.9628550655127762], Output: [0.8880835911854827]\n",
      "Epoch 435/500, Loss: 0.21820714862821744, Accuracy: -0.48189172409575054\n",
      "Power operation: base = 0.804898767279365, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1200797657099919, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44499678229187634, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11191640881451725, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897783159256633, 0.9901866383678568, -0.9743596673626055, -0.9974635702744987]\n",
      "Layer: Layer 1, Input: [0.9897783159256633, 0.9901866383678568, -0.9743596673626055, -0.9974635702744987], Output: [-0.9978627718962945, -0.6974044806451969, -0.9918346388095421, -0.9708002692763792]\n",
      "Layer: Layer 2, Input: [-0.9978627718962945, -0.6974044806451969, -0.9918346388095421, -0.9708002692763792], Output: [1.8060915924578032]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982074603829809, 0.9830049599919233, 0.006557559965001839, -0.9357983903898697]\n",
      "Layer: Layer 1, Input: [0.9982074603829809, 0.9830049599919233, 0.006557559965001839, -0.9357983903898697], Output: [-0.9968229186141692, 0.8071154695729776, -0.9786175487184052, -0.9590807882960903]\n",
      "Layer: Layer 2, Input: [-0.9968229186141692, 0.8071154695729776, -0.9786175487184052, -0.9590807882960903], Output: [-0.8821552082482667]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329104411078456, 0.43129343243571827, 0.42680256261550814, -0.8822702971544725]\n",
      "Layer: Layer 1, Input: [0.9329104411078456, 0.43129343243571827, 0.42680256261550814, -0.8822702971544725], Output: [-0.985845083349288, 0.9982162136378668, -0.9375243568545923, -0.8821486008338054]\n",
      "Layer: Layer 2, Input: [-0.985845083349288, 0.9982162136378668, -0.9375243568545923, -0.8821486008338054], Output: [-1.4453225386526594]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.887740373491973, 0.9886299252248885, -0.7996870245731281, -0.929182869061848]\n",
      "Layer: Layer 1, Input: [0.887740373491973, 0.9886299252248885, -0.7996870245731281, -0.929182869061848], Output: [-0.9969667092028821, -0.18712246442162495, -0.9878312810915403, -0.9630584312095817]\n",
      "Layer: Layer 2, Input: [-0.9969667092028821, -0.18712246442162495, -0.9878312810915403, -0.9630584312095817], Output: [0.8883954988936882]\n",
      "Epoch 436/500, Loss: 0.2186096946183511, Accuracy: -0.4808634239685077\n",
      "Power operation: base = 0.8060915924578032, power = 2, grad = 0.25\n",
      "Power operation: base = 0.11784479175173335, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44532253865265936, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11160450110631182, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897810848274935, 0.9902025784923786, -0.9743650347196727, -0.9974650248378235]\n",
      "Layer: Layer 1, Input: [0.9897810848274935, 0.9902025784923786, -0.9743650347196727, -0.9974650248378235], Output: [-0.9978665210702939, -0.6982888461641238, -0.9918758638483615, -0.9709626462640492]\n",
      "Layer: Layer 2, Input: [-0.9978665210702939, -0.6982888461641238, -0.9918758638483615, -0.9709626462640492], Output: [1.8072784262966897]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998207824909713, 0.9830322807943803, 0.006462078480249928, -0.9358295928858169]\n",
      "Layer: Layer 1, Input: [0.998207824909713, 0.9830322807943803, 0.006462078480249928, -0.9358295928858169], Output: [-0.996828575049267, 0.8078058513674107, -0.9787224556893843, -0.9592916756430594]\n",
      "Layer: Layer 2, Input: [-0.996828575049267, 0.8078058513674107, -0.9787224556893843, -0.9592916756430594], Output: [-0.8843814252905373]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329226480925852, 0.4319526114970086, 0.42672638529899043, -0.8823241584217627]\n",
      "Layer: Layer 1, Input: [0.9329226480925852, 0.4319526114970086, 0.42672638529899043, -0.8823241584217627], Output: [-0.9858885171113908, 0.9982341169780597, -0.9378468532776285, -0.8827840193930324]\n",
      "Layer: Layer 2, Input: [-0.9858885171113908, 0.9982341169780597, -0.9378468532776285, -0.8827840193930324], Output: [-1.4456475676337766]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8877643683861857, 0.9886482966721598, -0.7997227122233613, -0.9292188104957836]\n",
      "Layer: Layer 1, Input: [0.8877643683861857, 0.9886482966721598, -0.7997227122233613, -0.9292188104957836], Output: [-0.9969723082637261, -0.18761960848847578, -0.9878928592665944, -0.9632603206071642]\n",
      "Layer: Layer 2, Input: [-0.9969723082637261, -0.18761960848847578, -0.9878928592665944, -0.9632603206071642], Output: [0.8887058746624215]\n",
      "Epoch 437/500, Loss: 0.21901356231361638, Accuracy: -0.47983869397750745\n",
      "Power operation: base = 0.8072784262966897, power = 2, grad = 0.25\n",
      "Power operation: base = 0.11561857470946268, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44564756763377655, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11129412533757854, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897838461867454, 0.9902184604099754, -0.9743704000499304, -0.9974664760412766]\n",
      "Layer: Layer 1, Input: [0.9897838461867454, 0.9902184604099754, -0.9743704000499304, -0.9974664760412766], Output: [-0.9978702581810996, -0.69916749793987, -0.9919167979213144, -0.9711238028360998]\n",
      "Layer: Layer 2, Input: [-0.9978702581810996, -0.69916749793987, -0.9919167979213144, -0.9711238028360998], Output: [1.808459348119082]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982081886372948, 0.9830595030391925, 0.006366577672048714, -0.935860737277535]\n",
      "Layer: Layer 1, Input: [0.9982081886372948, 0.9830595030391925, 0.006366577672048714, -0.935860737277535], Output: [-0.9968342137009921, 0.8084925395080959, -0.9788266675980233, -0.9595011538412083]\n",
      "Layer: Layer 2, Input: [-0.9968342137009921, 0.8084925395080959, -0.9788266675980233, -0.9595011538412083], Output: [-0.8865988993225287]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329348304781736, 0.4326100035180163, 0.4266501794283916, -0.8823779264741816]\n",
      "Layer: Layer 1, Input: [0.9329348304781736, 0.4326100035180163, 0.4266501794283916, -0.8823779264741816], Output: [-0.9859317395082593, 0.9982517765255495, -0.9381672328338241, -0.8834154364110962]\n",
      "Layer: Layer 2, Input: [-0.9859317395082593, 0.9982517765255495, -0.9381672328338241, -0.8834154364110962], Output: [-1.445971836447991]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8877883062493112, 0.9886666014791304, -0.7997583966585045, -0.9292546798063771]\n",
      "Layer: Layer 1, Input: [0.8877883062493112, 0.9886666014791304, -0.7997583966585045, -0.9292546798063771], Output: [-0.9969778888457035, -0.18811387105448948, -0.9879540082250029, -0.9634607444740262]\n",
      "Layer: Layer 2, Input: [-0.9969778888457035, -0.18811387105448948, -0.9879540082250029, -0.9634607444740262], Output: [0.8890147106344068]\n",
      "Epoch 438/500, Loss: 0.21941873513908777, Accuracy: -0.4788175746101375\n",
      "Power operation: base = 0.808459348119082, power = 2, grad = 0.25\n",
      "Power operation: base = 0.11340110067747133, power = 2, grad = 0.25\n",
      "Power operation: base = -0.445971836447991, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11098528936559315, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897866000352589, 0.9902342843844891, -0.9743757633329498, -0.9974679238953206]\n",
      "Layer: Layer 1, Input: [0.9897866000352589, 0.9902342843844891, -0.9743757633329498, -0.9974679238953206], Output: [-0.9978739832812789, -0.7000404590366929, -0.9919574432626185, -0.9712837485670928]\n",
      "Layer: Layer 2, Input: [-0.9978739832812789, -0.7000404590366929, -0.9919574432626185, -0.9712837485670928], Output: [1.8096344366688122]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982085515683017, 0.9830866271636819, 0.006271058136479167, -0.9358918236680969]\n",
      "Layer: Layer 1, Input: [0.9982085515683017, 0.9830866271636819, 0.006271058136479167, -0.9358918236680969], Output: [-0.996839834642274, 0.8091755772630842, -0.9789301891323363, -0.959709231546055]\n",
      "Layer: Layer 2, Input: [-0.996839834642274, 0.8091755772630842, -0.9789301891323363, -0.959709231546055], Output: [-0.8888076445835473]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329469883334961, 0.43326561344825726, 0.4265739455170237, -0.8824316014327713]\n",
      "Layer: Layer 1, Input: [0.9329469883334961, 0.43326561344825726, 0.4265739455170237, -0.8824316014327713], Output: [-0.9859747518127057, 0.9982691965872148, -0.9384855084742151, -0.8840428700484433]\n",
      "Layer: Layer 2, Input: [-0.9859747518127057, 0.9982691965872148, -0.9384855084742151, -0.8840428700484433], Output: [-1.4462953130970018]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8878121872880861, 0.988684839944247, -0.7997940776848687, -0.929290477158283]\n",
      "Layer: Layer 1, Input: [0.8878121872880861, 0.988684839944247, -0.7997940776848687, -0.929290477158283], Output: [-0.9969834510300435, -0.18860522165686466, -0.9880147311630373, -0.9636597135193724]\n",
      "Layer: Layer 2, Input: [-0.9969834510300435, -0.18860522165686466, -0.9880147311630373, -0.9636597135193724], Output: [0.8893219992056594]\n",
      "Epoch 439/500, Loss: 0.21982519682381663, Accuracy: -0.47780010597660727\n",
      "Power operation: base = 0.8096344366688122, power = 2, grad = 0.25\n",
      "Power operation: base = 0.11119235541645267, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44629531309700177, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11067800079434065, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897893464047562, 0.9902500506775369, -0.9743811245481816, -0.9974693684103384]\n",
      "Layer: Layer 1, Input: [0.9897893464047562, 0.9902500506775369, -0.9743811245481816, -0.9974693684103384], Output: [-0.9978776964228793, -0.7009077529790254, -0.9919978020900754, -0.9714424929675596]\n",
      "Layer: Layer 2, Input: [-0.9978776964228793, -0.7009077529790254, -0.9919978020900754, -0.9714424929675596], Output: [1.8108037701040436]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982089137052897, 0.983113653601482, 0.006175520473162001, -0.9359228521589928]\n",
      "Layer: Layer 1, Input: [0.9982089137052897, 0.983113653601482, 0.006175520473162001, -0.9359228521589928], Output: [-0.9968454379452752, 0.8098550072336216, -0.9790330249553877, -0.9599159173901128]\n",
      "Layer: Layer 2, Input: [-0.9968454379452752, 0.8098550072336216, -0.9790330249553877, -0.9599159173901128], Output: [-0.8910076756473906]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329591217267161, 0.433919446193122, 0.42649768408139943, -0.8824851834158798]\n",
      "Layer: Layer 1, Input: [0.9329591217267161, 0.433919446193122, 0.42649768408139943, -0.8824851834158798], Output: [-0.9860175552857963, 0.9982863813812837, -0.9388016931093425, -0.8846663385467217]\n",
      "Layer: Layer 2, Input: [-0.9860175552857963, 0.9982863813812837, -0.9388016931093425, -0.8846663385467217], Output: [-1.4466179663643652]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8878360117080991, 0.9887030123634384, -0.7998297551077109, -0.9293262027143154]\n",
      "Layer: Layer 1, Input: [0.8878360117080991, 0.9887030123634384, -0.7998297551077109, -0.9293262027143154], Output: [-0.9969889948971797, -0.18909363082700437, -0.9880750312551241, -0.9638572383933471]\n",
      "Layer: Layer 2, Input: [-0.9969889948971797, -0.18909363082700437, -0.9880750312551241, -0.9638572383933471], Output: [0.889627733025443]\n",
      "Epoch 440/500, Loss: 0.2202329313948148, Accuracy: -0.4767863277955753\n",
      "Power operation: base = 0.8108037701040436, power = 2, grad = 0.25\n",
      "Power operation: base = 0.10899232435260942, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44661796636436524, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11037226697455704, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897920853268446, 0.9902657595485652, -0.9743864836749656, -0.9974708095966359]\n",
      "Layer: Layer 1, Input: [0.9897920853268446, 0.9902657595485652, -0.9743864836749656, -0.9974708095966359], Output: [-0.9978813976574435, -0.701769403737017, -0.9920378766052192, -0.9716000454843956]\n",
      "Layer: Layer 2, Input: [-0.9978813976574435, -0.701769403737017, -0.9920378766052192, -0.9716000454843956], Output: [1.8119674259910878]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982092750507955, 0.9831405827826316, 0.006079965285005095, -0.9359538228502078]\n",
      "Layer: Layer 1, Input: [0.9982092750507955, 0.9831405827826316, 0.006079965285005095, -0.9359538228502078], Output: [-0.9968510236814131, 0.8105308713629604, -0.9791351797054452, -0.9601212199827236]\n",
      "Layer: Layer 2, Input: [-0.9968510236814131, 0.8105308713629604, -0.9791351797054452, -0.9601212199827236], Output: [-0.8931990074230391]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329712307253002, 0.4345715066156434, 0.42642139564102366, -0.8825386725392999]\n",
      "Layer: Layer 1, Input: [0.9329712307253002, 0.4345715066156434, 0.42642139564102366, -0.8825386725392999], Output: [-0.9860601511770853, 0.9983033350393405, -0.9391157996091414, -0.8852858602266137]\n",
      "Layer: Layer 2, Input: [-0.9860601511770853, 0.9983033350393405, -0.9391157996091414, -0.8852858602266137], Output: [-1.4469397658084322]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.88785977971382, 0.9887211190301778, -0.7998654287313215, -0.9293618566355304]\n",
      "Layer: Layer 1, Input: [0.88785977971382, 0.9887211190301778, -0.7998654287313215, -0.9293618566355304], Output: [-0.9969945205267696, -0.18957907007967398, -0.9881349116540283, -0.9640533296872584]\n",
      "Layer: Layer 2, Input: [-0.9969945205267696, -0.18957907007967398, -0.9881349116540283, -0.9640533296872584], Output: [0.8899319049961081]\n",
      "Epoch 441/500, Loss: 0.22064192317117468, Accuracy: -0.4757762793803728\n",
      "Power operation: base = 0.8119674259910878, power = 2, grad = 0.25\n",
      "Power operation: base = 0.10680099257696085, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4469397658084322, power = 2, grad = 0.25\n",
      "Power operation: base = -0.11006809500389192, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897948168330174, 0.990281411254904, -0.9743918406925438, -0.9974722474644452]\n",
      "Layer: Layer 1, Input: [0.9897948168330174, 0.990281411254904, -0.9743918406925438, -0.9974722474644452], Output: [-0.997885087036022, -0.7026254357122925, -0.9920776689934658, -0.9717564155012408]\n",
      "Layer: Layer 2, Input: [-0.997885087036022, -0.7026254357122925, -0.9920776689934658, -0.9717564155012408], Output: [1.8131254812984778]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982096356073366, 0.9831674151336656, 0.0059843931779586185, -0.9359847358402935]\n",
      "Layer: Layer 1, Input: [0.9982096356073366, 0.9831674151336656, 0.0059843931779586185, -0.9359847358402935], Output: [-0.9968565919213798, 0.8112032109450578, -0.9792366579961255, -0.9603251479098792]\n",
      "Layer: Layer 2, Input: [-0.9968565919213798, 0.8112032109450578, -0.9792366579961255, -0.9603251479098792], Output: [-0.8953816551551439]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329833153960426, 0.4352217995382166, 0.4263450807181875, -0.882592068916404]\n",
      "Layer: Layer 1, Input: [0.9329833153960426, 0.4352217995382166, 0.4263450807181875, -0.882592068916404], Output: [-0.9861025407248439, 0.9983200616082825, -0.9394278408028086, -0.8859014534856189]\n",
      "Layer: Layer 2, Input: [-0.9861025407248439, 0.9983200616082825, -0.9394278408028086, -0.8859014534856189], Output: [-1.447260681755317]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.88788349150863, 0.9887391602355453, -0.7999010983591088, -0.9293974390813002]\n",
      "Layer: Layer 1, Input: [0.88788349150863, 0.9887391602355453, -0.7999010983591088, -0.9293974390813002], Output: [-0.997000027997715, -0.19006151190215423, -0.9881943754910324, -0.9642479979337888]\n",
      "Layer: Layer 2, Input: [-0.997000027997715, -0.19006151190215423, -0.9881943754910324, -0.9642479979337888], Output: [0.89023450827285]\n",
      "Epoch 442/500, Loss: 0.22105215675832313, Accuracy: -0.474769999625801\n",
      "Power operation: base = 0.8131254812984778, power = 2, grad = 0.25\n",
      "Power operation: base = 0.1046183448448561, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4472606817553171, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10976549172715, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989797540954656, 0.9902970060518179, -0.9743971955800692, -0.9974736820239254]\n",
      "Layer: Layer 1, Input: [0.989797540954656, 0.9902970060518179, -0.9743971955800692, -0.9974736820239254], Output: [-0.997888764609183, -0.7034758737239156, -0.9921171814242526, -0.9719116123388488]\n",
      "Layer: Layer 2, Input: [-0.997888764609183, -0.7034758737239156, -0.9921171814242526, -0.9719116123388488], Output: [1.81427801239127]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982099953774127, 0.9831941510777038, 0.005888804760773933, -0.9360155912264423]\n",
      "Layer: Layer 1, Input: [0.9982099953774127, 0.9831941510777038, 0.005888804760773933, -0.9360155912264423], Output: [-0.9968621427351617, 0.811872066633183, -0.979337464416532, -0.960527709734029]\n",
      "Layer: Layer 2, Input: [-0.9968621427351617, 0.811872066633183, -0.979337464416532, -0.960527709734029], Output: [-0.8975556344243216]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9329953758050887, 0.43587032974427564, 0.42626873983776725, -0.8826453726582768]\n",
      "Layer: Layer 1, Input: [0.9329953758050887, 0.43587032974427564, 0.42626873983776725, -0.8826453726582768], Output: [-0.9861447251562836, 0.9983365650522282, -0.9397378294786544, -0.8865131367957864]\n",
      "Layer: Layer 2, Input: [-0.9861447251562836, 0.9983365650522282, -0.9397378294786544, -0.8865131367957864], Output: [-1.4475806852918733]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8879071472948502, 0.9887571362682874, -0.7999367637936852, -0.9294329502093919]\n",
      "Layer: Layer 1, Input: [0.8879071472948502, 0.9887571362682874, -0.7999367637936852, -0.9294329502093919], Output: [-0.9970055173881793, -0.19054092974336187, -0.9882534258761092, -0.9644412536071924]\n",
      "Layer: Layer 2, Input: [-0.9970055173881793, -0.19054092974336187, -0.9882534258761092, -0.9644412536071924], Output: [0.8905355362633518]\n",
      "Epoch 443/500, Loss: 0.2214636170423939, Accuracy: -0.47376752699547\n",
      "Power operation: base = 0.8142780123912701, power = 2, grad = 0.25\n",
      "Power operation: base = 0.10244436557567838, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44758068529187334, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1094644637366482, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898002577230314, 0.9903125441925574, -0.9744025483166182, -0.9974751132851678]\n",
      "Layer: Layer 1, Input: [0.9898002577230314, 0.9903125441925574, -0.9744025483166182, -0.9974751132851678], Output: [-0.9978924304270276, -0.7043207429945737, -0.9921564160511793, -0.9720656452554457]\n",
      "Layer: Layer 2, Input: [-0.9978924304270276, -0.7043207429945737, -0.9921564160511793, -0.9720656452554457], Output: [1.8154250950256339]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998210354363506, 0.9832207910345372, 0.005793200644766249, -0.9360463891045554]\n",
      "Layer: Layer 1, Input: [0.998210354363506, 0.9832207910345372, 0.005793200644766249, -0.9360463891045554], Output: [-0.9968676761920601, 0.8125374784484257, -0.9794376035313862, -0.9607289139938728]\n",
      "Layer: Layer 2, Input: [-0.9968676761920601, 0.8125374784484257, -0.9794376035313862, -0.9607289139938728], Output: [-0.8997209611472803]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9330074120179582, 0.4365171019799248, 0.4261923735270253, -0.8826985838738441]\n",
      "Layer: Layer 1, Input: [0.9330074120179582, 0.4365171019799248, 0.4261923735270253, -0.8826985838738441], Output: [-0.9861867056877723, 0.9983528492543796, -0.9400457783839336, -0.8871209287014049]\n",
      "Layer: Layer 2, Input: [-0.9861867056877723, 0.9983528492543796, -0.9400457783839336, -0.8871209287014049], Output: [-1.4478997482587008]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8879307472737699, 0.9887750474148749, -0.7999724248369469, -0.929468390176038]\n",
      "Layer: Layer 1, Input: [0.8879307472737699, 0.9887750474148749, -0.7999724248369469, -0.929468390176038], Output: [-0.9970109887756077, -0.19101729800295048, -0.9883120658980893, -0.9646331071234799]\n",
      "Layer: Layer 2, Input: [-0.9970109887756077, -0.19101729800295048, -0.9883120658980893, -0.9646331071234799], Output: [0.890834982627319]\n",
      "Epoch 444/500, Loss: 0.22187628918474364, Accuracy: -0.47276889950973544\n",
      "Power operation: base = 0.8154250950256339, power = 2, grad = 0.25\n",
      "Power operation: base = 0.10027903885271972, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4478997482587008, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10916501737268103, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898029671693057, 0.9903280259284081, -0.9744078988811993, -0.9974765412581957]\n",
      "Layer: Layer 1, Input: [0.9898029671693057, 0.9903280259284081, -0.9744078988811993, -0.9974765412581957], Output: [-0.9978960845391993, -0.7051600691369553, -0.9921953750121414, -0.9722185234470787]\n",
      "Layer: Layer 2, Input: [-0.9978960845391993, -0.7051600691369553, -0.9921953750121414, -0.9722185234470787], Output: [1.8165668043436458]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982107125680817, 0.9832473354207117, 0.005697581443581091, -0.936077129569313]\n",
      "Layer: Layer 1, Input: [0.9982107125680817, 0.9832473354207117, 0.005697581443581091, -0.936077129569313], Output: [-0.9968731923607084, 0.8131994857881042, -0.9795370798811516, -0.960928769204146]\n",
      "Layer: Layer 2, Input: [-0.9968731923607084, 0.8131994857881042, -0.9795370798811516, -0.960928769204146], Output: [-0.9018776515767124]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.933019424099568, 0.43716212095552814, 0.42611598231541586, -0.8827517026699977]\n",
      "Layer: Layer 1, Input: [0.933019424099568, 0.43716212095552814, 0.42611598231541586, -0.8827517026699977], Output: [-0.9862284835250473, 0.9983689180188385, -0.9403517002246644, -0.8877248478166525]\n",
      "Layer: Layer 2, Input: [-0.9862284835250473, 0.9983689180188385, -0.9403517002246644, -0.8877248478166525], Output: [-1.448217843243131]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8879542916456729, 0.9887928939595598, -0.8000080812901575, -0.9295037591360107]\n",
      "Layer: Layer 1, Input: [0.8879542916456729, 0.9887928939595598, -0.8000080812901575, -0.9295037591360107], Output: [-0.9970164422367437, -0.19149059202041108, -0.9883702986248257, -0.964823568840593]\n",
      "Layer: Layer 2, Input: [-0.9970164422367437, -0.19149059202041108, -0.9883702986248257, -0.964823568840593], Output: [0.8911328412759643]\n",
      "Epoch 445/500, Loss: 0.22229015861656584, Accuracy: -0.4717741547341001\n",
      "Power operation: base = 0.8165668043436458, power = 2, grad = 0.25\n",
      "Power operation: base = 0.0981223484232876, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44821784324313096, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10886715872403574, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898056693245336, 0.9903434515087383, -0.9744132472527643, -0.9974779659529683]\n",
      "Layer: Layer 1, Input: [0.9898056693245336, 0.9903434515087383, -0.9744132472527643, -0.9974779659529683], Output: [-0.997899726994896, -0.7059938781403539, -0.9922340604294638, -0.972370256047954]\n",
      "Layer: Layer 2, Input: [-0.997899726994896, -0.7059938781403539, -0.9922340604294638, -0.972370256047954], Output: [1.8177032148683683]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982110699935882, 0.9832737846496108, 0.0056019477729676945, -0.9361078127142399]\n",
      "Layer: Layer 1, Input: [0.9982110699935882, 0.9832737846496108, 0.0056019477729676945, -0.9361078127142399], Output: [-0.9968786913090927, 0.8138581274340884, -0.9796358979821513, -0.9611272838553917]\n",
      "Layer: Layer 2, Input: [-0.9968786913090927, 0.8138581274340884, -0.9796358979821513, -0.9611272838553917], Output: [-0.9040257223010544]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9330314121142537, 0.43780539134725466, 0.4260395667343931, -0.8828047291517184]\n",
      "Layer: Layer 1, Input: [0.9330314121142537, 0.43780539134725466, 0.4260395667343931, -0.8828047291517184], Output: [-0.9862700598634199, 0.9983847750723781, -0.9406556076654286, -0.8883249128232077]\n",
      "Layer: Layer 2, Input: [-0.9862700598634199, 0.9983847750723781, -0.9406556076654286, -0.8883249128232077], Output: [-1.4485349435722625]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8879777806098644, 0.9888106761844309, -0.8000437329540253, -0.9295390572426903]\n",
      "Layer: Layer 1, Input: [0.8879777806098644, 0.9888106761844309, -0.8000437329540253, -0.9295390572426903], Output: [-0.9970218778476488, -0.19196078806412772, -0.9884281271033515, -0.9650126490585684]\n",
      "Layer: Layer 2, Input: [-0.9970218778476488, -0.19196078806412772, -0.9884281271033515, -0.9650126490585684], Output: [0.8914291063713424]\n",
      "Epoch 446/500, Loss: 0.2227052110336493, Accuracy: -0.470783329768234\n",
      "Power operation: base = 0.8177032148683683, power = 2, grad = 0.25\n",
      "Power operation: base = 0.09597427769894562, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44853494357226253, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10857089362865757, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898083642196638, 0.9903588211810461, -0.9744185934102182, -0.9974793873793825]\n",
      "Layer: Layer 1, Input: [0.9898083642196638, 0.9903588211810461, -0.9744185934102182, -0.9974793873793825], Output: [-0.9979033578428814, -0.7068221963574612, -0.9922724744100287, -0.9725208521307657]\n",
      "Layer: Layer 2, Input: [-0.9979033578428814, -0.7068221963574612, -0.9922724744100287, -0.9725208521307657], Output: [1.8188344004991501]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982114266424587, 0.9833001391315339, 0.005506300250553044, -0.9361384386317713]\n",
      "Layer: Layer 1, Input: [0.9982114266424587, 0.9833001391315339, 0.005506300250553044, -0.9361384386317713], Output: [-0.9968841731045676, 0.8145134415610248, -0.9797340623266795, -0.9613244664137225]\n",
      "Layer: Layer 2, Input: [-0.9968841731045676, 0.8145134415610248, -0.9797340623266795, -0.9613244664137225], Output: [-0.9061651902440389]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9330433761257918, 0.43844691779858425, 0.42596312731722336, -0.8828576634221967]\n",
      "Layer: Layer 1, Input: [0.9330433761257918, 0.43844691779858425, 0.42596312731722336, -0.8828576634221967], Output: [-0.9863114358879768, 0.9984004240661721, -0.9409575133291614, -0.8889211424678298]\n",
      "Layer: Layer 2, Input: [-0.9863114358879768, 0.9984004240661721, -0.9409575133291614, -0.8889211424678298], Output: [-1.4488510233059557]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8880012143646957, 0.9888283943694668, -0.8000793796287816, -0.9295742846481333]\n",
      "Layer: Layer 1, Input: [0.8880012143646957, 0.9888283943694668, -0.8000793796287816, -0.9295742846481333], Output: [-0.997027295683717, -0.19242786332045178, -0.9884855543600343, -0.965200358019691]\n",
      "Layer: Layer 2, Input: [-0.997027295683717, -0.19242786332045178, -0.9884855543600343, -0.965200358019691], Output: [0.891723772325645]\n",
      "Epoch 447/500, Loss: 0.22312143239123305, Accuracy: -0.46979646123542196\n",
      "Power operation: base = 0.8188344004991501, power = 2, grad = 0.25\n",
      "Power operation: base = 0.09383480975596115, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4488510233059557, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10827622767435496, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898110518855402, 0.9903741351910047, -0.9744239373324278, -0.9974808055472755]\n",
      "Layer: Layer 1, Input: [0.9898110518855402, 0.9903741351910047, -0.9744239373324278, -0.9974808055472755], Output: [-0.9979069771314955, -0.7076450504913797, -0.9923106190454011, -0.9726703207070161]\n",
      "Layer: Layer 2, Input: [-0.9979069771314955, -0.7076450504913797, -0.9923106190454011, -0.9726703207070161], Output: [1.8199604345071911]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982117825171101, 0.9833263992737746, 0.0054106394956222135, -0.9361690074133157]\n",
      "Layer: Layer 1, Input: [0.9982117825171101, 0.9833263992737746, 0.0054106394956222135, -0.9361690074133157], Output: [-0.9968896378138753, 0.8151654657444757, -0.9798315773831078, -0.961520325320575]\n",
      "Layer: Layer 2, Input: [-0.9968896378138753, 0.8151654657444757, -0.9798315773831078, -0.961520325320575], Output: [-0.9082960726640721]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9330553161974202, 0.43908670492177043, 0.4258866645988002, -0.8829105055829475]\n",
      "Layer: Layer 1, Input: [0.9330553161974202, 0.43908670492177043, 0.4258866645988002, -0.8829105055829475], Output: [-0.9863526127737751, 0.9984158685774813, -0.9412574297969258, -0.8895135555599054]\n",
      "Layer: Layer 2, Input: [-0.9863526127737751, 0.9984158685774813, -0.9412574297969258, -0.8895135555599054], Output: [-1.4491660572298732]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8880245931075891, 0.9888460487925885, -0.8001150211142569, -0.9296094415031386]\n",
      "Layer: Layer 1, Input: [0.8880245931075891, 0.9888460487925885, -0.8001150211142569, -0.9296094415031386], Output: [-0.9970326958196932, -0.19289179588272687, -0.9885425834007264, -0.9653867059086396]\n",
      "Layer: Layer 2, Input: [-0.9970326958196932, -0.19289179588272687, -0.9885425834007264, -0.9653867059086396], Output: [0.8920168338003576]\n",
      "Epoch 448/500, Loss: 0.22353880889899605, Accuracy: -0.4688135852726347\n",
      "Power operation: base = 0.8199604345071911, power = 2, grad = 0.25\n",
      "Power operation: base = 0.09170392733592792, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44916605722987324, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10798316619964243, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898137323529029, 0.9903893937825063, -0.9744292789982322, -0.9974822204664261]\n",
      "Layer: Layer 1, Input: [0.9898137323529029, 0.9903893937825063, -0.9744292789982322, -0.9974822204664261], Output: [-0.9979105849086656, -0.708462467582828, -0.992348496411952, -0.9728186707273295]\n",
      "Layer: Layer 2, Input: [-0.9979105849086656, -0.708462467582828, -0.992348496411952, -0.9728186707273295], Output: [1.821081389531333]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982121376199452, 0.9833525654806957, 0.005314966128903497, -0.9361995191493167]\n",
      "Layer: Layer 1, Input: [0.9982121376199452, 0.9833525654806957, 0.005314966128903497, -0.9361995191493167], Output: [-0.9968950855031624, 0.8158142369689702, -0.9799284475959852, -0.9617148689924562]\n",
      "Layer: Layer 2, Input: [-0.9968950855031624, 0.8158142369689702, -0.9799284475959852, -0.9617148689924562], Output: [-0.9104183871534444]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.933067232391859, 0.43972475729926397, 0.42581017911546354, -0.8829632557339248]\n",
      "Layer: Layer 1, Input: [0.933067232391859, 0.43972475729926397, 0.42581017911546354, -0.8829632557339248], Output: [-0.9863935916860325, 0.9984311121112996, -0.9415553696076769, -0.8901021709689709]\n",
      "Layer: Layer 2, Input: [-0.9863935916860325, 0.9984311121112996, -0.9415553696076769, -0.8901021709689709], Output: [-1.4494800208484806]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8880479170350614, 0.9888636397297107, -0.8001506572099545, -0.9296445279573118]\n",
      "Layer: Layer 1, Input: [0.8880479170350614, 0.9888636397297107, -0.8001506572099545, -0.9296445279573118], Output: [-0.9970380783296893, -0.1933525647403374, -0.988599217210911, -0.9655717028526224]\n",
      "Layer: Layer 2, Input: [-0.9970380783296893, -0.1933525647403374, -0.988599217210911, -0.9655717028526224], Output: [0.8923082857053881]\n",
      "Epoch 449/500, Loss: 0.22395732701613938, Accuracy: -0.46783473752098104\n",
      "Power operation: base = 0.8210813895313329, power = 2, grad = 0.25\n",
      "Power operation: base = 0.08958161284655564, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4494800208484806, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10769171429461188, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898164056523903, 0.9904045971977057, -0.9744346183864514, -0.9974836321465577]\n",
      "Layer: Layer 1, Input: [0.9898164056523903, 0.9904045971977057, -0.9744346183864514, -0.9974836321465577], Output: [-0.9979141812219162, -0.7092744749975548, -0.9923861085709771, -0.9729659110817549]\n",
      "Layer: Layer 2, Input: [-0.9979141812219162, -0.7092744749975548, -0.9923861085709771, -0.9729659110817549], Output: [1.8221973375740985]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982124919533519, 0.9833786381538026, 0.005219280772355707, -0.9362299739293124]\n",
      "Layer: Layer 1, Input: [0.9982124919533519, 0.9833786381538026, 0.005219280772355707, -0.9362299739293124], Output: [-0.996900516237996, 0.8164597916359683, -0.9800246773861341, -0.9619081058206814]\n",
      "Layer: Layer 2, Input: [-0.996900516237996, 0.8164597916359683, -0.9800246773861341, -0.9619081058206814], Output: [-0.9125321516373743]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9330791247713299, 0.44036107948509773, 0.42573367140482127, -0.8830159139736319]\n",
      "Layer: Layer 1, Input: [0.9330791247713299, 0.44036107948509773, 0.42573367140482127, -0.8830159139736319], Output: [-0.9864343737803128, 0.9984461581019604, -0.941851345258015, -0.8906870076222096]\n",
      "Layer: Layer 2, Input: [-0.9864343737803128, 0.9984461581019604, -0.941851345258015, -0.8906870076222096], Output: [-1.4497928903780783]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8880711863427471, 0.9888811674547902, -0.8001862877151249, -0.9296795441591282]\n",
      "Layer: Layer 1, Input: [0.8880711863427471, 0.9888811674547902, -0.8001862877151249, -0.9296795441591282], Output: [-0.9970434432872, -0.19381014976772096, -0.988655458755844, -0.9657553589215067]\n",
      "Layer: Layer 2, Input: [-0.9970434432872, -0.19381014976772096, -0.988655458755844, -0.9657553589215067], Output: [0.8925981231980575]\n",
      "Epoch 450/500, Loss: 0.22437697344659227, Accuracy: -0.466859953116745\n",
      "Power operation: base = 0.8221973375740985, power = 2, grad = 0.25\n",
      "Power operation: base = 0.08746784836262567, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44979289037807835, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10740187680194246, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898190718145388, 0.9904197456770615, -0.9744399554758958, -0.99748504059734]\n",
      "Layer: Layer 1, Input: [0.9898190718145388, 0.9904197456770615, -0.9744399554758958, -0.99748504059734], Output: [-0.9979177661183793, -0.7100811004139561, -0.9924234575688156, -0.9731120506000644]\n",
      "Layer: Layer 2, Input: [-0.9979177661183793, -0.7100811004139561, -0.9924234575688156, -0.9731120506000644], Output: [1.82330834999797]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982128455197045, 0.983404617691814, 0.005123584048961147, -0.9362603718419958]\n",
      "Layer: Layer 1, Input: [0.9982128455197045, 0.983404617691814, 0.005123584048961147, -0.9362603718419958], Output: [-0.9969059300833807, 0.8171021655717416, -0.9801202711507397, -0.9621000441711058]\n",
      "Layer: Layer 2, Input: [-0.9969059300833807, 0.8171021655717416, -0.9801202711507397, -0.9621000441711058], Output: [-0.9146373843728837]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9330909933975764, 0.44099567600623146, 0.42565714200557436, -0.8830684803992298]\n",
      "Layer: Layer 1, Input: [0.9330909933975764, 0.44099567600623146, 0.42565714200557436, -0.8830684803992298], Output: [-0.9864749602027063, 0.998461009914703, -0.9421453692019296, -0.8912680845019274]\n",
      "Layer: Layer 2, Input: [-0.9864749602027063, 0.998461009914703, -0.9421453692019296, -0.8912680845019274], Output: [-1.4501046427398077]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8880944012254207, 0.9888986322398746, -0.8002219124288358, -0.929714490255993]\n",
      "Layer: Layer 1, Input: [0.8880944012254207, 0.9888986322398746, -0.8002219124288358, -0.929714490255993], Output: [-0.9970487907651174, -0.19426453171337774, -0.9887113109806936, -0.9659376841279406]\n",
      "Layer: Layer 2, Input: [-0.9970487907651174, -0.19426453171337774, -0.9887113109806936, -0.9659376841279406], Output: [0.8928863416820283]\n",
      "Epoch 451/500, Loss: 0.22479773513431797, Accuracy: -0.4658892666828658\n",
      "Power operation: base = 0.8233083499979701, power = 2, grad = 0.25\n",
      "Power operation: base = 0.08536261562711633, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45010464273980766, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1071136583179717, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898217308697851, 0.9904348394593769, -0.974445290245375, -0.997486445828391]\n",
      "Layer: Layer 1, Input: [0.9898217308697851, 0.9904348394593769, -0.974445290245375, -0.997486445828391], Output: [-0.9979213396448039, -0.7108823718108863, -0.9924605454369626, -0.9732570980520441]\n",
      "Layer: Layer 2, Input: [-0.9979213396448039, -0.7108823718108863, -0.9924605454369626, -0.9732570980520441], Output: [1.8244144975219116]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982131983213633, 0.983430504490732, 0.005027876582521427, -0.9362907129752697]\n",
      "Layer: Layer 1, Input: [0.9982131983213633, 0.983430504490732, 0.005027876582521427, -0.9362907129752697], Output: [-0.9969113271037738, 0.8177413940351694, -0.9802152332634376, -0.9622906923838505]\n",
      "Layer: Layer 2, Input: [-0.9969113271037738, 0.8177413940351694, -0.9802152332634376, -0.9622906923838505], Output: [-0.916734103947503]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331028383318825, 0.4416285513638587, 0.4255805914573462, -0.8831209551066418]\n",
      "Layer: Layer 1, Input: [0.9331028383318825, 0.4416285513638587, 0.4255805914573462, -0.8831209551066418], Output: [-0.986515352090004, 0.9984756708472032, -0.9424374538505332, -0.8918454206430109]\n",
      "Layer: Layer 2, Input: [-0.986515352090004, 0.9984756708472032, -0.9424374538505332, -0.8918454206430109], Output: [-1.4504152555526577]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8881175618770181, 0.9889160343551494, -0.8002575311500427, -0.9297493663943007]\n",
      "Layer: Layer 1, Input: [0.8881175618770181, 0.9889160343551494, -0.8002575311500427, -0.9297493663943007], Output: [-0.9970541208357478, -0.19471569218888976, -0.9887667768106738, -0.9661186884274673]\n",
      "Layer: Layer 2, Input: [-0.9970541208357478, -0.19471569218888976, -0.9887667768106738, -0.9661186884274673], Output: [0.8931729368061774]\n",
      "Epoch 452/500, Loss: 0.22521959925872853, Accuracy: -0.464922712320889\n",
      "Power operation: base = 0.8244144975219116, power = 2, grad = 0.25\n",
      "Power operation: base = 0.08326589605249701, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4504152555526577, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10682706319382262, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898243828484664, 0.9904498787818399, -0.9744506226737059, -0.997487847849279]\n",
      "Layer: Layer 1, Input: [0.9898243828484664, 0.9904498787818399, -0.9744506226737059, -0.997487847849279], Output: [-0.9979249018475662, -0.7116783174556734, -0.9924973741921833, -0.9734010621477782]\n",
      "Layer: Layer 2, Input: [-0.9979249018475662, -0.7116783174556734, -0.9924973741921833, -0.9734010621477782], Output: [1.8255158502181148]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982135503606764, 0.9834562989439085, 0.004932158997459051, -0.9363209974163027]\n",
      "Layer: Layer 1, Input: [0.9982135503606764, 0.9834562989439085, 0.004932158997459051, -0.9363209974163027], Output: [-0.9969167073631011, 0.8183775117254551, -0.9803095680743943, -0.9624800587730237]\n",
      "Layer: Layer 2, Input: [-0.9969167073631011, 0.8183775117254551, -0.9803095680743943, -0.9624800587730237], Output: [-0.9188223292778366]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331146596350907, 0.4422597100346783, 0.42550402030051365, -0.8831733381906558]\n",
      "Layer: Layer 1, Input: [0.9331146596350907, 0.4422597100346783, 0.42550402030051365, -0.8831733381906558], Output: [-0.9865555505698709, 0.9984901441310657, -0.9427276115717889, -0.8924190351303707]\n",
      "Layer: Layer 2, Input: [-0.9865555505698709, 0.9984901441310657, -0.9427276115717889, -0.8924190351303707], Output: [-1.4507247071264677]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8881406684906572, 0.9889333740689827, -0.8002931436776572, -0.9297841727194933]\n",
      "Layer: Layer 1, Input: [0.8881406684906572, 0.9889333740689827, -0.8002931436776572, -0.9297841727194933], Output: [-0.9970594335708248, -0.19516361365791357, -0.9888218591511779, -0.9662983817186352]\n",
      "Layer: Layer 2, Input: [-0.9970594335708248, -0.19516361365791357, -0.9888218591511779, -0.9662983817186352], Output: [0.8934579044633537]\n",
      "Epoch 453/500, Loss: 0.22564255323019822, Accuracy: -0.46396032360339223\n",
      "Power operation: base = 0.8255158502181148, power = 2, grad = 0.25\n",
      "Power operation: base = 0.08117767072216342, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4507247071264677, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10654209553664629, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898270277808218, 0.9904648638800605, -0.9744559527397214, -0.9974892466695237]\n",
      "Layer: Layer 1, Input: [0.9898270277808218, 0.9904648638800605, -0.9744559527397214, -0.9974892466695237], Output: [-0.997928452772678, -0.7124689658923279, -0.9925339458366207, -0.9735439515379282]\n",
      "Layer: Layer 2, Input: [-0.997928452772678, -0.7124689658923279, -0.9925339458366207, -0.9735439515379282], Output: [1.8266124775089763]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982139016399785, 0.9834820014421113, 0.004836431918620898, -0.9363512252515835]\n",
      "Layer: Layer 1, Input: [0.9982139016399785, 0.9834820014421113, 0.004836431918620898, -0.9363512252515835], Output: [-0.9969220709247721, 0.819010552789762, -0.9804032799103852, -0.9626681516264359]\n",
      "Layer: Layer 2, Input: [-0.9969220709247721, 0.819010552789762, -0.9804032799103852, -0.9626681516264359], Output: [-0.9209020796079619]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331264573676208, 0.442889156472126, 0.4254274290760425, -0.8832256297450237]\n",
      "Layer: Layer 1, Input: [0.9331264573676208, 0.442889156472126, 0.4254274290760425, -0.8832256297450237], Output: [-0.9865955567610103, 0.9985044329332811, -0.9430158546902302, -0.8929889470963703]\n",
      "Layer: Layer 2, Input: [-0.9865955567610103, 0.9985044329332811, -0.9430158546902302, -0.8929889470963703], Output: [-1.4510329764549184]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8881637212586587, 0.9889506516479698, -0.800328749810614, -0.9298189093761152]\n",
      "Layer: Layer 1, Input: [0.8881637212586587, 0.9889506516479698, -0.800328749810614, -0.9298189093761152], Output: [-0.9970647290415244, -0.19560827942518652, -0.9888765608879063, -0.9664767738431013]\n",
      "Layer: Layer 2, Input: [-0.9970647290415244, -0.19560827942518652, -0.9888765608879063, -0.9664767738431013], Output: [0.8937412407890815]\n",
      "Epoch 454/500, Loss: 0.22606658468567495, Accuracy: -0.46300213356685127\n",
      "Power operation: base = 0.8266124775089763, power = 2, grad = 0.25\n",
      "Power operation: base = 0.07909792039203811, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45103297645491836, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10625875921091854, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989829665696993, 0.9904797949881092, -0.9744612804222792, -0.9974906422985993]\n",
      "Layer: Layer 1, Input: [0.989829665696993, 0.9904797949881092, -0.9744612804222792, -0.9974906422985993], Output: [-0.9979319924657969, -0.7132543459299503, -0.9925702623579035, -0.9736857748140042]\n",
      "Layer: Layer 2, Input: [-0.9979319924657969, -0.7132543459299503, -0.9925702623579035, -0.9736857748140042], Output: [1.8277044481643214]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982142521615927, 0.9835076123735872, 0.004740695971086819, -0.936381396566973]\n",
      "Layer: Layer 1, Input: [0.9982142521615927, 0.9835076123735872, 0.004740695971086819, -0.936381396566973], Output: [-0.9969274178516943, 0.8196405508307697, -0.9804963730748693, -0.9628549792053128]\n",
      "Layer: Layer 2, Input: [-0.9969274178516943, 0.8196405508307697, -0.9804963730748693, -0.9628549792053128], Output: [-0.9229733745076816]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.933138231589487, 0.4435168951075736, 0.42535081832532523, -0.883277829862559]\n",
      "Layer: Layer 1, Input: [0.933138231589487, 0.4435168951075736, 0.42535081832532523, -0.883277829862559], Output: [-0.9866353717733269, 0.998518540357648, -0.9433021954866734, -0.8935551757182464]\n",
      "Layer: Layer 2, Input: [-0.9866353717733269, 0.998518540357648, -0.9433021954866734, -0.8935551757182464], Output: [-1.4513400432085142]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8881867203725651, 0.9889678673569761, -0.8003643493479358, -0.9298535765078686]\n",
      "Layer: Layer 1, Input: [0.8881867203725651, 0.9889678673569761, -0.8003643493479358, -0.9298535765078686], Output: [-0.9970700073184787, -0.19604967362551884, -0.988930884886992, -0.9666538745857306]\n",
      "Layer: Layer 2, Input: [-0.9970700073184787, -0.19604967362551884, -0.988930884886992, -0.9666538745857306], Output: [0.8940229421601806]\n",
      "Epoch 455/500, Loss: 0.22649168148439638, Accuracy: -0.4620481747049734\n",
      "Power operation: base = 0.8277044481643214, power = 2, grad = 0.25\n",
      "Power operation: base = 0.07702662549231842, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4513400432085142, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10597705783981937, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989832296627025, 0.9904946723385528, -0.9744666057002681, -0.9974920347459356]\n",
      "Layer: Layer 1, Input: [0.989832296627025, 0.9904946723385528, -0.9744666057002681, -0.9974920347459356], Output: [-0.9979355209722338, -0.7140344866313317, -0.9926063257292519, -0.9738265405086362]\n",
      "Layer: Layer 2, Input: [-0.9979355209722338, -0.7140344866313317, -0.9926063257292519, -0.9738265405086362], Output: [1.8287918302988402]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982146019278298, 0.9835331321241242, 0.004644951779983092, -0.9364115114477554]\n",
      "Layer: Layer 1, Input: [0.9982146019278298, 0.9835331321241242, 0.004644951779983092, -0.9364115114477554], Output: [-0.9969327482062874, 0.8202675389141503, -0.9805888518480584, -0.9630405497440038]\n",
      "Layer: Layer 2, Input: [-0.9969327482062874, 0.8202675389141503, -0.9805888518480584, -0.9630405497440038], Output: [-0.9250362338706308]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331499823603153, 0.4441429303514899, 0.42527418859002347, -0.8833299386352297]\n",
      "Layer: Layer 1, Input: [0.9331499823603153, 0.4441429303514899, 0.42527418859002347, -0.8833299386352297], Output: [-0.9866749967080843, 0.9985324694461614, -0.9435866461979274, -0.8941177402155209]\n",
      "Layer: Layer 2, Input: [-0.9866749967080843, 0.9985324694461614, -0.9435866461979274, -0.8941177402155209], Output: [-1.4516458877275547]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8882096660231592, 0.9889850214591785, -0.8003999420887984, -0.9298881742576652]\n",
      "Layer: Layer 1, Input: [0.8882096660231592, 0.9889850214591785, -0.8003999420887984, -0.9298881742576652], Output: [-0.9970752684717896, -0.19648778121279664, -0.9889848339951236, -0.9668296936746898]\n",
      "Layer: Layer 2, Input: [-0.9970752684717896, -0.19648778121279664, -0.9889848339951236, -0.9668296936746898], Output: [0.8943030051933114]\n",
      "Epoch 456/500, Loss: 0.2269178317036941, Accuracy: -0.4610984789624526\n",
      "Power operation: base = 0.8287918302988402, power = 2, grad = 0.25\n",
      "Power operation: base = 0.07496376612936917, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45164588772755465, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1056969948066886, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989834920600867, 0.9905094961624896, -0.9744719285526183, -0.997493424020919]\n",
      "Layer: Layer 1, Input: [0.989834920600867, 0.9905094961624896, -0.9744719285526183, -0.997493424020919], Output: [-0.9979390383369628, -0.7148094173017552, -0.99264213790958, -0.9739662570958341]\n",
      "Layer: Layer 2, Input: [-0.9979390383369628, -0.7148094173017552, -0.99264213790958, -0.9739662570958341], Output: [1.8298746913697652]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.99821495094099, 0.9835585610771109, 0.004549199970296618, -0.936441569978687]\n",
      "Layer: Layer 1, Input: [0.99821495094099, 0.9835585610771109, 0.004549199970296618, -0.936441569978687], Output: [-0.9969380620504975, 0.8208915495759732, -0.9806807204869861, -0.9632248714496877]\n",
      "Layer: Layer 2, Input: [-0.9969380620504975, 0.8208915495759732, -0.9806807204869861, -0.9632248714496877], Output: [-0.9270906779122372]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331617097393595, 0.4447672665945688, 0.42519754041191116, -0.883381956154251]\n",
      "Layer: Layer 1, Input: [0.9331617097393595, 0.4447672665945688, 0.42519754041191116, -0.883381956154251], Output: [-0.9867144326580584, 0.9985462231803681, -0.9438692190164959, -0.8946766598474075]\n",
      "Layer: Layer 2, Input: [-0.9867144326580584, 0.9985462231803681, -0.9438692190164959, -0.8946766598474075], Output: [-1.4519504910150909]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8882325584004834, 0.9890021142161067, -0.8004355278325919, -0.9299227027676786]\n",
      "Layer: Layer 1, Input: [0.8882325584004834, 0.9890021142161067, -0.8004355278325919, -0.9299227027676786], Output: [-0.9970805125710422, -0.19692258794899978, -0.9890384110396663, -0.967004240781539]\n",
      "Layer: Layer 2, Input: [-0.9970805125710422, -0.19692258794899978, -0.9890384110396663, -0.967004240781539], Output: [0.8945814267435015]\n",
      "Epoch 457/500, Loss: 0.22734502363489445, Accuracy: -0.4601530777291174\n",
      "Power operation: base = 0.8298746913697652, power = 2, grad = 0.25\n",
      "Power operation: base = 0.0729093220877628, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4519504910150909, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1054185732564985, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898375376483731, 0.9905242666895839, -0.9744772489583068, -0.9974948101328959]\n",
      "Layer: Layer 1, Input: [0.9898375376483731, 0.9905242666895839, -0.9744772489583068, -0.9974948101328959], Output: [-0.997942544604629, -0.7155791674779726, -0.9926777008435962, -0.9741049329912492]\n",
      "Layer: Layer 2, Input: [-0.997942544604629, -0.7155791674779726, -0.9926777008435962, -0.9741049329912492], Output: [1.8309530981747386]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982152992033618, 0.9835838996135954, 0.004453441166697288, -0.9364715722440453]\n",
      "Layer: Layer 1, Input: [0.9982152992033618, 0.9835838996135954, 0.004453441166697288, -0.9364715722440453], Output: [-0.9969433594458105, 0.8215126148300296, -0.9807719832255707, -0.963407952502078]\n",
      "Layer: Layer 2, Input: [-0.9969433594458105, 0.8215126148300296, -0.9807719832255707, -0.963407952502078], Output: [-0.9291367271675508]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331734137855181, 0.4453899082088226, 0.4251208743327233, -0.883433882510175]\n",
      "Layer: Layer 1, Input: [0.9331734137855181, 0.4453899082088226, 0.4251208743327233, -0.883433882510175], Output: [-0.9867536807076862, 0.9985598044826892, -0.9441499260902764, -0.895231953910216]\n",
      "Layer: Layer 2, Input: [-0.9867536807076862, 0.9985598044826892, -0.9441499260902764, -0.895231953910216], Output: [-1.4522538347298841]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.888255397693856, 0.9890191458876817, -0.8004711063789831, -0.929957162179393]\n",
      "Layer: Layer 1, Input: [0.888255397693856, 0.9890191458876817, -0.8004711063789831, -0.929957162179393], Output: [-0.9970857396853168, -0.19735408039319136, -0.9890916188287777, -0.9671775255213182]\n",
      "Layer: Layer 2, Input: [-0.9970857396853168, -0.19735408039319136, -0.9890916188287777, -0.9671775255213182], Output: [0.8948582039025048]\n",
      "Epoch 458/500, Loss: 0.2277732457793039, Accuracy: -0.4592120018345671\n",
      "Power operation: base = 0.8309530981747386, power = 2, grad = 0.25\n",
      "Power operation: base = 0.0708632728324492, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4522538347298841, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10514179609749519, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898401477993032, 0.9905389841480993, -0.9744825668963657, -0.9974961930911722]\n",
      "Layer: Layer 1, Input: [0.9898401477993032, 0.9905389841480993, -0.9744825668963657, -0.9974961930911722], Output: [-0.997946039819556, -0.7163437669173903, -0.9927130164619039, -0.9742425765524279]\n",
      "Layer: Layer 2, Input: [-0.997946039819556, -0.7163437669173903, -0.9927130164619039, -0.9742425765524279], Output: [1.8320271168499405]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982156467172236, 0.9836091481123413, 0.004357675993360332, -0.9365015183276756]\n",
      "Layer: Layer 1, Input: [0.9982156467172236, 0.9836091481123413, 0.004357675993360332, -0.9365015183276756], Output: [-0.9969486404532648, 0.8221307661750842, -0.9808626442746765, -0.9635898010531233]\n",
      "Layer: Layer 2, Input: [-0.9969486404532648, 0.8221307661750842, -0.9808626442746765, -0.9635898010531233], Output: [-0.931174402488935]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331850945573499, 0.44601085954864206, 0.42504419089400636, -0.8834857177929749]\n",
      "Layer: Layer 1, Input: [0.9331850945573499, 0.44601085954864206, 0.42504419089400636, -0.8834857177929749], Output: [-0.9867927419332126, 0.9985732162177121, -0.9444287795222578, -0.8957836417347553]\n",
      "Layer: Layer 2, Input: [-0.9867927419332126, 0.9985732162177121, -0.9444287795222578, -0.8957836417347553], Output: [-1.4525559011793314]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8882781840918887, 0.9890361167322543, -0.8005066775279744, -0.9299915526336524]\n",
      "Layer: Layer 1, Input: [0.8882781840918887, 0.9890361167322543, -0.8005066775279744, -0.9299915526336524], Output: [-0.9970909498832027, -0.1977822458905546, -0.9891444601515242, -0.9673495574526321]\n",
      "Layer: Layer 2, Input: [-0.9970909498832027, -0.1977822458905546, -0.9891444601515242, -0.9673495574526321], Output: [0.8951333339971983]\n",
      "Epoch 459/500, Loss: 0.2282024868442899, Accuracy: -0.45827528154313857\n",
      "Power operation: base = 0.8320271168499405, power = 2, grad = 0.25\n",
      "Power operation: base = 0.06882559751106498, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4525559011793314, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1048666660028017, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898427510833232, 0.9905536487649305, -0.9744878823458901, -0.9974975729050166]\n",
      "Layer: Layer 1, Input: [0.9898427510833232, 0.9905536487649305, -0.9744878823458901, -0.9974975729050166], Output: [-0.9979495240257554, -0.7171032455874341, -0.9927480866810976, -0.9743791960790632]\n",
      "Layer: Layer 2, Input: [-0.9979495240257554, -0.7171032455874341, -0.9927480866810976, -0.9743791960790632], Output: [1.8330968128684084]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982159934848432, 0.9836343069498831, 0.004261905073794846, -0.9365314083130353]\n",
      "Layer: Layer 1, Input: [0.9982159934848432, 0.9836343069498831, 0.004261905073794846, -0.9365314083130353], Output: [-0.9969539051334653, 0.822746034602054, -0.9809527078221737, -0.9637704252267095]\n",
      "Layer: Layer 2, Input: [-0.9969539051334653, 0.822746034602054, -0.9809527078221737, -0.9637704252267095], Output: [-0.9332037250436214]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9331967521130891, 0.4466301249518232, 0.424967490636972, -0.8835374620921322]\n",
      "Layer: Layer 1, Input: [0.9331967521130891, 0.4466301249518232, 0.424967490636972, -0.8835374620921322], Output: [-0.9868316174028303, 0.9985864611934513, -0.9447057913702123, -0.8963317426837386]\n",
      "Layer: Layer 2, Input: [-0.9868316174028303, 0.9985864611934513, -0.9447057913702123, -0.8963317426837386], Output: [-1.4528566733123958]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8883009177825034, 0.9890530270066423, -0.8005422410799625, -0.9300258742707066]\n",
      "Layer: Layer 1, Input: [0.8883009177825034, 0.9890530270066423, -0.8005422410799625, -0.9300258742707066], Output: [-0.9970961432328096, -0.1982070725614106, -0.9891969377779932, -0.9675203460777314]\n",
      "Layer: Layer 2, Input: [-0.9970961432328096, -0.1982070725614106, -0.9891969377779932, -0.9675203460777314], Output: [0.8954068145878589]\n",
      "Epoch 460/500, Loss: 0.22863273573944412, Accuracy: -0.45734294654932395\n",
      "Power operation: base = 0.8330968128684084, power = 2, grad = 0.25\n",
      "Power operation: base = 0.06679627495637863, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45285667331239576, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10459318541214113, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989845347530006, 0.9905682607656353, -0.9744931952860435, -0.9974989495836608]\n",
      "Layer: Layer 1, Input: [0.989845347530006, 0.9905682607656353, -0.9744931952860435, -0.9974989495836608], Output: [-0.9979529972669333, -0.7178576336551022, -0.9927829134038583, -0.9745147998132426]\n",
      "Layer: Layer 2, Input: [-0.9979529972669333, -0.7178576336551022, -0.9927829134038583, -0.9745147998132426], Output: [1.8341622510385678]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998216339508479, 0.983659376500579, 0.004166129030674989, -0.9365612422832387]\n",
      "Layer: Layer 1, Input: [0.998216339508479, 0.983659376500579, 0.004166129030674989, -0.9365612422832387], Output: [-0.9969591535465943, 0.8233584506011136, -0.981042178032994, -0.9639498331183605]\n",
      "Layer: Layer 2, Input: [-0.9969591535465943, 0.8233584506011136, -0.981042178032994, -0.9639498331183605], Output: [-0.9352247163111507]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332083865106604, 0.44724770874056374, 0.4248907741023542, -0.8835891154967158]\n",
      "Layer: Layer 1, Input: [0.9332083865106604, 0.44724770874056374, 0.4248907741023542, -0.8835891154967158], Output: [-0.9868703081768188, 0.9985995421625797, -0.9449809736463879, -0.8968762761491905]\n",
      "Layer: Layer 2, Input: [-0.9868703081768188, 0.9985995421625797, -0.9449809736463879, -0.8968762761491905], Output: [-1.4531561347125095]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8883235989529468, 0.9890698769661668, -0.8005777968357954, -0.9300601272302571]\n",
      "Layer: Layer 1, Input: [0.8883235989529468, 0.9890698769661668, -0.8005777968357954, -0.9300601272302571], Output: [-0.9971013198017794, -0.19862854929026633, -0.989249054459404, -0.9676899008425918]\n",
      "Layer: Layer 2, Input: [-0.9971013198017794, -0.19862854929026633, -0.989249054459404, -0.9676899008425918], Output: [0.8956786434663915]\n",
      "Epoch 461/500, Loss: 0.22906398157282395, Accuracy: -0.4564150259735351\n",
      "Power operation: base = 0.8341622510385678, power = 2, grad = 0.25\n",
      "Power operation: base = 0.06477528368884933, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4531561347125095, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10432135653360852, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898479371688318, 0.9905828203744651, -0.9744985056960669, -0.9975003231363017]\n",
      "Layer: Layer 1, Input: [0.9898479371688318, 0.9905828203744651, -0.9744985056960669, -0.9975003231363017], Output: [-0.9979564595864984, -0.7186069614767088, -0.9928174985190479, -0.9746493959396939]\n",
      "Layer: Layer 2, Input: [-0.9979564595864984, -0.7186069614767088, -0.9928174985190479, -0.9746493959396939], Output: [1.8352234955029907]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982166847903794, 0.983684357136663, 0.004070348485675368, -0.9365910203211]\n",
      "Layer: Layer 1, Input: [0.9982166847903794, 0.983684357136663, 0.004070348485675368, -0.9365910203211], Output: [-0.9969643857524245, 0.8239680441687264, -0.9811310590491844, -0.964128032794937]\n",
      "Layer: Layer 2, Input: [-0.9969643857524245, 0.8239680441687264, -0.9811310590491844, -0.964128032794937], Output: [-0.937237398080681]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332199978076937, 0.44786361522242557, 0.4248140418302692, -0.8836406780954632]\n",
      "Layer: Layer 1, Input: [0.9332199978076937, 0.44786361522242557, 0.4248140418302692, -0.8836406780954632], Output: [-0.9869088153076772, 0.9986124618236313, -0.9452543383171979, -0.897417261549862]\n",
      "Layer: Layer 2, Input: [-0.9869088153076772, 0.9986124618236313, -0.9452543383171979, -0.897417261549862], Output: [-1.453454269590484]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.888346227789807, 0.9890866668646864, -0.8006133445968279, -0.9300943116515015]\n",
      "Layer: Layer 1, Input: [0.888346227789807, 0.9890866668646864, -0.8006133445968279, -0.9300943116515015], Output: [-0.9971064796572987, -0.19904666571486837, -0.9893008129282149, -0.9678582311369927]\n",
      "Layer: Layer 2, Input: [-0.9971064796572987, -0.19904666571486837, -0.9893008129282149, -0.9678582311369927], Output: [0.8959488186544995]\n",
      "Epoch 462/500, Loss: 0.2294962136472877, Accuracy: -0.4554915483582942\n",
      "Power operation: base = 0.8352234955029907, power = 2, grad = 0.25\n",
      "Power operation: base = 0.06276260191931904, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45345426959048396, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10405118134550051, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898505200291885, 0.9905973278143937, -0.9745038135552831, -0.9975016935721028]\n",
      "Layer: Layer 1, Input: [0.9898505200291885, 0.9905973278143937, -0.9745038135552831, -0.9975016935721028], Output: [-0.9979599110275688, -0.7193512595878099, -0.9928518439018017, -0.974782992586025]\n",
      "Layer: Layer 2, Input: [-0.9979599110275688, -0.7193512595878099, -0.9928518439018017, -0.974782992586025], Output: [1.836280609737349]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982170293327839, 0.983709249228295, 0.003974564059309972, -0.9366207425091742]\n",
      "Layer: Layer 1, Input: [0.9982170293327839, 0.983709249228295, 0.003974564059309972, -0.9366207425091742], Output: [-0.9969696018103313, 0.8245748448146107, -0.9812193549899597, -0.9643050322943394]\n",
      "Layer: Layer 2, Input: [-0.9969696018103313, 0.8245748448146107, -0.9812193549899597, -0.9643050322943394], Output: [-0.9392417924481746]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332315860615379, 0.44847784869126783, 0.42473729436007823, -0.883692149976856]\n",
      "Layer: Layer 1, Input: [0.9332315860615379, 0.44847784869126783, 0.42473729436007823, -0.883692149976856], Output: [-0.9869471398402555, 0.9986252228221744, -0.9455258973029101, -0.8979547183286513]\n",
      "Layer: Layer 2, Input: [-0.9869471398402555, 0.9986252228221744, -0.9455258973029101, -0.8979547183286513], Output: [-1.4537510627773829]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8883688044790274, 0.9891033969546319, -0.8006488841649756, -0.9301284276731749]\n",
      "Layer: Layer 1, Input: [0.8883688044790274, 0.9891033969546319, -0.8006488841649756, -0.9301284276731749], Output: [-0.9971116228661081, -0.19946141221527594, -0.9893522158982321, -0.9680253462945928]\n",
      "Layer: Layer 2, Input: [-0.9971116228661081, -0.19946141221527594, -0.9893522158982321, -0.9680253462945928], Output: [0.8962173384018097]\n",
      "Epoch 463/500, Loss: 0.22992942145689793, Accuracy: -0.4545725416647475\n",
      "Power operation: base = 0.836280609737349, power = 2, grad = 0.25\n",
      "Power operation: base = 0.06075820755182537, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45375106277738286, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10378266159819027, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898530961403728, 0.9906117833071467, -0.974509118843105, -0.997503060900195]\n",
      "Layer: Layer 1, Input: [0.9898530961403728, 0.9906117833071467, -0.974509118843105, -0.997503060900195], Output: [-0.9979633516329799, -0.7200905586933088, -0.9928859514136186, -0.9749155978229659]\n",
      "Layer: Layer 2, Input: [-0.9979633516329799, -0.7200905586933088, -0.9928859514136186, -0.9749155978229659], Output: [1.8373336565495695]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982173731379231, 0.9837340531436088, 0.00387877637077412, -0.9366504089297972]\n",
      "Layer: Layer 1, Input: [0.9982173731379231, 0.9837340531436088, 0.00387877637077412, -0.9366504089297972], Output: [-0.9969748017793026, 0.8251788815686273, -0.9813070699517527, -0.9644808396252061]\n",
      "Layer: Layer 2, Input: [-0.9969748017793026, 0.8251788815686273, -0.9813070699517527, -0.9644808396252061], Output: [-0.9412379218134816]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332431513292747, 0.44909041342814887, 0.4246605322302535, -0.8837435312291959]\n",
      "Layer: Layer 1, Input: [0.9332431513292747, 0.44909041342814887, 0.4246605322302535, -0.8837435312291959], Output: [-0.9869852828118806, 0.9986378277519585, -0.9457956624773364, -0.8984886659500332]\n",
      "Layer: Layer 2, Input: [-0.9869852828118806, 0.9986378277519585, -0.9457956624773364, -0.8984886659500332], Output: [-1.4540464997174016]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8883913292059209, 0.9891200674870384, -0.800684415342768, -0.9301624754335925]\n",
      "Layer: Layer 1, Input: [0.8883913292059209, 0.9891200674870384, -0.800684415342768, -0.9301624754335925], Output: [-0.9971167494945156, -0.19987277990295052, -0.9894032660647115, -0.9681912555930041]\n",
      "Layer: Layer 2, Input: [-0.9971167494945156, -0.19987277990295052, -0.9894032660647115, -0.9681912555930041], Output: [0.8964842011839202]\n",
      "Epoch 464/500, Loss: 0.23036359468340661, Accuracy: -0.4536580332695692\n",
      "Power operation: base = 0.8373336565495695, power = 2, grad = 0.25\n",
      "Power operation: base = 0.05876207818651835, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45404649971740163, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10351579881607975, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898556655315897, 0.9906261870732291, -0.9745144215390412, -0.9975044251296784]\n",
      "Layer: Layer 1, Input: [0.9898556655315897, 0.9906261870732291, -0.9745144215390412, -0.9975044251296784], Output: [-0.9979667814452908, -0.7208248896577555, -0.9929198229024502, -0.9750472196646036]\n",
      "Layer: Layer 2, Input: [-0.9979667814452908, -0.7208248896577555, -0.9929198229024502, -0.9750472196646036], Output: [1.838382698079199]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998217716208019, 0.9837587692487607, 0.003782986037791494, -0.9366800196651253]\n",
      "Layer: Layer 1, Input: [0.998217716208019, 0.9837587692487607, 0.003782986037791494, -0.9366800196651253], Output: [-0.9969799857179519, 0.8257801829876064, -0.9813942080082624, -0.9646554627666187]\n",
      "Layer: Layer 2, Input: [-0.9969799857179519, 0.8257801829876064, -0.9813942080082624, -0.9646554627666187], Output: [-0.943225808877302]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332546936677322, 0.44970131370219896, 0.4245837559782473, -0.8837948219406763]\n",
      "Layer: Layer 1, Input: [0.9332546936677322, 0.44970131370219896, 0.4245837559782473, -0.8837948219406763], Output: [-0.9870232452524808, 0.9986502791560342, -0.9460636456675205, -0.8990191238975019]\n",
      "Layer: Layer 2, Input: [-0.9870232452524808, 0.9986502791560342, -0.9460636456675205, -0.8990191238975019], Output: [-1.4543405664607238]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8884138021551834, 0.9891366787115782, -0.8007199379334011, -0.9301964550706893]\n",
      "Layer: Layer 1, Input: [0.8884138021551834, 0.9891366787115782, -0.8007199379334011, -0.9301964550706893], Output: [-0.9971218596084054, -0.2002807606098775, -0.9894539661044633, -0.9683559682538686]\n",
      "Layer: Layer 2, Input: [-0.9971218596084054, -0.2002807606098775, -0.9894539661044633, -0.9683559682538686], Output: [0.8967494057004259]\n",
      "Epoch 465/500, Loss: 0.2307987231928152, Accuracy: -0.452748049962195\n",
      "Power operation: base = 0.8383826980791991, power = 2, grad = 0.25\n",
      "Power operation: base = 0.05677419112269799, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45434056646072385, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10325059429957406, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898582282319537, 0.9906405393319523, -0.974519721622702, -0.9975057862696233]\n",
      "Layer: Layer 1, Input: [0.9898582282319537, 0.9906405393319523, -0.974519721622702, -0.9975057862696233], Output: [-0.997970200506791, -0.7215542834958117, -0.992953460202789, -0.9751778660686187]\n",
      "Layer: Layer 2, Input: [-0.997970200506791, -0.7215542834958117, -0.992953460202789, -0.9751778660686187], Output: [1.839427795796964]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982180585452854, 0.9837833979079736, 0.0036871936764638633, -0.936709574797172]\n",
      "Layer: Layer 1, Input: [0.9982180585452854, 0.9837833979079736, 0.0036871936764638633, -0.936709574797172], Output: [-0.9969851536845274, 0.8263787771620968, -0.9814807732105014, -0.9648289096678041]\n",
      "Layer: Layer 2, Input: [-0.9969851536845274, 0.8263787771620968, -0.9814807732105014, -0.9648289096678041], Output: [-0.9452054766380398]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332662131334974, 0.450310553771464, 0.4245069661403636, -0.883846022199453]\n",
      "Layer: Layer 1, Input: [0.9332662131334974, 0.450310553771464, 0.4245069661403636, -0.883846022199453], Output: [-0.9870610281847043, 0.9986625795278462, -0.9463298586534304, -0.8995461116710246]\n",
      "Layer: Layer 2, Input: [-0.9870610281847043, 0.9986625795278462, -0.9463298586534304, -0.8995461116710246], Output: [-1.454633249656367]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8884362235109072, 0.9891532308765907, -0.8007554517407856, -0.930230366722058]\n",
      "Layer: Layer 1, Input: [0.8884362235109072, 0.9891532308765907, -0.8007554517407856, -0.930230366722058], Output: [-0.9971269532732487, -0.20068534687769987, -0.9895043186759526, -0.9685194934429295]\n",
      "Layer: Layer 2, Input: [-0.9971269532732487, -0.20068534687769987, -0.9895043186759526, -0.9685194934429295], Output: [0.8970129508728748]\n",
      "Epoch 466/500, Loss: 0.23123479703200883, Accuracy: -0.4518426179424164\n",
      "Power operation: base = 0.839427795796964, power = 2, grad = 0.25\n",
      "Power operation: base = 0.05479452336196022, power = 2, grad = 0.25\n",
      "Power operation: base = -0.454633249656367, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1029870491271252, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898607842704886, 0.9906548403014598, -0.9745250190738062, -0.9975071443290716]\n",
      "Layer: Layer 1, Input: [0.9898607842704886, 0.9906548403014598, -0.9745250190738062, -0.9975071443290716], Output: [-0.9979736088595075, -0.7222787713629002, -0.9929868651357556, -0.9753075449365175]\n",
      "Layer: Layer 2, Input: [-0.9979736088595075, -0.7222787713629002, -0.9929868651357556, -0.9753075449365175], Output: [1.840469010504508]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982184001519281, 0.9838079394835822, 0.0035913999011237133, -0.9367390744078454]\n",
      "Layer: Layer 1, Input: [0.9982184001519281, 0.9838079394835822, 0.0035913999011237133, -0.9367390744078454], Output: [-0.9969903057369234, 0.8269746917230562, -0.9815667695868404, -0.9650011882478403]\n",
      "Layer: Layer 2, Input: [-0.9969903057369234, 0.8269746917230562, -0.9815667695868404, -0.9650011882478403], Output: [-0.9471769483885701]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332777097829291, 0.45091813788371893, 0.4244301632516326, -0.8838971320937117]\n",
      "Layer: Layer 1, Input: [0.9332777097829291, 0.45091813788371893, 0.4244301632516326, -0.8838971320937117], Output: [-0.9870986326240377, 0.9986747313123011, -0.9465943131676463, -0.9000696487845079]\n",
      "Layer: Layer 2, Input: [-0.9870986326240377, 0.9986747313123011, -0.9465943131676463, -0.9000696487845079], Output: [-1.4549245365450298]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8884585934565937, 0.9891697242291131, -0.8007909565695979, -0.9302642105249879]\n",
      "Layer: Layer 1, Input: [0.8884585934565937, 0.9891697242291131, -0.8007909565695979, -0.9302642105249879], Output: [-0.9971320305541141, -0.20108653194687984, -0.9895543264193983, -0.9686818402701062]\n",
      "Layer: Layer 2, Input: [-0.9971320305541141, -0.20108653194687984, -0.9895543264193983, -0.9686818402701062], Output: [0.8972748358426639]\n",
      "Epoch 467/500, Loss: 0.23167180642545815, Accuracy: -0.4509417628183039\n",
      "Power operation: base = 0.8404690105045081, power = 2, grad = 0.25\n",
      "Power operation: base = 0.05282305161142986, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45492453654502985, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10272516415733612, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898633336761284, 0.9906690901987532, -0.9745303138721855, -0.9975084993170379]\n",
      "Layer: Layer 1, Input: [0.9898633336761284, 0.9906690901987532, -0.9745303138721855, -0.9975084993170379], Output: [-0.9979770065452108, -0.7229983845460386, -0.9930200395091832, -0.9754362641138643]\n",
      "Layer: Layer 2, Input: [-0.9979770065452108, -0.7229983845460386, -0.9930200395091832, -0.9754362641138643], Output: [1.8415064023343506]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982187410301452, 0.9838323943360759, 0.0034956053241915466, -0.9367685185789827]\n",
      "Layer: Layer 1, Input: [0.9982187410301452, 0.9838323943360759, 0.0034956053241915466, -0.9367685185789827], Output: [-0.9969954419326903, 0.8275679538484654, -0.9816522011430536, -0.9651723063953651]\n",
      "Layer: Layer 2, Input: [-0.9969954419326903, 0.8275679538484654, -0.9816522011430536, -0.9651723063953651], Output: [-0.9491402477128785]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9332891836721701, 0.45152407027725566, 0.42435334784568857, -0.8839481517117342]\n",
      "Layer: Layer 1, Input: [0.9332891836721701, 0.45152407027725566, 0.42435334784568857, -0.8839481517117342], Output: [-0.987136059578918, 0.9986867369068113, -0.9468570208950567, -0.9005897547632848]\n",
      "Layer: Layer 2, Input: [-0.987136059578918, 0.9986867369068113, -0.9468570208950567, -0.9005897547632848], Output: [-1.4552144149519055]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.888480912175165, 0.9891861590149088, -0.8008264522253264, -0.9302979866164991]\n",
      "Layer: Layer 1, Input: [0.888480912175165, 0.9891861590149088, -0.8008264522253264, -0.9302979866164991], Output: [-0.9971370915156772, -0.2014843097458809, -0.989603991956872, -0.9688430177895675]\n",
      "Layer: Layer 2, Input: [-0.9971370915156772, -0.2014843097458809, -0.989603991956872, -0.9688430177895675], Output: [0.8975350599689049]\n",
      "Epoch 468/500, Loss: 0.2321097417719977, Accuracy: -0.45004550960447265\n",
      "Power operation: base = 0.8415064023343506, power = 2, grad = 0.25\n",
      "Power operation: base = 0.050859752287121474, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4552144149519055, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10246494003109508, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898658764777171, 0.9906832892397165, -0.974535605997792, -0.9975098512425105]\n",
      "Layer: Layer 1, Input: [0.9898658764777171, 0.9906832892397165, -0.974535605997792, -0.9975098512425105], Output: [-0.9979803936054206, -0.7237131544548371, -0.9930529851177011, -0.9755640313905113]\n",
      "Layer: Layer 2, Input: [-0.9979803936054206, -0.7237131544548371, -0.9930529851177011, -0.9755640313905113], Output: [1.8425400307499995]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982190811821275, 0.9838567628241401, 0.00339981055603666, -0.9367979073923852]\n",
      "Layer: Layer 1, Input: [0.9982190811821275, 0.9838567628241401, 0.00339981055603666, -0.9367979073923852], Output: [-0.9970005623290453, 0.8281585902698798, -0.9817370718623616, -0.9653422719682859]\n",
      "Layer: Layer 2, Input: [-0.9970005623290453, 0.8281585902698798, -0.9817370718623616, -0.9653422719682859], Output: [-0.9510953984826243]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9333006348571586, 0.4521283551816406, 0.42427652045465025, -0.8839990811419624]\n",
      "Layer: Layer 1, Input: [0.9333006348571586, 0.4521283551816406, 0.42427652045465025, -0.8839990811419624], Output: [-0.987173310050844, 0.9986985986623128, -0.9471179934725514, -0.9011064491416136]\n",
      "Layer: Layer 2, Input: [-0.987173310050844, 0.9986985986623128, -0.9471179934725514, -0.9011064491416136], Output: [-1.4555028732795048]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.888503179848976, 0.9892025354784963, -0.8008619385143194, -0.9303316951333797]\n",
      "Layer: Layer 1, Input: [0.888503179848976, 0.9892025354784963, -0.8008619385143194, -0.9303316951333797], Output: [-0.9971421362222298, -0.20187867488041578, -0.9896533178923941, -0.9690030349998061]\n",
      "Layer: Layer 2, Input: [-0.9971421362222298, -0.20187867488041578, -0.9896533178923941, -0.9690030349998061], Output: [0.8977936228262786]\n",
      "Epoch 469/500, Loss: 0.23254859364166128, Accuracy: -0.4491538827206014\n",
      "Power operation: base = 0.8425400307499995, power = 2, grad = 0.25\n",
      "Power operation: base = 0.048904601517375745, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4555028732795048, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10220637717372139, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898684127040089, 0.9906974376391399, -0.9745408954307019, -0.9975112001144525]\n",
      "Layer: Layer 1, Input: [0.9898684127040089, 0.9906974376391399, -0.9745408954307019, -0.9975112001144525], Output: [-0.9979837700814134, -0.7244231126126797, -0.9930857037428196, -0.9756908545008274]\n",
      "Layer: Layer 2, Input: [-0.9979837700814134, -0.7244231126126797, -0.9930857037428196, -0.9756908545008274], Output: [1.843569954546279]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982194206100587, 0.9838810453046967, 0.0033040162048402753, -0.9368272409298501]\n",
      "Layer: Layer 1, Input: [0.9982194206100587, 0.9838810453046967, 0.0033040162048402753, -0.9368272409298501], Output: [-0.9970056669828802, 0.8287466272789168, -0.9818213857054723, -0.9655110927934935]\n",
      "Layer: Layer 2, Input: [-0.9970056669828802, 0.8287466272789168, -0.9818213857054723, -0.9655110927934935], Output: [-0.9530424248536145]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9333120633936406, 0.4527309968184477, 0.4241996816090042, -0.8840499204730591]\n",
      "Layer: Layer 1, Input: [0.9333120633936406, 0.4527309968184477, 0.4241996816090042, -0.8840499204730591], Output: [-0.9872103850344833, 0.9987103188842616, -0.9473772424887199, -0.9016197514601982]\n",
      "Layer: Layer 2, Input: [-0.9872103850344833, 0.9987103188842616, -0.9473772424887199, -0.9016197514601982], Output: [-1.4557899005004566]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8885253966598253, 0.989218853863176, -0.8008974152438287, -0.9303653362122181]\n",
      "Layer: Layer 1, Input: [0.8885253966598253, 0.989218853863176, -0.8008974152438287, -0.9303653362122181], Output: [-0.9971471647376893, -0.20226962262267545, -0.9897023068120291, -0.9691619008437122]\n",
      "Layer: Layer 2, Input: [-0.9971471647376893, -0.20226962262267545, -0.9897023068120291, -0.9691619008437122], Output: [0.8980505242027705]\n",
      "Epoch 470/500, Loss: 0.23298835277259639, Accuracy: -0.4482669059903506\n",
      "Power operation: base = 0.8435699545462789, power = 2, grad = 0.25\n",
      "Power operation: base = 0.046957575146385544, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45578990050045665, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10194947579722946, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898709423836692, 0.9907115356107427, -0.974546182151122, -0.9975125459418029]\n",
      "Layer: Layer 1, Input: [0.9898709423836692, 0.9907115356107427, -0.974546182151122, -0.9975125459418029], Output: [-0.9979871360142265, -0.7251282906480702, -0.9931181971530099, -0.9758167411239262]\n",
      "Layer: Layer 2, Input: [-0.9979871360142265, -0.7251282906480702, -0.9931181971530099, -0.9758167411239262], Output: [1.8445962318498]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982197593161155, 0.9839052421329425, 0.003208222876462504, -0.9368565192732037]\n",
      "Layer: Layer 1, Input: [0.9982197593161155, 0.9839052421329425, 0.003208222876462504, -0.9368565192732037], Output: [-0.9970107559507725, 0.8293320907336688, -0.9819051466106239, -0.9656787766665775]\n",
      "Layer: Layer 2, Input: [-0.9970107559507725, 0.8293320907336688, -0.9819051466106239, -0.9656787766665775], Output: [-0.954981351262167]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.93332346933718, 0.45333199940196317, 0.4241228318374903, -0.8841006697939687]\n",
      "Layer: Layer 1, Input: [0.93332346933718, 0.45333199940196317, 0.4241228318374903, -0.8841006697939687], Output: [-0.9872472855177773, 0.9987218998336052, -0.9476347794835511, -0.9021296812637286]\n",
      "Layer: Layer 2, Input: [-0.9872472855177773, 0.9987218998336052, -0.9476347794835511, -0.9021296812637286], Output: [-1.4560754861503105]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8885475627889666, 0.9892351144110564, -0.8009328822220546, -0.9303989099894354]\n",
      "Layer: Layer 1, Input: [0.8885475627889666, 0.9892351144110564, -0.8009328822220546, -0.9303989099894354], Output: [-0.9971521771256078, -0.20265714890062633, -0.9897509612839788, -0.9693196242086501]\n",
      "Layer: Layer 2, Input: [-0.9971521771256078, -0.20265714890062633, -0.9897509612839788, -0.9693196242086501], Output: [0.8983057640974277]\n",
      "Epoch 471/500, Loss: 0.23342901006802785, Accuracy: -0.4473846026405157\n",
      "Power operation: base = 0.8445962318497999, power = 2, grad = 0.25\n",
      "Power operation: base = 0.04501864873783301, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45607548615031046, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10169423590257232, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898734655452739, 0.9907255833671957, -0.9745514661393941, -0.9975138887334781]\n",
      "Layer: Layer 1, Input: [0.9898734655452739, 0.9907255833671957, -0.9745514661393941, -0.9975138887334781], Output: [-0.9979904914446648, -0.7258287202861549, -0.9931504671037861, -0.9759416988838927]\n",
      "Layer: Layer 2, Input: [-0.9979904914446648, -0.7258287202861549, -0.9931504671037861, -0.9759416988838927], Output: [1.845618920119641]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982200973024682, 0.9839293536623878, 0.0031124311743140893, -0.9368857425043313]\n",
      "Layer: Layer 1, Input: [0.9982200973024682, 0.9839293536623878, 0.0031124311743140893, -0.9368857425043313], Output: [-0.9970158292889933, 0.8299150060650629, -0.9819883584936246, -0.965845331351548]\n",
      "Layer: Layer 2, Input: [-0.9970158292889933, 0.8299150060650629, -0.9819883584936246, -0.965845331351548], Output: [-0.9569122024214147]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9333348527431702, 0.45393136713986504, 0.42404597166699126, -0.8841513291939741]\n",
      "Layer: Layer 1, Input: [0.9333348527431702, 0.45393136713986504, 0.42404597166699126, -0.8841513291939741], Output: [-0.9872840124820425, 0.9987333437277324, -0.9478906159481382, -0.9026362580984403]\n",
      "Layer: Layer 2, Input: [-0.9872840124820425, 0.9987333437277324, -0.9478906159481382, -0.9026362580984403], Output: [-1.4563596203203204]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8885696784171178, 0.9892513173630799, -0.8009683392581888, -0.930432416601319]\n",
      "Layer: Layer 1, Input: [0.8885696784171178, 0.9892513173630799, -0.8009683392581888, -0.930432416601319], Output: [-0.9971571734491809, -0.2030412502873466, -0.9897992838586764, -0.9694762139265336]\n",
      "Layer: Layer 2, Input: [-0.9971571734491809, -0.2030412502873466, -0.9897992838586764, -0.9694762139265336], Output: [0.8985593427180749]\n",
      "Epoch 472/500, Loss: 0.2338705565932942, Accuracy: -0.44650699530047167\n",
      "Power operation: base = 0.8456189201196409, power = 2, grad = 0.25\n",
      "Power operation: base = 0.043087797578585274, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4563596203203204, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10144065728192508, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.98987598221731, 0.990739581120143, -0.9745567473760012, -0.9975152284983723]\n",
      "Layer: Layer 1, Input: [0.98987598221731, 0.990739581120143, -0.9745567473760012, -0.9975152284983723], Output: [-0.9979938364133063, -0.7265244333404127, -0.993182515337784, -0.97606573535001]\n",
      "Layer: Layer 2, Input: [-0.9979938364133063, -0.7265244333404127, -0.993182515337784, -0.97606573535001], Output: [1.846638076148185]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982204345712805, 0.9839533802448922, 0.003016641699229672, -0.9369149107052073]\n",
      "Layer: Layer 1, Input: [0.9982204345712805, 0.9839533802448922, 0.003016641699229672, -0.9369149107052073], Output: [-0.9970208870535175, 0.8304953982831442, -0.9820710252478931, -0.9660107645805583]\n",
      "Layer: Layer 2, Input: [-0.9970208870535175, 0.8304953982831442, -0.9820710252478931, -0.9660107645805583], Output: [-0.9588350033175086]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9333462136668438, 0.4545291042338777, 0.4239691016224243, -0.8842018987627526]\n",
      "Layer: Layer 1, Input: [0.9333462136668438, 0.4545291042338777, 0.4239691016224243, -0.8842018987627526], Output: [-0.9873205669020686, 0.9987446527414017, -0.9481447633243859, -0.9031395015096988]\n",
      "Layer: Layer 2, Input: [-0.9873205669020686, 0.9987446527414017, -0.9481447633243859, -0.9031395015096988], Output: [-1.4566422936502352]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8885917437244721, 0.9892674629590477, -0.8010037861624549, -0.9304658561840502]\n",
      "Layer: Layer 1, Input: [0.8885917437244721, 0.9892674629590477, -0.8010037861624549, -0.9304658561840502], Output: [-0.9971621537712554, -0.20342192399037562, -0.9898472770688778, -0.9696316787739045]\n",
      "Layer: Layer 2, Input: [-0.9971621537712554, -0.20342192399037562, -0.9898472770688778, -0.9696316787739045], Output: [0.8988112604789471]\n",
      "Epoch 473/500, Loss: 0.2343129835729442, Accuracy: -0.4456341060019646\n",
      "Power operation: base = 0.8466380761481851, power = 2, grad = 0.25\n",
      "Power operation: base = 0.041164996682491406, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45664229365023523, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1011887395210529, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898784924281759, 0.9907535290802226, -0.9745620258415703, -0.9975165652453576]\n",
      "Layer: Layer 1, Input: [0.9898784924281759, 0.9907535290802226, -0.9745620258415703, -0.9975165652453576], Output: [-0.9979971709605069, -0.7272154617045078, -0.9932143435848413, -0.9761888580369844]\n",
      "Layer: Layer 2, Input: [-0.9979971709605069, -0.7272154617045078, -0.9932143435848413, -0.9761888580369844], Output: [1.847653756062111]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.99822077112471, 0.9839773222307, 0.0029208550493446486, -0.936944023957924]\n",
      "Layer: Layer 1, Input: [0.99822077112471, 0.9839773222307, 0.0029208550493446486, -0.936944023957924], Output: [-0.9970259293000304, 0.8310732919833053, -0.982153150744497, -0.9661750840536321]\n",
      "Layer: Layer 2, Input: [-0.9970259293000304, 0.8310732919833053, -0.982153150744497, -0.9661750840536321], Output: [-0.9607497792057629]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9333575521632835, 0.4551252148804002, 0.4238922222266343, -0.8842523785904295]\n",
      "Layer: Layer 1, Input: [0.9333575521632835, 0.4551252148804002, 0.4238922222266343, -0.8842523785904295], Output: [-0.9873569497462165, 0.9987558290076477, -0.9483972330047209, -0.9036394310396061]\n",
      "Layer: Layer 2, Input: [-0.9873569497462165, 0.9987558290076477, -0.9483972330047209, -0.9036394310396061], Output: [-1.4569234973210667]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8886137588907068, 0.9892835514376432, -0.80103922274615, -0.9304992288737348]\n",
      "Layer: Layer 1, Input: [0.8886137588907068, 0.9892835514376432, -0.80103922274615, -0.9304992288737348], Output: [-0.9971671181543381, -0.2037991678411251, -0.9898949434297512, -0.9697860274720111]\n",
      "Layer: Layer 2, Input: [-0.9971671181543381, -0.2037991678411251, -0.9898949434297512, -0.9697860274720111], Output: [0.8990615179983266]\n",
      "Epoch 474/500, Loss: 0.23475628238787952, Accuracy: -0.4447659561790882\n",
      "Power operation: base = 0.8476537560621109, power = 2, grad = 0.25\n",
      "Power operation: base = 0.03925022079423712, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45692349732106674, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10093848200167344, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898809962061813, 0.9907674274570868, -0.9745673015168794, -0.9975178989832874]\n",
      "Layer: Layer 1, Input: [0.9898809962061813, 0.9907674274570868, -0.9745673015168794, -0.9975178989832874], Output: [-0.9980004951264061, -0.727901837344321, -0.9932459535620743, -0.9763110744051715]\n",
      "Layer: Layer 2, Input: [-0.9980004951264061, -0.727901837344321, -0.9932459535620743, -0.9763110744051715], Output: [1.8486660153235919]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982211069649085, 0.9840011799684747, 0.002825071819976854, -0.9369730823447188]\n",
      "Layer: Layer 1, Input: [0.9982211069649085, 0.9840011799684747, 0.002825071819976854, -0.9369730823447188], Output: [-0.9970309560839377, 0.8316487113524403, -0.9822347388321929, -0.9663382974383962]\n",
      "Layer: Layer 2, Input: [-0.9970309560839377, 0.8316487113524403, -0.9822347388321929, -0.9663382974383962], Output: [-0.962656555606701]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9333688682874315, 0.4557197032711116, 0.4238153340002925, -0.8843027687676304]\n",
      "Layer: Layer 1, Input: [0.9333688682874315, 0.4557197032711116, 0.4238153340002925, -0.8843027687676304], Output: [-0.9873931619765094, 0.9987668746186666, -0.9486480363318089, -0.9041360662246312]\n",
      "Layer: Layer 2, Input: [-0.9873931619765094, 0.9987668746186666, -0.9486480363318089, -0.9041360662246312], Output: [-1.457203223047867]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8886357240949925, 0.9892995830364556, -0.801074648821683, -0.9305325348064314]\n",
      "Layer: Layer 1, Input: [0.8886357240949925, 0.9892995830364556, -0.801074648821683, -0.9305325348064314], Output: [-0.9971720666606041, -0.20417298028433384, -0.9899422854389677, -0.9699392686868898]\n",
      "Layer: Layer 2, Input: [-0.9971720666606041, -0.20417298028433384, -0.9899422854389677, -0.9699392686868898], Output: [0.8993101160961539]\n",
      "Epoch 475/500, Loss: 0.23520044457257655, Accuracy: -0.44390256666860406\n",
      "Power operation: base = 0.8486660153235919, power = 2, grad = 0.25\n",
      "Power operation: base = 0.03734344439329895, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4572032230478671, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10068988390384614, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898834935795474, 0.9907812764594216, -0.97457257438286, -0.9975192297209947]\n",
      "Layer: Layer 1, Input: [0.9898834935795474, 0.9907812764594216, -0.97457257438286, -0.9975192297209947], Output: [-0.998003808950932, -0.7285835922901249, -0.9932773469739561, -0.9764323918608004]\n",
      "Layer: Layer 2, Input: [-0.998003808950932, -0.7285835922901249, -0.9932773469739561, -0.9764323918608004], Output: [1.8496749087315978]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998221442094022, 0.9840249538053312, 0.002729292603509314, -0.9370020859480008]\n",
      "Layer: Layer 1, Input: [0.998221442094022, 0.9840249538053312, 0.002729292603509314, -0.9370020859480008], Output: [-0.9970359674603719, 0.8322216801750455, -0.9823157933374647, -0.966500412369816]\n",
      "Layer: Layer 2, Input: [-0.9970359674603719, 0.8322216801750455, -0.9823157933374647, -0.966500412369816], Output: [-0.9645553583020527]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.933380162094099, 0.45631257359355176, 0.42373843746179485, -0.8843530693855299]\n",
      "Layer: Layer 1, Input: [0.933380162094099, 0.45631257359355176, 0.42373843746179485, -0.8843530693855299], Output: [-0.9874292045487253, 0.9987777916266826, -0.9488971845982744, -0.9046294265932676]\n",
      "Layer: Layer 2, Input: [-0.9874292045487253, 0.9987777916266826, -0.9488971845982744, -0.9046294265932676], Output: [-1.4574814630724964]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.888657639516002, 0.9893155579920019, -0.8011100642026132, -0.9305657741181783]\n",
      "Layer: Layer 1, Input: [0.888657639516002, 0.9893155579920019, -0.8011100642026132, -0.9305657741181783], Output: [-0.9971769993519035, -0.20454336036755677, -0.9899893055767894, -0.9700914110294475]\n",
      "Layer: Layer 2, Input: [-0.9971769993519035, -0.20454336036755677, -0.9899893055767894, -0.9700914110294475], Output: [0.8995570557915746]\n",
      "Epoch 476/500, Loss: 0.2356454618123384, Accuracy: -0.4430439577104668\n",
      "Power operation: base = 0.8496749087315978, power = 2, grad = 0.25\n",
      "Power operation: base = 0.035444641697947254, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4574814630724964, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10044294420842537, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898859845764071, 0.9907950762949659, -0.974577844420603, -0.9975205574672944]\n",
      "Layer: Layer 1, Input: [0.9898859845764071, 0.9907950762949659, -0.974577844420603, -0.9975205574672944], Output: [-0.9980071124738059, -0.7292607586289438, -0.9933085255123911, -0.976552817756199]\n",
      "Layer: Layer 2, Input: [-0.9980071124738059, -0.7292607586289438, -0.9933085255123911, -0.976552817756199], Output: [1.85068049042341]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982217765141911, 0.9840486440868682, 0.002633517989278164, -0.9370310348503774]\n",
      "Layer: Layer 1, Input: [0.9982217765141911, 0.9840486440868682, 0.002633517989278164, -0.9370310348503774], Output: [-0.997040963484202, 0.8327922218392522, -0.982396318064562, -0.966661436449938]\n",
      "Layer: Layer 2, Input: [-0.997040963484202, 0.8327922218392522, -0.982396318064562, -0.966661436449938], Output: [-0.9664462133306699]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9333914336379755, 0.4569038300316783, 0.42366153312716515, -0.8844032805359018]\n",
      "Layer: Layer 1, Input: [0.9333914336379755, 0.4569038300316783, 0.42366153312716515, -0.8844032805359018], Output: [-0.9874650784124847, 0.9987885820447922, -0.9491446890464259, -0.9051195316637168]\n",
      "Layer: Layer 2, Input: [-0.9874650784124847, 0.9987885820447922, -0.9491446890464259, -0.9051195316637168], Output: [-1.4577582101563893]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8886795053319181, 0.9893314765397486, -0.8011454687036864, -0.9305989469450192]\n",
      "Layer: Layer 1, Input: [0.8886795053319181, 0.9893314765397486, -0.8011454687036864, -0.9305989469450192], Output: [-0.9971819162897697, -0.2049103077307077, -0.9900360063061584, -0.9702424630555452]\n",
      "Layer: Layer 2, Input: [-0.9971819162897697, -0.2049103077307077, -0.9900360063061584, -0.9702424630555452], Output: [0.8998023383004838]\n",
      "Epoch 477/500, Loss: 0.236091325940624, Accuracy: -0.4421901489486455\n",
      "Power operation: base = 0.85068049042341, power = 2, grad = 0.25\n",
      "Power operation: base = 0.033553786669330066, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4577582101563893, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10019766169951616, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898884692248046, 0.9908088271705292, -0.9745831116113624, -0.9975218822309829]\n",
      "Layer: Layer 1, Input: [0.9898884692248046, 0.9908088271705292, -0.9745831116113624, -0.9975218822309829], Output: [-0.9980104057345479, -0.7299333684970606, -0.9933394908567931, -0.976672359390018]\n",
      "Layer: Layer 2, Input: [-0.9980104057345479, -0.7299333684970606, -0.9933394908567931, -0.976672359390018], Output: [1.8516828138762556]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998222110227551, 0.984072251157199, 0.0025377485634617567, -0.9370599291346775]\n",
      "Layer: Layer 1, Input: [0.998222110227551, 0.984072251157199, 0.0025377485634617567, -0.9370599291346775], Output: [-0.9970459442100394, 0.8333603593427953, -0.9824763167955389, -0.9668213772476336]\n",
      "Layer: Layer 2, Input: [-0.9970459442100394, 0.8333603593427953, -0.9824763167955389, -0.9668213772476336], Output: [-0.9683291469843915]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334026829736372, 0.4574934767664012, 0.4235846215099593, -0.8844534023111628]\n",
      "Layer: Layer 1, Input: [0.9334026829736372, 0.4574934767664012, 0.4235846215099593, -0.8844534023111628], Output: [-0.9875007845113365, 0.9987992478477921, -0.9493905608679865, -0.9056064009415985]\n",
      "Layer: Layer 2, Input: [-0.9875007845113365, 0.9987992478477921, -0.9493905608679865, -0.9056064009415985], Output: [-1.4580334575733183]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8887013217204421, 0.9893473389141325, -0.8011808621408718, -0.9306320534230283]\n",
      "Layer: Layer 1, Input: [0.8887013217204421, 0.9893473389141325, -0.8011808621408718, -0.9306320534230283], Output: [-0.9971868175354265, -0.20527382259566002, -0.990082390072782, -0.9703924332660858]\n",
      "Layer: Layer 2, Input: [-0.9971868175354265, -0.20527382259566002, -0.990082390072782, -0.9703924332660858], Output: [0.9000459650330424]\n",
      "Epoch 478/500, Loss: 0.23653802893641435, Accuracy: -0.4413411594321399\n",
      "Power operation: base = 0.8516828138762556, power = 2, grad = 0.25\n",
      "Power operation: base = 0.03167085301560846, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45803345757331826, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09995403496695765, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898909475526961, 0.99082252929201, -0.9745883759365586, -0.9975232040208409]\n",
      "Layer: Layer 1, Input: [0.9898909475526961, 0.99082252929201, -0.9745883759365586, -0.9975232040208409], Output: [-0.99801368877248, -0.7306014540726795, -0.9933702446741572, -0.9767910240074571]\n",
      "Layer: Layer 2, Input: [-0.99801368877248, -0.7306014540726795, -0.9933702446741572, -0.9767910240074571], Output: [1.8526819319090864]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982224432362318, 0.9840957753589807, 0.0024419849089749464, -0.937088768883976]\n",
      "Layer: Layer 1, Input: [0.9982224432362318, 0.9840957753589807, 0.0024419849089749464, -0.937088768883976], Output: [-0.9970509096922456, 0.8339261152989255, -0.9825557932902924, -0.9669802422983516]\n",
      "Layer: Layer 2, Input: [-0.9970509096922456, 0.8339261152989255, -0.9825557932902924, -0.9669802422983516], Output: [-0.9702041858038379]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334139101555564, 0.4580815179760949, 0.4235077031211736, -0.8845034348044196]\n",
      "Layer: Layer 1, Input: [0.9334139101555564, 0.4580815179760949, 0.4235077031211736, -0.8845034348044196], Output: [-0.9875363237828415, 0.9988097909729861, -0.9496348112038289, -0.9060900539176903]\n",
      "Layer: Layer 2, Input: [-0.9875363237828415, 0.9988097909729861, -0.9496348112038289, -0.9060900539176903], Output: [-1.4583071991021566]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.888723088858801, 0.9893631453485813, -0.8012162443313953, -0.9306650936883352]\n",
      "Layer: Layer 1, Input: [0.888723088858801, 0.9893631453485813, -0.8012162443313953, -0.9306650936883352], Output: [-0.9971917031497943, -0.20563390575586818, -0.9901284593052209, -0.9705413301071033]\n",
      "Layer: Layer 2, Input: [-0.9971917031497943, -0.20563390575586818, -0.9901284593052209, -0.9705413301071033], Output: [0.9002879375911235]\n",
      "Epoch 479/500, Loss: 0.23698556292162987, Accuracy: -0.4404970076162815\n",
      "Power operation: base = 0.8526819319090864, power = 2, grad = 0.25\n",
      "Power operation: base = 0.029795814196162063, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45830719910215656, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09971206240887653, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898934195879494, 0.9908361828644123, -0.9745936373777837, -0.9975245228456319]\n",
      "Layer: Layer 1, Input: [0.9898934195879494, 0.9908361828644123, -0.9745936373777837, -0.9975245228456319], Output: [-0.998016961626732, -0.7312650475687603, -0.9934007886191365, -0.9769088188004885]\n",
      "Layer: Layer 2, Input: [-0.998016961626732, -0.7312650475687603, -0.9934007886191365, -0.9769088188004885], Output: [1.8536778966845393]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982227755423588, 0.9841192170334434, 0.002346227605366005, -0.9371175541816166]\n",
      "Layer: Layer 1, Input: [0.9982227755423588, 0.9841192170334434, 0.002346227605366005, -0.9371175541816166], Output: [-0.9970558599849398, 0.8344895119422528, -0.9826347512866002, -0.9671380391038731]\n",
      "Layer: Layer 2, Input: [-0.9970558599849398, 0.8344895119422528, -0.9826347512866002, -0.9671380391038731], Output: [-0.9720713565741539]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334251152381091, 0.45866795783708836, 0.42343077846915445, -0.8845533781095102]\n",
      "Layer: Layer 1, Input: [0.9334251152381091, 0.45866795783708836, 0.42343077846915445, -0.8845533781095102], Output: [-0.9875716971586534, 0.9988202133209744, -0.9498774511437187, -0.9065705100656948]\n",
      "Layer: Layer 2, Input: [-0.9875716971586534, 0.9988202133209744, -0.9498774511437187, -0.9065705100656948], Output: [-1.4585794290196512]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8887448069237549, 0.989378896075532, -0.8012516150937739, -0.9306980678771465]\n",
      "Layer: Layer 1, Input: [0.8887448069237549, 0.989378896075532, -0.8012516150937739, -0.9306980678771465], Output: [-0.9971965731934989, -0.20599055856608192, -0.9901742164149728, -0.970689161969853]\n",
      "Layer: Layer 2, Input: [-0.9971965731934989, -0.20599055856608192, -0.9901742164149728, -0.970689161969853], Output: [0.9005282577658082]\n",
      "Epoch 480/500, Loss: 0.23743392015861045, Accuracy: -0.4396577113642284\n",
      "Power operation: base = 0.8536778966845393, power = 2, grad = 0.25\n",
      "Power operation: base = 0.02792864342584611, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4585794290196512, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09947174223419175, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898958853583442, 0.9908497880918622, -0.9745988959168048, -0.9975258387141038]\n",
      "Layer: Layer 1, Input: [0.9898958853583442, 0.9908497880918622, -0.9745988959168048, -0.9975258387141038], Output: [-0.9980202243362454, -0.7319241812259961, -0.9934311243341134, -0.9770257509080839]\n",
      "Layer: Layer 2, Input: [-0.9980202243362454, -0.7319241812259961, -0.9934311243341134, -0.9770257509080839], Output: [1.8546707597110057]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982231071480526, 0.9841425765204173, 0.00225047722871408, -0.9371462851112337]\n",
      "Layer: Layer 1, Input: [0.9982231071480526, 0.9841425765204173, 0.00225047722871408, -0.9371462851112337], Output: [-0.9970607951420051, 0.8350505711345322, -0.9827131945001599, -0.9672947751320736]\n",
      "Layer: Layer 2, Input: [-0.9970607951420051, 0.8350505711345322, -0.9827131945001599, -0.9672947751320736], Output: [-0.973930686320692]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334362982755832, 0.4592528005241335, 0.4233538480595111, -0.8846032323210447]\n",
      "Layer: Layer 1, Input: [0.9334362982755832, 0.4592528005241335, 0.4233538480595111, -0.8846032323210447], Output: [-0.9876069055645983, 0.9988305167564251, -0.9501184917260596, -0.907047788840038]\n",
      "Layer: Layer 2, Input: [-0.9876069055645983, 0.9988305167564251, -0.9501184917260596, -0.907047788840038], Output: [-1.4588501420931834]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8887664760916036, 0.9893945913264509, -0.8012869742478477, -0.9307309761257692]\n",
      "Layer: Layer 1, Input: [0.8887664760916036, 0.9893945913264509, -0.8012869742478477, -0.9307309761257692], Output: [-0.9972014277268751, -0.20634378293209218, -0.990219663796559, -0.9708359371909058]\n",
      "Layer: Layer 2, Input: [-0.9972014277268751, -0.20634378293209218, -0.990219663796559, -0.9708359371909058], Output: [0.9007669275348]\n",
      "Epoch 481/500, Loss: 0.23788309304762903, Accuracy: -0.43882328794869707\n",
      "Power operation: base = 0.8546707597110057, power = 2, grad = 0.25\n",
      "Power operation: base = 0.02606931367930798, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4588501420931834, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09923307246519997, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9898983448915717, 0.9908633451776236, -0.9746041515355669, -0.9975271516349901]\n",
      "Layer: Layer 1, Input: [0.9898983448915717, 0.9908633451776236, -0.9746041515355669, -0.9975271516349901], Output: [-0.9980234769397773, -0.7325788873059478, -0.9934612534492734, -0.9771418274164384]\n",
      "Layer: Layer 2, Input: [-0.9980234769397773, -0.7325788873059478, -0.9934612534492734, -0.9771418274164384], Output: [1.8556605718448536]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982234380554289, 0.9841658541583597, 0.00215473435153472, -0.9371749617567718]\n",
      "Layer: Layer 1, Input: [0.9982234380554289, 0.9841658541583597, 0.00215473435153472, -0.9371749617567718], Output: [-0.9970657152170953, 0.8356093143703878, -0.9827911266246279, -0.9674504578166901]\n",
      "Layer: Layer 2, Input: [-0.9970657152170953, 0.8356093143703878, -0.9827911266246279, -0.9674504578166901], Output: [-0.9757822023046572]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334474593221861, 0.4598360502108524, 0.42327691239503085, -0.8846529975344464]\n",
      "Layer: Layer 1, Input: [0.9334474593221861, 0.4598360502108524, 0.42327691239503085, -0.8846529975344464], Output: [-0.9876419499207503, 0.9988407031088282, -0.9503579439376476, -0.9075219096736983]\n",
      "Layer: Layer 2, Input: [-0.9876419499207503, 0.9988407031088282, -0.9503579439376476, -0.9075219096736983], Output: [-1.459119333573546]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8887880965381935, 0.9894102313318508, -0.8013223216148113, -0.930763818570631]\n",
      "Layer: Layer 1, Input: [0.8887880965381935, 0.9894102313318508, -0.8013223216148113, -0.930763818570631], Output: [-0.9972062668099765, -0.20669358130053708, -0.990264803827608, -0.9709816640522446]\n",
      "Layer: Layer 2, Input: [-0.9972062668099765, -0.20669358130053708, -0.990264803827608, -0.9709816640522446], Output: [0.9010039490598487]\n",
      "Epoch 482/500, Loss: 0.23833307412445912, Accuracy: -0.4379937540538936\n",
      "Power operation: base = 0.8556605718448536, power = 2, grad = 0.25\n",
      "Power operation: base = 0.024217797695342824, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45911933357354595, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09899605094015129, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989900798215235, 0.9908768543241143, -0.9746094042161974, -0.9975284616170097]\n",
      "Layer: Layer 1, Input: [0.989900798215235, 0.9908768543241143, -0.9746094042161974, -0.9975284616170097], Output: [-0.998026719475905, -0.7332291980843341, -0.993491177582677, -0.9772570553591973]\n",
      "Layer: Layer 2, Input: [-0.998026719475905, -0.7332291980843341, -0.993491177582677, -0.9772570553591973], Output: [1.8566473832927777]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982237682665995, 0.9841890502843806, 0.00205899954268273, -0.9372035842025085]\n",
      "Layer: Layer 1, Input: [0.9982237682665995, 0.9841890502843806, 0.00205899954268273, -0.9372035842025085], Output: [-0.9970706202636411, 0.836165762782974, -0.9828685513316573, -0.9676050945570928]\n",
      "Layer: Layer 2, Input: [-0.9970706202636411, 0.836165762782974, -0.9828685513316573, -0.9676050945570928], Output: [-0.9776259320186931]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334585984320525, 0.4604177110701652, 0.4231999719755965, -0.8847026738459878]\n",
      "Layer: Layer 1, Input: [0.9334585984320525, 0.4604177110701652, 0.4231999719755965, -0.8847026738459878], Output: [-0.9876768311415068, 0.9988507741732326, -0.9505958187134306, -0.9079928919760643]\n",
      "Layer: Layer 2, Input: [-0.9876768311415068, 0.9988507741732326, -0.9505958187134306, -0.9079928919760643], Output: [-1.4593869991877249]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8888096684389234, 0.9894258163213088, -0.8013576570172447, -0.9307965953483007]\n",
      "Layer: Layer 1, Input: [0.8888096684389234, 0.9894258163213088, -0.8013576570172447, -0.9307965953483007], Output: [-0.9972110905025787, -0.20703995664876343, -0.9903096388689389, -0.9711263507813643]\n",
      "Layer: Layer 2, Input: [-0.9972110905025787, -0.20703995664876343, -0.9903096388689389, -0.9711263507813643], Output: [0.9012393246841235]\n",
      "Epoch 483/500, Loss: 0.23878385605798647, Accuracy: -0.43716912577768596\n",
      "Power operation: base = 0.8566473832927777, power = 2, grad = 0.25\n",
      "Power operation: base = 0.022374067981306922, power = 2, grad = 0.25\n",
      "Power operation: base = -0.45938699918772485, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09876067531587651, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899032453568489, 0.9908903157329196, -0.974614653941009, -0.997529768668868]\n",
      "Layer: Layer 1, Input: [0.9899032453568489, 0.9908903157329196, -0.974614653941009, -0.997529768668868], Output: [-0.9980299519830294, -0.7338751458444653, -0.9935208983403314, -0.9773714417176833]\n",
      "Layer: Layer 2, Input: [-0.9980299519830294, -0.7338751458444653, -0.9935208983403314, -0.9773714417176833], Output: [1.8576312436142937]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982240977836716, 0.9842121652342676, 0.0019632733672624502, -0.9372321525330709]\n",
      "Layer: Layer 1, Input: [0.9982240977836716, 0.9842121652342676, 0.0019632733672624502, -0.9372321525330709], Output: [-0.9970755103348569, 0.836719937149578, -0.9829454722709389, -0.9677586927180646]\n",
      "Layer: Layer 2, Input: [-0.9970755103348569, 0.836719937149578, -0.9829454722709389, -0.9677586927180646], Output: [-0.979461903182421]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334697156592507, 0.4609977872746957, 0.4231230272981069, -0.8847522613528279]\n",
      "Layer: Layer 1, Input: [0.9334697156592507, 0.4609977872746957, 0.4231230272981069, -0.8847522613528279], Output: [-0.9877115501356607, 0.998860731710966, -0.9508321269362743, -0.9084607551308272]\n",
      "Layer: Layer 2, Input: [-0.9877115501356607, 0.998860731710966, -0.9508321269362743, -0.9084607551308272], Output: [-1.4596531351316724]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8888311919687507, 0.9894413465234831, -0.8013929802791406, -0.9308293065955089]\n",
      "Layer: Layer 1, Input: [0.8888311919687507, 0.9894413465234831, -0.8013929802791406, -0.9308293065955089], Output: [-0.9972158988641875, -0.20738291247476645, -0.9903541712646455, -0.9712700055513722]\n",
      "Layer: Layer 2, Input: [-0.9972158988641875, -0.20738291247476645, -0.9903541712646455, -0.9712700055513722], Output: [0.901473056929631]\n",
      "Epoch 484/500, Loss: 0.23923543164786382, Accuracy: -0.4363494186339141\n",
      "Power operation: base = 0.8576312436142937, power = 2, grad = 0.25\n",
      "Power operation: base = 0.02053809681757901, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4596531351316724, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09852694307036902, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899056863438396, 0.9909037296048074, -0.9746199006925034, -0.9975310727992575]\n",
      "Layer: Layer 1, Input: [0.9899056863438396, 0.9909037296048074, -0.9746199006925034, -0.9975310727992575], Output: [-0.9980331744993786, -0.7345167628708325, -0.9935504173162607, -0.9774849934211229]\n",
      "Layer: Layer 2, Input: [-0.9980331744993786, -0.7345167628708325, -0.9935504173162607, -0.9774849934211229], Output: [1.8586122017243367]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982244266087483, 0.9842351993425089, 0.0018675563865386906, -0.9372606668334547]\n",
      "Layer: Layer 1, Input: [0.9982244266087483, 0.9842351993425089, 0.0018675563865386906, -0.9372606668334547], Output: [-0.9970803854837456, 0.8372718578971637, -0.9830218930702393, -0.9679112596295845]\n",
      "Layer: Layer 2, Input: [-0.9970803854837456, 0.8372718578971637, -0.9830218930702393, -0.9679112596295845], Output: [-0.9812901437379704]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334808110577907, 0.46157628299715936, 0.42304607885639905, -0.8848017601530468]\n",
      "Layer: Layer 1, Input: [0.9334808110577907, 0.46157628299715936, 0.42304607885639905, -0.8848017601530468], Output: [-0.9877461078064712, 0.9988705774503391, -0.9510668794367344, -0.908925518493904]\n",
      "Layer: Layer 2, Input: [-0.9877461078064712, 0.9988705774503391, -0.9510668794367344, -0.908925518493904], Output: [-1.45991773806311]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8888526673021971, 0.9894568221661293, -0.8014282912259352, -0.9308619524491638]\n",
      "Layer: Layer 1, Input: [0.8888526673021971, 0.9894568221661293, -0.8014282912259352, -0.9308619524491638], Output: [-0.9972206919540427, -0.20772245278716492, -0.990398403342178, -0.9714126364810937]\n",
      "Layer: Layer 2, Input: [-0.9972206919540427, -0.20772245278716492, -0.990398403342178, -0.9714126364810937], Output: [0.9017051484945213]\n",
      "Epoch 485/500, Loss: 0.23968779382220765, Accuracy: -0.4355346475549551\n",
      "Power operation: base = 0.8586122017243367, power = 2, grad = 0.25\n",
      "Power operation: base = 0.01870985626202959, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4599177380631101, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09829485150547868, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989908121203545, 0.9909170961397418, -0.9746251444533738, -0.9975323740168577]\n",
      "Layer: Layer 1, Input: [0.989908121203545, 0.9909170961397418, -0.9746251444533738, -0.9975323740168577], Output: [-0.9980363870630132, -0.7351540814428363, -0.9935797360925772, -0.9775977173468738]\n",
      "Layer: Layer 2, Input: [-0.9980363870630132, -0.7351540814428363, -0.9935797360925772, -0.9775977173468738], Output: [1.8595903058960106]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982247547439292, 0.9842581529423176, 0.0017718491578507752, -0.9372891271890426]\n",
      "Layer: Layer 1, Input: [0.9982247547439292, 0.9842581529423176, 0.0017718491578507752, -0.9372891271890426], Output: [-0.9970852457631056, 0.8378215451078492, -0.9830978173354429, -0.9680628025866183]\n",
      "Layer: Layer 2, Input: [-0.9970852457631056, 0.8378215451078492, -0.9830978173354429, -0.9680628025866183], Output: [-0.9831106818454147]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9334918846816295, 0.4621532024107307, 0.42296912714117324, -0.8848511703456777]\n",
      "Layer: Layer 1, Input: [0.9334918846816295, 0.4621532024107307, 0.42296912714117324, -0.8848511703456777], Output: [-0.9877805050517312, 0.9988803130873342, -0.951300086992836, -0.9093872013913925]\n",
      "Layer: Layer 2, Input: [-0.9877805050517312, 0.9988803130873342, -0.951300086992836, -0.9093872013913925], Output: [-1.4601808050943292]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8888740946133534, 0.9894722434761157, -0.8014635896845336, -0.9308945330463713]\n",
      "Layer: Layer 1, Input: [0.8888740946133534, 0.9894722434761157, -0.8014635896845336, -0.9308945330463713], Output: [-0.9972254698311259, -0.20805858209526, -0.990442337412426, -0.9715542516351802]\n",
      "Layer: Layer 2, Input: [-0.9972254698311259, -0.20805858209526, -0.990442337412426, -0.9715542516351802], Output: [0.9019356022504761]\n",
      "Epoch 486/500, Loss: 0.24014093563534142, Accuracy: -0.434724826894449\n",
      "Power operation: base = 0.8595903058960106, power = 2, grad = 0.25\n",
      "Power operation: base = 0.016889318154585276, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46018080509432924, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09806439774952391, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899105499632146, 0.9909304155368959, -0.9746303852065081, -0.9975336723303369]\n",
      "Layer: Layer 1, Input: [0.9899105499632146, 0.9909304155368959, -0.9746303852065081, -0.9975336723303369], Output: [-0.9980395897118276, -0.735787133828668, -0.993608856239552, -0.9777096203206553]\n",
      "Layer: Layer 2, Input: [-0.9980395897118276, -0.735787133828668, -0.993608856239552, -0.9777096203206553], Output: [1.860565603763436]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982250821913096, 0.9842810263656525, 0.0016761522345306883, -0.9373175336856198]\n",
      "Layer: Layer 1, Input: [0.9982250821913096, 0.9842810263656525, 0.0016761522345306883, -0.9373175336856198], Output: [-0.9970900912255356, 0.8383690185243312, -0.9831732486505912, -0.9682133288489148]\n",
      "Layer: Layer 2, Input: [-0.9970900912255356, 0.8383690185243312, -0.9831732486505912, -0.9682133288489148], Output: [-0.9849235458782317]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335029365846783, 0.46272854968939287, 0.4228921726399205, -0.8849004920307401]\n",
      "Layer: Layer 1, Input: [0.9335029365846783, 0.46272854968939287, 0.4228921726399205, -0.8849004920307401], Output: [-0.9878147427638347, 0.9988899402862772, -0.9515317603298595, -0.9098458231175615]\n",
      "Layer: Layer 2, Input: [-0.9878147427638347, 0.9988899402862772, -0.9515317603298595, -0.9098458231175615], Output: [-1.4604423337850037]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8888954740758852, 0.9894876106794385, -0.8014988754833354, -0.93092704852445]\n",
      "Layer: Layer 1, Input: [0.8888954740758852, 0.9894876106794385, -0.8014988754833354, -0.93092704852445], Output: [-0.997230232554164, -0.2083913053991518, -0.9904859757698009, -0.9716948590242196]\n",
      "Layer: Layer 2, Input: [-0.997230232554164, -0.2083913053991518, -0.9904859757698009, -0.9716948590242196], Output: [0.9021644212400197]\n",
      "Epoch 487/500, Loss: 0.24059485026557348, Accuracy: -0.43391997043018815\n",
      "Power operation: base = 0.8605656037634359, power = 2, grad = 0.25\n",
      "Power operation: base = 0.015076454121768279, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46044233378500365, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09783557875998028, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899129726500091, 0.9909436879946648, -0.9746356229349921, -0.9975349677483508]\n",
      "Layer: Layer 1, Input: [0.9899129726500091, 0.9909436879946648, -0.9746356229349921, -0.9975349677483508], Output: [-0.9980427824835556, -0.7364159522793201, -0.9936377793156821, -0.9778207091167753]\n",
      "Layer: Layer 2, Input: [-0.9980427824835556, -0.7364159522793201, -0.9936377793156821, -0.9778207091167753], Output: [1.861538142324716]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982254089529813, 0.98430381994324, 0.0015804661658225675, -0.9373458864093904]\n",
      "Layer: Layer 1, Input: [0.9982254089529813, 0.98430381994324, 0.0015804661658225675, -0.9373458864093904], Output: [-0.9970949219234401, 0.8389142975552474, -0.9832481905779238, -0.9683628456408088]\n",
      "Layer: Layer 2, Input: [-0.9970949219234401, 0.8389142975552474, -0.9832481905779238, -0.9683628456408088], Output: [-0.9867287644186913]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335139668208087, 0.4633023290082679, 0.4228152158368522, -0.8849497253092683]\n",
      "Layer: Layer 1, Input: [0.9335139668208087, 0.4633023290082679, 0.4228152158368522, -0.8849497253092683], Output: [-0.9878488218298416, 0.9988994606804966, -0.9517619101201343, -0.9103014029328735]\n",
      "Layer: Layer 2, Input: [-0.9878488218298416, 0.9988994606804966, -0.9517619101201343, -0.9103014029328735], Output: [-1.4607023221350106]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8889168058630368, 0.9895029240012364, -0.8015341484522625, -0.9309594990209487]\n",
      "Layer: Layer 1, Input: [0.8889168058630368, 0.9895029240012364, -0.8015341484522625, -0.9309594990209487], Output: [-0.9972349801816356, -0.2087206281799252, -0.9905293206923153, -0.9718344666048501]\n",
      "Layer: Layer 2, Input: [-0.9972349801816356, -0.2087206281799252, -0.9905293206923153, -0.9718344666048501], Output: [0.9023916086738453]\n",
      "Epoch 488/500, Loss: 0.241049531013012, Accuracy: -0.43312009136719\n",
      "Power operation: base = 0.8615381423247159, power = 2, grad = 0.25\n",
      "Power operation: base = 0.013271235581308716, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4607023221350106, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09760839132615473, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899153892910008, 0.9909569137106784, -0.974640857622112, -0.9975362602795455]\n",
      "Layer: Layer 1, Input: [0.9899153892910008, 0.9909569137106784, -0.974640857622112, -0.9975362602795455], Output: [-0.9980459654157718, -0.7370405690227648, -0.993666506867762, -0.9779309904583616]\n",
      "Layer: Layer 2, Input: [-0.9980459654157718, -0.7370405690227648, -0.993666506867762, -0.9779309904583616], Output: [1.8625079679450476]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982257350310327, 0.9843265340045945, 0.0014847914968045323, -0.937374185446993]\n",
      "Layer: Layer 1, Input: [0.9982257350310327, 0.9843265340045945, 0.0014847914968045323, -0.937374185446993], Output: [-0.9970997379090343, 0.8394574012804779, -0.983322646657922, -0.9685113601510289]\n",
      "Layer: Layer 2, Input: [-0.9970997379090343, 0.8394574012804779, -0.983322646657922, -0.9685113601510289], Output: [-0.9885263662532306]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335249754438579, 0.4638745445439301, 0.42273825721283165, -0.8849988702833412]\n",
      "Layer: Layer 1, Input: [0.9335249754438579, 0.4638745445439301, 0.42273825721283165, -0.8849988702833412], Output: [-0.9878827431315395, 0.9989088758729653, -0.9519905469828376, -0.9107539600620416]\n",
      "Layer: Layer 2, Input: [-0.9878827431315395, 0.9989088758729653, -0.9519905469828376, -0.9107539600620416], Output: [-1.4609607685772792]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8889380901476361, 0.9895181836658041, -0.80156940842278, -0.93099188467366]\n",
      "Layer: Layer 1, Input: [0.8889380901476361, 0.9895181836658041, -0.80156940842278, -0.93099188467366], Output: [-0.9972397127717751, -0.2090465563899005, -0.9905723744416667, -0.9719730822798774]\n",
      "Layer: Layer 2, Input: [-0.9972397127717751, -0.2090465563899005, -0.9905723744416667, -0.9719730822798774], Output: [0.9026171679281205]\n",
      "Epoch 489/500, Loss: 0.24150497129743653, Accuracy: -0.4323252023409756\n",
      "Power operation: base = 0.8625079679450476, power = 2, grad = 0.25\n",
      "Power operation: base = 0.011473633746769352, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4609607685772792, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09738283207187948, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899177999131726, 0.9909700928818121, -0.9746460892513567, -0.9975375499325548]\n",
      "Layer: Layer 1, Input: [0.9899177999131726, 0.9909700928818121, -0.9746460892513567, -0.9975375499325548], Output: [-0.9980491385458967, -0.7376610162582359, -0.9936950404309511, -0.9780404710175928]\n",
      "Layer: Layer 2, Input: [-0.9980491385458967, -0.7376610162582359, -0.9936950404309511, -0.9780404710175928], Output: [1.8634751263598783]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982260604275487, 0.9843491688780375, 0.0013891287683172931, -0.937402430885513]\n",
      "Layer: Layer 1, Input: [0.9982260604275487, 0.9843491688780375, 0.0013891287683172931, -0.937402430885513], Output: [-0.9971045392343498, 0.8399983484563927, -0.9833966204093497, -0.968658879532514]\n",
      "Layer: Layer 2, Input: [-0.9971045392343498, 0.8399983484563927, -0.9833966204093497, -0.968658879532514], Output: [-0.9903163803678074]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335359625076348, 0.464445200474701, 0.4226612972453091, -0.8850479270561088]\n",
      "Layer: Layer 1, Input: [0.9335359625076348, 0.464445200474701, 0.4226612972453091, -0.8850479270561088], Output: [-0.9879165075455056, 0.9989181874369301, -0.9522176814838029, -0.9112035136921195]\n",
      "Layer: Layer 2, Input: [-0.9879165075455056, 0.9989181874369301, -0.9522176814838029, -0.9112035136921195], Output: [-1.4612176719706351]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8889593271020991, 0.9895333898966061, -0.8016046552279217, -0.9310242056206361]\n",
      "Layer: Layer 1, Input: [0.8889593271020991, 0.9895333898966061, -0.8016046552279217, -0.9310242056206361], Output: [-0.997244430382579, -0.20936909644295895, -0.9906151392633166, -0.9721107138983951]\n",
      "Layer: Layer 2, Input: [-0.997244430382579, -0.20936909644295895, -0.9906151392633166, -0.9721107138983951], Output: [0.9028411025417933]\n",
      "Epoch 490/500, Loss: 0.24196116465617387, Accuracy: -0.4315353154209127\n",
      "Power operation: base = 0.8634751263598783, power = 2, grad = 0.25\n",
      "Power operation: base = 0.009683619632192553, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4612176719706351, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09715889745820672, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899202045434193, 0.990983225704199, -0.9746513178064208, -0.9975388367160042]\n",
      "Layer: Layer 1, Input: [0.9899202045434193, 0.990983225704199, -0.9746513178064208, -0.9975388367160042], Output: [-0.9980523019111976, -0.7382773261506784, -0.993723381528842, -0.9781491574159301]\n",
      "Layer: Layer 2, Input: [-0.9980523019111976, -0.7382773261506784, -0.993723381528842, -0.9781491574159301], Output: [1.8644396626782296]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982263851446107, 0.9843717248907167, 0.001293478516888684, -0.937430622812499]\n",
      "Layer: Layer 1, Input: [0.9982263851446107, 0.9843717248907167, 0.001293478516888684, -0.937430622812499], Output: [-0.9971093259512391, 0.8405371575210333, -0.9834701153292971, -0.9688054109022333]\n",
      "Layer: Layer 2, Input: [-0.9971093259512391, 0.8405371575210333, -0.9834701153292971, -0.9688054109022333], Output: [-0.9920988359432137]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335469280659252, 0.4650143009809272, 0.4225843364082576, -0.8850968957318182]\n",
      "Layer: Layer 1, Input: [0.9335469280659252, 0.4650143009809272, 0.4225843364082576, -0.8850968957318182], Output: [-0.9879501159431658, 0.998927396916526, -0.9524433241353343, -0.9116500829706289]\n",
      "Layer: Layer 2, Input: [-0.9879501159431658, 0.998927396916526, -0.9524433241353343, -0.9116500829706289], Output: [-1.461473031592682]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8889805168984334, 0.9895485429162892, -0.8016398887023113, -0.9310564620002013]\n",
      "Layer: Layer 1, Input: [0.8889805168984334, 0.9895485429162892, -0.8016398887023113, -0.9310564620002013], Output: [-0.9972491330718091, -0.20968825520494122, -0.9906576173865719, -0.972247369255907]\n",
      "Layer: Layer 2, Input: [-0.9972491330718091, -0.20968825520494122, -0.9906576173865719, -0.972247369255907], Output: [0.9030634162138851]\n",
      "Epoch 491/500, Loss: 0.24241810474204167, Accuracy: -0.43075044211381286\n",
      "Power operation: base = 0.8644396626782296, power = 2, grad = 0.25\n",
      "Power operation: base = 0.007901164056786314, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46147303159268205, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09693658378611492, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899226032085461, 0.9909963123732402, -0.9746565432712065, -0.997540120638508]\n",
      "Layer: Layer 1, Input: [0.9899226032085461, 0.9909963123732402, -0.9746565432712065, -0.997540120638508], Output: [-0.9980554555487945, -0.7388895308253198, -0.9937515316735285, -0.9782570562243493]\n",
      "Layer: Layer 2, Input: [-0.9980554555487945, -0.7388895308253198, -0.9937515316735285, -0.9782570562243493], Output: [1.8654016213860913]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982267091842972, 0.9843942023686242, 0.001197841274668195, -0.9374587613159733]\n",
      "Layer: Layer 1, Input: [0.9982267091842972, 0.9843942023686242, 0.001197841274668195, -0.9374587613159733], Output: [-0.9971140981113791, 0.8410738465992447, -0.983543134893225, -0.9689509613410158]\n",
      "Layer: Layer 2, Input: [-0.9971140981113791, 0.8410738465992447, -0.983543134893225, -0.9689509613410158], Output: [-0.9938737623503959]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.933557872172497, 0.4655818502452429, 0.4225073751721122, -0.8851457764158381]\n",
      "Layer: Layer 1, Input: [0.933557872172497, 0.4655818502452429, 0.4225073751721122, -0.8851457764158381], Output: [-0.9879835691908521, 0.9989365058273776, -0.9526674853960281, -0.9120936870037192]\n",
      "Layer: Layer 2, Input: [-0.9879835691908521, 0.9989365058273776, -0.9526674853960281, -0.9120936870037192], Output: [-1.4617268471326863]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8890016597082419, 0.9895636429466951, -0.8016751086821843, -0.9310886539509653]\n",
      "Layer: Layer 1, Input: [0.8890016597082419, 0.9895636429466951, -0.8016751086821843, -0.9310886539509653], Output: [-0.9972538208969983, -0.21000403998410896, -0.9906998110246649, -0.9723830560944561]\n",
      "Layer: Layer 2, Input: [-0.9972538208969983, -0.21000403998410896, -0.9906998110246649, -0.9723830560944561], Output: [0.9032841128007743]\n",
      "Epoch 492/500, Loss: 0.2428757853213099, Accuracy: -0.42997059336760746\n",
      "Power operation: base = 0.8654016213860913, power = 2, grad = 0.25\n",
      "Power operation: base = 0.006126237649604072, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4617268471326863, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09671588719922575, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989924995935269, 0.9910093530836158, -0.974661765629827, -0.9975414017086719]\n",
      "Layer: Layer 1, Input: [0.989924995935269, 0.9910093530836158, -0.974661765629827, -0.9975414017086719], Output: [-0.9980585994956601, -0.7394976623623737, -0.9937794923656724, -0.9783641739635758]\n",
      "Layer: Layer 2, Input: [-0.9980585994956601, -0.7394976623623737, -0.9937794923656724, -0.9783641739635758], Output: [1.8663610463499074]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982270325486836, 0.9844166016366136, 0.0011022175693575441, -0.9374868464844451]\n",
      "Layer: Layer 1, Input: [0.9982270325486836, 0.9844166016366136, 0.0011022175693575441, -0.9374868464844451], Output: [-0.9971188557662772, 0.8416084335077407, -0.9836156825550084, -0.9690955378933832]\n",
      "Layer: Layer 2, Input: [-0.9971188557662772, 0.8416084335077407, -0.9836156825550084, -0.9690955378933832], Output: [-0.9956411891457249]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335687948811051, 0.46614785245281426, 0.42243041400371084, -0.885194569214682]\n",
      "Layer: Layer 1, Input: [0.9335687948811051, 0.46614785245281426, 0.42243041400371084, -0.885194569214682], Output: [-0.9880168681498591, 0.9989455156571866, -0.952890175670602, -0.9125343448543628]\n",
      "Layer: Layer 2, Input: [-0.9880168681498591, 0.9989455156571866, -0.952890175670602, -0.9125343448543628], Output: [-1.4619791186844866]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8890227557027262, 0.9895786902088718, -0.8017103150054078, -0.9311207816118348]\n",
      "Layer: Layer 1, Input: [0.8890227557027262, 0.9895786902088718, -0.8017103150054078, -0.9311207816118348], Output: [-0.9972584939154538, -0.21031645852168118, -0.9907417223748333, -0.9725177821027515]\n",
      "Layer: Layer 2, Input: [-0.9972584939154538, -0.21031645852168118, -0.9907417223748333, -0.9725177821027515], Output: [0.9035031963134603]\n",
      "Epoch 493/500, Loss: 0.2433342002716958, Accuracy: -0.4291957795752088\n",
      "Power operation: base = 0.8663610463499074, power = 2, grad = 0.25\n",
      "Power operation: base = 0.004358810854275141, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4619791186844866, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09649680368653968, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899273827502146, 0.9910223480292945, -0.9746669848666063, -0.9975426799350925]\n",
      "Layer: Layer 1, Input: [0.9899273827502146, 0.9910223480292945, -0.9746669848666063, -0.9975426799350925], Output: [-0.9980617337886246, -0.7401017527918895, -0.9938072650945717, -0.9784705171043176]\n",
      "Layer: Layer 2, Input: [-0.9980617337886246, -0.7401017527918895, -0.9938072650945717, -0.9784705171043176], Output: [1.8673179808202036]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982273552398422, 0.9844389230184162, 0.0010066079241498186, -0.9375148784069218]\n",
      "Layer: Layer 1, Input: [0.9982273552398422, 0.9844389230184162, 0.0010066079241498186, -0.9375148784069218], Output: [-0.9971235989672752, 0.8421409357601186, -0.9836877617469837, -0.969239147567392]\n",
      "Layer: Layer 2, Input: [-0.9971235989672752, 0.8421409357601186, -0.9836877617469837, -0.969239147567392], Output: [-0.9974011460662737]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335796962454963, 0.46671231179156913, 0.4223534533662374, -0.8852432742360292]\n",
      "Layer: Layer 1, Input: [0.9335796962454963, 0.46671231179156913, 0.4223534533662374, -0.8852432742360292], Output: [-0.988050013676498, 0.9989544278663065, -0.9531114053097329, -0.912972075540587]\n",
      "Layer: Layer 2, Input: [-0.988050013676498, 0.9989544278663065, -0.9531114053097329, -0.912972075540587], Output: [-1.462229846739426]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8890438050526901, 0.9895936849230852, -0.8017455075115003, -0.9311528451220262]\n",
      "Layer: Layer 1, Input: [0.8890438050526901, 0.9895936849230852, -0.8017455075115003, -0.9311528451220262], Output: [-0.9972631521842624, -0.21062551898246865, -0.9907833536183999, -0.9726515549163038]\n",
      "Layer: Layer 2, Input: [-0.9972631521842624, -0.21062551898246865, -0.9907833536183999, -0.9726515549163038], Output: [0.9037206709148764]\n",
      "Epoch 494/500, Loss: 0.24379334358040966, Accuracy: -0.4284260105784794\n",
      "Power operation: base = 0.8673179808202036, power = 2, grad = 0.25\n",
      "Power operation: base = 0.002598853933726275, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4622298467394259, power = 2, grad = 0.25\n",
      "Power operation: base = -0.0962793290851236, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899297636799205, 0.9910352974035433, -0.974672200966084, -0.9975439553263573]\n",
      "Layer: Layer 1, Input: [0.9899297636799205, 0.9910352974035433, -0.974672200966084, -0.9975439553263573], Output: [-0.9980648584643772, -0.7407018340887092, -0.9938348513382268, -0.9785760920675024]\n",
      "Layer: Layer 2, Input: [-0.9980648584643772, -0.7407018340887092, -0.9938348513382268, -0.9785760920675024], Output: [1.868272467435225]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982276772598423, 0.984461166836658, 0.0009110128576653276, -0.9375428571729194]\n",
      "Layer: Layer 1, Input: [0.9982276772598423, 0.984461166836658, 0.0009110128576653276, -0.9375428571729194], Output: [-0.997128327765552, 0.8426713705718116, -0.9837593758799928, -0.9693817973344809]\n",
      "Layer: Layer 2, Input: [-0.997128327765552, 0.8426713705718116, -0.9837593758799928, -0.9693817973344809], Output: [-0.9991536630250772]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9335905763194133, 0.4672752324524105, 0.4222764937191668, -0.8852918915887468]\n",
      "Layer: Layer 1, Input: [0.9335905763194133, 0.4672752324524105, 0.4222764937191668, -0.8852918915887468], Output: [-0.9880830066221495, 0.9989632438883047, -0.9533311846099004, -0.9134068980337399]\n",
      "Layer: Layer 2, Input: [-0.9880830066221495, 0.9989632438883047, -0.9533311846099004, -0.9134068980337399], Output: [-1.462479032179302]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8890648079285425, 0.9896086273088301, -0.8017806860416501, -0.9311848446210745]\n",
      "Layer: Layer 1, Input: [0.8890648079285425, 0.9896086273088301, -0.8017806860416501, -0.9311848446210745], Output: [-0.997267795760294, -0.210931229945552, -0.9908247069208527, -0.9727843821175618]\n",
      "Layer: Layer 2, Input: [-0.997267795760294, -0.210931229945552, -0.9908247069208527, -0.9727843821175618], Output: [0.903936540917142]\n",
      "Epoch 495/500, Loss: 0.24425320934219913, Accuracy: -0.4276612956723076\n",
      "Power operation: base = 0.8682724674352249, power = 2, grad = 0.25\n",
      "Power operation: base = 0.0008463369749227567, power = 2, grad = 0.25\n",
      "Power operation: base = -0.462479032179302, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09606345908285796, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899321387508341, 0.9910482013989372, -0.974677413913015, -0.997545227891046]\n",
      "Layer: Layer 1, Input: [0.9899321387508341, 0.9910482013989372, -0.974677413913015, -0.997545227891046], Output: [-0.9980679735594701, -0.7412979381675792, -0.9938622525634069, -0.9786809052245135]\n",
      "Layer: Layer 2, Input: [-0.9980679735594701, -0.7412979381675792, -0.9938622525634069, -0.9786809052245135], Output: [1.8692245482247554]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982279986107505, 0.9844833334128734, 0.0008154328838961427, -0.9375707828724732]\n",
      "Layer: Layer 1, Input: [0.9982279986107505, 0.9844833334128734, 0.0008154328838961427, -0.9375707828724732], Output: [-0.9971330422121295, 0.8431997548649848, -0.9838305283434322, -0.9695234941293238]\n",
      "Layer: Layer 2, Input: [-0.9971330422121295, 0.8431997548649848, -0.9838305283434322, -0.9695234941293238], Output: [-1.0008987701063754]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9336014351565995, 0.46783661862941567, 0.42219953551821315, -0.8853404213829076]\n",
      "Layer: Layer 1, Input: [0.9336014351565995, 0.46783661862941567, 0.42219953551821315, -0.8853404213829076], Output: [-0.9881158478333161, 0.9989719651305121, -0.9535495238132392, -0.913838831256792]\n",
      "Layer: Layer 2, Input: [-0.9881158478333161, 0.9989719651305121, -0.9535495238132392, -0.913838831256792], Output: [-1.4627266762693472]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8890857645002997, 0.9896235175848405, -0.801815850438733, -0.9312167802488448]\n",
      "Layer: Layer 1, Input: [0.8890857645002997, 0.9896235175848405, -0.801815850438733, -0.9312167802488448], Output: [-0.9972724247002056, -0.2112336003950567, -0.9908657844319243, -0.9729162712360503]\n",
      "Layer: Layer 2, Input: [-0.9972724247002056, -0.2112336003950567, -0.9908657844319243, -0.9729162712360503], Output: [0.9041508107788294]\n",
      "Epoch 496/500, Loss: 0.2447137917574668, Accuracy: -0.4286991838216485\n",
      "Power operation: base = 0.8692245482247554, power = 2, grad = 0.25\n",
      "Power operation: base = -0.0008987701063754017, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46272667626934716, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09584918922117058, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899345079893132, 0.9910610602073674, -0.9746826236923726, -0.9975464976377302]\n",
      "Layer: Layer 1, Input: [0.9899345079893132, 0.9910610602073674, -0.9746826236923726, -0.9975464976377302], Output: [-0.9980710791103193, -0.7418900968783688, -0.9938894702257158, -0.9787849628974272]\n",
      "Layer: Layer 2, Input: [-0.9980710791103193, -0.7418900968783688, -0.9938894702257158, -0.9787849628974272], Output: [1.8701742646139365]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998228319294631, 0.9845054230675211, 0.0007198685121471367, -0.9375986555961461]\n",
      "Layer: Layer 1, Input: [0.998228319294631, 0.9845054230675211, 0.0007198685121471367, -0.9375986555961461], Output: [-0.9971377423578752, 0.8437261052733789, -0.9839012225052997, -0.9696642448496915]\n",
      "Layer: Layer 2, Input: [-0.9971377423578752, 0.8437261052733789, -0.9839012225052997, -0.9696642448496915], Output: [-1.0026364975608661]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9336122728108028, 0.4683964745200202, 0.42212257921527835, -0.8853888637298084]\n",
      "Layer: Layer 1, Input: [0.9336122728108028, 0.4683964745200202, 0.42212257921527835, -0.8853888637298084], Output: [-0.9881485381516709, 0.9989805929745603, -0.9537664331073986, -0.9142678940826746]\n",
      "Layer: Layer 2, Input: [-0.9881485381516709, 0.9989805929745603, -0.9537664331073986, -0.9142678940826746], Output: [-1.4629727806512305]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8891066749375887, 0.9896383559690991, -0.8018510005473294, -0.9312486521455403]\n",
      "Layer: Layer 1, Input: [0.8891066749375887, 0.9896383559690991, -0.8018510005473294, -0.9312486521455403], Output: [-0.9972770390604453, -0.2115326397110053, -0.9909065882856706, -0.9730472297485155]\n",
      "Layer: Layer 2, Input: [-0.9972770390604453, -0.2115326397110053, -0.9909065882856706, -0.9730472297485155], Output: [0.9043634851022482]\n",
      "Epoch 497/500, Loss: 0.2451750851303785, Accuracy: -0.431420057723785\n",
      "Power operation: base = 0.8701742646139365, power = 2, grad = 0.25\n",
      "Power operation: base = -0.0026364975608661467, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4629727806512305, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09563651489775182, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899368714216256, 0.99107387402005, -0.9746878302893497, -0.9975477645749727]\n",
      "Layer: Layer 1, Input: [0.9899368714216256, 0.99107387402005, -0.9746878302893497, -0.9975477645749727], Output: [-0.9980741751532084, -0.7424783420014224, -0.9939165057696584, -0.9788882713592519]\n",
      "Layer: Layer 2, Input: [-0.9980741751532084, -0.7424783420014224, -0.9939165057696584, -0.9788882713592519], Output: [1.8711216574272358]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982286393135449, 0.9845274361199968, 0.000624320246984495, -0.9376264754350382]\n",
      "Layer: Layer 1, Input: [0.9982286393135449, 0.9845274361199968, 0.000624320246984495, -0.9376264754350382], Output: [-0.997142428253506, 0.844250438147089, -0.9839714617122436, -0.9698040563563184]\n",
      "Layer: Layer 2, Input: [-0.997142428253506, 0.844250438147089, -0.9839714617122436, -0.9698040563563184], Output: [-1.0043668758009252]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9336230893357793, 0.4689548043251872, 0.4220456252584043, -0.8854372187419874]\n",
      "Layer: Layer 1, Input: [0.9336230893357793, 0.4689548043251872, 0.4220456252584043, -0.8854372187419874], Output: [-0.9881810784141073, 0.9989891287769079, -0.9539819226254095, -0.9146941053326524]\n",
      "Layer: Layer 2, Input: [-0.9881810784141073, 0.9989891287769079, -0.9539819226254095, -0.9146941053326524], Output: [-1.4632173473360872]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8891275394096488, 0.9896531426788476, -0.8018861362137402, -0.9312804604517124]\n",
      "Layer: Layer 1, Input: [0.8891275394096488, 0.9896531426788476, -0.8018861362137402, -0.9312804604517124], Output: [-0.9972816388972557, -0.2118283576602513, -0.9909471206005509, -0.9731772650790708]\n",
      "Layer: Layer 2, Input: [-0.9972816388972557, -0.2118283576602513, -0.9909471206005509, -0.9731772650790708], Output: [0.9045745686307249]\n",
      "Epoch 498/500, Loss: 0.24563708386703215, Accuracy: -0.4341313119335233\n",
      "Power operation: base = 0.8711216574272358, power = 2, grad = 0.25\n",
      "Power operation: base = -0.004366875800925207, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4632173473360872, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09542543136927506, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899392290739489, 0.9910866430275342, -0.9746930336893604, -0.9975490287113302]\n",
      "Layer: Layer 1, Input: [0.9899392290739489, 0.9910866430275342, -0.9746930336893604, -0.9975490287113302], Output: [-0.99807726172429, -0.7430627052430312, -0.9939433606287059, -0.9789908368341681]\n",
      "Layer: Layer 2, Input: [-0.99807726172429, -0.7430627052430312, -0.9939433606287059, -0.9789908368341681], Output: [1.8720667668924378]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.998228958669551, 0.9845493728886475, 0.0005287885881820652, -0.9376542424807951]\n",
      "Layer: Layer 1, Input: [0.998228958669551, 0.9845493728886475, 0.0005287885881820652, -0.9376542424807951], Output: [-0.9971470999495919, 0.8447727695572931, -0.9840412492896129, -0.9699429354727763]\n",
      "Layer: Layer 2, Input: [-0.9971470999495919, 0.8447727695572931, -0.9840412492896129, -0.9699429354727763], Output: [-1.0060899353958481]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9336338847852973, 0.46951161224956334, 0.4219686740917259, -0.8854854865332391]\n",
      "Layer: Layer 1, Input: [0.9336338847852973, 0.46951161224956334, 0.4219686740917259, -0.8854854865332391], Output: [-0.9882134694527847, 0.9989975738693541, -0.9541960024455601, -0.9151174837747335]\n",
      "Layer: Layer 2, Input: [-0.9882134694527847, 0.9989975738693541, -0.9541960024455601, -0.9151174837747335], Output: [-1.4634603786975724]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8891483580853347, 0.9896678779305953, -0.8019212572860013, -0.9313122053082677]\n",
      "Layer: Layer 1, Input: [0.8891483580853347, 0.9896678779305953, -0.8019212572860013, -0.9313122053082677], Output: [-0.9972862242666779, -0.21212076438748403, -0.9909873834795059, -0.9733063845993458]\n",
      "Layer: Layer 2, Input: [-0.9972862242666779, -0.21212076438748403, -0.9909873834795059, -0.9733063845993458], Output: [0.9047840662458633]\n",
      "Epoch 499/500, Loss: 0.2460997824736311, Accuracy: -0.43683301473999503\n",
      "Power operation: base = 0.8720667668924378, power = 2, grad = 0.25\n",
      "Power operation: base = -0.006089935395848123, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4634603786975724, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09521593375413673, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899415809723704, 0.9910993674197102, -0.9746982338780417, -0.9975502900553508]\n",
      "Layer: Layer 1, Input: [0.9899415809723704, 0.9910993674197102, -0.9746982338780417, -0.9975502900553508], Output: [-0.9980803388595886, -0.7436432182310319, -0.9939700362253612, -0.9790926654977683]\n",
      "Layer: Layer 2, Input: [-0.9980803388595886, -0.7436432182310319, -0.9939700362253612, -0.9790926654977683], Output: [1.8730096326447514]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.9982292773647055, 0.9845712336907835, 0.00043327403067552005, -0.9376819568256146]\n",
      "Layer: Layer 1, Input: [0.9982292773647055, 0.9845712336907835, 0.00043327403067552005, -0.9376819568256146], Output: [-0.9971517574965592, 0.8452931153009239, -0.9841105885415076, -0.9700808889853547]\n",
      "Layer: Layer 2, Input: [-0.9971517574965592, 0.8452931153009239, -0.9841105885415076, -0.9700808889853547], Output: [-1.0078057070670878]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.9336446592131405, 0.4700669025016208, 0.4218917261554275, -0.8855336672186297]\n",
      "Layer: Layer 1, Input: [0.9336446592131405, 0.4700669025016208, 0.4218917261554275, -0.8855336672186297], Output: [-0.9882457120951765, 0.9990059295595415, -0.9544086825912776, -0.9155380481221129]\n",
      "Layer: Layer 2, Input: [-0.9882457120951765, 0.9990059295595415, -0.9544086825912776, -0.9155380481221129], Output: [-1.4637018774649535]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.8891691311331168, 0.9896825619401278, -0.8019563636138989, -0.9313438868564758]\n",
      "Layer: Layer 1, Input: [0.8891691311331168, 0.9896825619401278, -0.8019563636138989, -0.9313438868564758], Output: [-0.9972907952245538, -0.21240987040632436, -0.991027379010038, -0.9734345956286411]\n",
      "Layer: Layer 2, Input: [-0.9972907952245538, -0.21240987040632436, -0.991027379010038, -0.9734345956286411], Output: [0.9049919829648276]\n",
      "Epoch 500/500, Loss: 0.24656317555470486, Accuracy: -0.4395252342119651\n",
      "Power operation: base = 0.8730096326447514, power = 2, grad = 0.25\n",
      "Power operation: base = -0.00780570706708783, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4637018774649535, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09500801703517237, power = 2, grad = 0.25\n"
     ]
    }
   ],
   "source": [
    "# Run our model training for multiple epochs\n",
    "epochs = 500\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Reset model parameters\n",
    "for param in mlp.parameters():\n",
    "    param.data = random.uniform(-1, 1)  # Random initialization of parameters\n",
    "    param.grad = 0.0\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "y_true = [Value(y_i) for y_i in y]  # Convert labels to Value objects\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_preds = [mlp(i)[0] for i in x]  # Forward pass through the neural network\n",
    "    loss = loss_fn_mse(y_preds, y_true)\n",
    "    losses.append(loss)\n",
    "    accuracy.append(1 - sum([abs(y_true - y_pred.data) for y_true, y_pred in zip(y, y_preds)]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.data}, Accuracy: {accuracy[-1]}\")\n",
    "        \n",
    "    mlp.zero_grad()  # Reset gradients of all parameters\n",
    "    loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "    visited = set()\n",
    "    loss.backward(loss, visited)\n",
    "    for param in mlp.parameters():\n",
    "        param.data = param.data - learning_rate * param.grad  # Update parameters using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "id": "62fd9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds after training: [1.8730096326447514, -1.0078057070670878, -1.4637018774649535, 0.9049919829648276]\n",
      "y_true after training: [1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_preds after training: {[item.data for item in y_preds]}\")\n",
    "print(f\"y_true after training: {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1809,
   "id": "08b99310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(range(epochs), [item.data for item in losses])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "2e370b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy over epochs\n",
    "plt.plot(range(epochs), accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "id": "912faec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.0080,  0.6315,  0.2013, -1.9987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0080,  0.6315,  0.2013, -1.9987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7649,  0.5591,  0.1986, -0.9639], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.7649,  0.5591,  0.1986, -0.9639], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3581, -1.2206, -0.5217,  0.9181], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3581, -1.2206, -0.5217,  0.9181], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8759, -0.8398, -0.4790,  0.7250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8759, -0.8398, -0.4790,  0.7250], grad_fn=<TanhBackward0>),), Output: tensor([0.5528], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5528], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5528], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.8141,  0.5481, -1.5705, -0.6861], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.8141,  0.5481, -1.5705, -0.6861], grad_fn=<ViewBackward0>),), Output: tensor([-0.9482,  0.4991, -0.9171, -0.5955], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9482,  0.4991, -0.9171, -0.5955], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2511, -0.7747,  0.2231, -1.0186], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2511, -0.7747,  0.2231, -1.0186], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8486, -0.6496,  0.2195, -0.7693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8486, -0.6496,  0.2195, -0.7693], grad_fn=<TanhBackward0>),), Output: tensor([0.8540], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8540], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8540], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7748, -0.7841, -0.5231, -1.7591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7748, -0.7841, -0.5231, -1.7591], grad_fn=<ViewBackward0>),), Output: tensor([-0.6497, -0.6551, -0.4801, -0.9424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6497, -0.6551, -0.4801, -0.9424], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4910, -0.9059,  1.1426, -0.4672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4910, -0.9059,  1.1426, -0.4672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9035, -0.7192,  0.8153, -0.4360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9035, -0.7192,  0.8153, -0.4360], grad_fn=<TanhBackward0>),), Output: tensor([1.3563], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3563], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3563], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3531,  0.4977, -2.6552, -3.9193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3531,  0.4977, -2.6552, -3.9193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9821,  0.4603, -0.9902, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9821,  0.4603, -0.9902, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5759, -1.1228,  0.0065, -1.0245], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5759, -1.1228,  0.0065, -1.0245], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9180, -0.8085,  0.0065, -0.7717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9180, -0.8085,  0.0065, -0.7717], grad_fn=<TanhBackward0>),), Output: tensor([0.4844], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4844], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4844], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1020,  0.7994, -0.0229, -2.0033], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1020,  0.7994, -0.0229, -2.0033], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8012,  0.6637, -0.0229, -0.9643], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8012,  0.6637, -0.0229, -0.9643], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1919, -1.1032, -0.8885,  0.7204], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1919, -1.1032, -0.8885,  0.7204], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8312, -0.8016, -0.7107,  0.6172], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8312, -0.8016, -0.7107,  0.6172], grad_fn=<TanhBackward0>),), Output: tensor([0.1431], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1431], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1431], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7888,  0.6301, -1.6242, -0.6931], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7888,  0.6301, -1.6242, -0.6931], grad_fn=<ViewBackward0>),), Output: tensor([-0.9456,  0.5582, -0.9252, -0.6000], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9456,  0.5582, -0.9252, -0.6000], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2236, -0.8163,  0.0412, -1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2236, -0.8163,  0.0412, -1.0341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8407, -0.6731,  0.0412, -0.7756], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8407, -0.6731,  0.0412, -0.7756], grad_fn=<TanhBackward0>),), Output: tensor([0.5052], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5052], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5052], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7485, -0.7327, -0.5837, -1.7624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7485, -0.7327, -0.5837, -1.7624], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.6247, -0.5254, -0.9428], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.6247, -0.5254, -0.9428], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4322, -0.8983,  0.9788, -0.5130], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4322, -0.8983,  0.9788, -0.5130], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8921, -0.7155,  0.7525, -0.4723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8921, -0.7155,  0.7525, -0.4723], grad_fn=<TanhBackward0>),), Output: tensor([1.0877], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0877], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0877], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3352,  0.4874, -2.7083, -3.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3352,  0.4874, -2.7083, -3.9338], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814,  0.4521, -0.9912, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814,  0.4521, -0.9912, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5463, -1.1423, -0.0671, -1.0364], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5463, -1.1423, -0.0671, -1.0364], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9132, -0.8152, -0.0670, -0.7765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9132, -0.8152, -0.0670, -0.7765], grad_fn=<TanhBackward0>),), Output: tensor([0.2931], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2931], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2931], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1406,  0.8638, -0.1559, -2.0103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1406,  0.8638, -0.1559, -2.0103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8146,  0.6982, -0.1547, -0.9647], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8146,  0.6982, -0.1547, -0.9647], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0858, -1.0353, -1.0761,  0.5931], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0858, -1.0353, -1.0761,  0.5931], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7953, -0.7760, -0.7917,  0.5321], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7953, -0.7760, -0.7917,  0.5321], grad_fn=<TanhBackward0>),), Output: tensor([-0.0771], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0771], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0771], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7759,  0.6675, -1.6569, -0.7048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7759,  0.6675, -1.6569, -0.7048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9443,  0.5833, -0.9298, -0.6074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9443,  0.5833, -0.9298, -0.6074], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2070, -0.8487, -0.0593, -1.0438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2070, -0.8487, -0.0593, -1.0438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358, -0.6904, -0.0592, -0.7794], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8358, -0.6904, -0.0592, -0.7794], grad_fn=<TanhBackward0>),), Output: tensor([0.2998], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.2998], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.2998], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -0.7391, -0.6174, -1.7678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -0.7391, -0.6174, -1.7678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.6286, -0.5493, -0.9434], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.6286, -0.5493, -0.9434], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3962, -0.8934,  0.9105, -0.5400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3962, -0.8934,  0.9105, -0.5400], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8845, -0.7131,  0.7214, -0.4930], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8845, -0.7131,  0.7214, -0.4930], grad_fn=<TanhBackward0>),), Output: tensor([0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279,  0.4153, -2.7410, -3.9491], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279,  0.4153, -2.7410, -3.9491], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.3930, -0.9917, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.3930, -0.9917, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5164, -1.1398, -0.0610, -1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5164, -1.1398, -0.0610, -1.0477], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9081, -0.8144, -0.0610, -0.7809], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9081, -0.8144, -0.0610, -0.7809], grad_fn=<TanhBackward0>),), Output: tensor([0.2119], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2119], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2119], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1620,  0.8913, -0.2479, -2.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1620,  0.8913, -0.2479, -2.0177], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217,  0.7121, -0.2429, -0.9653], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8217,  0.7121, -0.2429, -0.9653], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0101, -0.9921, -1.1904,  0.5040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0101, -0.9921, -1.1904,  0.5040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7658, -0.7583, -0.8307,  0.4653], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7658, -0.7583, -0.8307,  0.4653], grad_fn=<TanhBackward0>),), Output: tensor([-0.2211], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2211], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2211], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7677,  0.6821, -1.6797, -0.7174], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7677,  0.6821, -1.6797, -0.7174], grad_fn=<ViewBackward0>),), Output: tensor([-0.9434,  0.5929, -0.9328, -0.6153], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9434,  0.5929, -0.9328, -0.6153], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1955, -0.8733, -0.1150, -1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1955, -0.8733, -0.1150, -1.0502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8323, -0.7030, -0.1145, -0.7819], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8323, -0.7030, -0.1145, -0.7819], grad_fn=<TanhBackward0>),), Output: tensor([0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7342, -0.7756, -0.6383, -1.7735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7342, -0.7756, -0.6383, -1.7735], grad_fn=<ViewBackward0>),), Output: tensor([-0.6256, -0.6502, -0.5638, -0.9440], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6256, -0.6502, -0.5638, -0.9440], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3709, -0.8864,  0.8924, -0.5578], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3709, -0.8864,  0.8924, -0.5578], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8789, -0.7096,  0.7126, -0.5064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8789, -0.7096,  0.7126, -0.5064], grad_fn=<TanhBackward0>),), Output: tensor([0.8706], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8706], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8706], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3260,  0.3002, -2.7628, -3.9642], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3260,  0.3002, -2.7628, -3.9642], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.2915, -0.9921, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.2915, -0.9921, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4850, -1.1189,  0.0027, -1.0591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4850, -1.1189,  0.0027, -1.0591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9024, -0.8072,  0.0027, -0.7853], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9024, -0.8072,  0.0027, -0.7853], grad_fn=<TanhBackward0>),), Output: tensor([0.2056], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2056], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2056], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1759,  0.8992, -0.3171, -2.0250], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1759,  0.8992, -0.3171, -2.0250], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262,  0.7159, -0.3069, -0.9658], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8262,  0.7159, -0.3069, -0.9658], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9515, -0.9620, -1.2661,  0.4373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9515, -0.9620, -1.2661,  0.4373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7405, -0.7452, -0.8527,  0.4114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7405, -0.7452, -0.8527,  0.4114], grad_fn=<TanhBackward0>),), Output: tensor([-0.3261], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3261], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3261], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7617,  0.6822, -1.6971, -0.7299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7617,  0.6822, -1.6971, -0.7299], grad_fn=<ViewBackward0>),), Output: tensor([-0.9427,  0.5930, -0.9350, -0.6230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9427,  0.5930, -0.9350, -0.6230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1865, -0.8918, -0.1450, -1.0549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1865, -0.8918, -0.1450, -1.0549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8295, -0.7123, -0.1440, -0.7837], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8295, -0.7123, -0.1440, -0.7837], grad_fn=<TanhBackward0>),), Output: tensor([0.0919], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0919], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0919], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7333, -0.8328, -0.6522, -1.7790], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7333, -0.8328, -0.6522, -1.7790], grad_fn=<ViewBackward0>),), Output: tensor([-0.6251, -0.6820, -0.5732, -0.9446], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6251, -0.6820, -0.5732, -0.9446], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3514, -0.8768,  0.9030, -0.5706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3514, -0.8768,  0.9030, -0.5706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8744, -0.7048,  0.7177, -0.5158], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8744, -0.7048,  0.7177, -0.5158], grad_fn=<TanhBackward0>),), Output: tensor([0.8348], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8348], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8348], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3265,  0.1563, -2.7783, -3.9787], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3265,  0.1563, -2.7783, -3.9787], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.1551, -0.9923, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.1551, -0.9923, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4517, -1.0827,  0.1083, -1.0711], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4517, -1.0827,  0.1083, -1.0711], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8960, -0.7942,  0.1078, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8960, -0.7942,  0.1078, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1862,  0.8956, -0.3722, -2.0321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1862,  0.8956, -0.3722, -2.0321], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8294,  0.7141, -0.3559, -0.9662], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8294,  0.7141, -0.3559, -0.9662], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9037, -0.9397, -1.3203,  0.3848], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9037, -0.9397, -1.3203,  0.3848], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7181, -0.7351, -0.8669,  0.3669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7181, -0.7351, -0.8669,  0.3669], grad_fn=<TanhBackward0>),), Output: tensor([-0.4106], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4106], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4106], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7568,  0.6732, -1.7113, -0.7421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7568,  0.6732, -1.7113, -0.7421], grad_fn=<ViewBackward0>),), Output: tensor([-0.9421,  0.5871, -0.9368, -0.6304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9421,  0.5871, -0.9368, -0.6304], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1786, -0.9063, -0.1621, -1.0588], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1786, -0.9063, -0.1621, -1.0588], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8270, -0.7194, -0.1607, -0.7852], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8270, -0.7194, -0.1607, -0.7852], grad_fn=<TanhBackward0>),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7338, -0.9037, -0.6622, -1.7844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7338, -0.9037, -0.6622, -1.7844], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.7181, -0.5798, -0.9452], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.7181, -0.5798, -0.9452], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3356, -0.8655,  0.9281, -0.5804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3356, -0.8655,  0.9281, -0.5804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8706, -0.6991,  0.7297, -0.5230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8706, -0.6991,  0.7297, -0.5230], grad_fn=<TanhBackward0>),), Output: tensor([0.8196], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8196], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8196], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3277e+00,  3.3126e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3277e+00,  3.3126e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.0033, -0.9925, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.0033, -0.9925, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4188, -1.0382,  0.2316, -1.0828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4188, -1.0382,  0.2316, -1.0828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8894, -0.7772,  0.2275, -0.7942], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8894, -0.7772,  0.2275, -0.7942], grad_fn=<TanhBackward0>),), Output: tensor([0.3211], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3211], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3211], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1943,  0.8872, -0.4174, -2.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1943,  0.8872, -0.4174, -2.0390], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8319,  0.7100, -0.3947, -0.9667], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8319,  0.7100, -0.3947, -0.9667], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8633, -0.9229, -1.3639,  0.3421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8633, -0.9229, -1.3639,  0.3421], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6980, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6980, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>),), Output: tensor([-0.4851], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4851], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4851], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7524,  0.6613, -1.7233, -0.7539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7524,  0.6613, -1.7233, -0.7539], grad_fn=<ViewBackward0>),), Output: tensor([-0.9417,  0.5792, -0.9383, -0.6375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9417,  0.5792, -0.9383, -0.6375], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1715, -0.9188, -0.1770, -1.0623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1715, -0.9188, -0.1770, -1.0623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8248, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8248, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>),), Output: tensor([-0.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7349, -0.9790, -0.6698, -1.7895], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7349, -0.9790, -0.6698, -1.7895], grad_fn=<ViewBackward0>),), Output: tensor([-0.6261, -0.7527, -0.5848, -0.9457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6261, -0.7527, -0.5848, -0.9457], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3225, -0.8541,  0.9561, -0.5881], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3225, -0.8541,  0.9561, -0.5881], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8674, -0.6932,  0.7426, -0.5286], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8674, -0.6932,  0.7426, -0.5286], grad_fn=<TanhBackward0>),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -0.1373, -2.8000, -4.0063], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -0.1373, -2.8000, -4.0063], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.1364, -0.9926, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.1364, -0.9926, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3899, -0.9953,  0.3445, -1.0929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3899, -0.9953,  0.3445, -1.0929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8832, -0.7596,  0.3315, -0.7979], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8832, -0.7596,  0.3315, -0.7979], grad_fn=<TanhBackward0>),), Output: tensor([0.3864], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3864], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3864], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2012,  0.8800, -0.4550, -2.0458], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2012,  0.8800, -0.4550, -2.0458], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8340,  0.7064, -0.4260, -0.9671], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8340,  0.7064, -0.4260, -0.9671], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8291, -0.9110, -1.4037,  0.3069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8291, -0.9110, -1.4037,  0.3069], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6800, -0.7216, -0.8861,  0.2976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6800, -0.7216, -0.8861,  0.2976], grad_fn=<TanhBackward0>),), Output: tensor([-0.5542], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5542], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5542], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7482,  0.6526, -1.7338, -0.7653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7482,  0.6526, -1.7338, -0.7653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1653, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1653, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8228, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8228, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>),), Output: tensor([-0.0744], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0744], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0744], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.0487, -0.6757, -1.7944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.0487, -0.6757, -1.7944], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.7813, -0.5887, -0.9462], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.7813, -0.5887, -0.9462], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3120, -0.8440,  0.9790, -0.5942], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3120, -0.8440,  0.9790, -0.5942], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.6879,  0.7526, -0.5329], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.6879,  0.7526, -0.5329], grad_fn=<TanhBackward0>),), Output: tensor([0.8071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3298, -0.2556, -2.8077, -4.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3298, -0.2556, -2.8077, -4.0194], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.2502, -0.9927, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.2502, -0.9927, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3667, -0.9590,  0.4341, -1.1007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3667, -0.9590,  0.4341, -1.1007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8779, -0.7438,  0.4087, -0.8008], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8779, -0.7438,  0.4087, -0.8008], grad_fn=<TanhBackward0>),), Output: tensor([0.4358], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4358], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4358], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2069,  0.8763, -0.4862, -2.0522], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2069,  0.8763, -0.4862, -2.0522], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8357,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8357,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8002, -0.9030, -1.4416,  0.2780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8002, -0.9030, -1.4416,  0.2780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6641, -0.7177, -0.8940,  0.2711], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6641, -0.7177, -0.8940,  0.2711], grad_fn=<TanhBackward0>),), Output: tensor([-0.6184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7442,  0.6493, -1.7429, -0.7764], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7442,  0.6493, -1.7429, -0.7764], grad_fn=<ViewBackward0>),), Output: tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8211, -0.7366, -0.2204, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8211, -0.7366, -0.2204, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.1335], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1335], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1335], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7372, -1.1080, -0.6803, -1.7992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7372, -1.1080, -0.6803, -1.7992], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3040, -0.8354,  0.9953, -0.5987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3040, -0.8354,  0.9953, -0.5987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6834,  0.7596, -0.5361], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6834,  0.7596, -0.5361], grad_fn=<TanhBackward0>),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3308, -0.3536, -2.8134, -4.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3308, -0.3536, -2.8134, -4.0317], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.3396, -0.9928, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.3396, -0.9928, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3486, -0.9289,  0.5027, -1.1065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3486, -0.9289,  0.5027, -1.1065], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8737, -0.7301,  0.4642, -0.8028], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8737, -0.7301,  0.4642, -0.8028], grad_fn=<TanhBackward0>),), Output: tensor([0.4729], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4729], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4729], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2116,  0.8754, -0.5119, -2.0584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2116,  0.8754, -0.5119, -2.0584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7760, -0.8979, -1.4771,  0.2544], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7760, -0.8979, -1.4771,  0.2544], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6504, -0.7153, -0.9009,  0.2490], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6504, -0.7153, -0.9009,  0.2490], grad_fn=<TanhBackward0>),), Output: tensor([-0.6767], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6767], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6767], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7405,  0.6505, -1.7508, -0.7868], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7405,  0.6505, -1.7508, -0.7868], grad_fn=<ViewBackward0>),), Output: tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1563, -0.9548, -0.2549, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1563, -0.9548, -0.2549, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8198, -0.7419, -0.2495, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8198, -0.7419, -0.2495, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7383, -1.1578, -0.6836, -1.8037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7383, -1.1578, -0.6836, -1.8037], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.8203, -0.5938, -0.9472], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.8203, -0.5938, -0.9472], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2980, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2980, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8612, -0.6793,  0.7646, -0.5383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8612, -0.6793,  0.7646, -0.5383], grad_fn=<TanhBackward0>),), Output: tensor([0.7999], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7999], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7999], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3320, -0.4359, -2.8175, -4.0432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3320, -0.4359, -2.8175, -4.0432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.4102, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.4102, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3347, -0.9034,  0.5563, -1.1106], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3347, -0.9034,  0.5563, -1.1106], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8704, -0.7179,  0.5052, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8704, -0.7179,  0.5052, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2154,  0.8761, -0.5328, -2.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2154,  0.8761, -0.5328, -2.0642], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7560, -0.8948, -1.5097,  0.2352], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7560, -0.8948, -1.5097,  0.2352], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>),), Output: tensor([-0.7288], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7288], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7288], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7370,  0.6546, -1.7576, -0.7967], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7370,  0.6546, -1.7576, -0.7967], grad_fn=<ViewBackward0>),), Output: tensor([-0.9399,  0.5748, -0.9422, -0.6622], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9399,  0.5748, -0.9422, -0.6622], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1533, -0.9657, -0.2871, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1533, -0.9657, -0.2871, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7468, -0.2794, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7468, -0.2794, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.2499], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2499], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2499], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7396, -1.2002, -0.6858, -1.8078], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7396, -1.2002, -0.6858, -1.8078], grad_fn=<ViewBackward0>),), Output: tensor([-0.6289, -0.8337, -0.5953, -0.9476], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6289, -0.8337, -0.5953, -0.9476], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2939, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2939, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8601, -0.6753,  0.7686, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8601, -0.6753,  0.7686, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([0.8009], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8009], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8009], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3333, -0.5062, -2.8201, -4.0539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3333, -0.5062, -2.8201, -4.0539], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.4670, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.4670, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3239, -0.8810,  0.5994, -1.1134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3239, -0.8810,  0.5994, -1.1134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8678, -0.7069,  0.5367, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8678, -0.7069,  0.5367, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.5299], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5299], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5299], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2184,  0.8778, -0.5498, -2.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2184,  0.8778, -0.5498, -2.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8392,  0.7053, -0.5004, -0.9686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8392,  0.7053, -0.5004, -0.9686], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7394, -0.8931, -1.5390,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7394, -0.8931, -1.5390,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6288, -0.7129, -0.9119,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6288, -0.7129, -0.9119,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-0.7748], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7748], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7748], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1511, -0.9755, -0.3190, -1.0732], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1511, -0.9755, -0.3190, -1.0732], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7511, -0.3086, -0.7907], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7511, -0.3086, -0.7907], grad_fn=<TanhBackward0>),), Output: tensor([-0.3029], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3029], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3029], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7410, -1.2369, -0.6870, -1.8117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7410, -1.2369, -0.6870, -1.8117], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8595, -0.6714,  0.7721, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8595, -0.6714,  0.7721, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([0.8053], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8053], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8053], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3347, -0.5670, -2.8215, -4.0638], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3347, -0.5670, -2.8215, -4.0638], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.5132, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.5132, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.8609,  0.6350, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.8609,  0.6350, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.6967,  0.5615, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.6967,  0.5615, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.5548], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5548], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5548], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2209,  0.8798, -0.5635, -2.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2209,  0.8798, -0.5635, -2.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8399,  0.7063, -0.5105, -0.9689], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8399,  0.7063, -0.5105, -0.9689], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7258, -0.8922, -1.5651,  0.2071], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7258, -0.8922, -1.5651,  0.2071], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6205, -0.7125, -0.9162,  0.2042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6205, -0.7125, -0.9162,  0.2042], grad_fn=<TanhBackward0>),), Output: tensor([-0.8153], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8153], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8153], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1495, -0.9841, -0.3498, -1.0741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1495, -0.9841, -0.3498, -1.0741], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8176, -0.7548, -0.3362, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8176, -0.7548, -0.3362, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.3515], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3515], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3515], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7424, -1.2690, -0.6875, -1.8152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7424, -1.2690, -0.6875, -1.8152], grad_fn=<ViewBackward0>),), Output: tensor([-0.6306, -0.8535, -0.5964, -0.9484], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6306, -0.8535, -0.5964, -0.9484], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8591, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8591, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3362, -0.6201, -2.8221, -4.0730], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3362, -0.6201, -2.8221, -4.0730], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5512, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5512, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3091, -0.8427,  0.6649, -1.1164], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3091, -0.8427,  0.6649, -1.1164], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6872,  0.5816, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6872,  0.5816, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2228,  0.8820, -0.5744, -2.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2228,  0.8820, -0.5744, -2.0792], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8405,  0.7074, -0.5186, -0.9692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8405,  0.7074, -0.5186, -0.9692], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7146, -0.8918, -1.5884,  0.1971], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7146, -0.8918, -1.5884,  0.1971], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6135, -0.7123, -0.9199,  0.1946], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6135, -0.7123, -0.9199,  0.1946], grad_fn=<TanhBackward0>),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1484, -0.9916, -0.3793, -1.0747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1484, -0.9916, -0.3793, -1.0747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7581, -0.3621, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7581, -0.3621, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.3959], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3959], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3959], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7438, -1.2973, -0.6875, -1.8185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7438, -1.2973, -0.6875, -1.8185], grad_fn=<ViewBackward0>),), Output: tensor([-0.6315, -0.8610, -0.5964, -0.9487], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6315, -0.8610, -0.5964, -0.9487], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7988,  1.0417, -0.6044], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7988,  1.0417, -0.6044], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6634,  0.7786, -0.5401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6634,  0.7786, -0.5401], grad_fn=<TanhBackward0>),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3376, -0.6668, -2.8220, -4.0814], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3376, -0.6668, -2.8220, -4.0814], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5829, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5829, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3041, -0.8259,  0.6904, -1.1170], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3041, -0.8259,  0.6904, -1.1170], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.6783,  0.5982, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.6783,  0.5982, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2244,  0.8841, -0.5830, -2.0834], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2244,  0.8841, -0.5830, -2.0834], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8409,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8409,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7054, -0.8918, -1.6091,  0.1892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7054, -0.8918, -1.6091,  0.1892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6078, -0.7123, -0.9230,  0.1870], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6078, -0.7123, -0.9230,  0.1870], grad_fn=<TanhBackward0>),), Output: tensor([-0.8823], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8823], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8823], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7262,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7262,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9386,  0.5932, -0.9443, -0.6802], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9386,  0.5932, -0.9443, -0.6802], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1477, -0.9982, -0.4071, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1477, -0.9982, -0.4071, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7608, -0.3860, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7608, -0.3860, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.4364], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4364], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4364], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7452, -1.3225, -0.6871, -1.8215], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7452, -1.3225, -0.6871, -1.8215], grad_fn=<ViewBackward0>),), Output: tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2892, -0.7916,  1.0495, -0.6035], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2892, -0.7916,  1.0495, -0.6035], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3390, -0.7081, -2.8215, -4.0891], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3390, -0.7081, -2.8215, -4.0891], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6095, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6095, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3002, -0.8103,  0.7123, -1.1172], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3002, -0.8103,  0.7123, -1.1172], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8618, -0.6698,  0.6121, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8618, -0.6698,  0.6121, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2256,  0.8861, -0.5897, -2.0874], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2256,  0.8861, -0.5897, -2.0874], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6981, -0.8921, -1.6275,  0.1830], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6981, -0.8921, -1.6275,  0.1830], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>),), Output: tensor([-0.9099], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9099], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9099], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1473, -1.0038, -0.4334, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1473, -1.0038, -0.4334, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8169, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8169, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.4733], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4733], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4733], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7465, -1.3449, -0.6863, -1.8243], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7465, -1.3449, -0.6863, -1.8243], grad_fn=<ViewBackward0>),), Output: tensor([-0.6331, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6331, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8591, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8591, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3403, -0.7448, -2.8206, -4.0963], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3403, -0.7448, -2.8206, -4.0963], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6321, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6321, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2971, -0.7958,  0.7314, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2971, -0.7958,  0.7314, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6617,  0.6239, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6617,  0.6239, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.6436], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6436], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6436], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2267,  0.8879, -0.5947, -2.0910], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2267,  0.8879, -0.5947, -2.0910], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6922, -0.8924, -1.6438,  0.1783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6922, -0.8924, -1.6438,  0.1783], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5994, -0.7126, -0.9280,  0.1764], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5994, -0.7126, -0.9280,  0.1764], grad_fn=<TanhBackward0>),), Output: tensor([-0.9342], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9342], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9342], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7220,  0.6982, -1.7822, -0.8425], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7220,  0.6982, -1.7822, -0.8425], grad_fn=<ViewBackward0>),), Output: tensor([-0.9381,  0.6032, -0.9449, -0.6871], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9381,  0.6032, -0.9449, -0.6871], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0087, -0.4581, -1.0753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0087, -0.4581, -1.0753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7477, -1.3651, -0.6854, -1.8268], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7477, -1.3651, -0.6854, -1.8268], grad_fn=<ViewBackward0>),), Output: tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2906, -0.7774,  1.0645, -0.6009], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2906, -0.7774,  1.0645, -0.6009], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3414, -0.7777, -2.8196, -4.1029], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3414, -0.7777, -2.8196, -4.1029], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6514, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6514, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2948, -0.7823,  0.7482, -1.1168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2948, -0.7823,  0.7482, -1.1168], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2275,  0.8895, -0.5984, -2.0944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2275,  0.8895, -0.5984, -2.0944], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8418,  0.7111, -0.5359, -0.9701], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8418,  0.7111, -0.5359, -0.9701], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6876, -0.8929, -1.6582,  0.1748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6876, -0.8929, -1.6582,  0.1748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5964, -0.7128, -0.9300,  0.1730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5964, -0.7128, -0.9300,  0.1730], grad_fn=<TanhBackward0>),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7202,  0.7058, -1.7846, -0.8482], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7202,  0.7058, -1.7846, -0.8482], grad_fn=<ViewBackward0>),), Output: tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0130, -0.4814, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0130, -0.4814, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7670, -0.4473, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7670, -0.4473, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7489, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7489, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>),), Output: tensor([-0.6345, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6345, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2918, -0.7705,  1.0715, -0.5994], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2918, -0.7705,  1.0715, -0.5994], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3424, -0.8072, -2.8184, -4.1090], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3424, -0.8072, -2.8184, -4.1090], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6680, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6680, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2929, -0.7697,  0.7629, -1.1163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2929, -0.7697,  0.7629, -1.1163], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6468,  0.6428, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6468,  0.6428, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.6819], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6819], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6819], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2281,  0.8908, -0.6008, -2.0976], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2281,  0.8908, -0.6008, -2.0976], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8420,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8420,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6841, -0.8934, -1.6709,  0.1724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6841, -0.8934, -1.6709,  0.1724], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5942, -0.7131, -0.9317,  0.1707], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5942, -0.7131, -0.9317,  0.1707], grad_fn=<TanhBackward0>),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>),), Output: tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1472, -1.0166, -0.5032, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1472, -1.0166, -0.5032, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7685, -0.4646, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7685, -0.4646, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7499, -1.3997, -0.6832, -1.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7499, -1.3997, -0.6832, -1.8314], grad_fn=<ViewBackward0>),), Output: tensor([-0.6351, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6351, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2930, -0.7638,  1.0781, -0.5978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2930, -0.7638,  1.0781, -0.5978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3432, -0.8338, -2.8172, -4.1147], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3432, -0.8338, -2.8172, -4.1147], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6825, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6825, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2915, -0.7579,  0.7760, -1.1158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2915, -0.7579,  0.7760, -1.1158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8595, -0.6399,  0.6504, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8595, -0.6399,  0.6504, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.6994], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6994], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6994], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2287,  0.8918, -0.6022, -2.1005], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2287,  0.8918, -0.6022, -2.1005], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8422,  0.7123, -0.5386, -0.9705], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8422,  0.7123, -0.5386, -0.9705], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6816, -0.8939, -1.6820,  0.1709], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6816, -0.8939, -1.6820,  0.1709], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7168,  0.7202, -1.7885, -0.8585], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7168,  0.7202, -1.7885, -0.8585], grad_fn=<ViewBackward0>),), Output: tensor([-0.9375,  0.6171, -0.9456, -0.6955], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9375,  0.6171, -0.9456, -0.6955], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1475, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1475, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8169, -0.7698, -0.4805, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8169, -0.7698, -0.4805, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7508, -1.4146, -0.6820, -1.8334], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7508, -1.4146, -0.6820, -1.8334], grad_fn=<ViewBackward0>),), Output: tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2944, -0.7573,  1.0844, -0.5961], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2944, -0.7573,  1.0844, -0.5961], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8603, -0.6395,  0.7948, -0.5343], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8603, -0.6395,  0.7948, -0.5343], grad_fn=<TanhBackward0>),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3439, -0.8579, -2.8160, -4.1200], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3439, -0.8579, -2.8160, -4.1200], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2291,  0.8926, -0.6028, -2.1032], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2291,  0.8926, -0.6028, -2.1032], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6799, -0.8944, -1.6918,  0.1702], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6799, -0.8944, -1.6918,  0.1702], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5915, -0.7136, -0.9344,  0.1686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5915, -0.7136, -0.9344,  0.1686], grad_fn=<TanhBackward0>),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>),), Output: tensor([-0.9373,  0.6212, -0.9458, -0.6978], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9373,  0.6212, -0.9458, -0.6978], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1478, -1.0226, -0.5429, -1.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1478, -1.0226, -0.5429, -1.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.6166], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6166], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6166], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7516, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7516, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>),), Output: tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2958, -0.7511,  1.0902, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2958, -0.7511,  1.0902, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8606, -0.6358,  0.7970, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8606, -0.6358,  0.7970, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3444, -0.8798, -2.8148, -4.1249], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3444, -0.8798, -2.8148, -4.1249], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7063, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7063, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2896, -0.7366,  0.7981, -1.1146], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2896, -0.7366,  0.7981, -1.1146], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2294,  0.8931, -0.6026, -2.1057], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2294,  0.8931, -0.6026, -2.1057], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8424,  0.7129, -0.5389, -0.9708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8424,  0.7129, -0.5389, -0.9708], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6790, -0.8949, -1.7003,  0.1702], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6790, -0.8949, -1.7003,  0.1702], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7138, -0.9354,  0.1686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7138, -0.9354,  0.1686], grad_fn=<TanhBackward0>),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7139,  0.7334, -1.7914, -0.8673], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7139,  0.7334, -1.7914, -0.8673], grad_fn=<ViewBackward0>),), Output: tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1483, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1483, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.6388], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6388], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6388], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7522, -1.4407, -0.6796, -1.8371], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7522, -1.4407, -0.6796, -1.8371], grad_fn=<ViewBackward0>),), Output: tensor([-0.6365, -0.8938, -0.5913, -0.9505], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6365, -0.8938, -0.5913, -0.9505], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2973, -0.7451,  1.0957, -0.5929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2973, -0.7451,  1.0957, -0.5929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3448, -0.8999, -2.8137, -4.1295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3448, -0.8999, -2.8137, -4.1295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7162, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7162, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2889, -0.7270,  0.8074, -1.1139], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2889, -0.7270,  0.8074, -1.1139], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2297,  0.8933, -0.6017, -2.1081], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2297,  0.8933, -0.6017, -2.1081], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8425,  0.7130, -0.5382, -0.9709], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8425,  0.7130, -0.5382, -0.9709], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6787, -0.8955, -1.7077,  0.1708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6787, -0.8955, -1.7077,  0.1708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5907, -0.7141, -0.9364,  0.1691], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5907, -0.7141, -0.9364,  0.1691], grad_fn=<TanhBackward0>),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7126,  0.7395, -1.7926, -0.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7126,  0.7395, -1.7926, -0.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1487, -1.0272, -0.5779, -1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1487, -1.0272, -0.5779, -1.0739], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>),), Output: tensor([-0.6593], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6593], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6593], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2987, -0.7394,  1.1008, -0.5913], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2987, -0.7394,  1.1008, -0.5913], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8614, -0.6288,  0.8008, -0.5308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8614, -0.6288,  0.8008, -0.5308], grad_fn=<TanhBackward0>),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3451, -0.9183, -2.8126, -4.1338], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3451, -0.9183, -2.8126, -4.1338], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2884, -0.7180,  0.8159, -1.1133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2884, -0.7180,  0.8159, -1.1133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8587, -0.6157,  0.6728, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8587, -0.6157,  0.6728, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2299,  0.8933, -0.6002, -2.1103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2299,  0.8933, -0.6002, -2.1103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8425,  0.7130, -0.5372, -0.9710], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8425,  0.7130, -0.5372, -0.9710], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8960, -1.7140,  0.1719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8960, -1.7140,  0.1719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7143, -0.9371,  0.1702], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7143, -0.9371,  0.1702], grad_fn=<TanhBackward0>),), Output: tensor([-1.0389], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0389], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0389], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>),), Output: tensor([-0.9368,  0.6323, -0.9461, -0.7039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9368,  0.6323, -0.9461, -0.7039], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1493, -1.0290, -0.5938, -1.0735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1493, -1.0290, -0.5938, -1.0735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.4628, -0.6774, -1.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.4628, -0.6774, -1.8403], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3001, -0.7339,  1.1056, -0.5898], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3001, -0.7339,  1.1056, -0.5898], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8617, -0.6255,  0.8025, -0.5297], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8617, -0.6255,  0.8025, -0.5297], grad_fn=<TanhBackward0>),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9352, -2.8117, -4.1378], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9352, -2.8117, -4.1378], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2881, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2881, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8586, -0.6104,  0.6769, -0.8050], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8586, -0.6104,  0.6769, -0.8050], grad_fn=<TanhBackward0>),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2300,  0.8930, -0.5983, -2.1124], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2300,  0.8930, -0.5983, -2.1124], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6797, -0.8965, -1.7194,  0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6797, -0.8965, -1.7194,  0.1734], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5913, -0.7146, -0.9378,  0.1717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5913, -0.7146, -0.9378,  0.1717], grad_fn=<TanhBackward0>),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7101,  0.7507, -1.7945, -0.8783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7101,  0.7507, -1.7945, -0.8783], grad_fn=<ViewBackward0>),), Output: tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7537, -1.4726, -0.6763, -1.8417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7537, -1.4726, -0.6763, -1.8417], grad_fn=<ViewBackward0>),), Output: tensor([-0.6374, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6374, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3014, -0.7288,  1.1099, -0.5883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3014, -0.7288,  1.1099, -0.5883], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9508, -2.8108, -4.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9508, -2.8108, -4.1416], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2878, -0.7016,  0.8303, -1.1122], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2878, -0.7016,  0.8303, -1.1122], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2302,  0.8925, -0.5960, -2.1143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2302,  0.8925, -0.5960, -2.1143], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7126, -0.5342, -0.9713], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7126, -0.5342, -0.9713], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6809, -0.8970, -1.7239,  0.1754], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6809, -0.8970, -1.7239,  0.1754], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5921, -0.7148, -0.9383,  0.1736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5921, -0.7148, -0.9383,  0.1736], grad_fn=<TanhBackward0>),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7090,  0.7559, -1.7953, -0.8816], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7090,  0.7559, -1.7953, -0.8816], grad_fn=<ViewBackward0>),), Output: tensor([-0.9365,  0.6386, -0.9463, -0.7072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9365,  0.6386, -0.9463, -0.7072], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1505, -1.0321, -0.6229, -1.0727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1505, -1.0321, -0.6229, -1.0727], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8179, -0.7747, -0.5531, -0.7905], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8179, -0.7747, -0.5531, -0.7905], grad_fn=<TanhBackward0>),), Output: tensor([-0.7121], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7121], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7121], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.4816, -0.6754, -1.8431], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.4816, -0.6754, -1.8431], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3027, -0.7239,  1.1139, -0.5869], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3027, -0.7239,  1.1139, -0.5869], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9654, -2.8101, -4.1452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9654, -2.8101, -4.1452], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2876, -0.6943,  0.8366, -1.1116], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2876, -0.6943,  0.8366, -1.1116], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2303,  0.8917, -0.5932, -2.1161], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2303,  0.8917, -0.5932, -2.1161], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6824, -0.8975, -1.7276,  0.1777], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6824, -0.8975, -1.7276,  0.1777], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5931, -0.7151, -0.9388,  0.1758], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5931, -0.7151, -0.9388,  0.1758], grad_fn=<TanhBackward0>),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7079,  0.7607, -1.7960, -0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7079,  0.7607, -1.7960, -0.8846], grad_fn=<ViewBackward0>),), Output: tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1511, -1.0333, -0.6361, -1.0724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1511, -1.0333, -0.6361, -1.0724], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7752, -0.5622, -0.7903], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7752, -0.5622, -0.7903], grad_fn=<TanhBackward0>),), Output: tensor([-0.7272], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7272], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7272], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7543, -1.4901, -0.6744, -1.8444], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7543, -1.4901, -0.6744, -1.8444], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3450, -0.9789, -2.8094, -4.1486], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3450, -0.9789, -2.8094, -4.1486], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2874, -0.6873,  0.8423, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2874, -0.6873,  0.8423, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.5963,  0.6870, -0.8045], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.5963,  0.6870, -0.8045], grad_fn=<TanhBackward0>),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2303,  0.8908, -0.5902, -2.1179], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2303,  0.8908, -0.5902, -2.1179], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7118, -0.5300, -0.9715], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7118, -0.5300, -0.9715], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6843, -0.8980, -1.7306,  0.1803], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6843, -0.8980, -1.7306,  0.1803], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7069,  0.7652, -1.7966, -0.8874], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7069,  0.7652, -1.7966, -0.8874], grad_fn=<ViewBackward0>),), Output: tensor([-0.9363,  0.6441, -0.9465, -0.7101], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9363,  0.6441, -0.9465, -0.7101], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1517, -1.0345, -0.6485, -1.0720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1517, -1.0345, -0.6485, -1.0720], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.7412], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7412], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7412], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.4980, -0.6736, -1.8457], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.4980, -0.6736, -1.8457], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3051, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3051, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3447, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3447, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7580, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7580, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2873, -0.6809,  0.8476, -1.1107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2873, -0.6809,  0.8476, -1.1107], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5921,  0.6898, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5921,  0.6898, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8897, -0.5869, -2.1195], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8897, -0.5869, -2.1195], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6865, -0.8985, -1.7330,  0.1831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6865, -0.8985, -1.7330,  0.1831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5957, -0.7156, -0.9394,  0.1811], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5957, -0.7156, -0.9394,  0.1811], grad_fn=<TanhBackward0>),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7059,  0.7694, -1.7971, -0.8900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7059,  0.7694, -1.7971, -0.8900], grad_fn=<ViewBackward0>),), Output: tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1524, -1.0355, -0.6602, -1.0716], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1524, -1.0355, -0.6602, -1.0716], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8186, -0.7761, -0.5785, -0.7901], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8186, -0.7761, -0.5785, -0.7901], grad_fn=<TanhBackward0>),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3062, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3062, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.6111,  0.8090, -0.5250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.6111,  0.8090, -0.5250], grad_fn=<TanhBackward0>),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3444, -1.0035, -2.8084, -4.1548], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3444, -1.0035, -2.8084, -4.1548], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7630, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7630, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2873, -0.6748,  0.8524, -1.1103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2873, -0.6748,  0.8524, -1.1103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8884, -0.5833, -2.1211], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8884, -0.5833, -2.1211], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7106, -0.5251, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7106, -0.5251, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6889, -0.8990, -1.7347,  0.1862], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6889, -0.8990, -1.7347,  0.1862], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5972, -0.7158, -0.9396,  0.1841], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5972, -0.7158, -0.9396,  0.1841], grad_fn=<TanhBackward0>),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>),), Output: tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1531, -1.0364, -0.6713, -1.0712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1531, -1.0364, -0.6713, -1.0712], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7546, -1.5124, -0.6721, -1.8480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7546, -1.5124, -0.6721, -1.8480], grad_fn=<ViewBackward0>),), Output: tensor([-0.6379, -0.9074, -0.5863, -0.9516], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6379, -0.9074, -0.5863, -0.9516], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3072, -0.7067,  1.1270, -0.5822], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3072, -0.7067,  1.1270, -0.5822], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8636, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8636, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6691,  0.8568, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6691,  0.8568, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5844,  0.6946, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5844,  0.6946, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8870, -0.5796, -2.1225], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8870, -0.5796, -2.1225], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7099, -0.5224, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7099, -0.5224, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6914, -0.8996, -1.7360,  0.1895], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6914, -0.8996, -1.7360,  0.1895], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7041,  0.7771, -1.7979, -0.8949], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7041,  0.7771, -1.7979, -0.8949], grad_fn=<ViewBackward0>),), Output: tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1538, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1538, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8190, -0.7768, -0.5926, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8190, -0.7768, -0.5926, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>),), Output: tensor([-0.6379, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6379, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.7030,  1.1296, -0.5812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.7030,  1.1296, -0.5812], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3434, -1.0252, -2.8079, -4.1603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3434, -1.0252, -2.8079, -4.1603], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6637,  0.8609, -1.1096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6637,  0.8609, -1.1096], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8855, -0.5757, -2.1239], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8855, -0.5757, -2.1239], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7091, -0.5195, -0.9718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7091, -0.5195, -0.9718], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6942, -0.9001, -1.7367,  0.1929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6942, -0.9001, -1.7367,  0.1929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6007, -0.7163, -0.9398,  0.1906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6007, -0.7163, -0.9398,  0.1906], grad_fn=<TanhBackward0>),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7033,  0.7806, -1.7983, -0.8971], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7033,  0.7806, -1.7983, -0.8971], grad_fn=<ViewBackward0>),), Output: tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1545, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1545, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8192, -0.7770, -0.5989, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8192, -0.7770, -0.5989, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5252, -0.6708, -1.8501], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5252, -0.6708, -1.8501], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9096, -0.5855, -0.9518], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9096, -0.5855, -0.9518], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3429, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3429, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6587,  0.8647, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6587,  0.8647, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5775,  0.6987, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5775,  0.6987, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8838, -0.5716, -2.1253], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8838, -0.5716, -2.1253], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7083, -0.5166, -0.9719], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7083, -0.5166, -0.9719], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6971, -0.9006, -1.7370,  0.1965], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6971, -0.9006, -1.7370,  0.1965], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6025, -0.7166, -0.9399,  0.1940], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6025, -0.7166, -0.9399,  0.1940], grad_fn=<TanhBackward0>),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7024,  0.7839, -1.7985, -0.8992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7024,  0.7839, -1.7985, -0.8992], grad_fn=<ViewBackward0>),), Output: tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1552, -1.0385, -0.7007, -1.0701], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1552, -1.0385, -0.7007, -1.0701], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8195, -0.7773, -0.6048, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8195, -0.7773, -0.6048, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.7980], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7980], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7980], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3098, -0.6961,  1.1342, -0.5794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3098, -0.6961,  1.1342, -0.5794], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.6019,  0.8124, -0.5223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.6019,  0.8124, -0.5223], grad_fn=<TanhBackward0>),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3423, -1.0448, -2.8077, -4.1654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3423, -1.0448, -2.8077, -4.1654], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8820, -0.5675, -2.1265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8820, -0.5675, -2.1265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7074, -0.5135, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7074, -0.5135, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7001, -0.9011, -1.7369,  0.2002], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7001, -0.9011, -1.7369,  0.2002], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6045, -0.7169, -0.9399,  0.1975], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6045, -0.7169, -0.9399,  0.1975], grad_fn=<TanhBackward0>),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7017,  0.7869, -1.7988, -0.9012], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7017,  0.7869, -1.7988, -0.9012], grad_fn=<ViewBackward0>),), Output: tensor([-0.9356,  0.6567, -0.9467, -0.7169], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9356,  0.6567, -0.9467, -0.7169], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8197, -0.7775, -0.6103, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8197, -0.7775, -0.6103, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3106, -0.6929,  1.1362, -0.5787], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3106, -0.6929,  1.1362, -0.5787], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5999,  0.8131, -0.5217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5999,  0.8131, -0.5217], grad_fn=<TanhBackward0>),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3417, -1.0539, -2.8077, -4.1678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3417, -1.0539, -2.8077, -4.1678], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8801, -0.5633, -2.1277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8801, -0.5633, -2.1277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7064, -0.5104, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7064, -0.5104, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7032, -0.9017, -1.7365,  0.2040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7032, -0.9017, -1.7365,  0.2040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7009,  0.7897, -1.7990, -0.9030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7009,  0.7897, -1.7990, -0.9030], grad_fn=<ViewBackward0>),), Output: tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7541, -1.5420, -0.6694, -1.8529], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7541, -1.5420, -0.6694, -1.8529], grad_fn=<ViewBackward0>),), Output: tensor([-0.6376, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6376, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3113, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3113, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3410, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3410, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7866, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7866, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6452,  0.8747, -1.1088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6452,  0.8747, -1.1088], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8781, -0.5590, -2.1289], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8781, -0.5590, -2.1289], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7054, -0.5072, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7054, -0.5072, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7064, -0.9022, -1.7357,  0.2078], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7064, -0.9022, -1.7357,  0.2078], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7002,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7002,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1572, -1.0400, -0.7255, -1.0691], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1572, -1.0400, -0.7255, -1.0691], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7539, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7539, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>),), Output: tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6870,  1.1397, -0.5774], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6870,  1.1397, -0.5774], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5961,  0.8143, -0.5208], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5961,  0.8143, -0.5208], grad_fn=<TanhBackward0>),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3403, -1.0709, -2.8080, -4.1722], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3403, -1.0709, -2.8080, -4.1722], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8760, -0.5546, -2.1300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8760, -0.5546, -2.1300], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7044, -0.5040, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7044, -0.5040, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7097, -0.9028, -1.7346,  0.2117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7097, -0.9028, -1.7346,  0.2117], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6105, -0.7176, -0.9396,  0.2086], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6105, -0.7176, -0.9396,  0.2086], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6995,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6995,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6612, -0.9467, -0.7195], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6612, -0.9467, -0.7195], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1579, -1.0403, -0.7328, -1.0688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1579, -1.0403, -0.7328, -1.0688], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3396, -1.0789, -2.8083, -4.1743], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3396, -1.0789, -2.8083, -4.1743], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6375,  0.8805, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6375,  0.8805, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5632,  0.7067, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5632,  0.7067, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8739, -0.5503, -2.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8739, -0.5503, -2.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7033, -0.5007, -0.9722], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7033, -0.5007, -0.9722], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7129, -0.9033, -1.7333,  0.2157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7129, -0.9033, -1.7333,  0.2157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6125, -0.7179, -0.9394,  0.2124], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6125, -0.7179, -0.9394,  0.2124], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6625, -0.9468, -0.7202], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6625, -0.9468, -0.7202], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1585, -1.0407, -0.7398, -1.0685], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1585, -1.0407, -0.7398, -1.0685], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8206, -0.7782, -0.6290, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8206, -0.7782, -0.6290, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7534, -1.5568, -0.6684, -1.8554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7534, -1.5568, -0.6684, -1.8554], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.9149, -0.5840, -0.9523], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.9149, -0.5840, -0.9523], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3130, -0.6817,  1.1426, -0.5764], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3130, -0.6817,  1.1426, -0.5764], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3388, -1.0866, -2.8087, -4.1763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3388, -1.0866, -2.8087, -4.1763], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7956, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7956, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6339,  0.8832, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6339,  0.8832, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8717, -0.5459, -2.1320], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8717, -0.5459, -2.1320], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7022, -0.4974, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7022, -0.4974, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7162, -0.9039, -1.7318,  0.2196], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7162, -0.9039, -1.7318,  0.2196], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6982,  0.7993, -1.7996, -0.9097], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6982,  0.7993, -1.7996, -0.9097], grad_fn=<ViewBackward0>),), Output: tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1592, -1.0410, -0.7464, -1.0682], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1592, -1.0410, -0.7464, -1.0682], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.8450], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8450], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8450], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7531, -1.5613, -0.6682, -1.8562], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7531, -1.5613, -0.6682, -1.8562], grad_fn=<ViewBackward0>),), Output: tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3135, -0.6793,  1.1439, -0.5759], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3135, -0.6793,  1.1439, -0.5759], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8652, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8652, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3380, -1.0941, -2.8091, -4.1782], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3380, -1.0941, -2.8091, -4.1782], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6305,  0.8857, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6305,  0.8857, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8694, -0.5415, -2.1330], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8694, -0.5415, -2.1330], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7195, -0.9045, -1.7300,  0.2236], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7195, -0.9045, -1.7300,  0.2236], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>),), Output: tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1598, -1.0413, -0.7526, -1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1598, -1.0413, -0.7526, -1.0679], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7528, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7528, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5895,  0.8161, -0.5195], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5895,  0.8161, -0.5195], grad_fn=<TanhBackward0>),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6273,  0.8882, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6273,  0.8882, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5562,  0.7105, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5562,  0.7105, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8671, -0.5372, -2.1340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8671, -0.5372, -2.1340], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6999, -0.4908, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6999, -0.4908, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7228, -0.9050, -1.7281,  0.2276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7228, -0.9050, -1.7281,  0.2276], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6969,  0.8032, -1.7998, -0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6969,  0.8032, -1.7998, -0.9125], grad_fn=<ViewBackward0>),), Output: tensor([-0.9350,  0.6658, -0.9468, -0.7223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9350,  0.6658, -0.9468, -0.7223], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1604, -1.0415, -0.7585, -1.0677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1604, -1.0415, -0.7585, -1.0677], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7525, -1.5698, -0.6680, -1.8577], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7525, -1.5698, -0.6680, -1.8577], grad_fn=<ViewBackward0>),), Output: tensor([-0.6366, -0.9170, -0.5836, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6366, -0.9170, -0.5836, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3143, -0.6747,  1.1462, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3143, -0.6747,  1.1462, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3364, -1.1083, -2.8102, -4.1818], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3364, -1.1083, -2.8102, -4.1818], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8034, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8034, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8648, -0.5328, -2.1348], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8648, -0.5328, -2.1348], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6987, -0.4875, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6987, -0.4875, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7261, -0.9056, -1.7260,  0.2316], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7261, -0.9056, -1.7260,  0.2316], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6207, -0.7190, -0.9386,  0.2275], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6207, -0.7190, -0.9386,  0.2275], grad_fn=<TanhBackward0>),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6963,  0.8050, -1.7998, -0.9139], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6963,  0.8050, -1.7998, -0.9139], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1610, -1.0417, -0.7641, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1610, -1.0417, -0.7641, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7521, -1.5739, -0.6679, -1.8584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7521, -1.5739, -0.6679, -1.8584], grad_fn=<ViewBackward0>),), Output: tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3147, -0.6725,  1.1472, -0.5751], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3147, -0.6725,  1.1472, -0.5751], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5866,  0.8168, -0.5191], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5866,  0.8168, -0.5191], grad_fn=<TanhBackward0>),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3356, -1.1150, -2.8108, -4.1835], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3356, -1.1150, -2.8108, -4.1835], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6213,  0.8928, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6213,  0.8928, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8625, -0.5285, -2.1357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8625, -0.5285, -2.1357], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6975, -0.4842, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6975, -0.4842, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7294, -0.9062, -1.7238,  0.2356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7294, -0.9062, -1.7238,  0.2356], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6227, -0.7193, -0.9383,  0.2313], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6227, -0.7193, -0.9383,  0.2313], grad_fn=<TanhBackward0>),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6958,  0.8066, -1.7999, -0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6958,  0.8066, -1.7999, -0.9152], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1616, -1.0419, -0.7694, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1616, -1.0419, -0.7694, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8216, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8216, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7518, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7518, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>),), Output: tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3149, -0.6704,  1.1482, -0.5749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3149, -0.6704,  1.1482, -0.5749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5853,  0.8171, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5853,  0.8171, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3348, -1.1216, -2.8115, -4.1852], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3348, -1.1216, -2.8115, -4.1852], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6185,  0.8950, -1.1088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6185,  0.8950, -1.1088], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5501,  0.7138, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5501,  0.7138, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8601, -0.5242, -2.1365], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8601, -0.5242, -2.1365], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6963, -0.4810, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6963, -0.4810, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7326, -0.9067, -1.7215,  0.2395], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7326, -0.9067, -1.7215,  0.2395], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6247, -0.7196, -0.9380,  0.2350], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6247, -0.7196, -0.9380,  0.2350], grad_fn=<TanhBackward0>),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6952,  0.8081, -1.8000, -0.9164], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6952,  0.8081, -1.8000, -0.9164], grad_fn=<ViewBackward0>),), Output: tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1622, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1622, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>),), Output: tensor([-0.6360, -0.9189, -0.5836, -0.9527], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6360, -0.9189, -0.5836, -0.9527], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3339, -1.1280, -2.8122, -4.1868], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3339, -1.1280, -2.8122, -4.1868], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8103, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8103, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2309,  0.8577, -0.5200, -2.1373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2309,  0.8577, -0.5200, -2.1373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7359, -0.9073, -1.7190,  0.2434], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7359, -0.9073, -1.7190,  0.2434], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6266, -0.7198, -0.9377,  0.2387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6266, -0.7198, -0.9377,  0.2387], grad_fn=<TanhBackward0>),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6947,  0.8095, -1.8000, -0.9176], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6947,  0.8095, -1.8000, -0.9176], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6693, -0.9468, -0.7247], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6693, -0.9468, -0.7247], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1627, -1.0422, -0.7792, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1627, -1.0422, -0.7792, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8219, -0.7787, -0.6523, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8219, -0.7787, -0.6523, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7510, -1.5854, -0.6680, -1.8604], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7510, -1.5854, -0.6680, -1.8604], grad_fn=<ViewBackward0>),), Output: tensor([-0.6358, -0.9194, -0.5836, -0.9527], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6358, -0.9194, -0.5836, -0.9527], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6665,  1.1498, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6665,  1.1498, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5827,  0.8177, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5827,  0.8177, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3331, -1.1343, -2.8130, -4.1883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3331, -1.1343, -2.8130, -4.1883], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6133,  0.8992, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6133,  0.8992, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8553, -0.5159, -2.1381], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8553, -0.5159, -2.1381], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6938, -0.4745, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6938, -0.4745, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7390, -0.9079, -1.7165,  0.2473], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7390, -0.9079, -1.7165,  0.2473], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6286, -0.7201, -0.9374,  0.2423], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6286, -0.7201, -0.9374,  0.2423], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6941,  0.8108, -1.8001, -0.9187], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6941,  0.8108, -1.8001, -0.9187], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1632, -1.0423, -0.7838, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1632, -1.0423, -0.7838, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7507, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7507, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>),), Output: tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6108,  0.9012, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6108,  0.9012, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2311,  0.8529, -0.5117, -2.1389], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2311,  0.8529, -0.5117, -2.1389], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7421, -0.9084, -1.7139,  0.2511], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7421, -0.9084, -1.7139,  0.2511], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6304, -0.7204, -0.9371,  0.2459], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6304, -0.7204, -0.9371,  0.2459], grad_fn=<TanhBackward0>),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6936,  0.8121, -1.8001, -0.9198], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6936,  0.8121, -1.8001, -0.9198], grad_fn=<ViewBackward0>),), Output: tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1638, -1.0424, -0.7880, -1.0665], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1638, -1.0424, -0.7880, -1.0665], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8223, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8223, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8861], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8861], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8861], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7503, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7503, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>),), Output: tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6628,  1.1513, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6628,  1.1513, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5803,  0.8182, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5803,  0.8182, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3314, -1.1464, -2.8148, -4.1913], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3314, -1.1464, -2.8148, -4.1913], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8165, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8165, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6085,  0.9032, -1.1095], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6085,  0.9032, -1.1095], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5431,  0.7179, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5431,  0.7179, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2311,  0.8505, -0.5077, -2.1396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2311,  0.8505, -0.5077, -2.1396], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6913, -0.4682, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6913, -0.4682, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7452, -0.9090, -1.7112,  0.2549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7452, -0.9090, -1.7112,  0.2549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6323, -0.7206, -0.9368,  0.2495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6323, -0.7206, -0.9368,  0.2495], grad_fn=<TanhBackward0>),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1643, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1643, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7499, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7499, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>),), Output: tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3305, -1.1522, -2.8158, -4.1927], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3305, -1.1522, -2.8158, -4.1927], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5415,  0.7188, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5415,  0.7188, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2312,  0.8481, -0.5037, -2.1403], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2312,  0.8481, -0.5037, -2.1403], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6901, -0.4651, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6901, -0.4651, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7482, -0.9095, -1.7085,  0.2586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7482, -0.9095, -1.7085,  0.2586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6341, -0.7209, -0.9365,  0.2529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6341, -0.7209, -0.9365,  0.2529], grad_fn=<TanhBackward0>),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6927,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6927,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6719, -0.9468, -0.7268], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6719, -0.9468, -0.7268], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1648, -1.0425, -0.7960, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1648, -1.0425, -0.7960, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7495, -1.5993, -0.6686, -1.8628], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7495, -1.5993, -0.6686, -1.8628], grad_fn=<ViewBackward0>),), Output: tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6594,  1.1525, -0.5748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6594,  1.1525, -0.5748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5780,  0.8186, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5780,  0.8186, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3297, -1.1579, -2.8168, -4.1941], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3297, -1.1579, -2.8168, -4.1941], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6041,  0.9071, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6041,  0.9071, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2313,  0.8457, -0.4998, -2.1409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2313,  0.8457, -0.4998, -2.1409], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6888, -0.4620, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6888, -0.4620, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7512, -0.9101, -1.7057,  0.2622], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7512, -0.9101, -1.7057,  0.2622], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6922,  0.8152, -1.8003, -0.9228], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6922,  0.8152, -1.8003, -0.9228], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7789, -0.6638, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7789, -0.6638, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7491, -1.6025, -0.6688, -1.8633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7491, -1.6025, -0.6688, -1.8633], grad_fn=<ViewBackward0>),), Output: tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6578,  1.1531, -0.5749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6578,  1.1531, -0.5749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5769,  0.8188, -0.5190], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5769,  0.8188, -0.5190], grad_fn=<TanhBackward0>),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -1.1635, -2.8178, -4.1954], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -1.1635, -2.8178, -4.1954], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6020,  0.9090, -1.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6020,  0.9090, -1.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8433, -0.4960, -2.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8433, -0.4960, -2.1416], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6875, -0.4590, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6875, -0.4590, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7541, -0.9106, -1.7029,  0.2658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7541, -0.9106, -1.7029,  0.2658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6376, -0.7214, -0.9358,  0.2597], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6376, -0.7214, -0.9358,  0.2597], grad_fn=<TanhBackward0>),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6917,  0.8161, -1.8003, -0.9237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6917,  0.8161, -1.8003, -0.9237], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6730, -0.9468, -0.7277], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6730, -0.9468, -0.7277], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1657, -1.0425, -0.8031, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1657, -1.0425, -0.8031, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7487, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7487, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>),), Output: tensor([-0.6344, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6344, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3280, -1.1690, -2.8189, -4.1967], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3280, -1.1690, -2.8189, -4.1967], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2315,  0.8409, -0.4923, -2.1422], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2315,  0.8409, -0.4923, -2.1422], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6863, -0.4560, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6863, -0.4560, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7569, -0.9112, -1.7001,  0.2693], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7569, -0.9112, -1.7001,  0.2693], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6393, -0.7217, -0.9354,  0.2630], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6393, -0.7217, -0.9354,  0.2630], grad_fn=<TanhBackward0>),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1661, -1.0425, -0.8064, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1661, -1.0425, -0.8064, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7483, -1.6088, -0.6694, -1.8644], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7483, -1.6088, -0.6694, -1.8644], grad_fn=<ViewBackward0>),), Output: tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6547,  1.1541, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6547,  1.1541, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3271, -1.1744, -2.8200, -4.1979], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3271, -1.1744, -2.8200, -4.1979], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.5980,  0.9126, -1.1108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.5980,  0.9126, -1.1108], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2317,  0.8385, -0.4886, -2.1428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2317,  0.8385, -0.4886, -2.1428], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6850, -0.4531, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6850, -0.4531, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7597, -0.9117, -1.6973,  0.2728], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7597, -0.9117, -1.6973,  0.2728], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6409, -0.7219, -0.9351,  0.2662], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6409, -0.7219, -0.9351,  0.2662], grad_fn=<TanhBackward0>),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6909,  0.8177, -1.8005, -0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6909,  0.8177, -1.8005, -0.9255], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6738, -0.9469, -0.7285], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6738, -0.9469, -0.7285], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1666, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1666, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8232, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8232, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7479, -1.6119, -0.6698, -1.8649], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7479, -1.6119, -0.6698, -1.8649], grad_fn=<ViewBackward0>),), Output: tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6532,  1.1546, -0.5755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6532,  1.1546, -0.5755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3263, -1.1797, -2.8212, -4.1992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3263, -1.1797, -2.8212, -4.1992], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5961,  0.9144, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5961,  0.9144, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5343,  0.7233, -0.8045], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5343,  0.7233, -0.8045], grad_fn=<TanhBackward0>),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2318,  0.8362, -0.4850, -2.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2318,  0.8362, -0.4850, -2.1434], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6838, -0.4503, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6838, -0.4503, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7624, -0.9122, -1.6945,  0.2761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7624, -0.9122, -1.6945,  0.2761], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6425, -0.7222, -0.9347,  0.2693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6425, -0.7222, -0.9347,  0.2693], grad_fn=<TanhBackward0>),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6904,  0.8184, -1.8005, -0.9263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6904,  0.8184, -1.8005, -0.9263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1670, -1.0424, -0.8126, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1670, -1.0424, -0.8126, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8233, -0.7789, -0.6710, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8233, -0.7789, -0.6710, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7475, -1.6148, -0.6701, -1.8655], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7475, -1.6148, -0.6701, -1.8655], grad_fn=<ViewBackward0>),), Output: tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6517,  1.1550, -0.5758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6517,  1.1550, -0.5758], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3254, -1.1849, -2.8224, -4.2004], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3254, -1.1849, -2.8224, -4.2004], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2866, -0.5943,  0.9162, -1.1114], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2866, -0.5943,  0.9162, -1.1114], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5330,  0.7241, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5330,  0.7241, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2319,  0.8339, -0.4815, -2.1440], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2319,  0.8339, -0.4815, -2.1440], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6825, -0.4475, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6825, -0.4475, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7651, -0.9127, -1.6917,  0.2794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7651, -0.9127, -1.6917,  0.2794], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6441, -0.7224, -0.9344,  0.2724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6441, -0.7224, -0.9344,  0.2724], grad_fn=<TanhBackward0>),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>),), Output: tensor([-0.9342,  0.6746, -0.9469, -0.7293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9342,  0.6746, -0.9469, -0.7293], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1674, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1674, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7470, -1.6177, -0.6705, -1.8660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7470, -1.6177, -0.6705, -1.8660], grad_fn=<ViewBackward0>),), Output: tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3246, -1.1900, -2.8236, -4.2015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3246, -1.1900, -2.8236, -4.2015], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2866, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2866, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5317,  0.7249, -0.8047], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5317,  0.7249, -0.8047], grad_fn=<TanhBackward0>),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2320,  0.8316, -0.4781, -2.1446], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2320,  0.8316, -0.4781, -2.1446], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6813, -0.4447, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6813, -0.4447, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7677, -0.9132, -1.6889,  0.2827], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7677, -0.9132, -1.6889,  0.2827], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6456, -0.7227, -0.9340,  0.2754], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6456, -0.7227, -0.9340,  0.2754], grad_fn=<TanhBackward0>),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8235, -0.7788, -0.6740, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8235, -0.7788, -0.6740, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>),), Output: tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5709,  0.8197, -0.5201], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5709,  0.8197, -0.5201], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3238, -1.1951, -2.8249, -4.2027], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3238, -1.1951, -2.8249, -4.2027], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5305,  0.7258, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5305,  0.7258, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2322,  0.8293, -0.4748, -2.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2322,  0.8293, -0.4748, -2.1451], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6801, -0.4420, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6801, -0.4420, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7702, -0.9137, -1.6861,  0.2858], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7702, -0.9137, -1.6861,  0.2858], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6470, -0.7229, -0.9336,  0.2783], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6470, -0.7229, -0.9336,  0.2783], grad_fn=<TanhBackward0>),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6892,  0.8203, -1.8008, -0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6892,  0.8203, -1.8008, -0.9287], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1681, -1.0423, -0.8207, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1681, -1.0423, -0.8207, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8237, -0.7788, -0.6754, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8237, -0.7788, -0.6754, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>),), Output: tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3229, -1.2000, -2.8262, -4.2038], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3229, -1.2000, -2.8262, -4.2038], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5293,  0.7266, -0.8049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5293,  0.7266, -0.8049], grad_fn=<TanhBackward0>),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2323,  0.8270, -0.4715, -2.1456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2323,  0.8270, -0.4715, -2.1456], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7726, -0.9141, -1.6833,  0.2889], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7726, -0.9141, -1.6833,  0.2889], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6485, -0.7231, -0.9333,  0.2811], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6485, -0.7231, -0.9333,  0.2811], grad_fn=<TanhBackward0>),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6889,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6889,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1685, -1.0422, -0.8231, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1685, -1.0422, -0.8231, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7458, -1.6262, -0.6719, -1.8674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7458, -1.6262, -0.6719, -1.8674], grad_fn=<ViewBackward0>),), Output: tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.6461,  1.1565, -0.5772], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.6461,  1.1565, -0.5772], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5690,  0.8199, -0.5207], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5690,  0.8199, -0.5207], grad_fn=<TanhBackward0>),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3221, -1.2049, -2.8275, -4.2048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3221, -1.2049, -2.8275, -4.2048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2864, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2864, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2324,  0.8248, -0.4683, -2.1462], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2324,  0.8248, -0.4683, -2.1462], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6777, -0.4369, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6777, -0.4369, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7750, -0.9146, -1.6805,  0.2919], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7750, -0.9146, -1.6805,  0.2919], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6498, -0.7233, -0.9329,  0.2839], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6498, -0.7233, -0.9329,  0.2839], grad_fn=<TanhBackward0>),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6885,  0.8212, -1.8010, -0.9301], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6885,  0.8212, -1.8010, -0.9301], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6757, -0.9469, -0.7307], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6757, -0.9469, -0.7307], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1688, -1.0421, -0.8254, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1688, -1.0421, -0.8254, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7454, -1.6288, -0.6724, -1.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7454, -1.6288, -0.6724, -1.8679], grad_fn=<ViewBackward0>),), Output: tensor([-0.6324, -0.9259, -0.5865, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6324, -0.9259, -0.5865, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6448,  1.1569, -0.5777], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6448,  1.1569, -0.5777], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3213, -1.2096, -2.8289, -4.2059], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3213, -1.2096, -2.8289, -4.2059], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5859,  0.9249, -1.1133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5859,  0.9249, -1.1133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5270,  0.7282, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5270,  0.7282, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.9104], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9104], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9104], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2326,  0.8225, -0.4653, -2.1467], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2326,  0.8225, -0.4653, -2.1467], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6765, -0.4344, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6765, -0.4344, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7774, -0.9150, -1.6778,  0.2949], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7774, -0.9150, -1.6778,  0.2949], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6512, -0.7235, -0.9326,  0.2866], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6512, -0.7235, -0.9326,  0.2866], grad_fn=<TanhBackward0>),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6881,  0.8216, -1.8011, -0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6881,  0.8216, -1.8011, -0.9308], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1692, -1.0420, -0.8276, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1692, -1.0420, -0.8276, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7450, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7450, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>),), Output: tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6435,  1.1572, -0.5781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6435,  1.1572, -0.5781], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3205, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3205, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2862, -0.5844,  0.9266, -1.1137], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2862, -0.5844,  0.9266, -1.1137], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5258,  0.7290, -0.8054], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5258,  0.7290, -0.8054], grad_fn=<TanhBackward0>),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2327,  0.8204, -0.4623, -2.1471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2327,  0.8204, -0.4623, -2.1471], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7796, -0.9154, -1.6751,  0.2977], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7796, -0.9154, -1.6751,  0.2977], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6525, -0.7237, -0.9322,  0.2892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6525, -0.7237, -0.9322,  0.2892], grad_fn=<TanhBackward0>),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6878,  0.8220, -1.8012, -0.9315], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6878,  0.8220, -1.8012, -0.9315], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1695, -1.0419, -0.8297, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1695, -1.0419, -0.8297, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7446, -1.6341, -0.6734, -1.8688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7446, -1.6341, -0.6734, -1.8688], grad_fn=<ViewBackward0>),), Output: tensor([-0.6319, -0.9266, -0.5872, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6319, -0.9266, -0.5872, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3150, -0.6422,  1.1575, -0.5786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3150, -0.6422,  1.1575, -0.5786], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5664,  0.8202, -0.5216], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5664,  0.8202, -0.5216], grad_fn=<TanhBackward0>),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3197, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3197, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2862, -0.5829,  0.9282, -1.1141], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2862, -0.5829,  0.9282, -1.1141], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5248,  0.7298, -0.8055], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5248,  0.7298, -0.8055], grad_fn=<TanhBackward0>),), Output: tensor([0.9124], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9124], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9124], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2329,  0.8182, -0.4593, -2.1476], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2329,  0.8182, -0.4593, -2.1476], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6741, -0.4295, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6741, -0.4295, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7818, -0.9158, -1.6724,  0.3005], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7818, -0.9158, -1.6724,  0.3005], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6538, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6538, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1698, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1698, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7442, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7442, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>),), Output: tensor([-0.6317, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6317, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3148, -0.6409,  1.1578, -0.5791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3148, -0.6409,  1.1578, -0.5791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3189, -1.2236, -2.8331, -4.2089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3189, -1.2236, -2.8331, -4.2089], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2330,  0.8161, -0.4565, -2.1481], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2330,  0.8161, -0.4565, -2.1481], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6729, -0.4272, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6729, -0.4272, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7840, -0.9162, -1.6698,  0.3032], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7840, -0.9162, -1.6698,  0.3032], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6550, -0.7241, -0.9315,  0.2942], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6550, -0.7241, -0.9315,  0.2942], grad_fn=<TanhBackward0>),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6871,  0.8227, -1.8014, -0.9328], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6871,  0.8227, -1.8014, -0.9328], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1701, -1.0416, -0.8336, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1701, -1.0416, -0.8336, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8243, -0.7785, -0.6824, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8243, -0.7785, -0.6824, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7438, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7438, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6397,  1.1580, -0.5796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6397,  1.1580, -0.5796], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5647,  0.8204, -0.5224], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5647,  0.8204, -0.5224], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3181, -1.2281, -2.8346, -4.2099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3181, -1.2281, -2.8346, -4.2099], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5227,  0.7313, -0.8058], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5227,  0.7313, -0.8058], grad_fn=<TanhBackward0>),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2332,  0.8139, -0.4537, -2.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2332,  0.8139, -0.4537, -2.1485], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6718, -0.4250, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6718, -0.4250, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7860, -0.9166, -1.6671,  0.3058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7860, -0.9166, -1.6671,  0.3058], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6562, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6562, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6867,  0.8230, -1.8016, -0.9334], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6867,  0.8230, -1.8016, -0.9334], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1704, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1704, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8244, -0.7785, -0.6834, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8244, -0.7785, -0.6834, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7434, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7434, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>),), Output: tensor([-0.6312, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6312, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3173, -1.2325, -2.8360, -4.2108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3173, -1.2325, -2.8360, -4.2108], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5217,  0.7321, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5217,  0.7321, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2333,  0.8119, -0.4510, -2.1490], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2333,  0.8119, -0.4510, -2.1490], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6706, -0.4228, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6706, -0.4228, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7881, -0.9170, -1.6646,  0.3084], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7881, -0.9170, -1.6646,  0.3084], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6573, -0.7245, -0.9308,  0.2990], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6573, -0.7245, -0.9308,  0.2990], grad_fn=<TanhBackward0>),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6864,  0.8232, -1.8017, -0.9340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6864,  0.8232, -1.8017, -0.9340], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1707, -1.0413, -0.8371, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1707, -1.0413, -0.8371, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>),), Output: tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3142, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3142, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3166, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3166, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2859, -0.5773,  0.9348, -1.1158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2859, -0.5773,  0.9348, -1.1158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5207,  0.7328, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5207,  0.7328, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2335,  0.8098, -0.4484, -2.1494], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2335,  0.8098, -0.4484, -2.1494], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6695, -0.4206, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6695, -0.4206, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7900, -0.9173, -1.6620,  0.3109], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7900, -0.9173, -1.6620,  0.3109], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6861,  0.8234, -1.8018, -0.9346], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6861,  0.8234, -1.8018, -0.9346], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>),), Output: tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3158, -1.2412, -2.8390, -4.2126], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3158, -1.2412, -2.8390, -4.2126], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2336,  0.8078, -0.4459, -2.1498], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2336,  0.8078, -0.4459, -2.1498], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6684, -0.4185, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6684, -0.4185, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7919, -0.9177, -1.6595,  0.3133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7919, -0.9177, -1.6595,  0.3133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6858,  0.8236, -1.8020, -0.9351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6858,  0.8236, -1.8020, -0.9351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6770, -0.9470, -0.7330], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6770, -0.9470, -0.7330], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1712, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1712, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7783, -0.6859, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7783, -0.6859, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3137, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3137, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8652, -0.5614,  0.8207, -0.5240], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8652, -0.5614,  0.8207, -0.5240], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2338,  0.8058, -0.4434, -2.1502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2338,  0.8058, -0.4434, -2.1502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6673, -0.4165, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6673, -0.4165, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7937, -0.9180, -1.6570,  0.3157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7937, -0.9180, -1.6570,  0.3157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6605, -0.7249, -0.9298,  0.3056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6605, -0.7249, -0.9298,  0.3056], grad_fn=<TanhBackward0>),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6855,  0.8238, -1.8021, -0.9357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6855,  0.8238, -1.8021, -0.9357], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1715, -1.0408, -0.8417, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1715, -1.0408, -0.8417, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7418, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7418, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>),), Output: tensor([-0.6302, -0.9290, -0.5900, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6302, -0.9290, -0.5900, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3134, -0.6337,  1.1592, -0.5825], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3134, -0.6337,  1.1592, -0.5825], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5606,  0.8208, -0.5245], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5606,  0.8208, -0.5245], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3143, -1.2497, -2.8421, -4.2144], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3143, -1.2497, -2.8421, -4.2144], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2857, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2857, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2339,  0.8038, -0.4410, -2.1506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2339,  0.8038, -0.4410, -2.1506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6662, -0.4145, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6662, -0.4145, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7955, -0.9183, -1.6546,  0.3180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7955, -0.9183, -1.6546,  0.3180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6852,  0.8239, -1.8023, -0.9362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6852,  0.8239, -1.8023, -0.9362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1717, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1717, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7414, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7414, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>),), Output: tensor([-0.6300, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6300, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5598,  0.8209, -0.5249], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5598,  0.8209, -0.5249], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3135, -1.2538, -2.8436, -4.2152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3135, -1.2538, -2.8436, -4.2152], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5721,  0.9411, -1.1176], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5721,  0.9411, -1.1176], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5169,  0.7357, -0.8067], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5169,  0.7357, -0.8067], grad_fn=<TanhBackward0>),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2341,  0.8019, -0.4387, -2.1510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2341,  0.8019, -0.4387, -2.1510], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6651, -0.4126, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6651, -0.4126, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7973, -0.9186, -1.6522,  0.3202], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7973, -0.9186, -1.6522,  0.3202], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6849,  0.8240, -1.8025, -0.9367], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6849,  0.8240, -1.8025, -0.9367], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1719, -1.0404, -0.8444, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1719, -1.0404, -0.8444, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8249, -0.7780, -0.6882, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8249, -0.7780, -0.6882, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7410, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7410, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3128, -0.6314,  1.1596, -0.5837], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3128, -0.6314,  1.1596, -0.5837], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3128, -1.2579, -2.8452, -4.2161], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3128, -1.2579, -2.8452, -4.2161], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2855, -0.5709,  0.9427, -1.1180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2855, -0.5709,  0.9427, -1.1180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2343,  0.8000, -0.4365, -2.1514], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2343,  0.8000, -0.4365, -2.1514], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6640, -0.4107, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6640, -0.4107, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7990, -0.9189, -1.6499,  0.3223], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7990, -0.9189, -1.6499,  0.3223], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6634, -0.7254, -0.9288,  0.3116], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6634, -0.7254, -0.9288,  0.3116], grad_fn=<TanhBackward0>),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6846,  0.8241, -1.8026, -0.9373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6846,  0.8241, -1.8026, -0.9373], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6773, -0.9471, -0.7340], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6773, -0.9471, -0.7340], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1722, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1722, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7406, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7406, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>),), Output: tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6303,  1.1598, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6303,  1.1598, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5582,  0.8210, -0.5259], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5582,  0.8210, -0.5259], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3121, -1.2619, -2.8468, -4.2169], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3121, -1.2619, -2.8468, -4.2169], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2854, -0.5697,  0.9442, -1.1185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2854, -0.5697,  0.9442, -1.1185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2344,  0.7981, -0.4343, -2.1518], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2344,  0.7981, -0.4343, -2.1518], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6630, -0.4089, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6630, -0.4089, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8006, -0.9192, -1.6476,  0.3244], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8006, -0.9192, -1.6476,  0.3244], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6644, -0.7255, -0.9285,  0.3135], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6644, -0.7255, -0.9285,  0.3135], grad_fn=<TanhBackward0>),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6843,  0.8242, -1.8028, -0.9377], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6843,  0.8242, -1.8028, -0.9377], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1724, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1724, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7402, -1.6599, -0.6805, -1.8731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7402, -1.6599, -0.6805, -1.8731], grad_fn=<ViewBackward0>),), Output: tensor([-0.6293, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6293, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3122, -0.6292,  1.1600, -0.5851], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3122, -0.6292,  1.1600, -0.5851], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5575,  0.8210, -0.5263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5575,  0.8210, -0.5263], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3113, -1.2659, -2.8484, -4.2177], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3113, -1.2659, -2.8484, -4.2177], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2854, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2854, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5143,  0.7379, -0.8072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5143,  0.7379, -0.8072], grad_fn=<TanhBackward0>),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2346,  0.7963, -0.4322, -2.1521], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2346,  0.7963, -0.4322, -2.1521], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6619, -0.4071, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6619, -0.4071, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8022, -0.9194, -1.6453,  0.3265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8022, -0.9194, -1.6453,  0.3265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6652, -0.7256, -0.9282,  0.3153], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6652, -0.7256, -0.9282,  0.3153], grad_fn=<TanhBackward0>),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1726, -1.0398, -0.8480, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1726, -1.0398, -0.8480, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7398, -1.6620, -0.6812, -1.8735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7398, -1.6620, -0.6812, -1.8735], grad_fn=<ViewBackward0>),), Output: tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6281,  1.1602, -0.5857], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6281,  1.1602, -0.5857], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3106, -1.2698, -2.8500, -4.2185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3106, -1.2698, -2.8500, -4.2185], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2348,  0.7944, -0.4301, -2.1525], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2348,  0.7944, -0.4301, -2.1525], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6609, -0.4054, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6609, -0.4054, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8037, -0.9197, -1.6431,  0.3284], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8037, -0.9197, -1.6431,  0.3284], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6661, -0.7257, -0.9279,  0.3171], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6661, -0.7257, -0.9279,  0.3171], grad_fn=<TanhBackward0>),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6837,  0.8243, -1.8032, -0.9387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6837,  0.8243, -1.8032, -0.9387], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1728, -1.0396, -0.8491, -1.0667], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1728, -1.0396, -0.8491, -1.0667], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7394, -1.6641, -0.6820, -1.8738], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7394, -1.6641, -0.6820, -1.8738], grad_fn=<ViewBackward0>),), Output: tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3116, -0.6270,  1.1603, -0.5864], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3116, -0.6270,  1.1603, -0.5864], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5560,  0.8211, -0.5273], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5560,  0.8211, -0.5273], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3099, -1.2736, -2.8516, -4.2193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3099, -1.2736, -2.8516, -4.2193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5126,  0.7392, -0.8075], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5126,  0.7392, -0.8075], grad_fn=<TanhBackward0>),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2349,  0.7926, -0.4281, -2.1529], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2349,  0.7926, -0.4281, -2.1529], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6599, -0.4038, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6599, -0.4038, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8052, -0.9199, -1.6409,  0.3303], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8052, -0.9199, -1.6409,  0.3303], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6669, -0.7258, -0.9276,  0.3188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6669, -0.7258, -0.9276,  0.3188], grad_fn=<TanhBackward0>),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6835,  0.8244, -1.8034, -0.9392], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6835,  0.8244, -1.8034, -0.9392], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1730, -1.0393, -0.8501, -1.0669], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1730, -1.0393, -0.8501, -1.0669], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7390, -1.6661, -0.6827, -1.8742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7390, -1.6661, -0.6827, -1.8742], grad_fn=<ViewBackward0>),), Output: tensor([-0.6286, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6286, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3113, -0.6259,  1.1605, -0.5871], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3113, -0.6259,  1.1605, -0.5871], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3092, -1.2774, -2.8532, -4.2200], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3092, -1.2774, -2.8532, -4.2200], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2852, -0.5651,  0.9503, -1.1204], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2852, -0.5651,  0.9503, -1.1204], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5118,  0.7399, -0.8077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5118,  0.7399, -0.8077], grad_fn=<TanhBackward0>),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2351,  0.7909, -0.4262, -2.1532], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2351,  0.7909, -0.4262, -2.1532], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6589, -0.4021, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6589, -0.4021, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8066, -0.9201, -1.6388,  0.3322], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8066, -0.9201, -1.6388,  0.3322], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6677, -0.7259, -0.9273,  0.3205], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6677, -0.7259, -0.9273,  0.3205], grad_fn=<TanhBackward0>),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6832,  0.8244, -1.8036, -0.9396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6832,  0.8244, -1.8036, -0.9396], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9472, -0.7350], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9472, -0.7350], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7387, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7387, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>),), Output: tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8645, -0.5545,  0.8212, -0.5283], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8645, -0.5545,  0.8212, -0.5283], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3085, -1.2812, -2.8548, -4.2208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3085, -1.2812, -2.8548, -4.2208], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2353,  0.7891, -0.4243, -2.1535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2353,  0.7891, -0.4243, -2.1535], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6579, -0.4006, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6579, -0.4006, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8080, -0.9203, -1.6367,  0.3340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8080, -0.9203, -1.6367,  0.3340], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6685, -0.7260, -0.9270,  0.3221], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6685, -0.7260, -0.9270,  0.3221], grad_fn=<TanhBackward0>),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6829,  0.8244, -1.8038, -0.9401], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6829,  0.8244, -1.8038, -0.9401], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7352], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7352], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1734, -1.0389, -0.8520, -1.0671], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1734, -1.0389, -0.8520, -1.0671], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8254, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8254, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9532], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9532], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9532], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7383, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7383, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3106, -0.6238,  1.1608, -0.5885], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3106, -0.6238,  1.1608, -0.5885], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5538,  0.8213, -0.5288], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5538,  0.8213, -0.5288], grad_fn=<TanhBackward0>),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3078, -1.2849, -2.8564, -4.2215], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3078, -1.2849, -2.8564, -4.2215], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5102,  0.7413, -0.8080], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5102,  0.7413, -0.8080], grad_fn=<TanhBackward0>),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2354,  0.7874, -0.4225, -2.1539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2354,  0.7874, -0.4225, -2.1539], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6569, -0.3990, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6569, -0.3990, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8094, -0.9205, -1.6346,  0.3357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8094, -0.9205, -1.6346,  0.3357], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6692, -0.7261, -0.9267,  0.3237], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6692, -0.7261, -0.9267,  0.3237], grad_fn=<TanhBackward0>),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6827,  0.8243, -1.8040, -0.9405], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6827,  0.8243, -1.8040, -0.9405], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1736, -1.0386, -0.8528, -1.0673], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1736, -1.0386, -0.8528, -1.0673], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8254, -0.7773, -0.6925, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8254, -0.7773, -0.6925, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>),), Output: tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3103, -0.6227,  1.1609, -0.5893], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3103, -0.6227,  1.1609, -0.5893], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8643, -0.5530,  0.8213, -0.5294], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8643, -0.5530,  0.8213, -0.5294], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3071, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3071, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2850, -0.5619,  0.9547, -1.1218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2850, -0.5619,  0.9547, -1.1218], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5094,  0.7419, -0.8082], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5094,  0.7419, -0.8082], grad_fn=<TanhBackward0>),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2356,  0.7857, -0.4207, -2.1542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2356,  0.7857, -0.4207, -2.1542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6560, -0.3975, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6560, -0.3975, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8107, -0.9207, -1.6326,  0.3374], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8107, -0.9207, -1.6326,  0.3374], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6700, -0.7262, -0.9264,  0.3252], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6700, -0.7262, -0.9264,  0.3252], grad_fn=<TanhBackward0>),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6824,  0.8243, -1.8042, -0.9409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6824,  0.8243, -1.8042, -0.9409], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1738, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1738, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7773, -0.6930, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7773, -0.6930, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>),), Output: tensor([-0.6277, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6277, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3099, -0.6217,  1.1610, -0.5900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3099, -0.6217,  1.1610, -0.5900], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8643, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8643, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3064, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3064, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2358,  0.7840, -0.4190, -2.1545], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2358,  0.7840, -0.4190, -2.1545], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6550, -0.3961, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6550, -0.3961, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8119, -0.9209, -1.6307,  0.3391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8119, -0.9209, -1.6307,  0.3391], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6707, -0.7263, -0.9262,  0.3266], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6707, -0.7263, -0.9262,  0.3266], grad_fn=<TanhBackward0>),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1740, -1.0382, -0.8544, -1.0676], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1740, -1.0382, -0.8544, -1.0676], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7772, -0.6934, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7772, -0.6934, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7372, -1.6759, -0.6865, -1.8758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7372, -1.6759, -0.6865, -1.8758], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3096, -0.6207,  1.1612, -0.5907], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3096, -0.6207,  1.1612, -0.5907], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2848, -0.5598,  0.9576, -1.1228], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2848, -0.5598,  0.9576, -1.1228], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2359,  0.7824, -0.4174, -2.1548], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2359,  0.7824, -0.4174, -2.1548], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6541, -0.3947, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6541, -0.3947, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8132, -0.9210, -1.6287,  0.3407], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8132, -0.9210, -1.6287,  0.3407], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6820,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6820,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7360], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7771, -0.6938, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7771, -0.6938, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>),), Output: tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3092, -0.6197,  1.1613, -0.5915], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3092, -0.6197,  1.1613, -0.5915], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8641, -0.5509,  0.8215, -0.5310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8641, -0.5509,  0.8215, -0.5310], grad_fn=<TanhBackward0>),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3051, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3051, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2848, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2848, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2361,  0.7808, -0.4158, -2.1551], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2361,  0.7808, -0.4158, -2.1551], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6532, -0.3933, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6532, -0.3933, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8144, -0.9212, -1.6268,  0.3422], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8144, -0.9212, -1.6268,  0.3422], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6720, -0.7265, -0.9256,  0.3294], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6720, -0.7265, -0.9256,  0.3294], grad_fn=<TanhBackward0>),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6817,  0.8241, -1.8048, -0.9421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6817,  0.8241, -1.8048, -0.9421], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1743, -1.0377, -0.8559, -1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1743, -1.0377, -0.8559, -1.0679], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7770, -0.6941, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7770, -0.6941, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7364, -1.6796, -0.6881, -1.8765], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7364, -1.6796, -0.6881, -1.8765], grad_fn=<ViewBackward0>),), Output: tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3089, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3089, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3044, -1.3028, -2.8646, -4.2250], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3044, -1.3028, -2.8646, -4.2250], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5064,  0.7445, -0.8089], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5064,  0.7445, -0.8089], grad_fn=<TanhBackward0>),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2363,  0.7792, -0.4142, -2.1554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2363,  0.7792, -0.4142, -2.1554], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6522, -0.3920, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6522, -0.3920, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8155, -0.9213, -1.6249,  0.3437], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8155, -0.9213, -1.6249,  0.3437], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6726, -0.7265, -0.9253,  0.3308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6726, -0.7265, -0.9253,  0.3308], grad_fn=<TanhBackward0>),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6815,  0.8241, -1.8050, -0.9425], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6815,  0.8241, -1.8050, -0.9425], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7364], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7364], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1745, -1.0374, -0.8565, -1.0680], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1745, -1.0374, -0.8565, -1.0680], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7769, -0.6945, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7769, -0.6945, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7361, -1.6814, -0.6889, -1.8768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7361, -1.6814, -0.6889, -1.8768], grad_fn=<ViewBackward0>),), Output: tensor([-0.6268, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6268, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3037, -1.3062, -2.8663, -4.2257], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3037, -1.3062, -2.8663, -4.2257], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5569,  0.9618, -1.1242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5569,  0.9618, -1.1242], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2364,  0.7776, -0.4127, -2.1557], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2364,  0.7776, -0.4127, -2.1557], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6513, -0.3907, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6513, -0.3907, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8166, -0.9214, -1.6231,  0.3451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8166, -0.9214, -1.6231,  0.3451], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6812,  0.8240, -1.8052, -0.9429], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6812,  0.8240, -1.8052, -0.9429], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1746, -1.0371, -0.8571, -1.0682], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1746, -1.0371, -0.8571, -1.0682], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7768, -0.6948, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7768, -0.6948, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7357, -1.6832, -0.6897, -1.8771], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7357, -1.6832, -0.6897, -1.8771], grad_fn=<ViewBackward0>),), Output: tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.6167,  1.1616, -0.5937], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.6167,  1.1616, -0.5937], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3031, -1.3096, -2.8679, -4.2263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3031, -1.3096, -2.8679, -4.2263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2366,  0.7761, -0.4112, -2.1560], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2366,  0.7761, -0.4112, -2.1560], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6505, -0.3895, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6505, -0.3895, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8177, -0.9216, -1.6213,  0.3465], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8177, -0.9216, -1.6213,  0.3465], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6738, -0.7266, -0.9248,  0.3333], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6738, -0.7266, -0.9248,  0.3333], grad_fn=<TanhBackward0>),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1748, -1.0369, -0.8577, -1.0683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1748, -1.0369, -0.8577, -1.0683], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7767, -0.6951, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7767, -0.6951, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7354, -1.6850, -0.6905, -1.8774], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7354, -1.6850, -0.6905, -1.8774], grad_fn=<ViewBackward0>),), Output: tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3078, -0.6157,  1.1617, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3078, -0.6157,  1.1617, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3024, -1.3129, -2.8696, -4.2270], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3024, -1.3129, -2.8696, -4.2270], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2368,  0.7746, -0.4098, -2.1563], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2368,  0.7746, -0.4098, -2.1563], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6496, -0.3883, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6496, -0.3883, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8188, -0.9217, -1.6196,  0.3479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8188, -0.9217, -1.6196,  0.3479], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6744, -0.7267, -0.9246,  0.3345], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6744, -0.7267, -0.9246,  0.3345], grad_fn=<TanhBackward0>),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6808,  0.8238, -1.8057, -0.9436], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6808,  0.8238, -1.8057, -0.9436], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6771, -0.9474, -0.7369], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6771, -0.9474, -0.7369], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7350, -1.6867, -0.6913, -1.8777], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7350, -1.6867, -0.6913, -1.8777], grad_fn=<ViewBackward0>),), Output: tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3074, -0.6147,  1.1618, -0.5953], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3074, -0.6147,  1.1618, -0.5953], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3018, -1.3162, -2.8713, -4.2276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3018, -1.3162, -2.8713, -4.2276], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2845, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2845, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2370,  0.7731, -0.4084, -2.1566], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2370,  0.7731, -0.4084, -2.1566], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6487, -0.3871, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6487, -0.3871, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8198, -0.9218, -1.6178,  0.3492], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8198, -0.9218, -1.6178,  0.3492], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6750, -0.7267, -0.9243,  0.3357], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6750, -0.7267, -0.9243,  0.3357], grad_fn=<TanhBackward0>),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6806,  0.8236, -1.8059, -0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6806,  0.8236, -1.8059, -0.9439], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1751, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1751, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7764, -0.6956, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7764, -0.6956, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7346, -1.6885, -0.6921, -1.8780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7346, -1.6885, -0.6921, -1.8780], grad_fn=<ViewBackward0>),), Output: tensor([-0.6259, -0.9340, -0.5994, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6259, -0.9340, -0.5994, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3070, -0.6137,  1.1619, -0.5960], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3070, -0.6137,  1.1619, -0.5960], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.5468,  0.8216, -0.5342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.5468,  0.8216, -0.5342], grad_fn=<TanhBackward0>),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5531,  0.9673, -1.1262], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5531,  0.9673, -1.1262], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2371,  0.7716, -0.4071, -2.1569], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2371,  0.7716, -0.4071, -2.1569], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6479, -0.3860, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6479, -0.3860, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8208, -0.9219, -1.6162,  0.3505], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8208, -0.9219, -1.6162,  0.3505], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6755, -0.7268, -0.9241,  0.3368], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6755, -0.7268, -0.9241,  0.3368], grad_fn=<TanhBackward0>),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6804,  0.8235, -1.8061, -0.9443], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6804,  0.8235, -1.8061, -0.9443], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1752, -1.0361, -0.8593, -1.0688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1752, -1.0361, -0.8593, -1.0688], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7343, -1.6902, -0.6930, -1.8783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7343, -1.6902, -0.6930, -1.8783], grad_fn=<ViewBackward0>),), Output: tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3066, -0.6128,  1.1619, -0.5968], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3066, -0.6128,  1.1619, -0.5968], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3005, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3005, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5022,  0.7481, -0.8099], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5022,  0.7481, -0.8099], grad_fn=<TanhBackward0>),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2373,  0.7701, -0.4058, -2.1571], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2373,  0.7701, -0.4058, -2.1571], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6470, -0.3849, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6470, -0.3849, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8218, -0.9220, -1.6145,  0.3518], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8218, -0.9220, -1.6145,  0.3518], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6760, -0.7268, -0.9238,  0.3379], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6760, -0.7268, -0.9238,  0.3379], grad_fn=<TanhBackward0>),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1754, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1754, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7762, -0.6961, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7762, -0.6961, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>),), Output: tensor([-0.6255, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6255, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3063, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3063, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2999, -1.3259, -2.8762, -4.2295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2999, -1.3259, -2.8762, -4.2295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2375,  0.7687, -0.4045, -2.1574], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2375,  0.7687, -0.4045, -2.1574], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6462, -0.3838, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6462, -0.3838, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8227, -0.9220, -1.6129,  0.3530], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8227, -0.9220, -1.6129,  0.3530], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6765, -0.7269, -0.9236,  0.3390], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6765, -0.7269, -0.9236,  0.3390], grad_fn=<TanhBackward0>),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6799,  0.8233, -1.8066, -0.9450], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6799,  0.8233, -1.8066, -0.9450], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6768, -0.9475, -0.7375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6768, -0.9475, -0.7375], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7761, -0.6964, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7761, -0.6964, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>),), Output: tensor([-0.6253, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6253, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3059, -0.6109,  1.1621, -0.5984], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3059, -0.6109,  1.1621, -0.5984], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8632, -0.5448,  0.8217, -0.5359], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8632, -0.5448,  0.8217, -0.5359], grad_fn=<TanhBackward0>),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2992, -1.3290, -2.8779, -4.2301], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2992, -1.3290, -2.8779, -4.2301], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2376,  0.7673, -0.4033, -2.1577], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2376,  0.7673, -0.4033, -2.1577], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6454, -0.3827, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6454, -0.3827, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8236, -0.9221, -1.6113,  0.3541], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8236, -0.9221, -1.6113,  0.3541], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6770, -0.7269, -0.9234,  0.3400], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6770, -0.7269, -0.9234,  0.3400], grad_fn=<TanhBackward0>),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6797,  0.8231, -1.8068, -0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6797,  0.8231, -1.8068, -0.9453], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1757, -1.0352, -0.8606, -1.0694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1757, -1.0352, -0.8606, -1.0694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7333, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7333, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>),), Output: tensor([-0.6251, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6251, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3055, -0.6100,  1.1622, -0.5991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3055, -0.6100,  1.1622, -0.5991], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2986, -1.3321, -2.8795, -4.2307], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2986, -1.3321, -2.8795, -4.2307], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5496,  0.9725, -1.1281], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5496,  0.9725, -1.1281], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2378,  0.7659, -0.4021, -2.1579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2378,  0.7659, -0.4021, -2.1579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6445, -0.3817, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6445, -0.3817, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8245, -0.9222, -1.6097,  0.3553], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8245, -0.9222, -1.6097,  0.3553], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6775, -0.7269, -0.9231,  0.3410], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6775, -0.7269, -0.9231,  0.3410], grad_fn=<TanhBackward0>),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1758, -1.0350, -0.8610, -1.0696], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1758, -1.0350, -0.8610, -1.0696], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>),), Output: tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3051, -0.6091,  1.1622, -0.5999], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3051, -0.6091,  1.1622, -0.5999], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.5435,  0.8218, -0.5370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.5435,  0.8218, -0.5370], grad_fn=<TanhBackward0>),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2980, -1.3352, -2.8811, -4.2312], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2980, -1.3352, -2.8811, -4.2312], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4996,  0.7504, -0.8105], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4996,  0.7504, -0.8105], grad_fn=<TanhBackward0>),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2380,  0.7645, -0.4009, -2.1582], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2380,  0.7645, -0.4009, -2.1582], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6437, -0.3807, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6437, -0.3807, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8253, -0.9222, -1.6082,  0.3564], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8253, -0.9222, -1.6082,  0.3564], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6780, -0.7269, -0.9229,  0.3420], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6780, -0.7269, -0.9229,  0.3420], grad_fn=<TanhBackward0>),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6793,  0.8228, -1.8073, -0.9459], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6793,  0.8228, -1.8073, -0.9459], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7326, -1.6983, -0.6971, -1.8797], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7326, -1.6983, -0.6971, -1.8797], grad_fn=<ViewBackward0>),), Output: tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2974, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2974, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8713, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8713, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5479,  0.9750, -1.1291], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5479,  0.9750, -1.1291], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2381,  0.7632, -0.3998, -2.1584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2381,  0.7632, -0.3998, -2.1584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6429, -0.3798, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6429, -0.3798, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8262, -0.9223, -1.6067,  0.3574], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8262, -0.9223, -1.6067,  0.3574], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1761, -1.0344, -0.8617, -1.0699], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761, -1.0344, -0.8617, -1.0699], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7757, -0.6971, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7757, -0.6971, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>),), Output: tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3044, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3044, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.5422,  0.8218, -0.5381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.5422,  0.8218, -0.5381], grad_fn=<TanhBackward0>),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2968, -1.3412, -2.8844, -4.2324], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2968, -1.3412, -2.8844, -4.2324], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2383,  0.7618, -0.3987, -2.1587], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2383,  0.7618, -0.3987, -2.1587], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6422, -0.3788, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6422, -0.3788, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8270, -0.9223, -1.6052,  0.3585], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8270, -0.9223, -1.6052,  0.3585], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1762, -1.0341, -0.8620, -1.0701], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1762, -1.0341, -0.8620, -1.0701], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7756, -0.6973, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7756, -0.6973, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7319, -1.7014, -0.6987, -1.8802], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7319, -1.7014, -0.6987, -1.8802], grad_fn=<ViewBackward0>),), Output: tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3040, -0.6063,  1.1624, -0.6023], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3040, -0.6063,  1.1624, -0.6023], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.5415,  0.8218, -0.5387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.5415,  0.8218, -0.5387], grad_fn=<TanhBackward0>),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2962, -1.3442, -2.8861, -4.2330], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2962, -1.3442, -2.8861, -4.2330], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2385,  0.7605, -0.3976, -2.1589], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2385,  0.7605, -0.3976, -2.1589], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6414, -0.3779, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6414, -0.3779, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8277, -0.9223, -1.6038,  0.3595], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8277, -0.9223, -1.6038,  0.3595], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6793, -0.7270, -0.9222,  0.3448], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6793, -0.7270, -0.9222,  0.3448], grad_fn=<TanhBackward0>),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6787,  0.8223, -1.8080, -0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6787,  0.8223, -1.8080, -0.9468], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6763, -0.9476, -0.7384], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6763, -0.9476, -0.7384], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7316, -1.7029, -0.6995, -1.8805], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7316, -1.7029, -0.6995, -1.8805], grad_fn=<ViewBackward0>),), Output: tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2956, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2956, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4971,  0.7525, -0.8112], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4971,  0.7525, -0.8112], grad_fn=<TanhBackward0>),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2386,  0.7592, -0.3966, -2.1592], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2386,  0.7592, -0.3966, -2.1592], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6406, -0.3770, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6406, -0.3770, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8285, -0.9224, -1.6024,  0.3605], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8285, -0.9224, -1.6024,  0.3605], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6797, -0.7270, -0.9220,  0.3456], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6797, -0.7270, -0.9220,  0.3456], grad_fn=<TanhBackward0>),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6762, -0.9477, -0.7385], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6762, -0.9477, -0.7385], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1764, -1.0335, -0.8626, -1.0705], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1764, -1.0335, -0.8626, -1.0705], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>),), Output: tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3032, -0.6046,  1.1625, -0.6038], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3032, -0.6046,  1.1625, -0.6038], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8625, -0.5403,  0.8218, -0.5398], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8625, -0.5403,  0.8218, -0.5398], grad_fn=<TanhBackward0>),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2950, -1.3500, -2.8893, -4.2341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2950, -1.3500, -2.8893, -4.2341], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4965,  0.7531, -0.8114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4965,  0.7531, -0.8114], grad_fn=<TanhBackward0>),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2388,  0.7580, -0.3956, -2.1594], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2388,  0.7580, -0.3956, -2.1594], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6399, -0.3762, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6399, -0.3762, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8292, -0.9224, -1.6010,  0.3614], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8292, -0.9224, -1.6010,  0.3614], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6801, -0.7270, -0.9218,  0.3464], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6801, -0.7270, -0.9218,  0.3464], grad_fn=<TanhBackward0>),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1766, -1.0333, -0.8629, -1.0707], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1766, -1.0333, -0.8629, -1.0707], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7752, -0.6977, -0.7897], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7752, -0.6977, -0.7897], grad_fn=<TanhBackward0>),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7309, -1.7059, -0.7012, -1.8810], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7309, -1.7059, -0.7012, -1.8810], grad_fn=<ViewBackward0>),), Output: tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3028, -0.6037,  1.1625, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3028, -0.6037,  1.1625, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.5397,  0.8219, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.5397,  0.8219, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2944, -1.3529, -2.8909, -4.2346], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2944, -1.3529, -2.8909, -4.2346], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5438,  0.9812, -1.1315], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5438,  0.9812, -1.1315], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2390,  0.7567, -0.3946, -2.1596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2390,  0.7567, -0.3946, -2.1596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6391, -0.3754, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6391, -0.3754, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8300, -0.9224, -1.5996,  0.3623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8300, -0.9224, -1.5996,  0.3623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6805, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6805, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6781,  0.8218, -1.8088, -0.9477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6781,  0.8218, -1.8088, -0.9477], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1767, -1.0330, -0.8631, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1767, -1.0330, -0.8631, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9714], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9714], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9714], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7306, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7306, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>),), Output: tensor([-0.6234, -0.9363, -0.6056, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6234, -0.9363, -0.6056, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2391,  0.7555, -0.3937, -2.1599], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2391,  0.7555, -0.3937, -2.1599], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6384, -0.3745, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6384, -0.3745, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8306, -0.9224, -1.5983,  0.3632], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8306, -0.9224, -1.5983,  0.3632], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6808, -0.7270, -0.9214,  0.3480], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6808, -0.7270, -0.9214,  0.3480], grad_fn=<TanhBackward0>),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6780,  0.8216, -1.8090, -0.9480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6780,  0.8216, -1.8090, -0.9480], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6760, -0.9477, -0.7389], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6760, -0.9477, -0.7389], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1768, -1.0327, -0.8634, -1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1768, -1.0327, -0.8634, -1.0710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7303, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7303, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3021, -0.6019,  1.1626, -0.6062], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3021, -0.6019,  1.1626, -0.6062], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8623, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8623, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Run model training for multiple epochs with PyTorch model\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "loss_rmse_list = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_preds = [tmlp(torch.tensor(i)) for i in x]\n",
    "    y_true = [torch.tensor([y_i.data]) for y_i in y_true]\n",
    "    loss_rmse = rmse(y_true, y_preds)  # Calculate loss\n",
    "    loss_rmse_list.append(loss_rmse.item())\n",
    "    loss_rmse.backward()  # Perform backpropagation\n",
    "    optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1820,
   "id": "3c92ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds_tmlp = [0.9358289241790771, -1.0214004516601562, -0.9719018936157227, 1.059492588043213]\n",
      "y_true = [tensor([1.]), tensor([-1.]), tensor([-1.]), tensor([1.])]\n"
     ]
    }
   ],
   "source": [
    "# Print prediction using PyTorch model\n",
    "print(f\"y_preds_tmlp = {[item.item() for item in y_preds]}\")\n",
    "print(f\"y_true = {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "id": "a83fc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_rmse_list = [1.498351812362671, 0.9614522457122803, 0.7609688639640808, 0.655349612236023, 0.5761975646018982, 0.501936674118042, 0.4307599663734436, 0.367279976606369, 0.31345903873443604, 0.26842188835144043, 0.23068277537822723, 0.1989007443189621, 0.1719910055398941, 0.14910173416137695, 0.12956500053405762, 0.11285087466239929, 0.0985308513045311, 0.08625147491693497, 0.0757165253162384, 0.06667446345090866, 0.05891042947769165, 0.05223962664604187, 0.04650302976369858, 0.04156395420432091, 0.03730503097176552, 0.03362554311752319, 0.030439501628279686, 0.02767348289489746, 0.025265028700232506, 0.0231611430644989, 0.021316811442375183, 0.019693993031978607, 0.018260536715388298, 0.016989244148135185, 0.015857156366109848, 0.014844922348856926, 0.013936166651546955, 0.013117010705173016, 0.012375819496810436, 0.011702601797878742, 0.011088969185948372, 0.01052772719413042, 0.010012799873948097, 0.009538893587887287, 0.009101547300815582, 0.00869688205420971, 0.008321563713252544, 0.007972671650350094, 0.007647679187357426, 0.007344385609030724, 0.007060816511511803, 0.006795275490731001, 0.006546230521053076, 0.006312322802841663, 0.006092341151088476, 0.005885200574994087, 0.00568993529304862, 0.0055056409910321236, 0.005331522785127163, 0.0051668500527739525, 0.0050109680742025375, 0.004863264970481396, 0.004723159596323967, 0.00459018861874938, 0.0044638412073254585, 0.00434370432049036, 0.004229375626891851, 0.004120480269193649, 0.004016675986349583, 0.003917653113603592, 0.0038231173530220985, 0.0037327874451875687, 0.0036464272998273373, 0.003563774051144719, 0.003484630025923252, 0.0034087826497852802, 0.0033360389061272144, 0.0032662374433130026, 0.0031991833820939064, 0.0031347484327852726, 0.00307278661057353, 0.0030131349340081215, 0.0029557019006460905, 0.0029003508388996124, 0.0028469834942370653, 0.002795466687530279, 0.0027457408141344786, 0.0026976950466632843, 0.00265124486759305, 0.002606324851512909, 0.0025628400035202503, 0.0025207330472767353, 0.002479939954355359, 0.0024403859861195087, 0.002402015496045351, 0.0023647777270525694, 0.00232863612473011, 0.0022935112938284874, 0.0022593820467591286, 0.002226194366812706]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "print(f\"loss_rmse_list = {loss_rmse_list}\")\n",
    "plt.plot(range(epochs), loss_rmse_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ec98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
