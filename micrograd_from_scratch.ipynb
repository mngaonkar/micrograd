{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "7b5e86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "from IPython import display\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "d5629e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "84ab2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for Jupyter Notebook to find the graphviz executables\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\"/opt/homebrew/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "4eba97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for gradient calculation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "3fbd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-10, 10, 0.5)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "08cde3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "71c90bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = -2\n",
    "c = 1\n",
    "d1 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "id": "4e7752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c + h\n",
    "d2 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "id": "c7b273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dc_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dc_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "id": "68d78e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -5.000002\n",
      "da_dy =  -2.000000000279556\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "a = a + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"da_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "id": "49ed6158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.9999970000000005\n",
      "db_dy =  2.9999999995311555\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "b = b + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"db_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "c4f10ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dab_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "d2 = a*b + h + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dab_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "id": "e5c68b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    \"\"\" Basic class to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "        else:\n",
    "            raise ValueError(\"Can only add Value to Value\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "id": "077e5615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d._prev = (Value(data=-6), Value(data=1)) d = -5\n"
     ]
    }
   ],
   "source": [
    "a = Value(3, label=\"a\")\n",
    "b = Value(-2, label=\"b\")\n",
    "c = Value(1, label=\"c\")\n",
    "d = a*b + c; d.label = \"d\"\n",
    "print(f\"d._prev = {d._prev} d = {d.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "db81115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(root):\n",
    "    \"\"\" Vibe codded and it works! \"\"\"\n",
    "    # Initialize a directed graph\n",
    "    dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})  # Left-to-right layout\n",
    "    \n",
    "    def build_graph(node, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        \n",
    "        # Skip if node already visited to avoid cycles\n",
    "        if id(node) in visited:\n",
    "            return\n",
    "        visited.add(id(node))\n",
    "        \n",
    "        # Add node to the graph\n",
    "        node_id = str(id(node))\n",
    "        dot.node(node_id, f\"{{ {node.label} | data = {node.data} grad={node.grad} }}\", shape='record')\n",
    "        \n",
    "        # If node has an operation, create an operation node\n",
    "        if node._op:\n",
    "            op_id = f\"{node_id}_op\"\n",
    "            dot.node(op_id, node._op, shape='circle')\n",
    "            dot.edge(op_id, node_id)  # Edge from operation to result\n",
    "        \n",
    "            # Recursively process children\n",
    "            for child in node._prev:\n",
    "                child_id = str(id(child))\n",
    "                build_graph(child, visited)\n",
    "                dot.edge(child_id, op_id)  # Edge from child to operation\n",
    "    \n",
    "    # Build the graph starting from the root\n",
    "    build_graph(root)\n",
    "    \n",
    "    # Render and display the graph\n",
    "    dot.render('computation_graph', view=True, cleanup=True)\n",
    "    \n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "84c181f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "id": "98dd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "id": "68ed37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142981514304\n"
     ]
    }
   ],
   "source": [
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "ec8210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "id": "70612029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "daba22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "922f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_dn = 1 - math.tanh(o.data)**2\n",
    "y.grad = do_dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "72a71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "2a71919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1_x2w2.grad = y.grad\n",
    "b.grad = y.grad\n",
    "x1w1.grad = x1w1_x2w2.grad\n",
    "x2w2.grad = x1w1_x2w2.grad\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "ef9473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = x1w1.grad * w1.data\n",
    "x2.grad = x2w2.grad * w2.data\n",
    "w1.grad = x1w1.grad * x1.data\n",
    "w2.grad = x2w2.grad * x2.data\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1300,
   "id": "d7edad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement generic backpropagation\n",
    "class Value():\n",
    "    \"\"\" Complete class with backprop to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "\n",
    "    def backward(self, root_node, visited=None):\n",
    "        visited.add(self)\n",
    "        logger.debug(f\"node.data = {self.data}\")\n",
    "        self._backward()  # Compute the gradient for childeren of this node\n",
    "        for item in self._prev:\n",
    "            if item not in visited:\n",
    "                item.backward(root_node, visited)\n",
    "\n",
    "    def _backward(self):\n",
    "        \"\"\" Perform backpropagation to compute gradients. \"\"\"\n",
    "        logger.debug(f\"Backward pass for node: {self.label}, op: {self._op}, data: {self.data}, grad: {self.grad}\")\n",
    "        # For addition operation, local gradient is 1 for each child hence gradient of the child with respect\n",
    "        # to the output is 1 * self gradient.\n",
    "        # Note, we need to accumulate gradients for each child and not simply overwrite them.\n",
    "        if self._op == '+':\n",
    "            for child in self._prev:\n",
    "                child.grad += self.grad\n",
    "\n",
    "        # For multiplication operation, local gradient is the value of the other child hence\n",
    "        # gradient of the child with respect to the output is self.grad * other child's value.\n",
    "        elif self._op == '*':\n",
    "            self._prev[0].grad = self.grad * self._prev[1].data\n",
    "            self._prev[1].grad = self.grad * self._prev[0].data\n",
    "\n",
    "        elif self._op == '/':\n",
    "            # For division operation, local gradient is 1 / other child's value hence\n",
    "            # gradient of the child with respect to the output is self.grad * (1 / other child's value).\n",
    "            self._prev[0].grad = self.grad / self._prev[1].data\n",
    "            self._prev[1].grad = -self.grad * (self._prev[0].data / (self._prev[1].data ** 2))\n",
    "\n",
    "        # For power operation, local gradient is power * base^(power-1) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == '**':\n",
    "            power = self._prev[0].data\n",
    "            base = self.data\n",
    "            self._prev[0].grad = self.grad * power * (base ** (power - 1))\n",
    "\n",
    "        # For subtraction operation, local gradient is 1 for the first child and -1 for the second child\n",
    "        # hence gradient of the first child with respect to the output is self.grad * 1 and for the second child\n",
    "        # it is self.grad * -1.\n",
    "        elif self._op == '-':\n",
    "            self._prev[0].grad = self.grad  # First child\n",
    "            self._prev[1].grad = -self.grad  # Second child\n",
    "\n",
    "        # For tanh operation, local gradient is 1 - tanh^2(self.data) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == 'tanh':\n",
    "            logger.debug(f\"tanh: self.data = {self.data}, self.grad = {self.grad}\")\n",
    "            self._prev[0].grad = self.grad * (1 - np.tanh(self._prev[0].data)**2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data - other.data, _children=(self, other), _op='-')\n",
    "        else:\n",
    "            raise ValueError(\"Can only subtract Value from Value\")\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "        \n",
    "    def __pow__(self, power):\n",
    "        return Value(self.data ** power, _children=(self,), _op='**')\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "id": "de7dc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1302,
   "id": "b1415a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(19855) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(19856) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(19857) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1412pt\" height=\"210pt\"\n",
       " viewBox=\"0.00 0.00 1411.82 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-206 1407.82,-206 1407.82,4 -4,4\"/>\n",
       "<!-- 5757488352 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5757488352</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1150.57,-54.5 1150.57,-90.5 1403.82,-90.5 1403.82,-54.5 1150.57,-54.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1161.94\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">o</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1173.32,-55 1173.32,-90.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1288.57\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9866142981514304 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5757488352_op -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5757488352_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1087.78\" cy=\"-72.5\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text text-anchor=\"middle\" x=\"1087.78\" y=\"-67.45\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 5757488352_op&#45;&gt;5757488352 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5757488352_op&#45;&gt;5757488352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1114.84,-72.5C1121.99,-72.5 1130.27,-72.5 1139.22,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1138.93,-76 1148.93,-72.5 1138.93,-69 1138.93,-76\"/>\n",
       "</g>\n",
       "<!-- 5757485232 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5757485232</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"873,-54.5 873,-90.5 1025,-90.5 1025,-54.5 873,-54.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"884.37\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"895.75,-55 895.75,-90.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"960.37\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.5 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5757485232&#45;&gt;5757488352_op -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>5757485232&#45;&gt;5757488352_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1025.19,-72.5C1033.59,-72.5 1041.84,-72.5 1049.45,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1049.27,-76 1059.27,-72.5 1049.27,-69 1049.27,-76\"/>\n",
       "</g>\n",
       "<!-- 5757485232_op -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5757485232_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"819\" cy=\"-72.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"819\" y=\"-67.45\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 5757485232_op&#45;&gt;5757485232 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5757485232_op&#45;&gt;5757485232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M837.26,-72.5C844.05,-72.5 852.39,-72.5 861.41,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"861.19,-76 871.19,-72.5 861.19,-69 861.19,-76\"/>\n",
       "</g>\n",
       "<!-- 5756841440 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5756841440</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"553,-82.5 553,-118.5 765,-118.5 765,-82.5 553,-82.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"594.37\" y=\"-95.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1w1_x2w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"635.75,-83 635.75,-118.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"700.37\" y=\"-95.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;3.5 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5756841440&#45;&gt;5757485232_op -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5756841440&#45;&gt;5757485232_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M764.07,-82.06C773.47,-80.39 782.35,-78.82 790.08,-77.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"790.47,-80.93 799.71,-75.74 789.25,-74.04 790.47,-80.93\"/>\n",
       "</g>\n",
       "<!-- 5756841440_op -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5756841440_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"499\" cy=\"-100.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"499\" y=\"-95.45\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 5756841440_op&#45;&gt;5756841440 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5756841440_op&#45;&gt;5756841440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M517.21,-100.5C523.86,-100.5 532.07,-100.5 541.15,-100.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"541.1,-104 551.1,-100.5 541.1,-97 541.1,-104\"/>\n",
       "</g>\n",
       "<!-- 5756162016 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5756162016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"272,-110.5 272,-146.5 442.75,-146.5 442.75,-110.5 272,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"295\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"318,-111 318,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"380.38\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1.0 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5756162016&#45;&gt;5756841440_op -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5756162016&#45;&gt;5756841440_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M443.22,-111.49C452.77,-109.57 461.93,-107.73 469.94,-106.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"470.5,-109.58 479.62,-104.19 469.12,-102.72 470.5,-109.58\"/>\n",
       "</g>\n",
       "<!-- 5756162016_op -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5756162016_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"215.75\" cy=\"-128.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.75\" y=\"-123.45\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 5756162016_op&#45;&gt;5756162016 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5756162016_op&#45;&gt;5756162016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.15,-128.5C241.37,-128.5 250.36,-128.5 260.16,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"260.01,-132 270.01,-128.5 260.01,-125 260.01,-132\"/>\n",
       "</g>\n",
       "<!-- 5749838080 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5749838080</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"9,-165.5 9,-201.5 152.75,-201.5 152.75,-165.5 9,-165.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"23.75\" y=\"-178.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"38.5,-166 38.5,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"95.62\" y=\"-178.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 2 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5749838080&#45;&gt;5756162016_op -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5749838080&#45;&gt;5756162016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.88,-165.12C147.31,-162.41 154.76,-159.51 161.75,-156.5 171.13,-152.47 181.1,-147.41 189.84,-142.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191.36,-145.87 198.43,-137.98 187.99,-139.74 191.36,-145.87\"/>\n",
       "</g>\n",
       "<!-- 5749837216 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5749837216</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2.25,-110.5 2.25,-146.5 159.5,-146.5 159.5,-110.5 2.25,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"18.5\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"34.75,-111 34.75,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.12\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.5 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5749837216&#45;&gt;5756162016_op -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5749837216&#45;&gt;5756162016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.94,-128.5C169.28,-128.5 178.31,-128.5 186.24,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"186.2,-132 196.2,-128.5 186.2,-125 186.2,-132\"/>\n",
       "</g>\n",
       "<!-- 5753346464 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>5753346464</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"269.75,-55.5 269.75,-91.5 445,-91.5 445,-55.5 269.75,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.75\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">x2w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"315.75,-56 315.75,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"380.38\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;4.5 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5753346464&#45;&gt;5756841440_op -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5753346464&#45;&gt;5756841440_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M445.21,-90.29C453.99,-91.99 462.38,-93.61 469.79,-95.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"468.91,-98.44 479.39,-96.9 470.24,-91.57 468.91,-98.44\"/>\n",
       "</g>\n",
       "<!-- 5753346464_op -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>5753346464_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"215.75\" cy=\"-73.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.75\" y=\"-68.45\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 5753346464_op&#45;&gt;5753346464 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5753346464_op&#45;&gt;5753346464</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.15,-73.5C240.86,-73.5 249.08,-73.5 258.06,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"257.84,-77 267.84,-73.5 257.84,-70 257.84,-77\"/>\n",
       "</g>\n",
       "<!-- 5749841824 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>5749841824</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"9,-55.5 9,-91.5 152.75,-91.5 152.75,-55.5 9,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"23.75\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"38.5,-56 38.5,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"95.62\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 3 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5749841824&#45;&gt;5753346464_op -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5749841824&#45;&gt;5753346464_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152.98,-73.5C164.61,-73.5 176.04,-73.5 185.85,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185.79,-77 195.79,-73.5 185.79,-70 185.79,-77\"/>\n",
       "</g>\n",
       "<!-- 5749836016 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>5749836016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-36.5 161.75,-36.5 161.75,-0.5 0,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"16.25\" y=\"-13.7\" font-family=\"Times,serif\" font-size=\"14.00\">w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"32.5,-1 32.5,-36.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.12\" y=\"-13.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.5 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5749836016&#45;&gt;5753346464_op -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5749836016&#45;&gt;5753346464_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.88,-36.88C147.31,-39.59 154.76,-42.49 161.75,-45.5 171.13,-49.53 181.1,-54.59 189.84,-59.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"187.99,-62.26 198.43,-64.02 191.36,-56.13 187.99,-62.26\"/>\n",
       "</g>\n",
       "<!-- 5749845376 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>5749845376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"590.5,-27.5 590.5,-63.5 727.5,-63.5 727.5,-27.5 590.5,-27.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"601.87\" y=\"-40.7\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"613.25,-28 613.25,-63.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"670.37\" y=\"-40.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 5749845376&#45;&gt;5757485232_op -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>5749845376&#45;&gt;5757485232_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M727.92,-57.11C749.56,-60.81 772.34,-64.7 789.57,-67.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"788.85,-71.07 799.3,-69.3 790.03,-64.17 788.85,-71.07\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1573c1a90>"
      ]
     },
     "execution_count": 1302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1303,
   "id": "65eb5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0\n",
    "\n",
    "visited = set()\n",
    "o.backward(o, visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "id": "b9b0f81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(19903) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(19904) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(19905) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1864pt\" height=\"210pt\"\n",
       " viewBox=\"0.00 0.00 1864.07 210.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 206)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-206 1860.07,-206 1860.07,4 -4,4\"/>\n",
       "<!-- 5757488352 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5757488352</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1602.82,-54.5 1602.82,-90.5 1856.07,-90.5 1856.07,-54.5 1602.82,-54.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1614.19\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">o</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1625.57,-55 1625.57,-90.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1740.82\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9866142981514304 grad=1.0</text>\n",
       "</g>\n",
       "<!-- 5757488352_op -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5757488352_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1540.03\" cy=\"-72.5\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text text-anchor=\"middle\" x=\"1540.03\" y=\"-67.45\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 5757488352_op&#45;&gt;5757488352 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5757488352_op&#45;&gt;5757488352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1567.09,-72.5C1574.24,-72.5 1582.52,-72.5 1591.47,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1591.18,-76 1601.18,-72.5 1591.18,-69 1591.18,-76\"/>\n",
       "</g>\n",
       "<!-- 5757485232 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5757485232</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1210.5,-54.5 1210.5,-90.5 1477.25,-90.5 1477.25,-54.5 1210.5,-54.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1221.88\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">y</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1233.25,-55 1233.25,-90.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1355.25\" y=\"-67.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.5 grad=0.026592226683160525</text>\n",
       "</g>\n",
       "<!-- 5757485232&#45;&gt;5757488352_op -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>5757485232&#45;&gt;5757488352_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1477.6,-72.5C1486.16,-72.5 1494.29,-72.5 1501.67,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1501.44,-76 1511.44,-72.5 1501.44,-69 1501.44,-76\"/>\n",
       "</g>\n",
       "<!-- 5757485232_op -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5757485232_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1156.5\" cy=\"-72.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-67.45\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 5757485232_op&#45;&gt;5757485232 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5757485232_op&#45;&gt;5757485232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1174.94,-72.5C1181.61,-72.5 1189.87,-72.5 1199.1,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1198.85,-76 1208.85,-72.5 1198.85,-69 1198.85,-76\"/>\n",
       "</g>\n",
       "<!-- 5756841440 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5756841440</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"775.75,-82.5 775.75,-118.5 1102.5,-118.5 1102.5,-82.5 775.75,-82.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"817.12\" y=\"-95.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1w1_x2w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"858.5,-83 858.5,-118.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"980.5\" y=\"-95.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;3.5 grad=0.026592226683160525</text>\n",
       "</g>\n",
       "<!-- 5756841440&#45;&gt;5757485232_op -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5756841440&#45;&gt;5757485232_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1082.28,-82.02C1099.12,-79.83 1114.7,-77.8 1127.12,-76.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1127.45,-79.68 1136.92,-74.92 1126.55,-72.73 1127.45,-79.68\"/>\n",
       "</g>\n",
       "<!-- 5756841440_op -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5756841440_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"721.75\" cy=\"-100.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"721.75\" y=\"-95.45\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 5756841440_op&#45;&gt;5756841440 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5756841440_op&#45;&gt;5756841440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M740.01,-100.5C746.61,-100.5 754.81,-100.5 764.09,-100.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"763.93,-104 773.93,-100.5 763.93,-97 763.93,-104\"/>\n",
       "</g>\n",
       "<!-- 5756162016 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5756162016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"380,-110.5 380,-146.5 665.5,-146.5 665.5,-110.5 380,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"403\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"426,-111 426,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"545.75\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1.0 grad=0.026592226683160525</text>\n",
       "</g>\n",
       "<!-- 5756162016&#45;&gt;5756841440_op -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5756162016&#45;&gt;5756841440_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M653.78,-110.02C668.07,-107.99 681.38,-106.1 692.3,-104.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"692.64,-108.03 702.04,-103.16 691.65,-101.1 692.64,-108.03\"/>\n",
       "</g>\n",
       "<!-- 5756162016_op -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5756162016_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"323.75\" cy=\"-128.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"323.75\" y=\"-123.45\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 5756162016_op&#45;&gt;5756162016 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5756162016_op&#45;&gt;5756162016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M342.23,-128.5C349.36,-128.5 358.29,-128.5 368.35,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"368.16,-132 378.16,-128.5 368.16,-125 368.16,-132\"/>\n",
       "</g>\n",
       "<!-- 5749838080 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5749838080</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5.62,-165.5 5.62,-201.5 264.12,-201.5 264.12,-165.5 5.62,-165.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"20.38\" y=\"-178.7\" font-family=\"Times,serif\" font-size=\"14.00\">x1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"35.12,-166 35.12,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.62\" y=\"-178.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 2 grad=0.013296113341580262</text>\n",
       "</g>\n",
       "<!-- 5749838080&#45;&gt;5756162016_op -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5749838080&#45;&gt;5756162016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.89,-165.07C251.41,-162.53 260.82,-159.69 269.75,-156.5 279.37,-153.07 289.4,-148.16 298.11,-143.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"299.7,-146.53 306.66,-138.54 296.23,-140.44 299.7,-146.53\"/>\n",
       "</g>\n",
       "<!-- 5749837216 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5749837216</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2.25,-110.5 2.25,-146.5 267.5,-146.5 267.5,-110.5 2.25,-110.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"18.5\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"34.75,-111 34.75,-146.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.12\" y=\"-123.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.5 grad=0.05318445336632105</text>\n",
       "</g>\n",
       "<!-- 5749837216&#45;&gt;5756162016_op -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5749837216&#45;&gt;5756162016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M267.94,-128.5C277.46,-128.5 286.33,-128.5 294.04,-128.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"293.97,-132 303.97,-128.5 293.97,-125 293.97,-132\"/>\n",
       "</g>\n",
       "<!-- 5753346464 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>5753346464</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"377.75,-55.5 377.75,-91.5 667.75,-91.5 667.75,-55.5 377.75,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"400.75\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">x2w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"423.75,-56 423.75,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"545.75\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;4.5 grad=0.026592226683160525</text>\n",
       "</g>\n",
       "<!-- 5753346464&#45;&gt;5756841440_op -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5753346464&#45;&gt;5756841440_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M658.69,-91.99C671.1,-93.7 682.62,-95.27 692.27,-96.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"691.56,-100.03 701.94,-97.92 692.51,-93.1 691.56,-100.03\"/>\n",
       "</g>\n",
       "<!-- 5753346464_op -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>5753346464_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"323.75\" cy=\"-73.5\" rx=\"18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"323.75\" y=\"-68.45\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 5753346464_op&#45;&gt;5753346464 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5753346464_op&#45;&gt;5753346464</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M342.23,-73.5C348.87,-73.5 357.07,-73.5 366.29,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"366.03,-77 376.03,-73.5 366.03,-70 366.03,-77\"/>\n",
       "</g>\n",
       "<!-- 5749841824 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>5749841824</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.75,-55.5 6.75,-91.5 263,-91.5 263,-55.5 6.75,-55.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"21.5\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">x2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"36.25,-56 36.25,-91.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.62\" y=\"-68.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 3 grad=&#45;0.03988834002474079</text>\n",
       "</g>\n",
       "<!-- 5749841824&#45;&gt;5753346464_op -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5749841824&#45;&gt;5753346464_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M263.36,-73.5C274.57,-73.5 285.02,-73.5 293.93,-73.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"293.91,-77 303.91,-73.5 293.91,-70 293.91,-77\"/>\n",
       "</g>\n",
       "<!-- 5749836016 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>5749836016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-36.5 269.75,-36.5 269.75,-0.5 0,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"16.25\" y=\"-13.7\" font-family=\"Times,serif\" font-size=\"14.00\">w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"32.5,-1 32.5,-36.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.12\" y=\"-13.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.5 grad=0.07977668004948157</text>\n",
       "</g>\n",
       "<!-- 5749836016&#45;&gt;5753346464_op -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5749836016&#45;&gt;5753346464_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M241.89,-36.93C251.41,-39.47 260.82,-42.31 269.75,-45.5 279.37,-48.93 289.4,-53.84 298.11,-58.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"296.23,-61.56 306.66,-63.46 299.7,-55.47 296.23,-61.56\"/>\n",
       "</g>\n",
       "<!-- 5749845376 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>5749845376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"813.25,-27.5 813.25,-63.5 1065,-63.5 1065,-27.5 813.25,-27.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"824.62\" y=\"-40.7\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"836,-28 836,-63.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"950.5\" y=\"-40.7\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1 grad=0.026592226683160525</text>\n",
       "</g>\n",
       "<!-- 5749845376&#45;&gt;5757485232_op -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>5749845376&#45;&gt;5757485232_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1065.41,-61.21C1088.64,-64.12 1110.75,-66.89 1127.26,-68.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1126.36,-72.37 1136.71,-70.14 1127.23,-65.43 1126.36,-72.37\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1573c06b0>"
      ]
     },
     "execution_count": 1304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "id": "160da944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142868995667\n"
     ]
    }
   ],
   "source": [
    "# Verfiy with PyTorch\n",
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2.0])\n",
    "x2 = torch.Tensor([3.0])\n",
    "w1 = torch.Tensor([0.5])\n",
    "w2 = torch.Tensor([-1.5])\n",
    "b = torch.Tensor([1.0])\n",
    "x1.requires_grad = True\n",
    "x2.requires_grad = True\n",
    "w1.requires_grad = True\n",
    "w2.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "y = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(y)\n",
    "\n",
    "print(f\"o = {o.item()}\")\n",
    "\n",
    "o.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "id": "182b150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.grad = 0.013296124525368214\n",
      "x2.grad = -0.039888374507427216\n",
      "w1.grad = 0.053184498101472855\n",
      "w2.grad = 0.07977674901485443\n",
      "b.grad = 0.026592249050736427\n"
     ]
    }
   ],
   "source": [
    "print(f\"x1.grad = {x1.grad.item()}\") \n",
    "print(f\"x2.grad = {x2.grad.item()}\") \n",
    "print(f\"w1.grad = {w1.grad.item()}\")\n",
    "print(f\"w2.grad = {w2.grad.item()}\")\n",
    "print(f\"b.grad = {b.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "id": "f1702ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "class N():\n",
    "    \"\"\" Class to represent a single neuron with forward and backward pass. \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "        self.weights = [Value(random.uniform(-1, 1)) for _ in range(input_size)]\n",
    "        self.b = Value(random.uniform(-1, 1))  # Bias term\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.b]  # Return all parameters (weights and bias)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None) -> Value:\n",
    "        \"\"\" Forward pass for the neuron. \"\"\"\n",
    "        assert len(input) == self.input_size, f\"Input size {len(input)} does not match expected size {self.input_size}\"\n",
    "        wx = [w*x for w, x in zip(self.weights, input)]\n",
    "        wx_sum = Value(0.0)  # Initialize sum of weighted inputs\n",
    "        for item in wx:\n",
    "            wx_sum += item  # Sum the weighted inputs\n",
    "\n",
    "        wx_sum = wx_sum + self.b\n",
    "        if act_fn is None:\n",
    "            return wx_sum\n",
    "        elif act_fn == 'tanh':\n",
    "            return wx_sum.tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {act_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1515,
   "id": "95f55a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -2.742169638094225\n"
     ]
    }
   ],
   "source": [
    "n = N(2)  # Create a neuron with 2 inputs\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "\n",
    "o = n([x1, x2])\n",
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "id": "f5d28c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\" Class to represent a layer of neurons. \"\"\"\n",
    "    def __init__(self, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.neurons = [N(input) for _ in range(output)]\n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for n in self.neurons:\n",
    "            parameters.extend(n.parameters())  # Collect parameters from each neuron\n",
    "        return parameters\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None):\n",
    "        \"\"\" Forward pass for the layer. \"\"\"\n",
    "        outputs = [n(input, act_fn) for n in self.neurons]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1599,
   "id": "29894ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class NN():\n",
    "    \"\"\" Class to represent a simple neural network with hidden layers. \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                 hidden_layer_num: int, \n",
    "                 hidden_layer_size: int, \n",
    "                 output_size: int):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_num = hidden_layer_num\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.forward_hook = None  # Hook for forward pass\n",
    "\n",
    "        self.layers = []\n",
    "        for i in range(hidden_layer_num):\n",
    "            if i == 0:\n",
    "                # First layer takes the input size\n",
    "                self.layers.append(Layer(input_size, hidden_layer_size))\n",
    "            elif i == hidden_layer_num - 1:\n",
    "                # Last layer is the output layer, use output_size\n",
    "                self.layers.append(Layer(hidden_layer_size, output_size))\n",
    "            else:\n",
    "                # Intermediate layers use hidden_layer_size\n",
    "                self.layers.append(Layer(hidden_layer_size, hidden_layer_size))\n",
    "           \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for layer in self.layers:\n",
    "            parameters.extend(layer.parameters())  # Collect parameters from each layer\n",
    "        return parameters\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def register_forward_hook(self, func: Callable[[str, list[Value], list[Value]], None]): \n",
    "        self.forward_hook = func\n",
    "\n",
    "    def __call__(self, input):\n",
    "        \"\"\" Forward pass for the neural network. \"\"\"\n",
    "        assert len(input) == self.input_size, \"input size mismatch\"\n",
    "\n",
    "        x = [Value(i) for i in input]\n",
    "        for num, layer in enumerate(self.layers):\n",
    "            if num != len(self.layers) - 1:\n",
    "                act_fn = 'tanh'\n",
    "            else:\n",
    "                act_fn = None\n",
    "            input = x.copy()\n",
    "            x = layer(x, act_fn)  # Forward pass through the layer\n",
    "            self.forward_hook(f\"Layer {num}\", [i.data for i in input], [o.data for o in x]) if self.forward_hook else None\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "id": "7e307dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # For reproducibility\n",
    "mlp = NN(input_size=3, hidden_layer_num=3, hidden_layer_size=4, output_size=1)  # Create a neural network with 2 inputs, 2 hidden layers of size 3, and 1 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "id": "b87ae772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model information:\n",
      "input size: 3\n",
      "total model layers: 3\n",
      "[0] layer input: 3, layer output: 4, neurons: 4\n",
      "[1] layer input: 4, layer output: 4, neurons: 4\n",
      "[2] layer input: 4, layer output: 1, neurons: 1\n",
      "total model parameters: 41\n",
      "model parameters:\n",
      "[tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]), tensor([-0.5536, -0.8261,  0.0107,  0.0899]), tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]), tensor([ 0.6116, -0.3268,  0.6143,  0.1041]), tensor([[0.6588, 0.2370, 0.7234, 0.1547]]), tensor([0.4091])]\n"
     ]
    }
   ],
   "source": [
    "print(\"model information:\")\n",
    "print(f\"input size: {mlp.input_size}\")\n",
    "print(f\"total model layers: {len(mlp.layers)}\")\n",
    "for i, layer in enumerate(mlp.layers):\n",
    "    print(f\"[{i}] layer input: {layer.input}, layer output: {layer.output}, neurons: {len(layer.neurons)}\")\n",
    "print(f\"total model parameters: {len(mlp.parameters())}\")\n",
    "\n",
    "# Build tensor parameters for the model, this will be used to set the parameters in PyTorch\n",
    "mlp_tensor_parameters = []\n",
    "print(\"model parameters:\")\n",
    "for layer_num, layer in enumerate(mlp.layers):\n",
    "    layer_params = []\n",
    "    bias_params = []\n",
    "    for neuron_num, neuron in enumerate(layer.neurons):\n",
    "        layer_params.append([x.data for x in neuron.parameters()][:-1])\n",
    "        bias_params.append([x.data for x in neuron.parameters()][-1])\n",
    "    mlp_tensor_parameters.append(torch.tensor(layer_params))\n",
    "    mlp_tensor_parameters.append(torch.tensor(bias_params))\n",
    "    \n",
    "print(mlp_tensor_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1602,
   "id": "4fb2c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch model with the same architecture for verification\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 4),  # First hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 4),  # Second hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1)   # Output layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def hook_fn(module, input, output, name=None):\n",
    "    \"\"\" Hook function to capture the output of each layer. \"\"\"\n",
    "    print(f\"Layer: {module}, Input: {input}, Output: {output}\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\" Calculate Root Mean Squared Error. \"\"\"\n",
    "    return torch.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1603,
   "id": "bd7853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook for layer: \n",
      "Registering hook for layer: layers\n",
      "Registering hook for layer: layers.0\n",
      "Registering hook for layer: layers.1\n",
      "Registering hook for layer: layers.2\n",
      "Registering hook for layer: layers.3\n",
      "Registering hook for layer: layers.4\n",
      "model parameters = [Parameter containing:\n",
      "tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5536, -0.8261,  0.0107,  0.0899], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.6116, -0.3268,  0.6143,  0.1041], requires_grad=True), Parameter containing:\n",
      "tensor([[0.6588, 0.2370, 0.7234, 0.1547]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4091], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmlp = MLP(input_size=3)  # Create a PyTorch model with the same architecture\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "# Register hooks to capture the output of each layer\n",
    "for name, module in tmlp.named_modules():\n",
    "    print(f\"Registering hook for layer: {name}\")\n",
    "    module.register_forward_hook(hook_fn)\n",
    "\n",
    "print(f\"model parameters = {[p for p in tmlp.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1605,
   "id": "5df68e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model parameters:\n",
      "layers.0.weight: data: tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) grad=None\n",
      "layers.0.bias: data: tensor([-0.5536, -0.8261,  0.0107,  0.0899]) grad=None\n",
      "layers.2.weight: data: tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]) grad=None\n",
      "layers.2.bias: data: tensor([ 0.6116, -0.3268,  0.6143,  0.1041]) grad=None\n",
      "layers.4.weight: data: tensor([[0.6588, 0.2370, 0.7234, 0.1547]]) grad=None\n",
      "layers.4.bias: data: tensor([0.4091]) grad=None\n"
     ]
    }
   ],
   "source": [
    "# Print parameters of the PyTorch model\n",
    "print(\"PyTorch model parameters:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: data: {param.data} grad={param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1606,
   "id": "bd430978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "\n",
    "y = [1.0, -1.0, -1.0, 1.0]  # Example labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "id": "014ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mse(y_preds, y_true):\n",
    "    \"\"\"Mean squared error loss function.\"\"\"\n",
    "    loss = sum([(i - j)**2 for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss/len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1608,
   "id": "8bb459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mae(y_preds, y_true):\n",
    "    \"\"\"Mean absolute error loss function.\"\"\"\n",
    "    loss = sum([(i - j) for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1616,
   "id": "3d011511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9835516902524112, 0.3786647677864891, -0.9881146621761316, -0.9991982757903943]\n",
      "Layer: Layer 1, Input: [-0.9835516902524112, 0.3786647677864891, -0.9881146621761316, -0.9991982757903943], Output: [0.9230153224441545, -0.7878449485179578, 0.24680950547766523, -0.7654749814179418]\n",
      "Layer: Layer 2, Input: [0.9230153224441545, -0.7878449485179578, 0.24680950547766523, -0.7654749814179418], Output: [0.930450953168436]\n",
      "y_preds = 0.930450953168436\n",
      "y = 1.0\n",
      "loss = Value(data=0.004837069915179088)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with our model\n",
    "mlp.register_forward_hook(hook_fn)  # Register the hook to capture outputs\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1610,
   "id": "7c87c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "y_preds_tmlp = 0.8661433458328247\n",
      "loss_tmlp = Value(data=0.017917603864830767)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with PyTorch model\n",
    "y_preds_tmlp = tmlp(torch.tensor(x[0]))\n",
    "print(f\"y_preds_tmlp = {y_preds_tmlp.item()}\")\n",
    "loss_tmlp = loss_fn_mse([Value(y_preds_tmlp.item())], [Value(y[0])])\n",
    "print(f\"loss_tmlp = {loss_tmlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "id": "dedc339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass with our model\n",
    "mlp.zero_grad()\n",
    "visited = set()\n",
    "loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "loss.backward(loss, visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "id": "494cc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for our model\n",
    "learning_rate = 0.001\n",
    "for param in mlp.parameters():\n",
    "    param.data -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "id": "8964c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with PyTorch model\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train\n",
    "optimizer.zero_grad()\n",
    "output = tmlp(torch.tensor(x[0]))  # Forward pass\n",
    "loss_rmse = rmse(torch.tensor([y[0]]), output)  # Calculate loss\n",
    "loss_rmse.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1614,
   "id": "30507a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for PyTorch model\n",
    "optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "id": "46a77386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for our model:\n",
      ": 0.27873192499369126 (grad: 0.0756247110604745)\n",
      ": -0.9501609974377805 (grad: 0.11343706659071175)\n",
      ": -0.44988052730072337 (grad: -0.03781235553023725)\n",
      ": -0.5536393596633926 (grad: 0.03781235553023725)\n",
      ": 0.4739633373446741 (grad: -0.6342846571410186)\n",
      ": 0.3549303383707966 (grad: -0.9514269857115278)\n",
      ": 0.7838486809013662 (grad: 0.3171423285705093)\n",
      ": -0.825611880232843 (grad: -0.3171423285705093)\n",
      ": -0.1560591252932449 (grad: -0.06036745919098969)\n",
      ": -0.9402597081195379 (grad: -0.09055118878648453)\n",
      ": -0.5627726680609004 (grad: 0.030183729595494844)\n",
      ": 0.010759193874831895 (grad: -0.030183729595494844)\n",
      ": -0.9469386036517635 (grad: 0.0065521775779216)\n",
      ": -0.6023405131559391 (grad: 0.0098282663668824)\n",
      ": 0.2997741470687918 (grad: -0.0032760887889608)\n",
      ": 0.089877689696688 (grad: 0.0032760887889608)\n",
      ": -0.5623934975652981 (grad: 2.0342276950948213)\n",
      ": 0.17978900367177295 (grad: -0.7831722169988281)\n",
      ": 0.6155709567439014 (grad: 2.0436650474487075)\n",
      ": -0.9903293320791834 (grad: 2.06658869650479)\n",
      ": 0.614968024518906 (grad: -2.0682468600839603)\n",
      ": 0.3933901602201404 (grad: 1.7637222519614237)\n",
      ": -0.31838969131710276 (grad: -0.6790283455335651)\n",
      ": -0.6919430517177757 (grad: 1.7719046537575873)\n",
      ": 0.9114915485731516 (grad: 1.791779985331265)\n",
      ": -0.3238739592551305 (grad: -1.7932176513354328)\n",
      ": -0.8371682440193996 (grad: 13.972629982639864)\n",
      ": -0.7978651589223761 (grad: -5.3794251386879655)\n",
      ": 0.6722235184329548 (grad: 14.037452928849186)\n",
      ": 0.18443155140846582 (grad: 14.19491006449083)\n",
      ": 0.6372955292079918 (grad: -14.206299598808107)\n",
      ": 0.4574323566898333 (grad: 1.2292094893137548)\n",
      ": 0.07323617176985188 (grad: -0.4732423628009731)\n",
      ": 0.9441908733174502 (grad: 1.2349121366109905)\n",
      ": -0.24499478468090646 (grad: 1.2487640603741863)\n",
      ": 0.10614645739989959 (grad: -1.249766028055221)\n",
      ": 0.6898409921809706 (grad: -19.228828133084118)\n",
      ": 0.21052441756891638 (grad: 16.412875000227206)\n",
      ": 0.7313013621839374 (grad: -5.141688818203392)\n",
      ": 0.12894169846866904 (grad: 15.946849960068699)\n",
      ": 0.44277511967269767 (grad: -20.83262072201139)\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters for out model\n",
    "print(\"Updated parameters for our model:\")\n",
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "id": "ea105b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for PyTorch model:\n",
      "layers.0.weight: tensor([[ 0.2788, -0.9500, -0.4499],\n",
      "        [ 0.4727,  0.3530,  0.7845],\n",
      "        [-0.1561, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) (grad: tensor([[ 9.6584e-03,  1.4488e-02, -4.8292e-03],\n",
      "        [ 2.5877e-01,  3.8816e-01, -1.2939e-01],\n",
      "        [-6.8197e-03, -1.0229e-02,  3.4098e-03],\n",
      "        [-9.6238e-05, -1.4436e-04,  4.8119e-05]]))\n",
      "layers.0.bias: tensor([-0.5536, -0.8263,  0.0107,  0.0899]) (grad: tensor([ 4.8292e-03,  1.2939e-01, -3.4098e-03, -4.8119e-05]))\n",
      "layers.2.weight: tensor([[-0.5591,  0.1785,  0.6188, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6891,  0.9144],\n",
      "        [-0.8147, -0.8065,  0.6948,  0.2073],\n",
      "        [ 0.4594,  0.0725,  0.9462, -0.2429]]) (grad: tensor([[ 0.0259, -0.0099,  0.0261,  0.0264],\n",
      "        [ 0.0235, -0.0090,  0.0236,  0.0239],\n",
      "        [ 0.1817, -0.0695,  0.1826,  0.1846],\n",
      "        [ 0.0168, -0.0064,  0.0169,  0.0170]]))\n",
      "layers.2.bias: tensor([ 0.6117, -0.3268,  0.6144,  0.1041]) (grad: tensor([-0.0264, -0.0239, -0.1848, -0.0171]))\n",
      "layers.4.weight: tensor([[0.6591, 0.2368, 0.7235, 0.1545]]) (grad: tensor([[-0.2469,  0.2113, -0.0574,  0.2053]]))\n",
      "layers.4.bias: tensor([0.4094]) (grad: tensor([-0.2677]))\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters of PyTorch model\n",
    "print(\"Updated parameters for PyTorch model:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "id": "d85f718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9837086880999435, 0.4104862500252361, -0.9880359995850213, -0.9991988033317043]\n",
      "Layer: Layer 1, Input: [-0.9837086880999435, 0.4104862500252361, -0.9880359995850213, -0.9991988033317043], Output: [0.9300756159974627, -0.7781620501975345, 0.4325779256190116, -0.7567228577133508]\n",
      "Layer: Layer 2, Input: [0.9300756159974627, -0.7781620501975345, 0.4325779256190116, -0.7567228577133508], Output: [1.218553099743485]\n",
      "y_preds = 1.218553099743485\n",
      "y = 1.0\n",
      "loss = Value(data=0.047765457407485716)\n"
     ]
    }
   ],
   "source": [
    "# Second forward pass with our model\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "id": "20af6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = 0.2781168415395158, grad = 0.73675537625166\n",
      " = -0.95101455180252, grad = 1.0360622478538968\n",
      " = -0.4496190327846514, grad = -0.32233047711010127\n",
      " = -0.5538548069684489, grad = 0.27628326609437254\n",
      " = 0.47874179372064934, grad = -5.7993653926245345\n",
      " = 0.361518086395497, grad = -8.119111549674347\n",
      " = 0.7818460770728869, grad = 2.5130583368039647\n",
      " = -0.8239959007638721, grad = -2.126433977295662\n",
      " = -0.15564021035113365, grad = -0.5161502783255044\n",
      " = -0.939686637521906, grad = -0.7189236019533811\n",
      " = -0.5629452576549328, grad = 0.22120726213950187\n",
      " = 0.010894915591841027, grad = -0.18433938511625153\n",
      " = -0.9469799415771389, grad = 0.05188094486624031\n",
      " = -0.6023965337811332, grad = 0.07183515443017889\n",
      " = 0.29979082518956673, grad = -0.021949630520332438\n",
      " = 0.08986500241782581, grad = 0.017958788607544723\n",
      " = -0.5740049233377658, grad = 14.886167419159179\n",
      " = 0.1837504684843409, grad = -5.219100732523457\n",
      " = 0.6063979977126209, grad = 12.46291564303239\n",
      " = -0.998344845293084, grad = 11.342364649205999\n",
      " = 0.6204674216180595, grad = -8.828917952443646\n",
      " = 0.38390480742858285, grad = 12.373982547870861\n",
      " = -0.3151964939502172, grad = -4.30247301379903\n",
      " = -0.6992123205646679, grad = 10.171320188230926\n",
      " = 0.9052836175729262, grad = 9.14252684063618\n",
      " = -0.31994851256506335, grad = -6.862397209683107\n",
      " = -0.9013813212102605, grad = 86.87300797055632\n",
      " = -0.7766632858850004, grad = -29.903960448071558\n",
      " = 0.6251666420299947, grad = 69.82209066492487\n",
      " = 0.14567285390800375, grad = 61.77920882577839\n",
      " = 0.6584199618508769, grad = -44.16341530211658\n",
      " = 0.4522455085112372, grad = 7.218064876398609\n",
      " = 0.07491015489059694, grad = -2.4539719811954543\n",
      " = 0.9405913304259814, grad = 5.640197532759838\n",
      " = -0.24781989580672836, grad = 4.888650223435316\n",
      " = 0.10734297784801546, grad = -3.2617153015614506\n",
      " = 0.7414291772992669, grad = -82.6198487932772\n",
      " = 0.17642623177240094, grad = 60.613272956091166\n",
      " = 0.7371431643424521, grad = -13.729363720897624\n",
      " = 0.11544132217437869, grad = 39.26296833914538\n",
      " = 0.4347413254715256, grad = -25.597653041678633\n"
     ]
    }
   ],
   "source": [
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label} = {param.data}, grad = {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1620,
   "id": "f4b8b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276315321914, -0.9918175594997916, -0.8350656162904463, 0.9423739739343306]\n",
      "Layer: Layer 1, Input: [-0.9991276315321914, -0.9918175594997916, -0.8350656162904463, 0.9423739739343306], Output: [0.9237175099716631, -0.7910865084461395, 0.9660906038665381, -0.011681945501092817]\n",
      "Layer: Layer 2, Input: [0.9237175099716631, -0.7910865084461395, 0.9660906038665381, -0.011681945501092817], Output: [-0.6695304217747466]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996886996296201, -0.6386645378500293, -0.8637446594463088, 0.944183622989383]\n",
      "Layer: Layer 1, Input: [-0.996886996296201, -0.6386645378500293, -0.8637446594463088, 0.944183622989383], Output: [0.8822340059944829, -0.7453213735062068, 0.957075979802214, -0.14906437136899842]\n",
      "Layer: Layer 2, Input: [0.8822340059944829, -0.7453213735062068, 0.957075979802214, -0.14906437136899842], Output: [-0.6999307556674828]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784573575697186, -0.8448527847911291, -0.8940667525169448, 0.28513683526960454]\n",
      "Layer: Layer 1, Input: [-0.9784573575697186, -0.8448527847911291, -0.8940667525169448, 0.28513683526960454], Output: [0.7138940973595561, -0.8897996264143349, 0.9824591623525861, 0.0681464016598766]\n",
      "Layer: Layer 2, Input: [0.7138940973595561, -0.8897996264143349, 0.9824591623525861, 0.0681464016598766], Output: [-0.6043407601078499]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522088987764, -0.5490313912555997, -0.3927370301832145, 0.28525678051628184]\n",
      "Layer: Layer 1, Input: [-0.9537522088987764, -0.5490313912555997, -0.3927370301832145, 0.28525678051628184], Output: [0.5273799607497388, -0.7465401796753427, 0.963923556933513, 0.13225188832603177]\n",
      "Layer: Layer 2, Input: [0.5273799607497388, -0.7465401796753427, 0.963923556933513, 0.13225188832603177], Output: [-0.6390967189665377]\n",
      "Epoch 1/100, Loss: 1.4301394172161386, Accuracy: -3.0043556249659513\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276360650415, -0.9918174606602559, -0.8350609568116586, 0.9423744993258379]\n",
      "Layer: Layer 1, Input: [-0.9991276360650415, -0.9918174606602559, -0.8350609568116586, 0.9423744993258379], Output: [0.9237375806349157, -0.7907479348659125, 0.966102635661681, -0.012390835866087406]\n",
      "Layer: Layer 2, Input: [0.9237375806349157, -0.7907479348659125, 0.966102635661681, -0.012390835866087406], Output: [-0.6756854400803974]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869916816828, -0.6386834175084359, -0.863744928703001, 0.9441920079039977]\n",
      "Layer: Layer 1, Input: [-0.9968869916816828, -0.6386834175084359, -0.863744928703001, 0.9441920079039977], Output: [0.8822698562753237, -0.7449167328219181, 0.9570917063303006, -0.14976031172441928]\n",
      "Layer: Layer 2, Input: [0.8822698562753237, -0.7449167328219181, 0.9570917063303006, -0.14976031172441928], Output: [-0.7061434590928837]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784572942825396, -0.8448643248409959, -0.8940676989423679, 0.2852226415608398]\n",
      "Layer: Layer 1, Input: [-0.9784572942825396, -0.8448643248409959, -0.8940676989423679, 0.2852226415608398], Output: [0.7140089424691692, -0.889599578678066, 0.9824640617479875, 0.06741596593290738]\n",
      "Layer: Layer 2, Input: [0.7140089424691692, -0.889599578678066, 0.9824640617479875, 0.06741596593290738], Output: [-0.6104406326063954]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522424665275, -0.5490448286608123, -0.39273328797319257, 0.2853055409463866]\n",
      "Layer: Layer 1, Input: [-0.9537522424665275, -0.5490448286608123, -0.39273328797319257, 0.2853055409463866], Output: [0.5275278890135165, -0.7461123001579062, 0.9639352517945451, 0.13152680154778754]\n",
      "Layer: Layer 2, Input: [0.5275278890135165, -0.7461123001579062, 0.9639352517945451, 0.13152680154778754], Output: [-0.6453740925604458]\n",
      "Epoch 2/100, Loss: 1.4383214414811367, Accuracy: -3.0044754409415644\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276403159771, -0.9918174005129764, -0.835056540523674, 0.9423755079097267]\n",
      "Layer: Layer 1, Input: [-0.9991276403159771, -0.9918174005129764, -0.835056540523674, 0.9423755079097267], Output: [0.9237583975988433, -0.7903969187509421, 0.9661150316109868, -0.013120359140464938]\n",
      "Layer: Layer 2, Input: [0.9237583975988433, -0.7903969187509421, 0.9661150316109868, -0.013120359140464938], Output: [-0.6820171987536823]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869865695611, -0.6387031517594661, -0.8637452998049701, 0.944200667109464]\n",
      "Layer: Layer 1, Input: [-0.9968869865695611, -0.6387031517594661, -0.8637452998049701, 0.944200667109464], Output: [0.8823068820624187, -0.7444975891673467, 0.9571079173213703, -0.15047575979167077]\n",
      "Layer: Layer 2, Input: [0.8823068820624187, -0.7444975891673467, 0.9571079173213703, -0.15047575979167077], Output: [-0.7125332589761664]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784572283562679, -0.8448762184583322, -0.8940687078686683, 0.28531041337747476]\n",
      "Layer: Layer 1, Input: [-0.9784572283562679, -0.8448762184583322, -0.8940687078686683, 0.28531041337747476], Output: [0.714126996537172, -0.8893924288377311, 0.9824691208817452, 0.06666497735256029]\n",
      "Layer: Layer 2, Input: [0.714126996537172, -0.8893924288377311, 0.9824691208817452, 0.06666497735256029], Output: [-0.6167147025596461]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522663440553, -0.5490594913674857, -0.39272999850525, 0.28535717695671253]\n",
      "Layer: Layer 1, Input: [-0.9537522663440553, -0.5490594913674857, -0.39272999850525, 0.28535717695671253], Output: [0.5276815827065852, -0.7456696978133984, 0.9639472622317392, 0.13078166912608805]\n",
      "Layer: Layer 2, Input: [0.5276815827065852, -0.7456696978133984, 0.9639472622317392, 0.13078166912608805], Output: [-0.6518281176816902]\n",
      "Epoch 3/100, Loss: 1.446815683423956, Accuracy: -3.00459735489956\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999127644279622, -0.9918173804294347, -0.835052372163555, 0.9423770148822214]\n",
      "Layer: Layer 1, Input: [-0.999127644279622, -0.9918173804294347, -0.835052372163555, 0.9423770148822214], Output: [0.9237800037118024, -0.7900325531331951, 0.9661278181184649, -0.013871951543357942]\n",
      "Layer: Layer 2, Input: [0.9237800037118024, -0.7900325531331951, 0.9661278181184649, -0.013871951543357942], Output: [-0.68853819917826]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869809409396, -0.6387237900357913, -0.863745776670345, 0.9442096151450559]\n",
      "Layer: Layer 1, Input: [-0.9968869809409396, -0.6387237900357913, -0.863745776670345, 0.9442096151450559], Output: [0.8823451548905594, -0.7440628787360387, 0.9571246474730907, -0.15121208852791837]\n",
      "Layer: Layer 2, Input: [0.8823451548905594, -0.7440628787360387, 0.9571246474730907, -0.15121208852791837], Output: [-0.7191127265624702]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784571596617666, -0.8448884894885987, -0.8940697823833703, 0.2854002744094855]\n",
      "Layer: Layer 1, Input: [-0.9784571596617666, -0.8448884894885987, -0.8940697823833703, 0.2854002744094855], Output: [0.7142484605921123, -0.8891776548154966, 0.9824743516670158, 0.06589198630496892]\n",
      "Layer: Layer 2, Input: [0.7142484605921123, -0.8891776548154966, 0.9824743516670158, 0.06589198630496892], Output: [-0.6231752949057472]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522802553651, -0.549075437840257, -0.3927271748803922, 0.2854118126919304]\n",
      "Layer: Layer 1, Input: [-0.9537522802553651, -0.549075437840257, -0.3927271748803922, 0.2854118126919304], Output: [0.5278413577202182, -0.7452112881757389, 0.9639596136583671, 0.13001506596907256]\n",
      "Layer: Layer 2, Input: [0.5278413577202182, -0.7452112881757389, 0.9639596136583671, 0.13001506596907256], Output: [-0.6584713885580757]\n",
      "Epoch 4/100, Loss: 1.4556457788746133, Accuracy: -3.0047215662681186\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276479498543, -0.9918174019694211, -0.8350484571639252, 0.9423790373753741]\n",
      "Layer: Layer 1, Input: [-0.9991276479498543, -0.9918174019694211, -0.8350484571639252, 0.9423790373753741], Output: [0.9238024473352255, -0.7896538104208239, 0.9661410251097255, -0.014647236244113822]\n",
      "Layer: Layer 2, Input: [0.9238024473352255, -0.7896538104208239, 0.9661410251097255, -0.014647236244113822], Output: [-0.6952625744411454]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869747745447, -0.6387453883127813, -0.8637463637442444, 0.944218868319654]\n",
      "Layer: Layer 1, Input: [-0.9968869747745447, -0.6387453883127813, -0.8637463637442444, 0.944218868319654], Output: [0.8823847554944684, -0.7436113962129185, 0.9571419361109025, -0.15197084960612903]\n",
      "Layer: Layer 2, Input: [0.8823847554944684, -0.7436113962129185, 0.9571419361109025, -0.15197084960612903], Output: [-0.7258960742499863]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784570880540309, -0.8449011649043943, -0.8940709259803904, 0.2854923632114542]\n",
      "Layer: Layer 1, Input: [-0.9784570880540309, -0.8449011649043943, -0.8940709259803904, 0.2854923632114542], Output: [0.714373561027283, -0.8889546651935122, 0.982479767634323, 0.06509535466945073]\n",
      "Layer: Layer 2, Input: [0.714373561027283, -0.8889546651935122, 0.982479767634323, 0.06509535466945073], Output: [-0.6298363427520459]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522838885586, -0.5490927343858613, -0.39272483201824626, 0.28546958766383557]\n",
      "Layer: Layer 1, Input: [-0.9537522838885586, -0.5490927343858613, -0.39272483201824626, 0.28546958766383557], Output: [0.5280075702470827, -0.7447358426690746, 0.9639723349216438, 0.1292253814616762]\n",
      "Layer: Layer 2, Input: [0.5280075702470827, -0.7447358426690746, 0.9639723349216438, 0.1292253814616762], Output: [-0.6653181439822846]\n",
      "Epoch 5/100, Loss: 1.4648384530590426, Accuracy: -3.004848301421398\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276513196806, -0.991817466916107, -0.8350448017778224, 0.9423815947918145]\n",
      "Layer: Layer 1, Input: [-0.9991276513196806, -0.991817466916107, -0.8350448017778224, 0.9423815947918145], Output: [0.9238257833596734, -0.7892595190966681, 0.9661546867111559, -0.015448058784247824]\n",
      "Layer: Layer 2, Input: [0.9238257833596734, -0.7892595190966681, 0.9661546867111559, -0.015448058784247824], Output: [-0.7022063990908338]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869680463127, -0.6387680103413906, -0.8637470660958305, 0.9442284450211033]\n",
      "Layer: Layer 1, Input: [-0.9968869680463127, -0.6387680103413906, -0.8637470660958305, 0.9442284450211033], Output: [0.8824257755098864, -0.7431417674360239, 0.9571598280796151, -0.1527538072783904]\n",
      "Layer: Layer 2, Input: [0.8824257755098864, -0.7431417674360239, 0.9571598280796151, -0.1527538072783904], Output: [-0.7328994671841814]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784570133694093, -0.84491427539642, -0.8940721426353677, 0.2855868358086704]\n",
      "Layer: Layer 1, Input: [-0.9784570133694093, -0.84491427539642, -0.8940721426353677, 0.2855868358086704], Output: [0.7145025542292737, -0.8887227858394102, 0.9824853842479223, 0.06427322013001577]\n",
      "Layer: Layer 2, Input: [0.7145025542292737, -0.8887227858394102, 0.9824853842479223, 0.06427322013001577], Output: [-0.6367136925575337]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522768896375, -0.5491114566246883, -0.3927229869888868, 0.2855306594260269]\n",
      "Layer: Layer 1, Input: [-0.9537522768896375, -0.5491114566246883, -0.3927229869888868, 0.2855306594260269], Output: [0.5281806241326589, -0.7442419608209313, 0.9639854589740755, 0.12841078433943343]\n",
      "Layer: Layer 2, Input: [0.5281806241326589, -0.7442419608209313, 0.9639854589740755, 0.12841078433943343], Output: [-0.6723845795292436]\n",
      "Epoch 6/100, Loss: 1.474424110689666, Accuracy: -3.004977818878362\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276543810782, -0.9918175773199572, -0.8350414132341646, 0.9423847092181715]\n",
      "Layer: Layer 1, Input: [-0.9991276543810782, -0.9918175773199572, -0.8350414132341646, 0.9423847092181715], Output: [0.9238500744742115, -0.7888483343769551, 0.9661688421049639, -0.01627653153230873]\n",
      "Layer: Layer 2, Input: [0.9238500744742115, -0.7888483343769551, 0.9661688421049639, -0.01627653153230873], Output: [-0.7093880780240418]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869607288784, -0.6387917291945394, -0.8637478895396014, 0.9442383660989685]\n",
      "Layer: Layer 1, Input: [-0.9968869607288784, -0.6387917291945394, -0.8637478895396014, 0.9442383660989685], Output: [0.8824683195999927, -0.7426524149716432, 0.9571783748656877, -0.15356298087487869]\n",
      "Layer: Layer 2, Input: [0.8824683195999927, -0.7426524149716432, 0.9571783748656877, -0.15356298087487869], Output: [-0.7401414144602817]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784569354221654, -0.8449278561150089, -0.8940734368998919, 0.2856838689229086]\n",
      "Layer: Layer 1, Input: [-0.9784569354221654, -0.8449278561150089, -0.8940734368998919, 0.2856838689229086], Output: [0.7146357323499595, -0.8884812430693327, 0.9824912193050258, 0.06342345139157232]\n",
      "Layer: Layer 2, Input: [0.7146357323499595, -0.8884812430693327, 0.9824912193050258, 0.06342345139157232], Output: [-0.6438254872523975]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522588548475, -0.5491316913354414, -0.39272165942700704, 0.285595206881162]\n",
      "Layer: Layer 1, Input: [-0.9537522588548475, -0.5491316913354414, -0.39272165942700704, 0.285595206881162], Output: [0.5283609800428057, -0.7437280352834289, 0.963999023720564, 0.12756917860866582]\n",
      "Layer: Layer 2, Input: [0.5283609800428057, -0.7437280352834289, 0.963999023720564, 0.12756917860866582], Output: [-0.6796892395379821]\n",
      "Epoch 7/100, Loss: 1.4844375776800267, Accuracy: -3.0051104158493445\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276571248026, -0.9918177355543683, -0.8350382999336147, 0.9423884059412013]\n",
      "Layer: Layer 1, Input: [-0.9991276571248026, -0.9918177355543683, -0.8350382999336147, 0.9423884059412013], Output: [0.9238753927707367, -0.7884187008180883, 0.9661835366186414, -0.017135090139413715]\n",
      "Layer: Layer 2, Input: [0.9238753927707367, -0.7884187008180883, 0.9661835366186414, -0.017135090139413715], Output: [-0.7168288405368441]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869527909348, -0.6388166292298016, -0.8637488407887586, 0.9442486553432461]\n",
      "Layer: Layer 1, Input: [-0.9968869527909348, -0.6388166292298016, -0.8637488407887586, 0.9442486553432461], Output: [0.8825125081445283, -0.7421415142419224, 0.9571976360269558, -0.15440069877568127]\n",
      "Layer: Layer 2, Input: [0.8825125081445283, -0.7421415142419224, 0.9571976360269558, -0.15440069877568127], Output: [-0.7476432661303865]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784568540001755, -0.8449419476116519, -0.8940748140207551, 0.2857836640085625]\n",
      "Layer: Layer 1, Input: [-0.9784568540001755, -0.8449419476116519, -0.8940748140207551, 0.2857836640085625], Output: [0.714773430587092, -0.8882291421962444, 0.9824972934457418, 0.0625435913143166]\n",
      "Layer: Layer 2, Input: [0.714773430587092, -0.8882291421962444, 0.9824972934457418, 0.0625435913143166], Output: [-0.6511926529319012]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522293211215, -0.5491535387950449, -0.39272087205494943, 0.2856634344147749]\n",
      "Layer: Layer 1, Input: [-0.9537522293211215, -0.5491535387950449, -0.39272087205494943, 0.2856634344147749], Output: [0.5285491670278107, -0.7431922072697145, 0.9640130731003115, 0.12669814757269213]\n",
      "Layer: Layer 2, Input: [0.5285491670278107, -0.7431922072697145, 0.9640130731003115, 0.12669814757269213], Output: [-0.6872535151044977]\n",
      "Epoch 8/100, Loss: 1.494919044607398, Accuracy: -3.0052464365790543\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276595401396, -0.991817944387096, -0.8350354716985523, 0.9423927140998788]\n",
      "Layer: Layer 1, Input: [-0.9991276595401396, -0.991817944387096, -0.8350354716985523, 0.9423927140998788], Output: [0.9239018217978476, -0.7879688040219366, 0.966198823131758, -0.018026566183508775]\n",
      "Layer: Layer 2, Input: [0.9239018217978476, -0.7879688040219366, 0.966198823131758, -0.018026566183508775], Output: [-0.7245533762952167]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869441964243, -0.6388428086134236, -0.8637499276516648, 0.9442593400902884]\n",
      "Layer: Layer 1, Input: [-0.9968869441964243, -0.6388428086134236, -0.8637499276516648, 0.9442593400902884], Output: [0.882558480684609, -0.7416069368613316, 0.9572176810384665, -0.15526966785928262]\n",
      "Layer: Layer 2, Input: [0.882558480684609, -0.7416069368613316, 0.9572176810384665, -0.15526966785928262], Output: [-0.7554298529978847]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784567688594791, -0.8449565970502739, -0.8940762800928417, 0.2858864523634633]\n",
      "Layer: Layer 1, Input: [-0.9784567688594791, -0.8449565970502739, -0.8940762800928417, 0.2858864523634633], Output: [0.7149160364849334, -0.8879654398321863, 0.9825036308132659, 0.061630783752470795]\n",
      "Layer: Layer 2, Input: [0.7149160364849334, -0.8879654398321863, 0.9825036308132659, 0.061630783752470795], Output: [-0.6588395253145465]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537521877539982, -0.5491771157860225, -0.3927206513518333, 0.2857355771243762]\n",
      "Layer: Layer 1, Input: [-0.9537521877539982, -0.5491771157860225, -0.3927206513518333, 0.2857355771243762], Output: [0.5287457972959139, -0.7426323090179886, 0.9640276584873283, 0.12579488181521806]\n",
      "Layer: Layer 2, Input: [0.5287457972959139, -0.7426323090179886, 0.9640276584873283, 0.12579488181521806], Output: [-0.6951022851385111]\n",
      "Epoch 9/100, Loss: 1.5059152827663183, Accuracy: -3.0053862831212967\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276616145942, -0.9918182070733075, -0.8350329400967539, 0.9423976675203151]\n",
      "Layer: Layer 1, Input: [-0.9991276616145942, -0.9918182070733075, -0.8350329400967539, 0.9423976675203151], Output: [0.9239294592282169, -0.787496507325267, 0.9662147639197819, -0.018954282026614117]\n",
      "Layer: Layer 2, Input: [0.9239294592282169, -0.787496507325267, 0.9662147639197819, -0.018954282026614117], Output: [-0.7325906661154048]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869349035007, -0.6388703826142015, -0.8637511592871687, 0.9442704520000319]\n",
      "Layer: Layer 1, Input: [-0.9968869349035007, -0.6388703826142015, -0.8637511592871687, 0.9442704520000319], Output: [0.8826064003995074, -0.7410461763543127, 0.9572385917112803, -0.15617306418687485]\n",
      "Layer: Layer 2, Input: [0.8826064003995074, -0.7410461763543127, 0.9572385917112803, -0.15617306418687485], Output: [-0.7635303224186359]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784566797172863, -0.8449718597885812, -0.8940778422580096, 0.2859925016873362]\n",
      "Layer: Layer 1, Input: [-0.9784566797172863, -0.8449718597885812, -0.8940778422580096, 0.2859925016873362], Output: [0.7150640019847359, -0.8876889075897855, 0.9825102599215516, 0.06068167803706945]\n",
      "Layer: Layer 2, Input: [0.7150640019847359, -0.8876889075897855, 0.9825102599215516, 0.06068167803706945], Output: [-0.666794668038152]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537521335321498, -0.5492025595188987, -0.3927210284220739, 0.2858119075227113]\n",
      "Layer: Layer 1, Input: [-0.9537521335321498, -0.5492025595188987, -0.3927210284220739, 0.2858119075227113], Output: [0.5289515853566872, -0.7420457883936951, 0.9640428405308151, 0.12485608517392224]\n",
      "Layer: Layer 2, Input: [0.5289515853566872, -0.7420457883936951, 0.9640428405308151, 0.12485608517392224], Output: [-0.7032647538036887]\n",
      "Epoch 10/100, Loss: 1.5174812348808504, Accuracy: -3.005530429462305\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276633334818, -0.9918185274788255, -0.8350307188673814, 0.9424033058008262]\n",
      "Layer: Layer 1, Input: [-0.9991276633334818, -0.9918185274788255, -0.8350307188673814, 0.9424033058008262], Output: [0.9239584203790139, -0.786999267403062, 0.9662314331115047, -0.01992217673793717]\n",
      "Layer: Layer 2, Input: [0.9239584203790139, -0.786999267403062, 0.9662314331115047, -0.01992217673793717], Output: [-0.7409750853109577]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869248631784, -0.6388994879735287, -0.8637525465418862, 0.9442820280679616]\n",
      "Layer: Layer 1, Input: [-0.9968869248631784, -0.6388994879735287, -0.8637525465418862, 0.9442820280679616], Output: [0.8826564600193555, -0.7404562491313766, 0.9572604654155893, -0.15711465338573458]\n",
      "Layer: Layer 2, Input: [0.8826564600193555, -0.7404562491313766, 0.9572604654155893, -0.15711465338573458], Output: [-0.7719792483517082]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784565862428642, -0.8449878014768751, -0.8940795089680403, 0.28610212462460843]\n",
      "Layer: Layer 1, Input: [-0.9784565862428642, -0.8449878014768751, -0.8940795089680403, 0.28610212462460843], Output: [0.7152178592883177, -0.8873980837100751, 0.9825172148151093, 0.05969230219858537]\n",
      "Layer: Layer 2, Input: [0.7152178592883177, -0.8873980837100751, 0.9825172148151093, 0.05969230219858537], Output: [-0.6750919593441558]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537520659272629, -0.5492300328331147, -0.3927220401412101, 0.2858927442600269]\n",
      "Layer: Layer 1, Input: [-0.9537520659272629, -0.5492300328331147, -0.3927220401412101, 0.2858927442600269], Output: [0.5291673732253693, -0.7414296084188616, 0.9640586916147669, 0.12387784993687857]\n",
      "Layer: Layer 2, Input: [0.5291673732253693, -0.7414296084188616, 0.9640586916147669, 0.12387784993687857], Output: [-0.7117755627298377]\n",
      "Epoch 11/100, Loss: 1.529682130724405, Accuracy: -3.005679440344931\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276646793923, -0.9918189102464317, -0.8350288244920336, 0.942409675746061]\n",
      "Layer: Layer 1, Input: [-0.9991276646793923, -0.9918189102464317, -0.8350288244920336, 0.942409675746061], Output: [0.9239888429437756, -0.786474019609074, 0.9662489200269735, -0.02093497640987078]\n",
      "Layer: Layer 2, Input: [0.9239888429437756, -0.786474019609074, 0.9662489200269735, -0.02093497640987078], Output: [-0.7497478967118493]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869140175433, -0.6389302888125318, -0.8637541024040334, 0.9442941119651199]\n",
      "Layer: Layer 1, Input: [-0.9968869140175433, -0.6389302888125318, -0.8637541024040334, 0.9442941119651199], Output: [0.882708889778563, -0.7398335599558976, 0.9572834194577846, -0.1580989534719471]\n",
      "Layer: Layer 2, Input: [0.882708889778563, -0.7398335599558976, 0.9572834194577846, -0.1580989534719471], Output: [-0.7808181335004607]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784564880454635, -0.8450045008961892, -0.8940812903387739, 0.28621569008127634]\n",
      "Layer: Layer 1, Input: [-0.9784564880454635, -0.8450045008961892, -0.8940812903387739, 0.28621569008127634], Output: [0.7153782421205804, -0.8870912073682824, 0.982524536649255, 0.05865789152780426]\n",
      "Layer: Layer 2, Input: [0.7153782421205804, -0.8870912073682824, 0.982524536649255, 0.05865789152780426], Output: [-0.6837720624292517]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537519840774343, -0.5492597312232248, -0.3927237306956987, 0.28597846366642193]\n",
      "Layer: Layer 1, Input: [-0.9537519840774343, -0.5492597312232248, -0.3927237306956987, 0.28597846366642193], Output: [0.5293941642112642, -0.7407801108319042, 0.9640752992086138, 0.12285548806581387]\n",
      "Layer: Layer 2, Input: [0.5293941642112642, -0.7407801108319042, 0.9640752992086138, 0.12285548806581387], Output: [-0.720676296054847]\n",
      "Epoch 12/100, Loss: 1.5425963542387597, Accuracy: -3.0058339968369836\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276656314682, -0.9918193610251179, -0.8350272769765177, 0.9424168332991782]\n",
      "Layer: Layer 1, Input: [-0.9991276656314682, -0.9918193610251179, -0.8350272769765177, 0.9424168332991782], Output: [0.9240208934865467, -0.785917018792284, 0.9662673338106724, -0.021998429485577235]\n",
      "Layer: Layer 2, Input: [0.9240208934865467, -0.785917018792284, 0.9662673338106724, -0.021998429485577235], Output: [-0.7589593146184401]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996886902297338, -0.638962984789102, -0.863755842627084, 0.9443067558469005]\n",
      "Layer: Layer 1, Input: [-0.996886902297338, -0.638962984789102, -0.863755842627084, 0.9443067558469005], Output: [0.8827639683402085, -0.739173715167468, 0.9573075971546576, -0.1591314598231325]\n",
      "Layer: Layer 2, Input: [0.8827639683402085, -0.739173715167468, 0.9573075971546576, -0.1591314598231325], Output: [-0.790097485950688]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978456384658002, -0.8450220538789187, -0.8940831986371925, 0.2863336385073714]\n",
      "Layer: Layer 1, Input: [-0.978456384658002, -0.8450220538789187, -0.8940831986371925, 0.2863336385073714], Output: [0.7155459148199884, -0.8867661275041878, 0.9825322758908084, 0.05757265174532149]\n",
      "Layer: Layer 2, Input: [0.7155459148199884, -0.8867661275041878, 0.9825322758908084, 0.05757265174532149], Output: [-0.692884457884959]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537518869513006, -0.5492918925356167, -0.39272615369613956, 0.2860695153220762]\n",
      "Layer: Layer 1, Input: [-0.9537518869513006, -0.5492918925356167, -0.39272615369613956, 0.2860695153220762], Output: [0.5296331691563819, -0.7400928267509012, 0.9640927705324502, 0.12178329803396898]\n",
      "Layer: Layer 2, Input: [0.5296331691563819, -0.7400928267509012, 0.9640927705324502, 0.12178329803396898], Output: [-0.7300175610347494]\n",
      "Epoch 13/100, Loss: 1.5563194133961082, Accuracy: -3.0059949318175425\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276661644114, -0.9918198867939755, -0.8350261009473523, 0.9424248462030387]\n",
      "Layer: Layer 1, Input: [-0.9991276661644114, -0.9918198867939755, -0.8350261009473523, 0.9424248462030387], Output: [0.9240547765713285, -0.7853236127133258, 0.9662868100251386, -0.02311964001348909]\n",
      "Layer: Layer 2, Input: [0.9240547765713285, -0.7853236127133258, 0.9662868100251386, -0.02311964001348909], Output: [-0.7686714291995724]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968868896186287, -0.6389978226422189, -0.8637577866078499, 0.9443200228491028]\n",
      "Layer: Layer 1, Input: [-0.9968868896186287, -0.6389978226422189, -0.8637577866078499, 0.9443200228491028], Output: [0.8828220381670892, -0.7384712568192754, 0.9573331764757399, -0.16021896376635686]\n",
      "Layer: Layer 2, Input: [0.8828220381670892, -0.7384712568192754, 0.9573331764757399, -0.16021896376635686], Output: [-0.7998797616519048]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784562755145273, -0.8450405788596822, -0.8940852489678337, 0.2864565029952084]\n",
      "Layer: Layer 1, Input: [-0.9784562755145273, -0.8450405788596822, -0.8940852489678337, 0.2864565029952084], Output: [0.7157218130926655, -0.8864201731037781, 0.9825404954610486, 0.05642942369499201]\n",
      "Layer: Layer 2, Input: [0.7157218130926655, -0.8864201731037781, 0.9825404954610486, 0.05642942369499201], Output: [-0.7024903231687414]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537517732985945, -0.5493268106839787, -0.39272937514870654, 0.28616644352933424]\n",
      "Layer: Layer 1, Input: [-0.9537517732985945, -0.5493268106839787, -0.39272937514870654, 0.28616644352933424], Output: [0.5298858712321131, -0.7393622073013327, 0.9641112392181846, 0.12065423469945057]\n",
      "Layer: Layer 2, Input: [0.5298858712321131, -0.7393622073013327, 0.9641112392181846, 0.12065423469945057], Output: [-0.7398619360902561]\n",
      "Epoch 14/100, Loss: 1.5709695746818326, Accuracy: -3.006163280469183\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276662470819, -0.9918204963331024, -0.8350253272337892, 0.9424337977605051]\n",
      "Layer: Layer 1, Input: [-0.9991276662470819, -0.9918204963331024, -0.8350253272337892, 0.9424337977605051], Output: [0.9240907479608074, -0.7846879099980261, 0.9663075203116626, -0.024307553314631112]\n",
      "Layer: Layer 2, Input: [0.9240907479608074, -0.7846879099980261, 0.9663075203116626, -0.024307553314631112], Output: [-0.7789624708270646]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968868758780851, -0.6390351130055092, -0.8637599586582768, 0.9443339906218131]\n",
      "Layer: Layer 1, Input: [-0.9968868758780851, -0.6390351130055092, -0.8637599586582768, 0.9443339906218131], Output: [0.8828835277655012, -0.7377192730665988, 0.9573603827025202, -0.16137001686555547]\n",
      "Layer: Layer 2, Input: [0.8828835277655012, -0.7377192730665988, 0.9573603827025202, -0.16137001686555547], Output: [-0.8102436552932215]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978456159918266, -0.8450602249629051, -0.8940874602678786, 0.2865849391631435]\n",
      "Layer: Layer 1, Input: [-0.978456159918266, -0.8450602249629051, -0.8940874602678786, 0.2865849391631435], Output: [0.7159071027042843, -0.8860499631890969, 0.98254927535815, 0.055219194809054524]\n",
      "Layer: Layer 2, Input: [0.7159071027042843, -0.8860499631890969, 0.98254927535815, 0.055219194809054524], Output: [-0.7126667309901951]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537516415802075, -0.5493648556134509, -0.3927334777532115, 0.2862699176922035]\n",
      "Layer: Layer 1, Input: [-0.9537516415802075, -0.5493648556134509, -0.3927334777532115, 0.2862699176922035], Output: [0.5301541192900188, -0.7385812290751614, 0.9641308751037023, 0.11945942829673104]\n",
      "Layer: Layer 2, Input: [0.5301541192900188, -0.7385812290751614, 0.9641308751037023, 0.11945942829673104], Output: [-0.7502882696924837]\n",
      "Epoch 15/100, Loss: 1.5866960943676456, Accuracy: -3.0063403542361318\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276658404621, -0.9918212009318537, -0.8350249952278433, 0.9424437923102372]\n",
      "Layer: Layer 1, Input: [-0.9991276658404621, -0.9918212009318537, -0.8350249952278433, 0.9424437923102372], Output: [0.9241291343401169, -0.7840022765204168, 0.9663296870398441, -0.0255736881692469]\n",
      "Layer: Layer 2, Input: [0.9241291343401169, -0.7840022765204168, 0.9663296870398441, -0.0255736881692469], Output: [-0.789933242992176]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968868609460877, -0.6390752557389516, -0.8637623899101172, 0.9443487564858175]\n",
      "Layer: Layer 1, Input: [-0.9968868609460877, -0.6390752557389516, -0.8637623899101172, 0.9443487564858175], Output: [0.8829489849607308, -0.7369088072357134, 0.9573895076197599, -0.16259563086471748]\n",
      "Layer: Layer 2, Input: [0.8829489849607308, -0.7369088072357134, 0.9573895076197599, -0.16259563086471748], Output: [-0.8212905735376802]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784560369949333, -0.8450811841924699, -0.8940898567987811, 0.28671976877956634]\n",
      "Layer: Layer 1, Input: [-0.9784560369949333, -0.8450811841924699, -0.8940898567987811, 0.28671976877956634], Output: [0.7161032668054474, -0.8856511187702073, 0.9825587196954598, 0.0539303628047413]\n",
      "Layer: Layer 2, Input: [0.7161032668054474, -0.8856511187702073, 0.9825587196954598, 0.0539303628047413], Output: [-0.7235129820204547]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537514898662188, -0.5494065033617063, -0.39273856733140156, 0.2863807766137451]\n",
      "Layer: Layer 1, Input: [-0.9537514898662188, -0.5494065033617063, -0.39273856733140156, 0.2863807766137451], Output: [0.5304402668175983, -0.7377407960770967, 0.9641518991413506, 0.11818745944465753]\n",
      "Layer: Layer 2, Input: [0.5304402668175983, -0.7377407960770967, 0.9641518991413506, 0.11818745944465753], Output: [-0.7613981654964161]\n",
      "Epoch 16/100, Loss: 1.6036916605000855, Accuracy: -3.006527852930457\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276648945824, -0.9918220154982547, -0.8350251565489129, 0.9424549634926705]\n",
      "Layer: Layer 1, Input: [-0.9991276648945824, -0.9918220154982547, -0.8350251565489129, 0.9424549634926705], Output: [0.9241703639852666, -0.7832565393947064, 0.966353606457792, -0.026933286478232666]\n",
      "Layer: Layer 2, Input: [0.9241703639852666, -0.7832565393947064, 0.966353606457792, -0.026933286478232666], Output: [-0.8017172300861559]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968868446562933, -0.6391187796779603, -0.8637651212842189, 0.9443644452324906]\n",
      "Layer: Layer 1, Input: [-0.9968868446562933, -0.6391187796779603, -0.8637651212842189, 0.9443644452324906], Output: [0.8830191286975564, -0.7360279238025943, 0.9574209398339505, -0.16391037669797134]\n",
      "Layer: Layer 2, Input: [0.8830191286975564, -0.7360279238025943, 0.9574209398339505, -0.16391037669797134], Output: [-0.8331548066262577]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784559056219743, -0.8451037105663926, -0.8940924704737843, 0.28686204578130087]\n",
      "Layer: Layer 1, Input: [-0.9784559056219743, -0.8451037105663926, -0.8940924704737843, 0.28686204578130087], Output: [0.7163122410408489, -0.8852178078077297, 0.9825689678734922, 0.05254757992164049]\n",
      "Layer: Layer 2, Input: [0.7163122410408489, -0.8852178078077297, 0.9825689678734922, 0.05254757992164049], Output: [-0.7351605539690839]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537513156817184, -0.5494523832018126, -0.39274478283483455, 0.28650009545564714]\n",
      "Layer: Layer 1, Input: [-0.9537513156817184, -0.5494523832018126, -0.39274478283483455, 0.28650009545564714], Output: [0.5307473870497378, -0.7368287950596613, 0.9641746070544701, 0.11682322108678377]\n",
      "Layer: Layer 2, Input: [0.5307473870497378, -0.7368287950596613, 0.9641746070544701, 0.11682322108678377], Output: [-0.7733261723053502]\n",
      "Epoch 17/100, Loss: 1.6222119853245898, Accuracy: -3.0067280417961646\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276633436809, -0.9918229603854077, -0.835025881020167, 0.9424674872861349]\n",
      "Layer: Layer 1, Input: [-0.9991276633436809, -0.9918229603854077, -0.835025881020167, 0.9424674872861349], Output: [0.9242150168226084, -0.7824366637169571, 0.9663796871682843, -0.028407210520649286]\n",
      "Layer: Layer 2, Input: [0.9242150168226084, -0.7824366637169571, 0.9663796871682843, -0.028407210520649286], Output: [-0.8144972907419119]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968868267891218, -0.6391664081858147, -0.8637682083524086, 0.9443812214509856]\n",
      "Layer: Layer 1, Input: [-0.9968868267891218, -0.6391664081858147, -0.8637682083524086, 0.9443812214509856], Output: [0.883094933703972, -0.7350601556990515, 0.9574552151470574, -0.1653341981074931]\n",
      "Layer: Layer 2, Input: [0.883094933703972, -0.7350601556990515, 0.9574552151470574, -0.1653341981074931], Output: [-0.8460203279779978]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784557643164793, -0.8451281516850284, -0.8940953446725096, 0.28701316066019494]\n",
      "Layer: Layer 1, Input: [-0.9784557643164793, -0.8451281516850284, -0.8940953446725096, 0.28701316066019494], Output: [0.7165366328272569, -0.8847419892260436, 0.9825802132387603, 0.05104984627149358]\n",
      "Layer: Layer 2, Input: [0.7165366328272569, -0.8847419892260436, 0.9825802132387603, 0.05104984627149358], Output: [-0.7477895305154029]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537511157631767, -0.5495033553431645, -0.39275231270935046, 0.28662929148629185]\n",
      "Layer: Layer 1, Input: [-0.9537511157631767, -0.5495033553431645, -0.39275231270935046, 0.28662929148629185], Output: [0.5310796223300595, -0.7358285262659194, 0.964199408832004, 0.11534604095498617]\n",
      "Layer: Layer 2, Input: [0.5310796223300595, -0.7358285262659194, 0.964199408832004, 0.11534604095498617], Output: [-0.7862566133450704]\n",
      "Epoch 18/100, Loss: 1.6426082417855956, Accuracy: -3.006944045593582\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276610981419, -0.9918240645915327, -0.8350272670327398, 0.9424816037170959]\n",
      "Layer: Layer 1, Input: [-0.9991276610981419, -0.9918240645915327, -0.8350272670327398, 0.9424816037170959], Output: [0.9242639112657542, -0.7815224093535462, 0.9664085182465707, -0.030025275298709277]\n",
      "Layer: Layer 2, Input: [0.9242639112657542, -0.7815224093535462, 0.9664085182465707, -0.030025275298709277], Output: [-0.8285350030292128]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968868070441427, -0.6392191742089867, -0.8637717298032912, 0.9443993101030569]\n",
      "Layer: Layer 1, Input: [-0.9968868070441427, -0.6392191742089867, -0.8637717298032912, 0.9443993101030569], Output: [0.8831777775737738, -0.7339817548166323, 0.9574931057059921, -0.16689559696566791]\n",
      "Layer: Layer 2, Input: [0.8831777775737738, -0.7339817548166323, 0.9574931057059921, -0.16689559696566791], Output: [-0.8601503278250366]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784556110475711, -0.8451550041597311, -0.8940985408893579, 0.2871750147751355]\n",
      "Layer: Layer 1, Input: [-0.9784556110475711, -0.8451550041597311, -0.8940985408893579, 0.2871750147751355], Output: [0.7167800991966616, -0.8842120751147209, 0.9825927362954648, 0.04940716234889262]\n",
      "Layer: Layer 2, Input: [0.7167800991966616, -0.8842120751147209, 0.9825927362954648, 0.04940716234889262], Output: [-0.7616574771274283]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537508856516501, -0.5495606472305199, -0.3927614233506029, 0.28677030044747326]\n",
      "Layer: Layer 1, Input: [-0.9537508856516501, -0.5495606472305199, -0.3927614233506029, 0.28677030044747326], Output: [0.5314427866259311, -0.7347159268391917, 0.9642268989957069, 0.1137263850257357]\n",
      "Layer: Layer 2, Input: [0.5314427866259311, -0.7347159268391917, 0.9642268989957069, 0.1137263850257357], Output: [-0.8004531707197722]\n",
      "Epoch 19/100, Loss: 1.665384241568658, Accuracy: -3.0071803687965204\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276580300933, -0.9918253718365377, -0.8350294610044817, 0.9424976556322713]\n",
      "Layer: Layer 1, Input: [-0.9991276580300933, -0.9918253718365377, -0.8350294610044817, 0.9424976556322713], Output: [0.9243182671662424, -0.780482828889018, 0.9664410000816862, -0.03183259210384217]\n",
      "Layer: Layer 2, Input: [0.9243182671662424, -0.780482828889018, 0.9664410000816862, -0.03183259210384217], Output: [-0.8442265809574714]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968867849905171, -0.6392786391392108, -0.8637758034024461, 0.944419033352071]\n",
      "Layer: Layer 1, Input: [-0.9968867849905171, -0.6392786391392108, -0.8637758034024461, 0.944419033352071], Output: [0.8832697172432799, -0.7327564093761747, 0.9575357911737724, -0.16863769666126727]\n",
      "Layer: Layer 2, Input: [0.8832697172432799, -0.7327564093761747, 0.9575357911737724, -0.16863769666126727], Output: [-0.875943492286143]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784554428993144, -0.8451850190913507, -0.8941021512792889, 0.2873503325285823]\n",
      "Layer: Layer 1, Input: [-0.9784554428993144, -0.8451850190913507, -0.8941021512792889, 0.2873503325285823], Output: [0.7170480502140196, -0.8836103623280147, 0.9826069688833619, 0.047574159605662796]\n",
      "Layer: Layer 2, Input: [0.7170480502140196, -0.8836103623280147, 0.9826069688833619, 0.047574159605662796], Output: [-0.7771544532228672]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537506189638018, -0.5496261126667717, -0.3927725126753383, 0.28692589200234336]\n",
      "Layer: Layer 1, Input: [-0.9537506189638018, -0.5496261126667717, -0.3927725126753383, 0.28692589200234336], Output: [0.531845488442246, -0.7334542409930346, 0.9642579923143867, 0.11191958468028629]\n",
      "Layer: Layer 2, Input: [0.531845488442246, -0.7334542409930346, 0.9642579923143867, 0.11191958468028629], Output: [-0.8163152582790651]\n",
      "Epoch 20/100, Loss: 1.6913057385479973, Accuracy: -3.007443893727526\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276539451295, -0.9918269534205925, -0.8350326980359362, 0.9425161647039123]\n",
      "Layer: Layer 1, Input: [-0.9991276539451295, -0.9918269534205925, -0.8350326980359362, 0.9425161647039123], Output: [0.9243800457199561, -0.7792666141696872, 0.9664786248333004, -0.03390302609583727]\n",
      "Layer: Layer 2, Input: [0.9243800457199561, -0.7792666141696872, 0.9664786248333004, -0.03390302609583727], Output: [-0.862221631217601]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968867599692228, -0.6393473567581268, -0.8637806194784687, 0.9444408829350109]\n",
      "Layer: Layer 1, Input: [-0.9968867599692228, -0.6393473567581268, -0.8637806194784687, 0.9444408829350109], Output: [0.8833740668766604, -0.7313239168801507, 0.9575852254676185, -0.17063110440000517]\n",
      "Layer: Layer 2, Input: [0.8833740668766604, -0.7313239168801507, 0.9575852254676185, -0.17063110440000517], Output: [-0.8940535385941853]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784552554049571, -0.8452194257486361, -0.8941063250051526, 0.2875432751441411]\n",
      "Layer: Layer 1, Input: [-0.9784552554049571, -0.8452194257486361, -0.8941063250051526, 0.2875432751441411], Output: [0.7173491021506853, -0.8829075299488477, 0.9826236326821606, 0.04547659538309678]\n",
      "Layer: Layer 2, Input: [0.7173491021506853, -0.8829075299488477, 0.9826236326821606, 0.04547659538309678], Output: [-0.794919823600648]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537503059561055, -0.5497027807861601, -0.3927862223609223, 0.28710028909876195]\n",
      "Layer: Layer 1, Input: [-0.9537503059561055, -0.5497027807861601, -0.3927862223609223, 0.28710028909876195], Output: [0.5323014539125684, -0.7319826037132339, 0.9642942165182243, 0.1098525355877768]\n",
      "Layer: Layer 2, Input: [0.5323014539125684, -0.7319826037132339, 0.9642942165182243, 0.1098525355877768], Output: [-0.8344977482438064]\n",
      "Epoch 21/100, Loss: 1.7216334808806855, Accuracy: -3.007746017266574\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276485188662, -0.9918289399830198, -0.8350374008683857, 0.9425380013708083]\n",
      "Layer: Layer 1, Input: [-0.9991276485188662, -0.9918289399830198, -0.8350374008683857, 0.9425380013708083], Output: [0.9244527741555386, -0.7777778865641959, 0.9665241794047212, -0.03637252071946464]\n",
      "Layer: Layer 2, Input: [0.9244527741555386, -0.7777778865641959, 0.9665241794047212, -0.03637252071946464], Output: [-0.8837176156464457]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968867308725398, -0.6394300211254469, -0.8637865227754287, 0.944465682403919]\n",
      "Layer: Layer 1, Input: [-0.9968867308725398, -0.6394300211254469, -0.8637865227754287, 0.944465682403919], Output: [0.8834968034025555, -0.7295717780665292, 0.9576450555176663, -0.17300575831675719]\n",
      "Layer: Layer 2, Input: [0.8834968034025555, -0.7295717780665292, 0.9576450555176663, -0.17300575831675719], Output: [-0.9156856322451403]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784550410435768, -0.8452604851982608, -0.8941113327023484, 0.2877608173957983]\n",
      "Layer: Layer 1, Input: [-0.9784550410435768, -0.8452604851982608, -0.8941113327023484, 0.2877608173957983], Output: [0.7176985606061159, -0.8820488531828539, 0.9826440891205689, 0.04297793266674617]\n",
      "Layer: Layer 2, Input: [0.7176985606061159, -0.8820488531828539, 0.9826440891205689, 0.04297793266674617], Output: [-0.8161318242192465]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537499302922933, -0.5497962135431277, -0.3928037118107393, 0.2873005551918584]\n",
      "Layer: Layer 1, Input: [-0.9537499302922933, -0.5497962135431277, -0.3928037118107393, 0.2873005551918584], Output: [0.5328351055481164, -0.7301874460546439, 0.9643384512664264, 0.10739077966782534]\n",
      "Layer: Layer 2, Input: [0.5328351055481164, -0.7301874460546439, 0.9643384512664264, 0.10739077966782534], Output: [-0.8562078391088263]\n",
      "Epoch 22/100, Loss: 1.7587040040351583, Accuracy: -3.0081079982908854\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276411218604, -0.9918316214450572, -0.835044485928917, 0.9425648504271248]\n",
      "Layer: Layer 1, Input: [-0.9991276411218604, -0.9918316214450572, -0.835044485928917, 0.9425648504271248], Output: [0.9245440817430475, -0.7757985908277321, 0.9665839965226237, -0.03954424662502001]\n",
      "Layer: Layer 2, Input: [0.9245440817430475, -0.7757985908277321, 0.9665839965226237, -0.03954424662502001], Output: [-0.9113905053949239]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968866955319788, -0.6395370852124564, -0.8637942666849783, 0.9444950329131624]\n",
      "Layer: Layer 1, Input: [-0.9968866955319788, -0.6395370852124564, -0.8637942666849783, 0.9444950329131624], Output: [0.8836509022583486, -0.7272441454363175, 0.9577235614930913, -0.17605139828088098]\n",
      "Layer: Layer 2, Input: [0.8836509022583486, -0.7272441454363175, 0.9577235614930913, -0.17605139828088098], Output: [-0.9435333123901366]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784547850618143, -0.8453132362173126, -0.8941177668985462, 0.28801653278523964]\n",
      "Layer: Layer 1, Input: [-0.9784547850618143, -0.8453132362173126, -0.8941177668985462, 0.28801653278523964], Output: [0.7181289609496914, -0.8809100616048089, 0.9826714704372601, 0.039773972737846414]\n",
      "Layer: Layer 2, Input: [0.7181289609496914, -0.8809100616048089, 0.9826714704372601, 0.039773972737846414], Output: [-0.8434224506712931]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537494600885709, -0.5499187826853573, -0.3928275078649962, 0.2875404020833154]\n",
      "Layer: Layer 1, Input: [-0.9537494600885709, -0.5499187826853573, -0.3928275078649962, 0.2875404020833154], Output: [0.5334984889191409, -0.7278109755784639, 0.9643973147184749, 0.1042347104314703]\n",
      "Layer: Layer 2, Input: [0.5334984889191409, -0.7278109755784639, 0.9643973147184749, 0.1042347104314703], Output: [-0.8841433099752443]\n",
      "Epoch 23/100, Loss: 1.8077786731004364, Accuracy: -3.0085780523087386\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276301106711, -0.9918359423370227, -0.8350568470507073, 0.9426010652455239]\n",
      "Layer: Layer 1, Input: [-0.9991276301106711, -0.9918359423370227, -0.8350568470507073, 0.9426010652455239], Output: [0.9246778698996181, -0.7725942954074293, 0.966679356437678, -0.04441118584384253]\n",
      "Layer: Layer 2, Input: [0.9246778698996181, -0.7725942954074293, 0.966679356437678, -0.04441118584384253], Output: [-0.9540305089813094]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968866482229016, -0.6397027265753458, -0.8638062511245478, 0.9445330946887515]\n",
      "Layer: Layer 1, Input: [-0.9968866482229016, -0.6397027265753458, -0.8638062511245478, 0.9445330946887515], Output: [0.8838772340970743, -0.7234794153433229, 0.9578485370020944, -0.18071672584102813]\n",
      "Layer: Layer 2, Input: [0.8838772340970743, -0.7234794153433229, 0.9578485370020944, -0.18071672584102813], Output: [-0.9864460669286637]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784544484128892, -0.845394166283481, -0.8941275188221964, 0.2883457311444755]\n",
      "Layer: Layer 1, Input: [-0.9784544484128892, -0.845394166283481, -0.8941275188221964, 0.2883457311444755], Output: [0.7187394954432136, -0.8790734113369608, 0.9827164768875873, 0.03486970778375725]\n",
      "Layer: Layer 2, Input: [0.7187394954432136, -0.8790734113369608, 0.9827164768875873, 0.03486970778375725], Output: [-0.885432677450146]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537488114893015, -0.5501108923470707, -0.39286563617067677, 0.2878553890192049]\n",
      "Layer: Layer 1, Input: [-0.9537488114893015, -0.5501108923470707, -0.39286563617067677, 0.2878553890192049], Output: [0.5344509675572077, -0.7239872841162298, 0.9644933817599882, 0.09940413959135411]\n",
      "Layer: Layer 2, Input: [0.5344509675572077, -0.7239872841162298, 0.9644933817599882, 0.09940413959135411], Output: [-0.9271660776773358]\n",
      "Epoch 24/100, Loss: 1.8863784253694869, Accuracy: -3.0093178422798363\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276014514554, -0.9918556840541831, -0.8351146776227796, 0.9426816885105435]\n",
      "Layer: Layer 1, Input: [-0.9991276014514554, -0.9918556840541831, -0.8351146776227796, 0.9426816885105435], Output: [0.9251773997860454, -0.756642030625425, 0.9671349849978313, -0.06554813099981736]\n",
      "Layer: Layer 2, Input: [0.9251773997860454, -0.756642030625425, 0.9671349849978313, -0.06554813099981736], Output: [-1.1414990020553644]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968865392354029, -0.6404275831973046, -0.8638561190898542, 0.9446136424666879]\n",
      "Layer: Layer 1, Input: [-0.9968865392354029, -0.6404275831973046, -0.8638561190898542, 0.9446136424666879], Output: [0.8847340810122919, -0.7047822208502224, 0.9584432970514063, -0.20089357141154146]\n",
      "Layer: Layer 2, Input: [0.8847340810122919, -0.7047822208502224, 0.9584432970514063, -0.20089357141154146], Output: [-1.1752038689222348]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784536907467684, -0.8457449231978659, -0.8941671553390484, 0.28903561765994756]\n",
      "Layer: Layer 1, Input: [-0.9784536907467684, -0.8457449231978659, -0.8941671553390484, 0.28903561765994756], Output: [0.7207990216908939, -0.8699864203196025, 0.9829466592130268, 0.013679747709125204]\n",
      "Layer: Layer 2, Input: [0.7207990216908939, -0.8699864203196025, 0.9829466592130268, 0.013679747709125204], Output: [-1.0696650353459392]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537472604271903, -0.5509637472683168, -0.3930302643074241, 0.28853337902957976]\n",
      "Layer: Layer 1, Input: [-0.9537472604271903, -0.5509637472683168, -0.3930302643074241, 0.28853337902957976], Output: [0.5377520618222907, -0.7052107369415986, 0.9649792368833324, 0.07851400657780343]\n",
      "Layer: Layer 2, Input: [0.5377520618222907, -0.7052107369415986, 0.9649792368833324, 0.07851400657780343], Output: [-1.1162050478668635]\n",
      "Epoch 25/100, Loss: 2.2749728483140963, Accuracy: -3.502572954190402\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999127672897531, -0.9918464257340331, -0.8350759947803146, 0.9424754202214882]\n",
      "Layer: Layer 1, Input: [-0.999127672897531, -0.9918464257340331, -0.8350759947803146, 0.9424754202214882], Output: [0.9247920136384664, -0.7618902827272153, 0.9670142513250795, -0.05598157320979719]\n",
      "Layer: Layer 2, Input: [0.9247920136384664, -0.7618902827272153, 0.9670142513250795, -0.05598157320979719], Output: [-1.059262864359996]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996886790686085, -0.6400944968821505, -0.8638243299706144, 0.9444153491539228]\n",
      "Layer: Layer 1, Input: [-0.996886790686085, -0.6400944968821505, -0.8638243299706144, 0.9444153491539228], Output: [0.8841075008537306, -0.7109047279761499, 0.9582814739803893, -0.19178207494494592]\n",
      "Layer: Layer 2, Input: [0.8841075008537306, -0.7109047279761499, 0.9582814739803893, -0.19178207494494592], Output: [-1.0925734123864692]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784554098750431, -0.8455845011516061, -0.8941421560965729, 0.28735268534913555]\n",
      "Layer: Layer 1, Input: [-0.9784554098750431, -0.8455845011516061, -0.8941421560965729, 0.28735268534913555], Output: [0.718768800179191, -0.8731489955542007, 0.9829108474773459, 0.023523131038910003]\n",
      "Layer: Layer 2, Input: [0.718768800179191, -0.8731489955542007, 0.9829108474773459, 0.023523131038910003], Output: [-0.9882958012496429]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537509309355934, -0.5505691209552362, -0.3929236230489919, 0.2868441535300672]\n",
      "Layer: Layer 1, Input: [-0.9537509309355934, -0.5505691209552362, -0.3929236230489919, 0.2868441535300672], Output: [0.5346197915505705, -0.7116928750093086, 0.9648982087846885, 0.08822879164857846]\n",
      "Layer: Layer 2, Input: [0.5346197915505705, -0.7116928750093086, 0.9648982087846885, 0.08822879164857846], Output: [-1.0331787396944214]\n",
      "Epoch 26/100, Loss: 2.095771539256699, Accuracy: -3.1967192151912442\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991274262573231, -0.9918645452149718, -0.8351689829964767, 0.9432021162098976]\n",
      "Layer: Layer 1, Input: [-0.9991274262573231, -0.9918645452149718, -0.8351689829964767, 0.9432021162098976], Output: [0.9258564862967584, -0.7567616402374417, 0.9670902572344867, -0.07478812685997083]\n",
      "Layer: Layer 2, Input: [0.9258564862967584, -0.7567616402374417, 0.9670902572344867, -0.07478812685997083], Output: [-1.214393290509095]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968859069292562, -0.6407581716588167, -0.8639032181971834, 0.9451199134787178]\n",
      "Layer: Layer 1, Input: [-0.9968859069292562, -0.6407581716588167, -0.8639032181971834, 0.9451199134787178], Output: [0.8858020379898388, -0.7049817344021249, 0.958397084394256, -0.20967089112013165]\n",
      "Layer: Layer 2, Input: [0.8858020379898388, -0.7049817344021249, 0.958397084394256, -0.20967089112013165], Output: [-1.2480425911261452]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784493435208766, -0.8459053696140458, -0.894204636994112, 0.2933622715056833]\n",
      "Layer: Layer 1, Input: [-0.9784493435208766, -0.8459053696140458, -0.894204636994112, 0.2933622715056833], Output: [0.7248876854569625, -0.8695521870559005, 0.9828501352865464, 0.0036617718285503757]\n",
      "Layer: Layer 2, Input: [0.7248876854569625, -0.8695521870559005, 0.9828501352865464, 0.0036617718285503757], Output: [-1.1431638264185664]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953738107646631, -0.5513508141482351, -0.39318548612102283, 0.29284766647211236]\n",
      "Layer: Layer 1, Input: [-0.953738107646631, -0.5513508141482351, -0.39318548612102283, 0.29284766647211236], Output: [0.5439328853633014, -0.7043939136022647, 0.9647926816562536, 0.06859737648380779]\n",
      "Layer: Layer 2, Input: [0.5439328853633014, -0.7043939136022647, 0.9647926816562536, 0.06859737648380779], Output: [-1.1900206806922917]\n",
      "Epoch 27/100, Loss: 2.4454373087797507, Accuracy: -3.795620388746098\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991274682078655, -0.9918586534315815, -0.8351449258128154, 0.9430831070238682]\n",
      "Layer: Layer 1, Input: [-0.9991274682078655, -0.9918586534315815, -0.8351449258128154, 0.9430831070238682], Output: [0.9256238404537785, -0.7603301679053763, 0.9670065210799401, -0.06863865113757839]\n",
      "Layer: Layer 2, Input: [0.9256238404537785, -0.7603301679053763, 0.9670065210799401, -0.06863865113757839], Output: [-1.161146273406967]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996886054085652, -0.6405464550889264, -0.8638835233080866, 0.9450056972647993]\n",
      "Layer: Layer 1, Input: [-0.996886054085652, -0.6405464550889264, -0.8638835233080866, 0.9450056972647993], Output: [0.8854225760891218, -0.7091457002311115, 0.9582854609732008, -0.20383007323085575]\n",
      "Layer: Layer 2, Input: [0.8854225760891218, -0.7091457002311115, 0.9582854609732008, -0.20383007323085575], Output: [-1.1945284500160565]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784503488511893, -0.8458034677241139, -0.8941891623574844, 0.2923867651001631]\n",
      "Layer: Layer 1, Input: [-0.9784503488511893, -0.8458034677241139, -0.8941891623574844, 0.2923867651001631], Output: [0.7236859725695771, -0.8716927927133664, 0.9828219916665805, 0.009981145601199972]\n",
      "Layer: Layer 2, Input: [0.7236859725695771, -0.8716927927133664, 0.9828219916665805, 0.009981145601199972], Output: [-1.090524160482386]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537402581028837, -0.5510998131920906, -0.39311931902956493, 0.2918676179037484]\n",
      "Layer: Layer 1, Input: [-0.9537402581028837, -0.5510998131920906, -0.39311931902956493, 0.2918676179037484], Output: [0.5420681204141725, -0.7087774937224764, 0.9647302787076065, 0.07484353255923923]\n",
      "Layer: Layer 2, Input: [0.5420681204141725, -0.7087774937224764, 0.9647302787076065, 0.07484353255923923], Output: [-1.1362649750684457]\n",
      "Epoch 28/100, Loss: 2.3200543000654243, Accuracy: -3.5824638589738544\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991275266462161, -0.9918508122714713, -0.8351124967137142, 0.942916371921536]\n",
      "Layer: Layer 1, Input: [-0.9991275266462161, -0.9918508122714713, -0.8351124967137142, 0.942916371921536], Output: [0.9253057063045483, -0.7648056559515157, 0.9668991157703297, -0.06047152422473929]\n",
      "Layer: Layer 2, Input: [0.9253057063045483, -0.7648056559515157, 0.9668991157703297, -0.06047152422473929], Output: [-1.090798343648297]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968862594369532, -0.6402645549200091, -0.8638569245562387, 0.9448455428666784]\n",
      "Layer: Layer 1, Input: [-0.9968862594369532, -0.6402645549200091, -0.8638569245562387, 0.9448455428666784], Output: [0.8849045419691541, -0.7143715129520968, 0.9581419271500506, -0.1960584043582491]\n",
      "Layer: Layer 2, Input: [0.8849045419691541, -0.7143715129520968, 0.9581419271500506, -0.1960584043582491], Output: [-1.123842996177339]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784517523082773, -0.8456677386366099, -0.8941682541424588, 0.2910209347198258]\n",
      "Layer: Layer 1, Input: [-0.9784517523082773, -0.8456677386366099, -0.8941682541424588, 0.2910209347198258], Output: [0.7220273006197468, -0.8743832281849673, 0.9827879209228154, 0.018377296557811573]\n",
      "Layer: Layer 2, Input: [0.7220273006197468, -0.8743832281849673, 0.9827879209228154, 0.018377296557811573], Output: [-1.0209251852657497]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953743257229442, -0.5507657179471231, -0.39303002216850896, 0.290496079244779]\n",
      "Layer: Layer 1, Input: [-0.953743257229442, -0.5507657179471231, -0.39303002216850896, 0.290496079244779], Output: [0.5395003136854852, -0.7143034184363048, 0.9646540517337243, 0.08313480679191589]\n",
      "Layer: Layer 2, Input: [0.5395003136854852, -0.7143034184363048, 0.9646540517337243, 0.08313480679191589], Output: [-1.0652512802721328]\n",
      "Epoch 29/100, Loss: 2.1631188788871825, Accuracy: -3.3008178053635184\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991277133861416, -0.9918302204611207, -0.8350221159928842, 0.9423738698022044]\n",
      "Layer: Layer 1, Input: [-0.9991277133861416, -0.9918302204611207, -0.8350221159928842, 0.9423738698022044], Output: [0.9243648345346531, -0.7745184253964604, 0.9666678130983098, -0.039019254814732555]\n",
      "Layer: Layer 2, Input: [0.9243648345346531, -0.7745184253964604, 0.9666678130983098, -0.039019254814732555], Output: [-0.9087948748494986]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968869211875216, -0.6395205903436997, -0.8637819236976384, 0.9443223381360994]\n",
      "Layer: Layer 1, Input: [-0.9968869211875216, -0.6395205903436997, -0.8637819236976384, 0.9443223381360994], Output: [0.8833837299806878, -0.7257156398440118, 0.957828447628155, -0.1755647274953796]\n",
      "Layer: Layer 2, Input: [0.8833837299806878, -0.7257156398440118, 0.957828447628155, -0.1755647274953796], Output: [-0.9411015493494719]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978456283579622, -0.8453089605745823, -0.8941091423451876, 0.28657343407080527]\n",
      "Layer: Layer 1, Input: [-0.978456283579622, -0.8453089605745823, -0.8941091423451876, 0.28657343407080527], Output: [0.7169400530109645, -0.8803402975329637, 0.9827404608995344, 0.040537412932651826]\n",
      "Layer: Layer 2, Input: [0.7169400530109645, -0.8803402975329637, 0.9827404608995344, 0.040537412932651826], Output: [-0.8403790492400509]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537528947836946, -0.5498857810129831, -0.3927792645370267, 0.2860400924359713]\n",
      "Layer: Layer 1, Input: [-0.9537528947836946, -0.5498857810129831, -0.3927792645370267, 0.2860400924359713], Output: [0.5316891211629883, -0.7265920890596269, 0.9645386220355943, 0.10498043794350713]\n",
      "Layer: Layer 2, Input: [0.5316891211629883, -0.7265920890596269, 0.9645386220355943, 0.10498043794350713], Output: [-0.881504329548907]\n",
      "Epoch 30/100, Loss: 1.8031260729433845, Accuracy: -3.008818605808883\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991277028312839, -0.9918343286640563, -0.8350338027611425, 0.9424090367144268]\n",
      "Layer: Layer 1, Input: [-0.9991277028312839, -0.9918343286640563, -0.8350338027611425, 0.9424090367144268], Output: [0.9244933711602412, -0.7714354849057404, 0.9667580418671393, -0.04367079388455883]\n",
      "Layer: Layer 2, Input: [0.9244933711602412, -0.7714354849057404, 0.9667580418671393, -0.04367079388455883], Output: [-0.9495328475088912]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968868754292112, -0.6396785673038592, -0.8637933576731055, 0.9443594201362213]\n",
      "Layer: Layer 1, Input: [-0.9968868754292112, -0.6396785673038592, -0.8637933576731055, 0.9443594201362213], Output: [0.8836010887836802, -0.7220941626089987, 0.9579467291457214, -0.18002462011251102]\n",
      "Layer: Layer 2, Input: [0.8836010887836802, -0.7220941626089987, 0.9579467291457214, -0.18002462011251102], Output: [-0.9821023059266338]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784559574471783, -0.8453861972980662, -0.8941184620429256, 0.2868937029926481]\n",
      "Layer: Layer 1, Input: [-0.9784559574471783, -0.8453861972980662, -0.8941184620429256, 0.2868937029926481], Output: [0.7175293377669588, -0.8785735006565347, 0.9827828491322507, 0.035849428091053515]\n",
      "Layer: Layer 2, Input: [0.7175293377669588, -0.8785735006565347, 0.9827828491322507, 0.035849428091053515], Output: [-0.8805109546402357]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537522690908833, -0.5500688137896607, -0.39281554039944877, 0.28634599549055884]\n",
      "Layer: Layer 1, Input: [-0.9537522690908833, -0.5500688137896607, -0.39281554039944877, 0.28634599549055884], Output: [0.5326066792683758, -0.7229159624650515, 0.964629170291438, 0.10036313916811938]\n",
      "Layer: Layer 2, Input: [0.5326066792683758, -0.7229159624650515, 0.964629170291438, 0.10036313916811938], Output: [-0.9226106155538025]\n",
      "Epoch 31/100, Loss: 1.8779269654926072, Accuracy: -3.0095302024958244\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991276788769198, -0.99184911731296, -0.8350772439911435, 0.9424784166534874]\n",
      "Layer: Layer 1, Input: [-0.9991276788769198, -0.99184911731296, -0.8350772439911435, 0.9424784166534874], Output: [0.9248786084658369, -0.7595425105324789, 0.9670949916792899, -0.0595929307338445]\n",
      "Layer: Layer 2, Input: [0.9248786084658369, -0.7595425105324789, 0.9670949916792899, -0.0595929307338445], Output: [-1.0904723558872884]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968867830972276, -0.6402233948227443, -0.8638311804649581, 0.9444291330934537]\n",
      "Layer: Layer 1, Input: [-0.9968867830972276, -0.6402233948227443, -0.8638311804649581, 0.9444291330934537], Output: [0.8842602471412014, -0.7081504644535359, 0.9583868651781985, -0.19523813647475488]\n",
      "Layer: Layer 2, Input: [0.8842602471412014, -0.7081504644535359, 0.9583868651781985, -0.19523813647475488], Output: [-1.124009106269387]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784553138008996, -0.8456500627810742, -0.8941485867433356, 0.2874902346278375]\n",
      "Layer: Layer 1, Input: [-0.9784553138008996, -0.8456500627810742, -0.8941485867433356, 0.2874902346278375], Output: [0.7191458511391916, -0.8718006009113366, 0.9829513848685986, 0.019880817064270525]\n",
      "Layer: Layer 2, Input: [0.7191458511391916, -0.8718006009113366, 0.9829513848685986, 0.019880817064270525], Output: [-1.0190412911426863]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537509606740244, -0.5507090736480966, -0.3929400026018297, 0.2869303916956563]\n",
      "Layer: Layer 1, Input: [-0.9537509606740244, -0.5507090736480966, -0.3929400026018297, 0.2869303916956563], Output: [0.5351853316482191, -0.7089068669618199, 0.9649853791364645, 0.08462636608013732]\n",
      "Layer: Layer 2, Input: [0.5351853316482191, -0.7089068669618199, 0.9649853791364645, 0.08462636608013732], Output: [-1.0647391304513776]\n",
      "Epoch 32/100, Loss: 2.1622407941880435, Accuracy: -3.2982618837507403\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991278827336587, -0.9918269384144899, -0.8349794332697872, 0.9418795862495307]\n",
      "Layer: Layer 1, Input: [-0.9991278827336587, -0.9918269384144899, -0.8349794332697872, 0.9418795862495307], Output: [0.9238501588701, -0.7702026875666369, 0.9668556305989473, -0.03661956925440735]\n",
      "Layer: Layer 2, Input: [0.9238501588701, -0.7702026875666369, 0.9668556305989473, -0.03661956925440735], Output: [-0.8956399540663644]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968875058467909, -0.6394219143808927, -0.863749955706299, 0.9438515378577849]\n",
      "Layer: Layer 1, Input: [-0.9968875058467909, -0.6394219143808927, -0.863749955706299, 0.9438515378577849], Output: [0.8825992900427329, -0.7205874277758907, 0.9580615980230984, -0.17328361684073754]\n",
      "Layer: Layer 2, Input: [0.8825992900427329, -0.7205874277758907, 0.9580615980230984, -0.17328361684073754], Output: [-0.9283709652271531]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978460263296831, -0.8452635017027309, -0.8940845589303896, 0.2826065852821288]\n",
      "Layer: Layer 1, Input: [-0.978460263296831, -0.8452635017027309, -0.8940845589303896, 0.2826065852821288], Output: [0.7135477389649264, -0.8783445056115351, 0.9829066487913161, 0.043625721644113435]\n",
      "Layer: Layer 2, Input: [0.7135477389649264, -0.8783445056115351, 0.9829066487913161, 0.043625721644113435], Output: [-0.8258025860249928]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537614850169149, -0.5497612346634869, -0.39266853106323774, 0.2820379506740501]\n",
      "Layer: Layer 1, Input: [-0.9537614850169149, -0.5497612346634869, -0.39266853106323774, 0.2820379506740501], Output: [0.526613295129243, -0.722365779844166, 0.9648741628848257, 0.10802704301144855]\n",
      "Layer: Layer 2, Input: [0.526613295129243, -0.722365779844166, 0.9648741628848257, 0.10802704301144855], Output: [-0.868006612382103]\n",
      "Epoch 33/100, Loss: 1.7795937492535148, Accuracy: -3.0094730151963214\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991278740584888, -0.991830204666771, -0.8349884065234658, 0.9419102073715231]\n",
      "Layer: Layer 1, Input: [-0.9991278740584888, -0.991830204666771, -0.8349884065234658, 0.9419102073715231], Output: [0.9239574494312505, -0.7676686819719498, 0.9669264378583733, -0.040384455466866906]\n",
      "Layer: Layer 2, Input: [0.9239574494312505, -0.7676686819719498, 0.9669264378583733, -0.040384455466866906], Output: [-0.9285801736329529]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968874663178028, -0.6395498004802567, -0.8637592097395435, 0.9438844342437689]\n",
      "Layer: Layer 1, Input: [-0.9968874663178028, -0.6395498004802567, -0.8637592097395435, 0.9438844342437689], Output: [0.8827804814860783, -0.7176128092550121, 0.9581545285882446, -0.17689702387200676]\n",
      "Layer: Layer 2, Input: [0.8827804814860783, -0.7176128092550121, 0.9581545285882446, -0.17689702387200676], Output: [-0.9615289988744301]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784599791563227, -0.8453262651130411, -0.8940921732800592, 0.28289012628855664]\n",
      "Layer: Layer 1, Input: [-0.9784599791563227, -0.8453262651130411, -0.8940921732800592, 0.28289012628855664], Output: [0.7140491391165638, -0.8768909223365755, 0.9829392698062572, 0.039827674413957764]\n",
      "Layer: Layer 2, Input: [0.7140491391165638, -0.8768909223365755, 0.9829392698062572, 0.039827674413957764], Output: [-0.8582473438280491]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537609521465616, -0.5499085418393382, -0.39269743519146416, 0.2823061979079901]\n",
      "Layer: Layer 1, Input: [-0.9537609521465616, -0.5499085418393382, -0.39269743519146416, 0.2823061979079901], Output: [0.5273877529329543, -0.7193477524516068, 0.9649441300750752, 0.10428707422317204]\n",
      "Layer: Layer 2, Input: [0.5273877529329543, -0.7193477524516068, 0.9649441300750752, 0.10428707422317204], Output: [-0.9012556857648993]\n",
      "Epoch 34/100, Loss: 1.838942125560719, Accuracy: -3.0100595166953727\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991278595646812, -0.991836803330962, -0.8350076917606776, 0.9419561452166387]\n",
      "Layer: Layer 1, Input: [-0.9991278595646812, -0.991836803330962, -0.8350076917606776, 0.9419561452166387], Output: [0.9241488785999041, -0.7624179873368505, 0.9670703996979394, -0.04762436288657419]\n",
      "Layer: Layer 2, Input: [0.9241488785999041, -0.7624179873368505, 0.9670703996979394, -0.04762436288657419], Output: [-0.9923232256455727]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968874070811822, -0.6397976263994793, -0.8637769027631792, 0.9439317418806432]\n",
      "Layer: Layer 1, Input: [-0.9968874070811822, -0.6397976263994793, -0.8637769027631792, 0.9439317418806432], Output: [0.8831054910017998, -0.711456315895444, 0.958343056366005, -0.18383065158855108]\n",
      "Layer: Layer 2, Input: [0.8831054910017998, -0.711456315895444, 0.958343056366005, -0.18383065158855108], Output: [-1.0257062598349136]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784595614668812, -0.8454468217334359, -0.8941064178654143, 0.2832946337882111]\n",
      "Layer: Layer 1, Input: [-0.9784595614668812, -0.8454468217334359, -0.8941064178654143, 0.2832946337882111], Output: [0.714900147569257, -0.8738933802856581, 0.9830085099457065, 0.03254897538764295]\n",
      "Layer: Layer 2, Input: [0.714900147569257, -0.8738933802856581, 0.9830085099457065, 0.03254897538764295], Output: [-0.9209414453077922]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537601278121038, -0.5501978847598401, -0.3927546827608107, 0.28269731645750096]\n",
      "Layer: Layer 1, Input: [-0.9537601278121038, -0.5501978847598401, -0.3927546827608107, 0.28269731645750096], Output: [0.528723315166691, -0.7131444758933194, 0.9650913679873098, 0.09711928979097398]\n",
      "Layer: Layer 2, Input: [0.528723315166691, -0.7131444758933194, 0.9650913679873098, 0.09711928979097398], Output: [-0.9655605106778372]\n",
      "Epoch 35/100, Loss: 1.9599227558619052, Accuracy: -3.062648550850531\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991278443920667, -0.991825863578967, -0.834979581942582, 0.9420110253175582]\n",
      "Layer: Layer 1, Input: [-0.9991278443920667, -0.991825863578967, -0.834979581942582, 0.9420110253175582], Output: [0.9239731288635871, -0.7727559900719176, 0.9667775489016645, -0.036216099734297943]\n",
      "Layer: Layer 2, Input: [0.9239731288635871, -0.7727559900719176, 0.9667775489016645, -0.036216099734297943], Output: [-0.889278913144979]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996887347094505, -0.6394066718905463, -0.8637545155858807, 0.9439870542202647]\n",
      "Layer: Layer 1, Input: [-0.996887347094505, -0.6394066718905463, -0.8637545155858807, 0.9439870542202647], Output: [0.8827846121739635, -0.7235971029652316, 0.9579629513273233, -0.17290614507952057]\n",
      "Layer: Layer 2, Input: [0.8827846121739635, -0.7235971029652316, 0.9579629513273233, -0.17290614507952057], Output: [-0.9218178042050269]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784591411790448, -0.8452586923961037, -0.8940889399156107, 0.2837657625229417]\n",
      "Layer: Layer 1, Input: [-0.9784591411790448, -0.8452586923961037, -0.8940889399156107, 0.2837657625229417], Output: [0.7144546854812448, -0.8796454199680974, 0.9828459421994447, 0.04380248646223252]\n",
      "Layer: Layer 2, Input: [0.7144546854812448, -0.8796454199680974, 0.9828459421994447, 0.04380248646223252], Output: [-0.8201378757281804]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537592844860918, -0.5497338842801632, -0.3926787949771919, 0.28315807702165535]\n",
      "Layer: Layer 1, Input: [-0.9537592844860918, -0.5497338842801632, -0.3926787949771919, 0.28315807702165535], Output: [0.5279171811379432, -0.7250847612344327, 0.9647519646466886, 0.10818545147582574]\n",
      "Layer: Layer 2, Input: [0.5279171811379432, -0.7250847612344327, 0.9647519646466886, 0.10818545147582574], Output: [-0.861745360831132]\n",
      "Epoch 36/100, Loss: 1.7684833599293526, Accuracy: -3.009068594042904\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991278364676953, -0.991828792732388, -0.8349874709155438, 0.9420395528163534]\n",
      "Layer: Layer 1, Input: [-0.9991278364676953, -0.991828792732388, -0.8349874709155438, 0.9420395528163534], Output: [0.9240713592620888, -0.7705089886751699, 0.9668417081618182, -0.03964851591354628]\n",
      "Layer: Layer 2, Input: [0.9240713592620888, -0.7705089886751699, 0.9668417081618182, -0.03964851591354628], Output: [-0.9192595845749743]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968873100707132, -0.6395224890710038, -0.86376289418066, 0.9440179766330372]\n",
      "Layer: Layer 1, Input: [-0.9968873100707132, -0.6395224890710038, -0.86376289418066, 0.9440179766330372], Output: [0.8829504204165453, -0.7209574745438776, 0.9580471642484324, -0.17620166179270935]\n",
      "Layer: Layer 2, Input: [0.8829504204165453, -0.7209574745438776, 0.9580471642484324, -0.17620166179270935], Output: [-0.9519940845351861]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784588739546336, -0.8453156463234909, -0.8940958685787912, 0.284033194616263]\n",
      "Layer: Layer 1, Input: [-0.9784588739546336, -0.8453156463234909, -0.8940958685787912, 0.284033194616263], Output: [0.7149165545356829, -0.8783553402411975, 0.9828753457418953, 0.04033772378511487]\n",
      "Layer: Layer 2, Input: [0.7149165545356829, -0.8783553402411975, 0.9828753457418953, 0.04033772378511487], Output: [-0.8496807047817736]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953758788859912, -0.5498668741281758, -0.3927047458667383, 0.2834099340812488]\n",
      "Layer: Layer 1, Input: [-0.953758788859912, -0.5498668741281758, -0.3927047458667383, 0.2834099340812488], Output: [0.5286291674014743, -0.7224009553402644, 0.9648151124650669, 0.10477319823560152]\n",
      "Layer: Layer 2, Input: [0.5286291674014743, -0.7224009553402644, 0.9648151124650669, 0.10477319823560152], Output: [-0.8920094542431899]\n",
      "Epoch 37/100, Loss: 1.822039396590759, Accuracy: -3.0095942495012045\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991278241241134, -0.9918339530144409, -0.8350024033292902, 0.9420796859958362]\n",
      "Layer: Layer 1, Input: [-0.9991278241241134, -0.9918339530144409, -0.8350024033292902, 0.9420796859958362], Output: [0.924226834912638, -0.7664976106310857, 0.9669543424284524, -0.045405851343865364]\n",
      "Layer: Layer 2, Input: [0.924226834912638, -0.7664976106310857, 0.9669543424284524, -0.045405851343865364], Output: [-0.9698012795937639]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968872582587103, -0.6397183028867207, -0.8637769846493437, 0.944059747970871]\n",
      "Layer: Layer 1, Input: [-0.9968872582587103, -0.6397183028867207, -0.8637769846493437, 0.944059747970871], Output: [0.8832137928774785, -0.7162500101810326, 0.9581947455678336, -0.1817188482681474]\n",
      "Layer: Layer 2, Input: [0.8832137928774785, -0.7162500101810326, 0.9581947455678336, -0.1817188482681474], Output: [-1.002872210905552]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784585068058931, -0.8454111148137134, -0.8941072754673537, 0.2843917162547486]\n",
      "Layer: Layer 1, Input: [-0.9784585068058931, -0.8454111148137134, -0.8941072754673537, 0.2843917162547486], Output: [0.7156192659671813, -0.8760618552747967, 0.9829288564880104, 0.03454276582947135]\n",
      "Layer: Layer 2, Input: [0.7156192659671813, -0.8760618552747967, 0.9829288564880104, 0.03454276582947135], Output: [-0.8994258806861615]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537580736096108, -0.5500947161054096, -0.39274994039120564, 0.28375465008124523]\n",
      "Layer: Layer 1, Input: [-0.9537580736096108, -0.5500947161054096, -0.39274994039120564, 0.28375465008124523], Output: [0.5297273242486121, -0.7176428444064828, 0.9649291423540497, 0.0990662397445299]\n",
      "Layer: Layer 2, Input: [0.5297273242486121, -0.7176428444064828, 0.9649291423540497, 0.0990662397445299], Output: [-0.9430019610440122]\n",
      "Epoch 38/100, Loss: 1.9163742761953366, Accuracy: -3.016249570857166\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991278840505373, -0.9917338559584944, -0.8347190962057917, 0.9419494840915738]\n",
      "Layer: Layer 1, Input: [-0.9991278840505373, -0.9917338559584944, -0.8347190962057917, 0.9419494840915738], Output: [0.9219629227941709, -0.8391095703533781, 0.9644798297514257, 0.06016977745053601]\n",
      "Layer: Layer 2, Input: [0.9219629227941709, -0.8391095703533781, 0.9644798297514257, 0.06016977745053601], Output: [-0.03597151365103826]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996887465483522, -0.6360975883830405, -0.8635407001209098, 0.9439363102012501]\n",
      "Layer: Layer 1, Input: [-0.996887465483522, -0.6360975883830405, -0.8635407001209098, 0.9439363102012501], Output: [0.8792688758666948, -0.8022875909915419, 0.9549667005612299, -0.07923827173900508]\n",
      "Layer: Layer 2, Input: [0.8792688758666948, -0.8022875909915419, 0.9549667005612299, -0.07923827173900508], Output: [-0.06254596657270625]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784599178899873, -0.8436612019122852, -0.893920832206441, 0.28335382900994105]\n",
      "Layer: Layer 1, Input: [-0.9784599178899873, -0.8436612019122852, -0.893920832206441, 0.28335382900994105], Output: [0.7070822229197293, -0.9162108024149097, 0.9816380342224458, 0.13887570052115777]\n",
      "Layer: Layer 2, Input: [0.7070822229197293, -0.9162108024149097, 0.9816380342224458, 0.13887570052115777], Output: [0.018733374832356195]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537611166444595, -0.5458200568567162, -0.3919617514496297, 0.2827049038448758]\n",
      "Layer: Layer 1, Input: [-0.9537611166444595, -0.5458200568567162, -0.3919617514496297, 0.2827049038448758], Output: [0.5158206632328964, -0.8032640020223036, 0.9622141888447794, 0.20108346631849272]\n",
      "Layer: Layer 2, Input: [0.5158206632328964, -0.8032640020223036, 0.9622141888447794, 0.20108346631849272], Output: [-0.002416375300532597]\n",
      "Epoch 39/100, Loss: 0.9986783300883764, Accuracy: -2.9945752972112207\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991279531179704, -0.991726621968889, -0.8346585468075834, 0.9418576467894735]\n",
      "Layer: Layer 1, Input: [-0.9991279531179704, -0.991726621968889, -0.8346585468075834, 0.9418576467894735], Output: [0.9218973758240658, -0.8394107406496633, 0.9644665799220736, 0.06078819616350809]\n",
      "Layer: Layer 2, Input: [0.9218973758240658, -0.8394107406496633, 0.9644665799220736, 0.06078819616350809], Output: [-0.030739435265914383]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968875451734751, -0.6360180326363861, -0.8635234701099669, 0.9439110735845071]\n",
      "Layer: Layer 1, Input: [-0.9968875451734751, -0.6360180326363861, -0.8635234701099669, 0.9439110735845071], Output: [0.8791818608223133, -0.8026108418915806, 0.9549475110928428, -0.07872919618428717]\n",
      "Layer: Layer 2, Input: [0.8791818608223133, -0.8026108418915806, 0.9549475110928428, -0.07872919618428717], Output: [-0.05753265164885299]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784602105399802, -0.8436422627725452, -0.8939131085221219, 0.28325995859019537]\n",
      "Layer: Layer 1, Input: [-0.9784602105399802, -0.8436422627725452, -0.8939131085221219, 0.28325995859019537], Output: [0.7068840431907198, -0.9163618480505926, 0.9816327946159978, 0.13938827909794368]\n",
      "Layer: Layer 2, Input: [0.7068840431907198, -0.9163618480505926, 0.9816327946159978, 0.13938827909794368], Output: [0.023845903666077098]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537630817823137, -0.5456547160293503, -0.39186719647392926, 0.2823131930321021]\n",
      "Layer: Layer 1, Input: [-0.9537630817823137, -0.5456547160293503, -0.39186719647392926, 0.2823131930321021], Output: [0.5152678566273602, -0.8035589765332684, 0.9622120183717695, 0.20150896365474036]\n",
      "Layer: Layer 2, Input: [0.5152678566273602, -0.8035589765332684, 0.9622120183717695, 0.20150896365474036], Output: [0.0022946240204122365]\n",
      "Epoch 40/100, Loss: 0.9985862344581788, Accuracy: -2.9947580632627266\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991280221301045, -0.9917193853956706, -0.8345980516133018, 0.9417656849404354]\n",
      "Layer: Layer 1, Input: [-0.9991280221301045, -0.9917193853956706, -0.8345980516133018, 0.9417656849404354], Output: [0.9218316410831118, -0.8397183219460047, 0.9644530867650707, 0.06142303497529794]\n",
      "Layer: Layer 2, Input: [0.9218316410831118, -0.8397183219460047, 0.9644530867650707, 0.06142303497529794], Output: [-0.02537959540329461]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968876248821539, -0.6359383596215304, -0.863506246942052, 0.9438857623269081]\n",
      "Layer: Layer 1, Input: [-0.9968876248821539, -0.6359383596215304, -0.863506246942052, 0.9438857623269081], Output: [0.8790945636860752, -0.8029414680624807, 0.9549280182773499, -0.07820465372556377]\n",
      "Layer: Layer 2, Input: [0.8790945636860752, -0.8029414680624807, 0.9549280182773499, -0.07820465372556377], Output: [-0.05239455492317098]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784605036307557, -0.8436232456999395, -0.8939053819148063, 0.28316539754579423]\n",
      "Layer: Layer 1, Input: [-0.9784605036307557, -0.8436232456999395, -0.8939053819148063, 0.28316539754579423], Output: [0.7066849435920813, -0.9165161489990917, 0.9816274464699258, 0.13991580403748777]\n",
      "Layer: Layer 2, Input: [0.7066849435920813, -0.9165161489990917, 0.9816274464699258, 0.13991580403748777], Output: [0.029083323153517984]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537650461790472, -0.5454893039593933, -0.3917727220459768, 0.2819210746587403]\n",
      "Layer: Layer 1, Input: [-0.9537650461790472, -0.5454893039593933, -0.3917727220459768, 0.2819210746587403], Output: [0.5147136280056183, -0.8038602817165076, 0.9622096473365476, 0.20194695646402863]\n",
      "Layer: Layer 2, Input: [0.5147136280056183, -0.8038602817165076, 0.9622096473365476, 0.20194695646402863], Output: [0.0071246950292881694]\n",
      "Epoch 41/100, Loss: 0.9985433128555128, Accuracy: -2.994943668604354\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999128091076203, -0.9917121473645379, -0.834537620026201, 0.9416736126620889]\n",
      "Layer: Layer 1, Input: [-0.999128091076203, -0.9917121473645379, -0.834537620026201, 0.9416736126620889], Output: [0.9217657280145344, -0.8400325451631145, 0.9644393419543033, 0.06207495882987337]\n",
      "Layer: Layer 2, Input: [0.9217657280145344, -0.8400325451631145, 0.9644393419543033, 0.06207495882987337], Output: [-0.01988720917718069]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968877045973012, -0.635858581438961, -0.8634890332574712, 0.9438603801560128]\n",
      "Layer: Layer 1, Input: [-0.9968877045973012, -0.635858581438961, -0.8634890332574712, 0.9438603801560128], Output: [0.8790069968771239, -0.8032797403528196, 0.9549082126846545, -0.0776640030920275]\n",
      "Layer: Layer 2, Input: [0.8790069968771239, -0.8032797403528196, 0.9549082126846545, -0.0776640030920275], Output: [-0.04712700254423134]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784607971179837, -0.8436041535063541, -0.8938976535571216, 0.2830701593585062]\n",
      "Layer: Layer 1, Input: [-0.9784607971179837, -0.8436041535063541, -0.8938976535571216, 0.2830701593585062], Output: [0.7064849518290424, -0.9166738201472417, 0.9816219856702317, 0.14045887850696842]\n",
      "Layer: Layer 2, Input: [0.7064849518290424, -0.9166738201472417, 0.9816219856702317, 0.14045887850696842], Output: [0.03445030004505717]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537670095303299, -0.5453238460951143, -0.3916783427194495, 0.28152860867368806]\n",
      "Layer: Layer 1, Input: [-0.9537670095303299, -0.5453238460951143, -0.3916783427194495, 0.28152860867368806], Output: [0.5141580586065311, -0.8041681441314384, 0.9622070674996186, 0.2023979498217707]\n",
      "Layer: Layer 2, Input: [0.5141580586065311, -0.8041681441314384, 0.9622070674996186, 0.2023979498217707], Output: [0.012078291904227309]\n",
      "Epoch 42/100, Loss: 0.9985533983284345, Accuracy: -2.9951322147737796\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991281599443206, -0.9917049091335978, -0.8344772625054392, 0.9415814458152273]\n",
      "Layer: Layer 1, Input: [-0.9991281599443206, -0.9917049091335978, -0.8344772625054392, 0.9415814458152273], Output: [0.921699647367961, -0.8403536533603722, 0.9644253367455345, 0.06274467080387608]\n",
      "Layer: Layer 2, Input: [0.921699647367961, -0.8403536533603722, 0.9644253367455345, 0.06274467080387608], Output: [-0.01425722912405196]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968877843052084, -0.6357787117059311, -0.8634718320025659, 0.9438349313054346]\n",
      "Layer: Layer 1, Input: [-0.9968877843052084, -0.6357787117059311, -0.8634718320025659, 0.9438349313054346], Output: [0.8789191745703449, -0.8036259440460296, 0.9548880844586924, -0.0771065655007312]\n",
      "Layer: Layer 2, Input: [0.8789191745703449, -0.8036259440460296, 0.9548880844586924, -0.0771065655007312], Output: [-0.041725064072788906]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784610909517482, -0.843584989398842, -0.8938899247628053, 0.2829742596734227]\n",
      "Layer: Layer 1, Input: [-0.9784610909517482, -0.843584989398842, -0.8938899247628053, 0.2829742596734227], Output: [0.7062840997915945, -0.9168349823400123, 0.9816164078799126, 0.14101814024689663]\n",
      "Layer: Layer 2, Input: [0.7062840997915945, -0.9168349823400123, 0.9816164078799126, 0.14101814024689663], Output: [0.03995175688108751]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537689714968524, -0.545158370919372, -0.3915840746992209, 0.2811358623753243]\n",
      "Layer: Layer 1, Input: [-0.9537689714968524, -0.545158370919372, -0.3915840746992209, 0.2811358623753243], Output: [0.5136012405968098, -0.8044828020996583, 0.9622042701185824, 0.20286247750742403]\n",
      "Layer: Layer 2, Input: [0.5136012405968098, -0.8044828020996583, 0.9622042701185824, 0.20286247750742403], Output: [0.017160113133239438]\n",
      "Epoch 43/100, Loss: 0.9986206198782568, Accuracy: -2.995323808799111\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991282287211775, -0.9916976721072409, -0.8344169906750752, 0.941489202189086]\n",
      "Layer: Layer 1, Input: [-0.9991282287211775, -0.9916976721072409, -0.8344169906750752, 0.941489202189086], Output: [0.9216334113403596, -0.8406819025956049, 0.9644110619476313, 0.06343291500845229]\n",
      "Layer: Layer 2, Input: [0.9216334113403596, -0.8406819025956049, 0.9644110619476313, 0.06343291500845229], Output: [-0.008484325828396838]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996887863990563, -0.6356987657164593, -0.8634546464614622, 0.9438094205691686]\n",
      "Layer: Layer 1, Input: [-0.996887863990563, -0.6356987657164593, -0.8634546464614622, 0.9438094205691686], Output: [0.8788311128859464, -0.8039803798937555, 0.9548676232911567, -0.07653162175855542]\n",
      "Layer: Layer 2, Input: [0.8788311128859464, -0.8039803798937555, 0.9548676232911567, -0.07653162175855542], Output: [-0.03618353353962564]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784613850759554, -0.843565757022113, -0.8938821970014529, 0.2828777165369133]\n",
      "Layer: Layer 1, Input: [-0.9784613850759554, -0.843565757022113, -0.8938821970014529, 0.2828777165369133], Output: [0.7060824240112453, -0.916999762798801, 0.9816107085226555, 0.14159426420078378]\n",
      "Layer: Layer 2, Input: [0.7060824240112453, -0.916999762798801, 0.9816107085226555, 0.14159426420078378], Output: [0.04559289085446515]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537709317006966, -0.5449929102669878, -0.3914899360118131, 0.2807429111851185]\n",
      "Layer: Layer 1, Input: [-0.9537709317006966, -0.5449929102669878, -0.3914899360118131, 0.2807429111851185], Output: [0.5130432782437278, -0.804804506532751, 0.962201245907901, 0.203341104176677]\n",
      "Layer: Layer 2, Input: [0.5130432782437278, -0.804804506532751, 0.962201245907901, 0.203341104176677], Output: [0.022375119555310574]\n",
      "Epoch 44/100, Loss: 0.9987494291829022, Accuracy: -2.9955185635879253\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991282973920201, -0.9916904378516233, -0.8343568174456197, 0.9413969017081268]\n",
      "Layer: Layer 1, Input: [-0.9991282973920201, -0.9916904378516233, -0.8343568174456197, 0.9413969017081268], Output: [0.921567033733466, -0.8410175628619293, 0.9643965078912907, 0.06414047976744698]\n",
      "Layer: Layer 2, Input: [0.921567033733466, -0.8410175628619293, 0.9643965078912907, 0.06414047976744698], Output: [-0.002562866748580417]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968879436362804, -0.635618760619901, -0.8634374802914853, 0.9437838533622589]\n",
      "Layer: Layer 1, Input: [-0.9968879436362804, -0.635618760619901, -0.8634374802914853, 0.9437838533622589], Output: [0.8787428301012469, -0.8043433652426086, 0.9548468183931941, -0.07593840908481501]\n",
      "Layer: Layer 2, Input: [0.8787428301012469, -0.8043433652426086, 0.9548468183931941, -0.07593840908481501], Output: [-0.03049690874317386]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978461679427677, -0.8435464605059908, -0.8938744719149784, 0.2827805506625991]\n",
      "Layer: Layer 1, Input: [-0.978461679427677, -0.8435464605059908, -0.8938744719149784, 0.2827805506625991], Output: [0.7058799661714589, -0.9171682955769527, 0.9816048827650353, 0.1421879653950044]\n",
      "Layer: Layer 2, Input: [0.7058799661714589, -0.9171682955769527, 0.9816048827650353, 0.1421879653950044], Output: [0.05137919442434312]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537728897212902, -0.5448274996788393, -0.3913959466954986, 0.2803498395109317]\n",
      "Layer: Layer 1, Input: [-0.9537728897212902, -0.5448274996788393, -0.3913959466954986, 0.2803498395109317], Output: [0.5124842892246876, -0.8051335218339627, 0.9621979849946902, 0.20383442773948435]\n",
      "Layer: Layer 2, Input: [0.5124842892246876, -0.8051335218339627, 0.9621979849946902, 0.20383442773948435], Output: [0.027728554078902762]\n",
      "Epoch 45/100, Loss: 0.9989446301903889, Accuracy: -2.995716598350847\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991283659404663, -0.991683208111962, -0.8342967571497996, 0.9413045666631572]\n",
      "Layer: Layer 1, Input: [-0.9991283659404663, -0.991683208111962, -0.8342967571497996, 0.9413045666631572], Output: [0.9215005301298796, -0.8413609191100527, 0.9643816643950038, 0.06486820110371515]\n",
      "Layer: Layer 2, Input: [0.9215005301298796, -0.8413609191100527, 0.9643816643950038, 0.06486820110371515], Output: [0.003513106959463927]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968880232233145, -0.6355387156205475, -0.8634203375627261, 0.9437582357886459]\n",
      "Layer: Layer 1, Input: [-0.9968880232233145, -0.6355387156205475, -0.8634203375627261, 0.9437582357886459], Output: [0.8786543468876042, -0.8047152352645649, 0.9548256584648852, -0.07532611762207585]\n",
      "Layer: Layer 2, Input: [0.8786543468876042, -0.8047152352645649, 0.9548256584648852, -0.07532611762207585], Output: [-0.024659368588786576]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784619739364142, -0.8435271045184953, -0.8938667513360091, 0.28268278572906547]\n",
      "Layer: Layer 1, Input: [-0.9784619739364142, -0.8435271045184953, -0.8938667513360091, 0.28268278572906547], Output: [0.7056767736789048, -0.9173407220565305, 0.9815989254970484, 0.14280000209755606]\n",
      "Layer: Layer 2, Input: [0.7056767736789048, -0.9173407220565305, 0.9815989254970484, 0.14280000209755606], Output: [0.05731647787839911]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537748450908845, -0.544662178797516, -0.39130212901264677, 0.2799567417118351]\n",
      "Layer: Layer 1, Input: [-0.9537748450908845, -0.544662178797516, -0.39130212901264677, 0.2799567417118351], Output: [0.511924406091728, -0.8054701268817662, 0.9621944768700706, 0.20434308196748766]\n",
      "Layer: Layer 2, Input: [0.511924406091728, -0.8054701268817662, 0.9621944768700706, 0.20434308196748766], Output: [0.033225963266780886]\n",
      "Epoch 46/100, Loss: 0.9992114119444582, Accuracy: -2.9959180390633677\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991284343483303, -0.9916759848318919, -0.8342368256944331, 0.9412122219700343]\n",
      "Layer: Layer 1, Input: [-0.9991284343483303, -0.9916759848318919, -0.8342368256944331, 0.9412122219700343], Output: [0.9214339180903328, -0.8417122723655155, 0.9643665207279597, 0.06561696656960617]\n",
      "Layer: Layer 2, Input: [0.9214339180903328, -0.8417122723655155, 0.9643665207279597, 0.06561696656960617], Output: [0.009749905850149662]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968881027304467, -0.6354586522010756, -0.8634032228023161, 0.9437325747171555]\n",
      "Layer: Layer 1, Input: [-0.9968881027304467, -0.6354586522010756, -0.8634032228023161, 0.9437325747171555], Output: [0.8785656865758724, -0.8050963443025813, 0.9548041316623029, -0.07469388659832563]\n",
      "Layer: Layer 2, Input: [0.8785656865758724, -0.8050963443025813, 0.9548041316623029, -0.07469388659832563], Output: [-0.018664748245176804]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784622685232732, -0.8435076943253063, -0.8938590373084754, 0.2825844487135831]\n",
      "Layer: Layer 1, Input: [-0.9784622685232732, -0.8435076943253063, -0.8938590373084754, 0.2825844487135831], Output: [0.705472900303704, -0.9175171914908901, 0.9815928313107961, 0.14343117928830756]\n",
      "Layer: Layer 2, Input: [0.705472900303704, -0.9175171914908901, 0.9815928313107961, 0.14343117928830756], Output: [0.06341089406666013]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537767972894978, -0.5444969918101086, -0.3912085076872935, 0.2795637231780564]\n",
      "Layer: Layer 1, Input: [-0.9537767972894978, -0.5444969918101086, -0.3912085076872935, 0.2795637231780564], Output: [0.5113637779117609, -0.8058146161043716, 0.9621907103355392, 0.20486773935753094]\n",
      "Layer: Layer 2, Input: [0.5113637779117609, -0.8058146161043716, 0.9621907103355392, 0.20486773935753094], Output: [0.0388732210012417]\n",
      "Epoch 47/100, Loss: 0.9995553850571678, Accuracy: -2.996123018970092\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991285025954286, -0.9916687701751573, -0.8341770407306154, 0.9411198954597016]\n",
      "Layer: Layer 1, Input: [-0.9991285025954286, -0.9916687701751573, -0.8341770407306154, 0.9411198954597016], Output: [0.9213672173750272, -0.8420719409516056, 0.9643510655695566, 0.06638771946264348]\n",
      "Layer: Layer 2, Input: [0.9213672173750272, -0.8420719409516056, 0.9643510655695566, 0.06638771946264348], Output: [0.01615422008828564]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968881821340486, -0.6353785943730936, -0.8633861410440516, 0.9437068778667407]\n",
      "Layer: Layer 1, Input: [-0.9968881821340486, -0.6353785943730936, -0.8633861410440516, 0.9437068778667407], Output: [0.8784768754542858, -0.8054870673445395, 0.9547822255619183, -0.07404080009852111]\n",
      "Layer: Layer 2, Input: [0.8784768754542858, -0.8054870673445395, 0.9547822255619183, -0.07404080009852111], Output: [-0.012506511863117215]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784625631000434, -0.8434882358564817, -0.893851332110695, 0.2824855702667714]\n",
      "Layer: Layer 1, Input: [-0.9784625631000434, -0.8434882358564817, -0.893851332110695, 0.2824855702667714], Output: [0.7052684068981124, -0.9176978615982013, 0.9815865944771025, 0.14408235247780535]\n",
      "Layer: Layer 2, Input: [0.7052684068981124, -0.9176978615982013, 0.9815865944771025, 0.14408235247780535], Output: [0.06966896556036545]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537787457392466, -0.5443319879445431, -0.39111511017137096, 0.27917090154173496]\n",
      "Layer: Layer 1, Input: [-0.9537787457392466, -0.5443319879445431, -0.39111511017137096, 0.27917090154173496], Output: [0.5108025721064984, -0.8061673006554219, 0.9621866734437525, 0.20540911428163985]\n",
      "Layer: Layer 2, Input: [0.5108025721064984, -0.8061673006554219, 0.9621866734437525, 0.20540911428163985], Output: [0.04467655447285242]\n",
      "Epoch 48/100, Loss: 0.9999826223049201, Accuracy: -2.99633167913611\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991285706593603, -0.9916615665499688, -0.8341174218447415, 0.9410276182038796]\n",
      "Layer: Layer 1, Input: [-0.9991285706593603, -0.9916615665499688, -0.8341174218447415, 0.9410276182038796], Output: [0.9213004501923737, -0.8424402618301087, 0.964335286965144, 0.06718146347318739]\n",
      "Layer: Layer 2, Input: [0.9213004501923737, -0.8424402618301087, 0.964335286965144, 0.06718146347318739], Output: [0.022733150137757188]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968882614078167, -0.6352985689585486, -0.8633690978841095, 0.9436811539022573]\n",
      "Layer: Layer 1, Input: [-0.9968882614078167, -0.6352985689585486, -0.8633690978841095, 0.9436811539022573], Output: [0.8783879431032738, -0.8058878016403939, 0.9547599271220999, -0.07336588239757799]\n",
      "Layer: Layer 2, Input: [0.8783879431032738, -0.8058878016403939, 0.9547599271220999, -0.07336588239757799], Output: [-0.006177722566283211]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784628575681585, -0.8434687357814368, -0.8938436382812985, 0.28238618513389]\n",
      "Layer: Layer 1, Input: [-0.9784628575681585, -0.8434687357814368, -0.8938436382812985, 0.28238618513389], Output: [0.7050633622045471, -0.917882899211746, 0.981580208919827, 0.14475443191691323]\n",
      "Layer: Layer 2, Input: [0.7050633622045471, -0.917882899211746, 0.981580208919827, 0.14475443191691323], Output: [0.07609761452429728]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537806897979831, -0.5441672220268868, -0.39102196694357144, 0.2787784080366034]\n",
      "Layer: Layer 1, Input: [-0.9537806897979831, -0.5441672220268868, -0.39102196694357144, 0.2787784080366034], Output: [0.5102409765197501, -0.8065285097024892, 0.962182353433026, 0.20596796645809165]\n",
      "Layer: Layer 2, Input: [0.5102409765197501, -0.8065285097024892, 0.962182353433026, 0.20596796645809165], Output: [0.05064257276941715]\n",
      "Epoch 49/100, Loss: 1.0004997038964913, Accuracy: -2.9965441690508396\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991286385152616, -0.9916543766363928, -0.834057990773309, 0.9409354248814126]\n",
      "Layer: Layer 1, Input: [-0.9991286385152616, -0.9916543766363928, -0.834057990773309, 0.9409354248814126], Output: [0.9212336414789993, -0.8428175920737309, 0.9643191722775695, 0.06799926781758199]\n",
      "Layer: Layer 2, Input: [0.9212336414789993, -0.8428175920737309, 0.9643191722775695, 0.06799926781758199], Output: [0.029494240577103065]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968883405224724, -0.6352186059063404, -0.8633520995437152, 0.9436554125422619]\n",
      "Layer: Layer 1, Input: [-0.9968883405224724, -0.6352186059063404, -0.8633520995437152, 0.9436554125422619], Output: [0.8782989227724273, -0.8062989684794422, 0.9547372226414265, -0.07266809279994507]\n",
      "Layer: Layer 2, Input: [0.8782989227724273, -0.8062989684794422, 0.9547372226414265, -0.07266809279994507], Output: [0.0003289906167459611]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784631518175305, -0.8434492015933525, -0.8938359586483987, 0.282286332629355]\n",
      "Layer: Layer 1, Input: [-0.9784631518175305, -0.8434492015933525, -0.8938359586483987, 0.282286332629355], Output: [0.7048578437655869, -0.9180724809936139, 0.9815736681875934, 0.14544838724560025]\n",
      "Layer: Layer 2, Input: [0.7048578437655869, -0.9180724809936139, 0.9815736681875934, 0.14544838724560025], Output: [0.08270419563162483]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537826287521379, -0.5440027551082045, -0.39092911184544693, 0.27838638902758134]\n",
      "Layer: Layer 1, Input: [-0.9537826287521379, -0.5440027551082045, -0.39092911184544693, 0.27838638902758134], Output: [0.5096792017441323, -0.8068985918415654, 0.9621777366547446, 0.20654510478312788]\n",
      "Layer: Layer 2, Input: [0.5096792017441323, -0.8068985918415654, 0.9621777366547446, 0.20654510478312788], Output: [0.0567782983808964]\n",
      "Epoch 50/100, Loss: 1.0011137680462232, Accuracy: -2.9967606472903716\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991287061355277, -0.9916472034172126, -0.8339987716449084, 0.940843354191078]\n",
      "Layer: Layer 1, Input: [-0.9991287061355277, -0.9916472034172126, -0.8339987716449084, 0.940843354191078], Output: [0.9211668192155094, -0.843204310485953, 0.9643027081340458, 0.06884227291808742]\n",
      "Layer: Layer 2, Input: [0.9211668192155094, -0.843204310485953, 0.9643027081340458, 0.06884227291808742], Output: [0.036445517428849716]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968884194454256, -0.6351387386491976, -0.8633351529397595, 0.9436296646805516]\n",
      "Layer: Layer 1, Input: [-0.9968884194454256, -0.6351387386491976, -0.8633351529397595, 0.9436296646805516], Output: [0.8782098518056699, -0.806721015147011, 0.9547140977134952, -0.07194631992281823]\n",
      "Layer: Layer 2, Input: [0.8782098518056699, -0.806721015147011, 0.9547140977134952, -0.07194631992281823], Output: [0.007021469257883647]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784634457252345, -0.8434296417043665, -0.8938282963624657, 0.2821860571721293]\n",
      "Layer: Layer 1, Input: [-0.9784634457252345, -0.8434296417043665, -0.8938282963624657, 0.2821860571721293], Output: [0.7046519389506067, -0.9182667942193378, 0.9815669654226233, 0.1461652526362478]\n",
      "Layer: Layer 2, Input: [0.7046519389506067, -0.9182667942193378, 0.9815669654226233, 0.1461652526362478], Output: [0.08949653239757174]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537845618086586, -0.5438386551709442, -0.39083658246008945, 0.2779950077346399]\n",
      "Layer: Layer 1, Input: [-0.9537845618086586, -0.5438386551709442, -0.39083658246008945, 0.2779950077346399], Output: [0.5091174837443807, -0.8072779166525811, 0.9621728084927685, 0.20714139156861822]\n",
      "Layer: Layer 2, Input: [0.5091174837443807, -0.8072779166525811, 0.9621728084927685, 0.20714139156861822], Output: [0.0630912019814189]\n",
      "Epoch 51/100, Loss: 1.0018325675850548, Accuracy: -2.996981282245187\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991287734895015, -0.9916400502127638, -0.833939791253368, 0.9407514493176036]\n",
      "Layer: Layer 1, Input: [-0.9991287734895015, -0.9916400502127638, -0.833939791253368, 0.9407514493176036], Output: [0.921100014783222, -0.84360081938632, 0.9642858803677922, 0.06971169670006859]\n",
      "Layer: Layer 2, Input: [0.921100014783222, -0.84360081938632, 0.9642858803677922, 0.06971169670006859], Output: [0.04359552944619223]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968884981403943, -0.635059004506699, -0.8633182657645275, 0.943603922523454]\n",
      "Layer: Layer 1, Input: [-0.9968884981403943, -0.635059004506699, -0.8633182657645275, 0.943603922523454], Output: [0.8781207721216895, -0.8071544170826124, 0.9546905371778798, -0.0711993753505757]\n",
      "Layer: Layer 2, Input: [0.8781207721216895, -0.8071544170826124, 0.9546905371778798, -0.0711993753505757], Output: [0.013908065906403061]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784637391540216, -0.8434100655531274, -0.8938206549334573, 0.2820854088908885]\n",
      "Layer: Layer 1, Input: [-0.9784637391540216, -0.8434100655531274, -0.8938206549334573, 0.2820854088908885], Output: [0.7044457461161135, -0.9184660376420805, 0.9815600933263127, 0.1469061324950873]\n",
      "Layer: Layer 2, Input: [0.7044457461161135, -0.9184660376420805, 0.9815600933263127, 0.1469061324950873], Output: [0.09648295736338994]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537864880859088, -0.5436749979264617, -0.39074442053962044, 0.2776044461792904]\n",
      "Layer: Layer 1, Input: [-0.9537864880859088, -0.5436749979264617, -0.39074442053962044, 0.2776044461792904], Output: [0.5085560868205414, -0.8076668764131226, 0.9621675532737736, 0.20775774723771584]\n",
      "Layer: Layer 2, Input: [0.5085560868205414, -0.8076668764131226, 0.9621675532737736, 0.20775774723771584], Output: [0.06958924090253707]\n",
      "Epoch 52/100, Loss: 1.0026645334595137, Accuracy: -2.9972062529210635\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991288405431176, -0.9916329207203348, -0.833881079366695, 0.9406597584587618]\n",
      "Layer: Layer 1, Input: [-0.9991288405431176, -0.9916329207203348, -0.833881079366695, 0.9406597584587618], Output: [0.921033263367967, -0.8440075465817924, 0.9642686739538218, 0.07060884158761693]\n",
      "Layer: Layer 2, Input: [0.921033263367967, -0.8440075465817924, 0.9642686739538218, 0.07060884158761693], Output: [0.05095339386704102]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968885765669726, -0.634979445141304, -0.8633014465758987, 0.9435781997452068]\n",
      "Layer: Layer 1, Input: [-0.9968885765669726, -0.634979445141304, -0.8633014465758987, 0.9435781997452068], Output: [0.8780317307578562, -0.8075996802648437, 0.954666525066846, -0.07042598657690101]\n",
      "Layer: Layer 2, Input: [0.8780317307578562, -0.8075996802648437, 0.954666525066846, -0.07042598657690101], Output: [0.020997688836370626]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784640319506404, -0.843390483726547, -0.8938130382728314, 0.2819844443093558]\n",
      "Layer: Layer 1, Input: [-0.9784640319506404, -0.843390483726547, -0.8938130382728314, 0.2819844443093558], Output: [0.7042393759196898, -0.9186704224462232, 0.9815530441211386, 0.14767220779504076]\n",
      "Layer: Layer 2, Input: [0.7042393759196898, -0.9186704224462232, 0.9815530441211386, 0.14767220779504076], Output: [0.10367235662671666]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537884066033725, -0.5435118677172286, -0.3906526724887567, 0.27721490738679594]\n",
      "Layer: Layer 1, Input: [-0.9537884066033725, -0.5435118677172286, -0.3906526724887567, 0.27721490738679594], Output: [0.5079953069615305, -0.8080658879900012, 0.9621619541672994, 0.2083951555384169]\n",
      "Layer: Layer 2, Input: [0.5079953069615305, -0.8080658879900012, 0.9621619541672994, 0.2083951555384169], Output: [0.07628090177395881]\n",
      "Epoch 53/100, Loss: 1.0036188461077997, Accuracy: -2.9974357498220874\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991289072585018, -0.9916258190588212, -0.833822669077234, 0.9405683354227419]\n",
      "Layer: Layer 1, Input: [-0.9991289072585018, -0.9916258190588212, -0.833822669077234, 0.9405683354227419], Output: [0.9209666044180675, -0.844424947547839, 0.9642510729381623, 0.07153510229142981]\n",
      "Layer: Layer 2, Input: [0.9209666044180675, -0.844424947547839, 0.9642510729381623, 0.07153510229142981], Output: [0.058528847223476115]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968886546801445, -0.6349001070754279, -0.8632847048996062, 0.9435525116641639]\n",
      "Layer: Layer 1, Input: [-0.9968886546801445, -0.6349001070754279, -0.8632847048996062, 0.9435525116641639], Output: [0.877942780487253, -0.8080573438520796, 0.9546420445473929, -0.06962478913794948]\n",
      "Layer: Layer 2, Input: [0.877942780487253, -0.8080573438520796, 0.9546420445473929, -0.06962478913794948], Output: [0.028299851740108184]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978464323943929, -0.8433709080979127, -0.8938054507411899, 0.2818832271239539]\n",
      "Layer: Layer 1, Input: [-0.978464323943929, -0.8433709080979127, -0.8938054507411899, 0.2818832271239539], Output: [0.7040329528108463, -0.9188801733016666, 0.9815458095084229, 0.1484647431246239]\n",
      "Layer: Layer 2, Input: [0.7040329528108463, -0.9188801733016666, 0.9815458095084229, 0.1484647431246239], Output: [0.1110742192902753]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537903162699854, -0.5433493585395942, -0.39056138991296946, 0.27682661788283014]\n",
      "Layer: Layer 1, Input: [-0.9537903162699854, -0.5433493585395942, -0.39056138991296946, 0.27682661788283014], Output: [0.5074354756481216, -0.8084753949312492, 0.9621559930740889, 0.20905466934422]\n",
      "Layer: Layer 2, Input: [0.5074354756481216, -0.8084753949312492, 0.9621559930740889, 0.20905466934422], Output: [0.08317524788093125]\n",
      "Epoch 54/100, Loss: 1.0047055158671931, Accuracy: -2.997669975925976\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991289735935165, -0.9916187498194429, -0.8337645971994233, 0.9404772403065852]\n",
      "Layer: Layer 1, Input: [-0.9991289735935165, -0.9916187498194429, -0.8337645971994233, 0.9404772403065852], Output: [0.9209000821648693, -0.8448535078465581, 0.9642330603596926, 0.07249197449767356]\n",
      "Layer: Layer 2, Input: [0.9209000821648693, -0.8448535078465581, 0.9642330603596926, 0.07249197449767356], Output: [0.06633230188661726]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968887324297285, -0.6348210422790008, -0.8632680513454245, 0.9435268754430413]\n",
      "Layer: Layer 1, Input: [-0.9968887324297285, -0.6348210422790008, -0.8632680513454245, 0.9435268754430413], Output: [0.8778539805201241, -0.8085279831124362, 0.9546170778581317, -0.0687943178244247]\n",
      "Layer: Layer 2, Input: [0.8778539805201241, -0.8085279831124362, 0.9546170778581317, -0.0687943178244247], Output: [0.03582472903316486]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784646149426507, -0.8433513519838832, -0.8937978972024199, 0.281781829088038]\n",
      "Layer: Layer 1, Input: [-0.9784646149426507, -0.8433513519838832, -0.8937978972024199, 0.281781829088038], Output: [0.7038266167261249, -0.9190955295318635, 0.9815383806214023, 0.14928509455099384]\n",
      "Layer: Layer 2, Input: [0.7038266167261249, -0.9190955295318635, 0.9815383806214023, 0.14928509455099384], Output: [0.11869869249030893]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537922158708799, -0.5431875752057161, -0.3904706302412375, 0.2764398305300557]\n",
      "Layer: Layer 1, Input: [-0.9537922158708799, -0.5431875752057161, -0.3904706302412375, 0.2764398305300557], Output: [0.5068769641746642, -0.8088958697845334, 0.9621496505010667, 0.20973741712201655]\n",
      "Layer: Layer 2, Input: [0.5068769641746642, -0.8088958697845334, 0.9621496505010667, 0.20973741712201655], Output: [0.0902819718734286]\n",
      "Epoch 55/100, Loss: 1.0059354737637491, Accuracy: -2.9979091477634277\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991290395012399, -0.9916117181234785, -0.8337069047226513, 0.9403865402683673]\n",
      "Layer: Layer 1, Input: [-0.9991290395012399, -0.9916117181234785, -0.8337069047226513, 0.9403865402683673], Output: [0.9208337462156427, -0.8452937458133379, 0.9642146181636557, 0.07348106458424579]\n",
      "Layer: Layer 2, Input: [0.9208337462156427, -0.8452937458133379, 0.9642146181636557, 0.07348106458424579], Output: [0.07437490913568665]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996888809759746, -0.6347423088386133, -0.863251497739484, 0.943501310316982]\n",
      "Layer: Layer 1, Input: [-0.996888809759746, -0.6347423088386133, -0.863251497739484, 0.943501310316982], Output: [0.8777653973030398, -0.8090122126817025, 0.9545916062404605, -0.06793299684204335]\n",
      "Layer: Layer 2, Input: [0.8777653973030398, -0.8090122126817025, 0.9545916062404605, -0.06793299684204335], Output: [0.043583217542750574]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784649047330268, -0.8433318303233462, -0.8937903830853645, 0.28168033101948675]\n",
      "Layer: Layer 1, Input: [-0.9784649047330268, -0.8433318303233462, -0.8937903830853645, 0.28168033101948675], Output: [0.7036205250206189, -0.9193167464106099, 0.981530747972975, 0.15013471841113313]\n",
      "Layer: Layer 2, Input: [0.7036205250206189, -0.9193167464106099, 0.981530747972975, 0.15013471841113313], Output: [0.12655664277191053]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537941040522909, -0.54302663466659, -0.3903804574351796, 0.2760548277581418]\n",
      "Layer: Layer 1, Input: [-0.9537941040522909, -0.54302663466659, -0.3903804574351796, 0.2760548277581418], Output: [0.506320188571073, -0.8093278166720062, 0.9621429054210341, 0.2104446101603152]\n",
      "Layer: Layer 2, Input: [0.506320188571073, -0.8093278166720062, 0.9621429054210341, 0.2104446101603152], Output: [0.09761145456401714]\n",
      "Epoch 56/100, Loss: 1.0073206742705088, Accuracy: -2.9981534966149574\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991291049293749, -0.9916047296881387, -0.8336496373280932, 0.9402963104080919]\n",
      "Layer: Layer 1, Input: [-0.9991291049293749, -0.9916047296881387, -0.8336496373280932, 0.9402963104080919], Output: [0.9207676522304735, -0.8457462155485862, 0.9641957271057676, 0.07450410051186691]\n",
      "Layer: Layer 2, Input: [0.9207676522304735, -0.8457462155485862, 0.9641957271057676, 0.07450410051186691], Output: [0.08266862966917914]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968888866077009, -0.6346639717213766, -0.863235057275315, 0.9434758378539027]\n",
      "Layer: Layer 1, Input: [-0.9968888866077009, -0.6346639717213766, -0.863235057275315, 0.9434758378539027], Output: [0.8776771054314869, -0.8095106901941289, 0.9545656098634272, -0.06703912876798561]\n",
      "Layer: Layer 2, Input: [0.8776771054314869, -0.8095106901941289, 0.9545656098634272, -0.06703912876798561], Output: [0.051587005477990125]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784651930759214, -0.8433123598816578, -0.8937829144542362, 0.2815788239514605]\n",
      "Layer: Layer 1, Input: [-0.9784651930759214, -0.8433123598816578, -0.8937829144542362, 0.2815788239514605], Output: [0.7034148546739085, -0.9195440966050014, 0.9815229013973849, 0.15101518116408771]\n",
      "Layer: Layer 2, Input: [0.7034148546739085, -0.9195440966050014, 0.9815229013973849, 0.15101518116408771], Output: [0.1346597247039841]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537959793043317, -0.5428666675220829, -0.3902909427984956, 0.2756719252504519]\n",
      "Layer: Layer 1, Input: [-0.9537959793043317, -0.5428666675220829, -0.3902909427984956, 0.2756719252504519], Output: [0.5057656152213499, -0.8097717741563755, 0.9621357351148307, 0.21117755066629548]\n",
      "Layer: Layer 2, Input: [0.5057656152213499, -0.8097717741563755, 0.9621357351148307, 0.21117755066629548], Output: [0.10517483067203921]\n",
      "Epoch 57/100, Loss: 1.0088742119028307, Accuracy: -2.9984032698407557\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999129169819572, -0.9915977909019125, -0.8335928459800457, 0.9402066347750005]\n",
      "Layer: Layer 1, Input: [-0.999129169819572, -0.9915977909019125, -0.8335928459800457, 0.9402066347750005], Output: [0.9207018626968807, -0.8462115102569985, 0.9641763666456746, 0.07556294406255122]\n",
      "Layer: Layer 2, Input: [0.9207018626968807, -0.8462115102569985, 0.9641763666456746, 0.07556294406255122], Output: [0.09122631262994675]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968889629037552, -0.6345861036490471, -0.8632187446867071, 0.943450482252407]\n",
      "Layer: Layer 1, Input: [-0.9968889629037552, -0.6345861036490471, -0.8632187446867071, 0.943450482252407], Output: [0.8775891886944888, -0.8100241203382799, 0.9545390677415974, -0.06611088212474997]\n",
      "Layer: Layer 2, Input: [0.8775891886944888, -0.8100241203382799, 0.9545390677415974, -0.06611088212474997], Output: [0.05984864973100505]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784654797036195, -0.8432929594844206, -0.8937754980892116, 0.28147741044978125]\n",
      "Layer: Layer 1, Input: [-0.9784654797036195, -0.8432929594844206, -0.8937754980892116, 0.28147741044978125], Output: [0.703209804815393, -0.9197778717847745, 0.9815148299849896, 0.15192817045976104]\n",
      "Layer: Layer 2, Input: [0.703209804815393, -0.9197778717847745, 0.9815148299849896, 0.15192817045976104], Output: [0.14302045777622405]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953797839941284, -0.5427078197486737, -0.39020216590323914, 0.27529147616231964]\n",
      "Layer: Layer 1, Input: [-0.953797839941284, -0.5427078197486737, -0.39020216590323914, 0.27529147616231964], Output: [0.5052137672926356, -0.8102283184386337, 0.9621281149933212, 0.2119376408585845]\n",
      "Layer: Layer 2, Input: [0.5052137672926356, -0.8102283184386337, 0.9621281149933212, 0.2119376408585845], Output: [0.11298406251573478]\n",
      "Epoch 58/100, Loss: 1.0106104538597143, Accuracy: -2.9986587323615477\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991292341066507, -0.9915909089109688, -0.8335365876042855, 0.940117607522328]\n",
      "Layer: Layer 1, Input: [-0.9991292341066507, -0.9915909089109688, -0.8335365876042855, 0.940117607522328], Output: [0.9206364478185012, -0.8466902659839238, 0.9641565148283121, 0.07665960462811355]\n",
      "Layer: Layer 2, Input: [0.9206364478185012, -0.8466902659839238, 0.9641565148283121, 0.07665960462811355], Output: [0.10006178440018122]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968890385697827, -0.6345087861009192, -0.8632025764460499, 0.943425270683546]\n",
      "Layer: Layer 1, Input: [-0.9968890385697827, -0.6345087861009192, -0.8632025764460499, 0.943425270683546], Output: [0.8775017412733801, -0.8105532593989262, 0.9545119576451626, -0.06514627736141937]\n",
      "Layer: Layer 2, Input: [0.8775017412733801, -0.8105532593989262, 0.9545119576451626, -0.06514627736141937], Output: [0.06838166273812667]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784657643161299, -0.8432736502857691, -0.8937681415789245, 0.28137620612480607]\n",
      "Layer: Layer 1, Input: [-0.9784657643161299, -0.8432736502857691, -0.8937681415789245, 0.28137620612480607], Output: [0.7030055996224988, -0.9200183844216214, 0.981506522009112, 0.15287550760683366]\n",
      "Layer: Layer 2, Input: [0.7030055996224988, -0.9200183844216214, 0.981506522009112, 0.15287550760683366], Output: [0.15165231279958633]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953799684078989, -0.5425502546814215, -0.3901142156525917, 0.27491387596000727]\n",
      "Layer: Layer 1, Input: [-0.953799684078989, -0.5425502546814215, -0.3901142156525917, 0.27491387596000727], Output: [0.5046652321102525, -0.8106980669346192, 0.9621200183960976, 0.21272639320466558]\n",
      "Layer: Layer 2, Input: [0.5046652321102525, -0.8106980669346192, 0.9621200183960976, 0.21272639320466558], Output: [0.12105202282623663]\n",
      "Epoch 59/100, Loss: 1.0125451913316392, Accuracy: -2.998920168311295\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991292977177066, -0.9915840917185025, -0.8334809258684063, 0.9400293342345569]\n",
      "Layer: Layer 1, Input: [-0.9991292977177066, -0.9915840917185025, -0.8334809258684063, 0.9400293342345569], Output: [0.920571486537312, -0.8471831658068671, 0.9641361481514862, 0.077796254787617]\n",
      "Layer: Layer 2, Input: [0.920571486537312, -0.8471831658068671, 0.9641361481514862, 0.077796254787617], Output: [0.10918994864362744]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968891135182809, -0.6344321104675579, -0.863186570992548, 0.9434002336839168]\n",
      "Layer: Layer 1, Input: [-0.9968891135182809, -0.6344321104675579, -0.863186570992548, 0.9434002336839168], Output: [0.8774148691211188, -0.8110989203564181, 0.9544842560014288, -0.06414317099448566]\n",
      "Layer: Layer 2, Input: [0.8774148691211188, -0.8110989203564181, 0.9544842560014288, -0.06414317099448566], Output: [0.07720061034723853]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784660465769335, -0.8432544560770556, -0.893760853426904, 0.2812753413710281]\n",
      "Layer: Layer 1, Input: [-0.9784660465769335, -0.8432544560770556, -0.893760853426904, 0.2812753413710281], Output: [0.702802491655532, -0.9202659698060696, 0.9814979648438024, 0.15385916165496494]\n",
      "Layer: Layer 2, Input: [0.702802491655532, -0.9202659698060696, 0.9814979648438024, 0.15385916165496494], Output: [0.16056980924696626]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538015096088395, -0.5423941552937576, -0.39002719150363097, 0.27453956798669044]\n",
      "Layer: Layer 1, Input: [-0.9538015096088395, -0.5423941552937576, -0.39002719150363097, 0.27453956798669044], Output: [0.5041206696403004, -0.811181682285648, 0.9621114163632203, 0.21354544197833752]\n",
      "Layer: Layer 2, Input: [0.5041206696403004, -0.811181682285648, 0.9621114163632203, 0.21354544197833752], Output: [0.12939258806453288]\n",
      "Epoch 60/100, Loss: 1.0146958125956296, Accuracy: -2.9991878828860448\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991293605710793, -0.9915773482992859, -0.8334259320820676, 0.9399419334571438]\n",
      "Layer: Layer 1, Input: [-0.9991293605710793, -0.9915773482992859, -0.8334259320820676, 0.9399419334571438], Output: [0.9205070677127067, -0.8476909445503666, 0.9641152414177163, 0.07897524795653989]\n",
      "Layer: Layer 2, Input: [0.9205070677127067, -0.8476909445503666, 0.9641152414177163, 0.07897524795653989], Output: [0.11862689933962772]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889187651116, -0.6343561793818383, -0.8631707489955645, 0.943375405609068]\n",
      "Layer: Layer 1, Input: [-0.996889187651116, -0.6343561793818383, -0.8631707489955645, 0.943375405609068], Output: [0.8773286915537398, -0.8116619786275855, 0.9544559377867168, -0.06309923761450788]\n",
      "Layer: Layer 2, Input: [0.8773286915537398, -0.8116619786275855, 0.9544559377867168, -0.06309923761450788], Output: [0.08632122239889749]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784663261080758, -0.8432354036430324, -0.893753643174413, 0.28117496337418413]\n",
      "Layer: Layer 1, Input: [-0.9784663261080758, -0.8432354036430324, -0.893753643174413, 0.28117496337418413], Output: [0.7026007657055293, -0.9205209883143579, 0.981489144871131, 0.1548812653458452]\n",
      "Layer: Layer 2, Input: [0.7026007657055293, -0.9205209883143579, 0.981489144871131, 0.1548812653458452], Output: [0.16978862523067695]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538033141677754, -0.542239726827348, -0.3899412048782807, 0.27416904988285606]\n",
      "Layer: Layer 1, Input: [-0.9538033141677754, -0.542239726827348, -0.3899412048782807, 0.27416904988285606], Output: [0.503580822273185, -0.811679876868162, 0.9621022773756313, 0.21439655634468194]\n",
      "Layer: Layer 2, Input: [0.503580822273185, -0.811679876868162, 0.9621022773756313, 0.21439655634468194], Output: [0.1380207438726802]\n",
      "Epoch 61/100, Loss: 1.0170815016286996, Accuracy: -2.9994622044172665\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991294225751591, -0.991570688732147, -0.8333716862387501, 0.9398555384647006]\n",
      "Layer: Layer 1, Input: [-0.9991294225751591, -0.991570688732147, -0.8333716862387501, 0.9398555384647006], Output: [0.9204432914854349, -0.8482143941048081, 0.9640937675680454, 0.08019913844373212]\n",
      "Layer: Layer 2, Input: [0.9204432914854349, -0.8482143941048081, 0.9640937675680454, 0.08019913844373212], Output: [0.12839004887786468]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968892608580688, -0.6342811082591164, -0.8631551336594294, 0.9433508251579877]\n",
      "Layer: Layer 1, Input: [-0.9968892608580688, -0.6342811082591164, -0.8631551336594294, 0.9433508251579877], Output: [0.8772433430919376, -0.8122433785474531, 0.9544269764075841, -0.062011949409082785]\n",
      "Layer: Layer 2, Input: [0.8772433430919376, -0.8122433785474531, 0.9544269764075841, -0.062011949409082785], Output: [0.09576051804635721]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784666024844915, -0.8432165231740336, -0.8937465215426446, 0.28107523843366317]\n",
      "Layer: Layer 1, Input: [-0.9784666024844915, -0.8432165231740336, -0.8937465215426446, 0.28107523843366317], Output: [0.7024007432468584, -0.9207838279635625, 0.9814800473763828, 0.1559441332355206]\n",
      "Layer: Layer 2, Input: [0.7024007432468584, -0.9207838279635625, 0.9814800473763828, 0.1559441332355206], Output: [0.1793257221286338]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538050951035649, -0.5420871998348891, -0.38985638079638024, 0.2738028810143649]\n",
      "Layer: Layer 1, Input: [-0.9538050951035649, -0.5420871998348891, -0.38985638079638024, 0.2738028810143649], Output: [0.5030465261404939, -0.8121934178790496, 0.9620925670590411, 0.2152816552189076]\n",
      "Layer: Layer 2, Input: [0.5030465261404939, -0.8121934178790496, 0.9620925670590411, 0.2152816552189076], Output: [0.14695270459415666]\n",
      "Epoch 62/100, Loss: 1.0197234667194501, Accuracy: -2.9997434867029695\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991294836270009, -0.9915641243536549, -0.8333182782251191, 0.939770299311023]\n",
      "Layer: Layer 1, Input: [-0.9991294836270009, -0.9915641243536549, -0.8333182782251191, 0.939770299311023], Output: [0.9203802708602074, -0.8487543694447125, 0.9640716974951202, 0.08147070431738111]\n",
      "Layer: Layer 2, Input: [0.9203802708602074, -0.8487543694447125, 0.9640716974951202, 0.08147070431738111], Output: [0.13849827367814582]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968893330151503, -0.6342070270849918, -0.8631397510773724, 0.9433265359816843]\n",
      "Layer: Layer 1, Input: [-0.9968893330151503, -0.6342070270849918, -0.8631397510773724, 0.9433265359816843], Output: [0.8771589755986416, -0.8128441407095592, 0.9543973435701388, -0.06087855278436202]\n",
      "Layer: Layer 2, Input: [0.8771589755986416, -0.8128441407095592, 0.9543973435701388, -0.06087855278436202], Output: [0.10553694822680132]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978466875227413, -0.8431978487444453, -0.8937395005978526, 0.28097635465788595]\n",
      "Layer: Layer 1, Input: [-0.978466875227413, -0.8431978487444453, -0.8937395005978526, 0.28097635465788595], Output: [0.7022027876053153, -0.9210549073003058, 0.9814706564292166, 0.15705028234889962]\n",
      "Layer: Layer 2, Input: [0.7022027876053153, -0.9210549073003058, 0.9814706564292166, 0.15705028234889962], Output: [0.18919948625569036]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538068494345022, -0.5419368337117934, -0.3897728597719258, 0.27344169109328875]\n",
      "Layer: Layer 1, Input: [-0.9538068494345022, -0.5419368337117934, -0.3897728597719258, 0.27344169109328875], Output: [0.5025187242456817, -0.8127231330875424, 0.9620822478450621, 0.21620282419294765]\n",
      "Layer: Layer 2, Input: [0.5025187242456817, -0.8127231330875424, 0.9620822478450621, 0.21620282419294765], Output: [0.1562060491686263]\n",
      "Epoch 63/100, Loss: 1.022645204480145, Accuracy: -3.0000321116357194\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991295436107115, -0.991557667936996, -0.8332658092297109, 0.9396863852135047]\n",
      "Layer: Layer 1, Input: [-0.9991295436107115, -0.991557667936996, -0.8332658092297109, 0.9396863852135047], Output: [0.920318133547926, -0.8493117954602966, 0.9640489998323571, 0.08279297356119399]\n",
      "Layer: Layer 2, Input: [0.920318133547926, -0.8493117954602966, 0.9640489998323571, 0.08279297356119399], Output: [0.14897208028452746]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968894039826366, -0.6341340824973237, -0.8631246306438839, 0.9433025873916259]\n",
      "Layer: Layer 1, Input: [-0.9968894039826366, -0.6341340824973237, -0.8631246306438839, 0.9433025873916259], Output: [0.8770757607681904, -0.8134653703052815, 0.9543670091360563, -0.059696041583422274]\n",
      "Layer: Layer 2, Input: [0.8770757607681904, -0.8134653703052815, 0.9543670091360563, -0.059696041583422274], Output: [0.11567055817092925]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784671437966977, -0.8431794188699292, -0.8937325939437591, 0.2808785251025299]\n",
      "Layer: Layer 1, Input: [-0.9784671437966977, -0.8431794188699292, -0.8937325939437591, 0.2808785251025299], Output: [0.7020073099759306, -0.9213346786770235, 0.9814609547484862, 0.15820245579911993]\n",
      "Layer: Layer 2, Input: [0.7020073099759306, -0.9213346786770235, 0.9814609547484862, 0.15820245579911993], Output: [0.19942989044813514]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538085738024629, -0.5417889208089615, -0.38969080002236356, 0.27308619021612623]\n",
      "Layer: Layer 1, Input: [-0.9538085738024629, -0.5417889208089615, -0.38969080002236356, 0.27308619021612623], Output: [0.5019984817484933, -0.8132699173619881, 0.9620712785820996, 0.21716233488200917]\n",
      "Layer: Layer 2, Input: [0.5019984817484933, -0.8132699173619881, 0.9620712785820996, 0.21716233488200917], Output: [0.16579987616070108]\n",
      "Epoch 64/100, Loss: 1.0258728058046511, Accuracy: -3.0003284921738356\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991296023955609, -0.9915513339008916, -0.8332143933896359, 0.9396039873358539]\n",
      "Layer: Layer 1, Input: [-0.9991296023955609, -0.9915513339008916, -0.8332143933896359, 0.9396039873358539], Output: [0.9202570241174057, -0.8498876747385855, 0.9640256407154199, 0.08416925410086236]\n",
      "Layer: Layer 2, Input: [0.9202570241174057, -0.8498876747385855, 0.9640256407154199, 0.08416925410086236], Output: [0.1598337954813097]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968894736027735, -0.6340624402194133, -0.8631098055368637, 0.9432790351872422]\n",
      "Layer: Layer 1, Input: [-0.9968894736027735, -0.6340624402194133, -0.8631098055368637, 0.9432790351872422], Output: [0.8769938930348542, -0.8141082666303654, 0.9543359409637291, -0.058461126296001545]\n",
      "Layer: Layer 2, Input: [0.8769938930348542, -0.8141082666303654, 0.9543359409637291, -0.058461126296001545], Output: [0.12618317342378088]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784674075818575, -0.8431612771586019, -0.8937258169465396, 0.2807819914366687]\n",
      "Layer: Layer 1, Input: [-0.9784674075818575, -0.8431612771586019, -0.8937258169465396, 0.2807819914366687], Output: [0.7018147764539371, -0.9216236319803707, 0.9814509235479583, 0.15940364989310435]\n",
      "Layer: Layer 2, Input: [0.7018147764539371, -0.9216236319803707, 0.9814509235479583, 0.15940364989310435], Output: [0.21003867901105133]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538102644180365, -0.5416437912390698, -0.38961038005182846, 0.27273718059320967]\n",
      "Layer: Layer 1, Input: [-0.9538102644180365, -0.5416437912390698, -0.38961038005182846, 0.27273718059320967], Output: [0.5014870038170469, -0.8138347401011726, 0.9620596140869562, 0.2181626671152588]\n",
      "Layer: Layer 2, Input: [0.5014870038170469, -0.8138347401011726, 0.9620596140869562, 0.2181626671152588], Output: [0.17575498124285066]\n",
      "Epoch 65/100, Loss: 1.0294353117417456, Accuracy: -3.000633075710672\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991296598337704, -0.9915451385544936, -0.8331641597227725, 0.9395233220472387]\n",
      "Layer: Layer 1, Input: [-0.9991296598337704, -0.9915451385544936, -0.8331641597227725, 0.9395233220472387], Output: [0.9201971065175962, -0.8504830964581062, 0.9640015835115067, 0.08560316840374055]\n",
      "Layer: Layer 2, Input: [0.9201971065175962, -0.8504830964581062, 0.9640015835115067, 0.08560316840374055], Output: [0.17110778472101615]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889541697083, -0.6339922879140634, -0.863095313283491, 0.9432559426259848]\n",
      "Layer: Layer 1, Input: [-0.996889541697083, -0.6339922879140634, -0.863095313283491, 0.9432559426259848], Output: [0.8769135929836227, -0.8147741339611986, 0.95430410473277, -0.05717019852496449]\n",
      "Layer: Layer 2, Input: [0.8769135929836227, -0.8147741339611986, 0.95430410473277, -0.05717019852496449], Output: [0.13709861357681558]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784676658915401, -0.8431434730747771, -0.8937191869988899, 0.28068702824087804]\n",
      "Layer: Layer 1, Input: [-0.9784676658915401, -0.8431434730747771, -0.8937191869988899, 0.28068702824087804], Output: [0.7016257162788789, -0.9219222988894673, 0.9814405423596045, 0.1606571453547997]\n",
      "Layer: Layer 2, Input: [0.7016257162788789, -0.9219222988894673, 0.9814405423596045, 0.1606571453547997], Output: [0.22104958020032728]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953811916996149, -0.5415018185141688, -0.38953180168305246, 0.2723955703047586]\n",
      "Layer: Layer 1, Input: [-0.953811916996149, -0.5415018185141688, -0.38953180168305246, 0.2723955703047586], Output: [0.5009856565540443, -0.8144186537263212, 0.9620472046261554, 0.21920653448430358]\n",
      "Layer: Layer 2, Input: [0.5009856565540443, -0.8144186537263212, 0.9620472046261554, 0.21920653448430358], Output: [0.1860940611486834]\n",
      "Epoch 66/100, Loss: 1.033365129038314, Accuracy: -3.000946347907443\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991297157579043, -0.9915391003855742, -0.8331152544039859, 0.9394446347538512]\n",
      "Layer: Layer 1, Input: [-0.9991297157579043, -0.9915391003855742, -0.8331152544039859, 0.9394446347538512], Output: [0.9201385670453248, -0.8510992465957629, 0.9639767885110588, 0.08709869350846605]\n",
      "Layer: Layer 2, Input: [0.9201385670453248, -0.8510992465957629, 0.9639767885110588, 0.08709869350846605], Output: [0.1828207040825598]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968896080631932, -0.6339238385444249, -0.8630811964270072, 0.9432333815648544]\n",
      "Layer: Layer 1, Input: [-0.9968896080631932, -0.6339238385444249, -0.8630811964270072, 0.9432333815648544], Output: [0.8768351113653046, -0.8154643940461698, 0.9542714637498537, -0.055819289813057116]\n",
      "Layer: Layer 2, Input: [0.8768351113653046, -0.8154643940461698, 0.9542714637498537, -0.055819289813057116], Output: [0.14844293882007234]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978467917941139, -0.8431260628381847, -0.8937127238311945, 0.28059394806525223]\n",
      "Layer: Layer 1, Input: [-0.978467917941139, -0.8431260628381847, -0.8937127238311945, 0.28059394806525223], Output: [0.7014407315378538, -0.9222312577579973, 0.9814297888304405, 0.16196654343538283]\n",
      "Layer: Layer 2, Input: [0.7014407315378538, -0.9222312577579973, 0.9814297888304405, 0.16196654343538283], Output: [0.23248855131356616]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538135266802327, -0.5413634261843775, -0.3894552936301283, 0.27206238949674316]\n",
      "Layer: Layer 1, Input: [-0.9538135266802327, -0.5413634261843775, -0.3894552936301283, 0.27206238949674316], Output: [0.5004959916200565, -0.815022803422847, 0.9620339953135619, 0.22029691387499295]\n",
      "Layer: Layer 2, Input: [0.5004959916200565, -0.815022803422847, 0.9620339953135619, 0.22029691387499295], Output: [0.19684194898303248]\n",
      "Epoch 67/100, Loss: 1.0376985173585487, Accuracy: -3.0012688370680465\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991297699777835, -0.9915332404010524, -0.8330678434579827, 0.939368204421481]\n",
      "Layer: Layer 1, Input: [-0.9991297699777835, -0.9915332404010524, -0.8330678434579827, 0.939368204421481], Output: [0.9200816178513287, -0.8517374196878518, 0.9639512125753915, 0.08866020753507432]\n",
      "Layer: Layer 2, Input: [0.9200816178513287, -0.8517374196878518, 0.9639512125753915, 0.08866020753507432], Output: [0.19500179214620264]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889672471085, -0.6338573343480243, -0.8630675033157306, 0.9432114338091506]\n",
      "Layer: Layer 1, Input: [-0.996889672471085, -0.6338573343480243, -0.8630675033157306, 0.9432114338091506], Output: [0.8767587338422074, -0.8161806005110964, 0.9542379787336018, -0.05440402372939742]\n",
      "Layer: Layer 2, Input: [0.8767587338422074, -0.8161806005110964, 0.9542379787336018, -0.05440402372939742], Output: [0.16024473556743707]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784681628381459, -0.8431091104870252, -0.8937064498797441, 0.2805031074055137]\n",
      "Layer: Layer 1, Input: [-0.9784681628381459, -0.8431091104870252, -0.8937064498797441, 0.2805031074055137], Output: [0.7012605086321065, -0.9225511392346495, 0.9814186384880086, 0.16333580785332413]\n",
      "Layer: Layer 2, Input: [0.7012605086321065, -0.9225511392346495, 0.9814186384880086, 0.16333580785332413], Output: [0.24438406260033896]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538150879525285, -0.5412290956880544, -0.3893811157265173, 0.2717388095282896]\n",
      "Layer: Layer 1, Input: [-0.9538150879525285, -0.5412290956880544, -0.3893811157265173, 0.2717388095282896], Output: [0.5000197753243248, -0.8156484383622753, 0.9620199254077981, 0.22143707974903679]\n",
      "Layer: Layer 2, Input: [0.5000197753243248, -0.8156484383622753, 0.9620199254077981, 0.22143707974903679], Output: [0.20802588687121693]\n",
      "Epoch 68/100, Loss: 1.042476163044906, Accuracy: -3.001601119150356\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999129822276821, -0.9915275825311267, -0.8330221159593969, 0.9392943489364489]\n",
      "Layer: Layer 1, Input: [-0.999129822276821, -0.9915275825311267, -0.8330221159593969, 0.9392943489364489], Output: [0.9200265010999563, -0.8523990324419788, 0.9639248087323699, 0.09029254397237758]\n",
      "Layer: Layer 2, Input: [0.9200265010999563, -0.8523990324419788, 0.9639248087323699, 0.09029254397237758], Output: [0.20768320965460343]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889734658636, -0.6337930515565969, -0.8630542890409181, 0.9431901927129368]\n",
      "Layer: Layer 1, Input: [-0.996889734658636, -0.6337930515565969, -0.8630542890409181, 0.9431901927129368], Output: [0.8766847866215604, -0.8169244555455507, 0.9542036075758997, -0.0529195598556421]\n",
      "Layer: Layer 2, Input: [0.8766847866215604, -0.8169244555455507, 0.9542036075758997, -0.0529195598556421], Output: [0.17253544886009906]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978468399564751, -0.8430926891401871, -0.8937003907244158, 0.2804149137939292]\n",
      "Layer: Layer 1, Input: [-0.978468399564751, -0.8430926891401871, -0.8937003907244158, 0.2804149137939292], Output: [0.7010858318854549, -0.9228826327622595, 0.9814070644684947, 0.16476931372764872]\n",
      "Layer: Layer 2, Input: [0.7010858318854549, -0.9228826327622595, 0.9814070644684947, 0.16476931372764872], Output: [0.256767427644063]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538165945275076, -0.5410993756757132, -0.38930956395109984, 0.2714261657082707]\n",
      "Layer: Layer 1, Input: [-0.9538165945275076, -0.5410993756757132, -0.38930956395109984, 0.2714261657082707], Output: [0.49955902314157696, -0.8162969246870921, 0.9620049274890591, 0.2226306441209155]\n",
      "Layer: Layer 2, Input: [0.49955902314157696, -0.8162969246870921, 0.9620049274890591, 0.2226306441209155], Output: [0.21967584332107498]\n",
      "Epoch 69/100, Loss: 1.047743857945134, Accuracy: -3.0019438235284834\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991298724076428, -0.9915221541111331, -0.8329782878539106, 0.9392234314891588]\n",
      "Layer: Layer 1, Input: [-0.9991298724076428, -0.9915221541111331, -0.8329782878539106, 0.9392234314891588], Output: [0.9199734939269647, -0.8530856395665657, 0.9638975257105035, 0.09200105535479641]\n",
      "Layer: Layer 2, Input: [0.9199734939269647, -0.8530856395665657, 0.9638975257105035, 0.09200105535479641], Output: [0.22090043672700602]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968897943263019, -0.6337313060280751, -0.8630416165569117, 0.9431697650869338]\n",
      "Layer: Layer 1, Input: [-0.9968897943263019, -0.6337313060280751, -0.8630416165569117, 0.9431697650869338], Output: [0.8766136431735623, -0.8176978293234296, 0.9541683050766546, -0.051360527979094996]\n",
      "Layer: Layer 2, Input: [0.8766136431735623, -0.8176978293234296, 0.9541683050766546, -0.051360527979094996], Output: [0.18534977111194784]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784686269570833, -0.8430768825028911, -0.8936945756114104, 0.28032983425122027]\n",
      "Layer: Layer 1, Input: [-0.9784686269570833, -0.8430768825028911, -0.8936945756114104, 0.28032983425122027], Output: [0.7009175997683812, -0.9232264941290201, 0.9813950372000603, 0.16627190494997557]\n",
      "Layer: Layer 2, Input: [0.7009175997683812, -0.9232264941290201, 0.9813950372000603, 0.16627190494997557], Output: [0.2696731897133594]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953818039224632, -0.5409748931367461, -0.38924097643172234, 0.27112598442072966]\n",
      "Layer: Layer 1, Input: [-0.953818039224632, -0.5409748931367461, -0.38924097643172234, 0.27112598442072966], Output: [0.49911604085486816, -0.816969760608107, 0.9619889264899173, 0.22388160340477756]\n",
      "Layer: Layer 2, Input: [0.49911604085486816, -0.816969760608107, 0.9619889264899173, 0.22388160340477756], Output: [0.2318248844527696]\n",
      "Epoch 70/100, Loss: 1.0535533065475535, Accuracy: -3.0022976396455316\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991299200868344, -0.99151698645894, -0.8329366065443434, 0.9391558682121991]\n",
      "Layer: Layer 1, Input: [-0.9991299200868344, -0.99151698645894, -0.8329366065443434, 0.9391558682121991], Output: [0.9199229143774065, -0.8537989522746707, 0.9638693073996143, 0.09379168834855996]\n",
      "Layer: Layer 2, Input: [0.9199229143774065, -0.8537989522746707, 0.9638693073996143, 0.09379168834855996], Output: [0.23469273984558775]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889851130733, -0.6336724600008433, -0.8630295580258692, 0.9431502734840853]\n",
      "Layer: Layer 1, Input: [-0.996889851130733, -0.6336724600008433, -0.8630295580258692, 0.9431502734840853], Output: [0.8765457322823607, -0.8185027827225156, 0.9541320226485592, -0.049720950369644065]\n",
      "Layer: Layer 2, Input: [0.8765457322823607, -0.8185027827225156, 0.9541320226485592, -0.049720950369644065], Output: [0.19872609916231757]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784688436803107, -0.8430617866716382, -0.8936890380807684, 0.2802484054096559]\n",
      "Layer: Layer 1, Input: [-0.9784688436803107, -0.8430617866716382, -0.8936890380807684, 0.2802484054096559], Output: [0.7007568443350559, -0.9235835542876458, 0.981382524032156, 0.16784896180568679]\n",
      "Layer: Layer 2, Input: [0.7007568443350559, -0.9235835542876458, 0.981382524032156, 0.16784896180568679], Output: [0.28313957596540185]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538194138156704, -0.5408563667447113, -0.3891757406533317, 0.27084001564890864]\n",
      "Layer: Layer 1, Input: [-0.9538194138156704, -0.5408563667447113, -0.3891757406533317, 0.27084001564890864], Output: [0.4986934738370648, -0.8176685940500851, 0.9619718385482512, 0.22519439360231389]\n",
      "Layer: Layer 2, Input: [0.4986934738370648, -0.8176685940500851, 0.9619718385482512, 0.22519439360231389], Output: [0.24450961055398127]\n",
      "Epoch 71/100, Loss: 1.059963090802982, Accuracy: -3.0026633247281502\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991299649885995, -0.9915121155705238, -0.8328973564251566, 0.9390921373670941]\n",
      "Layer: Layer 1, Input: [-0.9991299649885995, -0.9915121155705238, -0.8328973564251566, 0.9390921373670941], Output: [0.91987512855465, -0.8545408600360361, 0.9638400922233656, 0.09567107279965255]\n",
      "Layer: Layer 2, Input: [0.91987512855465, -0.8545408600360361, 0.9638400922233656, 0.09567107279965255], Output: [0.24910372403379738]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889904677076, -0.6336169302376434, -0.8630181964410057, 0.943131858952011]\n",
      "Layer: Layer 1, Input: [-0.996889904677076, -0.6336169302376434, -0.8630181964410057, 0.943131858952011], Output: [0.87648154774547, -0.8193415940527166, 0.9540947079878798, -0.047994149455106085]\n",
      "Layer: Layer 2, Input: [0.87648154774547, -0.8193415940527166, 0.9540947079878798, -0.047994149455106085], Output: [0.21270707473687883]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784690481986197, -0.8430475123094823, -0.8936838167238066, 0.28017124570104507]\n",
      "Layer: Layer 1, Input: [-0.9784690481986197, -0.8430475123094823, -0.8936838167238066, 0.28017124570104507], Output: [0.7006047546316964, -0.9239547297137238, 0.9813694887992398, 0.16950648113070138]\n",
      "Layer: Layer 2, Input: [0.7006047546316964, -0.9239547297137238, 0.9813694887992398, 0.16950648113070138], Output: [0.29720903449692815]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538207088404771, -0.5407446229504107, -0.38911430216027526, 0.270570272182545]\n",
      "Layer: Layer 1, Input: [-0.9538207088404771, -0.5407446229504107, -0.38911430216027526, 0.270570272182545], Output: [0.4982943663916828, -0.8183952433937386, 0.9619535696419863, 0.22657395568954597]\n",
      "Layer: Layer 2, Input: [0.4982943663916828, -0.8183952433937386, 0.9619535696419863, 0.22657395568954597], Output: [0.25777067242531004]\n",
      "Epoch 72/100, Loss: 1.0670398300673045, Accuracy: -3.0030417127746993\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991300067370635, -0.991507582962739, -0.8328608656010753, 0.9390327904555459]\n",
      "Layer: Layer 1, Input: [-0.9991300067370635, -0.991507582962739, -0.8328608656010753, 0.9390327904555459], Output: [0.9198305592761696, -0.8553134563055993, 0.9638098124052049, 0.09764662799884317]\n",
      "Layer: Layer 2, Input: [0.9198305592761696, -0.8553134563055993, 0.9638098124052049, 0.09764662799884317], Output: [0.2641819898724512]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889954509633, -0.6335651979021726, -0.8630076275976547, 0.9431146843665716]\n",
      "Layer: Layer 1, Input: [-0.996889954509633, -0.6335651979021726, -0.8630076275976547, 0.9431146843665716], Output: [0.8764216601257291, -0.8202167906934309, 0.9540563047066138, -0.046172637466791226]\n",
      "Layer: Layer 2, Input: [0.8764216601257291, -0.8202167906934309, 0.9540563047066138, -0.046172637466791226], Output: [0.22734022755746267]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784692387388033, -0.8430341872826809, -0.893678956102775, 0.2800990701133622]\n",
      "Layer: Layer 1, Input: [-0.9784692387388033, -0.8430341872826809, -0.893678956102775, 0.2800990701133622], Output: [0.7004627050470001, -0.9243410346474286, 0.981355891304228, 0.17125117191879594]\n",
      "Layer: Layer 2, Input: [0.7004627050470001, -0.9243410346474286, 0.981355891304228, 0.17125117191879594], Output: [0.31192887334915254]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953821913383408, -0.5406406155019289, -0.38905717512506577, 0.2703190771560999]\n",
      "Layer: Layer 1, Input: [-0.953821913383408, -0.5406406155019289, -0.38905717512506577, 0.2703190771560999], Output: [0.4979222336115038, -0.8191517220103662, 0.9619340139542226, 0.22802581357149726]\n",
      "Layer: Layer 2, Input: [0.4979222336115038, -0.8191517220103662, 0.9619340139542226, 0.22802581357149726], Output: [0.27165338595303296]\n",
      "Epoch 73/100, Loss: 1.074859584282432, Accuracy: -3.0034337250811314\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991300448968673, -0.9915034367007876, -0.8328275140954101, 0.9389784657396386]\n",
      "Layer: Layer 1, Input: [-0.9991300448968673, -0.9915034367007876, -0.8328275140954101, 0.9389784657396386], Output: [0.9197896966177114, -0.8561190691625182, 0.9637783931043311, 0.0997266903586677]\n",
      "Layer: Layer 2, Input: [0.9197896966177114, -0.8561190691625182, 0.9637783931043311, 0.0997266903586677], Output: [0.27998192064896843]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968900001004549, -0.6335178206123669, -0.8629979625020366, 0.9430989384940733]\n",
      "Layer: Layer 1, Input: [-0.9968900001004549, -0.6335178206123669, -0.8629979625020366, 0.9430989384940733], Output: [0.876366731077942, -0.8211311867948028, 0.9540167519204852, -0.04424798363410927]\n",
      "Layer: Layer 2, Input: [0.876366731077942, -0.8211311867948028, 0.9540167519204852, -0.04424798363410927], Output: [0.24267874587695357]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784694132458263, -0.8430219598764379, -0.8936745078746219, 0.280032708166171]\n",
      "Layer: Layer 1, Input: [-0.9784694132458263, -0.8430219598764379, -0.8936745078746219, 0.280032708166171], Output: [0.7003322898580869, -0.9247435956601028, 0.9813416867029121, 0.17309057013411236]\n",
      "Layer: Layer 2, Input: [0.7003322898580869, -0.9247435956601028, 0.9813416867029121, 0.17309057013411236], Output: [0.3273520260687227]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538230148002314, -0.5405454492709785, -0.38900495526656237, 0.27008912204988084]\n",
      "Layer: Layer 1, Input: [-0.9538230148002314, -0.5405454492709785, -0.38900495526656237, 0.27008912204988084], Output: [0.49758114892915223, -0.8199402674834785, 0.9619130519024824, 0.22955616765713102]\n",
      "Layer: Layer 2, Input: [0.49758114892915223, -0.8199402674834785, 0.9619130519024824, 0.22955616765713102], Output: [0.2862084686597298]\n",
      "Epoch 74/100, Loss: 1.083509562842124, Accuracy: -3.0038403826369775\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991300789616008, -0.9914997326593288, -0.8327977439481132, 0.9389299048014177]\n",
      "Layer: Layer 1, Input: [-0.9991300789616008, -0.9914997326593288, -0.8327977439481132, 0.9389299048014177], Output: [0.9197531108431365, -0.8569602980722483, 0.9637457513916585, 0.10192066796993526]\n",
      "Layer: Layer 2, Input: [0.9197531108431365, -0.8569602980722483, 0.9637457513916585, 0.10192066796993526], Output: [0.2965646325935229]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968900408353188, -0.6334754472506686, -0.8629893303354409, 0.9430848409744862]\n",
      "Layer: Layer 1, Input: [-0.9968900408353188, -0.6334754472506686, -0.8629893303354409, 0.9430848409744862], Output: [0.8763175309313964, -0.8220879285414381, 0.9539759837860724, -0.04221065316164929]\n",
      "Layer: Layer 2, Input: [0.8763175309313964, -0.8220879285414381, 0.9539759837860724, -0.04221065316164929], Output: [0.2587824067198752]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784695693282225, -0.8430110027434451, -0.8936705321737002, 0.27997312595211155]\n",
      "Layer: Layer 1, Input: [-0.9784695693282225, -0.8430110027434451, -0.8936705321737002, 0.27997312595211155], Output: [0.7002153656060259, -0.92516366911905, 0.9813268247650374, 0.17503317762088205]\n",
      "Layer: Layer 2, Input: [0.7002153656060259, -0.92516366911905, 0.9813268247650374, 0.17503317762088205], Output: [0.3435379758778187]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538239983822574, -0.5404604095351553, -0.3889583357502285, 0.26988353793950287]\n",
      "Layer: Layer 1, Input: [-0.9538239983822574, -0.5404604095351553, -0.3889583357502285, 0.26988353793950287], Output: [0.4972758514973313, -0.8207633766803868, 0.9618905477457821, 0.2311720080335995]\n",
      "Layer: Layer 2, Input: [0.4972758514973313, -0.8207633766803868, 0.9618905477457821, 0.2311720080335995], Output: [0.3014929291900982]\n",
      "Epoch 75/100, Loss: 1.0930902210457656, Accuracy: -3.0042628208140734\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301083394589, -0.9914965360817886, -0.832772071732908, 0.9388879729707442]\n",
      "Layer: Layer 1, Input: [-0.9991301083394589, -0.9914965360817886, -0.832772071732908, 0.9388879729707442], Output: [0.9197214683749069, -0.8578400583669912, 0.9637117950266679, 0.10423922925564454]\n",
      "Layer: Layer 2, Input: [0.9197214683749069, -0.8578400583669912, 0.9637117950266679, 0.10423922925564454], Output: [0.3139991316988283]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968900759963543, -0.6334388362978428, -0.862981882129639, 0.943072648479219]\n",
      "Layer: Layer 1, Input: [-0.9968900759963543, -0.6334388362978428, -0.862981882129639, 0.943072648479219], Output: [0.8762749604264523, -0.823090548949405, 0.9539339289787022, -0.040049810372]\n",
      "Layer: Layer 2, Input: [0.8762749604264523, -0.823090548949405, 0.9539339289787022, -0.040049810372], Output: [0.27571870844200447]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784697041904986, -0.8430015177880652, -0.8936670993259964, 0.27992145336043345]\n",
      "Layer: Layer 1, Input: [-0.9784697041904986, -0.8430015177880652, -0.8936670993259964, 0.27992145336043345], Output: [0.7001141034540828, -0.9256026623052961, 0.9813112489801625, 0.17708863156645355]\n",
      "Layer: Layer 2, Input: [0.7001141034540828, -0.9256026623052961, 0.9813112489801625, 0.17708863156645355], Output: [0.3605538807653011]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538248469401315, -0.5403869982352025, -0.3889181269082162, 0.2697059836719818]\n",
      "Layer: Layer 1, Input: [-0.9538248469401315, -0.5403869982352025, -0.3889181269082162, 0.2697059836719818], Output: [0.497011878849761, -0.8216238482069825, 0.9618663466557904, 0.23288125249493502]\n",
      "Layer: Layer 2, Input: [0.497011878849761, -0.8216238482069825, 0.9618663466557904, 0.23288125249493502], Output: [0.31757115061676067]\n",
      "Epoch 76/100, Loss: 1.1037178528287375, Accuracy: -3.0047023068917165\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301323353179, -0.9914939235240192, -0.8327511042023388, 0.9388536847240576]\n",
      "Layer: Layer 1, Input: [-0.9991301323353179, -0.9914939235240192, -0.8327511042023388, 0.9388536847240576], Output: [0.9196955516780705, -0.8587616355754388, 0.9636764209833738, 0.10669453538815167]\n",
      "Layer: Layer 2, Input: [0.9196955516780705, -0.8587616355754388, 0.9636764209833738, 0.10669453538815167], Output: [0.3323637353868153]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968901047403463, -0.6334088787151466, -0.8629757953622857, 0.9430626623815882]\n",
      "Layer: Layer 1, Input: [-0.9968901047403463, -0.6334088787151466, -0.8629757953622857, 0.9430626623815882], Output: [0.8762400778037114, -0.8241430348274624, 0.9538905101002698, -0.03775307581050773]\n",
      "Layer: Layer 2, Input: [0.8762400778037114, -0.8241430348274624, 0.9538905101002698, -0.03775307581050773], Output: [0.2935642626970424]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784698145487648, -0.8429937422570599, -0.8936642919920964, 0.2798790179701799]\n",
      "Layer: Layer 1, Input: [-0.9784698145487648, -0.8429937422570599, -0.8936642919920964, 0.2798790179701799], Output: [0.7000310543996984, -0.9260621591932866, 0.9812948954658547, 0.17926791316146024]\n",
      "Layer: Layer 2, Input: [0.7000310543996984, -0.9260621591932866, 0.9812948954658547, 0.17926791316146024], Output: [0.3784759561818066]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538255402837824, -0.5403269792386185, -0.3888852809019484, 0.26956075588383305]\n",
      "Layer: Layer 1, Input: [-0.9538255402837824, -0.5403269792386185, -0.3888852809019484, 0.26956075588383305], Output: [0.49679573210924066, -0.8225248342985907, 0.9618402711001524, 0.2346929164683012]\n",
      "Layer: Layer 2, Input: [0.49679573210924066, -0.8225248342985907, 0.9618402711001524, 0.2346929164683012], Output: [0.3345162223649002]\n",
      "Epoch 77/100, Loss: 1.1155278259051045, Accuracy: -3.0051602611271333\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301501281222, -0.9914919852988098, -0.8327355580226269, 0.9388282355400686]\n",
      "Layer: Layer 1, Input: [-0.9991301501281222, -0.9914919852988098, -0.8327355580226269, 0.9388282355400686], Output: [0.9196762842365271, -0.8597287524970713, 0.9636395136555662, 0.10930052962478069]\n",
      "Layer: Layer 2, Input: [0.9196762842365271, -0.8597287524970713, 0.9636395136555662, 0.10930052962478069], Output: [0.35174783837154233]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968901260713857, -0.633386626763236, -0.8629712797557192, 0.9430552383969835]\n",
      "Layer: Layer 1, Input: [-0.9968901260713857, -0.633386626763236, -0.8629712797557192, 0.9430552383969835], Output: [0.876214132866482, -0.8252499094745517, 0.9538456430022795, -0.035306223422210875]\n",
      "Layer: Layer 2, Input: [0.876214132866482, -0.8252499094745517, 0.9538456430022795, -0.035306223422210875], Output: [0.31240652357211407]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784698965244655, -0.8429879564035656, -0.8936622078708573, 0.27984738762292]\n",
      "Layer: Layer 1, Input: [-0.9784698965244655, -0.8429879564035656, -0.8936622078708573, 0.27984738762292], Output: [0.6999692312200615, -0.9265439522648612, 0.981277691620747, 0.18158360722010974]\n",
      "Layer: Layer 2, Input: [0.6999692312200615, -0.9265439522648612, 0.981277691620747, 0.18158360722010974], Output: [0.39739119254693067]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538260545666402, -0.5402824353622648, -0.38886092285189533, 0.26945292751766947]\n",
      "Layer: Layer 1, Input: [-0.9538260545666402, -0.5402824353622648, -0.38886092285189533, 0.26945292751766947], Output: [0.4966350835584044, -0.823469904943943, 0.9618121163319807, 0.2366173244354801]\n",
      "Layer: Layer 2, Input: [0.4966350835584044, -0.823469904943943, 0.9618121163319807, 0.2366173244354801], Output: [0.3524115954380176]\n",
      "Epoch 78/100, Loss: 1.1286786587253692, Accuracy: -3.0056382823094854\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301607420674, -0.9914908285811441, -0.8327262849233206, 0.9388130422449341]\n",
      "Layer: Layer 1, Input: [-0.9991301607420674, -0.9914908285811441, -0.8327262849233206, 0.9388130422449341], Output: [0.9196647622376583, -0.8607456530315529, 0.9636009426450695, 0.11207330179827873]\n",
      "Layer: Layer 2, Input: [0.9196647622376583, -0.8607456530315529, 0.9636009426450695, 0.11207330179827873], Output: [0.37225413284023645]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968901388060418, -0.6333733306673952, -0.8629685846698021, 0.9430507988197918]\n",
      "Layer: Layer 1, Input: [-0.9968901388060418, -0.6333733306673952, -0.8629685846698021, 0.9430507988197918], Output: [0.8761986102416749, -0.8264163360572442, 0.9537992360030605, -0.032692798547275435]\n",
      "Layer: Layer 2, Input: [0.8761986102416749, -0.8264163360572442, 0.9537992360030605, -0.032692798547275435], Output: [0.3323459618320851]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784699455091679, -0.8429844932282807, -0.8936609631456736, 0.2798284244326445]\n",
      "Layer: Layer 1, Input: [-0.9784699455091679, -0.8429844932282807, -0.8936609631456736, 0.2798284244326445], Output: [0.699932212474954, -0.9270500822610833, 0.9812595544431222, 0.18405022906764767]\n",
      "Layer: Layer 2, Input: [0.699932212474954, -0.9270500822610833, 0.9812595544431222, 0.18405022906764767], Output: [0.4173995147373951]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538263614502083, -0.5402558409404864, -0.3888463905365917, 0.26938852398826246]\n",
      "Layer: Layer 1, Input: [-0.9538263614502083, -0.5402558409404864, -0.3888463905365917, 0.26938852398826246], Output: [0.4965390400329111, -0.8244631281292796, 0.9617816447013756, 0.23866637617820602]\n",
      "Layer: Layer 2, Input: [0.4965390400329111, -0.8244631281292796, 0.9617816447013756, 0.23866637617820602], Output: [0.37135316466788404]\n",
      "Epoch 79/100, Loss: 1.1433572159243288, Accuracy: -3.0061381790613595\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301630094483, -0.9914905813974251, -0.8327243041181667, 0.9388097946744789]\n",
      "Layer: Layer 1, Input: [-0.9991301630094483, -0.9914905813974251, -0.8327243041181667, 0.9388097946744789], Output: [0.9196622952195291, -0.8618172084421358, 0.9635605599970138, 0.1150315537794387]\n",
      "Layer: Layer 2, Input: [0.9196622952195291, -0.8618172084421358, 0.9635605599970138, 0.1150315537794387], Output: [0.3940014390994163]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968901415285029, -0.6333704858010951, -0.8629680086365104, 0.9430498482325022]\n",
      "Layer: Layer 1, Input: [-0.9968901415285029, -0.6333704858010951, -0.8629680086365104, 0.9430498482325022], Output: [0.87619528494761, -0.8276482486603055, 0.9537511889672795, -0.02989362948580202]\n",
      "Layer: Layer 2, Input: [0.87619528494761, -0.8276482486603055, 0.9537511889672795, -0.02989362948580202], Output: [0.3534988373616662]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784699559905381, -0.8429837510026579, -0.8936606969283667, 0.27982435408383083]\n",
      "Layer: Layer 1, Input: [-0.9784699559905381, -0.8429837510026579, -0.8936606969283667, 0.27982435408383083], Output: [0.6999242760004598, -0.9275828885719021, 0.9812403884030685, 0.18668464178585562]\n",
      "Layer: Layer 2, Input: [0.6999242760004598, -0.9275828885719021, 0.9812403884030685, 0.18668464178585562], Output: [0.43861653554738445]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538264270274719, -0.5402501552372597, -0.3888432856088049, 0.2693747497960477]\n",
      "Layer: Layer 1, Input: [-0.9538264270274719, -0.5402501552372597, -0.3888432856088049, 0.2693747497960477], Output: [0.4965184809143168, -0.8255091717269054, 0.9617485783893253, 0.24085388676237135]\n",
      "Layer: Layer 2, Input: [0.4965184809143168, -0.8255091717269054, 0.9617485783893253, 0.24085388676237135], Output: [0.39145192518445293]\n",
      "Epoch 80/100, Loss: 1.159785413566257, Accuracy: -3.006662008625182\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301555221314, -0.9914913978164299, -0.8327308446495306, 0.9388205226647744]\n",
      "Layer: Layer 1, Input: [-0.9991301555221314, -0.9914913978164299, -0.8327308446495306, 0.9388205226647744], Output: [0.9196704588884378, -0.8629490542987105, 0.963518196684443, 0.11819720335539613]\n",
      "Layer: Layer 2, Input: [0.9196704588884378, -0.8629490542987105, 0.963518196684443, 0.11819720335539613], Output: [0.4171283736100959]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968901325320326, -0.6333798942015523, -0.862969911819461, 0.9430529939338582]\n",
      "Layer: Layer 1, Input: [-0.9968901325320326, -0.6333798942015523, -0.862969911819461, 0.9430529939338582], Output: [0.8762062946993103, -0.8289525211528223, 0.9537013921966754, -0.02688619313471273]\n",
      "Layer: Layer 2, Input: [0.8762062946993103, -0.8289525211528223, 0.9537013921966754, -0.02688619313471273], Output: [0.37600079234678074]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784699213254243, -0.8429862095797788, -0.8936615770654286, 0.2798378559072694]\n",
      "Layer: Layer 1, Input: [-0.9784699213254243, -0.8429862095797788, -0.8936615770654286, 0.2798378559072694], Output: [0.6999505724857622, -0.928145074191757, 0.981220082706145, 0.18950659732009872]\n",
      "Layer: Layer 2, Input: [0.6999505724857622, -0.928145074191757, 0.981220082706145, 0.18950659732009872], Output: [0.4611771240593868]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953826210417258, -0.5402689442638924, -0.38885354054478616, 0.2694202838440301]\n",
      "Layer: Layer 1, Input: [-0.953826210417258, -0.5402689442638924, -0.38885354054478616, 0.2694202838440301], Output: [0.4965864974448622, -0.8266134350828682, 0.9617125899891135, 0.24319602778037036]\n",
      "Layer: Layer 2, Input: [0.4965864974448622, -0.8266134350828682, 0.9617125899891135, 0.24319602778037036], Output: [0.41283741721631084]\n",
      "Epoch 81/100, Loss: 1.1782289999712634, Accuracy: -3.007212125579761\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301365672058, -0.9914934648047617, -0.8327474015325036, 0.9388476841933985]\n",
      "Layer: Layer 1, Input: [-0.9991301365672058, -0.9914934648047617, -0.8327474015325036, 0.9388476841933985], Output: [0.9196911647795045, -0.864147770421914, 0.9634736580454933, 0.12159618236619081]\n",
      "Layer: Layer 2, Input: [0.9196911647795045, -0.864147770421914, 0.9634736580454933, 0.12159618236619081], Output: [0.4417981936644405]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968901097414079, -0.6334037459875255, -0.862974732544103, 0.943060972904051]\n",
      "Layer: Layer 1, Input: [-0.9968901097414079, -0.6334037459875255, -0.862974732544103, 0.943060972904051], Output: [0.8762342354163689, -0.8303371890073526, 0.9536497250457621, -0.023643775841513087]\n",
      "Layer: Layer 2, Input: [0.8762342354163689, -0.8303371890073526, 0.9536497250457621, -0.023643775841513087], Output: [0.4000115980039808]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978469833439465, -0.8429924519620735, -0.8936638078403839, 0.27987218175025375]\n",
      "Layer: Layer 1, Input: [-0.978469833439465, -0.8429924519620735, -0.8936638078403839, 0.27987218175025375], Output: [0.7000173545887066, -0.9287397911243668, 0.9811985077069817, 0.19253945144817694]\n",
      "Layer: Layer 2, Input: [0.7000173545887066, -0.9287397911243668, 0.9811985077069817, 0.19253945144817694], Output: [0.48524011932284006]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538256619011037, -0.540316542042934, -0.3888795074943758, 0.26953567010620644]\n",
      "Layer: Layer 1, Input: [-0.9538256619011037, -0.540316542042934, -0.3888795074943758, 0.26953567010620644], Output: [0.49675897228846366, -0.8277822223958172, 0.9616732900864785, 0.24571191105604046]\n",
      "Layer: Layer 2, Input: [0.49675897228846366, -0.8277822223958172, 0.9616732900864785, 0.24571191105604046], Output: [0.43566227963835114]\n",
      "Epoch 82/100, Loss: 1.1990092514527622, Accuracy: -3.0077912440240295\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991301040401418, -0.9914970114389987, -0.8327758115155757, 0.9388942833538518]\n",
      "Layer: Layer 1, Input: [-0.9991301040401418, -0.9914970114389987, -0.8327758115155757, 0.9388942833538518], Output: [0.9197267537576043, -0.865421122857939, 0.9634267177108996, 0.12525951512541006]\n",
      "Layer: Layer 2, Input: [0.9197267537576043, -0.865421122857939, 0.9634267177108996, 0.12525951512541006], Output: [0.468205342752708]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968900706083286, -0.6334447290390416, -0.8629830096200937, 0.9430746880319794]\n",
      "Layer: Layer 1, Input: [-0.9968900706083286, -0.6334447290390416, -0.8629830096200937, 0.9430746880319794], Output: [0.8762822896324867, -0.8318117474217628, 0.9535960541096996, -0.020134338910051394]\n",
      "Layer: Layer 2, Input: [0.8762822896324867, -0.8318117474217628, 0.9535960541096996, -0.020134338910051394], Output: [0.42572156914864945]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784696824223147, -0.8430031933325102, -0.8936676403747659, 0.2799313156879454]\n",
      "Layer: Layer 1, Input: [-0.9784696824223147, -0.8430031933325102, -0.8936676403747659, 0.2799313156879454], Output: [0.7001322847849033, -0.9293707553464453, 0.9811755101002838, 0.19581112971026862]\n",
      "Layer: Layer 2, Input: [0.7001322847849033, -0.9293707553464453, 0.9811755101002838, 0.19581112971026862], Output: [0.5109946998765753]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538247204098315, -0.5403982678777199, -0.38892407829840187, 0.26973384361390407]\n",
      "Layer: Layer 1, Input: [-0.9538247204098315, -0.5403982678777199, -0.38892407829840187, 0.26973384361390407], Output: [0.49705535761620634, -0.8290229766581315, 0.9616302105467704, 0.24842437859583436]\n",
      "Layer: Layer 2, Input: [0.49705535761620634, -0.8290229766581315, 0.9616302105467704, 0.24842437859583436], Output: [0.4601084077621298]\n",
      "Epoch 83/100, Loss: 1.2225188661591742, Accuracy: -3.008402518510387\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999130055325111, -0.9915023215434253, -0.832818357465863, 0.9389640315351482]\n",
      "Layer: Layer 1, Input: [-0.999130055325111, -0.9915023215434253, -0.832818357465863, 0.9389640315351482], Output: [0.9197801241883717, -0.8667783984145367, 0.9633771092710809, 0.12922481475393094]\n",
      "Layer: Layer 2, Input: [0.9197801241883717, -0.8667783984145367, 0.9633771092710809, 0.12922481475393094], Output: [0.49658453745298187]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968900119673859, -0.6335061798966632, -0.8629954131258304, 0.9430952578261688]\n",
      "Layer: Layer 1, Input: [-0.9968900119673859, -0.6335061798966632, -0.8629954131258304, 0.9430952578261688], Output: [0.8763544028470732, -0.8333875631590842, 0.9535402307014287, -0.016318944064420443]\n",
      "Layer: Layer 2, Input: [0.8763544028470732, -0.8333875631590842, 0.9535402307014287, -0.016318944064420443], Output: [0.4533604721408089]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784694559705476, -0.8430193209749629, -0.8936733869734882, 0.2800201933099503]\n",
      "Layer: Layer 1, Input: [-0.9784694559705476, -0.8430193209749629, -0.8936733869734882, 0.2800201933099503], Output: [0.7003048579476251, -0.930042405986832, 0.9811509062917224, 0.19935546780331165]\n",
      "Layer: Layer 2, Input: [0.7003048579476251, -0.930042405986832, 0.9811509062917224, 0.19935546780331165], Output: [0.5386692285667702]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538233100611213, -0.5405207252693924, -0.3889908500407495, 0.27003085366376567]\n",
      "Layer: Layer 1, Input: [-0.9538233100611213, -0.5405207252693924, -0.3889908500407495, 0.27003085366376567], Output: [0.4974997418814956, -0.8303446044423283, 0.9615827814717005, 0.2513611014207522]\n",
      "Layer: Layer 2, Input: [0.4974997418814956, -0.8303446044423283, 0.9615827814717005, 0.2513611014207522], Output: [0.48639551133820885]\n",
      "Epoch 84/100, Loss: 1.2492440889061456, Accuracy: -3.0090496519163885\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991299871258503, -0.9915097514682091, -0.8328779158641486, 0.9390615732172929]\n",
      "Layer: Layer 1, Input: [-0.9991299871258503, -0.9915097514682091, -0.8328779158641486, 0.9390615732172929], Output: [0.9198549122199229, -0.8682308829510205, 0.9633245144041246, 0.1335384275949294]\n",
      "Layer: Layer 2, Input: [0.9198549122199229, -0.8682308829510205, 0.9633245144041246, 0.1335384275949294], Output: [0.5272238060736959]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968899298325978, -0.6335922967587163, -0.8630127879565417, 0.9431240864144479]\n",
      "Layer: Layer 1, Input: [-0.9968899298325978, -0.6335922967587163, -0.8630127879565417, 0.9431240864144479], Output: [0.8764555320899886, -0.8350784627708306, 0.9534820870714587, -0.012149497259656918]\n",
      "Layer: Layer 2, Input: [0.8764555320899886, -0.8350784627708306, 0.9534820870714587, -0.012149497259656918], Output: [0.48321031148594695]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784691386009225, -0.843041950617908, -0.8936814414243701, 0.28014501094443334]\n",
      "Layer: Layer 1, Input: [-0.9784691386009225, -0.843041950617908, -0.8936814414243701, 0.28014501094443334], Output: [0.700546996830885, -0.930760133370208, 0.9811244729455136, 0.20321413331003654]\n",
      "Layer: Layer 2, Input: [0.700546996830885, -0.930760133370208, 0.9811244729455136, 0.20321413331003654], Output: [0.5685439475915959]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538213352673741, -0.5406922237372735, -0.38908435926844365, 0.2704468839155688]\n",
      "Layer: Layer 1, Input: [-0.9538213352673741, -0.5406922237372735, -0.38908435926844365, 0.2704468839155688], Output: [0.498122350406973, -0.8317579426126239, 0.9615302984736747, 0.2545561600740749]\n",
      "Layer: Layer 2, Input: [0.498122350406973, -0.8317579426126239, 0.9615302984736747, 0.2545561600740749], Output: [0.5147934094909894]\n",
      "Epoch 85/100, Loss: 1.279796427160322, Accuracy: -3.0097370435128576\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991298952190515, -0.991519755890137, -0.8329581717917663, 0.9391928123249594]\n",
      "Layer: Layer 1, Input: [-0.9991298952190515, -0.991519755890137, -0.8329581717917663, 0.9391928123249594], Output: [0.9199557536526075, -0.869792573806959, 0.9632685451653004, 0.1382586313260267]\n",
      "Layer: Layer 2, Input: [0.9199557536526075, -0.869792573806959, 0.9632685451653004, 0.1382586313260267], Output: [0.5604839707367051]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968898191007859, -0.6337084498389466, -0.8630362173926386, 0.9431629653445381]\n",
      "Layer: Layer 1, Input: [-0.9968898191007859, -0.6337084498389466, -0.8630362173926386, 0.9431629653445381], Output: [0.8765920078091164, -0.8369016077349659, 0.9534214302662909, -0.007565385750067685]\n",
      "Layer: Layer 2, Input: [0.8765920078091164, -0.8369016077349659, 0.9534214302662909, -0.007565385750067685], Output: [0.515624444087041]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784687105032644, -0.8430725085842986, -0.8936923086488161, 0.2803136765609138]\n",
      "Layer: Layer 1, Input: [-0.9784687105032644, -0.8430725085842986, -0.8936923086488161, 0.2803136765609138], Output: [0.7008739191997746, -0.9315306195800557, 0.9810959329320196, 0.20743949400835932]\n",
      "Layer: Layer 2, Input: [0.7008739191997746, -0.9315306195800557, 0.9810959329320196, 0.20743949400835932], Output: [0.6009699541765698]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538186736037925, -0.5409233930787614, -0.3892104238722445, 0.2710077375777384]\n",
      "Layer: Layer 1, Input: [-0.9538186736037925, -0.5409233930787614, -0.3892104238722445, 0.2710077375777384], Output: [0.49896172485702683, -0.8332764577144415, 0.9614718744683373, 0.2580524136221709]\n",
      "Layer: Layer 2, Input: [0.49896172485702683, -0.8332764577144415, 0.9614718744683373, 0.2580524136221709], Output: [0.545640427714288]\n",
      "Epoch 86/100, Loss: 1.3149598026493272, Accuracy: -3.010469999812618\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991297740804025, -0.9915329267642218, -0.8330639448191121, 0.9393654030849216]\n",
      "Layer: Layer 1, Input: [-0.9991297740804025, -0.9915329267642218, -0.8330639448191121, 0.9393654030849216], Output: [0.9200886802590283, -0.8714812959956906, 0.9632087160354159, 0.14346064760286661]\n",
      "Layer: Layer 2, Input: [0.9200886802590283, -0.8714812959956906, 0.9632087160354159, 0.14346064760286661], Output: [0.5968292565381814]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996889673101551, -0.633861652181745, -0.8630671196439159, 0.9432142278480491]\n",
      "Layer: Layer 1, Input: [-0.996889673101551, -0.633861652181745, -0.8630671196439159, 0.9432142278480491], Output: [0.876772082969394, -0.8388788637847392, 0.9533580312817646, -0.002488212332903742]\n",
      "Layer: Layer 2, Input: [0.876772082969394, -0.8388788637847392, 0.9533580312817646, -0.002488212332903742], Output: [0.5510576274776866]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784681457986876, -0.8431128566259661, -0.8937066497838917, 0.28053649610614817]\n",
      "Layer: Layer 1, Input: [-0.9784681457986876, -0.8431128566259661, -0.8937066497838917, 0.28053649610614817], Output: [0.7013054546214718, -0.932362373724838, 0.9810649333245507, 0.21209911935493814]\n",
      "Layer: Layer 2, Input: [0.7013054546214718, -0.932362373724838, 0.9810649333245507, 0.21209911935493814], Output: [0.6363990275212303]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538151649921768, -0.5412281141540556, -0.38937666215247513, 0.2717470883951756]\n",
      "Layer: Layer 1, Input: [-0.9538151649921768, -0.5412281141540556, -0.38937666215247513, 0.2717470883951756], Output: [0.5000680205990758, -0.8349173494838935, 0.9614063653255622, 0.2619052374671284]\n",
      "Layer: Layer 2, Input: [0.5000680205990758, -0.8349173494838935, 0.9614063653255622, 0.2619052374671284], Output: [0.5793723494263306]\n",
      "Epoch 87/100, Loss: 1.3557639524599547, Accuracy: -3.011255049034405\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999129616287972, -0.9915500552225517, -0.8332017086794654, 0.9395895276636155]\n",
      "Layer: Layer 1, Input: [-0.999129616287972, -0.9915500552225517, -0.8332017086794654, 0.9395895276636155], Output: [0.9202617525763525, -0.8733205647880435, 0.9631443966494682, 0.14924500831616822]\n",
      "Layer: Layer 2, Input: [0.9202617525763525, -0.8733205647880435, 0.9631443966494682, 0.14924500831616822], Output: [0.6368785151497043]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968894828783399, -0.6340613122351526, -0.8631074021890797, 0.9432809954750985]\n",
      "Layer: Layer 1, Input: [-0.9968894828783399, -0.6340613122351526, -0.8631074021890797, 0.9432809954750985], Output: [0.8770068123029932, -0.8410390828958322, 0.9532916042284029, 0.003186981272454297]\n",
      "Layer: Layer 2, Input: [0.8770068123029932, -0.8410390828958322, 0.9532916042284029, 0.003186981272454297], Output: [0.5901163394164147]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784674097519804, -0.8431654921140092, -0.8937253543823825, 0.28082727850799727]\n",
      "Layer: Layer 1, Input: [-0.9784674097519804, -0.8431654921140092, -0.8937253543823825, 0.28082727850799727], Output: [0.7018681566409266, -0.9332666284281719, 0.9810310086313032, 0.21728330738761995]\n",
      "Layer: Layer 2, Input: [0.7018681566409266, -0.9332666284281719, 0.9810310086313032, 0.21728330738761995], Output: [0.6754335702331531]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538105944367273, -0.5416250039090135, -0.38959332202656716, 0.27271007505580547]\n",
      "Layer: Layer 1, Input: [-0.9538105944367273, -0.5416250039090135, -0.38959332202656716, 0.27271007505580547], Output: [0.5015082680018205, -0.8367034071705369, 0.9613322482839444, 0.2661888144507924]\n",
      "Layer: Layer 2, Input: [0.5015082680018205, -0.8367034071705369, 0.9613322482839444, 0.2661888144507924], Output: [0.6165709560700644]\n",
      "Epoch 88/100, Loss: 1.403605666408044, Accuracy: -3.0121004384297994\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.999129411503985, -0.9915722368908889, -0.8333804776530526, 0.9398792166519587]\n",
      "Layer: Layer 1, Input: [-0.999129411503985, -0.9915722368908889, -0.8333804776530526, 0.9398792166519587], Output: [0.9204861451189146, -0.8753429525861464, 0.9630747247149918, 0.15575269385751614]\n",
      "Layer: Layer 2, Input: [0.9204861451189146, -0.8753429525861464, 0.9630747247149918, 0.15575269385751614], Output: [0.6814981436298264]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968892359583006, -0.6343205234753522, -0.8631597259017615, 0.9433676016171356]\n",
      "Layer: Layer 1, Input: [-0.9968892359583006, -0.6343205234753522, -0.8631597259017615, 0.9433676016171356], Output: [0.8773115650293051, -0.8434222234247315, 0.9532217626533398, 0.009607569235977399]\n",
      "Layer: Layer 2, Input: [0.8773115650293051, -0.8434222234247315, 0.9532217626533398, 0.009607569235977399], Output: [0.6336501326298156]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784664539866057, -0.8432338929327704, -0.8937496643132035, 0.2812052529515045]\n",
      "Layer: Layer 1, Input: [-0.9784664539866057, -0.8432338929327704, -0.8937496643132035, 0.2812052529515045], Output: [0.7025989474970689, -0.9342589670397171, 0.9809935140644611, 0.2231187373631246]\n",
      "Layer: Layer 2, Input: [0.7025989474970689, -0.9342589670397171, 0.9809935140644611, 0.2231187373631246], Output: [0.7189172581256962]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9538046625311222, -0.5421399527950068, -0.3898746982540954, 0.2739594536838767]\n",
      "Layer: Layer 1, Input: [-0.9538046625311222, -0.5421399527950068, -0.3898746982540954, 0.2739594536838767], Output: [0.5033753853473906, -0.8386663956663788, 0.9612474073666457, 0.2710076351215298]\n",
      "Layer: Layer 2, Input: [0.5033753853473906, -0.8386663956663788, 0.9612474073666457, 0.2710076351215298], Output: [0.6580522651002969]\n",
      "Epoch 89/100, Loss: 1.4604652455095148, Accuracy: -3.0130169820253885\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991291445688577, -0.9916010686717691, -0.8336134645564646, 0.9402548153694795]\n",
      "Layer: Layer 1, Input: [-0.9991291445688577, -0.9916010686717691, -0.8336134645564646, 0.9402548153694795], Output: [0.9207781988378425, -0.8775968438971453, 0.9629984272289053, 0.16319560138003056]\n",
      "Layer: Layer 2, Input: [0.9207781988378425, -0.8775968438971453, 0.9629984272289053, 0.16319560138003056], Output: [0.7319894393894124]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968889140399577, -0.6346584951497989, -0.8632280012863345, 0.9434803934545096]\n",
      "Layer: Layer 1, Input: [-0.9968889140399577, -0.6346584951497989, -0.8632280012863345, 0.9434803934545096], Output: [0.8777088961333749, -0.8460876090895059, 0.953147918341359, 0.0169951982613017]\n",
      "Layer: Layer 2, Input: [0.8777088961333749, -0.8460876090895059, 0.953147918341359, 0.0169951982613017], Output: [0.6829360180566301]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784652074453816, -0.843323172809268, -0.8937814074931325, 0.2816987524072141]\n",
      "Layer: Layer 1, Input: [-0.9784652074453816, -0.843323172809268, -0.8937814074931325, 0.2816987524072141], Output: [0.703552067379148, -0.9353626028988801, 0.9809514907187165, 0.22979603140837437]\n",
      "Layer: Layer 2, Input: [0.703552067379148, -0.9353626028988801, 0.9809514907187165, 0.22979603140837437], Output: [0.7681179508438276]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537969301611071, -0.5428108873589097, -0.3902417895794738, 0.2755871802676438]\n",
      "Layer: Layer 1, Input: [-0.9537969301611071, -0.5428108873589097, -0.3902417895794738, 0.2755871802676438], Output: [0.5058051962623095, -0.8408539182083405, 0.9611487141042133, 0.2765199229481016]\n",
      "Layer: Layer 2, Input: [0.5058051962623095, -0.8408539182083405, 0.9611487141042133, 0.2765199229481016], Output: [0.7050448764727493]\n",
      "Epoch 90/100, Loss: 1.5293357286155649, Accuracy: -3.0140196530382957\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991287914308454, -0.9916390689095527, -0.8339216186559297, 0.9407482579125206]\n",
      "Layer: Layer 1, Input: [-0.9991287914308454, -0.9916390689095527, -0.8339216186559297, 0.9407482579125206], Output: [0.9211638805504648, -0.8801620611896813, 0.9629133964223733, 0.17192752437589137]\n",
      "Layer: Layer 2, Input: [0.9211638805504648, -0.8801620611896813, 0.9629133964223733, 0.17192752437589137], Output: [0.7905252954117546]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968884880243666, -0.635105797546704, -0.8633184536173957, 0.9436294756678207]\n",
      "Layer: Layer 1, Input: [-0.9968884880243666, -0.635105797546704, -0.8633184536173957, 0.9436294756678207], Output: [0.8782348100715749, -0.8491330260855097, 0.9530690142550605, 0.025719894239399046]\n",
      "Layer: Layer 2, Input: [0.8782348100715749, -0.8491330260855097, 0.9530690142550605, 0.025719894239399046], Output: [0.7401087382612255]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784635568274208, -0.8434415113729451, -0.8938235024902508, 0.2823533786442969]\n",
      "Layer: Layer 1, Input: [-0.9784635568274208, -0.8434415113729451, -0.8938235024902508, 0.2823533786442969], Output: [0.7048143291087575, -0.936616001511857, 0.9809033506227471, 0.237634195948194]\n",
      "Layer: Layer 2, Input: [0.7048143291087575, -0.936616001511857, 0.9809033506227471, 0.237634195948194], Output: [0.8251543715194839]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.953786700118441, -0.5436979881946353, -0.39072798433705774, 0.2777393731466478]\n",
      "Layer: Layer 1, Input: [-0.953786700118441, -0.5436979881946353, -0.39072798433705774, 0.2777393731466478], Output: [0.5090133144015379, -0.8433454741601706, 0.9610310840540003, 0.2829929581050306]\n",
      "Layer: Layer 2, Input: [0.5090133144015379, -0.8433454741601706, 0.9610310840540003, 0.2829929581050306], Output: [0.7596068264227387]\n",
      "Epoch 91/100, Loss: 1.6152088576536592, Accuracy: -3.0151309879462165\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991283085279249, -0.9916907750139383, -0.8343428479050061, 0.9414168938488809]\n",
      "Layer: Layer 1, Input: [-0.9991283085279249, -0.9916907750139383, -0.8343428479050061, 0.9414168938488809], Output: [0.9216907164921905, -0.8831944807205078, 0.9628154484861811, 0.18264952345219118]\n",
      "Layer: Layer 2, Input: [0.9216907164921905, -0.8831944807205078, 0.9628154484861811, 0.18264952345219118], Output: [0.8614119420655707]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968879049433153, -0.6357182405983431, -0.8634424216069165, 0.9438333744806601]\n",
      "Layer: Layer 1, Input: [-0.9968879049433153, -0.6357182405983431, -0.8634424216069165, 0.9438333744806601], Output: [0.8789556005197837, -0.8527492628432028, 0.9529826672377248, 0.03651429562350584]\n",
      "Layer: Layer 2, Input: [0.8789556005197837, -0.8527492628432028, 0.9529826672377248, 0.03651429562350584], Output: [0.8094057475893076]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784612946333675, -0.8436039932483935, -0.8938812951450101, 0.28325437486419325]\n",
      "Layer: Layer 1, Input: [-0.9784612946333675, -0.8436039932483935, -0.8938812951450101, 0.28325437486419325], Output: [0.7065464548004265, -0.9380947627440916, 0.9808459669451205, 0.24726787842505363]\n",
      "Layer: Layer 2, Input: [0.7065464548004265, -0.9380947627440916, 0.9808459669451205, 0.24726787842505363], Output: [0.8942300482886634]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537727072115408, -0.5449105237764256, -0.39139393195317157, 0.28068228543574847]\n",
      "Layer: Layer 1, Input: [-0.9537727072115408, -0.5449105237764256, -0.39139393195317157, 0.28068228543574847], Output: [0.5133935035811877, -0.8462989440996436, 0.960884857785516, 0.2909656791391819]\n",
      "Layer: Layer 2, Input: [0.5133935035811877, -0.8462989440996436, 0.960884857785516, 0.2909656791391819], Output: [0.8258340446165032]\n",
      "Epoch 92/100, Loss: 1.7278992662663941, Accuracy: -3.016389809195897\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991275938025433, -0.9917667829648089, -0.8349658769911122, 0.9423946367720772]\n",
      "Layer: Layer 1, Input: [-0.9991275938025433, -0.9917667829648089, -0.8349658769911122, 0.9423946367720772], Output: [0.9224732500846752, -0.8871090075722923, 0.9626931108570164, 0.19727295858040522]\n",
      "Layer: Layer 2, Input: [0.9224732500846752, -0.8871090075722923, 0.9626931108570164, 0.19727295858040522], Output: [0.9563682273475094]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968870394454046, -0.636628750978724, -0.863626754081933, 0.9441367216729163]\n",
      "Layer: Layer 1, Input: [-0.9968870394454046, -0.636628750978724, -0.863626754081933, 0.9441367216729163], Output: [0.8800323665805605, -0.857444054734711, 0.9528812401447448, 0.051374098740278235]\n",
      "Layer: Layer 2, Input: [0.8800323665805605, -0.857444054734711, 0.9528812401447448, 0.051374098740278235], Output: [0.9023868510062285]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784579240560198, -0.8438472137112464, -0.8939675835412971, 0.2846139561932963]\n",
      "Layer: Layer 1, Input: [-0.9784579240560198, -0.8438472137112464, -0.8939675835412971, 0.2846139561932963], Output: [0.7091428912826933, -0.9400020478557836, 0.9807709030487634, 0.26043871179182054]\n",
      "Layer: Layer 2, Input: [0.7091428912826933, -0.9400020478557836, 0.9807709030487634, 0.26043871179182054], Output: [0.9868023438846247]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537519754421887, -0.5467062238403836, -0.39238241250676575, 0.2850487236914562]\n",
      "Layer: Layer 1, Input: [-0.9537519754421887, -0.5467062238403836, -0.39238241250676575, 0.2850487236914562], Output: [0.5198901792497653, -0.8501450565081666, 0.9606854021495769, 0.30194565167096543]\n",
      "Layer: Layer 2, Input: [0.5198901792497653, -0.8501450565081666, 0.9606854021495769, 0.30194565167096543], Output: [0.9149403485278469]\n",
      "Epoch 93/100, Loss: 1.8938995401100487, Accuracy: -3.0178806190154965\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991261685226385, -0.9919167156129431, -0.8362089647534207, 0.9443122686692271]\n",
      "Layer: Layer 1, Input: [-0.9991261685226385, -0.9919167156129431, -0.8362089647534207, 0.9443122686692271], Output: [0.9240982609718197, -0.8945279775176621, 0.9624704023431153, 0.22878200138252536]\n",
      "Layer: Layer 2, Input: [0.9240982609718197, -0.8945279775176621, 0.9624704023431153, 0.22878200138252536], Output: [1.1539971624248175]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968852922405389, -0.6384802538973197, -0.8640022531359194, 0.9447613599659288]\n",
      "Layer: Layer 1, Input: [-0.9968852922405389, -0.6384802538973197, -0.8640022531359194, 0.9447613599659288], Output: [0.882302347535263, -0.8664384482016061, 0.9527017119019586, 0.0838847272598359]\n",
      "Layer: Layer 2, Input: [0.882302347535263, -0.8664384482016061, 0.9527017119019586, 0.0838847272598359], Output: [1.0970355969253092]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784510194271978, -0.8443538678642064, -0.8941467296602037, 0.2875489155887916]\n",
      "Layer: Layer 1, Input: [-0.9784510194271978, -0.8443538678642064, -0.8941467296602037, 0.2875489155887916], Output: [0.7146835166079182, -0.9436534856202111, 0.9806247293075444, 0.28915955373299573]\n",
      "Layer: Layer 2, Input: [0.7146835166079182, -0.9436534856202111, 0.9806247293075444, 0.28915955373299573], Output: [1.1799660632207751]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.95371043684125, -0.5503104869878545, -0.3943765728426983, 0.29390132931658836]\n",
      "Layer: Layer 1, Input: [-0.95371043684125, -0.5503104869878545, -0.3943765728426983, 0.29390132931658836], Output: [0.5332448076552591, -0.8577777210198514, 0.9602912387691963, 0.32672985977002217]\n",
      "Layer: Layer 2, Input: [0.5332448076552591, -0.8577777210198514, 0.9602912387691963, 0.32672985977002217], Output: [1.103169897451152]\n",
      "Epoch 94/100, Loss: 2.2960423713352873, Accuracy: -3.5341687200220537\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991268438552946, -0.9918421915676252, -0.8356447060077095, 0.943292001784385]\n",
      "Layer: Layer 1, Input: [-0.9991268438552946, -0.9918421915676252, -0.8356447060077095, 0.943292001784385], Output: [0.922978309844687, -0.8906051457662822, 0.962575481853583, 0.20657574389005776]\n",
      "Layer: Layer 2, Input: [0.922978309844687, -0.8906051457662822, 0.962575481853583, 0.20657574389005776], Output: [1.0266525346109305]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968863040900896, -0.6372655528898574, -0.8638094073936071, 0.9442791363373632]\n",
      "Layer: Layer 1, Input: [-0.9968863040900896, -0.6372655528898574, -0.8638094073936071, 0.9442791363373632], Output: [0.880620189653558, -0.8615726584322445, 0.9527794533555027, 0.060574524333321084]\n",
      "Layer: Layer 2, Input: [0.880620189653558, -0.8615726584322445, 0.9527794533555027, 0.060574524333321084], Output: [0.9702359309964681]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784558333641208, -0.8439286947008966, -0.8940438441434876, 0.2844383037218445]\n",
      "Layer: Layer 1, Input: [-0.9784558333641208, -0.8439286947008966, -0.8940438441434876, 0.2844383037218445], Output: [0.7100233411728103, -0.9417456059873912, 0.9807275662303033, 0.2685160706332556]\n",
      "Layer: Layer 2, Input: [0.7100233411728103, -0.9417456059873912, 0.9807275662303033, 0.2685160706332556], Output: [1.0546390206198635]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537319003781173, -0.5482847240501126, -0.3934208652147865, 0.2883243850183062]\n",
      "Layer: Layer 1, Input: [-0.9537319003781173, -0.5482847240501126, -0.3934208652147865, 0.2883243850183062], Output: [0.5240872610892734, -0.8535229705138866, 0.9605315376937879, 0.3076708807099841]\n",
      "Layer: Layer 2, Input: [0.5240872610892734, -0.8535229705138866, 0.9605315376937879, 0.3076708807099841], Output: [0.9785723257453975]\n",
      "Epoch 95/100, Loss: 2.0261351579171047, Accuracy: -3.0729551604818646\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991216759511221, -0.9923703986429648, -0.8399886089403351, 0.949890166210542]\n",
      "Layer: Layer 1, Input: [-0.9991216759511221, -0.9923703986429648, -0.8399886089403351, 0.949890166210542], Output: [0.9282788717188952, -0.9044586190283592, 0.9621748304148278, 0.2591436563828489]\n",
      "Layer: Layer 2, Input: [0.9282788717188952, -0.9044586190283592, 0.9621748304148278, 0.2591436563828489], Output: [1.3788036778620842]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996879844483322, -0.6441817108147705, -0.8650971190571571, 0.9466019888532868]\n",
      "Layer: Layer 1, Input: [-0.996879844483322, -0.6441817108147705, -0.8650971190571571, 0.9466019888532868], Output: [0.8881365253604094, -0.8782692463057209, 0.9526197878186403, 0.11512755293300014]\n",
      "Layer: Layer 2, Input: [0.8881365253604094, -0.8782692463057209, 0.9526197878186403, 0.11512755293300014], Output: [1.3118753722394878]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784297110291698, -0.84589525425759, -0.8946420848967283, 0.2960048853421524]\n",
      "Layer: Layer 1, Input: [-0.9784297110291698, -0.84589525425759, -0.8946420848967283, 0.2960048853421524], Output: [0.7289324738221683, -0.9480508071981233, 0.9803771364051925, 0.3135680580947939]\n",
      "Layer: Layer 2, Input: [0.7289324738221683, -0.9480508071981233, 0.9803771364051925, 0.3135680580947939], Output: [1.39620189822521]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9535801685300086, -0.5614501329263151, -0.40037553262776493, 0.3207749802383782]\n",
      "Layer: Layer 1, Input: [-0.9535801685300086, -0.5614501329263151, -0.40037553262776493, 0.3207749802383782], Output: [0.5696414317159066, -0.8655942829816592, 0.9594545515364932, 0.3418461679437994]\n",
      "Layer: Layer 2, Input: [0.5696414317159066, -0.8655942829816592, 0.9594545515364932, 0.3418461679437994], Output: [1.302414202360932]\n",
      "Epoch 96/100, Loss: 2.830374462494253, Accuracy: -4.3892951506877145\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991221111049383, -0.9923183925323754, -0.8396677158130773, 0.9490825008092597]\n",
      "Layer: Layer 1, Input: [-0.9991221111049383, -0.9923183925323754, -0.8396677158130773, 0.9490825008092597], Output: [0.9268741317792587, -0.9007551912985087, 0.9622108187840552, 0.22875690582520064]\n",
      "Layer: Layer 2, Input: [0.9268741317792587, -0.9007551912985087, 0.9622108187840552, 0.22875690582520064], Output: [1.2302209217986058]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968808491471481, -0.6427670960915501, -0.8649341108269051, 0.9459414107073616]\n",
      "Layer: Layer 1, Input: [-0.9968808491471481, -0.6427670960915501, -0.8649341108269051, 0.9459414107073616], Output: [0.8858514792806161, -0.8735303513085707, 0.9526176361602187, 0.08267146955812073]\n",
      "Layer: Layer 2, Input: [0.8858514792806161, -0.8735303513085707, 0.9526176361602187, 0.08267146955812073], Output: [1.1621134963246822]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.978435771165903, -0.84527025399644, -0.8945323596109381, 0.29061398256818866]\n",
      "Layer: Layer 1, Input: [-0.978435771165903, -0.84527025399644, -0.8945323596109381, 0.29061398256818866], Output: [0.7219367769475701, -0.9462591986312279, 0.9804949448415793, 0.28489255946607567]\n",
      "Layer: Layer 2, Input: [0.7219367769475701, -0.9462591986312279, 0.9804949448415793, 0.28489255946607567], Output: [1.2489404456557127]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9535974086781187, -0.5595667998577454, -0.3997080576643564, 0.31453042821249394]\n",
      "Layer: Layer 1, Input: [-0.9535974086781187, -0.5595667998577454, -0.3997080576643564, 0.31453042821249394], Output: [0.5584418525720916, -0.8611223764791608, 0.9596788402760426, 0.31384480713458657]\n",
      "Layer: Layer 2, Input: [0.5584418525720916, -0.8611223764791608, 0.9596788402760426, 0.31384480713458657], Output: [1.1529054910323875]\n",
      "Epoch 97/100, Loss: 2.452212415279278, Accuracy: -3.794180354811388\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991227812263342, -0.9922453258149, -0.8391234251732239, 0.9480697363688367]\n",
      "Layer: Layer 1, Input: [-0.9991227812263342, -0.9922453258149, -0.8391234251732239, 0.9480697363688367], Output: [0.9255242000381116, -0.8972580555597415, 0.962247381823174, 0.20422692798398043]\n",
      "Layer: Layer 2, Input: [0.9255242000381116, -0.8972580555597415, 0.962247381823174, 0.20422692798398043], Output: [1.1099471373558036]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968819820886997, -0.6413281789744216, -0.8647264721777118, 0.9453344378447585]\n",
      "Layer: Layer 1, Input: [-0.9968819820886997, -0.6413281789744216, -0.8647264721777118, 0.9453344378447585], Output: [0.8837374564976725, -0.8691039293918478, 0.9526096316831002, 0.05672357555732089]\n",
      "Layer: Layer 2, Input: [0.8837374564976725, -0.8691039293918478, 0.9526096316831002, 0.05672357555732089], Output: [1.0414730363711162]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.97844163536857, -0.8447165461488279, -0.8944129370083067, 0.2862427304311329]\n",
      "Layer: Layer 1, Input: [-0.97844163536857, -0.8447165461488279, -0.8944129370083067, 0.2862427304311329], Output: [0.7157980138732156, -0.9445859720224505, 0.980589953066473, 0.2619225918639524]\n",
      "Layer: Layer 2, Input: [0.7157980138732156, -0.9445859720224505, 0.980589953066473, 0.2619225918639524], Output: [1.1302258268122554]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9536199404531912, -0.5573538099348221, -0.3987301485797174, 0.30803267309748295]\n",
      "Layer: Layer 1, Input: [-0.9536199404531912, -0.5573538099348221, -0.3987301485797174, 0.30803267309748295], Output: [0.547524520662432, -0.8571494019832998, 0.959892575245061, 0.29195668315254236]\n",
      "Layer: Layer 2, Input: [0.547524520662432, -0.8571494019832998, 0.959892575245061, 0.29195668315254236], Output: [1.0332477530753956]\n",
      "Epoch 98/100, Loss: 2.17966700438639, Accuracy: -3.3148937536145713\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991263749657416, -0.9918670320049513, -0.8360267831361695, 0.9431884738176666]\n",
      "Layer: Layer 1, Input: [-0.9991263749657416, -0.9918670320049513, -0.8360267831361695, 0.9431884738176666], Output: [0.9208790167074468, -0.8862729654858182, 0.9623889254888933, 0.14870154844008118]\n",
      "Layer: Layer 2, Input: [0.9208790167074468, -0.8862729654858182, 0.9623889254888933, 0.14870154844008118], Output: [0.82583371912133]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9968867395055712, -0.6359657906878643, -0.8637570946376514, 0.9433912356474502]\n",
      "Layer: Layer 1, Input: [-0.9968867395055712, -0.6359657906878643, -0.8637570946376514, 0.9433912356474502], Output: [0.8769668991874213, -0.8554842875339508, 0.9525491884041977, -0.001143813446172368]\n",
      "Layer: Layer 2, Input: [0.8769668991874213, -0.8554842875339508, 0.9525491884041977, -0.001143813446172368], Output: [0.7603172832616103]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784620246514959, -0.8430598542354052, -0.8939367132843998, 0.275469386741013]\n",
      "Layer: Layer 1, Input: [-0.9784620246514959, -0.8430598542354052, -0.8939367132843998, 0.275469386741013], Output: [0.6980602211208129, -0.9394962315103296, 0.9808211630129959, 0.2113609608577004]\n",
      "Layer: Layer 2, Input: [0.6980602211208129, -0.9394962315103296, 0.9808211630129959, 0.2113609608577004], Output: [0.8527652316978529]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9537280288451111, -0.5476223079837688, -0.3936619108323149, 0.28305762116278294]\n",
      "Layer: Layer 1, Input: [-0.9537280288451111, -0.5476223079837688, -0.3936619108323149, 0.28305762116278294], Output: [0.509086465290101, -0.8464204821664032, 0.9606152788234321, 0.24770512143585308]\n",
      "Layer: Layer 2, Input: [0.509086465290101, -0.8464204821664032, 0.9606152788234321, 0.24770512143585308], Output: [0.7604291058892706]\n",
      "Epoch 99/100, Loss: 1.6547960120595142, Accuracy: -3.026819689948862\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9991253646969636, -0.9919724498276629, -0.8369113949623889, 0.9445267432282481]\n",
      "Layer: Layer 1, Input: [-0.9991253646969636, -0.9919724498276629, -0.8369113949623889, 0.9445267432282481], Output: [0.9219816383321982, -0.8896777039750808, 0.9623278453224309, 0.16255141114230223]\n",
      "Layer: Layer 2, Input: [0.9219816383321982, -0.8896777039750808, 0.9623278453224309, 0.16255141114230223], Output: [0.9007226665328086]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.996885528788225, -0.6372407938331579, -0.8640198774793665, 0.9438143604470153]\n",
      "Layer: Layer 1, Input: [-0.996885528788225, -0.6372407938331579, -0.8640198774793665, 0.9438143604470153], Output: [0.8784961232271095, -0.8596426411891026, 0.9525371697637197, 0.013033883707543915]\n",
      "Layer: Layer 2, Input: [0.8784961232271095, -0.8596426411891026, 0.9525371697637197, 0.013033883707543915], Output: [0.8340150728884494]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9784573578026255, -0.8433964199331564, -0.8940594673038873, 0.2773099454067815]\n",
      "Layer: Layer 1, Input: [-0.9784573578026255, -0.8433964199331564, -0.8940594673038873, 0.2773099454067815], Output: [0.7017408304879267, -0.9411269070956305, 0.9807698116283372, 0.2239349960428322]\n",
      "Layer: Layer 2, Input: [0.7017408304879267, -0.9411269070956305, 0.9807698116283372, 0.2239349960428322], Output: [0.9254961936190139]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9536988636063274, -0.5501464162636015, -0.39507421027581696, 0.2891735068005401]\n",
      "Layer: Layer 1, Input: [-0.9536988636063274, -0.5501464162636015, -0.39507421027581696, 0.2891735068005401], Output: [0.5182314375404296, -0.8497362442787388, 0.9604284884629312, 0.2581982426555155]\n",
      "Layer: Layer 2, Input: [0.5182314375404296, -0.8497362442787388, 0.9604284884629312, 0.2581982426555155], Output: [0.8310586725095291]\n",
      "Epoch 100/100, Loss: 1.7773860100744836, Accuracy: -3.027729927465126\n"
     ]
    }
   ],
   "source": [
    "# Run model training for multiple epochs\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Reset model parameters\n",
    "for param in mlp.parameters():\n",
    "    param.data = random.uniform(-1, 1)  # Random initialization of parameters\n",
    "    param.grad = 0.0\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "y_true = [Value(y_i) for y_i in y]  # Convert labels to Value objects\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_preds = [mlp(i)[0] for i in x]  # Forward pass through the neural network\n",
    "    loss = loss_fn_mse(y_preds, y_true)\n",
    "    losses.append(loss)\n",
    "    accuracy.append(1 - sum([abs(y_true - y_pred.data) for y_true, y_pred in zip(y, y_preds)]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.data}, Accuracy: {accuracy[-1]}\")\n",
    "        \n",
    "    mlp.zero_grad()  # Reset gradients of all parameters\n",
    "    loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "    visited = set()\n",
    "    loss.backward(loss, visited)\n",
    "    for param in mlp.parameters():\n",
    "        param.data = param.data - learning_rate * param.grad  # Update parameters using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1621,
   "id": "62fd9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds after training: [0.9007226665328086, 0.8340150728884494, 0.9254961936190139, 0.8310586725095291]\n",
      "y_true after training: [1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_preds after training: {[item.data for item in y_preds]}\")\n",
    "print(f\"y_true after training: {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "id": "08b99310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(range(epochs), [item.data for item in losses])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "2e370b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy over epochs\n",
    "plt.plot(range(epochs), accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912faec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
