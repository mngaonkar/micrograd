{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5e86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "from IPython import display\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5629e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ab2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for Jupyter Notebook to find the graphviz executables\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\"/opt/homebrew/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eba97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for gradient calculation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAATshJREFUeJzt3Ql8TOf6B/Bf9n0R2WUhtgQRxBZFFbUrpYsutKqUi1a1qu7t1VZ7S+m/u0t7b4sWpVrcUstVaxFbbBEEEZLIKpFFIuvM//O+SeYmxJL1nJn5fT+f0zkzcxLP6cnMPPMuz2ui1Wq1ICIiIlIxU6UDICIiIrofJixERESkekxYiIiISPWYsBAREZHqMWEhIiIi1WPCQkRERKrHhIWIiIhUjwkLERERqZ459JBGo0FiYiIcHBxgYmKidDhERET0AESt2pycHHh7e8PU1NTwExaRrPj6+iodBhEREdVAfHw8fHx8DD9hES0r5Sfs6OiodDhERET0ALKzs2WDQ/nnuMEnLOXdQCJZYcJCRESkX2oynIODbomIiEj1mLAQERGR6jFhISIiItVjwkJERESGlbAsWbIE7du31w12DQsLw9atW3XP9+nTRw6kqbhNnjy50u+Ii4vD0KFDYWtrC3d3d8yaNQvFxcV1d0ZERERkcKo1S0jMmV6wYAFatmwpi7+sWLECI0aMwIkTJ9C2bVt5zMSJEzFv3jzdz4jEpFxJSYlMVjw9PXHw4EEkJSVh3LhxsLCwwEcffVSX50VEREQGxEQrMo9acHFxwaJFizBhwgTZwtKhQwd8/vnnVR4rWmOGDRsmC795eHjIx5YuXYrZs2cjLS0NlpaWDzyP28nJCVlZWZzWTEREpCdq8/ld4zEsorVkzZo1yM3NlV1D5VatWgVXV1e0a9cOc+bMQV5enu658PBwBAcH65IVYeDAgfIEoqKiahoKERERGbhqF46LjIyUCUp+fj7s7e2xYcMGtGnTRj737LPPwt/fX64RcPr0adlyEh0djfXr18vnk5OTKyUrQvl98dzdFBQUyK2cSHCIiIjIeFQ7YWndujVOnjwpm3N++eUXvPDCC9i7d69MWiZNmqQ7TrSkeHl5oV+/foiJiUHz5s1rHOT8+fPx/vvv1/jniYiISL9Vu0tIjDNp0aIFQkNDZSIREhKCL774ospju3XrJm8vXbokb8Vg25SUlErHlN8Xz92N6FoSCVL5JtYQIiIiIuNR6zosGo2mUndNRaIlRhAtLYLoShJdSqmpqbpjduzYIQfelHcrVcXKyko3lZrrBxERERmfanUJiZaOwYMHw8/PDzk5OVi9ejX27NmD7du3y24fcX/IkCFo3LixHMPy+uuvo3fv3rJ2izBgwACZmIwdOxYLFy6U41beeecdTJ06VSYlSjubmI3VR66iS1MXjOjQROlwiIiIqCYJi2gZEXVTRP0UMS1JJCIiWXn00UdlN80ff/whpzSLmUNi+ejRo0fLhKScmZkZNm/ejClTpsjWFjs7OzkGpmLdFiXtvZCGlYfiEJ2cw4SFiIjIkOqwKKG+6rCkZOcjbP5OaLTAnjf7oKmrXZ39biIiImOXrUQdFkPk4WiN3q3c5P6vxxOUDoeIiIjKMGG5zROhPvL214gEaERTCxERESmOCctt+gd5wNHaHIlZ+TgYk650OERERMSE5U7WFmZ4rIO33P8lgvVeiIiI1IAJSxWeCPWVt9uikpGdX6R0OEREREaPCUsVQnyc0NLdHvlFGmw5naR0OEREREaPCUsVTExMdINvf4ngbCEiIiKlMWG5i8c7NoGpCXDs6g1cTrupdDhERERGjQnLXbg7WuNh1mQhIiJSBSYsDzD4dv3xayhhTRYiIiLFMGG5h35B7nCysUCSrMlyXelwiIiIjBYTlvvUZBmhq8nCbiEiIiKlMGG5j/LZQtvOJCPrFmuyEBERKYEJy30EN3FCKw97FBRr8DtrshARESmCCUu1arKwVD8REZESmLA8gJEdmsDM1ATH4zIRw5osREREDY4JS3VrsnDwLRERUYNjwvKAnizrFmJNFiIioobHhOUB9Q1yh7OtBZKz87H/EmuyEBERNSQmLA/IytwMI0JYk4WIiEgJTFhqUKp/exRrshARETUkJizV0K6JI1p7OKCwWIPNpxOVDoeIiMhoMGGpZk2WJzuXDr5dd4zdQkRERA2FCUs1jSiryXIyPhOXUnOUDoeIiMgoMGGpJjcHKzzSurQmyy8R15QOh4iIyCgwYamB8lL9G04ksCYLERFRA2DCUgN9Az3QyNYCKdkF+PNimtLhEBERGTwmLDVgaW4qx7II61iThYiIqN4xYallt9COqBRk5hUqHQ4REZFBY8JSQ229HRHo6YDCEg02nuDgWyIiovrEhKUWNVnGdCmtfLvmaDy0Wg6+JSIiqi9MWGrh8Y4+sDI3xfnkHFmXhYiIiOoHE5ZacLK1wJBgL7m/5ki80uEQEREZLCYstVTeLbTpdCJuFhQrHQ4REZFBYsJSS12buSDAzQ55hSX47SQXRCQiIqoPTFjqdPBtnNLhEBERGSQmLHVgdCcfWJiZ4HRCFqISs5QOh4iIyOAwYakDje2tMKCNp9zn4FsiIqK6x4SljozpWtottPHkNdwqLFE6HCIiIuNNWJYsWYL27dvD0dFRbmFhYdi6davu+fz8fEydOhWNGzeGvb09Ro8ejZSUlEq/Iy4uDkOHDoWtrS3c3d0xa9YsFBfr/+yah5q7wtfFBjn5xfg9MknpcIiIiIw3YfHx8cGCBQsQERGBY8eOoW/fvhgxYgSioqLk86+//jo2bdqEdevWYe/evUhMTMSoUaN0P19SUiKTlcLCQhw8eBArVqzA8uXLMXfuXOg7U1MTPN25bPDtEQ6+JSIiqksm2lrWlHdxccGiRYvwxBNPwM3NDatXr5b7wvnz5xEUFITw8HB0795dtsYMGzZMJjIeHh7ymKVLl2L27NlIS0uDpaXlA/2b2dnZcHJyQlZWlmzpUYuU7Hz0WLALJRotdrzeGy09HJQOiYiISDVq8/ld4zEsorVkzZo1yM3NlV1DotWlqKgI/fv31x0TGBgIPz8/mbAI4jY4OFiXrAgDBw6UJ1DeSlOVgoICeUzFTY08HK3RN9Bdt74QERER1Y1qJyyRkZFyfIqVlRUmT56MDRs2oE2bNkhOTpYtJM7OzpWOF8mJeE4QtxWTlfLny5+7m/nz58uMrHzz9S3telGjZ8oG364/noCCYg6+JSIiUiRhad26NU6ePInDhw9jypQpeOGFF3D27FnUpzlz5sjmo/ItPl69rRcPt3KHl5M1buQVYXtU5QHHRERE1EAJi2hFadGiBUJDQ2XLR0hICL744gt4enrKwbSZmZVXLRazhMRzgri9fdZQ+f3yY6oiWnPKZyaVb2plZmqCJzn4loiISF11WDQajRxjIhIYCwsL7Ny5U/dcdHS0nMYsxrgI4lZ0KaWmpuqO2bFjh0xARLeSoXiqsw9MTICDMem4mp6rdDhERER6z7y6XTODBw+WA2lzcnLkjKA9e/Zg+/btcmzJhAkTMHPmTDlzSCQh06dPl0mKmCEkDBgwQCYmY8eOxcKFC+W4lXfeeUfWbhGtKIbCp5Eterd0w94LaXLw7exBgUqHREREZDwtLKJlZNy4cXIcS79+/XD06FGZrDz66KPy+c8++0xOWxYF43r37i27edavX6/7eTMzM2zevFneikTm+eefl79v3rx5MDTlg2/XHUtAUYlG6XCIiIiMuw6LEtRah6UikaSEzd+F6zcLsPT5UAxqd/cxOkRERMYgW4k6LHRvFmameCLUR+6vOcrBt0RERLXBhKUejelS2i0kxrJcy7yldDhERER6iwlLPWrqaoewgMYQnW4/s/ItERFRjTFhqWdjdINv4+UaQ0RERFR9TFjq2cC2nnC2tUBiVj72XUhTOhwiIiK9xISlnllbmGFUx9LBtz+x8i0REVGNMGFpwJosO8+nIjU7X+lwiIiI9A4TlgbQ0sMBnf0byTEs6yISlA6HiIhI7zBhaSBjuvrpuoU4+JaIiKh6mLA0kKHBXnCysUDCjVvYe+F/iz8SERHR/TFhaSA2lmZ4sqzy7Y/hV5UOh4iISK8wYWlAz3f3l7d7LqQhLj1P6XCIiIj0BhOWBq5827uVm6x8u+owW1mIiIgeFBOWBjaurJVl7bF45BeVKB0OERGRXmDC0sAeCXRHE2cbZOYVYfPpJKXDISIi0gtMWBqYmakJnu1WOsX5x0PsFiIiInoQTFgU8HQXX1iameJUfCZOJ2QqHQ4REZHqMWFRgKu9FYYEe8p9TnEmIiK6PyYsChkb1lTe/nYqEZl5hUqHQ0REpGpMWBTSyc8ZbbwcUVCswbpjXF+IiIjoXpiwKMTExARjw0qnOK88fBUari9ERER0V0xYFDSigzccrM1xNT0P+y6mKR0OERGRajFhUZCtpTmeKFtfaCWnOBMREd0VExaVrC+083wq4jO4vhAREVFVmLAorLmbPXq2cJXrC60+Eqd0OERERKrEhEUFygffrj0aj4Jiri9ERER0OyYsKtAv0B1eTtbIyC3ElkiuL0RERHQ7JiwqYG5mime7lq0vxMq3REREd2DCohJPd/WFhZkJjsdl4sy1LKXDISIiUhUmLCrh7mCNQe285D6nOBMREVXGhEVFxpUNvt148hqybhUpHQ4REZFqMGFRkc7+jRDo6YD8Ig1+ieD6QkREROWYsKhsfaHyQnKiW4jrCxEREZViwqIyj3dsAnsrc8Rez8XBmHSlwyEiIlIFJiwqY2dljtGdmsj9H8KvKB0OERGRKjBhUXHl2z/OpeBa5i2lwyEiIlIcExYVauHugLCAxhBDWDjFmYiIiAmLao1/qKm8XX04DrcKub4QEREZt2olLPPnz0eXLl3g4OAAd3d3jBw5EtHR0ZWO6dOnj5ztUnGbPHlypWPi4uIwdOhQ2Nrayt8za9YsFBcX180ZGYh+QR7wc7GV9Vh+Pc4pzkREZNyqlbDs3bsXU6dOxaFDh7Bjxw4UFRVhwIAByM3NrXTcxIkTkZSUpNsWLlyoe66kpEQmK4WFhTh48CBWrFiB5cuXY+7cuXV3VgbAzNRE18qy7EAspzgTEZFRM9FqtTX+JExLS5MtJCKR6d27t66FpUOHDvj888+r/JmtW7di2LBhSExMhIeHh3xs6dKlmD17tvx9lpaW9/13s7Oz4eTkhKysLDg6OsJQ3SwoRthHO5FTUIxl47vgkdbuSodERERUY7X5/K7VGBbxDwouLi6VHl+1ahVcXV3Rrl07zJkzB3l5ebrnwsPDERwcrEtWhIEDB8qTiIqKqvLfKSgokM9X3IyBqMfyVBdfuf/9/lilwyEiIlJMjRMWjUaDGTNm4KGHHpKJSblnn30WK1euxO7du2Wy8uOPP+L555/XPZ+cnFwpWRHK74vn7jZ2RmRk5Zuvb+mHuDF4sUdTmJoAf168jgspOUqHQ0REpAjzmv6gGMty5swZ7N+/v9LjkyZN0u2LlhQvLy/069cPMTExaN68eY3+LZH4zJw5U3dftLAYS9Li62KLAW08sS0qWY5lmT+qvdIhERER6UcLy7Rp07B582bZiuLj43PPY7t16yZvL126JG89PT2RkpJS6Zjy++K5qlhZWcm+roqbMZnQq5m8XX/8GjJyC5UOh4iISN0JixifK5KVDRs2YNeuXWjWrPSD9F5Onjwpb0VLixAWFobIyEikpqbqjhEzjkQS0qZNm+qfgZGs4hzcxAkFxRr8dCRO6XCIiIjUnbCIbiAxPmX16tWyFosYcyK2W7dKy8eLbp8PPvgAERERuHLlCn777TeMGzdOziBq3760K0NMgxaJydixY3Hq1Cls374d77zzjvzdoiWF7iRq2bzUs3SK84qDV1BYrFE6JCIiIvUmLEuWLJEzg8TUZdFiUr6tXbtWPi+mJP/xxx8yKQkMDMQbb7yB0aNHY9OmTbrfYWZmJruTxK1obREDckVSM2/evLo/OwMyNNgb7g5WSM0pwJbIJKXDISIi0p86LEoxljost/t610V88t8Lsnvot2kPyZYXIiIifaFYHRZqWM9284eVuSkir2Xh2NUbSodDRETUYJiw6BEXO0uM6tRE7rOQHBERGRMmLHpm/EOlM7O2RyUjPuN/FYSJiIgMGRMWPdPKwwG9WrpCrIUoZgwRERHVpeISDZKySmf/qgkTFj30Us/SVpa1R+PlAolERER1ZXtUCnp9vBvv/Vb1+n5KYcKihx5u6YYANzu5ivO6Y/FKh0NERAZCq9Xi230xKNZo4WhjATVhwqKHTE1N8FLZWJblB6+gRPQPERER1dLh2AycSsiSM1LHhflDTZiw6CkxW8jJxgJX0/Ow81zltZmIiIhq4tt9l+Xt6FAfuNqrq/o8ExY9ZWtpjme7+cn97w9wijMREdXOxZQc7DqfClGTdGKvAKgNExY9JprrzExNcOhyBqISs5QOh4iI9Ni//ixtXRnQxgPNXO2gNkxY9JiXkw2GBJeugv39fk5xJiKimknNzsfGE4lyf1Jv9bWuCExY9NyEsinOm04lIjUnX+lwiIhIDy07eAWFJRqE+jdCqL8L1IgJi57r4OuMTn7O8g9t5aE4pcMhIiI9c7OgGKsOXVV164rAhMUATOhZ+ge28tBV5BeVKB0OERHpkbVH45GdXyzHrTwa5AG1YsJiAAa29YBPIxtk5BaykBwRET2wohKNbjHdl3s1k3W+1IoJiwEwNzPVTUH79s/Lch0IIiKi+9kSmYRrmbfQ2M4Sozv5QM2YsBiIpzr7wsXOEvEZt7DlTLLS4RARkV6U4b8s91/o0RTWFmZQMyYsBsLG0gwvhDWV+0v3xMg/RCIiors5GJOOqMRsWFuYYmx3dZXhrwoTFgMrJGdjYYazSdn48+J1pcMhIiIV+6asdUW00Deys4TaMWExIOIPbkxXX7m/dG+M0uEQEZFKnUvKxr4LaRBjbF8um2mqdkxYDMzLvQJgbmoim/pOJ2QqHQ4REam4DP/gdl7wa2wLfcCExcA0cbbBYyHecp+tLEREdLukrFv47aS6y/BXhQmLAXrl4ebyduuZZMRez1U6HCIiUpFlB66gWKNF12YuCPF1hr5gwmKAWns6oG+gO8REofIpa0RERNn5RVh9uHQZl1f0qHVFYMJioKb0KW1l+fV4AhdFJCIiac2ROLl2UAt3ezzS2h36hAmLgerS1EWuullYrJHNf0REZNwKi0UZ/tLPg0m9AlRdhr8qTFgM2OSysSxiUcSc/CKlwyEiIgVtOpWI5Ox8uDlYYUTH0skZ+oQJiwHrF+iOlu72yMkv1vVZEhGR8dFqtbqpzC/2aAorc3WX4a8KExYDJpr7yqesfbc/FgXFJUqHRERECth38TrOJ+fA1tIMz3dTfxn+qjBhMXAjOjSBl5M1UnMKsOH4NaXDISIiBXy7r7Qu15gufnCytYA+YsJi4CzNTTGhZzO5L6Y4l2i4KCIRkTE5FZ+JA5fSYWZqgpd6li6Sq4+YsBiBMV394GhtjsvXc7HjbLLS4RARUQP6evcleTuigzd8GulHGf6qMGExAvZW5hgXVppVL9l7WQ6+IiIi41jkcMfZFJiYAH/p0wL6jAmLkXjxITEq3FQ2DR66nKF0OERE1AAWl7WuDAn2ksXi9BkTFiPham+FJzv7yH0uikhEZPhi0m7i98gkuT/tEf1uXRGYsBiRSb2aQxQ23HshDWcTs5UOh4iI6tE/d8fINeX6B3kgyMsR+o4JixHxa2wrmwWFb8qmuBERkeGJz8jDxpOlpSym9dX/1hWBCYuRluvffDpJ/kETEZHhWbI3Rpax6NXSFR18nWF0Ccv8+fPRpUsXODg4wN3dHSNHjkR0dHSlY/Lz8zF16lQ0btwY9vb2GD16NFJSUiodExcXh6FDh8LW1lb+nlmzZqG4uLhuzojuqV0TJ/kHLP6Q2cpCRGR4krJu4ZdjCXJ/et+WMBTVSlj27t0rk5FDhw5hx44dKCoqwoABA5Cbm6s75vXXX8emTZuwbt06eXxiYiJGjRqle76kpEQmK4WFhTh48CBWrFiB5cuXY+7cuXV7ZnRXU8sGX/18NEH+YRMRkeH4dt9lFJZo0LWZi9wMhYm2FkU50tLSZAuJSEx69+6NrKwsuLm5YfXq1XjiiSfkMefPn0dQUBDCw8PRvXt3bN26FcOGDZOJjIeHhzxm6dKlmD17tvx9lpaW9/13s7Oz4eTkJP89R0f9H0ikhKe/Ccfh2Ay8EOaP90e0UzocIiKqA9dvFqDnx7uQX6TBjxO6oldLN6hJbT6/azWGRfyDgotLaQYXEREhW1369++vOyYwMBB+fn4yYRHEbXBwsC5ZEQYOHChPIioqqsp/p6CgQD5fcaPaea1faTPhT0fjkZKdr3Q4RERUB77bHyuTlRBfZ/Rs4QpDUuOERaPRYMaMGXjooYfQrl3pN/Tk5GTZQuLsXHmAj0hOxHPlx1RMVsqfL3/ubmNnREZWvvn6+tY0bCoT1rwxujRthMJiDeuyEBEZgMy8Qvxw8Ircn/5IC5iI8rYGpMYJixjLcubMGaxZswb1bc6cObI1p3yLj4+v93/T0Ik/5FfLWllWH45DKltZiIj02vKDV5BbWCJrrvQLcoehqVHCMm3aNGzevBm7d++Gj09p9VTB09NTDqbNzMysdLyYJSSeKz/m9llD5ffLj7mdlZWV7OuquFHtiebCTn7OKCjWyEFaRESkn3Lyi7DswBVdVVtDa12pdsIixueKZGXDhg3YtWsXmjVrVun50NBQWFhYYOfOnbrHxLRnMY05LCxM3he3kZGRSE1N1R0jZhyJJKRNmza1PyOqUSvLysNXkZZToHRIRERUAysPxSHrVhGau9lhULuqv/wbVcIiuoFWrlwpZwGJWixizInYbt0qnRorxpdMmDABM2fOlK0vYhDu+PHjZZIiZggJYhq0SEzGjh2LU6dOYfv27XjnnXfk7xYtKdSwHm7lJgdniUFa//6TrSxERPrmVmGJ7v1blK0wE2uwGHvCsmTJEjmGpE+fPvDy8tJta9eu1R3z2WefyWnLomCcmOosunnWr1+ve97MzEx2J4lbkcg8//zzGDduHObNm1e3Z0YP3Moyo6yV5Yfwq0i/yVYWIiJ98tOROKTnFsLXxQaPhXjDUNWqDotSWIelbok/gRGLD+B0QpYs3f/24EClQyIiogdQUFyC3gt3IyW7APNHBeOZrn5QM8XqsJABjWUpK9/8Q/gVZOQWKh0SERE9gF8iEmSy4uVkjVGdmsCQMWEhSUyBa+vtiLzCEny3n2NZiIjUrqhEgyV7SutovdI7AFbmZjBkTFjojhlDKw5elQWIiIhIvf5zMhEJN27B1d4SY1TeFVQXmLCQzqNBHgj0dMDNgmJ8vz9W6XCIiOguSjRa/HP3Jbk/sVcArC0Mu3VFYMJCOqamJro1hkQBoqy8IqVDIiKiKmyJTMLl67lwtrXAc939YQyYsFAlA9t6orWHA3IKirHsIFtZiIjU2Lryxc6Lcn98j2awtzKHMWDCQne0skzv10Lui26h7Hy2shARqclvp67hUupNONlYYHzPpjAWTFjoDkPaeaGluz2y84uxomxtCiIiUsfMoM//KG1dEXWzHK0tYCyYsFCVrSzT+pa2svx7f6xcVIuIiNRRd+Vqep6cGfRCD+MYu1KOCQtVaVh7bwS42cnFtETJfiIiUlZ+UQm+LBu78pc+LWBraRxjV8oxYaEqicWzppe3svx5GbkFxUqHRERk1NYciUNSVj48Ha3xbDfDr7tyOyYsdFfD23ujmasdbuSxlYWISOkVmb/eXVrVVkyMMIa6K7djwkJ3ZW5mimmPlLay/OvPy7KgHBERNbwfwq/g+s0CuSLzk6G+MEZMWOieRnTwRtPGtnJBRFa/JSJqeGLiw9K9pa0rr/VrBUtz4/zoNs6zpmq1sswc0Fru/2vfZdzgSs5ERA1KVB6/kVckJ0KM7OANY8WEhe5rWLAX2ng5yuq3S8qyfCIiqn9iIVrxZVGY+Wgr+SXSWBnvmVO16rLMGljayrLi4BUkZ+UrHRIRkVEQ4wfFl8VATwdZ1NOYMWGhB9KntRu6NG2EgmKNbg0LIiKqP2KQregOEt4Y0Fp+eTRmTFjogZiYmOCtQYFy/+dj8Yi9nqt0SEREBm3JnhjkFZYgxMcJ/YPcYeyYsNAD69LUBY+0dpMrhX6644LS4RARGSzR9f7joau61hUTE+NuXRGYsFC1vFk2lmXTqUREJWYpHQ4RkUH6evdFFBZr0LWpC3q1dFU6HFVgwkLV0tbbCcNDSqfVfbI9WulwiIgMTnxGHtYejZf7bwxoxdaVMkxYqNrE1Dqx1tDu6DQcic1QOhwiIoMiFjgsKtHKlpVuAY2VDkc1mLBQtYn1hZ7uUloaeuG289BqtUqHRERkEC6n3cSvxxN0Y1fof5iwUI282rclrMxNcezqDeyOTlU6HCIig/D5Hxeh0QL9gzzQwddZ6XBUhQkL1YinkzVe7NFU7i/afgEa8QojIqIaO5+cjU2nE3Vd71QZExaqsckPN4eDlTnOJf3vRUZERDXz6X8vQPSwD23vhTbejkqHozpMWKjGGtlZYlLvALkv6rIUlWiUDomISC+diLuB/55NgShm+3r/lkqHo0pMWKhWXurZDK72lrianicr4BIRUfWIiQsfbTkn90d38kELdwelQ1IlJixUK3ZW5pj6SAvdVLz8ohKlQyIi0iuiZeXolRuwtjDlzKB7YMJCtfZsNz80cbZBSnaBXM2ZiIgejOhKX7D1vNyf2CtATmigqjFhoVqzMjfDjLI+1yV7Y5CdX6R0SEREeuGnI3FyMVnRtf7Kw82VDkfVmLBQnRgl+13tkZlXhH/tu6x0OEREqie+3Im6K8KM/q1gb2WudEiqxoSF6oQo1f/mgNK6Ad/tj0VaToHSIRERqdrSPTHIyC1Eczc7jCmrHk53x4SF6szAtp4I8XFCXmEJvtpV+q2BiIjulJh5S365E+YMDoK5GT+O74f/h6jOiBVFZw8OlPurDsfhUmqO0iEREanSJ/+NRkGxBt2auaBfkLvS4egFJixUp3o0d5VrYJRotPjH76V1BYiI6H/OXMvChhPX5P7fhgbJL3t0f0xYqM79dUggzE1NsDs6DfsupCkdDhGR6orEiRL8Izp4o70PFzist4Rl3759GD58OLy9vWVWuHHjxkrPv/jii/LxitugQYMqHZORkYHnnnsOjo6OcHZ2xoQJE3Dz5s3qhkIqFeBmj3FhpQsjfvj7WRSzZD8RkbQnOg0HY9JhaW6KN1kkrn4TltzcXISEhGDx4sV3PUYkKElJSbrtp59+qvS8SFaioqKwY8cObN68WSZBkyZNqm4opGKv9WsJZ1sLXEi5ibUs2U9EJL+8lZfgH9+jKXxdbJUOSa9Ue9L34MGD5XYvVlZW8PT0rPK5c+fOYdu2bTh69Cg6d+4sH/vqq68wZMgQfPLJJ7LlhvSfk60FZvRrifc2nZUrkA4P8YajtYXSYRERKWZdRAIupt6UX+b+UrakCSk8hmXPnj1wd3dH69atMWXKFKSnp+ueCw8Pl91A5cmK0L9/f5iamuLw4cNV/r6CggJkZ2dX2kj9nuvujwA3O6TnFmLx7ktKh0NEpJjcgmK5qr3wat+WcLLhFzjFExbRHfTDDz9g586d+Pjjj7F3717ZIlNSUrooXnJyskxmKjI3N4eLi4t8rirz58+Hk5OTbvP1ZYEdfWBhZoq/DQmS+8v2X0Fcep7SIRERKeLbfZdlQU3/xrZ4vru/0uHopTpPWMaMGYPHHnsMwcHBGDlypByjIrp/RKtLTc2ZMwdZWVm6LT6eYyL0Rd9Ad/Rs4YpCscDXNk5zJiLjk5qdLxMWYfagQDnglqqv3v+vBQQEwNXVFZculXYJiLEtqamplY4pLi6WM4fuNu5FjIkRM4oqbqQfxCyxd4YFwdQE2BKZjCOxGUqHRETUoERX0K2iEnTyc8bgdlV/zpEKEpaEhAQ5hsXLy0veDwsLQ2ZmJiIiInTH7Nq1CxqNBt26davvcEgBgZ6OeLqLn9z/YPNZaDRapUMiImoQ0ck5+LlspiSLxDVwwiLqpZw8eVJuQmxsrNyPi4uTz82aNQuHDh3ClStX5DiWESNGoEWLFhg4cKA8PigoSI5zmThxIo4cOYIDBw5g2rRpsiuJM4QM18xHS1cijaxQ4ZGIyNDN33oO4jvakGBPhPq7KB2OcSUsx44dQ8eOHeUmzJw5U+7PnTsXZmZmOH36tBzD0qpVK1kQLjQ0FH/++afs1im3atUqBAYGol+/fnI6c8+ePfHtt9/W7ZmRqrg5WGFq2TS+hdvPI6+wWOmQiIjq1YFL12WhOAszE7w1sHSdNao5E62oE6xnxLRmMVtIDMDleBb9kV9Ugv6f7kXCjVuY0b8lZvRvpXRIRET1ViRu2Ff7cT45By/2aIr3HmurdEh6//nNocrUYKwtzOQy6sI3ey8jOStf6ZCIiOrFykNXZbIiisSJyt9Ue0xYqEGJftzO/o3kiHnRNUREZGiu3yzA/5UViZs1sDUa2VkqHZJBYMJCDUqMkP/7sDZyf/3xazidkKl0SEREdWrhtvPIyS9GuyaOGFM2Q5JqjwkLNbgQX2c83rGJbpqzHg6jIiKq0om4G/j5WILcf/+xdjATRaioTjBhIUW8Nag1rC1McfTKDWw9U/WSDERE+qREo8Xc/0TJ/SdDfRDq30jpkAwKExZShJeTDSb1bq6rUyBmEBER6bO1R+NlrSkHa3O8NYjTmOsaExZSzOSHA+DhaIX4jFty1hARkb66kVuom0ggCmWK2lNUt5iwkGJsLc3xztDSAbiL91zC1fRcpUMiIqqR/9sRjcy8IrT2cMBYrsZcL5iwkKKGtfcqXc25WCP7fjkAl4j0zZlrWVh1OE7uzxvRFuZm/GitD/y/SopPcxYvcEszU+y9kIbtURyAS0T6QyzmOvc/ZyC+a43o4I1uAY2VDslgMWEhxQW42cvxLML7m84it4DrDBGRflh/4hqOx2XCztIMfx1SWsmb6gcTFlKFvzzSAr4uNkjKyscXOy8qHQ4R0X1l5xdhwdZzcv/Vfi3h4WitdEgGjQkLqWadoXmPtZP73+2PRXRyjtIhERHd0+c7LuL6zUIEuNlh/EPNlA7H4DFhIdV4JNAdA9t6yOJL72yM5ABcIlKt88nZWBF+Re6/N7wtLM35cVrf+H+YVGXu8LawsTCTFXB/PX5N6XCIiO4gvky9+58o+eVqUFtP9G7lpnRIRoEJC6lKE2cbvNa/dCn2+VvOITOvUOmQiIgq2XQ6CYdjM+TyIu8M40DbhsKEhVRnQs9maOluj/TcQizaHq10OEREOmIW4z9+Pyv3p/ZpAZ9GtkqHZDSYsJDqWJiZ4sORpQNwVx+Jw8n4TKVDIiKSvtx1ESnZBfBzscXE3qXlGKhhMGEhVRLFl0Z1aiKLMf1tQ6TsKyYiUtKl1Bx8vz9W7r87vI2c3UgNhwkLqdacwUFwtDZHVGI2Vh66qnQ4RGTkFW3f/jUSRSVa9A10R78gD6VDMjpMWEi1xGqns8qWaP9kezRSc/KVDomIjNSqw1dx7OoNWdH2g7Iua2pYTFhI1Z7t6ocQHyfkFBTjo99LK0oSETWkxMxbWLD1vNx/a1CgnM1IDY8JC6mamakJPhwZDBMTYOPJRByMua50SERkZDVX3tl4BrmFJejk54yx3f2VDsloMWEh1Qv2cdK9Sfx94xkUFmuUDomIjKjmyq7zqXJF+Y9Ht4epqYnSIRktJiykF94Y0Bqu9paIScvFv/68rHQ4RGQEbuQW4v3fouT+1EdaoKWHg9IhGTUmLKQXnGws8LehpRUlxWrOl1JvKh0SERm4DzaflQUsW3nYY0qf5kqHY/SYsJDeGNmhCfq0dpNdQrN+OcXaLERUb/ZeSMP6E9fk+LkFo9tzcUMV4BUgvWFiYoL5o4LhYGWOE3GZugJORER1XX7/r+sj5f6LPZqik18jpUMiJiykb7ycbHRdQ5/8NxqX09g1RER1S7y3XMu8JacvvzmgtdLhUBkmLKR3nu7ii14tXVFQrMFbv5xm1xAR1ZnjcTew/OAVuf/RqGDYWZkrHRKVYcJCets1JCpOisqTK8reXIiIakOMj3v719NyDbNRHZvg4VZuSodEFTBhIb0klnSfM6S0a2jh9vO4mp6rdEhEpOeW7InBhZSbaGxnib8Pa6N0OHQbJiyk12X7wwIaI7+otGtILE5GRFQTF1Ny8PXui3J/7vA2aGRnqXRIdBsmLKS3RMXJhU+0h62lGQ7HZmDlYa7oTETVJ77szP71tG4l5sdCvJUOiarAhIX0mq+LLWaXregsFieLz8hTOiQi0jM/HrqK43GZsLcyx4cj28lxcqQ+TFhI74l1hro2c0FeYYn8liQWKyMiehBi+vLCbaUrMc8e1BreXIlZtZiwkGF0DY1uD2sLUxyMScfqI3FKh0REekB8uREF4sRKzJ39G+G5blyJWc2YsJBBaOpqh1kDS7uG5m85L781ERHdy8pDV2UJflF2f8HoYK7ErHJMWMhgiBLaof6NcLOguKyWAruGiKhqMWk38Y8t5+T+24MC0cKdKzEbXMKyb98+DB8+HN7e3nJg0saNGys9Lz4k5s6dCy8vL9jY2KB///64eLF0qli5jIwMPPfcc3B0dISzszMmTJiAmzdZYp1qx6xs1pCVuSn+vHgdPx+LVzokIlKhohINZqw5KUsi9GzhKr/skPpVO2HJzc1FSEgIFi9eXOXzCxcuxJdffomlS5fi8OHDsLOzw8CBA5Gfn687RiQrUVFR2LFjBzZv3iyToEmTJtXuTIgANHezxxsDWsn9DzefQ1IWu4aIqLIv/riIyGtZcLKxwCdPhrArSE+YaGvRbi5aWDZs2ICRI0fK++JXiZaXN954A2+++aZ8LCsrCx4eHli+fDnGjBmDc+fOoU2bNjh69Cg6d+4sj9m2bRuGDBmChIQE+fP3k52dDScnJ/m7RSsNUUVibaHRSw7iZHwmHmnthu9f7MJpikQkHbuSgae+CYeoM7n42U4Y2t5L6ZCMSnYtPr/rdAxLbGwskpOTZTdQORFYt27dEB4eLu+LW9ENVJ6sCOJ4U1NT2SJTlYKCAnmSFTeie3UNffJkezmQbnd0GtYcZdcQEQE5+UV4/eeTMlkZ1akJkxU9U6cJi0hWBNGiUpG4X/6cuHV3d6/0vLm5OVxcXHTH3G7+/Pky8SnffH196zJsMkBiAN2bZV1D72+KwqXUHKVDIiKFzdt0FvEZt9DE2QbvPdZW6XDIEGcJzZkzRzYflW/x8fzGTPf3cs8A9GrpKgfWTf9JDLArUTokIlLItjNJWBeRANE7/NnTHeBobaF0SKRkwuLp6SlvU1JSKj0u7pc/J25TU1MrPV9cXCxnDpUfczsrKyvZ11VxI7ofMZDu/54MgYudJc4lZePjsmqWRGRcUrPzMWd9pNyf/HBzWRmbjDxhadasmUw6du7cqXtMjDcRY1PCwsLkfXGbmZmJiIgI3TG7du2CRqORY12I6pK7o7UczyIsO3AFu89XTpaJyLCJySBv/nIaN/KK0NbbEa/3L+0qJiNIWES9lJMnT8qtfKCt2I+Li5MzMWbMmIEPP/wQv/32GyIjIzFu3Dg586d8JlFQUBAGDRqEiRMn4siRIzhw4ACmTZsmZxA9yAwhourqG+ihq7Pw5rpT8tsWERmHH8KvYt+FNFmf6YsxHeRgfNJP1b5yx44dQ8eOHeUmzJw5U+6LYnHCW2+9henTp8u6Kl26dJEJjpi2bG1trfsdq1atQmBgIPr16yenM/fs2RPffvttXZ4XUSVvDw5EkJcj0nML8ca6U3I5eSIybGKw/Udl1Wz/OiSI1WyNuQ6LUliHhWr65jXsq/1yEO5fhwRiUu/mSodERPWksFiDx/95AFGJ2ejdyg0rxrMekxqopg4LkZqJb1dzh5VOZVy0PRqRCVlKh0RE9eTzPy7IZKWRrQUWPdGeyYoBYMJCRuWZrr4Y1NYTRSVavLrmBHILipUOiYjq2JHYDCzZGyP3548Khofj/4YkkP5iwkJGRXzLEsvIezlZI/Z6Lt79LUrpkIiorqvZrj0JMdjhyVAfDGrHaraGggkLGR1nW0t8/nQHiPXOfolIwG+nEpUOiYjqgBiSOfvX07iWeQu+LjZ4l9VsDQoTFjJK3QIaY9ojLeT+39ZHIj4jT+mQiKiWvj9wBVsik2FhZoIvx3SEvZW50iFRHWLCQkbr1X4tEerfCDkFxXhtzQkUl2iUDomIarEK8/yyKczvDG2Djn6NlA6J6hgTFjJa5mamsmvIwdocx+My8cXOi0qHREQ1cP1mAaauPo5ijRbDQ7wxLsxf6ZCoHjBhIaPm62KLjx4Plvtf776EQ5fTlQ6JiKqhRKOVLaQp2QVo4W6PBaOCOYXZQDFhIaMnvpGJ2QRiVoF440vNYel+In3x2Y4LOHApHbaWZlj6fCfYcdyKwWLCQgTgvcfaoqW7vfyWNnXVcVklk4jUbee5FNkyKiwY3Z6l9w0cExYiQH4r+2ZsKByszHH0yg18+PtZpUMionsQM/tEvRXhhTB/PBbCxXMNHRMWojIBbvb4fEwH3QqvPx+LVzokIqpCflEJpqyKQHZ+MTr4OuNvQ9soHRI1ACYsRBX0C/LAjP4t5f47G8/gVHym0iER0W3e33QWZ66VrhO0+LlOsDTnR5kx4FUmus2rfVuif5C7HMcyeWWEnDJJROrwa0QCfjoSBzER6IsxHdHE2UbpkKiBMGEhuo2pqQk+fboDAlztkJSVLwfhFrGoHJHizidn428bI+X+jH6t0LuVm9IhUQNiwkJUBUdrC3w7LhR2lmY4HCsqaJ5XOiQio5adX4QpK48jv0iDh1u5YXrf0qU1yHgwYSG6CzFF8v+eKh2E+/2BWGw4kaB0SERGu6jhW+tOyxXWRReQXLxUrF5KRoUJC9E9DGrnqfsm9/avkThzLUvpkIiMznf7Y7EtqnRRQzHItpGdpdIhkQKYsBDdx4z+rdCntRsKijV45ccIZOQWKh0SkdHYE52Kj8oWNZw7rI2cxkzGiQkL0X2YmZrgi6c7wr+xLa5l3sL0n45zZWeiBhpkO231CWi0kMtnPN+dixoaMyYsRA/AydYC347tLNcrEeuWLNoerXRIRAYtNTsfLy07ipsFxQgLaIx/PM5FDY0dExaiB9Ta0wGLngiR+9/su4xNpxKVDonIIN0qLMHLPxxDYlY+AtzssPT5UBaHIyYsRNUxtL0XJj/cXO6/9ctpRCVyEC5RXdJotHKNoNMJWbKS7bIXu8gWTiImLETVNGtga/Rq6YpbRSUYv+woEm7kKR0SkcH4eNt5OSPI0swU347rDP/GdkqHRCrBhIWoBoNwv362E1p7OCA1pwAvLjuKrLwipcMi0nui5L7obhUWPtEeXZq6KB0SqQgTFqIacLKxwLLxXeDpaI1LqTcx8YdjcgVZIqqZ/RevywVHBbEA6ciOTZQOiVSGCQtRDXk722D5S13gYGWOI1cy8MbPp2T/OxFVz8WUHExZFYESjRaPd2yC1/qVrphOVBETFqJaCPR0xDfjQmUFzt8jk/Dh76UFrojowYjV0McvP4qc/GJ0adoIC0Zz+jJVjQkLUS31aO6KT54M0a059O8/S/vgiejeRDeq6E5NuHFLFmb8ZmxnWJmbKR0WqRQTFqI6MKJDE8wZHCj3RSsLa7QQ3ZvoPn1j3SmciMuUY8K+f7ELXLhGEN0DExaiOjKpdwBe7NFU7ovxLOEx6UqHRKRan+64gN9PJ8nuVFEYrrmbvdIhkcoxYSGqI6Lf/e/D2mBQW08Ulmgw6cdjuJCSo3RYRKqz5kgcvt59Se5/9Hgwwpo3Vjok0gNMWIjquEbL52M6oLN/IzmI8IXvjyA5K1/psIhU4z8nr2HOhki5P/WR5niys6/SIZGeYMJCVMesLczw7xc6o7mbHZKy8vHisiPIzmdhOaJtZ5Ix8+dT0GqB57r54c0BrZUOifQIExaieuBsa4nl47vCzcEK55NzMPnHCBQWa5QOi0gxu6NTMf2n47LWyuhOPvhgRDtOX6ZqYcJCVE98XWzlwm12lmY4GJOON9edkm/WRMZGDEAXSXtRiVYuIPrx6GCYmjJZoephwkJUj9o1ccKS50NhbmqC304lYtYvTFrIuERcvYEJK46ioFiD/kHu+PzpDjA340cPVR//aojqWe9WbvjymY5yQO7649eYtJDROHMtCy9+fwR5hSVyhXOxaKgFkxWqoTr/y3nvvfdkv2TFLTCwtKCWkJ+fj6lTp6Jx48awt7fH6NGjkZKSUtdhEKnKkGAvfMWkhYxIdHIOxn53GDkFxeja1AXfjA2VA9KJaqpeUt22bdsiKSlJt+3fv1/33Ouvv45NmzZh3bp12Lt3LxITEzFq1Kj6CINIVZi0kLG4nHYTz/37MG7kFSHE1xnfvdgZtpbmSodFeq5e/oLMzc3h6el5x+NZWVn47rvvsHr1avTt21c+tmzZMgQFBeHQoUPo3r17fYRDpKqkRZj+0wmZtAiLngiRSQyRIYjPyJPJiljUMMjLESvGd4GDtYXSYZEBqJcWlosXL8Lb2xsBAQF47rnnEBcXJx+PiIhAUVER+vfvrztWdBf5+fkhPDz8rr+voKAA2dnZlTYifcWWFjJUokiiSFZE/SFRh+jHCV3lFH8iVSYs3bp1w/Lly7Ft2zYsWbIEsbGx6NWrF3JycpCcnAxLS0s4OztX+hkPDw/53N3Mnz8fTk5Ous3Xl5URybCSlrd+Oc2khfSaaFF57t+HEJeRJ1deXj2xO1ztrZQOiwxInXcJDR48WLffvn17mcD4+/vj559/ho2NTY1+55w5czBz5kzdfdHCwqSFDCFpERU/X11zAr8eT5CPLXyiPbuHSO+k5RTIAbYxabnwdrLGqpe7wcPRWumwyMDU+/wy0ZrSqlUrXLp0SY5rKSwsRGZmZqVjxCyhqsa8lLOysoKjo2OljcgQiCJaX44pbWkRSQtbWkjfxKXn4YmlB2VFZ1HZedXE7vBpZKt0WGSA6j1huXnzJmJiYuDl5YXQ0FBYWFhg586duuejo6PlGJewsLD6DoVIlZi0kL46l5SN0UsP4mp6HnxdbLDulTA0c7VTOiwyUHXeJfTmm29i+PDhshtITFl+9913YWZmhmeeeUaOP5kwYYLs3nFxcZEtJdOnT5fJCmcIkbEnLQK7h0hfHInNkBVsxarkgZ4O+OGlrnBnNxDpU8KSkJAgk5P09HS4ubmhZ8+ecsqy2Bc+++wzmJqayoJxYvbPwIED8c9//rOuwyDS+6Qlv6gE//dUCIttker8cTYFU1cfl+X2RVG4f73QGU42nLpM9ctEqxXD/vSLGHQrWmtEXReOZyFDsyUyCa+tOSEXiuvs3wj/GtcZjew4NZTUYd2xeLy9PlJ2W4q1gUS5fSbV1BCf31zUgUiFs4dWvNQVDtbmOHb1BkYtEWMEcpUOiwjf7I3BrLIxVk+E+mDp8yy3Tw2HCQuRCvVo7or1U3qgibMNYq/nYtQ/D+JE3A2lwyIjJRri5285h/lbz8v7k3oHYNET7bnqMjUo/rURqVRLDwdsmNoD7Zo4Ij23EM/86xC2R929wCJRfSgu0chWlW/2XZb35wwOxF+HBMmFbYkaEhMWIhVzd7DG2klh6BvojvwiDSavjMD3+2OVDouMhBj4Lf7mfolIkDPWxMy1Vx5urnRYZKSYsBCpnJ2VOb4dG4rnuvnJyrjzNp/FvE1nWauF6lXWrSKM++4I/jiXCitzUzle5anOrDBOymHCQqQHxFiBD0e2w9uDA+X97w/EYuqq4/IbMFFdu5iSg8cXH8CRKxly8LeosfJoGw+lwyIjx4SFSE+IMQOTH24uF020NDPFtqhkOa4l/WaB0qGRAfn9dBJGLD6Ay9dL1wUSXZLdAhorHRYRExYifTM8xBsrX+4mC3WdiMuU057FTCKi2g6u/WjLOVkQLq+wBD2aN8am6T3Rxpu1rkgdmLAQ6aGuzVzw65Qecv0WsY7LyMUHZPVRopoQrXRjvzuCb8tmAr3SO0B2AzW2t1I6NCIdJixEeqqFuz3WT3kIHXyd5QDJl384hg83n0VhsUbp0EiPnIrPxPCv9iP8cjpsLc2w+NlOmDMkiDVWSHX4F0mkx9wcrLD2le546aFm8v6/98fiyW/CEZ+Rp3RopAfWHInDk0vDkZiVjwBXO/xn6kO6Na2I1IYJC5GeszI3w9zhbeTUZ0drc/mNeeiXf2LbGRaZo6oVFJdgzvrTck2gwhKNnAG0cdpDslghkVoxYSEyEAPaemLLa73Q0c8Z2fnFsuDXe79FyQ8nonKJmbfw1NJw/HQkHqJY7ayBrfHN8yLZ5WrLpG5MWIgMiE8jW/z8SpgcNCksP3gFTywJ5+KJJB2MuS7Hq5xKyIKzrQWWj++KqY+0gKkpy+yT+jFhITIwFmamctDk9y92RiNbC0Rey8LQL/dj8+lEpUMjhYgCg2LK8vP/PizXpWrj5YhN03ri4VZuSodG9MCYsBAZqL6BHrKLqEvTRrhZUIxpq0/gbxsiWR3XyBy7koEhX/wppyyL1RyeCPXB+r+IKfG2SodGVC0mWrFuuJ7Jzs6Gk5MTsrKy4OjIokZE9ysI9umOC/jnnhh5P9DTQVbL5QBLw5ZXWIxF26Nlt6B4l/dwtMI/RgajP0vsk55+fjNhITISey+kYebak7JLwMLMBJN6B2DaIy1hY2mmdGhUx8Jj0jH719OIK5ve/mSoD94Z1kZWRyZSEhMWInogKdn5+Ov6SOw8nyrvi0q5H4xohz6t3ZUOjepAbkExFmw9jx8PXZX3vZysMX9UMK8vqQYTFiJ6YOIlvz0qBe9vikJSVr58bGiwF/4+rA08nayVDo9qaP/F67JV5VrmLXn/ma5++OuQQDhwujKpCBMWIqo2MRD38x0XsOzgFZRotLC3MscbA1phXFhTmHGaq97Izi/C/C3nZF0VoYmzDT4e3R49W7oqHRrRHZiwEFGNRSVm4W8bzuBkfKa8366JIz56PBjtfZyVDo3uQbx1//dsiiwOWN5SNi7MH28NCpTJJ5EaMWEholrRaLT46WgcPt56XlbJFRVQx3X3xxsDW7MCqgodvpyOj7edx/G40iTTv7GtbFXpHtBY6dCI7okJCxHVibScAllgbMOJa7rFFd8ZGoTh7b1ZDVUFziZmY+H289gTnSbvW1uYyoUvp/VtAVtLtqqQ+jFhIaI6dfDSdbyz8QwuXy8t6d/aw0F+KA4J9uL4FgWIpRVELZ3/nCytVmxuaoIxXX3xat+WcHfkQGnSH0xYiKjOiUUTv917WVZIzSkolo81d7OTiYtocTE3Y6Hs+paak4+vdl7CT0fiUCzK1AIYHuKNNx5thaaudkqHR1RtTFiIqN5k3SrC8gNX8P2BWLkvNG1si7880gKPd2wi1y6iup/5I5LF7/bH4lbZUgpi3R+xsnK7Jk5Kh0dUY0xYiKje5eQX4Yfwq/j3n5dxI680cfFpZIO/9GmB0aFNYGXOirl1kaisORInl1HILPt/3MHXGbMHBSKsOQfUkv5jwkJEDVpNddXhq/h2Xyyu3yzQVVSd/HBzPN3FF9YWTFyq63RCJlYdisNvpxJ1LSot3O1li8qANh4wEdO2iAwAExYianBi1WcxtmLp3hikZBfoZhWN7e4vu4q4GvD9Ez8xiHb1kas4cy1b93hLd3tM7B2A0Z18OMCZDE42ExYiUjJxWReRgKV7YnRl4YUuTRvh8Y4+suy/ky1ruVScmixaqESyIqoNC5bmphjSzhPPdfdHZ/9GbFEhg5XNhIWIlFZYrMHm04n49XgCDsako/ydxdLMFH0D3fF4pybo09rNKMe63Coskf9vVh2O01UUFpq52uHZrn4YHeoDFztLRWMkaghMWIhIVZKybuG3k4myAN355Bzd4042FhjW3gujOjVBJz/DbknIyivCgZjr2HchDVsik2QF4fIaKgNFa0pXPzmQ1pD/HxDdjgkLEam6C2TjyWvYeOIaUnNKx7oIfi62eCzEGz1aNJYzYfS9UqtYQPJUQqZMUMQmWlLKSqfoZlQ9280PT4b6yrE+RMYomwkLEenDB3p4TDrWn0jAtjPJyCssnQ1T3urQtokTuvg3QuemLujctBFc7dX/oZ6YeQt/XhQJynXsv3RdV6emnJjp06ulK/oFeqBH88Zc3oCMXjYTFiLSJ3mFxfhvVAr+OJeCY1duIDm7dLXhigJc7WTiIhKYLk1dZLE6pbpPxNvk9ZuFiL2ei9jrN3EuKUcmKJdSb1Y6ztHaHD1buqJ3Szf0auWGJs42isRLpFZMWIhIb4m3IDG7SCQuR69kyNvolP+Neynnam+JVh4O8HSyhqejtbz1ELeO1rIOTGN7q1pPAxazdq5cz5VrKF1Ou1mWoOQiNi1XtzxBReKfE91ZvVq6oXcrN4T4OHHJAqJ6+vzW705jItJ7otXEp5Gt3EZ2bKIbsHo87n8JzMmETNnCcf1m+l1/j0hW3B2sdEmMq4OlnKlUVKJBcYkWhWW3xRoNCsVtiUY+V1SilbdipeqKY2zujLN0HEozV3vZ+tO1mQseau7KKdtEDUTRFpbFixdj0aJFSE5ORkhICL766it07dr1vj/HFhYi41uIURRXi8vIRXJWAVKy8+VMpOTsAqRk5ctFAisOcK0N0ZIjphuXbvYIcLOTCYoohMcqvkRG2MKydu1azJw5E0uXLkW3bt3w+eefY+DAgYiOjoa7u7tSYRGRConaLaH+jeRWFdFaIlpgxFiY5Kx8mdCk3yyQg1zF4owWZiYwNzWFhbkpLMoeMzcrf650v5FtaaIipl4Tkfoo1sIikpQuXbrg66+/lvc1Gg18fX0xffp0vP322/f8WbawEBER6Z/afH4rMjqssLAQERER6N+///8CMTWV98PDw+84vqCgQJ5kxY2IiIiMhyIJy/Xr11FSUgIPD49Kj4v7YjzL7ebPny8zsvJNtMQQERGR8dCL+Xdz5syRzUflW3x8vNIhERERUQNSZNCtq6srzMzMkJKSUulxcd/T0/OO462srORGRERExkmRFhZLS0uEhoZi586dusfEoFtxPywsTImQiIiISMUUm9YspjS/8MIL6Ny5s6y9IqY15+bmYvz48UqFRERERCqlWMLy9NNPIy0tDXPnzpUDbTt06IBt27bdMRCXiIiIiGsJERERUYPQuzosRERERNXBhIWIiIhUjwkLERERqR4TFiIiIlI9JixERESkeopNa66N8olNXASRiIhIf5R/btdkgrJeJiw5OTnylosgEhER6efnuJjebPB1WEQZ/8TERDg4OMDExKTOsz+RCIkFFg21xosxnKPA8zQsPE/DYQznKPA87yRSDpGseHt7w9TU1PBbWMRJ+vj41Ou/If6nG/IfmLGco8DzNCw8T8NhDOco8Dwrq27LSjkOuiUiIiLVY8JCREREqseE5TZWVlZ499135a2hMoZzFHiehoXnaTiM4RwFnmfd0stBt0RERGRc2MJCREREqseEhYiIiFSPCQsRERGpHhMWIiIiUj2jS1j+8Y9/oEePHrC1tYWzs3OVx8TFxWHo0KHyGHd3d8yaNQvFxcX3/L0ZGRl47rnnZNEc8XsnTJiAmzdvQg327NkjKwJXtR09evSuP9enT587jp88eTLUrGnTpnfEvGDBgnv+TH5+PqZOnYrGjRvD3t4eo0ePRkpKCtTqypUr8u+rWbNmsLGxQfPmzeUI/cLCwnv+nD5cz8WLF8traG1tjW7duuHIkSP3PH7dunUIDAyUxwcHB2PLli1Qs/nz56NLly6ySrd4bxk5ciSio6Pv+TPLly+/47qJ81Wz9957746YxXUypGtZ1XuN2MR7iT5fx3379mH48OGyEq2IcePGjZWeF/N05s6dCy8vL/n+079/f1y8eLHOX9tVMbqERbypP/nkk5gyZUqVz5eUlMhkRRx38OBBrFixQv6hiQt0LyJZiYqKwo4dO7B582Z50SdNmgQ1EAlaUlJSpe3ll1+WH3idO3e+589OnDix0s8tXLgQajdv3rxKMU+fPv2ex7/++uvYtGmTfMPcu3evXPZh1KhRUKvz58/L5Sm++eYb+Tf32WefYenSpfjrX/96359V8/Vcu3YtZs6cKZOv48ePIyQkBAMHDkRqamqVx4vX5zPPPCOTtxMnTsgPf7GdOXMGaiX+vsQH2qFDh+R7RVFREQYMGIDc3Nx7/pz4IlTxul29ehVq17Zt20ox79+//67H6uO1FF/2Kp6fuJ6C+HzR5+uYm5srX3siwaiKeM/48ssv5XvO4cOHYWdnJ1+n4otfXb2270prpJYtW6Z1cnK64/EtW7ZoTU1NtcnJybrHlixZonV0dNQWFBRU+bvOnj0rpoZrjx49qnts69atWhMTE+21a9e0alNYWKh1c3PTzps3757HPfzww9rXXntNq0/8/f21n3322QMfn5mZqbWwsNCuW7dO99i5c+fk9QwPD9fqi4ULF2qbNWum19eza9eu2qlTp+rul5SUaL29vbXz58+v8vinnnpKO3To0EqPdevWTfvKK69o9UVqaqr8W9u7d2+136vU7N1339WGhIQ88PGGcC3Fa6t58+ZajUZjMNcRgHbDhg26++LcPD09tYsWLar0HmplZaX96aef6uy1fTdG18JyP+Hh4bI50sPDQ/eYyATF4k7i2+zdfkZ0A1VsrRDNZGLNI5GBqs1vv/2G9PR0jB8//r7Hrlq1Cq6urmjXrh3mzJmDvLw8qJ3oAhLdOx07dsSiRYvu2Z0XEREhv+WK61VONEv7+fnJ66ovsrKy4OLiorfXU7RoimtR8TqI14+4f7frIB6veHz5a1Xfrptwv2snupf9/f3lAnMjRoy463uRmohuAtGtEBAQIFugRVf73ej7tRR/vytXrsRLL710zwV59fE6VhQbG4vk5ORK10qsCyS6eO52rWry2jaoxQ/rk7gYFZMVofy+eO5uPyP6oysyNzeXb0J3+xklfffdd/LN4H4LSD777LPyxSXedE6fPo3Zs2fL/vb169dDrV599VV06tRJ/r8XzcziQ1k0vX766adVHi+uj6Wl5R3jmcQ1V+O1q8qlS5fw1Vdf4ZNPPtHb63n9+nXZHVvVa090gVXntaov1010682YMQMPPfSQTCDvpnXr1vj+++/Rvn17meCI6yy6ecWHXX0vAltT4gNMdKWL2MXr7/3330evXr1kF48Yv2No11KM88jMzMSLL75oUNfxduXXozrXqiavbYNOWN5++218/PHH9zzm3Llz9x30ZQznnZCQgO3bt+Pnn3++7++vOAZHtDqJQVb9+vVDTEyMHOipxvMU/aTlxBuDSEZeeeUVOdhR7eWxa3I9r127hkGDBsl+czE+RR+uJ5USY1nEB/i9xnYIYWFhcisnPuSCgoLkGKYPPvgAajR48OBKr0ORwIhkWbzviHEqhkZ8CRTnLL4MGNJ1VBuDSFjeeOONe2a2gmiWfBCenp53jF4unzEinrvbz9w+eEh0Q4iZQ3f7GaXOe9myZbK75LHHHqv2vyfedMq/0TfkB1xtrq+IWVwLMbNGfMO5nbg+oslSfDuq2Moirnl9Xru6OE8xOPiRRx6Rb3zffvut3lzPqohuKjMzsztmZ93rOojHq3O8mkybNk03OL+6364tLCxkd6e4bvpCvLZatWp115j1+VqKgbN//PFHtVsq9fE6epZdD3FtxBeecuJ+hw4d6uy1fVdaI3W/QbcpKSm6x7755hs56DY/P/+eg26PHTume2z79u2qG3QrBkyJgZlvvPFGjX5+//798jxPnTql1RcrV66U1zMjI+Oeg25/+eUX3WPnz59X/aDbhIQEbcuWLbVjxozRFhcXG8T1FAPzpk2bVmlgXpMmTe456HbYsGGVHgsLC1P1QE3xGhSDD8WAwwsXLtTod4jr3bp1a+3rr7+u1Rc5OTnaRo0aab/44guDuZYVBxiLgahFRUUGdx1xl0G3n3zyie6xrKysBxp0W53X9l3j0RqZq1evak+cOKF9//33tfb29nJfbOIFVf5H1K5dO+2AAQO0J0+e1G7btk3OqJkzZ47udxw+fFj+oYkPjXKDBg3SduzYUT4nPgjEh8kzzzyjVZM//vhD/gGKWTC3E+cizknEL1y6dEnOIhJJWGxsrPY///mPNiAgQNu7d2+tWh08eFDOEBLXLSYmRiYr4tqNGzfurucpTJ48Wevn56fdtWuXPF/xRik2tRLn0KJFC22/fv3kflJSkm7T5+u5Zs0a+ca3fPly+SVg0qRJWmdnZ92MvbFjx2rffvtt3fEHDhzQmpubyzdP8TctPjhE8hkZGalVqylTpsgvSnv27Kl03fLy8nTH3H6e4r1KfAESf9MREREySbW2ttZGRUVp1Up8KRLnKP7WxHXq37+/1tXVVc6KMpRrWf7BK947Zs+efcdz+nodc3JydJ+L4vPi008/lfvis1NYsGCBfF2K95DTp09rR4wYIb8I37p1S/c7+vbtq/3qq68e+LX9oIwuYXnhhRfkRbh92717t+6YK1euaAcPHqy1sbGRLzLx4quYPYtjxc+IF2O59PR0maCIJEi0xowfP16XBKmFiK9Hjx5VPifOpeL/h7i4OPlh5uLiIv/QxAfkrFmzZDatVuJNQEyFFB8I4o0gKChI+9FHH1VqGbv9PAXxQvvLX/4ivwHa2tpqH3/88Uof/mpsHazqb7hig6m+Xk/xJic+ACwtLeW3skOHDlWali1evxX9/PPP2latWsnj27Ztq/3999+1ana36yau6d3Oc8aMGbr/Jx4eHtohQ4Zojx8/rlWzp59+Wuvl5SVjFt+kxX2RNBvStRREAiKuX3R09B3P6et13F32+Xb7Vn4uopXl73//uzwH8V4ivjjdfv6ivIRIOh/0tf2gTMR/atKXRURERNRQWIeFiIiIVI8JCxEREakeExYiIiJSPSYsREREpHpMWIiIiEj1mLAQERGR6jFhISIiItVjwkJERESqx4SFiIiIVI8JCxEREakeExYiIiJSPSYsREREBLX7f8X/QAC6d2feAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-10, 10, 0.5)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cde3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c90bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = -2\n",
    "c = 1\n",
    "d1 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c + h\n",
    "d2 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dc_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dc_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d78e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -5.000002\n",
      "da_dy =  -2.000000000279556\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "a = a + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"da_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ed6158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.9999970000000005\n",
      "db_dy =  2.9999999995311555\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "b = b + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"db_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f10ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dab_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "d2 = a*b + h + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dab_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c68b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    \"\"\" Basic class to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "        else:\n",
    "            raise ValueError(\"Can only add Value to Value\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077e5615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d._prev = (Value(data=-6), Value(data=1)) d = -5\n"
     ]
    }
   ],
   "source": [
    "a = Value(3, label=\"a\")\n",
    "b = Value(-2, label=\"b\")\n",
    "c = Value(1, label=\"c\")\n",
    "d = a*b + c; d.label = \"d\"\n",
    "print(f\"d._prev = {d._prev} d = {d.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db81115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(root):\n",
    "    \"\"\" Vibe codded and it works! \"\"\"\n",
    "    # Initialize a directed graph\n",
    "    dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})  # Left-to-right layout\n",
    "    \n",
    "    def build_graph(node, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        \n",
    "        # Skip if node already visited to avoid cycles\n",
    "        if id(node) in visited:\n",
    "            return\n",
    "        visited.add(id(node))\n",
    "        \n",
    "        # Add node to the graph\n",
    "        node_id = str(id(node))\n",
    "        dot.node(node_id, f\"{{ {node.label} | data = {node.data} grad={node.grad} }}\", shape='record')\n",
    "        \n",
    "        # If node has an operation, create an operation node\n",
    "        if node._op:\n",
    "            op_id = f\"{node_id}_op\"\n",
    "            dot.node(op_id, node._op, shape='circle')\n",
    "            dot.edge(op_id, node_id)  # Edge from operation to result\n",
    "        \n",
    "            # Recursively process children\n",
    "            for child in node._prev:\n",
    "                child_id = str(id(child))\n",
    "                build_graph(child, visited)\n",
    "                dot.edge(child_id, op_id)  # Edge from child to operation\n",
    "    \n",
    "    # Build the graph starting from the root\n",
    "    build_graph(root)\n",
    "    \n",
    "    # Render and display the graph\n",
    "    dot.render('computation_graph', view=True, cleanup=True)\n",
    "    \n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c181f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98dd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ed37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142981514304\n"
     ]
    }
   ],
   "source": [
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec8210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70612029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daba22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "922f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_dn = 1 - math.tanh(o.data)**2\n",
    "y.grad = do_dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72a71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a71919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1_x2w2.grad = y.grad\n",
    "b.grad = y.grad\n",
    "x1w1.grad = x1w1_x2w2.grad\n",
    "x2w2.grad = x1w1_x2w2.grad\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef9473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = x1w1.grad * w1.data\n",
    "x2.grad = x2w2.grad * w2.data\n",
    "w1.grad = x1w1.grad * x1.data\n",
    "w2.grad = x2w2.grad * x2.data\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "d7edad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement generic backpropagation\n",
    "class Value():\n",
    "    \"\"\" Complete class with backprop to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    visited = set()  # Set to keep track of visited nodes during backpropagation\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []  # Topological order of nodes for backpropagation\n",
    "        def build_topo(v, visited=None):\n",
    "            if visited is None:\n",
    "                visited = set()\n",
    "            if id(v) not in visited:\n",
    "                visited.add(id(v))\n",
    "                for child in v._prev:\n",
    "                    build_topo(child, visited)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for item in reversed(topo):\n",
    "            item._backward()\n",
    "            \n",
    "\n",
    "    # def backward(self, root_node, visited=None):\n",
    "    #     visited.add(self)\n",
    "    #     logger.debug(f\"node.data = {self.data}\")\n",
    "    #     if self.grad == 0.0:\n",
    "    #         print(f\"Skipping backward pass for node {self.label} {self._op} as grad is 0.0\")\n",
    "    #         return\n",
    "    #     self._backward()  # Compute the gradient for childeren of this node\n",
    "    #     for item in self._prev:\n",
    "    #         if item not in visited:\n",
    "    #             item.backward(root_node, visited)\n",
    "\n",
    "    # def backward(self, root_node, visited=None):\n",
    "\n",
    "    #     # topological order all of the children in the graph\n",
    "    #     topo = []\n",
    "    #     visited = set()\n",
    "    #     def build_topo(v):\n",
    "    #         if v not in visited:\n",
    "    #             visited.add(v)\n",
    "    #             for child in v._prev:\n",
    "    #                 build_topo(child)\n",
    "    #             topo.append(v)\n",
    "    #     build_topo(self)\n",
    "\n",
    "    #     # go one variable at a time and apply the chain rule to get its gradient\n",
    "    #     self.grad = 1\n",
    "    #     for v in reversed(topo):\n",
    "    #         v._backward()\n",
    "\n",
    "    def _backward(self):\n",
    "        \"\"\" Perform backpropagation to compute gradients. \"\"\"\n",
    "        logger.debug(f\"Backward pass for node: {self.label}, op: {self._op}, data: {self.data}, grad: {self.grad}\")\n",
    "        # For addition operation, local gradient is 1 for each child hence gradient of the child with respect\n",
    "        # to the output is 1 * self gradient.\n",
    "        # Note, we need to accumulate gradients for each child and not simply overwrite them.\n",
    "        if self._op == '+':\n",
    "            for child in self._prev:\n",
    "                child.grad += self.grad\n",
    "\n",
    "        # For multiplication operation, local gradient is the value of the other child hence\n",
    "        # gradient of the child with respect to the output is self.grad * other child's value.\n",
    "        elif self._op == '*':\n",
    "            self._prev[0].grad += self.grad * self._prev[1].data\n",
    "            self._prev[1].grad += self.grad * self._prev[0].data\n",
    "\n",
    "        elif self._op == '/':\n",
    "            # For division operation, local gradient is 1 / other child's value hence\n",
    "            # gradient of the child with respect to the output is self.grad * (1 / other child's value).\n",
    "            self._prev[0].grad += self.grad / self._prev[1].data\n",
    "            self._prev[1].grad += -self.grad * (self._prev[0].data / (self._prev[1].data ** 2))\n",
    "\n",
    "        # For power operation, local gradient is power * base^(power-1) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == '**':\n",
    "            base = self._prev[0].data\n",
    "            power = self._prev[1].data\n",
    "            self._prev[0].grad += self.grad * power * (base ** (power - 1))\n",
    "\n",
    "        # For subtraction operation, local gradient is 1 for the first child and -1 for the second child\n",
    "        # hence gradient of the first child with respect to the output is self.grad * 1 and for the second child\n",
    "        # it is self.grad * -1.\n",
    "        elif self._op == '-':\n",
    "            self._prev[0].grad += self.grad  # First child\n",
    "            self._prev[1].grad += -self.grad  # Second child\n",
    "\n",
    "        # For tanh operation, local gradient is 1 - tanh^2(self.data) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == 'tanh':\n",
    "            logger.debug(f\"tanh: self.data = {self.data}, self.grad = {self.grad}\")\n",
    "            self._prev[0].grad += self.grad * (1 - np.tanh(self._prev[0].data)**2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data - other.data, _children=(self, other), _op='-')\n",
    "        else:\n",
    "            raise ValueError(\"Can only subtract Value from Value\")\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "        \n",
    "    def __pow__(self, power):\n",
    "        return Value(self.data ** power, _children=(self,Value(power)), _op='**')\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "de7dc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "b1415a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "65eb5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0\n",
    "\n",
    "o.visited = set()  # Reset visited set for each backward pass\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "b9b0f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "160da944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142868995667\n"
     ]
    }
   ],
   "source": [
    "# Verfiy with PyTorch\n",
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2.0])\n",
    "x2 = torch.Tensor([3.0])\n",
    "w1 = torch.Tensor([0.5])\n",
    "w2 = torch.Tensor([-1.5])\n",
    "b = torch.Tensor([1.0])\n",
    "x1.requires_grad = True\n",
    "x2.requires_grad = True\n",
    "w1.requires_grad = True\n",
    "w2.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "y = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(y)\n",
    "\n",
    "print(f\"o = {o.item()}\")\n",
    "\n",
    "o.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "182b150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.grad = 0.013296124525368214\n",
      "x2.grad = -0.039888374507427216\n",
      "w1.grad = 0.053184498101472855\n",
      "w2.grad = 0.07977674901485443\n",
      "b.grad = 0.026592249050736427\n"
     ]
    }
   ],
   "source": [
    "print(f\"x1.grad = {x1.grad.item()}\") \n",
    "print(f\"x2.grad = {x2.grad.item()}\") \n",
    "print(f\"w1.grad = {w1.grad.item()}\")\n",
    "print(f\"w2.grad = {w2.grad.item()}\")\n",
    "print(f\"b.grad = {b.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "f1702ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "class N():\n",
    "    \"\"\" Class to represent a single neuron with forward and backward pass. \"\"\"\n",
    "    def __init__(self, input_size, label=\"\"):\n",
    "        self.input_size = input_size\n",
    "        self.weights = [Value(random.uniform(-1, 1), label = f\"{label} w{i}\") for i in range(input_size)]\n",
    "        self.b = Value(random.uniform(-1, 1), label=f\"{label} b\")  # Bias term\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.b]  # Return all parameters (weights and bias)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None) -> Value:\n",
    "        \"\"\" Forward pass for the neuron. \"\"\"\n",
    "        assert len(input) == self.input_size, f\"Input size {len(input)} does not match expected size {self.input_size}\"\n",
    "        wx = [w*x for w, x in zip(self.weights, input)]\n",
    "        wx_sum = Value(0.0)  # Initialize sum of weighted inputs\n",
    "        for item in wx:\n",
    "            wx_sum += item  # Sum the weighted inputs\n",
    "\n",
    "        wx_sum = wx_sum + self.b\n",
    "        if act_fn is None:\n",
    "            return wx_sum\n",
    "        elif act_fn == 'tanh':\n",
    "            return wx_sum.tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {act_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "95f55a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -2.742169638094225\n"
     ]
    }
   ],
   "source": [
    "n = N(2)  # Create a neuron with 2 inputs\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "\n",
    "o = n([x1, x2])\n",
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "f5d28c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\" Class to represent a layer of neurons. \"\"\"\n",
    "    def __init__(self, input, output, label=\"\"):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.neurons = [N(input, label=f\"{label} Neuron {i}\") for i in range(output)]\n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for n in self.neurons:\n",
    "            parameters.extend(n.parameters())  # Collect parameters from each neuron\n",
    "        return parameters\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None):\n",
    "        \"\"\" Forward pass for the layer. \"\"\"\n",
    "        outputs = [n(input, act_fn) for n in self.neurons]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "29894ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class NN():\n",
    "    \"\"\" Class to represent a simple neural network with hidden layers. \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                 hidden_layer_num: int, \n",
    "                 hidden_layer_size: int, \n",
    "                 output_size: int):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_num = hidden_layer_num\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.forward_hook = None  # Hook for forward pass\n",
    "\n",
    "        self.layers = []\n",
    "        for i in range(hidden_layer_num):\n",
    "            if i == 0:\n",
    "                # First layer takes the input size\n",
    "                self.layers.append(Layer(input_size, hidden_layer_size, label=f\"Layer {i}\"))\n",
    "            elif i == hidden_layer_num - 1:\n",
    "                # Last layer is the output layer, use output_size\n",
    "                self.layers.append(Layer(hidden_layer_size, output_size, label=f\"Layer {i}\"))\n",
    "            else:\n",
    "                # Intermediate layers use hidden_layer_size\n",
    "                self.layers.append(Layer(hidden_layer_size, hidden_layer_size, label=f\"Layer {i}\"))\n",
    "           \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for layer in self.layers:\n",
    "            parameters.extend(layer.parameters())  # Collect parameters from each layer\n",
    "        return parameters\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def register_forward_hook(self, func: Callable[[str, list[Value], list[Value]], None]): \n",
    "        self.forward_hook = func\n",
    "\n",
    "    def __call__(self, input):\n",
    "        \"\"\" Forward pass for the neural network. \"\"\"\n",
    "        assert len(input) == self.input_size, \"input size mismatch\"\n",
    "\n",
    "        x = [Value(i) for i in input]\n",
    "        for num, layer in enumerate(self.layers):\n",
    "            if num != len(self.layers) - 1:\n",
    "                act_fn = 'tanh'\n",
    "            else:\n",
    "                act_fn = None\n",
    "            input = x.copy()\n",
    "            x = layer(x, act_fn)  # Forward pass through the layer\n",
    "            self.forward_hook(f\"Layer {num}\", [i.data for i in input], [o.data for o in x]) if self.forward_hook else None\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "7e307dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # For reproducibility\n",
    "mlp = NN(input_size=3, hidden_layer_num=3, hidden_layer_size=4, output_size=1)  # Create a neural network with 2 inputs, 2 hidden layers of size 3, and 1 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "b87ae772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model information:\n",
      "input size: 3\n",
      "total model layers: 3\n",
      "[0] layer input: 3, layer output: 4, neurons: 4\n",
      "[1] layer input: 4, layer output: 4, neurons: 4\n",
      "[2] layer input: 4, layer output: 1, neurons: 1\n",
      "total model parameters: 41\n",
      "model parameters:\n",
      "[tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]), tensor([-0.5536, -0.8261,  0.0107,  0.0899]), tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]), tensor([ 0.6116, -0.3268,  0.6143,  0.1041]), tensor([[0.6588, 0.2370, 0.7234, 0.1547]]), tensor([0.4091])]\n"
     ]
    }
   ],
   "source": [
    "print(\"model information:\")\n",
    "print(f\"input size: {mlp.input_size}\")\n",
    "print(f\"total model layers: {len(mlp.layers)}\")\n",
    "for i, layer in enumerate(mlp.layers):\n",
    "    print(f\"[{i}] layer input: {layer.input}, layer output: {layer.output}, neurons: {len(layer.neurons)}\")\n",
    "print(f\"total model parameters: {len(mlp.parameters())}\")\n",
    "\n",
    "# Build tensor parameters for the model, this will be used to set the parameters in PyTorch\n",
    "mlp_tensor_parameters = []\n",
    "print(\"model parameters:\")\n",
    "\n",
    "# Save pre-defined parameters in a list of tensors\n",
    "for layer_num, layer in enumerate(mlp.layers):\n",
    "    layer_params = []\n",
    "    bias_params = []\n",
    "    for neuron_num, neuron in enumerate(layer.neurons):\n",
    "        layer_params.append([x.data for x in neuron.parameters()][:-1])\n",
    "        bias_params.append([x.data for x in neuron.parameters()][-1])\n",
    "    mlp_tensor_parameters.append(torch.tensor(layer_params))\n",
    "    mlp_tensor_parameters.append(torch.tensor(bias_params))\n",
    "    \n",
    "print(mlp_tensor_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "4fb2c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch model with the same architecture for verification\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 4),  # First hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 4),  # Second hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1)   # Output layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def hook_fn(module, input, output, name=None):\n",
    "    \"\"\" Hook function to capture the output of each layer. \"\"\"\n",
    "    print(f\"Layer: {module}, Input: {input}, Output: {output}\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\" Calculate Root Mean Squared Error. \"\"\"\n",
    "    diffs = torch.stack([(y_true_i - y_pred_i) ** 2 for y_true_i, y_pred_i in zip(y_true, y_pred)])\n",
    "    return torch.mean(diffs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "bd7853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook for layer: \n",
      "Registering hook for layer: layers\n",
      "Registering hook for layer: layers.0\n",
      "Registering hook for layer: layers.1\n",
      "Registering hook for layer: layers.2\n",
      "Registering hook for layer: layers.3\n",
      "Registering hook for layer: layers.4\n",
      "model parameters = [Parameter containing:\n",
      "tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5536, -0.8261,  0.0107,  0.0899], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.6116, -0.3268,  0.6143,  0.1041], requires_grad=True), Parameter containing:\n",
      "tensor([[0.6588, 0.2370, 0.7234, 0.1547]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4091], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmlp = MLP(input_size=3)  # Create a PyTorch model with the same architecture\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "# Register hooks to capture the output of each layer\n",
    "for name, module in tmlp.named_modules():\n",
    "    print(f\"Registering hook for layer: {name}\")\n",
    "    module.register_forward_hook(hook_fn)\n",
    "\n",
    "print(f\"model parameters = {[p for p in tmlp.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "5df68e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model parameters:\n",
      "layers.0.weight: data: tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) grad=None\n",
      "layers.0.bias: data: tensor([-0.5536, -0.8261,  0.0107,  0.0899]) grad=None\n",
      "layers.2.weight: data: tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]) grad=None\n",
      "layers.2.bias: data: tensor([ 0.6116, -0.3268,  0.6143,  0.1041]) grad=None\n",
      "layers.4.weight: data: tensor([[0.6588, 0.2370, 0.7234, 0.1547]]) grad=None\n",
      "layers.4.bias: data: tensor([0.4091]) grad=None\n"
     ]
    }
   ],
   "source": [
    "# Print parameters of the PyTorch model\n",
    "print(\"PyTorch model parameters:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: data: {param.data} grad={param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "bd430978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "\n",
    "y = [1.0, -1.0, -1.0, 1.0]  # Example labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "014ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mse(y_preds, y_true):\n",
    "    \"\"\"Mean squared error loss function.\"\"\"\n",
    "    loss = sum([(i - j)**2 for i, j in zip(y_true, y_preds)])\n",
    "\n",
    "    return loss/len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "8bb459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mae(y_preds, y_true):\n",
    "    \"\"\"Mean absolute error loss function.\"\"\"\n",
    "    loss = sum([(i - j) for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "cab62bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: Layer 0 Neuron 0 w0, data: 0.2788535969157675, grad: 0.0\n",
      "param: Layer 0 Neuron 0 w1, data: -0.9499784895546661, grad: 0.0\n",
      "param: Layer 0 Neuron 0 w2, data: -0.4499413632617615, grad: 0.0\n",
      "param: Layer 0 Neuron 0 b, data: -0.5535785237023545, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w0, data: 0.4729424283280248, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w1, data: 0.3533989748458226, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w2, data: 0.7843591354096908, grad: 0.0\n",
      "param: Layer 0 Neuron 1 b, data: -0.8261223347411677, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w0, data: -0.15615636062945915, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w1, data: -0.9404055611238593, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w2, data: -0.5627240503927933, grad: 0.0\n",
      "param: Layer 0 Neuron 2 b, data: 0.010710576206724776, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w0, data: -0.9469280606322728, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w1, data: -0.602324698626703, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w2, data: 0.2997688755590464, grad: 0.0\n",
      "param: Layer 0 Neuron 3 b, data: 0.08988296120643335, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w0, data: -0.5591187559186066, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w1, data: 0.17853136775181744, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w2, data: 0.6188609133556533, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w3, data: -0.987002480643878, grad: 0.0\n",
      "param: Layer 1 Neuron 0 b, data: 0.6116385036656158, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w0, data: 0.3962787899764537, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w1, data: -0.31949896696401625, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w2, data: -0.6890410003764369, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w3, data: 0.9144261444135624, grad: 0.0\n",
      "param: Layer 1 Neuron 1 b, data: -0.32681090977474647, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w0, data: -0.8145083132397042, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w1, data: -0.806567246333072, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w2, data: 0.6949887326949196, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w3, data: 0.20745206273378214, grad: 0.0\n",
      "param: Layer 1 Neuron 2 b, data: 0.6142565465487604, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w0, data: 0.45946357338763577, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w1, data: 0.07245618290940148, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w2, data: 0.9462315279587412, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w3, data: -0.24293124558329304, grad: 0.0\n",
      "param: Layer 1 Neuron 3 b, data: 0.104081262546454, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w0, data: 0.6588093285059897, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w1, data: 0.2370395047284921, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w2, data: 0.7234138006215545, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w3, data: 0.15470429051352408, grad: 0.0\n",
      "param: Layer 2 Neuron 0 b, data: 0.40914367242984695, grad: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Print grads for our model\n",
    "for param in mlp.parameters():\n",
    "    print(f\"param: {param.label}, data: {param.data}, grad: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "3d011511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795]\n",
      "Layer: Layer 1, Input: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795], Output: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824]\n",
      "Layer: Layer 2, Input: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824], Output: [0.8661433515946025]\n",
      "y_preds = 0.8661433515946025\n",
      "y = 1.0\n",
      "loss = Value(data=0.017917602322326195)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with our model\n",
    "mlp.register_forward_hook(hook_fn)  # Register the hook to capture outputs\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "0f2e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "7c87c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "y_preds_tmlp = 0.8661433458328247\n",
      "loss_tmlp = Value(data=0.017917603864830767)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with PyTorch model\n",
    "y_preds_tmlp = tmlp(torch.tensor(x[0]))\n",
    "print(f\"y_preds_tmlp = {y_preds_tmlp.item()}\")\n",
    "loss_tmlp = loss_fn_mse([Value(y_preds_tmlp.item())], [Value(y[0])])\n",
    "print(f\"loss_tmlp = {loss_tmlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "dedc339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass with our model\n",
    "mlp.zero_grad()\n",
    "loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "loss.visited = set()  # Reset visited set for each backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "494cc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for our model\n",
    "learning_rate = 0.001\n",
    "for param in mlp.parameters():\n",
    "    param.data -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "8964c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "output = tensor([0.8661], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with PyTorch model\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "optimizer.zero_grad()\n",
    "output = tmlp(torch.tensor(x[0]))  # Forward pass\n",
    "print(f\"output = {output}\")\n",
    "loss_rmse = rmse([torch.tensor([y[0]])], [output])  # Calculate loss\n",
    "loss_rmse.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "6bc150d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmlp loss grad = 0.017917603254318237\n"
     ]
    }
   ],
   "source": [
    "# Print gradients of the loss function\n",
    "print(f\"tmlp loss grad = {loss_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "30507a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for PyTorch model\n",
    "optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "46a77386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for our model:\n",
      "Layer 0 Neuron 0 w0: 0.2788439384702872 (grad: 0.009658445480288656)\n",
      "Layer 0 Neuron 0 w1: -0.9499929772228866 (grad: 0.014487668220432983)\n",
      "Layer 0 Neuron 0 w2: -0.44993653403902134 (grad: -0.004829222740144328)\n",
      "Layer 0 Neuron 0 b: -0.5535833529250946 (grad: 0.004829222740144328)\n",
      "Layer 0 Neuron 1 w0: 0.47268365591740313 (grad: 0.2587724106216494)\n",
      "Layer 0 Neuron 1 w1: 0.3530108162298901 (grad: 0.38815861593247414)\n",
      "Layer 0 Neuron 1 w2: 0.7844885216150016 (grad: -0.1293862053108247)\n",
      "Layer 0 Neuron 1 b: -0.8262517209464785 (grad: 0.1293862053108247)\n",
      "Layer 0 Neuron 2 w0: -0.156149540968433 (grad: -0.006819661026130761)\n",
      "Layer 0 Neuron 2 w1: -0.9403953316323201 (grad: -0.010229491539196141)\n",
      "Layer 0 Neuron 2 w2: -0.5627274602233063 (grad: 0.0034098305130653805)\n",
      "Layer 0 Neuron 2 b: 0.010713986037237841 (grad: -0.0034098305130653805)\n",
      "Layer 0 Neuron 3 w0: -0.9469279643907854 (grad: -9.624148732860756e-05)\n",
      "Layer 0 Neuron 3 w1: -0.6023245542644721 (grad: -0.00014436223099291136)\n",
      "Layer 0 Neuron 3 w2: 0.29976882743830274 (grad: 4.812074366430378e-05)\n",
      "Layer 0 Neuron 3 b: 0.08988300932717702 (grad: -4.812074366430378e-05)\n",
      "Layer 1 Neuron 0 w0: -0.5591447037724337 (grad: 0.025947853827143978)\n",
      "Layer 1 Neuron 0 w1: 0.17854129211808092 (grad: -0.00992436626348306)\n",
      "Layer 1 Neuron 0 w2: 0.6188348446513917 (grad: 0.02606870426158594)\n",
      "Layer 1 Neuron 0 w3: -0.9870288415834612 (grad: 0.02636093958323322)\n",
      "Layer 1 Neuron 0 b: 0.6116648857576266 (grad: -0.026382092010792762)\n",
      "Layer 1 Neuron 1 w0: 0.39625526026487373 (grad: 0.02352971157995671)\n",
      "Layer 1 Neuron 1 w1: -0.31948996747306224 (grad: -0.008999490954019754)\n",
      "Layer 1 Neuron 1 w2: -0.6890646396761118 (grad: 0.023639299674820924)\n",
      "Layer 1 Neuron 1 w3: 0.914402240112671 (grad: 0.02390430089140105)\n",
      "Layer 1 Neuron 1 b: -0.32678698629267255 (grad: -0.02392348207389913)\n",
      "Layer 1 Neuron 2 w0: -0.8146900256750575 (grad: 0.18171243535335416)\n",
      "Layer 1 Neuron 2 w1: -0.8064977461433804 (grad: -0.06950018969159072)\n",
      "Layer 1 Neuron 2 w2: 0.6948061739457669 (grad: 0.18255874915264755)\n",
      "Layer 1 Neuron 2 w3: 0.207267457465008 (grad: 0.1846052687741373)\n",
      "Layer 1 Neuron 2 b: 0.6144412999476708 (grad: -0.1847533989104902)\n",
      "Layer 1 Neuron 3 w0: 0.45944679778766173 (grad: 0.01677559997402493)\n",
      "Layer 1 Neuron 3 w1: 0.07246259913170414 (grad: -0.0064162223026606735)\n",
      "Layer 1 Neuron 3 w2: 0.9462146742275059 (grad: 0.01685373123522252)\n",
      "Layer 1 Neuron 3 w3: -0.24294828824818293 (grad: 0.017042664889885966)\n",
      "Layer 1 Neuron 3 b: 0.10409831888664303 (grad: -0.017056340189029483)\n",
      "Layer 2 Neuron 0 w0: 0.6590562086406249 (grad: -0.24688013463515496)\n",
      "Layer 2 Neuron 0 w1: 0.2368281965653681 (grad: 0.2113081631240002)\n",
      "Layer 2 Neuron 0 w2: 0.7234712360937652 (grad: -0.05743547221069753)\n",
      "Layer 2 Neuron 0 w3: 0.15449897445037689 (grad: 0.20531606314719333)\n",
      "Layer 2 Neuron 0 b: 0.40941138572665775 (grad: -0.2677132968107949)\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters for out model\n",
    "print(\"Updated parameters for our model:\")\n",
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "ea105b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for PyTorch model:\n",
      "layers.0.weight: tensor([[ 0.2788, -0.9500, -0.4499],\n",
      "        [ 0.4727,  0.3530,  0.7845],\n",
      "        [-0.1561, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) (grad: tensor([[ 9.6584e-03,  1.4488e-02, -4.8292e-03],\n",
      "        [ 2.5877e-01,  3.8816e-01, -1.2939e-01],\n",
      "        [-6.8197e-03, -1.0229e-02,  3.4098e-03],\n",
      "        [-9.6238e-05, -1.4436e-04,  4.8119e-05]]))\n",
      "layers.0.bias: tensor([-0.5536, -0.8263,  0.0107,  0.0899]) (grad: tensor([ 4.8292e-03,  1.2939e-01, -3.4098e-03, -4.8119e-05]))\n",
      "layers.2.weight: tensor([[-0.5591,  0.1785,  0.6188, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6891,  0.9144],\n",
      "        [-0.8147, -0.8065,  0.6948,  0.2073],\n",
      "        [ 0.4594,  0.0725,  0.9462, -0.2429]]) (grad: tensor([[ 0.0259, -0.0099,  0.0261,  0.0264],\n",
      "        [ 0.0235, -0.0090,  0.0236,  0.0239],\n",
      "        [ 0.1817, -0.0695,  0.1826,  0.1846],\n",
      "        [ 0.0168, -0.0064,  0.0169,  0.0170]]))\n",
      "layers.2.bias: tensor([ 0.6117, -0.3268,  0.6144,  0.1041]) (grad: tensor([-0.0264, -0.0239, -0.1848, -0.0171]))\n",
      "layers.4.weight: tensor([[0.6591, 0.2368, 0.7235, 0.1545]]) (grad: tensor([[-0.2469,  0.2113, -0.0574,  0.2053]]))\n",
      "layers.4.bias: tensor([0.4094]) (grad: tensor([-0.2677]))\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters of PyTorch model\n",
    "print(\"Updated parameters for PyTorch model:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "696d9145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(3916) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(3917) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(3918) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.0.1 (20250615.1724)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"13322pt\" height=\"980pt\"\n",
       " viewBox=\"0.00 0.00 13322.00 980.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 976.28)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-976.28 13317.86,-976.28 13317.86,4 -4,4\"/>\n",
       "<!-- 6402157232 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>6402157232</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"13054.61,-52.78 13054.61,-88.78 13313.86,-88.78 13313.86,-52.78 13054.61,-52.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"13064.48\" y=\"-65.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"13074.36,-53.28 13074.36,-88.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"13194.11\" y=\"-65.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.017917602322326195 grad=1.0</text>\n",
       "</g>\n",
       "<!-- 6402157232_op -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>6402157232_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"13000.61\" cy=\"-70.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"13000.61\" y=\"-65.73\" font-family=\"Times,serif\" font-size=\"14.00\">/</text>\n",
       "</g>\n",
       "<!-- 6402157232_op&#45;&gt;6402157232 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>6402157232_op&#45;&gt;6402157232</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M13019.02,-70.78C13025.59,-70.78 13033.68,-70.78 13042.72,-70.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"13042.67,-74.28 13052.67,-70.78 13042.67,-67.28 13042.67,-74.28\"/>\n",
       "</g>\n",
       "<!-- 6402162368 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>6402162368</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"12687.36,-80.78 12687.36,-116.78 12946.61,-116.78 12946.61,-80.78 12687.36,-80.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12697.23\" y=\"-93.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"12707.11,-81.28 12707.11,-116.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12826.86\" y=\"-93.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.017917602322326195 grad=1.0</text>\n",
       "</g>\n",
       "<!-- 6402162368&#45;&gt;6402157232_op -->\n",
       "<g id=\"edge246\" class=\"edge\">\n",
       "<title>6402162368&#45;&gt;6402157232_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12937.87,-80.3C12950.15,-78.41 12961.65,-76.64 12971.31,-75.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12971.64,-78.64 12980.99,-73.66 12970.57,-71.72 12971.64,-78.64\"/>\n",
       "</g>\n",
       "<!-- 6402162368_op -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>6402162368_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"12633.36\" cy=\"-98.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12633.36\" y=\"-93.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402162368_op&#45;&gt;6402162368 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>6402162368_op&#45;&gt;6402162368</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12651.77,-98.78C12658.34,-98.78 12666.43,-98.78 12675.47,-98.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12675.42,-102.28 12685.42,-98.78 12675.42,-95.28 12675.42,-102.28\"/>\n",
       "</g>\n",
       "<!-- 6402158576 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>6402158576</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"12320.11,-108.78 12320.11,-144.78 12579.36,-144.78 12579.36,-108.78 12320.11,-108.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12329.98\" y=\"-121.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"12339.86,-109.28 12339.86,-144.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12459.61\" y=\"-121.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.017917602322326195 grad=1.0</text>\n",
       "</g>\n",
       "<!-- 6402158576&#45;&gt;6402162368_op -->\n",
       "<g id=\"edge244\" class=\"edge\">\n",
       "<title>6402158576&#45;&gt;6402162368_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12570.62,-108.3C12582.9,-106.41 12594.4,-104.64 12604.06,-103.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12604.39,-106.64 12613.74,-101.66 12603.32,-99.72 12604.39,-106.64\"/>\n",
       "</g>\n",
       "<!-- 6402158576_op -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>6402158576_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"12263.98\" cy=\"-126.78\" rx=\"20.13\" ry=\"20.13\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12263.98\" y=\"-121.73\" font-family=\"Times,serif\" font-size=\"14.00\">**</text>\n",
       "</g>\n",
       "<!-- 6402158576_op&#45;&gt;6402158576 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>6402158576_op&#45;&gt;6402158576</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12284.3,-126.78C12291.04,-126.78 12299.22,-126.78 12308.29,-126.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12308.24,-130.28 12318.24,-126.78 12308.24,-123.28 12308.24,-130.28\"/>\n",
       "</g>\n",
       "<!-- 6402256832 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6402256832</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"11854.1,-136.78 11854.1,-172.78 12207.85,-172.78 12207.85,-136.78 11854.1,-136.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11863.97\" y=\"-149.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"11873.85,-137.28 11873.85,-172.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12040.85\" y=\"-149.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.13385664840539746 grad=0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402256832&#45;&gt;6402158576_op -->\n",
       "<g id=\"edge242\" class=\"edge\">\n",
       "<title>6402256832&#45;&gt;6402158576_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12184.45,-136.3C12202.5,-134.12 12219.2,-132.09 12232.52,-130.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12232.73,-133.98 12242.24,-129.3 12231.89,-127.03 12232.73,-133.98\"/>\n",
       "</g>\n",
       "<!-- 6402256832_op -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6402256832_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"11800.1\" cy=\"-154.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11800.1\" y=\"-149.73\" font-family=\"Times,serif\" font-size=\"14.00\">&#45;</text>\n",
       "</g>\n",
       "<!-- 6402256832_op&#45;&gt;6402256832 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>6402256832_op&#45;&gt;6402256832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M11818.3,-154.78C11824.87,-154.78 11833.06,-154.78 11842.35,-154.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"11842.22,-158.28 11852.22,-154.78 11842.22,-151.28 11842.22,-158.28\"/>\n",
       "</g>\n",
       "<!-- 6402249008 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>6402249008</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"11447.47,-164.78 11447.47,-200.78 11693.22,-200.78 11693.22,-164.78 11447.47,-164.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11457.35\" y=\"-177.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"11467.22,-165.28 11467.22,-200.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11580.22\" y=\"-177.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1.0 grad=0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402249008&#45;&gt;6402256832_op -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6402249008&#45;&gt;6402256832_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M11693.56,-167.76C11722.39,-164.21 11750.51,-160.76 11770.47,-158.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"11770.77,-161.79 11780.27,-157.1 11769.92,-154.85 11770.77,-161.79\"/>\n",
       "</g>\n",
       "<!-- 6402152000 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>6402152000</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"11394.6,-109.78 11394.6,-145.78 11746.1,-145.78 11746.1,-109.78 11394.6,-109.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11404.47\" y=\"-122.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"11414.35,-110.28 11414.35,-145.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11580.22\" y=\"-122.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.8661433515946025 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402152000&#45;&gt;6402256832_op -->\n",
       "<g id=\"edge241\" class=\"edge\">\n",
       "<title>6402152000&#45;&gt;6402256832_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M11727.35,-146.28C11743.65,-148.21 11758.62,-149.99 11770.61,-151.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"11770.12,-154.87 11780.47,-152.58 11770.95,-147.92 11770.12,-154.87\"/>\n",
       "</g>\n",
       "<!-- 6402152000_op -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6402152000_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"11340.6\" cy=\"-127.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11340.6\" y=\"-122.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402152000_op&#45;&gt;6402152000 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>6402152000_op&#45;&gt;6402152000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M11359.09,-127.78C11365.68,-127.78 11373.85,-127.78 11383.11,-127.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"11382.93,-131.28 11392.93,-127.78 11382.93,-124.28 11382.93,-131.28\"/>\n",
       "</g>\n",
       "<!-- 6402151424 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>6402151424</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"10879.97,-137.78 10879.97,-173.78 11231.47,-173.78 11231.47,-137.78 10879.97,-137.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"10889.85\" y=\"-150.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"10899.72,-138.28 10899.72,-173.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11065.6\" y=\"-150.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.4569996791647556 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402151424&#45;&gt;6402152000_op -->\n",
       "<g id=\"edge239\" class=\"edge\">\n",
       "<title>6402151424&#45;&gt;6402152000_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M11231.85,-138.45C11262.55,-135.41 11291,-132.59 11310.95,-130.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"11311.1,-134.12 11320.71,-129.65 11310.41,-127.16 11311.1,-134.12\"/>\n",
       "</g>\n",
       "<!-- 6402151424_op -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>6402151424_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"10770.85\" cy=\"-155.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"10770.85\" y=\"-150.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402151424_op&#45;&gt;6402151424 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6402151424_op&#45;&gt;6402151424</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M10789.12,-155.78C10806.63,-155.78 10835.75,-155.78 10868.44,-155.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"10868.13,-159.28 10878.13,-155.78 10868.13,-152.28 10868.13,-159.28\"/>\n",
       "</g>\n",
       "<!-- 6402148592 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>6402148592</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"10372.1,-165.78 10372.1,-201.78 10716.85,-201.78 10716.85,-165.78 10372.1,-165.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"10381.97\" y=\"-178.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"10391.85,-166.28 10391.85,-201.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"10554.35\" y=\"-178.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.575646292009933 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402148592&#45;&gt;6402151424_op -->\n",
       "<g id=\"edge205\" class=\"edge\">\n",
       "<title>6402148592&#45;&gt;6402151424_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M10693.57,-165.3C10711.54,-163.06 10728.14,-160.99 10741.23,-159.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"10741.64,-162.83 10751.13,-158.12 10740.78,-155.89 10741.64,-162.83\"/>\n",
       "</g>\n",
       "<!-- 6402148592_op -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>6402148592_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"10318.1\" cy=\"-187.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"10318.1\" y=\"-182.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402148592_op&#45;&gt;6402148592 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6402148592_op&#45;&gt;6402148592</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M10336.33,-187.48C10342.89,-187.36 10351.05,-187.21 10360.3,-187.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"10360.18,-190.55 10370.12,-186.88 10360.06,-183.55 10360.18,-190.55\"/>\n",
       "</g>\n",
       "<!-- 6402152528 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>6402152528</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"9905.85,-220.78 9905.85,-256.78 10264.1,-256.78 10264.1,-220.78 9905.85,-220.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9915.72\" y=\"-233.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"9925.6,-221.28 9925.6,-256.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"10094.85\" y=\"-233.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.42044438856544564 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402152528&#45;&gt;6402148592_op -->\n",
       "<g id=\"edge171\" class=\"edge\">\n",
       "<title>6402152528&#45;&gt;6402148592_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M10179.55,-220.33C10206.87,-214.67 10236.74,-208.23 10264.1,-201.78 10272.41,-199.83 10281.4,-197.52 10289.58,-195.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"10290.24,-198.8 10298.98,-192.82 10288.42,-192.04 10290.24,-198.8\"/>\n",
       "</g>\n",
       "<!-- 6402152528_op -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>6402152528_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"9690.72\" cy=\"-246.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9690.72\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402152528_op&#45;&gt;6402152528 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>6402152528_op&#45;&gt;6402152528</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M9709.08,-246.43C9742.5,-245.75 9819.16,-244.19 9894.51,-242.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"9894.17,-246.16 9904.1,-242.45 9894.03,-239.16 9894.17,-246.16\"/>\n",
       "</g>\n",
       "<!-- 6402152048 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>6402152048</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"9118.47,-283.78 9118.47,-319.78 9469.97,-319.78 9469.97,-283.78 9118.47,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9128.35\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"9138.22,-284.28 9138.22,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9304.1\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6075414918049614 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402152048&#45;&gt;6402152528_op -->\n",
       "<g id=\"edge137\" class=\"edge\">\n",
       "<title>6402152048&#45;&gt;6402152528_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M9427.68,-283.32C9511.49,-271.63 9612.85,-257.5 9661.28,-250.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"9661.75,-254.22 9671.18,-249.37 9660.79,-247.28 9661.75,-254.22\"/>\n",
       "</g>\n",
       "<!-- 6402152048_op -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>6402152048_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8898.85\" cy=\"-301.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8898.85\" y=\"-296.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402152048_op&#45;&gt;6402152048 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>6402152048_op&#45;&gt;6402152048</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8917.26,-301.78C8951.31,-301.78 9030.1,-301.78 9106.81,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"9106.59,-305.28 9116.59,-301.78 9106.59,-298.28 9106.59,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402147776 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>6402147776</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8383.97,-283.78 8383.97,-319.78 8634.22,-319.78 8634.22,-283.78 8383.97,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8393.85\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"8403.72,-284.28 8403.72,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8518.97\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402147776&#45;&gt;6402152048_op -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>6402147776&#45;&gt;6402152048_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8634.65,-301.78C8717.74,-301.78 8820.39,-301.78 8869.31,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8869.04,-305.28 8879.04,-301.78 8869.04,-298.28 8869.04,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402157760 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>6402157760</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8333.35,-338.78 8333.35,-374.78 8684.85,-374.78 8684.85,-338.78 8333.35,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8343.22\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"8353.1,-339.28 8353.1,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8518.97\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6075414918049614 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402157760&#45;&gt;6402152048_op -->\n",
       "<g id=\"edge136\" class=\"edge\">\n",
       "<title>6402157760&#45;&gt;6402152048_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8640.29,-338.32C8722.46,-326.66 8821.8,-312.57 8869.54,-305.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8869.88,-309.29 8879.29,-304.42 8868.89,-302.36 8869.88,-309.29\"/>\n",
       "</g>\n",
       "<!-- 6402157760_op -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>6402157760_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8279.35\" cy=\"-356.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8279.35\" y=\"-351.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402157760_op&#45;&gt;6402157760 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>6402157760_op&#45;&gt;6402157760</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8297.84,-356.78C8304.43,-356.78 8312.6,-356.78 8321.86,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8321.68,-360.28 8331.68,-356.78 8321.68,-353.28 8321.68,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402257168 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>6402257168</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7752.72,-393.78 7752.72,-429.78 8224.22,-429.78 8224.22,-393.78 7752.72,-393.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7819.22\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2 Neuron 0 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7885.72,-394.28 7885.72,-429.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8054.97\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6590562086406249 grad=&#45;0.24688013463515496</text>\n",
       "</g>\n",
       "<!-- 6402257168&#45;&gt;6402157760_op -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>6402257168&#45;&gt;6402157760_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8188.4,-393.32C8201,-390.56 8213.41,-387.41 8225.35,-383.78 8235.04,-380.84 8245.09,-376.19 8253.8,-371.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8255.3,-374.74 8262.32,-366.81 8251.88,-368.63 8255.3,-374.74\"/>\n",
       "</g>\n",
       "<!-- 6402148784 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>6402148784</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7809.35,-338.78 7809.35,-374.78 8167.6,-374.78 8167.6,-338.78 7809.35,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7819.22\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7829.1,-339.28 7829.1,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7998.35\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.9221810704816664 grad=&#45;0.17637201730404453</text>\n",
       "</g>\n",
       "<!-- 6402148784&#45;&gt;6402157760_op -->\n",
       "<g id=\"edge135\" class=\"edge\">\n",
       "<title>6402148784&#45;&gt;6402157760_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8167.9,-356.78C8199.68,-356.78 8229.14,-356.78 8249.63,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8249.37,-360.28 8259.37,-356.78 8249.37,-353.28 8249.37,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402148784_op -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>6402148784_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7688.81\" cy=\"-356.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7688.81\" y=\"-351.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402148784_op&#45;&gt;6402148784 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>6402148784_op&#45;&gt;6402148784</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7715.97,-356.78C7735.89,-356.78 7765.31,-356.78 7797.52,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7797.51,-360.28 7807.51,-356.78 7797.51,-353.28 7797.51,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402157040 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>6402157040</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7262.15,-338.78 7262.15,-374.78 7620.4,-374.78 7620.4,-338.78 7262.15,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7272.03\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7281.9,-339.28 7281.9,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7451.15\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1.603415541453495 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402157040&#45;&gt;6402148784_op -->\n",
       "<g id=\"edge134\" class=\"edge\">\n",
       "<title>6402157040&#45;&gt;6402148784_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7620.72,-356.78C7631.46,-356.78 7641.47,-356.78 7650.32,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7650.11,-360.28 7660.11,-356.78 7650.11,-353.28 7650.11,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402157040_op -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>6402157040_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7202.53\" cy=\"-356.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7202.53\" y=\"-351.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402157040_op&#45;&gt;6402157040 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>6402157040_op&#45;&gt;6402157040</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7220.94,-356.78C7228.74,-356.78 7238.8,-356.78 7250.29,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7250.22,-360.28 7260.22,-356.78 7250.22,-353.28 7250.22,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402152672 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>6402152672</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6728.4,-393.78 6728.4,-429.78 7093.4,-429.78 7093.4,-393.78 6728.4,-393.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6738.28\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6748.15,-394.28 6748.15,-429.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6920.78\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.9917770377878792 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402152672&#45;&gt;6402157040_op -->\n",
       "<g id=\"edge132\" class=\"edge\">\n",
       "<title>6402152672&#45;&gt;6402157040_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7093.81,-396.91C7112.48,-393.41 7131.01,-389.1 7148.53,-383.78 7158.22,-380.84 7168.27,-376.19 7176.98,-371.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7178.48,-374.74 7185.5,-366.81 7175.06,-368.63 7178.48,-374.74\"/>\n",
       "</g>\n",
       "<!-- 6402152672_op -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>6402152672_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6619.28\" cy=\"-411.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6619.28\" y=\"-406.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402152672_op&#45;&gt;6402152672 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>6402152672_op&#45;&gt;6402152672</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6637.53,-411.78C6654.98,-411.78 6684,-411.78 6716.74,-411.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6716.46,-415.28 6726.46,-411.78 6716.46,-408.28 6716.46,-415.28\"/>\n",
       "</g>\n",
       "<!-- 6402155120 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>6402155120</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6193.53,-537.78 6193.53,-573.78 6565.28,-573.78 6565.28,-537.78 6193.53,-537.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6203.4\" y=\"-550.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6213.28,-538.28 6213.28,-573.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-550.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.00556590827962633 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402155120&#45;&gt;6402152672_op -->\n",
       "<g id=\"edge104\" class=\"edge\">\n",
       "<title>6402155120&#45;&gt;6402152672_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6476.76,-537.42C6507.25,-528.25 6539.66,-514.69 6565.28,-494.78 6584.04,-480.21 6598.04,-457 6606.93,-438.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6610.03,-440.47 6611.05,-429.93 6603.68,-437.53 6610.03,-440.47\"/>\n",
       "</g>\n",
       "<!-- 6402155120_op -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>6402155120_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-588.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-583.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402155120_op&#45;&gt;6402155120 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>6402155120_op&#45;&gt;6402155120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6157.63,-586.41C6174.81,-584.03 6203.05,-580.11 6233.69,-575.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6234.15,-579.33 6243.57,-574.49 6233.19,-572.4 6234.15,-579.33\"/>\n",
       "</g>\n",
       "<!-- 6402160256 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>6402160256</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5660.53,-704.78 5660.53,-740.78 6025.53,-740.78 6025.53,-704.78 5660.53,-704.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5670.4\" y=\"-717.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5680.28,-705.28 5680.28,-740.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-717.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6170754929904828 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402160256&#45;&gt;6402155120_op -->\n",
       "<g id=\"edge76\" class=\"edge\">\n",
       "<title>6402160256&#45;&gt;6402155120_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6025.84,-711.91C6047.13,-705.41 6067.61,-696.33 6085.53,-683.78 6108.32,-667.82 6122.43,-638.77 6130.3,-616.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6133.52,-618.39 6133.38,-607.79 6126.89,-616.16 6133.52,-618.39\"/>\n",
       "</g>\n",
       "<!-- 6402160256_op -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>6402160256_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-733.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-728.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402160256_op&#45;&gt;6402160256 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>6402160256_op&#45;&gt;6402160256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-733.16C5575.73,-732.44 5610.6,-731.18 5649.33,-729.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5648.97,-733.29 5658.84,-729.43 5648.72,-726.29 5648.97,-733.29\"/>\n",
       "</g>\n",
       "<!-- 6402154880 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>6402154880</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5053.33,-853.78 5053.33,-889.78 5418.33,-889.78 5418.33,-853.78 5053.33,-853.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5063.21\" y=\"-866.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5073.08,-854.28 5073.08,-889.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-866.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.5499158953981165 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402154880&#45;&gt;6402160256_op -->\n",
       "<g id=\"edge48\" class=\"edge\">\n",
       "<title>6402154880&#45;&gt;6402160256_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5389.41,-853.29C5419.36,-845.16 5449.39,-833.5 5474.96,-816.78 5496.43,-802.75 5513.17,-778.56 5523.77,-759.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5526.76,-761.73 5528.44,-751.27 5520.61,-758.4 5526.76,-761.73\"/>\n",
       "</g>\n",
       "<!-- 6402154880_op -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>6402154880_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-898.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-893.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402154880_op&#45;&gt;6402154880 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>6402154880_op&#45;&gt;6402154880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-897.22C4971.63,-895.48 5004.94,-892.48 5042.07,-889.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5042.02,-892.66 5051.66,-888.27 5041.39,-885.69 5042.02,-892.66\"/>\n",
       "</g>\n",
       "<!-- 6402161312 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>6402161312</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4493.39,-935.78 4493.39,-971.78 4757.14,-971.78 4757.14,-935.78 4493.39,-935.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4503.26\" y=\"-948.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4513.14,-936.28 4513.14,-971.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-948.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402161312&#45;&gt;6402154880_op -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>6402161312&#45;&gt;6402154880_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4757.33,-947.02C4794.56,-943.04 4834.84,-936.74 4871.14,-926.78 4883.57,-923.37 4896.68,-917.76 4907.6,-912.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4909,-915.66 4916.34,-908.02 4905.84,-909.42 4909,-915.66\"/>\n",
       "</g>\n",
       "<!-- 6402158624 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>6402158624</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4442.76,-880.78 4442.76,-916.78 4807.76,-916.78 4807.76,-880.78 4442.76,-880.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4452.64\" y=\"-893.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4462.51,-881.28 4462.51,-916.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-893.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.5499158953981165 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402158624&#45;&gt;6402154880_op -->\n",
       "<g id=\"edge47\" class=\"edge\">\n",
       "<title>6402158624&#45;&gt;6402154880_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4808.19,-898.78C4845.8,-898.78 4881.03,-898.78 4904.39,-898.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.27,-902.28 4914.27,-898.78 4904.27,-895.28 4904.27,-902.28\"/>\n",
       "</g>\n",
       "<!-- 6402158624_op -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>6402158624_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4316.6\" cy=\"-897.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4316.6\" y=\"-892.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402158624_op&#45;&gt;6402158624 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>6402158624_op&#45;&gt;6402158624</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4334.97,-897.84C4355.3,-897.91 4391.28,-898.02 4431.12,-898.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4430.93,-901.65 4440.94,-898.19 4430.95,-894.65 4430.93,-901.65\"/>\n",
       "</g>\n",
       "<!-- 6402255392 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>6402255392</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3770.32,-879.78 3770.32,-915.78 4248.57,-915.78 4248.57,-879.78 3770.32,-879.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3836.82\" y=\"-892.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 0 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3903.32,-880.28 3903.32,-915.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4075.94\" y=\"-892.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.5591447037724337 grad=0.025947853827143978</text>\n",
       "</g>\n",
       "<!-- 6402255392&#45;&gt;6402158624_op -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>6402255392&#45;&gt;6402158624_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4249.01,-897.78C4263.5,-897.78 4276.46,-897.78 4287,-897.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4286.71,-901.28 4296.71,-897.78 4286.71,-894.28 4286.71,-901.28\"/>\n",
       "</g>\n",
       "<!-- 6402161600 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>6402161600</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3833.69,-693.78 3833.69,-729.78 4185.19,-729.78 4185.19,-693.78 3833.69,-693.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3843.57\" y=\"-706.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3853.44,-694.28 3853.44,-729.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4019.32\" y=\"-706.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.983540418876898 grad=0.14791676623505545</text>\n",
       "</g>\n",
       "<!-- 6402161600&#45;&gt;6402158624_op -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>6402161600&#45;&gt;6402158624_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4123.34,-730.28C4167.61,-741.91 4216.62,-760.67 4253.82,-790.78 4267.66,-801.98 4289.52,-843.64 4303.19,-871.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4300,-872.99 4307.5,-880.47 4306.3,-869.94 4300,-872.99\"/>\n",
       "</g>\n",
       "<!-- 6402146624_op -->\n",
       "<g id=\"node154\" class=\"node\">\n",
       "<title>6402146624_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4316.6\" cy=\"-817.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4316.6\" y=\"-812.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402161600&#45;&gt;6402146624_op -->\n",
       "<g id=\"edge149\" class=\"edge\">\n",
       "<title>6402161600&#45;&gt;6402146624_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4073.05,-730.25C4122.55,-745.3 4193.19,-767.76 4253.82,-790.78 4265.72,-795.3 4278.66,-800.86 4289.61,-805.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4287.85,-808.79 4298.4,-809.73 4290.74,-802.42 4287.85,-808.79\"/>\n",
       "</g>\n",
       "<!-- 6402147728_op -->\n",
       "<g id=\"node183\" class=\"node\">\n",
       "<title>6402147728_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4316.6\" cy=\"-660.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4316.6\" y=\"-655.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402161600&#45;&gt;6402147728_op -->\n",
       "<g id=\"edge183\" class=\"edge\">\n",
       "<title>6402161600&#45;&gt;6402147728_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4185.56,-697.9C4208.68,-694.45 4231.94,-690.15 4253.82,-684.78 4265.76,-681.86 4278.5,-677.19 4289.29,-672.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4290.51,-676.03 4298.32,-668.88 4287.75,-669.6 4290.51,-676.03\"/>\n",
       "</g>\n",
       "<!-- 6402155024_op -->\n",
       "<g id=\"node212\" class=\"node\">\n",
       "<title>6402155024_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4316.6\" cy=\"-430.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4316.6\" y=\"-425.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402161600&#45;&gt;6402155024_op -->\n",
       "<g id=\"edge217\" class=\"edge\">\n",
       "<title>6402161600&#45;&gt;6402155024_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4185.68,-718.31C4210.73,-712.23 4234.51,-701.77 4253.82,-684.78 4262.4,-677.24 4295.74,-524.27 4309.55,-459.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4312.93,-460.39 4311.58,-449.88 4306.08,-458.94 4312.93,-460.39\"/>\n",
       "</g>\n",
       "<!-- 6402161600_op -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>6402161600_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3702.28\" cy=\"-711.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3702.28\" y=\"-706.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402161600_op&#45;&gt;6402161600 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>6402161600_op&#45;&gt;6402161600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3729.57,-711.78C3751.71,-711.78 3785.56,-711.78 3822.13,-711.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3822.04,-715.28 3832.04,-711.78 3822.04,-708.28 3822.04,-715.28\"/>\n",
       "</g>\n",
       "<!-- 6402259376 -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>6402259376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3229.5,-692.78 3229.5,-728.78 3594.5,-728.78 3594.5,-692.78 3229.5,-692.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3239.38\" y=\"-705.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3249.25,-693.28 3249.25,-728.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3421.88\" y=\"-705.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.3958654352730564 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402259376&#45;&gt;6402161600_op -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>6402259376&#45;&gt;6402161600_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3594.76,-711.42C3620.77,-711.51 3645.02,-711.59 3663.79,-711.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3663.78,-715.15 3673.79,-711.69 3663.8,-708.15 3663.78,-715.15\"/>\n",
       "</g>\n",
       "<!-- 6402259376_op -->\n",
       "<g id=\"node43\" class=\"node\">\n",
       "<title>6402259376_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2965.25\" cy=\"-707.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2965.25\" y=\"-702.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402259376_op&#45;&gt;6402259376 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>6402259376_op&#45;&gt;6402259376</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2983.68,-707.9C3023.31,-708.17 3123.97,-708.85 3217.64,-709.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3217.49,-712.98 3227.51,-709.55 3217.54,-705.98 3217.49,-712.98\"/>\n",
       "</g>\n",
       "<!-- 6402148160 -->\n",
       "<g id=\"node44\" class=\"node\">\n",
       "<title>6402148160</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2329.25,-621.78 2329.25,-657.78 2694.25,-657.78 2694.25,-621.78 2329.25,-621.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2339.12\" y=\"-634.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2349,-622.28 2349,-657.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2521.62\" y=\"-634.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.8422869115707021 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402148160&#45;&gt;6402259376_op -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>6402148160&#45;&gt;6402259376_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2635.53,-658.28C2738.16,-673.73 2876.94,-694.63 2935.88,-703.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2935.3,-706.96 2945.71,-704.99 2936.34,-700.04 2935.3,-706.96\"/>\n",
       "</g>\n",
       "<!-- 6402148160_op -->\n",
       "<g id=\"node45\" class=\"node\">\n",
       "<title>6402148160_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2223.5\" cy=\"-637.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2223.5\" y=\"-632.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402148160_op&#45;&gt;6402148160 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>6402148160_op&#45;&gt;6402148160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2241.98,-637.91C2258.91,-638.03 2286.59,-638.22 2317.88,-638.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2317.55,-641.93 2327.58,-638.5 2317.6,-634.93 2317.55,-641.93\"/>\n",
       "</g>\n",
       "<!-- 6402158192 -->\n",
       "<g id=\"node46\" class=\"node\">\n",
       "<title>6402158192</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1800.38,-619.78 1800.38,-655.78 2165.38,-655.78 2165.38,-619.78 1800.38,-619.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1810.25\" y=\"-632.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1820.12,-620.28 1820.12,-655.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-632.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.2922282748324636 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402158192&#45;&gt;6402148160_op -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>6402158192&#45;&gt;6402148160_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2165.65,-637.78C2176.2,-637.78 2185.85,-637.78 2194.08,-637.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2193.91,-641.28 2203.91,-637.78 2193.91,-634.28 2193.91,-641.28\"/>\n",
       "</g>\n",
       "<!-- 6402158192_op -->\n",
       "<g id=\"node47\" class=\"node\">\n",
       "<title>6402158192_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-637.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-632.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402158192_op&#45;&gt;6402158192 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>6402158192_op&#45;&gt;6402158192</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-637.78C1767.91,-637.78 1777.5,-637.78 1788.48,-637.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1788.38,-641.28 1798.38,-637.78 1788.38,-634.28 1788.38,-641.28\"/>\n",
       "</g>\n",
       "<!-- 6402160544 -->\n",
       "<g id=\"node48\" class=\"node\">\n",
       "<title>6402160544</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1266.62,-723.78 1266.62,-759.78 1620.38,-759.78 1620.38,-723.78 1266.62,-723.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1276.5\" y=\"-736.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1286.38,-724.28 1286.38,-759.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-736.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.557707193831535 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402160544&#45;&gt;6402158192_op -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>6402160544&#45;&gt;6402158192_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1620.58,-740.58C1644.41,-735.28 1667.7,-727.08 1688.25,-714.78 1707.39,-703.33 1721.26,-681.97 1730,-664.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1733.03,-666.42 1734.13,-655.88 1726.7,-663.44 1733.03,-666.42\"/>\n",
       "</g>\n",
       "<!-- 6402160544_op -->\n",
       "<g id=\"node49\" class=\"node\">\n",
       "<title>6402160544_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-741.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-736.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402160544_op&#45;&gt;6402160544 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>6402160544_op&#45;&gt;6402160544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1162.99,-741.78C1182.63,-741.78 1216.99,-741.78 1255.03,-741.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1254.88,-745.28 1264.88,-741.78 1254.88,-738.28 1254.88,-745.28\"/>\n",
       "</g>\n",
       "<!-- 6402260240 -->\n",
       "<g id=\"node50\" class=\"node\">\n",
       "<title>6402260240</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"713,-668.78 713,-704.78 972.25,-704.78 972.25,-668.78 713,-668.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"722.88\" y=\"-681.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"732.75,-669.28 732.75,-704.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-681.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402260240&#45;&gt;6402160544_op -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>6402260240&#45;&gt;6402160544_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M972.69,-692.62C1011.25,-696.7 1053.22,-703.5 1090.75,-714.78 1100.45,-717.7 1110.5,-722.35 1119.21,-726.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1117.29,-729.91 1127.73,-731.74 1120.71,-723.8 1117.29,-729.91\"/>\n",
       "</g>\n",
       "<!-- 6402257744 -->\n",
       "<g id=\"node51\" class=\"node\">\n",
       "<title>6402257744</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"665.75,-723.78 665.75,-759.78 1019.5,-759.78 1019.5,-723.78 665.75,-723.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"675.62\" y=\"-736.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"685.5,-724.28 685.5,-759.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-736.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.557707193831535 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402257744&#45;&gt;6402160544_op -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>6402257744&#45;&gt;6402160544_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1019.94,-741.78C1056.93,-741.78 1091.73,-741.78 1114.95,-741.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1114.79,-745.28 1124.79,-741.78 1114.79,-738.28 1114.79,-745.28\"/>\n",
       "</g>\n",
       "<!-- 6402257744_op -->\n",
       "<g id=\"node52\" class=\"node\">\n",
       "<title>6402257744_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.5\" cy=\"-713.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"540.5\" y=\"-708.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402257744_op&#45;&gt;6402257744 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>6402257744_op&#45;&gt;6402257744</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M558.5,-715.37C578.67,-717.25 614.62,-720.61 654.27,-724.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"653.75,-727.77 664.04,-725.22 654.4,-720.8 653.75,-727.77\"/>\n",
       "</g>\n",
       "<!-- 6402260864 -->\n",
       "<g id=\"node53\" class=\"node\">\n",
       "<title>6402260864</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6.38,-695.78 6.38,-731.78 480.12,-731.78 480.12,-695.78 6.38,-695.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"72.88\" y=\"-708.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 0 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"139.38,-696.28 139.38,-731.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"309.75\" y=\"-708.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.2788439384702872 grad=0.009658445480288656</text>\n",
       "</g>\n",
       "<!-- 6402260864&#45;&gt;6402257744_op -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>6402260864&#45;&gt;6402257744_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M480.46,-713.78C491.75,-713.78 501.95,-713.78 510.57,-713.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.49,-717.28 520.49,-713.78 510.49,-710.28 510.49,-717.28\"/>\n",
       "</g>\n",
       "<!-- 6402258368 -->\n",
       "<g id=\"node54\" class=\"node\">\n",
       "<title>6402258368</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"117,-475.78 117,-511.78 369.5,-511.78 369.5,-475.78 117,-475.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"126.88\" y=\"-488.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"136.75,-476.28 136.75,-511.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"253.12\" y=\"-488.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 2.0 grad=0.06311690586900427</text>\n",
       "</g>\n",
       "<!-- 6402258368&#45;&gt;6402257744_op -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>6402258368&#45;&gt;6402257744_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M361.31,-512.23C405.16,-524.27 452.53,-544.12 486.5,-576.78 516.52,-605.66 529.81,-653.45 535.49,-684.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"532.03,-684.78 537.13,-694.07 538.94,-683.63 532.03,-684.78\"/>\n",
       "</g>\n",
       "<!-- 6402161024_op -->\n",
       "<g id=\"node79\" class=\"node\">\n",
       "<title>6402161024_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.5\" cy=\"-603.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"540.5\" y=\"-598.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402258368&#45;&gt;6402161024_op -->\n",
       "<g id=\"edge59\" class=\"edge\">\n",
       "<title>6402258368&#45;&gt;6402161024_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M305.88,-512.25C355.38,-527.71 426.32,-551.3 486.5,-576.78 495.83,-580.74 505.79,-585.62 514.53,-590.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"512.65,-593.11 523.13,-594.7 515.92,-586.93 512.65,-593.11\"/>\n",
       "</g>\n",
       "<!-- 6402147296_op -->\n",
       "<g id=\"node103\" class=\"node\">\n",
       "<title>6402147296_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.5\" cy=\"-328.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"540.5\" y=\"-323.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402258368&#45;&gt;6402147296_op -->\n",
       "<g id=\"edge87\" class=\"edge\">\n",
       "<title>6402258368&#45;&gt;6402147296_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M277.26,-475.34C336.81,-442.06 460.97,-372.67 514.29,-342.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"515.91,-345.98 522.93,-338.04 512.49,-339.87 515.91,-345.98\"/>\n",
       "</g>\n",
       "<!-- 6402159152_op -->\n",
       "<g id=\"node127\" class=\"node\">\n",
       "<title>6402159152_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"540.5\" cy=\"-163.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"540.5\" y=\"-158.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402258368&#45;&gt;6402159152_op -->\n",
       "<g id=\"edge115\" class=\"edge\">\n",
       "<title>6402258368&#45;&gt;6402159152_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M302.4,-475.33C357.75,-454.81 439.39,-416.34 486.5,-355.78 524.12,-307.43 535.05,-234.04 538.22,-193.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"541.71,-193.66 538.87,-183.46 534.73,-193.21 541.71,-193.66\"/>\n",
       "</g>\n",
       "<!-- 6402160064 -->\n",
       "<g id=\"node55\" class=\"node\">\n",
       "<title>6402160064</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1261,-613.78 1261,-649.78 1626,-649.78 1626,-613.78 1261,-613.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1270.88\" y=\"-626.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1280.75,-614.28 1280.75,-649.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-626.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.8499354686639986 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402160064&#45;&gt;6402158192_op -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>6402160064&#45;&gt;6402158192_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1626.09,-635.46C1659.89,-636.14 1691.26,-636.77 1712.7,-637.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.53,-640.7 1722.6,-637.41 1712.67,-633.71 1712.53,-640.7\"/>\n",
       "</g>\n",
       "<!-- 6402160064_op -->\n",
       "<g id=\"node56\" class=\"node\">\n",
       "<title>6402160064_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-521.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-516.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402160064_op&#45;&gt;6402160064 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>6402160064_op&#45;&gt;6402160064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1151.45,-538.74C1158.98,-558.24 1174.21,-589.52 1198.75,-604.78 1214.39,-614.51 1231.71,-621.73 1249.69,-626.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1248.62,-630.33 1259.19,-629.56 1250.45,-623.57 1248.62,-630.33\"/>\n",
       "</g>\n",
       "<!-- 6402257024 -->\n",
       "<g id=\"node57\" class=\"node\">\n",
       "<title>6402257024</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"603.5,-503.78 603.5,-539.78 1081.75,-539.78 1081.75,-503.78 603.5,-503.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"670\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 0 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"736.5,-504.28 736.5,-539.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"909.12\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9499929772228866 grad=0.014487668220432983</text>\n",
       "</g>\n",
       "<!-- 6402257024&#45;&gt;6402160064_op -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>6402257024&#45;&gt;6402160064_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1081.93,-521.78C1094.38,-521.78 1105.58,-521.78 1114.91,-521.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1114.91,-525.28 1124.91,-521.78 1114.91,-518.28 1114.91,-525.28\"/>\n",
       "</g>\n",
       "<!-- 6402259952 -->\n",
       "<g id=\"node58\" class=\"node\">\n",
       "<title>6402259952</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"713,-393.78 713,-429.78 972.25,-429.78 972.25,-393.78 713,-393.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"722.88\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"732.75,-394.28 732.75,-429.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 3.0 grad=0.044372902481033025</text>\n",
       "</g>\n",
       "<!-- 6402259952&#45;&gt;6402160064_op -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>6402259952&#45;&gt;6402160064_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M972.54,-405.43C1012.87,-408.75 1055.89,-418.17 1090.75,-439.78 1093.65,-441.58 1113.9,-473.61 1128.51,-497.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1125.51,-498.9 1133.75,-505.55 1131.46,-495.21 1125.51,-498.9\"/>\n",
       "</g>\n",
       "<!-- 6402161408_op -->\n",
       "<g id=\"node82\" class=\"node\">\n",
       "<title>6402161408_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-466.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-461.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402259952&#45;&gt;6402161408_op -->\n",
       "<g id=\"edge64\" class=\"edge\">\n",
       "<title>6402259952&#45;&gt;6402161408_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M972.69,-417.62C1011.25,-421.7 1053.22,-428.5 1090.75,-439.78 1100.45,-442.7 1110.5,-447.35 1119.21,-451.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1117.29,-454.91 1127.73,-456.74 1120.71,-448.8 1117.29,-454.91\"/>\n",
       "</g>\n",
       "<!-- 6402154016_op -->\n",
       "<g id=\"node106\" class=\"node\">\n",
       "<title>6402154016_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-246.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402259952&#45;&gt;6402154016_op -->\n",
       "<g id=\"edge92\" class=\"edge\">\n",
       "<title>6402259952&#45;&gt;6402154016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M972.62,-423.43C1014.22,-420.77 1057.99,-410.4 1090.75,-383.78 1130.35,-351.61 1105.37,-321.11 1126.75,-274.78 1127.26,-273.67 1127.81,-272.55 1128.38,-271.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1131.34,-273.31 1133.19,-262.87 1125.24,-269.88 1131.34,-273.31\"/>\n",
       "</g>\n",
       "<!-- 6402160016_op -->\n",
       "<g id=\"node130\" class=\"node\">\n",
       "<title>6402160016_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-191.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-186.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402259952&#45;&gt;6402160016_op -->\n",
       "<g id=\"edge120\" class=\"edge\">\n",
       "<title>6402259952&#45;&gt;6402160016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M972.64,-425.41C1014.85,-423.08 1059,-412.41 1090.75,-383.78 1146.17,-333.81 1099.01,-289.06 1126.75,-219.78 1127.2,-218.65 1127.7,-217.51 1128.23,-216.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1131.22,-218.21 1132.9,-207.75 1125.06,-214.88 1131.22,-218.21\"/>\n",
       "</g>\n",
       "<!-- 6402155984 -->\n",
       "<g id=\"node59\" class=\"node\">\n",
       "<title>6402155984</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1802.62,-503.78 1802.62,-539.78 2163.12,-539.78 2163.12,-503.78 1802.62,-503.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1812.5\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1822.38,-504.28 1822.38,-539.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.4499413632617615 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402155984&#45;&gt;6402148160_op -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>6402155984&#45;&gt;6402148160_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2152.9,-540.28C2158.66,-543.1 2164.22,-546.25 2169.5,-549.78 2190.79,-564.02 2204.88,-589.98 2213.14,-610.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2209.85,-611.23 2216.7,-619.31 2216.39,-608.72 2209.85,-611.23\"/>\n",
       "</g>\n",
       "<!-- 6402155984_op -->\n",
       "<g id=\"node60\" class=\"node\">\n",
       "<title>6402155984_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-521.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-516.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402155984_op&#45;&gt;6402155984 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>6402155984_op&#45;&gt;6402155984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-521.78C1768.43,-521.78 1778.85,-521.78 1790.81,-521.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1790.67,-525.28 1800.67,-521.78 1790.67,-518.28 1790.67,-525.28\"/>\n",
       "</g>\n",
       "<!-- 6402254672 -->\n",
       "<g id=\"node61\" class=\"node\">\n",
       "<title>6402254672</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1198.75,-503.78 1198.75,-539.78 1688.25,-539.78 1688.25,-503.78 1198.75,-503.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1265.25\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 0 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1331.75,-504.28 1331.75,-539.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1510\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.44993653403902134 grad=&#45;0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402254672&#45;&gt;6402155984_op -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>6402254672&#45;&gt;6402155984_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1688.54,-521.78C1697.41,-521.78 1705.48,-521.78 1712.49,-521.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.41,-525.28 1722.41,-521.78 1712.41,-518.28 1712.41,-525.28\"/>\n",
       "</g>\n",
       "<!-- 6402250352 -->\n",
       "<g id=\"node62\" class=\"node\">\n",
       "<title>6402250352</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1315,-393.78 1315,-429.78 1572,-429.78 1572,-393.78 1315,-393.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1324.88\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1334.75,-394.28 1334.75,-429.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.0 grad=0.10121675360458975</text>\n",
       "</g>\n",
       "<!-- 6402250352&#45;&gt;6402155984_op -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>6402250352&#45;&gt;6402155984_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1572.3,-405.8C1611.89,-409.18 1654.05,-418.55 1688.25,-439.78 1691.15,-441.59 1711.4,-473.61 1726.01,-497.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1723.01,-498.9 1731.25,-505.55 1728.96,-495.21 1723.01,-498.9\"/>\n",
       "</g>\n",
       "<!-- 6402160448_op -->\n",
       "<g id=\"node85\" class=\"node\">\n",
       "<title>6402160448_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-466.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-461.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402250352&#45;&gt;6402160448_op -->\n",
       "<g id=\"edge69\" class=\"edge\">\n",
       "<title>6402250352&#45;&gt;6402160448_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1572.44,-417.85C1610.29,-421.94 1651.44,-428.69 1688.25,-439.78 1697.95,-442.71 1708,-447.36 1716.71,-451.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1714.79,-454.92 1725.23,-456.75 1718.21,-448.81 1714.79,-454.92\"/>\n",
       "</g>\n",
       "<!-- 6402147584_op -->\n",
       "<g id=\"node109\" class=\"node\">\n",
       "<title>6402147584_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-356.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-351.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402250352&#45;&gt;6402147584_op -->\n",
       "<g id=\"edge97\" class=\"edge\">\n",
       "<title>6402250352&#45;&gt;6402147584_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1572.44,-405.72C1610.29,-401.63 1651.44,-394.88 1688.25,-383.78 1697.95,-380.86 1708,-376.21 1716.71,-371.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1718.21,-374.76 1725.23,-366.82 1714.79,-368.65 1718.21,-374.76\"/>\n",
       "</g>\n",
       "<!-- 6402154448_op -->\n",
       "<g id=\"node133\" class=\"node\">\n",
       "<title>6402154448_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-301.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-296.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402250352&#45;&gt;6402154448_op -->\n",
       "<g id=\"edge125\" class=\"edge\">\n",
       "<title>6402250352&#45;&gt;6402154448_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1572.3,-417.77C1611.89,-414.39 1654.05,-405.02 1688.25,-383.78 1691.15,-381.98 1711.4,-349.96 1726.01,-326.47\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1728.96,-328.36 1731.25,-318.02 1723.01,-324.67 1728.96,-328.36\"/>\n",
       "</g>\n",
       "<!-- 6402254912 -->\n",
       "<g id=\"node63\" class=\"node\">\n",
       "<title>6402254912</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2277.5,-689.78 2277.5,-725.78 2746,-725.78 2746,-689.78 2277.5,-689.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2339.12\" y=\"-702.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 0 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2400.75,-690.28 2400.75,-725.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2573.38\" y=\"-702.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.5535833529250946 grad=0.004829222740144328</text>\n",
       "</g>\n",
       "<!-- 6402254912&#45;&gt;6402259376_op -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>6402254912&#45;&gt;6402259376_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2746.44,-707.78C2821.93,-707.78 2896.25,-707.78 2935.54,-707.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2935.29,-711.28 2945.29,-707.78 2935.29,-704.28 2935.29,-711.28\"/>\n",
       "</g>\n",
       "<!-- 6402155504 -->\n",
       "<g id=\"node64\" class=\"node\">\n",
       "<title>6402155504</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5049.96,-715.78 5049.96,-751.78 5421.71,-751.78 5421.71,-715.78 5049.96,-715.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5059.83\" y=\"-728.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5069.71,-716.28 5069.71,-751.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-728.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.06715959759236634 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402155504&#45;&gt;6402160256_op -->\n",
       "<g id=\"edge75\" class=\"edge\">\n",
       "<title>6402155504&#45;&gt;6402160256_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5422.08,-733.78C5455.63,-733.78 5486.69,-733.78 5507.99,-733.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5507.84,-737.28 5517.84,-733.78 5507.84,-730.28 5507.84,-737.28\"/>\n",
       "</g>\n",
       "<!-- 6402155504_op -->\n",
       "<g id=\"node65\" class=\"node\">\n",
       "<title>6402155504_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-733.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-728.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402155504_op&#45;&gt;6402155504 -->\n",
       "<g id=\"edge49\" class=\"edge\">\n",
       "<title>6402155504_op&#45;&gt;6402155504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-733.78C4970.98,-733.78 5002.71,-733.78 5038.34,-733.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5037.99,-737.28 5047.99,-733.78 5037.99,-730.28 5037.99,-737.28\"/>\n",
       "</g>\n",
       "<!-- 6402256016 -->\n",
       "<g id=\"node66\" class=\"node\">\n",
       "<title>6402256016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4386.14,-715.78 4386.14,-751.78 4864.39,-751.78 4864.39,-715.78 4386.14,-715.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4452.64\" y=\"-728.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 0 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4519.14,-716.28 4519.14,-751.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4691.76\" y=\"-728.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.17854129211808092 grad=&#45;0.00992436626348306</text>\n",
       "</g>\n",
       "<!-- 6402256016&#45;&gt;6402155504_op -->\n",
       "<g id=\"edge50\" class=\"edge\">\n",
       "<title>6402256016&#45;&gt;6402155504_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4864.87,-733.78C4880.03,-733.78 4893.57,-733.78 4904.5,-733.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.16,-737.28 4914.16,-733.78 4904.16,-730.28 4904.16,-737.28\"/>\n",
       "</g>\n",
       "<!-- 6402148400 -->\n",
       "<g id=\"node67\" class=\"node\">\n",
       "<title>6402148400</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4448.39,-605.78 4448.39,-641.78 4802.14,-641.78 4802.14,-605.78 4448.39,-605.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4458.26\" y=\"-618.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4468.14,-606.28 4468.14,-641.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-618.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.3761781385427304 grad=0.15071369974336016</text>\n",
       "</g>\n",
       "<!-- 6402148400&#45;&gt;6402155504_op -->\n",
       "<g id=\"edge74\" class=\"edge\">\n",
       "<title>6402148400&#45;&gt;6402155504_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4802.39,-625.19C4826.64,-630.63 4850.32,-639.07 4871.14,-651.78 4895.75,-666.82 4889.31,-683.11 4907.14,-705.78 4909.09,-708.27 4911.21,-710.8 4913.37,-713.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4910.35,-715.15 4919.66,-720.21 4915.54,-710.45 4910.35,-715.15\"/>\n",
       "</g>\n",
       "<!-- 6402157856_op -->\n",
       "<g id=\"node157\" class=\"node\">\n",
       "<title>6402157856_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-678.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-673.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402148400&#45;&gt;6402157856_op -->\n",
       "<g id=\"edge154\" class=\"edge\">\n",
       "<title>6402148400&#45;&gt;6402157856_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4802.36,-637.51C4825.69,-641.19 4849.14,-645.86 4871.14,-651.78 4883.52,-655.12 4896.61,-660.54 4907.54,-665.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4905.76,-668.68 4916.28,-669.91 4908.83,-662.38 4905.76,-668.68\"/>\n",
       "</g>\n",
       "<!-- 6402158864_op -->\n",
       "<g id=\"node186\" class=\"node\">\n",
       "<title>6402158864_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-568.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-563.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402148400&#45;&gt;6402158864_op -->\n",
       "<g id=\"edge188\" class=\"edge\">\n",
       "<title>6402148400&#45;&gt;6402158864_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4802.43,-611.14C4825.75,-607.49 4849.17,-602.81 4871.14,-596.78 4883.57,-593.37 4896.68,-587.76 4907.6,-582.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4909,-585.66 4916.34,-578.02 4905.84,-579.42 4909,-585.66\"/>\n",
       "</g>\n",
       "<!-- 6402154736_op -->\n",
       "<g id=\"node215\" class=\"node\">\n",
       "<title>6402154736_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-403.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-398.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402148400&#45;&gt;6402154736_op -->\n",
       "<g id=\"edge222\" class=\"edge\">\n",
       "<title>6402148400&#45;&gt;6402154736_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4802.47,-629.03C4827.47,-623.06 4851.35,-612.96 4871.14,-596.78 4872.79,-595.43 4907.51,-485.01 4924.16,-431.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4927.42,-433.14 4927.06,-422.55 4920.74,-431.05 4927.42,-433.14\"/>\n",
       "</g>\n",
       "<!-- 6402148400_op -->\n",
       "<g id=\"node68\" class=\"node\">\n",
       "<title>6402148400_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4316.6\" cy=\"-597.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4316.6\" y=\"-592.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402148400_op&#45;&gt;6402148400 -->\n",
       "<g id=\"edge51\" class=\"edge\">\n",
       "<title>6402148400_op&#45;&gt;6402148400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4343.75,-600C4366.03,-601.89 4400.24,-604.79 4437.2,-607.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4436.45,-611.37 4446.71,-608.73 4437.04,-604.4 4436.45,-611.37\"/>\n",
       "</g>\n",
       "<!-- 6402161456 -->\n",
       "<g id=\"node69\" class=\"node\">\n",
       "<title>6402161456</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3835.94,-579.78 3835.94,-615.78 4182.94,-615.78 4182.94,-579.78 3835.94,-579.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3845.82\" y=\"-592.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3855.69,-580.28 3855.69,-615.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4019.32\" y=\"-592.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.3956003110426589 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402161456&#45;&gt;6402148400_op -->\n",
       "<g id=\"edge73\" class=\"edge\">\n",
       "<title>6402161456&#45;&gt;6402148400_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4183.09,-597.78C4219.01,-597.78 4253.43,-597.78 4278.18,-597.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4278.01,-601.28 4288.01,-597.78 4278.01,-594.28 4278.01,-601.28\"/>\n",
       "</g>\n",
       "<!-- 6402161456_op -->\n",
       "<g id=\"node70\" class=\"node\">\n",
       "<title>6402161456_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3702.28\" cy=\"-597.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3702.28\" y=\"-592.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402161456_op&#45;&gt;6402161456 -->\n",
       "<g id=\"edge52\" class=\"edge\">\n",
       "<title>6402161456_op&#45;&gt;6402161456</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3720.57,-597.78C3742.09,-597.78 3781.28,-597.78 3823.95,-597.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3823.95,-601.28 3833.95,-597.78 3823.95,-594.28 3823.95,-601.28\"/>\n",
       "</g>\n",
       "<!-- 6402158000 -->\n",
       "<g id=\"node71\" class=\"node\">\n",
       "<title>6402158000</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2791.75,-545.78 2791.75,-581.78 3138.75,-581.78 3138.75,-545.78 2791.75,-545.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2801.62\" y=\"-558.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2811.5,-546.28 2811.5,-581.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2975.12\" y=\"-558.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1.2217226457838266 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402158000&#45;&gt;6402161456_op -->\n",
       "<g id=\"edge71\" class=\"edge\">\n",
       "<title>6402158000&#45;&gt;6402161456_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3139.23,-559.78C3275.64,-558.82 3470.42,-562.32 3639.5,-583.78 3650.76,-585.21 3662.98,-587.76 3673.55,-590.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3672.64,-593.68 3683.19,-592.73 3674.35,-586.89 3672.64,-593.68\"/>\n",
       "</g>\n",
       "<!-- 6402158000_op -->\n",
       "<g id=\"node72\" class=\"node\">\n",
       "<title>6402158000_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2223.5\" cy=\"-563.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2223.5\" y=\"-558.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402158000_op&#45;&gt;6402158000 -->\n",
       "<g id=\"edge53\" class=\"edge\">\n",
       "<title>6402158000_op&#45;&gt;6402158000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2241.7,-563.78C2312.97,-563.78 2590.28,-563.78 2779.87,-563.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2779.86,-567.28 2789.86,-563.78 2779.86,-560.28 2779.86,-567.28\"/>\n",
       "</g>\n",
       "<!-- 6402147920 -->\n",
       "<g id=\"node73\" class=\"node\">\n",
       "<title>6402147920</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1809.38,-558.78 1809.38,-594.78 2156.38,-594.78 2156.38,-558.78 1809.38,-558.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1819.25\" y=\"-571.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1829.12,-559.28 1829.12,-594.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-571.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 2.0060817811935174 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402147920&#45;&gt;6402158000_op -->\n",
       "<g id=\"edge66\" class=\"edge\">\n",
       "<title>6402147920&#45;&gt;6402158000_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2156.66,-567.37C2170.7,-566.61 2183.5,-565.91 2194,-565.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2193.9,-568.85 2203.69,-564.81 2193.52,-561.86 2193.9,-568.85\"/>\n",
       "</g>\n",
       "<!-- 6402147920_op -->\n",
       "<g id=\"node74\" class=\"node\">\n",
       "<title>6402147920_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-576.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-571.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402147920_op&#45;&gt;6402147920 -->\n",
       "<g id=\"edge54\" class=\"edge\">\n",
       "<title>6402147920_op&#45;&gt;6402147920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-576.78C1769.96,-576.78 1782.91,-576.78 1797.8,-576.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1797.44,-580.28 1807.44,-576.78 1797.44,-573.28 1797.44,-580.28\"/>\n",
       "</g>\n",
       "<!-- 6402156080 -->\n",
       "<g id=\"node75\" class=\"node\">\n",
       "<title>6402156080</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1270,-668.78 1270,-704.78 1617,-704.78 1617,-668.78 1270,-668.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1279.88\" y=\"-681.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1289.75,-669.28 1289.75,-704.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-681.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.9458848566560496 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402156080&#45;&gt;6402147920_op -->\n",
       "<g id=\"edge61\" class=\"edge\">\n",
       "<title>6402156080&#45;&gt;6402147920_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1617.48,-687C1642.47,-681.64 1666.92,-673.05 1688.25,-659.78 1699.42,-652.84 1716.3,-624.27 1728,-602.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1730.98,-604.41 1732.57,-593.94 1724.8,-601.14 1730.98,-604.41\"/>\n",
       "</g>\n",
       "<!-- 6402156080_op -->\n",
       "<g id=\"node76\" class=\"node\">\n",
       "<title>6402156080_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-631.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-626.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402156080_op&#45;&gt;6402156080 -->\n",
       "<g id=\"edge55\" class=\"edge\">\n",
       "<title>6402156080_op&#45;&gt;6402156080</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1160.4,-641.46C1170.69,-647.76 1185.02,-655.57 1198.75,-659.78 1217.81,-665.64 1238.05,-670.26 1258.4,-673.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1257.78,-677.34 1268.23,-675.56 1258.95,-670.44 1257.78,-677.34\"/>\n",
       "</g>\n",
       "<!-- 6402161552 -->\n",
       "<g id=\"node77\" class=\"node\">\n",
       "<title>6402161552</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"719.75,-558.78 719.75,-594.78 965.5,-594.78 965.5,-558.78 719.75,-558.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"729.62\" y=\"-571.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"739.5,-559.28 739.5,-594.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-571.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402161552&#45;&gt;6402156080_op -->\n",
       "<g id=\"edge56\" class=\"edge\">\n",
       "<title>6402161552&#45;&gt;6402156080_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M965.72,-581.91C1006.14,-585.9 1050.95,-592.82 1090.75,-604.78 1100.45,-607.7 1110.5,-612.35 1119.21,-616.97\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1117.29,-619.91 1127.73,-621.74 1120.71,-613.8 1117.29,-619.91\"/>\n",
       "</g>\n",
       "<!-- 6402161024 -->\n",
       "<g id=\"node78\" class=\"node\">\n",
       "<title>6402161024</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"669.12,-613.78 669.12,-649.78 1016.12,-649.78 1016.12,-613.78 669.12,-613.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"679\" y=\"-626.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"688.88,-614.28 688.88,-649.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-626.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.9458848566560496 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402161024&#45;&gt;6402156080_op -->\n",
       "<g id=\"edge60\" class=\"edge\">\n",
       "<title>6402161024&#45;&gt;6402156080_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1016.47,-631.78C1054.86,-631.78 1091.22,-631.78 1115.17,-631.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1114.99,-635.28 1124.99,-631.78 1114.99,-628.28 1114.99,-635.28\"/>\n",
       "</g>\n",
       "<!-- 6402161024_op&#45;&gt;6402161024 -->\n",
       "<g id=\"edge57\" class=\"edge\">\n",
       "<title>6402161024_op&#45;&gt;6402161024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M558.5,-605.37C579.23,-607.3 616.6,-610.79 657.55,-614.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"657.1,-618.08 667.38,-615.53 657.75,-611.11 657.1,-618.08\"/>\n",
       "</g>\n",
       "<!-- 6402254864 -->\n",
       "<g id=\"node80\" class=\"node\">\n",
       "<title>6402254864</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"9.75,-585.78 9.75,-621.78 476.75,-621.78 476.75,-585.78 9.75,-585.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"76.25\" y=\"-598.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 1 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"142.75,-586.28 142.75,-621.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"309.75\" y=\"-598.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.47268365591740313 grad=0.2587724106216494</text>\n",
       "</g>\n",
       "<!-- 6402254864&#45;&gt;6402161024_op -->\n",
       "<g id=\"edge58\" class=\"edge\">\n",
       "<title>6402254864&#45;&gt;6402161024_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M477.25,-603.78C489.9,-603.78 501.28,-603.78 510.74,-603.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.51,-607.28 520.51,-603.78 510.51,-600.28 510.51,-607.28\"/>\n",
       "</g>\n",
       "<!-- 6402161408 -->\n",
       "<g id=\"node81\" class=\"node\">\n",
       "<title>6402161408</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1270,-558.78 1270,-594.78 1617,-594.78 1617,-558.78 1270,-558.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1279.88\" y=\"-571.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1289.75,-559.28 1289.75,-594.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-571.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1.0601969245374678 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402161408&#45;&gt;6402147920_op -->\n",
       "<g id=\"edge65\" class=\"edge\">\n",
       "<title>6402161408&#45;&gt;6402147920_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1617.12,-576.78C1654.3,-576.78 1689.39,-576.78 1712.72,-576.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.58,-580.28 1722.58,-576.78 1712.58,-573.28 1712.58,-580.28\"/>\n",
       "</g>\n",
       "<!-- 6402161408_op&#45;&gt;6402161408 -->\n",
       "<g id=\"edge62\" class=\"edge\">\n",
       "<title>6402161408_op&#45;&gt;6402161408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1154.94,-481.91C1169.21,-505.28 1195.39,-547.7 1198.75,-549.78 1216.91,-561.08 1237.34,-568.99 1258.43,-574.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1257.51,-577.77 1268.04,-576.65 1259.11,-570.95 1257.51,-577.77\"/>\n",
       "</g>\n",
       "<!-- 6402254960 -->\n",
       "<g id=\"node83\" class=\"node\">\n",
       "<title>6402254960</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"609.12,-448.78 609.12,-484.78 1076.12,-484.78 1076.12,-448.78 609.12,-448.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"675.62\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 1 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"742.12,-449.28 742.12,-484.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"909.12\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.3530108162298901 grad=0.38815861593247414</text>\n",
       "</g>\n",
       "<!-- 6402254960&#45;&gt;6402161408_op -->\n",
       "<g id=\"edge63\" class=\"edge\">\n",
       "<title>6402254960&#45;&gt;6402161408_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1076.4,-466.78C1091.12,-466.78 1104.3,-466.78 1115.01,-466.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1114.88,-470.28 1124.88,-466.78 1114.88,-463.28 1114.88,-470.28\"/>\n",
       "</g>\n",
       "<!-- 6402160448 -->\n",
       "<g id=\"node84\" class=\"node\">\n",
       "<title>6402160448</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1807.12,-448.78 1807.12,-484.78 2158.62,-484.78 2158.62,-448.78 1807.12,-448.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1817\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1826.88,-449.28 1826.88,-484.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.7843591354096908 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402160448&#45;&gt;6402158000_op -->\n",
       "<g id=\"edge70\" class=\"edge\">\n",
       "<title>6402160448&#45;&gt;6402158000_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2150.6,-485.27C2157.13,-488.07 2163.46,-491.23 2169.5,-494.78 2186.63,-504.88 2200.15,-522.84 2209.25,-537.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2206.11,-539.45 2214.09,-546.42 2212.2,-535.99 2206.11,-539.45\"/>\n",
       "</g>\n",
       "<!-- 6402160448_op&#45;&gt;6402160448 -->\n",
       "<g id=\"edge67\" class=\"edge\">\n",
       "<title>6402160448_op&#45;&gt;6402160448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-466.78C1769.43,-466.78 1781.5,-466.78 1795.37,-466.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1795.34,-470.28 1805.34,-466.78 1795.34,-463.28 1795.34,-470.28\"/>\n",
       "</g>\n",
       "<!-- 6402255056 -->\n",
       "<g id=\"node86\" class=\"node\">\n",
       "<title>6402255056</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1211.12,-448.78 1211.12,-484.78 1675.88,-484.78 1675.88,-448.78 1211.12,-448.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1277.62\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 1 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1344.12,-449.28 1344.12,-484.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1510\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.7844885216150016 grad=&#45;0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402255056&#45;&gt;6402160448_op -->\n",
       "<g id=\"edge68\" class=\"edge\">\n",
       "<title>6402255056&#45;&gt;6402160448_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1676.13,-466.78C1690.03,-466.78 1702.49,-466.78 1712.7,-466.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.47,-470.28 1722.47,-466.78 1712.47,-463.28 1712.47,-470.28\"/>\n",
       "</g>\n",
       "<!-- 6402255104 -->\n",
       "<g id=\"node87\" class=\"node\">\n",
       "<title>6402255104</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3184.5,-592.78 3184.5,-628.78 3639.5,-628.78 3639.5,-592.78 3184.5,-592.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3246.12\" y=\"-605.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 1 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3307.75,-593.28 3307.75,-628.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3473.62\" y=\"-605.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.8262517209464785 grad=0.1293862053108247</text>\n",
       "</g>\n",
       "<!-- 6402255104&#45;&gt;6402161456_op -->\n",
       "<g id=\"edge72\" class=\"edge\">\n",
       "<title>6402255104&#45;&gt;6402161456_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3639.79,-600.56C3652.14,-600 3663.26,-599.5 3672.55,-599.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"3672.66,-602.58 3682.5,-598.63 3672.35,-595.59 3672.66,-602.58\"/>\n",
       "</g>\n",
       "<!-- 6402158288 -->\n",
       "<g id=\"node88\" class=\"node\">\n",
       "<title>6402158288</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5658.28,-570.78 5658.28,-606.78 6027.78,-606.78 6027.78,-570.78 5658.28,-570.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5668.15\" y=\"-583.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5678.03,-571.28 5678.03,-606.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-583.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.6115095847108565 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402158288&#45;&gt;6402155120_op -->\n",
       "<g id=\"edge103\" class=\"edge\">\n",
       "<title>6402158288&#45;&gt;6402155120_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6028.03,-588.78C6059.95,-588.78 6089.41,-588.78 6109.87,-588.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6109.6,-592.28 6119.6,-588.78 6109.6,-585.28 6109.6,-592.28\"/>\n",
       "</g>\n",
       "<!-- 6402158288_op -->\n",
       "<g id=\"node89\" class=\"node\">\n",
       "<title>6402158288_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-588.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-583.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402158288_op&#45;&gt;6402158288 -->\n",
       "<g id=\"edge77\" class=\"edge\">\n",
       "<title>6402158288_op&#45;&gt;6402158288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-588.78C5575.31,-588.78 5609.1,-588.78 5646.83,-588.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5646.6,-592.28 5656.6,-588.78 5646.6,-585.28 5646.6,-592.28\"/>\n",
       "</g>\n",
       "<!-- 6402255872 -->\n",
       "<g id=\"node90\" class=\"node\">\n",
       "<title>6402255872</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5002.33,-605.78 5002.33,-641.78 5469.33,-641.78 5469.33,-605.78 5002.33,-605.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5068.83\" y=\"-618.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 0 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5135.33,-606.28 5135.33,-641.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5302.33\" y=\"-618.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6188348446513917 grad=0.02606870426158594</text>\n",
       "</g>\n",
       "<!-- 6402255872&#45;&gt;6402158288_op -->\n",
       "<g id=\"edge78\" class=\"edge\">\n",
       "<title>6402255872&#45;&gt;6402158288_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5402.76,-605.31C5426.99,-602.52 5451.62,-599.62 5474.96,-596.78 5485.76,-595.47 5497.62,-593.96 5508.03,-592.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5508.48,-596.07 5517.94,-591.3 5507.57,-589.13 5508.48,-596.07\"/>\n",
       "</g>\n",
       "<!-- 6402153392 -->\n",
       "<g id=\"node91\" class=\"node\">\n",
       "<title>6402153392</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5054.46,-385.78 5054.46,-421.78 5417.21,-421.78 5417.21,-385.78 5054.46,-385.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5064.33\" y=\"-398.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5074.21,-386.28 5074.21,-421.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-398.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9881211941388645 grad=&#45;0.14438336294567486</text>\n",
       "</g>\n",
       "<!-- 6402153392&#45;&gt;6402158288_op -->\n",
       "<g id=\"edge102\" class=\"edge\">\n",
       "<title>6402153392&#45;&gt;6402158288_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5417.49,-402.3C5438.44,-408.46 5458.25,-417.86 5474.96,-431.78 5516.76,-466.61 5488,-499.46 5510.96,-548.78 5513.51,-554.26 5516.7,-559.87 5519.97,-565.1\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5516.92,-566.84 5525.35,-573.26 5522.77,-562.98 5516.92,-566.84\"/>\n",
       "</g>\n",
       "<!-- 6402147488_op -->\n",
       "<g id=\"node160\" class=\"node\">\n",
       "<title>6402147488_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-458.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-453.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402153392&#45;&gt;6402147488_op -->\n",
       "<g id=\"edge159\" class=\"edge\">\n",
       "<title>6402153392&#45;&gt;6402147488_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5417.66,-419.35C5437.16,-422.71 5456.58,-426.81 5474.96,-431.78 5487.33,-435.14 5500.42,-440.56 5511.35,-445.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5509.58,-448.7 5520.1,-449.93 5512.64,-442.4 5509.58,-448.7\"/>\n",
       "</g>\n",
       "<!-- 6402156224_op -->\n",
       "<g id=\"node189\" class=\"node\">\n",
       "<title>6402156224_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-403.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-398.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402153392&#45;&gt;6402156224_op -->\n",
       "<g id=\"edge193\" class=\"edge\">\n",
       "<title>6402153392&#45;&gt;6402156224_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5417.35,-403.78C5452.73,-403.78 5485.74,-403.78 5508.04,-403.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5507.76,-407.28 5517.76,-403.78 5507.76,-400.28 5507.76,-407.28\"/>\n",
       "</g>\n",
       "<!-- 6402155936_op -->\n",
       "<g id=\"node218\" class=\"node\">\n",
       "<title>6402155936_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-191.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-186.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402153392&#45;&gt;6402155936_op -->\n",
       "<g id=\"edge227\" class=\"edge\">\n",
       "<title>6402153392&#45;&gt;6402155936_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5417.57,-406.66C5438.69,-400.33 5458.53,-390.51 5474.96,-375.78 5527.96,-328.31 5477.75,-282.72 5510.96,-219.78 5512.41,-217.03 5514.2,-214.34 5516.16,-211.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5518.69,-214.21 5522.66,-204.38 5513.43,-209.59 5518.69,-214.21\"/>\n",
       "</g>\n",
       "<!-- 6402153392_op -->\n",
       "<g id=\"node92\" class=\"node\">\n",
       "<title>6402153392_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-321.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-316.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402153392_op&#45;&gt;6402153392 -->\n",
       "<g id=\"edge79\" class=\"edge\">\n",
       "<title>6402153392_op&#45;&gt;6402153392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.01,-341.88C4963.39,-353.82 4979.39,-368.1 4996.71,-375.78 5011.39,-382.3 5027.06,-387.49 5043.08,-391.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5042.21,-394.99 5052.75,-393.92 5043.85,-388.18 5042.21,-394.99\"/>\n",
       "</g>\n",
       "<!-- 6402147056 -->\n",
       "<g id=\"node93\" class=\"node\">\n",
       "<title>6402147056</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4437.14,-275.78 4437.14,-311.78 4813.39,-311.78 4813.39,-275.78 4437.14,-275.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4447.01\" y=\"-288.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4456.89,-276.28 4456.89,-311.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-288.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.5600947780309777 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402147056&#45;&gt;6402153392_op -->\n",
       "<g id=\"edge101\" class=\"edge\">\n",
       "<title>6402147056&#45;&gt;6402153392_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4813.48,-310.88C4844.63,-313.72 4873.81,-316.39 4895.53,-318.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4895.01,-321.84 4905.29,-319.26 4895.65,-314.87 4895.01,-321.84\"/>\n",
       "</g>\n",
       "<!-- 6402147056_op -->\n",
       "<g id=\"node94\" class=\"node\">\n",
       "<title>6402147056_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4316.6\" cy=\"-293.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4316.6\" y=\"-288.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402147056_op&#45;&gt;6402147056 -->\n",
       "<g id=\"edge80\" class=\"edge\">\n",
       "<title>6402147056_op&#45;&gt;6402147056</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4334.97,-293.78C4354.34,-293.78 4387.95,-293.78 4425.55,-293.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4425.28,-297.28 4435.28,-293.78 4425.28,-290.28 4425.28,-297.28\"/>\n",
       "</g>\n",
       "<!-- 6402153824 -->\n",
       "<g id=\"node95\" class=\"node\">\n",
       "<title>6402153824</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2323.62,-228.78 2323.62,-264.78 2699.88,-264.78 2699.88,-228.78 2323.62,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2333.5\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2343.38,-229.28 2343.38,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2521.62\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.5708053542377027 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402153824&#45;&gt;6402147056_op -->\n",
       "<g id=\"edge99\" class=\"edge\">\n",
       "<title>6402153824&#45;&gt;6402147056_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2700.27,-246.78C2881.99,-246.78 3165.38,-246.78 3411,-246.78 3411,-246.78 3411,-246.78 3703.28,-246.78 3948.11,-246.78 4015.44,-209.97 4253.82,-265.78 4266.38,-268.72 4279.49,-274.27 4290.4,-279.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4288.63,-282.68 4299.11,-284.19 4291.86,-276.47 4288.63,-282.68\"/>\n",
       "</g>\n",
       "<!-- 6402153824_op -->\n",
       "<g id=\"node96\" class=\"node\">\n",
       "<title>6402153824_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2223.5\" cy=\"-246.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2223.5\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402153824_op&#45;&gt;6402153824 -->\n",
       "<g id=\"edge81\" class=\"edge\">\n",
       "<title>6402153824_op&#45;&gt;6402153824</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2241.98,-246.78C2257.85,-246.78 2283.16,-246.78 2312.03,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2311.75,-250.28 2321.75,-246.78 2311.75,-243.28 2311.75,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402157088 -->\n",
       "<g id=\"node97\" class=\"node\">\n",
       "<title>6402157088</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1798.12,-228.78 1798.12,-264.78 2167.62,-264.78 2167.62,-228.78 1798.12,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1808\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1817.88,-229.28 1817.88,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;3.133529404630496 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402157088&#45;&gt;6402153824_op -->\n",
       "<g id=\"edge94\" class=\"edge\">\n",
       "<title>6402157088&#45;&gt;6402153824_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2168.05,-246.78C2177.54,-246.78 2186.23,-246.78 2193.76,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2193.75,-250.28 2203.75,-246.78 2193.75,-243.28 2193.75,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402157088_op -->\n",
       "<g id=\"node98\" class=\"node\">\n",
       "<title>6402157088_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-246.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402157088_op&#45;&gt;6402157088 -->\n",
       "<g id=\"edge82\" class=\"edge\">\n",
       "<title>6402157088_op&#45;&gt;6402157088</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-246.78C1767.4,-246.78 1776.21,-246.78 1786.26,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1786.12,-250.28 1796.12,-246.78 1786.12,-243.28 1786.12,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402148064 -->\n",
       "<g id=\"node99\" class=\"node\">\n",
       "<title>6402148064</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1255.38,-228.78 1255.38,-264.78 1631.62,-264.78 1631.62,-228.78 1255.38,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1265.25\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1275.12,-229.28 1275.12,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.3123127212589183 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402148064&#45;&gt;6402157088_op -->\n",
       "<g id=\"edge89\" class=\"edge\">\n",
       "<title>6402148064&#45;&gt;6402157088_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1632.02,-246.78C1663.55,-246.78 1692.54,-246.78 1712.72,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.57,-250.28 1722.57,-246.78 1712.57,-243.28 1712.57,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402148064_op -->\n",
       "<g id=\"node100\" class=\"node\">\n",
       "<title>6402148064_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-301.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-296.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402148064_op&#45;&gt;6402148064 -->\n",
       "<g id=\"edge83\" class=\"edge\">\n",
       "<title>6402148064_op&#45;&gt;6402148064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1160.4,-292.11C1170.69,-285.81 1185.02,-278 1198.75,-273.78 1213.24,-269.33 1228.42,-265.59 1243.81,-262.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1244.41,-265.91 1253.56,-260.57 1243.07,-259.04 1244.41,-265.91\"/>\n",
       "</g>\n",
       "<!-- 6402153056 -->\n",
       "<g id=\"node101\" class=\"node\">\n",
       "<title>6402153056</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"707.38,-338.78 707.38,-374.78 977.88,-374.78 977.88,-338.78 707.38,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"717.25\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"727.12,-339.28 727.12,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402153056&#45;&gt;6402148064_op -->\n",
       "<g id=\"edge84\" class=\"edge\">\n",
       "<title>6402153056&#45;&gt;6402148064_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M978.13,-350.35C1015.17,-346.22 1054.98,-339.54 1090.75,-328.78 1100.45,-325.87 1110.5,-321.22 1119.21,-316.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1120.71,-319.77 1127.73,-311.83 1117.29,-313.66 1120.71,-319.77\"/>\n",
       "</g>\n",
       "<!-- 6402147296 -->\n",
       "<g id=\"node102\" class=\"node\">\n",
       "<title>6402147296</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"654.5,-283.78 654.5,-319.78 1030.75,-319.78 1030.75,-283.78 654.5,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"664.38\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"674.25,-284.28 674.25,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.3123127212589183 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402147296&#45;&gt;6402148064_op -->\n",
       "<g id=\"edge88\" class=\"edge\">\n",
       "<title>6402147296&#45;&gt;6402148064_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1031.14,-301.78C1063.87,-301.78 1094.06,-301.78 1114.93,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1114.85,-305.28 1124.85,-301.78 1114.85,-298.28 1114.85,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402147296_op&#45;&gt;6402147296 -->\n",
       "<g id=\"edge85\" class=\"edge\">\n",
       "<title>6402147296_op&#45;&gt;6402147296</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M558.93,-327.22C577.22,-325.57 608.11,-322.79 642.91,-319.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"643.19,-323.15 652.83,-318.77 642.56,-316.18 643.19,-323.15\"/>\n",
       "</g>\n",
       "<!-- 6402254720 -->\n",
       "<g id=\"node104\" class=\"node\">\n",
       "<title>6402254720</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5.25,-310.78 5.25,-346.78 481.25,-346.78 481.25,-310.78 5.25,-310.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"71.75\" y=\"-323.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 2 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"138.25,-311.28 138.25,-346.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"309.75\" y=\"-323.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.156149540968433 grad=&#45;0.006819661026130761</text>\n",
       "</g>\n",
       "<!-- 6402254720&#45;&gt;6402147296_op -->\n",
       "<g id=\"edge86\" class=\"edge\">\n",
       "<title>6402254720&#45;&gt;6402147296_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M481.52,-328.78C492.63,-328.78 502.65,-328.78 511.11,-328.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.83,-332.28 520.83,-328.78 510.83,-325.28 510.83,-332.28\"/>\n",
       "</g>\n",
       "<!-- 6402154016 -->\n",
       "<g id=\"node105\" class=\"node\">\n",
       "<title>6402154016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1255.38,-173.78 1255.38,-209.78 1631.62,-209.78 1631.62,-173.78 1255.38,-173.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1265.25\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1275.12,-174.28 1275.12,-209.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;2.8212166833715777 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402154016&#45;&gt;6402157088_op -->\n",
       "<g id=\"edge93\" class=\"edge\">\n",
       "<title>6402154016&#45;&gt;6402157088_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1631.96,-205.28C1651.18,-208.82 1670.24,-213.25 1688.25,-218.78 1698.01,-221.78 1708.07,-226.6 1716.77,-231.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1714.89,-234.34 1725.29,-236.35 1718.41,-228.29 1714.89,-234.34\"/>\n",
       "</g>\n",
       "<!-- 6402154016_op&#45;&gt;6402154016 -->\n",
       "<g id=\"edge90\" class=\"edge\">\n",
       "<title>6402154016_op&#45;&gt;6402154016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1160.4,-237.11C1170.69,-230.81 1185.02,-223 1198.75,-218.78 1213.24,-214.33 1228.42,-210.59 1243.81,-207.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1244.41,-210.91 1253.56,-205.57 1243.07,-204.04 1244.41,-210.91\"/>\n",
       "</g>\n",
       "<!-- 6402255296 -->\n",
       "<g id=\"node107\" class=\"node\">\n",
       "<title>6402255296</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"601.25,-228.78 601.25,-264.78 1084,-264.78 1084,-228.78 601.25,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"667.75\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 2 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"734.25,-229.28 734.25,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"909.12\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9403953316323201 grad=&#45;0.010229491539196141</text>\n",
       "</g>\n",
       "<!-- 6402255296&#45;&gt;6402154016_op -->\n",
       "<g id=\"edge91\" class=\"edge\">\n",
       "<title>6402255296&#45;&gt;6402154016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1084.45,-246.78C1096.13,-246.78 1106.63,-246.78 1115.43,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1115.18,-250.28 1125.18,-246.78 1115.18,-243.28 1115.18,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402147584 -->\n",
       "<g id=\"node108\" class=\"node\">\n",
       "<title>6402147584</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1797,-338.78 1797,-374.78 2168.75,-374.78 2168.75,-338.78 1797,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1806.88\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1816.75,-339.28 1816.75,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.5627240503927933 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402147584&#45;&gt;6402153824_op -->\n",
       "<g id=\"edge98\" class=\"edge\">\n",
       "<title>6402147584&#45;&gt;6402153824_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2152.32,-338.29C2158.27,-335.47 2164.02,-332.32 2169.5,-328.78 2189.41,-315.93 2203.37,-292.67 2211.96,-274.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2215.13,-275.67 2215.9,-265.1 2208.71,-272.89 2215.13,-275.67\"/>\n",
       "</g>\n",
       "<!-- 6402147584_op&#45;&gt;6402147584 -->\n",
       "<g id=\"edge95\" class=\"edge\">\n",
       "<title>6402147584_op&#45;&gt;6402147584</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-356.78C1767.17,-356.78 1775.63,-356.78 1785.27,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1785.13,-360.28 1795.13,-356.78 1785.13,-353.28 1785.13,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402255200 -->\n",
       "<g id=\"node110\" class=\"node\">\n",
       "<title>6402255200</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1201,-338.78 1201,-374.78 1686,-374.78 1686,-338.78 1201,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1267.5\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 2 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1334,-339.28 1334,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1510\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.5627274602233063 grad=0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402255200&#45;&gt;6402147584_op -->\n",
       "<g id=\"edge96\" class=\"edge\">\n",
       "<title>6402255200&#45;&gt;6402147584_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1686.48,-356.78C1696.33,-356.78 1705.26,-356.78 1712.91,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.66,-360.28 1722.66,-356.78 1712.66,-353.28 1712.66,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402254816 -->\n",
       "<g id=\"node111\" class=\"node\">\n",
       "<title>6402254816</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3765.07,-275.78 3765.07,-311.78 4253.82,-311.78 4253.82,-275.78 3765.07,-275.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3826.69\" y=\"-288.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 2 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3888.32,-276.28 3888.32,-311.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4071.07\" y=\"-288.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.010713986037237841 grad=&#45;0.0034098305130653805</text>\n",
       "</g>\n",
       "<!-- 6402254816&#45;&gt;6402147056_op -->\n",
       "<g id=\"edge100\" class=\"edge\">\n",
       "<title>6402254816&#45;&gt;6402147056_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4254.22,-293.78C4266.52,-293.78 4277.57,-293.78 4286.79,-293.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4286.66,-297.28 4296.66,-293.78 4286.66,-290.28 4286.66,-297.28\"/>\n",
       "</g>\n",
       "<!-- 6402152864 -->\n",
       "<g id=\"node112\" class=\"node\">\n",
       "<title>6402152864</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6196.9,-338.78 6196.9,-374.78 6561.9,-374.78 6561.9,-338.78 6196.9,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6206.78\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6216.65,-339.28 6216.65,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.9862111295082528 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402152864&#45;&gt;6402152672_op -->\n",
       "<g id=\"edge131\" class=\"edge\">\n",
       "<title>6402152864&#45;&gt;6402152672_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6534.67,-375.23C6545.12,-377.73 6555.41,-380.56 6565.28,-383.78 6574.98,-386.95 6585.03,-391.81 6593.74,-396.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6591.86,-399.54 6602.27,-401.51 6595.35,-393.48 6591.86,-399.54\"/>\n",
       "</g>\n",
       "<!-- 6402152864_op -->\n",
       "<g id=\"node113\" class=\"node\">\n",
       "<title>6402152864_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-356.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-351.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402152864_op&#45;&gt;6402152864 -->\n",
       "<g id=\"edge105\" class=\"edge\">\n",
       "<title>6402152864_op&#45;&gt;6402152864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6158.02,-356.78C6165.3,-356.78 6174.54,-356.78 6185.07,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6184.97,-360.28 6194.97,-356.78 6184.97,-353.28 6184.97,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402255728 -->\n",
       "<g id=\"node114\" class=\"node\">\n",
       "<title>6402255728</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5607.28,-338.78 5607.28,-374.78 6078.78,-374.78 6078.78,-338.78 5607.28,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5673.78\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 0 w3</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5740.28,-339.28 5740.28,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5909.53\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9870288415834612 grad=0.02636093958323322</text>\n",
       "</g>\n",
       "<!-- 6402255728&#45;&gt;6402152864_op -->\n",
       "<g id=\"edge106\" class=\"edge\">\n",
       "<title>6402255728&#45;&gt;6402152864_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6078.93,-356.78C6090.54,-356.78 6101.01,-356.78 6109.82,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6109.59,-360.28 6119.59,-356.78 6109.59,-353.28 6109.59,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402146816 -->\n",
       "<g id=\"node115\" class=\"node\">\n",
       "<title>6402146816</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5661.65,-118.78 5661.65,-154.78 6024.4,-154.78 6024.4,-118.78 5661.65,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5671.53\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5681.4,-119.28 5681.4,-154.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9991982278148795 grad=&#45;0.03002102294840025</text>\n",
       "</g>\n",
       "<!-- 6402146816&#45;&gt;6402152864_op -->\n",
       "<g id=\"edge130\" class=\"edge\">\n",
       "<title>6402146816&#45;&gt;6402152864_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6024.7,-131.76C6047.13,-138.05 6068.21,-148.18 6085.53,-163.78 6141.28,-214.04 6093.67,-259.09 6121.53,-328.78 6121.98,-329.92 6122.48,-331.06 6123.01,-332.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6119.84,-333.69 6127.67,-340.82 6125.99,-330.36 6119.84,-333.69\"/>\n",
       "</g>\n",
       "<!-- 6402153200_op -->\n",
       "<g id=\"node163\" class=\"node\">\n",
       "<title>6402153200_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-301.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-296.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402146816&#45;&gt;6402153200_op -->\n",
       "<g id=\"edge164\" class=\"edge\">\n",
       "<title>6402146816&#45;&gt;6402153200_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6024.76,-134.84C6046.72,-140.78 6067.66,-149.99 6085.53,-163.78 6103.3,-177.52 6121.55,-237 6131.31,-273.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6127.86,-273.86 6133.79,-282.64 6134.63,-272.07 6127.86,-273.86\"/>\n",
       "</g>\n",
       "<!-- 6402148448_op -->\n",
       "<g id=\"node192\" class=\"node\">\n",
       "<title>6402148448_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-136.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-131.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402146816&#45;&gt;6402148448_op -->\n",
       "<g id=\"edge198\" class=\"edge\">\n",
       "<title>6402146816&#45;&gt;6402148448_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6024.67,-136.78C6057.91,-136.78 6088.75,-136.78 6109.93,-136.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6109.72,-140.28 6119.72,-136.78 6109.72,-133.28 6109.72,-140.28\"/>\n",
       "</g>\n",
       "<!-- 6402148304_op -->\n",
       "<g id=\"node221\" class=\"node\">\n",
       "<title>6402148304_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-81.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-76.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402146816&#45;&gt;6402148304_op -->\n",
       "<g id=\"edge232\" class=\"edge\">\n",
       "<title>6402146816&#45;&gt;6402148304_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6024.83,-122.97C6045.52,-119.29 6066.13,-114.64 6085.53,-108.78 6095.23,-105.86 6105.27,-101.21 6113.98,-96.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6115.48,-99.76 6122.5,-91.82 6112.06,-93.65 6115.48,-99.76\"/>\n",
       "</g>\n",
       "<!-- 6402146816_op -->\n",
       "<g id=\"node116\" class=\"node\">\n",
       "<title>6402146816_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-128.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-123.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402146816_op&#45;&gt;6402146816 -->\n",
       "<g id=\"edge107\" class=\"edge\">\n",
       "<title>6402146816_op&#45;&gt;6402146816</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5564.86,-129.47C5585.54,-130.02 5616.5,-130.84 5650.32,-131.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5649.78,-135.21 5659.87,-131.98 5649.97,-128.22 5649.78,-135.21\"/>\n",
       "</g>\n",
       "<!-- 6402154688 -->\n",
       "<g id=\"node117\" class=\"node\">\n",
       "<title>6402154688</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5049.21,-110.78 5049.21,-146.78 5422.46,-146.78 5422.46,-110.78 5049.21,-110.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5059.08\" y=\"-123.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5068.96,-111.28 5068.96,-146.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-123.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;3.9107161314972676 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402154688&#45;&gt;6402146816_op -->\n",
       "<g id=\"edge129\" class=\"edge\">\n",
       "<title>6402154688&#45;&gt;6402146816_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5422.93,-128.78C5451.9,-128.78 5478.95,-128.78 5499.4,-128.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5499.14,-132.28 5509.14,-128.78 5499.14,-125.28 5499.14,-132.28\"/>\n",
       "</g>\n",
       "<!-- 6402154688_op -->\n",
       "<g id=\"node118\" class=\"node\">\n",
       "<title>6402154688_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-132.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-127.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402154688_op&#45;&gt;6402154688 -->\n",
       "<g id=\"edge108\" class=\"edge\">\n",
       "<title>6402154688_op&#45;&gt;6402154688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-132.55C4970.87,-132.31 5002.33,-131.89 5037.69,-131.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5037.31,-134.92 5047.26,-131.29 5037.22,-127.92 5037.31,-134.92\"/>\n",
       "</g>\n",
       "<!-- 6402161504 -->\n",
       "<g id=\"node119\" class=\"node\">\n",
       "<title>6402161504</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2782,-114.78 2782,-150.78 3148.5,-150.78 3148.5,-114.78 2782,-114.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2791.88\" y=\"-127.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"2801.75,-115.28 2801.75,-150.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2975.12\" y=\"-127.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;4.000599092703701 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402161504&#45;&gt;6402154688_op -->\n",
       "<g id=\"edge127\" class=\"edge\">\n",
       "<title>6402161504&#45;&gt;6402154688_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3148.62,-132.78C3297.36,-132.78 3512.9,-132.78 3701.28,-132.78 3701.28,-132.78 3701.28,-132.78 4317.6,-132.78 4543.87,-132.78 4816.95,-132.78 4904.48,-132.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.28,-136.28 4914.28,-132.78 4904.28,-129.28 4904.28,-136.28\"/>\n",
       "</g>\n",
       "<!-- 6402161504_op -->\n",
       "<g id=\"node120\" class=\"node\">\n",
       "<title>6402161504_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2223.5\" cy=\"-132.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"2223.5\" y=\"-127.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402161504_op&#45;&gt;6402161504 -->\n",
       "<g id=\"edge109\" class=\"edge\">\n",
       "<title>6402161504_op&#45;&gt;6402161504</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2241.7,-132.78C2311.75,-132.78 2580.83,-132.78 2770.04,-132.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2770.02,-136.28 2780.02,-132.78 2770.02,-129.28 2770.02,-136.28\"/>\n",
       "</g>\n",
       "<!-- 6402156704 -->\n",
       "<g id=\"node121\" class=\"node\">\n",
       "<title>6402156704</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1796.25,-114.78 1796.25,-150.78 2169.5,-150.78 2169.5,-114.78 1796.25,-114.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1806.12\" y=\"-127.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1816,-115.28 1816,-150.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-127.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;3.7008302171446545 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402156704&#45;&gt;6402161504_op -->\n",
       "<g id=\"edge122\" class=\"edge\">\n",
       "<title>6402156704&#45;&gt;6402161504_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2169.84,-132.78C2178.78,-132.78 2186.98,-132.78 2194.12,-132.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2193.89,-136.28 2203.89,-132.78 2193.89,-129.28 2193.89,-136.28\"/>\n",
       "</g>\n",
       "<!-- 6402156704_op -->\n",
       "<g id=\"node122\" class=\"node\">\n",
       "<title>6402156704_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1742.25\" cy=\"-132.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1742.25\" y=\"-127.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402156704_op&#45;&gt;6402156704 -->\n",
       "<g id=\"edge110\" class=\"edge\">\n",
       "<title>6402156704_op&#45;&gt;6402156704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-132.78C1767.02,-132.78 1775.26,-132.78 1784.64,-132.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1784.63,-136.28 1794.63,-132.78 1784.63,-129.28 1784.63,-136.28\"/>\n",
       "</g>\n",
       "<!-- 6402153680 -->\n",
       "<g id=\"node123\" class=\"node\">\n",
       "<title>6402153680</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1256.88,-63.78 1256.88,-99.78 1630.12,-99.78 1630.12,-63.78 1256.88,-63.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1266.75\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1276.62,-64.28 1276.62,-99.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.8938561212645455 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402153680&#45;&gt;6402156704_op -->\n",
       "<g id=\"edge117\" class=\"edge\">\n",
       "<title>6402153680&#45;&gt;6402156704_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1630.32,-96.19C1650.04,-99.55 1669.67,-103.69 1688.25,-108.78 1697.56,-111.34 1707.32,-115.34 1715.88,-119.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1714.09,-122.36 1724.61,-123.64 1717.18,-116.08 1714.09,-122.36\"/>\n",
       "</g>\n",
       "<!-- 6402153680_op -->\n",
       "<g id=\"node124\" class=\"node\">\n",
       "<title>6402153680_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1144.75\" cy=\"-81.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1144.75\" y=\"-76.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402153680_op&#45;&gt;6402153680 -->\n",
       "<g id=\"edge111\" class=\"edge\">\n",
       "<title>6402153680_op&#45;&gt;6402153680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1162.99,-81.78C1180.96,-81.78 1211.23,-81.78 1245.39,-81.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1245.09,-85.28 1255.09,-81.78 1245.09,-78.28 1245.09,-85.28\"/>\n",
       "</g>\n",
       "<!-- 6402154544 -->\n",
       "<g id=\"node125\" class=\"node\">\n",
       "<title>6402154544</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"708.88,-118.78 708.88,-154.78 976.38,-154.78 976.38,-118.78 708.88,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"718.75\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"728.62,-119.28 728.62,-154.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402154544&#45;&gt;6402153680_op -->\n",
       "<g id=\"edge112\" class=\"edge\">\n",
       "<title>6402154544&#45;&gt;6402153680_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M976.85,-130.5C1014.25,-126.37 1054.57,-119.66 1090.75,-108.78 1100.45,-105.87 1110.5,-101.22 1119.21,-96.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1120.71,-99.77 1127.73,-91.83 1117.29,-93.66 1120.71,-99.77\"/>\n",
       "</g>\n",
       "<!-- 6402159152 -->\n",
       "<g id=\"node126\" class=\"node\">\n",
       "<title>6402159152</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"656,-63.78 656,-99.78 1029.25,-99.78 1029.25,-63.78 656,-63.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"665.88\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"675.75,-64.28 675.75,-99.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"852.5\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.8938561212645455 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402159152&#45;&gt;6402153680_op -->\n",
       "<g id=\"edge116\" class=\"edge\">\n",
       "<title>6402159152&#45;&gt;6402153680_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1029.43,-81.78C1062.91,-81.78 1093.87,-81.78 1115.11,-81.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1114.91,-85.28 1124.91,-81.78 1114.91,-78.28 1114.91,-85.28\"/>\n",
       "</g>\n",
       "<!-- 6402159152_op&#45;&gt;6402159152 -->\n",
       "<g id=\"edge113\" class=\"edge\">\n",
       "<title>6402159152_op&#45;&gt;6402159152</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M551.31,-148.83C560.71,-135.86 576.17,-117.78 594.5,-108.78 610.3,-101.03 627.34,-95.06 644.82,-90.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"645.39,-93.96 654.28,-88.2 643.74,-87.16 645.39,-93.96\"/>\n",
       "</g>\n",
       "<!-- 6402255344 -->\n",
       "<g id=\"node128\" class=\"node\">\n",
       "<title>6402255344</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-145.78 0,-181.78 486.5,-181.78 486.5,-145.78 0,-145.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"66.5\" y=\"-158.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 3 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"133,-146.28 133,-181.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"309.75\" y=\"-158.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9469279643907854 grad=&#45;9.624148732860756e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402255344&#45;&gt;6402159152_op -->\n",
       "<g id=\"edge114\" class=\"edge\">\n",
       "<title>6402255344&#45;&gt;6402159152_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M486.72,-163.78C495.59,-163.78 503.67,-163.78 510.7,-163.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"510.63,-167.28 520.63,-163.78 510.63,-160.28 510.63,-167.28\"/>\n",
       "</g>\n",
       "<!-- 6402160016 -->\n",
       "<g id=\"node129\" class=\"node\">\n",
       "<title>6402160016</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1260.25,-118.78 1260.25,-154.78 1626.75,-154.78 1626.75,-118.78 1260.25,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1270.12\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1280,-119.28 1280,-154.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1453.38\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.806974095880109 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402160016&#45;&gt;6402156704_op -->\n",
       "<g id=\"edge121\" class=\"edge\">\n",
       "<title>6402160016&#45;&gt;6402156704_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1626.94,-134.33C1660.34,-133.88 1691.31,-133.46 1712.56,-133.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.43,-136.67 1722.38,-133.04 1712.34,-129.67 1712.43,-136.67\"/>\n",
       "</g>\n",
       "<!-- 6402160016_op&#45;&gt;6402160016 -->\n",
       "<g id=\"edge118\" class=\"edge\">\n",
       "<title>6402160016_op&#45;&gt;6402160016</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1160.4,-182.11C1170.69,-175.81 1185.02,-168 1198.75,-163.78 1214.77,-158.86 1231.64,-154.81 1248.7,-151.49\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1249.25,-154.94 1258.44,-149.68 1247.97,-148.06 1249.25,-154.94\"/>\n",
       "</g>\n",
       "<!-- 6402255488 -->\n",
       "<g id=\"node131\" class=\"node\">\n",
       "<title>6402255488</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"594.5,-173.78 594.5,-209.78 1090.75,-209.78 1090.75,-173.78 594.5,-173.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"661\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 3 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"727.5,-174.28 727.5,-209.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"909.12\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.6023245542644721 grad=&#45;0.00014436223099291136</text>\n",
       "</g>\n",
       "<!-- 6402255488&#45;&gt;6402160016_op -->\n",
       "<g id=\"edge119\" class=\"edge\">\n",
       "<title>6402255488&#45;&gt;6402160016_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1091.13,-191.78C1099.99,-191.78 1108.05,-191.78 1115.06,-191.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1114.96,-195.28 1124.96,-191.78 1114.96,-188.28 1114.96,-195.28\"/>\n",
       "</g>\n",
       "<!-- 6402154448 -->\n",
       "<g id=\"node132\" class=\"node\">\n",
       "<title>6402154448</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1796.25,-283.78 1796.25,-319.78 2169.5,-319.78 2169.5,-283.78 1796.25,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1806.12\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1816,-284.28 1816,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1992.75\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.2997688755590464 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402154448&#45;&gt;6402161504_op -->\n",
       "<g id=\"edge126\" class=\"edge\">\n",
       "<title>6402154448&#45;&gt;6402161504_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2155.47,-283.5C2160.37,-280.6 2165.07,-277.37 2169.5,-273.78 2187.38,-259.31 2205.72,-198.12 2215.44,-161.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2218.8,-162.28 2217.9,-151.72 2212.02,-160.53 2218.8,-162.28\"/>\n",
       "</g>\n",
       "<!-- 6402154448_op&#45;&gt;6402154448 -->\n",
       "<g id=\"edge123\" class=\"edge\">\n",
       "<title>6402154448_op&#45;&gt;6402154448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1760.41,-301.78C1767.02,-301.78 1775.26,-301.78 1784.64,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1784.63,-305.28 1794.63,-301.78 1784.63,-298.28 1784.63,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402255632 -->\n",
       "<g id=\"node134\" class=\"node\">\n",
       "<title>6402255632</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1201.38,-283.78 1201.38,-319.78 1685.62,-319.78 1685.62,-283.78 1201.38,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1267.88\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 3 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1334.38,-284.28 1334.38,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1510\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.29976882743830274 grad=4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402255632&#45;&gt;6402154448_op -->\n",
       "<g id=\"edge124\" class=\"edge\">\n",
       "<title>6402255632&#45;&gt;6402154448_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1685.78,-301.78C1695.75,-301.78 1704.79,-301.78 1712.53,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1712.42,-305.28 1722.42,-301.78 1712.42,-298.28 1712.42,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402255440 -->\n",
       "<g id=\"node135\" class=\"node\">\n",
       "<title>6402255440</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4385.76,-161.78 4385.76,-197.78 4864.76,-197.78 4864.76,-161.78 4385.76,-161.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4447.39\" y=\"-174.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 0 Neuron 3 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4509.01,-162.28 4509.01,-197.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4686.89\" y=\"-174.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.08988300932717702 grad=&#45;4.812074366430378e&#45;05</text>\n",
       "</g>\n",
       "<!-- 6402255440&#45;&gt;6402154688_op -->\n",
       "<g id=\"edge128\" class=\"edge\">\n",
       "<title>6402255440&#45;&gt;6402154688_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4779.1,-161.32C4809.66,-157.03 4841.48,-152.13 4871.14,-146.78 4882.23,-144.79 4894.34,-142.14 4904.87,-139.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4905.57,-143.13 4914.49,-137.41 4903.95,-136.32 4905.57,-143.13\"/>\n",
       "</g>\n",
       "<!-- 6402255824 -->\n",
       "<g id=\"node136\" class=\"node\">\n",
       "<title>6402255824</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6676.65,-338.78 6676.65,-374.78 7145.15,-374.78 7145.15,-338.78 6676.65,-338.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6738.28\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 0 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6799.9,-339.28 6799.9,-374.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6972.53\" y=\"-351.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6116648857576266 grad=&#45;0.026382092010792762</text>\n",
       "</g>\n",
       "<!-- 6402255824&#45;&gt;6402157040_op -->\n",
       "<g id=\"edge133\" class=\"edge\">\n",
       "<title>6402255824&#45;&gt;6402157040_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7145.34,-356.78C7155.7,-356.78 7165.07,-356.78 7173.07,-356.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7172.92,-360.28 7182.92,-356.78 7172.92,-353.28 7172.92,-360.28\"/>\n",
       "</g>\n",
       "<!-- 6402158144 -->\n",
       "<g id=\"node137\" class=\"node\">\n",
       "<title>6402158144</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"9112.85,-228.78 9112.85,-264.78 9475.6,-264.78 9475.6,-228.78 9112.85,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9122.72\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"9132.6,-229.28 9132.6,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9304.1\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.18709710323951578 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402158144&#45;&gt;6402152528_op -->\n",
       "<g id=\"edge170\" class=\"edge\">\n",
       "<title>6402158144&#45;&gt;6402152528_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M9476.02,-246.78C9547.33,-246.78 9621.53,-246.78 9660.99,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"9660.79,-250.28 9670.79,-246.78 9660.79,-243.28 9660.79,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402158144_op -->\n",
       "<g id=\"node138\" class=\"node\">\n",
       "<title>6402158144_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8279.35\" cy=\"-246.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8279.35\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402158144_op&#45;&gt;6402158144 -->\n",
       "<g id=\"edge138\" class=\"edge\">\n",
       "<title>6402158144_op&#45;&gt;6402158144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8297.5,-246.78C8390.43,-246.78 8839.02,-246.78 9101.3,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"9100.97,-250.28 9110.97,-246.78 9100.97,-243.28 9100.97,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402257408 -->\n",
       "<g id=\"node139\" class=\"node\">\n",
       "<title>6402257408</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7758.35,-283.78 7758.35,-319.78 8218.6,-319.78 8218.6,-283.78 7758.35,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7824.85\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2 Neuron 0 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7891.35,-284.28 7891.35,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8054.97\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.2368281965653681 grad=0.2113081631240002</text>\n",
       "</g>\n",
       "<!-- 6402257408&#45;&gt;6402158144_op -->\n",
       "<g id=\"edge139\" class=\"edge\">\n",
       "<title>6402257408&#45;&gt;6402158144_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8188.4,-283.32C8201,-280.56 8213.41,-277.41 8225.35,-273.78 8235.04,-270.84 8245.09,-266.19 8253.8,-261.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8255.3,-264.74 8262.32,-256.81 8251.88,-258.63 8255.3,-264.74\"/>\n",
       "</g>\n",
       "<!-- 6402152480 -->\n",
       "<g id=\"node140\" class=\"node\">\n",
       "<title>6402152480</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7807.1,-228.78 7807.1,-264.78 8169.85,-264.78 8169.85,-228.78 7807.1,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7816.97\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7826.85,-229.28 7826.85,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7998.35\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.7893076871461533 grad=&#45;0.06345862728526264</text>\n",
       "</g>\n",
       "<!-- 6402152480&#45;&gt;6402158144_op -->\n",
       "<g id=\"edge169\" class=\"edge\">\n",
       "<title>6402152480&#45;&gt;6402158144_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8169.96,-246.78C8200.94,-246.78 8229.55,-246.78 8249.59,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8249.39,-250.28 8259.39,-246.78 8249.39,-243.28 8249.39,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402152480_op -->\n",
       "<g id=\"node141\" class=\"node\">\n",
       "<title>6402152480_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7688.81\" cy=\"-246.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7688.81\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402152480_op&#45;&gt;6402152480 -->\n",
       "<g id=\"edge140\" class=\"edge\">\n",
       "<title>6402152480_op&#45;&gt;6402152480</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7715.97,-246.78C7735.51,-246.78 7764.19,-246.78 7795.68,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7795.41,-250.28 7805.41,-246.78 7795.41,-243.28 7795.41,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402150944 -->\n",
       "<g id=\"node142\" class=\"node\">\n",
       "<title>6402150944</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7263.28,-228.78 7263.28,-264.78 7619.28,-264.78 7619.28,-228.78 7263.28,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7273.15\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7283.03,-229.28 7283.03,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7451.15\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.069592610382089 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402150944&#45;&gt;6402152480_op -->\n",
       "<g id=\"edge168\" class=\"edge\">\n",
       "<title>6402150944&#45;&gt;6402152480_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7619.74,-246.78C7630.84,-246.78 7641.2,-246.78 7650.31,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7650.02,-250.28 7660.02,-246.78 7650.02,-243.28 7650.02,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402150944_op -->\n",
       "<g id=\"node143\" class=\"node\">\n",
       "<title>6402150944_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7202.53\" cy=\"-246.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7202.53\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402150944_op&#45;&gt;6402150944 -->\n",
       "<g id=\"edge141\" class=\"edge\">\n",
       "<title>6402150944_op&#45;&gt;6402150944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7220.94,-246.78C7229.03,-246.78 7239.53,-246.78 7251.56,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7251.49,-250.28 7261.49,-246.78 7251.49,-243.28 7251.49,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402153584 -->\n",
       "<g id=\"node144\" class=\"node\">\n",
       "<title>6402153584</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6729.53,-283.78 6729.53,-319.78 7092.28,-319.78 7092.28,-283.78 6729.53,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6739.4\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6749.28,-284.28 6749.28,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6920.78\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.7427817006073426 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402153584&#45;&gt;6402150944_op -->\n",
       "<g id=\"edge166\" class=\"edge\">\n",
       "<title>6402153584&#45;&gt;6402150944_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7092.54,-287.15C7111.64,-283.6 7130.61,-279.22 7148.53,-273.78 7158.22,-270.84 7168.27,-266.19 7176.98,-261.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7178.48,-264.74 7185.5,-256.81 7175.06,-258.63 7178.48,-264.74\"/>\n",
       "</g>\n",
       "<!-- 6402153584_op -->\n",
       "<g id=\"node145\" class=\"node\">\n",
       "<title>6402153584_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6619.28\" cy=\"-301.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6619.28\" y=\"-296.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402153584_op&#45;&gt;6402153584 -->\n",
       "<g id=\"edge142\" class=\"edge\">\n",
       "<title>6402153584_op&#45;&gt;6402153584</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6637.53,-301.78C6655.14,-301.78 6684.54,-301.78 6717.67,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6717.52,-305.28 6727.52,-301.78 6717.52,-298.28 6717.52,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402153008 -->\n",
       "<g id=\"node146\" class=\"node\">\n",
       "<title>6402153008</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6203.65,-448.78 6203.65,-484.78 6555.15,-484.78 6555.15,-448.78 6203.65,-448.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6213.53\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6223.4,-449.28 6223.4,-484.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.170911282358282 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402153008&#45;&gt;6402153584_op -->\n",
       "<g id=\"edge161\" class=\"edge\">\n",
       "<title>6402153008&#45;&gt;6402153584_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6552.93,-448.38C6557.22,-445.78 6561.35,-442.92 6565.28,-439.78 6582.82,-425.75 6601.15,-366.38 6610.99,-330.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6614.3,-331.44 6613.49,-320.87 6607.53,-329.64 6614.3,-331.44\"/>\n",
       "</g>\n",
       "<!-- 6402153008_op -->\n",
       "<g id=\"node147\" class=\"node\">\n",
       "<title>6402153008_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-466.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-461.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402153008_op&#45;&gt;6402153008 -->\n",
       "<g id=\"edge143\" class=\"edge\">\n",
       "<title>6402153008_op&#45;&gt;6402153008</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6158.02,-466.78C6166.91,-466.78 6178.69,-466.78 6192.2,-466.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6191.87,-470.28 6201.87,-466.78 6191.87,-463.28 6191.87,-470.28\"/>\n",
       "</g>\n",
       "<!-- 6402153488 -->\n",
       "<g id=\"node148\" class=\"node\">\n",
       "<title>6402153488</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5661.65,-637.78 5661.65,-673.78 6024.4,-673.78 6024.4,-637.78 5661.65,-637.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5671.53\" y=\"-650.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5681.4,-638.28 5681.4,-673.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-650.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.5099447337443206 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402153488&#45;&gt;6402153008_op -->\n",
       "<g id=\"edge156\" class=\"edge\">\n",
       "<title>6402153488&#45;&gt;6402153008_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6024.63,-648.81C6046.8,-641.81 6067.84,-631.55 6085.53,-616.78 6104.41,-601.02 6122.67,-534.61 6132.03,-495.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6135.42,-496.52 6134.3,-485.98 6128.61,-494.92 6135.42,-496.52\"/>\n",
       "</g>\n",
       "<!-- 6402153488_op -->\n",
       "<g id=\"node149\" class=\"node\">\n",
       "<title>6402153488_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-678.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-673.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402153488_op&#45;&gt;6402153488 -->\n",
       "<g id=\"edge144\" class=\"edge\">\n",
       "<title>6402153488_op&#45;&gt;6402153488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-677.48C5575.86,-675.97 5611.05,-673.3 5650.09,-670.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5650.25,-673.84 5659.96,-669.59 5649.72,-666.86 5650.25,-673.84\"/>\n",
       "</g>\n",
       "<!-- 6402152144 -->\n",
       "<g id=\"node150\" class=\"node\">\n",
       "<title>6402152144</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5054.46,-770.78 5054.46,-806.78 5417.21,-806.78 5417.21,-770.78 5054.46,-770.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5064.33\" y=\"-783.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5074.21,-771.28 5074.21,-806.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-783.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.3897562070854716 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402152144&#45;&gt;6402153488_op -->\n",
       "<g id=\"edge151\" class=\"edge\">\n",
       "<title>6402152144&#45;&gt;6402153488_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5417.46,-785.51C5437.77,-780.22 5457.42,-772.59 5474.96,-761.78 5499.83,-746.46 5493,-729.83 5510.96,-706.78 5512.9,-704.29 5515.02,-701.75 5517.17,-699.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5519.33,-702.1 5523.46,-692.34 5514.15,-697.4 5519.33,-702.1\"/>\n",
       "</g>\n",
       "<!-- 6402152144_op -->\n",
       "<g id=\"node151\" class=\"node\">\n",
       "<title>6402152144_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-788.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-783.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402152144_op&#45;&gt;6402152144 -->\n",
       "<g id=\"edge145\" class=\"edge\">\n",
       "<title>6402152144_op&#45;&gt;6402152144</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-788.78C4971.8,-788.78 5005.53,-788.78 5043.06,-788.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5042.76,-792.28 5052.76,-788.78 5042.76,-785.28 5042.76,-792.28\"/>\n",
       "</g>\n",
       "<!-- 6402159680 -->\n",
       "<g id=\"node152\" class=\"node\">\n",
       "<title>6402159680</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4496.76,-770.78 4496.76,-806.78 4753.76,-806.78 4753.76,-770.78 4496.76,-770.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4506.64\" y=\"-783.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4516.51,-771.28 4516.51,-806.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-783.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402159680&#45;&gt;6402152144_op -->\n",
       "<g id=\"edge146\" class=\"edge\">\n",
       "<title>6402159680&#45;&gt;6402152144_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4754.09,-788.78C4809.71,-788.78 4869.94,-788.78 4904.38,-788.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.33,-792.28 4914.33,-788.78 4904.33,-785.28 4904.33,-792.28\"/>\n",
       "</g>\n",
       "<!-- 6402146624 -->\n",
       "<g id=\"node153\" class=\"node\">\n",
       "<title>6402146624</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4443.89,-825.78 4443.89,-861.78 4806.64,-861.78 4806.64,-825.78 4443.89,-825.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4453.76\" y=\"-838.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4463.64,-826.28 4463.64,-861.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-838.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.3897562070854716 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402146624&#45;&gt;6402152144_op -->\n",
       "<g id=\"edge150\" class=\"edge\">\n",
       "<title>6402146624&#45;&gt;6402152144_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4807.03,-830.41C4828.82,-826.87 4850.62,-822.41 4871.14,-816.78 4883.57,-813.37 4896.68,-807.76 4907.6,-802.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4909,-805.66 4916.34,-798.02 4905.84,-799.42 4909,-805.66\"/>\n",
       "</g>\n",
       "<!-- 6402146624_op&#45;&gt;6402146624 -->\n",
       "<g id=\"edge147\" class=\"edge\">\n",
       "<title>6402146624_op&#45;&gt;6402146624</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4334.97,-819.26C4355.47,-821 4391.9,-824.08 4432.15,-827.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4431.82,-830.98 4442.08,-828.34 4432.41,-824.01 4431.82,-830.98\"/>\n",
       "</g>\n",
       "<!-- 6402258224 -->\n",
       "<g id=\"node155\" class=\"node\">\n",
       "<title>6402258224</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3772.57,-799.78 3772.57,-835.78 4246.32,-835.78 4246.32,-799.78 3772.57,-799.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3839.07\" y=\"-812.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 1 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3905.57,-800.28 3905.57,-835.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4075.94\" y=\"-812.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.39625526026487373 grad=0.02352971157995671</text>\n",
       "</g>\n",
       "<!-- 6402258224&#45;&gt;6402146624_op -->\n",
       "<g id=\"edge148\" class=\"edge\">\n",
       "<title>6402258224&#45;&gt;6402146624_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4246.74,-817.78C4262.06,-817.78 4275.75,-817.78 4286.81,-817.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4286.61,-821.28 4296.61,-817.78 4286.61,-814.28 4286.61,-821.28\"/>\n",
       "</g>\n",
       "<!-- 6402157856 -->\n",
       "<g id=\"node156\" class=\"node\">\n",
       "<title>6402157856</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5051.08,-660.78 5051.08,-696.78 5420.58,-696.78 5420.58,-660.78 5051.08,-660.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5060.96\" y=\"-673.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5070.83,-661.28 5070.83,-696.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-673.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.12018852665884895 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402157856&#45;&gt;6402153488_op -->\n",
       "<g id=\"edge155\" class=\"edge\">\n",
       "<title>6402157856&#45;&gt;6402153488_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5420.79,-678.78C5454.85,-678.78 5486.43,-678.78 5508.01,-678.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5507.99,-682.28 5517.99,-678.78 5507.99,-675.28 5507.99,-682.28\"/>\n",
       "</g>\n",
       "<!-- 6402157856_op&#45;&gt;6402157856 -->\n",
       "<g id=\"edge152\" class=\"edge\">\n",
       "<title>6402157856_op&#45;&gt;6402157856</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-678.78C4971.15,-678.78 5003.29,-678.78 5039.31,-678.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5039.09,-682.28 5049.09,-678.78 5039.09,-675.28 5039.09,-682.28\"/>\n",
       "</g>\n",
       "<!-- 6402255776 -->\n",
       "<g id=\"node158\" class=\"node\">\n",
       "<title>6402255776</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4380.51,-660.78 4380.51,-696.78 4870.01,-696.78 4870.01,-660.78 4380.51,-660.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4447.01\" y=\"-673.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 1 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4513.51,-661.28 4513.51,-696.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4691.76\" y=\"-673.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.31948996747306224 grad=&#45;0.008999490954019754</text>\n",
       "</g>\n",
       "<!-- 6402255776&#45;&gt;6402157856_op -->\n",
       "<g id=\"edge153\" class=\"edge\">\n",
       "<title>6402255776&#45;&gt;6402157856_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4870.5,-678.78C4883.23,-678.78 4894.66,-678.78 4904.14,-678.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4903.93,-682.28 4913.93,-678.78 4903.93,-675.28 4903.93,-682.28\"/>\n",
       "</g>\n",
       "<!-- 6402147488 -->\n",
       "<g id=\"node159\" class=\"node\">\n",
       "<title>6402147488</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5663.9,-448.78 5663.9,-484.78 6022.15,-484.78 6022.15,-448.78 5663.9,-448.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5673.78\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5683.65,-449.28 5683.65,-484.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-461.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6808560161026026 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402147488&#45;&gt;6402153008_op -->\n",
       "<g id=\"edge160\" class=\"edge\">\n",
       "<title>6402147488&#45;&gt;6402153008_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6022.56,-466.78C6056.64,-466.78 6088.38,-466.78 6110.01,-466.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6109.71,-470.28 6119.71,-466.78 6109.71,-463.28 6109.71,-470.28\"/>\n",
       "</g>\n",
       "<!-- 6402147488_op&#45;&gt;6402147488 -->\n",
       "<g id=\"edge157\" class=\"edge\">\n",
       "<title>6402147488_op&#45;&gt;6402147488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-459.24C5576.25,-459.77 5612.42,-460.73 5652.36,-461.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5652.11,-465.28 5662.2,-462.04 5652.3,-458.28 5652.11,-465.28\"/>\n",
       "</g>\n",
       "<!-- 6402249392 -->\n",
       "<g id=\"node161\" class=\"node\">\n",
       "<title>6402249392</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4996.71,-440.78 4996.71,-476.78 5474.96,-476.78 5474.96,-440.78 4996.71,-440.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5063.21\" y=\"-453.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 1 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5129.71,-441.28 5129.71,-476.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5302.33\" y=\"-453.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.6890646396761118 grad=0.023639299674820924</text>\n",
       "</g>\n",
       "<!-- 6402249392&#45;&gt;6402147488_op -->\n",
       "<g id=\"edge158\" class=\"edge\">\n",
       "<title>6402249392&#45;&gt;6402147488_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5475.33,-458.78C5487.61,-458.78 5498.66,-458.78 5507.89,-458.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5507.77,-462.28 5517.77,-458.78 5507.77,-455.28 5507.77,-462.28\"/>\n",
       "</g>\n",
       "<!-- 6402153200 -->\n",
       "<g id=\"node162\" class=\"node\">\n",
       "<title>6402153200</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6198.03,-283.78 6198.03,-319.78 6560.78,-319.78 6560.78,-283.78 6198.03,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6207.9\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6217.78,-284.28 6217.78,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9136929829656246 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402153200&#45;&gt;6402153584_op -->\n",
       "<g id=\"edge165\" class=\"edge\">\n",
       "<title>6402153200&#45;&gt;6402153584_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6561,-301.78C6571.62,-301.78 6581.33,-301.78 6589.63,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6589.54,-305.28 6599.54,-301.78 6589.54,-298.28 6589.54,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402153200_op&#45;&gt;6402153200 -->\n",
       "<g id=\"edge162\" class=\"edge\">\n",
       "<title>6402153200_op&#45;&gt;6402153200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6158.02,-301.78C6165.58,-301.78 6175.24,-301.78 6186.28,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6186.23,-305.28 6196.23,-301.78 6186.23,-298.28 6186.23,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402252032 -->\n",
       "<g id=\"node164\" class=\"node\">\n",
       "<title>6402252032</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5612.9,-283.78 5612.9,-319.78 6073.15,-319.78 6073.15,-283.78 5612.9,-283.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5679.4\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 1 w3</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5745.9,-284.28 5745.9,-319.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5909.53\" y=\"-296.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.914402240112671 grad=0.02390430089140105</text>\n",
       "</g>\n",
       "<!-- 6402252032&#45;&gt;6402153200_op -->\n",
       "<g id=\"edge163\" class=\"edge\">\n",
       "<title>6402252032&#45;&gt;6402153200_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6073.53,-301.78C6087.4,-301.78 6099.83,-301.78 6110.02,-301.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6109.77,-305.28 6119.77,-301.78 6109.77,-298.28 6109.77,-305.28\"/>\n",
       "</g>\n",
       "<!-- 6402246320 -->\n",
       "<g id=\"node165\" class=\"node\">\n",
       "<title>6402246320</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6674.4,-228.78 6674.4,-264.78 7147.4,-264.78 7147.4,-228.78 6674.4,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6736.03\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 1 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6797.65,-229.28 6797.65,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6972.53\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.32678698629267255 grad=&#45;0.02392348207389913</text>\n",
       "</g>\n",
       "<!-- 6402246320&#45;&gt;6402150944_op -->\n",
       "<g id=\"edge167\" class=\"edge\">\n",
       "<title>6402246320&#45;&gt;6402150944_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7147.73,-246.78C7157.01,-246.78 7165.46,-246.78 7172.77,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7172.76,-250.28 7182.76,-246.78 7172.76,-243.28 7172.76,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402154352 -->\n",
       "<g id=\"node166\" class=\"node\">\n",
       "<title>6402154352</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"9511.6,-169.78 9511.6,-205.78 9869.85,-205.78 9869.85,-169.78 9511.6,-169.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9521.47\" y=\"-182.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"9531.35,-170.28 9531.35,-205.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"9700.6\" y=\"-182.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.15520190344448734 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402154352&#45;&gt;6402148592_op -->\n",
       "<g id=\"edge204\" class=\"edge\">\n",
       "<title>6402154352&#45;&gt;6402148592_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M9870.09,-187.78C10017.87,-187.78 10215.06,-187.78 10288.2,-187.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"10288.11,-191.28 10298.11,-187.78 10288.11,-184.28 10288.11,-191.28\"/>\n",
       "</g>\n",
       "<!-- 6402154352_op -->\n",
       "<g id=\"node167\" class=\"node\">\n",
       "<title>6402154352_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8279.35\" cy=\"-187.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8279.35\" y=\"-182.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402154352_op&#45;&gt;6402154352 -->\n",
       "<g id=\"edge172\" class=\"edge\">\n",
       "<title>6402154352_op&#45;&gt;6402154352</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8297.66,-187.78C8419.04,-187.78 9147.93,-187.78 9499.84,-187.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"9499.66,-191.28 9509.66,-187.78 9499.66,-184.28 9499.66,-191.28\"/>\n",
       "</g>\n",
       "<!-- 6402257648 -->\n",
       "<g id=\"node168\" class=\"node\">\n",
       "<title>6402257648</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7752.72,-173.78 7752.72,-209.78 8224.22,-209.78 8224.22,-173.78 7752.72,-173.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7819.22\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2 Neuron 0 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7885.72,-174.28 7885.72,-209.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8054.97\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.7234712360937652 grad=&#45;0.05743547221069753</text>\n",
       "</g>\n",
       "<!-- 6402257648&#45;&gt;6402154352_op -->\n",
       "<g id=\"edge173\" class=\"edge\">\n",
       "<title>6402257648&#45;&gt;6402154352_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8224.69,-188.53C8233.95,-188.4 8242.37,-188.28 8249.66,-188.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8249.67,-191.68 8259.62,-188.04 8249.58,-184.68 8249.67,-191.68\"/>\n",
       "</g>\n",
       "<!-- 6402146864 -->\n",
       "<g id=\"node169\" class=\"node\">\n",
       "<title>6402146864</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7809.35,-118.78 7809.35,-154.78 8167.6,-154.78 8167.6,-118.78 7809.35,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7819.22\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7829.1,-119.28 7829.1,-154.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7998.35\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.2145409768394499 grad=&#45;0.19366749352282342</text>\n",
       "</g>\n",
       "<!-- 6402146864&#45;&gt;6402154352_op -->\n",
       "<g id=\"edge203\" class=\"edge\">\n",
       "<title>6402146864&#45;&gt;6402154352_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8168.03,-151.23C8187.54,-154.58 8206.97,-158.71 8225.35,-163.78 8234.66,-166.36 8244.41,-170.36 8252.97,-174.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8251.18,-177.38 8261.7,-178.65 8254.27,-171.1 8251.18,-177.38\"/>\n",
       "</g>\n",
       "<!-- 6402146864_op -->\n",
       "<g id=\"node170\" class=\"node\">\n",
       "<title>6402146864_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7688.81\" cy=\"-136.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7688.81\" y=\"-131.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402146864_op&#45;&gt;6402146864 -->\n",
       "<g id=\"edge174\" class=\"edge\">\n",
       "<title>6402146864_op&#45;&gt;6402146864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7715.97,-136.78C7735.89,-136.78 7765.31,-136.78 7797.52,-136.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7797.51,-140.28 7807.51,-136.78 7797.51,-133.28 7797.51,-140.28\"/>\n",
       "</g>\n",
       "<!-- 6402152336 -->\n",
       "<g id=\"node171\" class=\"node\">\n",
       "<title>6402152336</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7265.53,-118.78 7265.53,-154.78 7617.03,-154.78 7617.03,-118.78 7265.53,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7275.4\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7285.28,-119.28 7285.28,-154.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7451.15\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.2179265988924476 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402152336&#45;&gt;6402146864_op -->\n",
       "<g id=\"edge202\" class=\"edge\">\n",
       "<title>6402152336&#45;&gt;6402146864_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7617.45,-136.78C7629.33,-136.78 7640.4,-136.78 7650.09,-136.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7650.05,-140.28 7660.05,-136.78 7650.05,-133.28 7650.05,-140.28\"/>\n",
       "</g>\n",
       "<!-- 6402152336_op -->\n",
       "<g id=\"node172\" class=\"node\">\n",
       "<title>6402152336_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7202.53\" cy=\"-136.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7202.53\" y=\"-131.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402152336_op&#45;&gt;6402152336 -->\n",
       "<g id=\"edge175\" class=\"edge\">\n",
       "<title>6402152336_op&#45;&gt;6402152336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7220.94,-136.78C7229.53,-136.78 7240.84,-136.78 7253.8,-136.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7253.54,-140.28 7263.54,-136.78 7253.54,-133.28 7253.54,-140.28\"/>\n",
       "</g>\n",
       "<!-- 6402148496 -->\n",
       "<g id=\"node173\" class=\"node\">\n",
       "<title>6402148496</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6732.9,-173.78 6732.9,-209.78 7088.9,-209.78 7088.9,-173.78 6732.9,-173.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6742.78\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6752.65,-174.28 6752.65,-209.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6920.78\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.3963299476563128 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402148496&#45;&gt;6402152336_op -->\n",
       "<g id=\"edge200\" class=\"edge\">\n",
       "<title>6402148496&#45;&gt;6402152336_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7089.37,-177.73C7109.54,-174.09 7129.62,-169.52 7148.53,-163.78 7158.22,-160.84 7168.27,-156.19 7176.98,-151.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7178.48,-154.74 7185.5,-146.81 7175.06,-148.63 7178.48,-154.74\"/>\n",
       "</g>\n",
       "<!-- 6402148496_op -->\n",
       "<g id=\"node174\" class=\"node\">\n",
       "<title>6402148496_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6619.28\" cy=\"-191.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6619.28\" y=\"-186.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402148496_op&#45;&gt;6402148496 -->\n",
       "<g id=\"edge176\" class=\"edge\">\n",
       "<title>6402148496_op&#45;&gt;6402148496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6637.53,-191.78C6655.77,-191.78 6686.65,-191.78 6721.21,-191.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6721.04,-195.28 6731.04,-191.78 6721.04,-188.28 6721.04,-195.28\"/>\n",
       "</g>\n",
       "<!-- 6402159968 -->\n",
       "<g id=\"node175\" class=\"node\">\n",
       "<title>6402159968</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6201.4,-393.78 6201.4,-429.78 6557.4,-429.78 6557.4,-393.78 6201.4,-393.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6211.28\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6221.15,-394.28 6221.15,-429.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.1890442142161765 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402159968&#45;&gt;6402148496_op -->\n",
       "<g id=\"edge195\" class=\"edge\">\n",
       "<title>6402159968&#45;&gt;6402148496_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6552.55,-393.45C6557.01,-390.55 6561.27,-387.34 6565.28,-383.78 6577.61,-372.84 6600.98,-271.65 6612.1,-220.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6615.51,-221.54 6614.21,-211.02 6608.67,-220.06 6615.51,-221.54\"/>\n",
       "</g>\n",
       "<!-- 6402159968_op -->\n",
       "<g id=\"node176\" class=\"node\">\n",
       "<title>6402159968_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-411.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-406.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402159968_op&#45;&gt;6402159968 -->\n",
       "<g id=\"edge177\" class=\"edge\">\n",
       "<title>6402159968_op&#45;&gt;6402159968</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6158.02,-411.78C6166.36,-411.78 6177.25,-411.78 6189.71,-411.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6189.54,-415.28 6199.54,-411.78 6189.54,-408.28 6189.54,-415.28\"/>\n",
       "</g>\n",
       "<!-- 6402159008 -->\n",
       "<g id=\"node177\" class=\"node\">\n",
       "<title>6402159008</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5663.9,-503.78 5663.9,-539.78 6022.15,-539.78 6022.15,-503.78 5663.9,-503.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5673.78\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5683.65,-504.28 5683.65,-539.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-516.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.49768888224738345 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402159008&#45;&gt;6402159968_op -->\n",
       "<g id=\"edge190\" class=\"edge\">\n",
       "<title>6402159008&#45;&gt;6402159968_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6022.64,-520.15C6044.87,-514.76 6066.46,-506.66 6085.53,-494.78 6088.46,-492.96 6108.88,-460.25 6123.49,-436.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6126.31,-438.56 6128.54,-428.2 6120.34,-434.91 6126.31,-438.56\"/>\n",
       "</g>\n",
       "<!-- 6402159008_op -->\n",
       "<g id=\"node178\" class=\"node\">\n",
       "<title>6402159008_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-521.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-516.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402159008_op&#45;&gt;6402159008 -->\n",
       "<g id=\"edge178\" class=\"edge\">\n",
       "<title>6402159008_op&#45;&gt;6402159008</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-521.78C5576.25,-521.78 5612.42,-521.78 5652.36,-521.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5652.2,-525.28 5662.2,-521.78 5652.2,-518.28 5652.2,-525.28\"/>\n",
       "</g>\n",
       "<!-- 6402159392 -->\n",
       "<g id=\"node179\" class=\"node\">\n",
       "<title>6402159392</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5060.08,-495.78 5060.08,-531.78 5411.58,-531.78 5411.58,-495.78 5060.08,-495.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5069.96\" y=\"-508.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5079.83,-496.28 5079.83,-531.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-508.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.8011018475824944 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402159392&#45;&gt;6402159008_op -->\n",
       "<g id=\"edge185\" class=\"edge\">\n",
       "<title>6402159392&#45;&gt;6402159008_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5411.73,-518.45C5449.2,-519.45 5484.54,-520.39 5508.02,-521.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5507.87,-524.52 5517.96,-521.28 5508.06,-517.52 5507.87,-524.52\"/>\n",
       "</g>\n",
       "<!-- 6402159392_op -->\n",
       "<g id=\"node180\" class=\"node\">\n",
       "<title>6402159392_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-513.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-508.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402159392_op&#45;&gt;6402159392 -->\n",
       "<g id=\"edge179\" class=\"edge\">\n",
       "<title>6402159392_op&#45;&gt;6402159392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-513.78C4972.74,-513.78 5008.83,-513.78 5048.53,-513.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5048.3,-517.28 5058.3,-513.78 5048.3,-510.28 5048.3,-517.28\"/>\n",
       "</g>\n",
       "<!-- 6402160976 -->\n",
       "<g id=\"node181\" class=\"node\">\n",
       "<title>6402160976</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4500.14,-440.78 4500.14,-476.78 4750.39,-476.78 4750.39,-440.78 4500.14,-440.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4510.01\" y=\"-453.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4519.89,-441.28 4519.89,-476.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-453.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402160976&#45;&gt;6402159392_op -->\n",
       "<g id=\"edge180\" class=\"edge\">\n",
       "<title>6402160976&#45;&gt;6402159392_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4750.62,-465.77C4789.66,-469.88 4832.61,-476.41 4871.14,-486.78 4883.52,-490.12 4896.61,-495.54 4907.54,-500.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4905.76,-503.68 4916.28,-504.91 4908.83,-497.38 4905.76,-503.68\"/>\n",
       "</g>\n",
       "<!-- 6402147728 -->\n",
       "<g id=\"node182\" class=\"node\">\n",
       "<title>6402147728</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4449.51,-495.78 4449.51,-531.78 4801.01,-531.78 4801.01,-495.78 4449.51,-495.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4459.39\" y=\"-508.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4469.26,-496.28 4469.26,-531.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-508.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.8011018475824944 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402147728&#45;&gt;6402159392_op -->\n",
       "<g id=\"edge184\" class=\"edge\">\n",
       "<title>6402147728&#45;&gt;6402159392_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4801.09,-513.78C4841.37,-513.78 4879.62,-513.78 4904.44,-513.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.31,-517.28 4914.31,-513.78 4904.31,-510.28 4904.31,-517.28\"/>\n",
       "</g>\n",
       "<!-- 6402147728_op&#45;&gt;6402147728 -->\n",
       "<g id=\"edge181\" class=\"edge\">\n",
       "<title>6402147728_op&#45;&gt;6402147728</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4330.78,-649.01C4335.21,-644.56 4339.9,-639.25 4343.39,-633.78 4367,-596.76 4344.59,-568.56 4379.39,-541.78 4396.8,-528.39 4417.07,-519.24 4438.35,-513.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4438.95,-516.64 4447.75,-510.74 4437.2,-509.86 4438.95,-516.64\"/>\n",
       "</g>\n",
       "<!-- 6402256256 -->\n",
       "<g id=\"node184\" class=\"node\">\n",
       "<title>6402256256</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3773.69,-638.78 3773.69,-674.78 4245.19,-674.78 4245.19,-638.78 3773.69,-638.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3840.19\" y=\"-651.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 2 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3906.69,-639.28 3906.69,-674.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4075.94\" y=\"-651.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.8146900256750575 grad=0.18171243535335416</text>\n",
       "</g>\n",
       "<!-- 6402256256&#45;&gt;6402147728_op -->\n",
       "<g id=\"edge182\" class=\"edge\">\n",
       "<title>6402256256&#45;&gt;6402147728_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4245.59,-659.87C4261.54,-660.08 4275.77,-660.26 4287.16,-660.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4286.8,-663.91 4296.85,-660.54 4286.9,-656.91 4286.8,-663.91\"/>\n",
       "</g>\n",
       "<!-- 6402158864 -->\n",
       "<g id=\"node185\" class=\"node\">\n",
       "<title>6402158864</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5057.83,-550.78 5057.83,-586.78 5413.83,-586.78 5413.83,-550.78 5057.83,-550.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5067.71\" y=\"-563.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5077.58,-551.28 5077.58,-586.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-563.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.3034129653351109 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402158864&#45;&gt;6402159008_op -->\n",
       "<g id=\"edge189\" class=\"edge\">\n",
       "<title>6402158864&#45;&gt;6402159008_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5414.32,-552.64C5434.87,-549.59 5455.44,-546.01 5474.96,-541.78 5486.53,-539.28 5499.01,-535.47 5509.69,-531.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5510.77,-535.17 5519.04,-528.55 5508.44,-528.57 5510.77,-535.17\"/>\n",
       "</g>\n",
       "<!-- 6402158864_op&#45;&gt;6402158864 -->\n",
       "<g id=\"edge186\" class=\"edge\">\n",
       "<title>6402158864_op&#45;&gt;6402158864</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-568.78C4972.4,-568.78 5007.62,-568.78 5046.53,-568.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5046.08,-572.28 5056.08,-568.78 5046.08,-565.28 5046.08,-572.28\"/>\n",
       "</g>\n",
       "<!-- 6402256208 -->\n",
       "<g id=\"node187\" class=\"node\">\n",
       "<title>6402256208</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4387.26,-550.78 4387.26,-586.78 4863.26,-586.78 4863.26,-550.78 4387.26,-550.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4453.76\" y=\"-563.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 2 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4520.26,-551.28 4520.26,-586.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4691.76\" y=\"-563.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.8064977461433804 grad=&#45;0.06950018969159072</text>\n",
       "</g>\n",
       "<!-- 6402256208&#45;&gt;6402158864_op -->\n",
       "<g id=\"edge187\" class=\"edge\">\n",
       "<title>6402256208&#45;&gt;6402158864_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4863.72,-568.78C4879.23,-568.78 4893.08,-568.78 4904.23,-568.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.12,-572.28 4914.12,-568.78 4904.12,-565.28 4904.12,-572.28\"/>\n",
       "</g>\n",
       "<!-- 6402156224 -->\n",
       "<g id=\"node188\" class=\"node\">\n",
       "<title>6402156224</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5671.78,-393.78 5671.78,-429.78 6014.28,-429.78 6014.28,-393.78 5671.78,-393.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5681.65\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5691.53,-394.28 5691.53,-429.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-406.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.68673309646356 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402156224&#45;&gt;6402159968_op -->\n",
       "<g id=\"edge194\" class=\"edge\">\n",
       "<title>6402156224&#45;&gt;6402159968_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6014.49,-411.78C6051.58,-411.78 6086.65,-411.78 6109.98,-411.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6109.85,-415.28 6119.85,-411.78 6109.85,-408.28 6109.85,-415.28\"/>\n",
       "</g>\n",
       "<!-- 6402156224_op&#45;&gt;6402156224 -->\n",
       "<g id=\"edge191\" class=\"edge\">\n",
       "<title>6402156224_op&#45;&gt;6402156224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-404.24C5577.59,-404.81 5617.26,-405.86 5660.31,-406.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5660.01,-410.48 5670.1,-407.25 5660.2,-403.49 5660.01,-410.48\"/>\n",
       "</g>\n",
       "<!-- 6402257888 -->\n",
       "<g id=\"node190\" class=\"node\">\n",
       "<title>6402257888</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5002.33,-330.78 5002.33,-366.78 5469.33,-366.78 5469.33,-330.78 5002.33,-330.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5068.83\" y=\"-343.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 2 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5135.33,-331.28 5135.33,-366.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5302.33\" y=\"-343.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6948061739457669 grad=0.18255874915264755</text>\n",
       "</g>\n",
       "<!-- 6402257888&#45;&gt;6402156224_op -->\n",
       "<g id=\"edge192\" class=\"edge\">\n",
       "<title>6402257888&#45;&gt;6402156224_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5439.05,-367.25C5451.27,-369.75 5463.33,-372.58 5474.96,-375.78 5487.39,-379.21 5500.49,-384.83 5511.41,-390.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5509.65,-393.17 5520.15,-394.57 5512.81,-386.93 5509.65,-393.17\"/>\n",
       "</g>\n",
       "<!-- 6402148448 -->\n",
       "<g id=\"node191\" class=\"node\">\n",
       "<title>6402148448</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6198.03,-118.78 6198.03,-154.78 6560.78,-154.78 6560.78,-118.78 6198.03,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6207.9\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6217.78,-119.28 6217.78,-154.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.20728573344013632 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402148448&#45;&gt;6402148496_op -->\n",
       "<g id=\"edge199\" class=\"edge\">\n",
       "<title>6402148448&#45;&gt;6402148496_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6534.67,-155.23C6545.12,-157.73 6555.41,-160.56 6565.28,-163.78 6574.98,-166.95 6585.03,-171.81 6593.74,-176.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6591.86,-179.54 6602.27,-181.51 6595.35,-173.48 6591.86,-179.54\"/>\n",
       "</g>\n",
       "<!-- 6402148448_op&#45;&gt;6402148448 -->\n",
       "<g id=\"edge196\" class=\"edge\">\n",
       "<title>6402148448_op&#45;&gt;6402148448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6158.02,-136.78C6165.58,-136.78 6175.24,-136.78 6186.28,-136.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6186.23,-140.28 6196.23,-136.78 6186.23,-133.28 6186.23,-140.28\"/>\n",
       "</g>\n",
       "<!-- 6402256112 -->\n",
       "<g id=\"node193\" class=\"node\">\n",
       "<title>6402256112</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5616.28,-63.78 5616.28,-99.78 6069.78,-99.78 6069.78,-63.78 5616.28,-63.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5682.78\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 2 w3</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5749.28,-64.28 5749.28,-99.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5909.53\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.207267457465008 grad=0.1846052687741373</text>\n",
       "</g>\n",
       "<!-- 6402256112&#45;&gt;6402148448_op -->\n",
       "<g id=\"edge197\" class=\"edge\">\n",
       "<title>6402256112&#45;&gt;6402148448_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6053.49,-100.26C6064.41,-102.76 6075.14,-105.59 6085.53,-108.78 6095.28,-111.79 6105.35,-116.6 6114.05,-121.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6112.16,-124.35 6122.57,-126.35 6115.68,-118.3 6112.16,-124.35\"/>\n",
       "</g>\n",
       "<!-- 6402256160 -->\n",
       "<g id=\"node194\" class=\"node\">\n",
       "<title>6402256160</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6683.4,-118.78 6683.4,-154.78 7138.4,-154.78 7138.4,-118.78 6683.4,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6745.03\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 2 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6806.65,-119.28 6806.65,-154.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6972.53\" y=\"-131.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.6144412999476708 grad=&#45;0.1847533989104902</text>\n",
       "</g>\n",
       "<!-- 6402256160&#45;&gt;6402152336_op -->\n",
       "<g id=\"edge201\" class=\"edge\">\n",
       "<title>6402256160&#45;&gt;6402152336_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7138.68,-136.78C7151.52,-136.78 7163.08,-136.78 7172.68,-136.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7172.59,-140.28 7182.59,-136.78 7172.59,-133.28 7172.59,-140.28\"/>\n",
       "</g>\n",
       "<!-- 6402147200 -->\n",
       "<g id=\"node195\" class=\"node\">\n",
       "<title>6402147200</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8720.85,-98.78 8720.85,-134.78 9076.85,-134.78 9076.85,-98.78 8720.85,-98.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8730.72\" y=\"-111.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"8740.6,-99.28 8740.6,-134.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8908.72\" y=\"-111.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.1186466128451774 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402147200&#45;&gt;6402151424_op -->\n",
       "<g id=\"edge238\" class=\"edge\">\n",
       "<title>6402147200&#45;&gt;6402151424_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M9077.07,-122.43C9237.14,-127.03 9479.18,-132.78 9689.72,-132.78 9689.72,-132.78 9689.72,-132.78 10319.1,-132.78 10479.09,-132.78 10670.62,-147.42 10741.59,-153.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"10740.9,-156.79 10751.16,-154.15 10741.49,-149.82 10740.9,-156.79\"/>\n",
       "</g>\n",
       "<!-- 6402147200_op -->\n",
       "<g id=\"node196\" class=\"node\">\n",
       "<title>6402147200_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"8279.35\" cy=\"-81.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8279.35\" y=\"-76.73\" font-family=\"Times,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 6402147200_op&#45;&gt;6402147200 -->\n",
       "<g id=\"edge206\" class=\"edge\">\n",
       "<title>6402147200_op&#45;&gt;6402147200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8297.51,-82.76C8356.56,-86.1 8556.16,-97.42 8709.16,-106.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8708.87,-109.58 8719.05,-106.65 8709.26,-102.59 8708.87,-109.58\"/>\n",
       "</g>\n",
       "<!-- 6402257504 -->\n",
       "<g id=\"node197\" class=\"node\">\n",
       "<title>6402257504</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7751.6,-63.78 7751.6,-99.78 8225.35,-99.78 8225.35,-63.78 7751.6,-63.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7818.1\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2 Neuron 0 w3</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7884.6,-64.28 7884.6,-99.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"8054.97\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.15449897445037689 grad=0.20531606314719333</text>\n",
       "</g>\n",
       "<!-- 6402257504&#45;&gt;6402147200_op -->\n",
       "<g id=\"edge207\" class=\"edge\">\n",
       "<title>6402257504&#45;&gt;6402147200_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8225.7,-81.78C8234.53,-81.78 8242.59,-81.78 8249.6,-81.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8249.5,-85.28 8259.5,-81.78 8249.5,-78.28 8249.5,-85.28\"/>\n",
       "</g>\n",
       "<!-- 6402160160 -->\n",
       "<g id=\"node198\" class=\"node\">\n",
       "<title>6402160160</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7807.1,-8.78 7807.1,-44.78 8169.85,-44.78 8169.85,-8.78 7807.1,-8.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7816.97\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7826.85,-9.28 7826.85,-44.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7998.35\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.7669251605843824 grad=&#45;0.04141639564415052</text>\n",
       "</g>\n",
       "<!-- 6402160160&#45;&gt;6402147200_op -->\n",
       "<g id=\"edge237\" class=\"edge\">\n",
       "<title>6402160160&#45;&gt;6402147200_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M8170.25,-40.46C8189.06,-43.96 8207.73,-48.33 8225.35,-53.78 8235.1,-56.8 8245.16,-61.62 8253.86,-66.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"8251.98,-69.37 8262.38,-71.37 8255.5,-63.31 8251.98,-69.37\"/>\n",
       "</g>\n",
       "<!-- 6402160160_op -->\n",
       "<g id=\"node199\" class=\"node\">\n",
       "<title>6402160160_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7688.81\" cy=\"-26.78\" rx=\"26.78\" ry=\"26.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7688.81\" y=\"-21.73\" font-family=\"Times,serif\" font-size=\"14.00\">tanh</text>\n",
       "</g>\n",
       "<!-- 6402160160_op&#45;&gt;6402160160 -->\n",
       "<g id=\"edge208\" class=\"edge\">\n",
       "<title>6402160160_op&#45;&gt;6402160160</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7715.97,-26.78C7735.51,-26.78 7764.19,-26.78 7795.68,-26.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7795.41,-30.28 7805.41,-26.78 7795.41,-23.28 7795.41,-30.28\"/>\n",
       "</g>\n",
       "<!-- 6402160496 -->\n",
       "<g id=\"node200\" class=\"node\">\n",
       "<title>6402160496</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"7256.53,-8.78 7256.53,-44.78 7626.03,-44.78 7626.03,-8.78 7256.53,-8.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7266.4\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"7276.28,-9.28 7276.28,-44.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7451.15\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.0128182581398735 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402160496&#45;&gt;6402160160_op -->\n",
       "<g id=\"edge236\" class=\"edge\">\n",
       "<title>6402160496&#45;&gt;6402160160_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7626.49,-26.78C7635.03,-26.78 7643.04,-26.78 7650.27,-26.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7650.15,-30.28 7660.15,-26.78 7650.15,-23.28 7650.15,-30.28\"/>\n",
       "</g>\n",
       "<!-- 6402160496_op -->\n",
       "<g id=\"node201\" class=\"node\">\n",
       "<title>6402160496_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"7202.53\" cy=\"-26.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"7202.53\" y=\"-21.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402160496_op&#45;&gt;6402160496 -->\n",
       "<g id=\"edge209\" class=\"edge\">\n",
       "<title>6402160496_op&#45;&gt;6402160496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7220.94,-26.78C7227.54,-26.78 7235.74,-26.78 7245.06,-26.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7244.98,-30.28 7254.98,-26.78 7244.98,-23.28 7244.98,-30.28\"/>\n",
       "</g>\n",
       "<!-- 6402156512 -->\n",
       "<g id=\"node202\" class=\"node\">\n",
       "<title>6402156512</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6726.15,-63.78 6726.15,-99.78 7095.65,-99.78 7095.65,-63.78 6726.15,-63.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6736.03\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6745.9,-64.28 6745.9,-99.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6920.78\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.1168995206863275 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402156512&#45;&gt;6402160496_op -->\n",
       "<g id=\"edge234\" class=\"edge\">\n",
       "<title>6402156512&#45;&gt;6402160496_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7096.02,-66.49C7113.94,-63.07 7131.7,-58.89 7148.53,-53.78 7158.22,-50.84 7168.27,-46.19 7176.98,-41.57\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7178.48,-44.74 7185.5,-36.81 7175.06,-38.63 7178.48,-44.74\"/>\n",
       "</g>\n",
       "<!-- 6402156512_op -->\n",
       "<g id=\"node203\" class=\"node\">\n",
       "<title>6402156512_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6619.28\" cy=\"-81.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6619.28\" y=\"-76.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402156512_op&#45;&gt;6402156512 -->\n",
       "<g id=\"edge210\" class=\"edge\">\n",
       "<title>6402156512_op&#45;&gt;6402156512</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6637.53,-81.78C6654.58,-81.78 6682.66,-81.78 6714.48,-81.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6714.37,-85.28 6724.37,-81.78 6714.37,-78.28 6714.37,-85.28\"/>\n",
       "</g>\n",
       "<!-- 6402154928 -->\n",
       "<g id=\"node204\" class=\"node\">\n",
       "<title>6402154928</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6194.65,-173.78 6194.65,-209.78 6564.15,-209.78 6564.15,-173.78 6194.65,-173.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6204.53\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6214.4,-174.28 6214.4,-209.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;1.3596359907540152 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402154928&#45;&gt;6402156512_op -->\n",
       "<g id=\"edge229\" class=\"edge\">\n",
       "<title>6402154928&#45;&gt;6402156512_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6547.72,-173.46C6553.81,-170.61 6559.69,-167.4 6565.28,-163.78 6585.18,-150.93 6599.15,-127.66 6607.73,-109.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6610.9,-110.67 6611.67,-100.1 6604.48,-107.88 6610.9,-110.67\"/>\n",
       "</g>\n",
       "<!-- 6402154928_op -->\n",
       "<g id=\"node205\" class=\"node\">\n",
       "<title>6402154928_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"6139.53\" cy=\"-191.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6139.53\" y=\"-186.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402154928_op&#45;&gt;6402154928 -->\n",
       "<g id=\"edge211\" class=\"edge\">\n",
       "<title>6402154928_op&#45;&gt;6402154928</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6158.02,-191.78C6164.8,-191.78 6173.27,-191.78 6182.9,-191.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6182.73,-195.28 6192.73,-191.78 6182.73,-188.28 6182.73,-195.28\"/>\n",
       "</g>\n",
       "<!-- 6402148256 -->\n",
       "<g id=\"node206\" class=\"node\">\n",
       "<title>6402148256</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5654.9,-228.78 5654.9,-264.78 6031.15,-264.78 6031.15,-228.78 5654.9,-228.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5664.78\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5674.65,-229.28 5674.65,-264.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-241.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.42464456341558143 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402148256&#45;&gt;6402154928_op -->\n",
       "<g id=\"edge224\" class=\"edge\">\n",
       "<title>6402148256&#45;&gt;6402154928_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6031.61,-231.73C6050.01,-228.26 6068.25,-224 6085.53,-218.78 6095.23,-215.86 6105.27,-211.21 6113.98,-206.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6115.48,-209.76 6122.5,-201.82 6112.06,-203.65 6115.48,-209.76\"/>\n",
       "</g>\n",
       "<!-- 6402148256_op -->\n",
       "<g id=\"node207\" class=\"node\">\n",
       "<title>6402148256_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"5537.74\" cy=\"-246.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5537.74\" y=\"-241.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402148256_op&#45;&gt;6402148256 -->\n",
       "<g id=\"edge212\" class=\"edge\">\n",
       "<title>6402148256_op&#45;&gt;6402148256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-246.78C5574.71,-246.78 5607.05,-246.78 5643.38,-246.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5643.26,-250.28 5653.26,-246.78 5643.26,-243.28 5643.26,-250.28\"/>\n",
       "</g>\n",
       "<!-- 6402158720 -->\n",
       "<g id=\"node208\" class=\"node\">\n",
       "<title>6402158720</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5047.71,-220.78 5047.71,-256.78 5423.96,-256.78 5423.96,-220.78 5047.71,-220.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5057.58\" y=\"-233.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5067.46,-221.28 5067.46,-256.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-233.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.45190099542835166 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402158720&#45;&gt;6402148256_op -->\n",
       "<g id=\"edge219\" class=\"edge\">\n",
       "<title>6402158720&#45;&gt;6402148256_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5424.21,-243.78C5456.92,-244.66 5487.09,-245.46 5507.94,-246.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5507.77,-249.51 5517.86,-246.28 5507.96,-242.52 5507.77,-249.51\"/>\n",
       "</g>\n",
       "<!-- 6402158720_op -->\n",
       "<g id=\"node209\" class=\"node\">\n",
       "<title>6402158720_op</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"4933.92\" cy=\"-238.78\" rx=\"18\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4933.92\" y=\"-233.73\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 6402158720_op&#45;&gt;6402158720 -->\n",
       "<g id=\"edge213\" class=\"edge\">\n",
       "<title>6402158720_op&#45;&gt;6402158720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4952.34,-238.78C4970.56,-238.78 5001.29,-238.78 5035.94,-238.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5035.8,-242.28 5045.8,-238.78 5035.8,-235.28 5035.8,-242.28\"/>\n",
       "</g>\n",
       "<!-- 6402157376 -->\n",
       "<g id=\"node210\" class=\"node\">\n",
       "<title>6402157376</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4493.39,-220.78 4493.39,-256.78 4757.14,-256.78 4757.14,-220.78 4493.39,-220.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4503.26\" y=\"-233.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4513.14,-221.28 4513.14,-256.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-233.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.0 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402157376&#45;&gt;6402158720_op -->\n",
       "<g id=\"edge214\" class=\"edge\">\n",
       "<title>6402157376&#45;&gt;6402158720_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4757.2,-238.78C4812.01,-238.78 4870.71,-238.78 4904.49,-238.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.25,-242.28 4914.25,-238.78 4904.25,-235.28 4904.25,-242.28\"/>\n",
       "</g>\n",
       "<!-- 6402155024 -->\n",
       "<g id=\"node211\" class=\"node\">\n",
       "<title>6402155024</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4437.14,-330.78 4437.14,-366.78 4813.39,-366.78 4813.39,-330.78 4437.14,-330.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4447.01\" y=\"-343.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4456.89,-331.28 4456.89,-366.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4635.14\" y=\"-343.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.45190099542835166 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402155024&#45;&gt;6402158720_op -->\n",
       "<g id=\"edge218\" class=\"edge\">\n",
       "<title>6402155024&#45;&gt;6402158720_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4813.86,-343.4C4833.97,-338.18 4853.49,-330.87 4871.14,-320.78 4883.16,-313.91 4903.35,-285.17 4917.37,-263.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4920.23,-265.65 4922.69,-255.34 4914.34,-261.87 4920.23,-265.65\"/>\n",
       "</g>\n",
       "<!-- 6402155024_op&#45;&gt;6402155024 -->\n",
       "<g id=\"edge215\" class=\"edge\">\n",
       "<title>6402155024_op&#45;&gt;6402155024</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4328.72,-416.83C4339.98,-403.8 4358.66,-385.01 4379.39,-375.78 4394.07,-369.25 4409.72,-364.05 4425.74,-359.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4426.5,-363.36 4435.41,-357.62 4424.86,-356.55 4426.5,-363.36\"/>\n",
       "</g>\n",
       "<!-- 6402256688 -->\n",
       "<g id=\"node213\" class=\"node\">\n",
       "<title>6402256688</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"3772.57,-412.78 3772.57,-448.78 4246.32,-448.78 4246.32,-412.78 3772.57,-412.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"3839.07\" y=\"-425.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 3 w0</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"3905.57,-413.28 3905.57,-448.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4075.94\" y=\"-425.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.45944679778766173 grad=0.01677559997402493</text>\n",
       "</g>\n",
       "<!-- 6402256688&#45;&gt;6402155024_op -->\n",
       "<g id=\"edge216\" class=\"edge\">\n",
       "<title>6402256688&#45;&gt;6402155024_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4246.74,-430.78C4262.06,-430.78 4275.75,-430.78 4286.81,-430.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4286.61,-434.28 4296.61,-430.78 4286.61,-427.28 4286.61,-434.28\"/>\n",
       "</g>\n",
       "<!-- 6402154736 -->\n",
       "<g id=\"node214\" class=\"node\">\n",
       "<title>6402154736</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5046.58,-275.78 5046.58,-311.78 5425.08,-311.78 5425.08,-275.78 5046.58,-275.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5056.46\" y=\"-288.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5066.33,-276.28 5066.33,-311.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5245.71\" y=\"-288.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.027256432012770244 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402154736&#45;&gt;6402148256_op -->\n",
       "<g id=\"edge223\" class=\"edge\">\n",
       "<title>6402154736&#45;&gt;6402148256_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5422.29,-275.31C5440.16,-272.53 5457.95,-269.37 5474.96,-265.78 5486.49,-263.35 5498.96,-259.72 5509.65,-256.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5510.62,-259.65 5519,-253.17 5508.4,-253.01 5510.62,-259.65\"/>\n",
       "</g>\n",
       "<!-- 6402154736_op&#45;&gt;6402154736 -->\n",
       "<g id=\"edge220\" class=\"edge\">\n",
       "<title>6402154736_op&#45;&gt;6402154736</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4944.1,-388.67C4957.56,-367.02 4982.61,-328.89 4996.71,-320.78 5008.8,-313.83 5021.82,-308.23 5035.3,-303.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5036.23,-307.13 5044.76,-300.85 5034.17,-300.44 5036.23,-307.13\"/>\n",
       "</g>\n",
       "<!-- 6402251744 -->\n",
       "<g id=\"node216\" class=\"node\">\n",
       "<title>6402251744</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4379.39,-385.78 4379.39,-421.78 4871.14,-421.78 4871.14,-385.78 4379.39,-385.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4445.89\" y=\"-398.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 3 w1</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4512.39,-386.28 4512.39,-421.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"4691.76\" y=\"-398.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.07246259913170414 grad=&#45;0.0064162223026606735</text>\n",
       "</g>\n",
       "<!-- 6402251744&#45;&gt;6402154736_op -->\n",
       "<g id=\"edge221\" class=\"edge\">\n",
       "<title>6402251744&#45;&gt;6402154736_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M4871.6,-403.78C4883.9,-403.78 4894.94,-403.78 4904.15,-403.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"4904.01,-407.28 4914.01,-403.78 4904.01,-400.28 4904.01,-407.28\"/>\n",
       "</g>\n",
       "<!-- 6402155936 -->\n",
       "<g id=\"node217\" class=\"node\">\n",
       "<title>6402155936</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5658.28,-173.78 5658.28,-209.78 6027.78,-209.78 6027.78,-173.78 5658.28,-173.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5668.15\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5678.03,-174.28 5678.03,-209.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5852.9\" y=\"-186.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.9349914273384337 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402155936&#45;&gt;6402154928_op -->\n",
       "<g id=\"edge228\" class=\"edge\">\n",
       "<title>6402155936&#45;&gt;6402154928_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6028.03,-191.78C6059.95,-191.78 6089.41,-191.78 6109.87,-191.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6109.6,-195.28 6119.6,-191.78 6109.6,-188.28 6109.6,-195.28\"/>\n",
       "</g>\n",
       "<!-- 6402155936_op&#45;&gt;6402155936 -->\n",
       "<g id=\"edge225\" class=\"edge\">\n",
       "<title>6402155936_op&#45;&gt;6402155936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5555.92,-191.78C5575.31,-191.78 5609.1,-191.78 5646.83,-191.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5646.6,-195.28 5656.6,-191.78 5646.6,-188.28 5646.6,-195.28\"/>\n",
       "</g>\n",
       "<!-- 6402252176 -->\n",
       "<g id=\"node219\" class=\"node\">\n",
       "<title>6402252176</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5002.33,-165.78 5002.33,-201.78 5469.33,-201.78 5469.33,-165.78 5002.33,-165.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5068.83\" y=\"-178.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 3 w2</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5135.33,-166.28 5135.33,-201.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5302.33\" y=\"-178.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.9462146742275059 grad=0.01685373123522252</text>\n",
       "</g>\n",
       "<!-- 6402252176&#45;&gt;6402155936_op -->\n",
       "<g id=\"edge226\" class=\"edge\">\n",
       "<title>6402252176&#45;&gt;6402155936_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M5469.81,-190C5484.45,-190.39 5497.55,-190.74 5508.19,-191.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"5507.9,-194.52 5517.99,-191.28 5508.09,-187.52 5507.9,-194.52\"/>\n",
       "</g>\n",
       "<!-- 6402148304 -->\n",
       "<g id=\"node220\" class=\"node\">\n",
       "<title>6402148304</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6196.9,-63.78 6196.9,-99.78 6561.9,-99.78 6561.9,-63.78 6196.9,-63.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6206.78\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6216.65,-64.28 6216.65,-99.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6389.28\" y=\"-76.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.2427364700676877 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402148304&#45;&gt;6402156512_op -->\n",
       "<g id=\"edge233\" class=\"edge\">\n",
       "<title>6402148304&#45;&gt;6402156512_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6562.21,-81.78C6572.34,-81.78 6581.62,-81.78 6589.59,-81.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6589.45,-85.28 6599.45,-81.78 6589.45,-78.28 6589.45,-85.28\"/>\n",
       "</g>\n",
       "<!-- 6402148304_op&#45;&gt;6402148304 -->\n",
       "<g id=\"edge230\" class=\"edge\">\n",
       "<title>6402148304_op&#45;&gt;6402148304</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6158.02,-81.78C6165.3,-81.78 6174.54,-81.78 6185.07,-81.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6184.97,-85.28 6194.97,-81.78 6184.97,-78.28 6184.97,-85.28\"/>\n",
       "</g>\n",
       "<!-- 6402257312 -->\n",
       "<g id=\"node222\" class=\"node\">\n",
       "<title>6402257312</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"5600.53,-8.78 5600.53,-44.78 6085.53,-44.78 6085.53,-8.78 5600.53,-8.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5667.03\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 3 w3</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"5733.53,-9.28 5733.53,-44.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"5909.53\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = &#45;0.24294828824818293 grad=0.017042664889885966</text>\n",
       "</g>\n",
       "<!-- 6402257312&#45;&gt;6402148304_op -->\n",
       "<g id=\"edge231\" class=\"edge\">\n",
       "<title>6402257312&#45;&gt;6402148304_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M6053.49,-45.26C6064.41,-47.76 6075.14,-50.59 6085.53,-53.78 6095.28,-56.79 6105.35,-61.6 6114.05,-66.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"6112.16,-69.35 6122.57,-71.35 6115.68,-63.3 6112.16,-69.35\"/>\n",
       "</g>\n",
       "<!-- 6402256640 -->\n",
       "<g id=\"node223\" class=\"node\">\n",
       "<title>6402256640</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"6673.28,-8.78 6673.28,-44.78 7148.53,-44.78 7148.53,-8.78 6673.28,-8.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6734.9\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 1 Neuron 3 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"6796.53,-9.28 6796.53,-44.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"6972.53\" y=\"-21.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.10409831888664303 grad=&#45;0.017056340189029483</text>\n",
       "</g>\n",
       "<!-- 6402256640&#45;&gt;6402160496_op -->\n",
       "<g id=\"edge235\" class=\"edge\">\n",
       "<title>6402256640&#45;&gt;6402160496_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M7148.74,-26.78C7157.6,-26.78 7165.68,-26.78 7172.7,-26.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"7172.64,-30.28 7182.64,-26.78 7172.64,-23.28 7172.64,-30.28\"/>\n",
       "</g>\n",
       "<!-- 6402257360 -->\n",
       "<g id=\"node224\" class=\"node\">\n",
       "<title>6402257360</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"10824.85,-82.78 10824.85,-118.78 11286.6,-118.78 11286.6,-82.78 10824.85,-82.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"10886.47\" y=\"-95.98\" font-family=\"Times,serif\" font-size=\"14.00\">Layer 2 Neuron 0 b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"10948.1,-83.28 10948.1,-118.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11117.35\" y=\"-95.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0.40941138572665775 grad=&#45;0.2677132968107949</text>\n",
       "</g>\n",
       "<!-- 6402257360&#45;&gt;6402152000_op -->\n",
       "<g id=\"edge240\" class=\"edge\">\n",
       "<title>6402257360&#45;&gt;6402152000_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M11250.48,-119.28C11274.08,-121.53 11295.41,-123.57 11311.28,-125.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"11310.51,-128.52 11320.8,-125.99 11311.18,-121.56 11310.51,-128.52\"/>\n",
       "</g>\n",
       "<!-- 6402147680 -->\n",
       "<g id=\"node225\" class=\"node\">\n",
       "<title>6402147680</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"11963.97,-81.78 11963.97,-117.78 12097.97,-117.78 12097.97,-81.78 11963.97,-81.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11973.85\" y=\"-94.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"11983.72,-82.28 11983.72,-117.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12040.85\" y=\"-94.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 2 grad=0.0</text>\n",
       "</g>\n",
       "<!-- 6402147680&#45;&gt;6402158576_op -->\n",
       "<g id=\"edge243\" class=\"edge\">\n",
       "<title>6402147680&#45;&gt;6402158576_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12098.17,-107.52C12142.41,-112.69 12198.54,-119.25 12232.56,-123.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12231.78,-126.66 12242.11,-124.35 12232.59,-119.71 12231.78,-126.66\"/>\n",
       "</g>\n",
       "<!-- 6402151808 -->\n",
       "<g id=\"node226\" class=\"node\">\n",
       "<title>6402151808</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"12382.73,-53.78 12382.73,-89.78 12516.73,-89.78 12516.73,-53.78 12382.73,-53.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12392.61\" y=\"-66.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"12402.48,-54.28 12402.48,-89.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12459.61\" y=\"-66.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 0 grad=1.0</text>\n",
       "</g>\n",
       "<!-- 6402151808&#45;&gt;6402162368_op -->\n",
       "<g id=\"edge245\" class=\"edge\">\n",
       "<title>6402151808&#45;&gt;6402162368_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12517.08,-81.65C12547.11,-86.11 12580.99,-91.15 12604.21,-94.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12603.4,-98.02 12613.81,-96.03 12604.43,-91.09 12603.4,-98.02\"/>\n",
       "</g>\n",
       "<!-- 6402158384 -->\n",
       "<g id=\"node227\" class=\"node\">\n",
       "<title>6402158384</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"12690.36,-25.78 12690.36,-61.78 12943.61,-61.78 12943.61,-25.78 12690.36,-25.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12700.23\" y=\"-38.98\" font-family=\"Times,serif\" font-size=\"14.00\"> </text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"12710.11,-26.28 12710.11,-61.78\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"12826.86\" y=\"-38.98\" font-family=\"Times,serif\" font-size=\"14.00\">data = 1 grad=&#45;0.017917602322326195</text>\n",
       "</g>\n",
       "<!-- 6402158384&#45;&gt;6402157232_op -->\n",
       "<g id=\"edge247\" class=\"edge\">\n",
       "<title>6402158384&#45;&gt;6402157232_op</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M12942.14,-62.24C12952.7,-63.81 12962.56,-65.28 12971.03,-66.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"12970.45,-69.99 12980.86,-68 12971.48,-63.07 12970.45,-69.99\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x17d992f90>"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "d85f718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9835427836930768, 0.3745107718519387, -0.9881199861535883, -0.9991982266578866]\n",
      "Layer: Layer 1, Input: [-0.9835427836930768, 0.3745107718519387, -0.9881199861535883, -0.9991982266578866], Output: [0.9221529606207961, -0.7890705788700002, 0.21654528178218366, -0.7669462096196659]\n",
      "Layer: Layer 2, Input: [0.9221529606207961, -0.7890705788700002, 0.21654528178218366, -0.7669462096196659], Output: [0.8684597374199408]\n",
      "y_preds = 0.8684597374199408\n",
      "y = 1.0\n",
      "loss = Value(data=0.017302840679630935)\n"
     ]
    }
   ],
   "source": [
    "# Second forward pass with our model\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "20af6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Neuron 0 w0 = 0.2788439384702872, grad = 0.009658445480288656\n",
      "Layer 0 Neuron 0 w1 = -0.9499929772228866, grad = 0.014487668220432983\n",
      "Layer 0 Neuron 0 w2 = -0.44993653403902134, grad = -0.004829222740144328\n",
      "Layer 0 Neuron 0 b = -0.5535833529250946, grad = 0.004829222740144328\n",
      "Layer 0 Neuron 1 w0 = 0.47268365591740313, grad = 0.2587724106216494\n",
      "Layer 0 Neuron 1 w1 = 0.3530108162298901, grad = 0.38815861593247414\n",
      "Layer 0 Neuron 1 w2 = 0.7844885216150016, grad = -0.1293862053108247\n",
      "Layer 0 Neuron 1 b = -0.8262517209464785, grad = 0.1293862053108247\n",
      "Layer 0 Neuron 2 w0 = -0.156149540968433, grad = -0.006819661026130761\n",
      "Layer 0 Neuron 2 w1 = -0.9403953316323201, grad = -0.010229491539196141\n",
      "Layer 0 Neuron 2 w2 = -0.5627274602233063, grad = 0.0034098305130653805\n",
      "Layer 0 Neuron 2 b = 0.010713986037237841, grad = -0.0034098305130653805\n",
      "Layer 0 Neuron 3 w0 = -0.9469279643907854, grad = -9.624148732860756e-05\n",
      "Layer 0 Neuron 3 w1 = -0.6023245542644721, grad = -0.00014436223099291136\n",
      "Layer 0 Neuron 3 w2 = 0.29976882743830274, grad = 4.812074366430378e-05\n",
      "Layer 0 Neuron 3 b = 0.08988300932717702, grad = -4.812074366430378e-05\n",
      "Layer 1 Neuron 0 w0 = -0.5591447037724337, grad = 0.025947853827143978\n",
      "Layer 1 Neuron 0 w1 = 0.17854129211808092, grad = -0.00992436626348306\n",
      "Layer 1 Neuron 0 w2 = 0.6188348446513917, grad = 0.02606870426158594\n",
      "Layer 1 Neuron 0 w3 = -0.9870288415834612, grad = 0.02636093958323322\n",
      "Layer 1 Neuron 0 b = 0.6116648857576266, grad = -0.026382092010792762\n",
      "Layer 1 Neuron 1 w0 = 0.39625526026487373, grad = 0.02352971157995671\n",
      "Layer 1 Neuron 1 w1 = -0.31948996747306224, grad = -0.008999490954019754\n",
      "Layer 1 Neuron 1 w2 = -0.6890646396761118, grad = 0.023639299674820924\n",
      "Layer 1 Neuron 1 w3 = 0.914402240112671, grad = 0.02390430089140105\n",
      "Layer 1 Neuron 1 b = -0.32678698629267255, grad = -0.02392348207389913\n",
      "Layer 1 Neuron 2 w0 = -0.8146900256750575, grad = 0.18171243535335416\n",
      "Layer 1 Neuron 2 w1 = -0.8064977461433804, grad = -0.06950018969159072\n",
      "Layer 1 Neuron 2 w2 = 0.6948061739457669, grad = 0.18255874915264755\n",
      "Layer 1 Neuron 2 w3 = 0.207267457465008, grad = 0.1846052687741373\n",
      "Layer 1 Neuron 2 b = 0.6144412999476708, grad = -0.1847533989104902\n",
      "Layer 1 Neuron 3 w0 = 0.45944679778766173, grad = 0.01677559997402493\n",
      "Layer 1 Neuron 3 w1 = 0.07246259913170414, grad = -0.0064162223026606735\n",
      "Layer 1 Neuron 3 w2 = 0.9462146742275059, grad = 0.01685373123522252\n",
      "Layer 1 Neuron 3 w3 = -0.24294828824818293, grad = 0.017042664889885966\n",
      "Layer 1 Neuron 3 b = 0.10409831888664303, grad = -0.017056340189029483\n",
      "Layer 2 Neuron 0 w0 = 0.6590562086406249, grad = -0.24688013463515496\n",
      "Layer 2 Neuron 0 w1 = 0.2368281965653681, grad = 0.2113081631240002\n",
      "Layer 2 Neuron 0 w2 = 0.7234712360937652, grad = -0.05743547221069753\n",
      "Layer 2 Neuron 0 w3 = 0.15449897445037689, grad = 0.20531606314719333\n",
      "Layer 2 Neuron 0 b = 0.40941138572665775, grad = -0.2677132968107949\n"
     ]
    }
   ],
   "source": [
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label} = {param.data}, grad = {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "f4b8b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9825057316653201, 0.9610686207780447, -0.9115415252700779, -0.9977308797483263]\n",
      "Layer: Layer 1, Input: [0.9825057316653201, 0.9610686207780447, -0.9115415252700779, -0.9977308797483263], Output: [0.9847014229020513, 0.012130760506167501, 0.51497159021045, 0.16476735567050552]\n",
      "Layer: Layer 2, Input: [0.9847014229020513, 0.012130760506167501, 0.51497159021045, 0.16476735567050552], Output: [1.0467845200421833]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7398227986896625, 0.9290378795204044, -0.9855247181733577, -0.9496027612288697]\n",
      "Layer: Layer 1, Input: [-0.7398227986896625, 0.9290378795204044, -0.9855247181733577, -0.9496027612288697], Output: [0.7066430177251568, -0.15721454971520726, 0.5521140010705042, 0.8250906195144444]\n",
      "Layer: Layer 2, Input: [0.7066430177251568, -0.15721454971520726, 0.5521140010705042, 0.8250906195144444], Output: [1.1752707845362775]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.1171341231332633, -0.8358852908189875, 0.2849119318755442, 0.36030619286707344]\n",
      "Layer: Layer 1, Input: [0.1171341231332633, -0.8358852908189875, 0.2849119318755442, 0.36030619286707344], Output: [-0.243674003310208, 0.06830282990172974, -0.6197996897542721, -0.3980373422441228]\n",
      "Layer: Layer 2, Input: [-0.243674003310208, 0.06830282990172974, -0.6197996897542721, -0.3980373422441228], Output: [0.09996554729270596]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5403559825341562, 0.7289774589179535, -0.8526138640072847, -0.9669897072051897]\n",
      "Layer: Layer 1, Input: [0.5403559825341562, 0.7289774589179535, -0.8526138640072847, -0.9669897072051897], Output: [0.9472891373093211, 0.08023172903643916, 0.40489491804838257, 0.28231161638148217]\n",
      "Layer: Layer 2, Input: [0.9472891373093211, 0.08023172903643916, 0.40489491804838257, 0.28231161638148217], Output: [0.9428118340125429]\n",
      "Epoch 1/100, Loss: 1.4867966172331502, Accuracy: -2.379209017858624\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9822072701316953, 0.9575772125317866, -0.9097560867440487, -0.9979465706417066]\n",
      "Layer: Layer 1, Input: [0.9822072701316953, 0.9575772125317866, -0.9097560867440487, -0.9979465706417066], Output: [0.984060582513575, 0.11871646977461549, 0.47084651848171094, 0.1600477487431656]\n",
      "Layer: Layer 2, Input: [0.984060582513575, 0.11871646977461549, 0.47084651848171094, 0.1600477487431656], Output: [0.8257435209600559]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7419980616521413, 0.9180275287015007, -0.9853702669392417, -0.9538300626562568]\n",
      "Layer: Layer 1, Input: [-0.7419980616521413, 0.9180275287015007, -0.9853702669392417, -0.9538300626562568], Output: [0.6888789306428873, -0.002311992968160026, 0.48814369026631593, 0.8216113464909386]\n",
      "Layer: Layer 2, Input: [0.6888789306428873, -0.002311992968160026, 0.48814369026631593, 0.8216113464909386], Output: [0.8925866205317352]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.11079538371685756, -0.8454483985312015, 0.29265929400331253, 0.3259374202652461]\n",
      "Layer: Layer 1, Input: [0.11079538371685756, -0.8454483985312015, 0.29265929400331253, 0.3259374202652461], Output: [-0.2843025972720082, 0.11994529503438464, -0.6159588891259417, -0.3871026072115056]\n",
      "Layer: Layer 2, Input: [-0.2843025972720082, 0.11994529503438464, -0.6159588891259417, -0.3871026072115056], Output: [0.007346943150666918]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5379176198391592, 0.718311099316546, -0.8515231817564933, -0.9683380409536924]\n",
      "Layer: Layer 1, Input: [0.5379176198391592, 0.718311099316546, -0.8515231817564933, -0.9683380409536924], Output: [0.9442493007762879, 0.19295186672032918, 0.3477927830013218, 0.2732832402992497]\n",
      "Layer: Layer 2, Input: [0.9442493007762879, 0.19295186672032918, 0.3477927830013218, 0.2732832402992497], Output: [0.7093766069180991]\n",
      "Epoch 2/100, Loss: 1.1778648142961408, Accuracy: -2.364813435804247\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9817720969666899, 0.9560223778853559, -0.9079789372487423, -0.9981289376413472]\n",
      "Layer: Layer 1, Input: [0.9817720969666899, 0.9560223778853559, -0.9079789372487423, -0.9981289376413472], Output: [0.9835702813057561, 0.17822133381379732, 0.44574857888155633, 0.16071956392673595]\n",
      "Layer: Layer 2, Input: [0.9835702813057561, 0.17822133381379732, 0.44574857888155633, 0.16071956392673595], Output: [0.691224168761634]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7461989460073265, 0.9071454199150742, -0.9852629754849386, -0.9573183614933873]\n",
      "Layer: Layer 1, Input: [-0.7461989460073265, 0.9071454199150742, -0.9852629754849386, -0.9573183614933873], Output: [0.6723475243927853, 0.11262441138315371, 0.4347357766378862, 0.8197038631473206]\n",
      "Layer: Layer 2, Input: [0.6723475243927853, 0.11262441138315371, 0.4347357766378862, 0.8197038631473206], Output: [0.6894728225238898]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.10306142551827552, -0.851993900329937, 0.29790947960864317, 0.2924887473474305]\n",
      "Layer: Layer 1, Input: [0.10306142551827552, -0.851993900329937, 0.29790947960864317, 0.2924887473474305], Output: [-0.3191191399748005, 0.1695752129420817, -0.6122599533540037, -0.37402760475021296]\n",
      "Layer: Layer 2, Input: [-0.3191191399748005, 0.1695752129420817, -0.6122599533540037, -0.37402760475021296], Output: [-0.07553807899339526]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5339271581605575, 0.7136973321413869, -0.8502940795536998, -0.9695210017884037]\n",
      "Layer: Layer 1, Input: [0.5339271581605575, 0.7136973321413869, -0.8502940795536998, -0.9695210017884037], Output: [0.9418432077269759, 0.2605072936115581, 0.3130184328613077, 0.27324353668009815]\n",
      "Layer: Layer 2, Input: [0.9418432077269759, 0.2605072936115581, 0.3130184328613077, 0.27324353668009815], Output: [0.5619164793969983]\n",
      "Epoch 3/100, Loss: 0.9990519866047312, Accuracy: -2.3607940953718622\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9812438325545977, 0.95573231195932, -0.9059890725506554, -0.9982838405189921]\n",
      "Layer: Layer 1, Input: [0.9812438325545977, 0.95573231195932, -0.9059890725506554, -0.9982838405189921], Output: [0.9831556246727721, 0.20730923204604879, 0.43448160384471973, 0.16302825954848957]\n",
      "Layer: Layer 2, Input: [0.9831556246727721, 0.20730923204604879, 0.43448160384471973, 0.16302825954848957], Output: [0.612381114724164]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7527306851249246, 0.8959549452030316, -0.9851708463457248, -0.9602062232931168]\n",
      "Layer: Layer 1, Input: [-0.7527306851249246, 0.8959549452030316, -0.9851708463457248, -0.9602062232931168], Output: [0.6553608456206012, 0.19725708206901726, 0.38906863666222447, 0.8184570070858406]\n",
      "Layer: Layer 2, Input: [0.6553608456206012, 0.19725708206901726, 0.38906863666222447, 0.8184570070858406], Output: [0.5386494726176011]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.09341193302929793, -0.8568284443977588, 0.3021812806002981, 0.2602741254865694]\n",
      "Layer: Layer 1, Input: [0.09341193302929793, -0.8568284443977588, 0.3021812806002981, 0.2602741254865694], Output: [-0.35148966578707136, 0.2171137875204753, -0.6086685511979086, -0.3587220273821592]\n",
      "Layer: Layer 2, Input: [-0.35148966578707136, 0.2171137875204753, -0.6086685511979086, -0.3587220273821592], Output: [-0.15209458667386444]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5290439892743407, 0.7127653628908861, -0.8488294411678251, -0.9705623665745463]\n",
      "Layer: Layer 1, Input: [0.5290439892743407, 0.7127653628908861, -0.8488294411678251, -0.9705623665745463], Output: [0.9397772588324682, 0.2993876601936393, 0.2938704786436811, 0.2772404140659806]\n",
      "Layer: Layer 2, Input: [0.9397772588324682, 0.2993876601936393, 0.2938704786436811, 0.2772404140659806], Output: [0.468935071560554]\n",
      "Epoch 4/100, Loss: 0.8796660369937656, Accuracy: -2.3052386996590184\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9806600138104095, 0.9561910513592605, -0.9037579354264104, -0.9984155676677292]\n",
      "Layer: Layer 1, Input: [0.9806600138104095, 0.9561910513592605, -0.9037579354264104, -0.9984155676677292], Output: [0.9827724884240979, 0.21653102391450094, 0.43266774351038173, 0.16524070649010023]\n",
      "Layer: Layer 2, Input: [0.9827724884240979, 0.21653102391450094, 0.43266774351038173, 0.16524070649010023], Output: [0.5706631339833562]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7613068809876887, 0.8839485538420613, -0.9850806212708796, -0.9626201414657634]\n",
      "Layer: Layer 1, Input: [-0.7613068809876887, 0.8839485538420613, -0.9850806212708796, -0.9626201414657634], Output: [0.6369283784165953, 0.2608215466183554, 0.3482614170923181, 0.8173173272838193]\n",
      "Layer: Layer 2, Input: [0.6369283784165953, 0.2608215466183554, 0.3482614170923181, 0.8173173272838193], Output: [0.4218865794264939]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.08187135918902459, -0.8606685407088216, 0.30613708493265035, 0.2296291465776058]\n",
      "Layer: Layer 1, Input: [0.08187135918902459, -0.8606685407088216, 0.30613708493265035, 0.2296291465776058], Output: [-0.3826726895595391, 0.26204512654976375, -0.6052671620529694, -0.3415214478529668]\n",
      "Layer: Layer 2, Input: [-0.3826726895595391, 0.26204512654976375, -0.6052671620529694, -0.3415214478529668], Output: [-0.22406565952016955]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5237743363162585, 0.7139210887395296, -0.8471534727324348, -0.9714803187855985]\n",
      "Layer: Layer 1, Input: [0.5237743363162585, 0.7139210887395296, -0.8471534727324348, -0.9714803187855985], Output: [0.9378740228036467, 0.3198994914168524, 0.2850532446121694, 0.282596347160876]\n",
      "Layer: Layer 2, Input: [0.9378740228036467, 0.3198994914168524, 0.2850532446121694, 0.282596347160876], Output: [0.4116330854963991]\n",
      "Epoch 5/100, Loss: 0.7885853290231314, Accuracy: -2.215524700426569\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9800547632929415, 0.9570463989446116, -0.9013261351002118, -0.9985274876988207]\n",
      "Layer: Layer 1, Input: [0.9800547632929415, 0.9570463989446116, -0.9013261351002118, -0.9985274876988207], Output: [0.9823949008843006, 0.21233708034393367, 0.4369791212844771, 0.16658813289823748]\n",
      "Layer: Layer 2, Input: [0.9823949008843006, 0.21233708034393367, 0.4369791212844771, 0.16658813289823748], Output: [0.5544740981711993]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7714466892302039, 0.8705490036043423, -0.9849876856970503, -0.9646564141917897]\n",
      "Layer: Layer 1, Input: [-0.7714466892302039, 0.8705490036043423, -0.9849876856970503, -0.9646564141917897], Output: [0.616379903467195, 0.3101694550425287, 0.30974374500863905, 0.8158968933288999]\n",
      "Layer: Layer 2, Input: [0.616379903467195, 0.3101694550425287, 0.30974374500863905, 0.8158968933288999], Output: [0.3268411030618174]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.06871328835650349, -0.8639331677982909, 0.3100445145808728, 0.20084817011005784]\n",
      "Layer: Layer 1, Input: [0.06871328835650349, -0.8639331677982909, 0.3100445145808728, 0.20084817011005784], Output: [-0.41297590790204985, 0.30394244734857023, -0.6022003404151564, -0.32291627107537535]\n",
      "Layer: Layer 2, Input: [-0.41297590790204985, 0.30394244734857023, -0.6022003404151564, -0.32291627107537535], Output: [-0.2925353009238182]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5185158523717944, 0.716125338631786, -0.8453254787679526, -0.9722884794377883]\n",
      "Layer: Layer 1, Input: [0.5185158523717944, 0.716125338631786, -0.8453254787679526, -0.9722884794377883], Output: [0.936029897229995, 0.3282631648868594, 0.28271407965122985, 0.28784874990043663]\n",
      "Layer: Layer 2, Input: [0.936029897229995, 0.3282631648868594, 0.28271407965122985, 0.28784874990043663], Output: [0.378344072452304]\n",
      "Epoch 6/100, Loss: 0.7114907586672015, Accuracy: -2.101487631514496\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9794614024835376, 0.9580685760903346, -0.8987572563119531, -0.998622390438785]\n",
      "Layer: Layer 1, Input: [0.9794614024835376, 0.9580685760903346, -0.8987572563119531, -0.998622390438785], Output: [0.9820076259140409, 0.19876257572107367, 0.4450098107191803, 0.1667678974005898]\n",
      "Layer: Layer 2, Input: [0.9820076259140409, 0.19876257572107367, 0.4450098107191803, 0.1667678974005898], Output: [0.5563117321984092]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7826244472270357, 0.8550772022459766, -0.984891422823685, -0.9663856519599913]\n",
      "Layer: Layer 1, Input: [-0.7826244472270357, 0.8550772022459766, -0.984891422823685, -0.9663856519599913], Output: [0.5931611700524269, 0.35001927911805225, 0.27131624071114546, 0.8138671179940659]\n",
      "Layer: Layer 2, Input: [0.5931611700524269, 0.35001927911805225, 0.27131624071114546, 0.8138671179940659], Output: [0.2449836602775878]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.05433671528151554, -0.8668826578046934, 0.3139798967139757, 0.17415582590453493]\n",
      "Layer: Layer 1, Input: [0.05433671528151554, -0.8668826578046934, 0.3139798967139757, 0.17415582590453493], Output: [-0.44227723443468286, 0.3425716849894695, -0.5996304817081628, -0.30344980356508044]\n",
      "Layer: Layer 2, Input: [-0.44227723443468286, 0.3425716849894695, -0.5996304817081628, -0.30344980356508044], Output: [-0.3582322380146534]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5136008401435844, 0.7186952870691055, -0.8434098209673057, -0.9729976235344476]\n",
      "Layer: Layer 1, Input: [0.5136008401435844, 0.7186952870691055, -0.8434098209673057, -0.9729976235344476], Output: [0.9341875063416542, 0.3282897241868761, 0.28414941949995903, 0.2921781754105162]\n",
      "Layer: Layer 2, Input: [0.9341875063416542, 0.3282897241868761, 0.28414941949995903, 0.2921781754105162], Output: [0.3615928630037724]\n",
      "Epoch 7/100, Loss: 0.6415682815585892, Accuracy: -1.9688468270607529\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9789133523613167, 0.9591097234535616, -0.8961197601210276, -0.9987026419958649]\n",
      "Layer: Layer 1, Input: [0.9789133523613167, 0.9591097234535616, -0.8961197601210276, -0.9987026419958649], Output: [0.9816020736523617, 0.17844673049488213, 0.4550863549406125, 0.165705419952426]\n",
      "Layer: Layer 2, Input: [0.9816020736523617, 0.17844673049488213, 0.4550863549406125, 0.165705419952426], Output: [0.5711979402316842]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.7943312432929721, 0.836699261888057, -0.9847929692700057, -0.9678601368691675]\n",
      "Layer: Layer 1, Input: [-0.7943312432929721, 0.836699261888057, -0.9847929692700057, -0.9678601368691675], Output: [0.5667106408023597, 0.38358570086563054, 0.23109472424259578, 0.8108922281326574]\n",
      "Layer: Layer 2, Input: [0.5667106408023597, 0.38358570086563054, 0.23109472424259578, 0.8108922281326574], Output: [0.1702422591226023]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.039205065346939384, -0.8696886816384483, 0.3179271821719162, 0.14970163504939346]\n",
      "Layer: Layer 1, Input: [0.039205065346939384, -0.8696886816384483, 0.3179271821719162, 0.14970163504939346], Output: [-0.4702830600013585, 0.3778645705023528, -0.5977074797918366, -0.28367681528288696]\n",
      "Layer: Layer 2, Input: [-0.4702830600013585, 0.3778645705023528, -0.5977074797918366, -0.28367681528288696], Output: [-0.42162686855514764]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5093195116653937, 0.721169543868964, -0.8414656518215999, -0.9736168069350669]\n",
      "Layer: Layer 1, Input: [0.5093195116653937, 0.721169543868964, -0.8414656518215999, -0.9736168069350669], Output: [0.9323192109404957, 0.32238388444786287, 0.28751812177349384, 0.29510930511472877]\n",
      "Layer: Layer 2, Input: [0.9323192109404957, 0.32238388444786287, 0.28751812177349384, 0.29510930511472877], Output: [0.3565015119019639]\n",
      "Epoch 8/100, Loss: 0.5754859837149262, Accuracy: -1.8209159384338065\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9784434866974245, 0.9600742082243949, -0.8934790133638293, -0.9987702605235615]\n",
      "Layer: Layer 1, Input: [0.9784434866974245, 0.9600742082243949, -0.8934790133638293, -0.9987702605235615], Output: [0.9811741354561891, 0.1532106650530189, 0.46609819603925967, 0.1634412444855359]\n",
      "Layer: Layer 2, Input: [0.9811741354561891, 0.1532106650530189, 0.46609819603925967, 0.1634412444855359], Output: [0.5957725470334555]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8061064463208838, 0.8143594704447191, -0.9846940692372533, -0.9691194809687312]\n",
      "Layer: Layer 1, Input: [-0.8061064463208838, 0.8143594704447191, -0.9846940692372533, -0.9691194809687312], Output: [0.5363670252175302, 0.41310973761061226, 0.1874185274832422, 0.8065775379686493]\n",
      "Layer: Layer 2, Input: [0.5363670252175302, 0.41310973761061226, 0.1874185274832422, 0.8065775379686493], Output: [0.09810859494162943]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.023808326484163436, -0.8724708742739904, 0.32182984169951967, 0.1275666443747098]\n",
      "Layer: Layer 1, Input: [0.023808326484163436, -0.8724708742739904, 0.32182984169951967, 0.1275666443747098], Output: [-0.49666423110152513, 0.40986468512683916, -0.5965497669654506, -0.26414178570062]\n",
      "Layer: Layer 2, Input: [-0.49666423110152513, 0.40986468512683916, -0.5965497669654506, -0.26414178570062], Output: [-0.48297115574391547]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5059271003712724, 0.7232232527168565, -0.8395434460242996, -0.9741539625319375]\n",
      "Layer: Layer 1, Input: [0.5059271003712724, 0.7232232527168565, -0.8395434460242996, -0.9741539625319375], Output: [0.9304174015354866, 0.31211176250787753, 0.2916223699687099, 0.2963578286320796]\n",
      "Layer: Layer 2, Input: [0.9304174015354866, 0.31211176250787753, 0.2916223699687099, 0.2963578286320796], Output: [0.35988013994773177]\n",
      "Epoch 9/100, Loss: 0.5115786452606543, Accuracy: -1.6594847522165264\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9780823388197395, 0.960899256235154, -0.8908933331405327, -0.9988269649636595]\n",
      "Layer: Layer 1, Input: [0.9780823388197395, 0.960899256235154, -0.8908933331405327, -0.9988269649636595], Output: [0.9807231618097643, 0.1243832303463633, 0.47736412419683294, 0.16007934548438718]\n",
      "Layer: Layer 2, Input: [0.9807231618097643, 0.1243832303463633, 0.47736412419683294, 0.16007934548438718], Output: [0.627743579475698]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8175554183509801, 0.7867099747167675, -0.9845964651402486, -0.970194404006623]\n",
      "Layer: Layer 1, Input: [-0.8175554183509801, 0.7867099747167675, -0.9845964651402486, -0.970194404006623], Output: [0.5012897117758643, 0.44023161194078037, 0.1387643189962859, 0.8004181164328835]\n",
      "Layer: Layer 2, Input: [0.5012897117758643, 0.44023161194078037, 0.1387643189962859, 0.8004181164328835], Output: [0.02503979574870041]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.008634477869958263, -0.8753153863841907, 0.3256191081846658, 0.10777449960537251]\n",
      "Layer: Layer 1, Input: [0.008634477869958263, -0.8753153863841907, 0.3256191081846658, 0.10777449960537251], Output: [-0.521127293394333, 0.43867966550089055, -0.5962336628873205, -0.24536174048475956]\n",
      "Layer: Layer 2, Input: [-0.521127293394333, 0.43867966550089055, -0.5962336628873205, -0.24536174048475956], Output: [-0.5423255687099974]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5036407780499355, 0.7246180544513315, -0.8376840445291948, -0.9746162023163277]\n",
      "Layer: Layer 1, Input: [0.5036407780499355, 0.7246180544513315, -0.8376840445291948, -0.9746162023163277], Output: [0.9284890163579814, 0.29852360231874947, 0.29575274052511913, 0.2957558759966667]\n",
      "Layer: Layer 2, Input: [0.9284890163579814, 0.29852360231874947, 0.29575274052511913, 0.2957558759966667], Output: [0.369681944435101]\n",
      "Epoch 10/100, Loss: 0.44901204042946136, Accuracy: -1.485288703127904\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.977855631217746, 0.9615440160973093, -0.8884120153621543, -0.9988742161027591]\n",
      "Layer: Layer 1, Input: [0.977855631217746, 0.9615440160973093, -0.8884120153621543, -0.9988742161027591], Output: [0.9802517157428271, 0.09298698056678492, 0.48853275419256226, 0.15576568026003912]\n",
      "Layer: Layer 2, Input: [0.9802517157428271, 0.09298698056678492, 0.48853275419256226, 0.15576568026003912], Output: [0.6655389080380025]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8283565901293721, 0.7520695369358459, -0.9845015727337733, -0.9711091942138336]\n",
      "Layer: Layer 1, Input: [-0.8283565901293721, 0.7520695369358459, -0.9845015727337733, -0.9711091942138336], Output: [0.4604034572279909, 0.46622993361355614, 0.08371179923272465, 0.7917433395047859]\n",
      "Layer: Layer 2, Input: [0.4604034572279909, 0.46622993361355614, 0.08371179923272465, 0.7917433395047859], Output: [-0.0519200212375332]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.0058539434977368295, -0.8782815927879325, 0.32922915788510093, 0.09030286145269073]\n",
      "Layer: Layer 1, Input: [-0.0058539434977368295, -0.8782815927879325, 0.32922915788510093, 0.09030286145269073], Output: [-0.5434470525294188, 0.4644463544948352, -0.5967875734371497, -0.22780817587334304]\n",
      "Layer: Layer 2, Input: [-0.5434470525294188, 0.4644463544948352, -0.5967875734371497, -0.22780817587334304], Output: [-0.5995814406197225]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5026313457352759, 0.725178986179798, -0.8359188209702552, -0.9750099853154541]\n",
      "Layer: Layer 1, Input: [0.5026313457352759, 0.725178986179798, -0.8359188209702552, -0.9750099853154541], Output: [0.9265533401549043, 0.2823411589348665, 0.29958546339013264, 0.29322247636521037]\n",
      "Layer: Layer 2, Input: [0.9265533401549043, 0.2823411589348665, 0.29958546339013264, 0.29322247636521037], Output: [0.3846636227969886]\n",
      "Epoch 11/100, Loss: 0.38742343699303866, Accuracy: -1.2982960073077532\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9777816519988893, 0.9619860950615192, -0.8860746863071206, -0.9989132556504396]\n",
      "Layer: Layer 1, Input: [0.9777816519988893, 0.9619860950615192, -0.8860746863071206, -0.9989132556504396], Output: [0.9797659662026569, 0.059849055455215065, 0.49950879218344274, 0.15068186577879425]\n",
      "Layer: Layer 2, Input: [0.9797659662026569, 0.059849055455215065, 0.49950879218344274, 0.15068186577879425], Output: [0.7080699233674381]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8382588927408612, 0.7084965727982004, -0.9844103282939293, -0.9718833500489708]\n",
      "Layer: Layer 1, Input: [-0.8382588927408612, 0.7084965727982004, -0.9844103282939293, -0.9718833500489708], Output: [0.41242594497540563, 0.49213748195909535, 0.021051245116575783, 0.7796718786323812]\n",
      "Layer: Layer 2, Input: [0.41242594497540563, 0.49213748195909535, 0.021051245116575783, 0.7796718786323812], Output: [-0.13527029467513346]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.019238936332763478, -0.8813987979205402, 0.3326045901192731, 0.07509316580829309]\n",
      "Layer: Layer 1, Input: [-0.019238936332763478, -0.8813987979205402, 0.3326045901192731, 0.07509316580829309], Output: [-0.5634738248642608, 0.48730624930792515, -0.598186806329555, -0.21188587819106658]\n",
      "Layer: Layer 2, Input: [-0.5634738248642608, 0.48730624930792515, -0.598186806329555, -0.21188587819106658], Output: [-0.654474139528253]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5030134217925141, 0.7247977509266291, -0.8342705213164863, -0.975341237623902]\n",
      "Layer: Layer 1, Input: [0.5030134217925141, 0.7247977509266291, -0.8342705213164863, -0.975341237623902], Output: [0.9246433073597665, 0.2640696329011354, 0.30312120796151554, 0.28876457273266865]\n",
      "Layer: Layer 2, Input: [0.9246433073597665, 0.2640696329011354, 0.30312120796151554, 0.28876457273266865], Output: [0.4041651322506367]\n",
      "Epoch 12/100, Loss: 0.3268469856986416, Accuracy: -1.0980205101785385\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9778689649402467, 0.9622257131626416, -0.8839117175809523, -0.9989451452752536]\n",
      "Layer: Layer 1, Input: [0.9778689649402467, 0.9622257131626416, -0.8839117175809523, -0.9989451452752536], Output: [0.9792766287568835, 0.02567962805320044, 0.5103905958605618, 0.1450465766600514]\n",
      "Layer: Layer 2, Input: [0.9792766287568835, 0.02567962805320044, 0.5103905958605618, 0.1450465766600514], Output: [0.754539342842591]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8470722093417811, 0.6541547654097558, -0.9843231709602545, -0.9725327601455723]\n",
      "Layer: Layer 1, Input: [-0.8470722093417811, 0.6541547654097558, -0.9843231709602545, -0.9725327601455723], Output: [0.3561215987488072, 0.5187075312364053, -0.04980536256463671, 0.7631356929649337]\n",
      "Layer: Layer 2, Input: [0.3561215987488072, 0.5187075312364053, -0.04980536256463671, 0.7631356929649337], Output: [-0.22678121613669466]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.03116252073616963, -0.8846532429563974, 0.33570320201861564, 0.06205757802821403]\n",
      "Layer: Layer 1, Input: [-0.03116252073616963, -0.8846532429563974, 0.33570320201861564, 0.06205757802821403], Output: [-0.5811238027347401, 0.5073864071139452, -0.600344291228059, -0.19790730991167343]\n",
      "Layer: Layer 2, Input: [-0.5811238027347401, 0.5073864071139452, -0.600344291228059, -0.19790730991167343], Output: [-0.706578947854009]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5048362378934222, 0.7234667907461803, -0.8327546131201999, -0.9756154754156615]\n",
      "Layer: Layer 1, Input: [0.5048362378934222, 0.7234667907461803, -0.8327546131201999, -0.9756154754156615], Output: [0.9228109259660722, 0.244070309460396, 0.3066516469103587, 0.28250473404188287]\n",
      "Layer: Layer 2, Input: [0.9228109259660722, 0.244070309460396, 0.3066516469103587, 0.28250473404188287], Output: [0.4279477061738425]\n",
      "Epoch 13/100, Loss: 0.2678644906613562, Accuracy: -0.8841527869928627\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.978114752912556, 0.9622969109851481, -0.8819454449235573, -0.998970807464345]\n",
      "Layer: Layer 1, Input: [0.978114752912556, 0.9622969109851481, -0.8819454449235573, -0.998970807464345], Output: [0.9788000573874281, -0.008848022482318993, 0.5213938849426852, 0.139119853302245]\n",
      "Layer: Layer 2, Input: [0.9788000573874281, -0.008848022482318993, 0.5213938849426852, 0.139119853302245], Output: [0.8042240647273529]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8546568448780265, 0.5882194867428231, -0.984240177161277, -0.9730706944463406]\n",
      "Layer: Layer 1, Input: [-0.8546568448780265, 0.5882194867428231, -0.984240177161277, -0.9730706944463406], Output: [0.2910110706996273, 0.5461899279355312, -0.12794920029720588, 0.7411094884330245]\n",
      "Layer: Layer 2, Input: [0.2910110706996273, 0.5461899279355312, -0.12794920029720588, 0.7411094884330245], Output: [-0.3265931606131672]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.04134169160450009, -0.8879684838951736, 0.33849590190509016, 0.05108212652873262]\n",
      "Layer: Layer 1, Input: [-0.04134169160450009, -0.8879684838951736, 0.33849590190509016, 0.05108212652873262], Output: [-0.5963605602608492, 0.52478373524772, -0.6030950238336721, -0.18606279295583855]\n",
      "Layer: Layer 2, Input: [-0.5963605602608492, 0.52478373524772, -0.6030950238336721, -0.18606279295583855], Output: [-0.7552890562343308]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5080748205723299, 0.7213440172195417, -0.8313810143536537, -0.9758379715600753]\n",
      "Layer: Layer 1, Input: [0.5080748205723299, 0.7213440172195417, -0.8313810143536537, -0.9758379715600753], Output: [0.9211356732852611, 0.22262473900200452, 0.31072235155962746, 0.2747324427332667]\n",
      "Layer: Layer 2, Input: [0.9211356732852611, 0.22262473900200452, 0.31072235155962746, 0.2747324427332667], Output: [0.45602046606945495]\n",
      "Epoch 14/100, Loss: 0.21190054187470525, Accuracy: -0.6578732523556943\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9785038585432202, 0.9622790689548348, -0.8801916583830705, -0.9989910699500476]\n",
      "Layer: Layer 1, Input: [0.9785038585432202, 0.9622790689548348, -0.8801916583830705, -0.9989910699500476], Output: [0.9783581883706209, -0.04299350966053393, 0.5327275877278514, 0.1332026252160445]\n",
      "Layer: Layer 2, Input: [0.9783581883706209, -0.04299350966053393, 0.5327275877278514, 0.1332026252160445], Output: [0.8561737668131977]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8609219874328273, 0.5123328459005781, -0.9841613857006997, -0.9735088275486802]\n",
      "Layer: Layer 1, Input: [-0.8609219874328273, 0.5123328459005781, -0.9841613857006997, -0.9735088275486802], Output: [0.21860653871769867, 0.5739811472500398, -0.20986334849374597, 0.7132161977003232]\n",
      "Layer: Layer 2, Input: [0.21860653871769867, 0.5739811472500398, -0.20986334849374597, 0.7132161977003232], Output: [-0.4318082179376159]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.04958939841627594, -0.8911927588951775, 0.3409651341800419, 0.04202520687205225]\n",
      "Layer: Layer 1, Input: [-0.04958939841627594, -0.8911927588951775, 0.3409651341800419, 0.04202520687205225], Output: [-0.6091801647141384, 0.5395595427462457, -0.6061830846817161, -0.17639314173270998]\n",
      "Layer: Layer 2, Input: [-0.6091801647141384, 0.5395595427462457, -0.6061830846817161, -0.17639314173270998], Output: [-0.7998054879480603]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5126190420744435, 0.7188172593519147, -0.8301559106605712, -0.9760139967339204]\n",
      "Layer: Layer 1, Input: [0.5126190420744435, 0.7188172593519147, -0.8301559106605712, -0.9760139967339204], Output: [0.9197282128684003, 0.20002685611568513, 0.31602345763350836, 0.26595578071616044]\n",
      "Layer: Layer 2, Input: [0.9197282128684003, 0.20002685611568513, 0.31602345763350836, 0.26595578071616044], Output: [0.4883600853233976]\n",
      "Epoch 15/100, Loss: 0.16134528287548186, Accuracy: -0.42385244197772853\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9790087440456373, 0.9622897433903089, -0.8786602760482063, -0.9990067115526219]\n",
      "Layer: Layer 1, Input: [0.9790087440456373, 0.9622897433903089, -0.8786602760482063, -0.9990067115526219], Output: [0.9779749596417315, -0.07584249857355253, 0.5444140944316348, 0.12761652705869206]\n",
      "Layer: Layer 2, Input: [0.9779749596417315, -0.07584249857355253, 0.5444140944316348, 0.12761652705869206], Output: [0.9088627288635044]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8658428495542589, 0.43166259866310647, -0.9840872506915695, -0.9738583958243984]\n",
      "Layer: Layer 1, Input: [-0.8658428495542589, 0.43166259866310647, -0.9840872506915695, -0.9738583958243984], Output: [0.14340500901709816, 0.6005130754418042, -0.28927273198270237, 0.6805817677630038]\n",
      "Layer: Layer 2, Input: [0.14340500901709816, 0.6005130754418042, -0.28927273198270237, 0.6805817677630038], Output: [-0.5358396212907456]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05584706604708775, -0.8941215316657195, 0.3431034095722006, 0.034712259060119065]\n",
      "Layer: Layer 1, Input: [-0.05584706604708775, -0.8941215316657195, 0.3431034095722006, 0.034712259060119065], Output: [-0.6196189376123691, 0.5517633155657113, -0.6092801835522998, -0.16878320670212948]\n",
      "Layer: Layer 2, Input: [-0.6196189376123691, 0.5517633155657113, -0.6092801835522998, -0.16878320670212948], Output: [-0.8392225733495846]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5182603146491573, 0.7164779321104697, -0.8290829173729026, -0.976149117910022]\n",
      "Layer: Layer 1, Input: [0.5182603146491573, 0.7164779321104697, -0.8290829173729026, -0.976149117910022], Output: [0.9187121467896603, 0.1767288799018871, 0.3231250408504796, 0.2568856501190252]\n",
      "Layer: Layer 2, Input: [0.9187121467896603, 0.1767288799018871, 0.3231250408504796, 0.2568856501190252], Output: [0.5244617772478967]\n",
      "Epoch 16/100, Loss: 0.11893421039307109, Accuracy: -0.19161329924826864\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9795916633424581, 0.96244083024313, -0.8773537778372447, -0.9990184968145499]\n",
      "Layer: Layer 1, Input: [0.9795916633424581, 0.96244083024313, -0.8773537778372447, -0.9990184968145499], Output: [0.97766820786193, -0.10630124223756356, 0.5561478500858249, 0.12265179218232476]\n",
      "Layer: Layer 2, Input: [0.97766820786193, -0.10630124223756356, 0.5561478500858249, 0.12265179218232476], Output: [0.9600588657940486]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8694899112394212, 0.3537378808890185, -0.9840188745970428, -0.9741312670086318]\n",
      "Layer: Layer 1, Input: [-0.8694899112394212, 0.3537378808890185, -0.9840188745970428, -0.9741312670086318], Output: [0.07194759856157489, 0.623866806375076, -0.3593603867968043, 0.6460787822853515]\n",
      "Layer: Layer 2, Input: [0.07194759856157489, 0.623866806375076, -0.3593603867968043, 0.6460787822853515], Output: [-0.6304725539657832]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06021708459707016, -0.8965724359029701, 0.34491400948246237, 0.028931740614784162]\n",
      "Layer: Layer 1, Input: [-0.06021708459707016, -0.8965724359029701, 0.34491400948246237, 0.028931740614784162], Output: [-0.6277935678041903, 0.5614970640846737, -0.6120650328915331, -0.16299604423049888]\n",
      "Layer: Layer 2, Input: [-0.6277935678041903, 0.5614970640846737, -0.6120650328915331, -0.16299604423049888], Output: [-0.8727914196614294]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5246901070674863, 0.7149152990971754, -0.8281623774425064, -0.9762494157125727]\n",
      "Layer: Layer 1, Input: [0.5246901070674863, 0.7149152990971754, -0.8281623774425064, -0.9762494157125727], Output: [0.9181731420030983, 0.15348300978100624, 0.33210946163858573, 0.24827720215551757]\n",
      "Layer: Layer 2, Input: [0.9181731420030983, 0.15348300978100624, 0.33210946163858573, 0.24827720215551757], Output: [0.5629011945526206]\n",
      "Epoch 17/100, Loss: 0.08634580405237738, Accuracy: 0.026224033973881733\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9802109981321226, 0.962782286412586, -0.8762636231286147, -0.9990271775079389]\n",
      "Layer: Layer 1, Input: [0.9802109981321226, 0.962782286412586, -0.8762636231286147, -0.9990271775079389], Output: [0.9774419616544914, -0.13330689469031365, 0.5673635687821159, 0.1185026642459174]\n",
      "Layer: Layer 2, Input: [0.9774419616544914, -0.13330689469031365, 0.5673635687821159, 0.1185026642459174], Output: [1.0072488949252185]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.872035329879122, 0.28501328612490356, -0.9839576015623129, -0.9743402854322681]\n",
      "Layer: Layer 1, Input: [-0.872035329879122, 0.28501328612490356, -0.9839576015623129, -0.9743402854322681], Output: [0.009765913985424585, 0.6428386461006577, -0.4161212224905352, 0.613158280757753]\n",
      "Layer: Layer 2, Input: [0.009765913985424585, 0.6428386461006577, -0.4161212224905352, 0.613158280757753], Output: [-0.7099219158748419]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06295665246168886, -0.8984677202924284, 0.34641419778243504, 0.02444187256113494]\n",
      "Layer: Layer 1, Input: [-0.06295665246168886, -0.8984677202924284, 0.34641419778243504, 0.02444187256113494], Output: [-0.6339400327247819, 0.5689810144191169, -0.614330003588637, -0.1587374185580672]\n",
      "Layer: Layer 2, Input: [-0.6339400327247819, 0.5689810144191169, -0.614330003588637, -0.1587374185580672], Output: [-0.9002582601240573]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5315397786464688, 0.7144381629773685, -0.8273886039361754, -0.9763213685138159]\n",
      "Layer: Layer 1, Input: [0.5315397786464688, 0.7144381629773685, -0.8273886039361754, -0.9763213685138159], Output: [0.918107776921883, 0.13129893863662612, 0.3424193789094715, 0.24068760247832444]\n",
      "Layer: Layer 2, Input: [0.918107776921883, 0.13129893863662612, 0.3424193789094715, 0.24068760247832444], Output: [0.6014016226660577]\n",
      "Epoch 18/100, Loss: 0.06325673061352281, Accuracy: 0.20433290373973834\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9808305056335545, 0.9632909337267052, -0.8753684916779668, -0.9990334542364714]\n",
      "Layer: Layer 1, Input: [0.9808305056335545, 0.9632909337267052, -0.8753684916779668, -0.9990334542364714], Output: [0.9772866960279849, -0.1561593310749505, 0.5775095327063416, 0.11523752161403177]\n",
      "Layer: Layer 2, Input: [0.9772866960279849, -0.1561593310749505, 0.5775095327063416, 0.11523752161403177], Output: [1.0484548095047608]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8737098324910747, 0.22836233800482214, -0.9839042282692692, -0.9744984573916688]\n",
      "Layer: Layer 1, Input: [-0.8737098324910747, 0.22836233800482214, -0.9839042282692692, -0.9744984573916688], Output: [-0.04086620157935109, 0.6573959244905774, -0.45946117832838623, 0.5842263646798156]\n",
      "Layer: Layer 2, Input: [-0.04086620157935109, 0.6573959244905774, -0.45946117832838623, 0.5842263646798156], Output: [-0.7728948617633211]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06440891611162065, -0.8998464590545237, 0.3476366207428338, 0.020992651262053342]\n",
      "Layer: Layer 1, Input: [-0.06440891611162065, -0.8998464590545237, 0.3476366207428338, 0.020992651262053342], Output: [-0.6383938740546066, 0.5745506669840476, -0.6160225240503066, -0.1557117729672396]\n",
      "Layer: Layer 2, Input: [-0.6383938740546066, 0.5745506669840476, -0.6160225240503066, -0.1557117729672396], Output: [-0.9219816990485172]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.538463830364965, 0.7149959803739987, -0.8267478338903534, -0.976371312349594]\n",
      "Layer: Layer 1, Input: [0.538463830364965, 0.7149959803739987, -0.8267478338903534, -0.976371312349594], Output: [0.9184278121930726, 0.11114191551434215, 0.35315403620193536, 0.23435138045689338]\n",
      "Layer: Layer 2, Input: [0.9184278121930726, 0.11114191551434215, 0.35315403620193536, 0.23435138045689338], Output: [0.6375907935410776]\n",
      "Epoch 19/100, Loss: 0.04783797514679641, Accuracy: 0.2840125448481552\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9814257763776788, 0.9639084436330825, -0.8746378390032217, -0.9990379280485162]\n",
      "Layer: Layer 1, Input: [0.9814257763776788, 0.9639084436330825, -0.8746378390032217, -0.9990379280485162], Output: [0.9771866025480428, -0.17469491637637335, 0.586272557752107, 0.11281987701673858]\n",
      "Layer: Layer 2, Input: [0.9771866025480428, -0.17469491637637335, 0.586272557752107, 0.11281987701673858], Output: [1.0827613906422087]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8747394650072644, 0.18347572805194465, -0.9838586230185395, -0.9746175927284518]\n",
      "Layer: Layer 1, Input: [-0.8747394650072644, 0.18347572805194465, -0.9838586230185395, -0.9746175927284518], Output: [-0.08051656502680389, 0.6682545043995766, -0.4916115493362265, 0.5601289514790261]\n",
      "Layer: Layer 2, Input: [-0.08051656502680389, 0.6682545043995766, -0.4916115493362265, 0.5601289514790261], Output: [-0.8212903914877574]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06491240269064574, -0.9008089539096784, 0.34862463456870335, 0.01835280606601406]\n",
      "Layer: Layer 1, Input: [-0.06491240269064574, -0.9008089539096784, 0.34862463456870335, 0.01835280606601406], Output: [-0.641517422648943, 0.5785858242525425, -0.6171979666673441, -0.1536513110999426]\n",
      "Layer: Layer 2, Input: [-0.641517422648943, 0.5785858242525425, -0.6171979666673441, -0.1536513110999426], Output: [-0.9387358277213627]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5452123867520052, 0.7163382714323219, -0.8262199437881128, -0.9764048050880195]\n",
      "Layer: Layer 1, Input: [0.5452123867520052, 0.7163382714323219, -0.8262199437881128, -0.9764048050880195], Output: [0.9190135361904349, 0.09361774541010473, 0.36352226611713606, 0.229245358163375]\n",
      "Layer: Layer 2, Input: [0.9190135361904349, 0.09361774541010473, 0.36352226611713606, 0.229245358163375], Output: [0.6698105428657228]\n",
      "Epoch 20/100, Loss: 0.03789123709081162, Accuracy: 0.3470753714326342\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9819845500095596, 0.9645795336328429, -0.8740385835061835, -0.9990410778618093]\n",
      "Layer: Layer 1, Input: [0.9819845500095596, 0.9645795336328429, -0.8740385835061835, -0.9990410778618093], Output: [0.9771263391478754, -0.18919988654846867, 0.5936032189673637, 0.11115190574580866]\n",
      "Layer: Layer 2, Input: [0.9771263391478754, -0.18919988654846867, 0.5936032189673637, 0.11115190574580866], Output: [1.1102465886983404]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8753077035302675, 0.14855235088999794, -0.9838199467914583, -0.9747074367657724]\n",
      "Layer: Layer 1, Input: [-0.8753077035302675, 0.14855235088999794, -0.9838199467914583, -0.9747074367657724], Output: [-0.11101975730745696, 0.6762976140164344, -0.515273754195213, 0.5406485707812078]\n",
      "Layer: Layer 2, Input: [-0.11101975730745696, 0.6762976140164344, -0.515273754195213, 0.5406485707812078], Output: [-0.8580490730442688]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06474628368877057, -0.9014607034540033, 0.3494241560266373, 0.016326898530693204]\n",
      "Layer: Layer 1, Input: [-0.06474628368877057, -0.9014607034540033, 0.3494241560266373, 0.016326898530693204], Output: [-0.6436357761117989, 0.5814397595598247, -0.6179517389652683, -0.15232739023274036]\n",
      "Layer: Layer 2, Input: [-0.6436357761117989, 0.5814397595598247, -0.6179517389652683, -0.15232739023274036], Output: [-0.9514259889433098]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5516479060631722, 0.7181956166463941, -0.8257827792641659, -0.9764262992247464]\n",
      "Layer: Layer 1, Input: [0.5516479060631722, 0.7181956166463941, -0.8257827792641659, -0.9764262992247464], Output: [0.919760073614049, 0.07889322273890685, 0.37306046000357723, 0.22521908355857762]\n",
      "Layer: Layer 2, Input: [0.919760073614049, 0.07889322273890685, 0.37306046000357723, 0.22521908355857762], Output: [0.6973649865764469]\n",
      "Epoch 21/100, Loss: 0.0315629404708055, Accuracy: 0.39659345986568506\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9825032239001944, 0.965266296511319, -0.8735404723097381, -0.9990432676854488]\n",
      "Layer: Layer 1, Input: [0.9825032239001944, 0.965266296511319, -0.8735404723097381, -0.9990432676854488], Output: [0.9770938402749247, -0.20020735020559174, 0.599623245495447, 0.11011235397842274]\n",
      "Layer: Layer 2, Input: [0.9770938402749247, -0.20020735020559174, 0.599623245495447, 0.11011235397842274], Output: [1.1316021723512055]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8755494409601011, 0.12152888110744421, -0.9837870629450564, -0.9747755604483395]\n",
      "Layer: Layer 1, Input: [-0.8755494409601011, 0.12152888110744421, -0.9837870629450564, -0.9747755604483395], Output: [-0.13436467782057496, 0.6822811480782349, -0.5327397329973497, 0.5251232156885043]\n",
      "Layer: Layer 2, Input: [-0.13436467782057496, 0.6822811480782349, -0.5327397329973497, 0.5251232156885043], Output: [-0.8859280606048607]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.0641197545471103, -0.9018876631553113, 0.35007723567802024, 0.014759141957180486]\n",
      "Layer: Layer 1, Input: [-0.0641197545471103, -0.9018876631553113, 0.35007723567802024, 0.014759141957180486], Output: [-0.6450114120437848, 0.5834062208037035, -0.6183785603642266, -0.1515529753988538]\n",
      "Layer: Layer 2, Input: [-0.6450114120437848, 0.5834062208037035, -0.6183785603642266, -0.1515529753988538], Output: [-0.9609047561958697]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5577195230406454, 0.7203605948917914, -0.8254158735804024, -0.9764391668196035]\n",
      "Layer: Layer 1, Input: [0.5577195230406454, 0.7203605948917914, -0.8254158735804024, -0.9764391668196035], Output: [0.9205929661395497, 0.06681052163547455, 0.38160245268312604, 0.22208756153412418]\n",
      "Layer: Layer 2, Input: [0.9205929661395497, 0.06681052163547455, 0.38160245268312604, 0.22208756153412418], Output: [0.7203029056025829]\n",
      "Epoch 22/100, Loss: 0.02752261045684669, Accuracy: 0.4355335500521078\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9829830101361006, 0.9659470012118175, -0.8731184949654068, -0.99904476771402]\n",
      "Layer: Layer 1, Input: [0.9829830101361006, 0.9659470012118175, -0.8731184949654068, -0.99904476771402], Output: [0.9770804610756572, -0.20832306146770013, 0.6045278943257938, 0.10958033028955098]\n",
      "Layer: Layer 2, Input: [0.9770804610756572, -0.20832306146770013, 0.6045278943257938, 0.10958033028955098], Output: [1.1477725896405417]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8755599359778833, 0.10059226738033536, -0.9837588322167334, -0.9748276700606631]\n",
      "Layer: Layer 1, Input: [-0.8755599359778833, 0.10059226738033536, -0.9837588322167334, -0.9748276700606631], Output: [-0.15225401878726835, 0.686771928132813, -0.5457239388880053, 0.5128117589458888]\n",
      "Layer: Layer 2, Input: [-0.15225401878726835, 0.686771928132813, -0.5457239388880053, 0.5128117589458888], Output: [-0.9071368873081331]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06318315589733994, -0.9021531307853385, 0.3506191280271687, 0.013529362524531543]\n",
      "Layer: Layer 1, Input: [-0.06318315589733994, -0.9021531307853385, 0.3506191280271687, 0.013529362524531543], Output: [-0.6458456046570393, 0.5847158595314802, -0.6185580608784516, -0.1511797894271485]\n",
      "Layer: Layer 2, Input: [-0.6458456046570393, 0.5847158595314802, -0.6185580608784516, -0.1511797894271485], Output: [-0.9678992873432244]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5634281294356798, 0.7226951826718135, -0.8251022036517385, -0.9764458925662647]\n",
      "Layer: Layer 1, Input: [0.5634281294356798, 0.7226951826718135, -0.8251022036517385, -0.9764458925662647], Output: [0.9214648535253231, 0.057043299059607366, 0.3891663592012815, 0.21967522148165552]\n",
      "Layer: Layer 2, Input: [0.9214648535253231, 0.057043299059607366, 0.3891663592012815, 0.21967522148165552], Output: [0.739087723358797]\n",
      "Epoch 23/100, Loss: 0.024891491950765704, Accuracy: 0.4663513083696128\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.983427236100403, 0.9666107563463432, -0.8727531406053624, -0.9990457765088074]\n",
      "Layer: Layer 1, Input: [0.983427236100403, 0.9666107563463432, -0.8727531406053624, -0.9990457765088074], Output: [0.977080227413715, -0.21412264005899245, 0.6085237700582798, 0.10944723369189098]\n",
      "Layer: Layer 2, Input: [0.977080227413715, -0.21412264005899245, 0.6085237700582798, 0.10944723369189098], Output: [1.1597247971068876]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8754059534812146, 0.08429577813628779, -0.9837342527006656, -0.9748680122691339]\n",
      "Layer: Layer 1, Input: [-0.8754059534812146, 0.08429577813628779, -0.9837342527006656, -0.9748680122691339], Output: [-0.16602279929949293, 0.6901753853655258, -0.5554533540071382, 0.5030452043183128]\n",
      "Layer: Layer 2, Input: [-0.16602279929949293, 0.6901753853655258, -0.5554533540071382, 0.5030452043183128], Output: [-0.9233480338342659]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06204315120011454, -0.9023021035191792, 0.35107788957963143, 0.012546490334369526]\n",
      "Layer: Layer 1, Input: [-0.06204315120011454, -0.9023021035191792, 0.35107788957963143, 0.012546490334369526], Output: [-0.6462893344030286, 0.5855448606246483, -0.6185530030695731, -0.15109287638767013]\n",
      "Layer: Layer 2, Input: [-0.6462893344030286, 0.5855448606246483, -0.6185530030695731, -0.15109287638767013], Output: [-0.973000021871655]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5687995561041636, 0.7251134961858604, -0.824828439371683, -0.9764482876067638]\n",
      "Layer: Layer 1, Input: [0.5687995561041636, 0.7251134961858604, -0.824828439371683, -0.9764482876067638], Output: [0.9223472969162275, 0.04921334113654951, 0.3958575510363575, 0.21783130559689176]\n",
      "Layer: Layer 2, Input: [0.9223472969162275, 0.04921334113654951, 0.3958575510363575, 0.21783130559689176], Output: [0.7543432098357656]\n",
      "Epoch 24/100, Loss: 0.023115948025158754, Accuracy: 0.49096646843479896\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.983839824061405, 0.9672529062533075, -0.8724296708771896, -0.9990464393708157]\n",
      "Layer: Layer 1, Input: [0.983839824061405, 0.9672529062533075, -0.8724296708771896, -0.9990464393708157], Output: [0.9770890411860426, -0.21810623438804183, 0.6117986905396481, 0.10962114603013264]\n",
      "Layer: Layer 2, Input: [0.9770890411860426, -0.21810623438804183, 0.6117986905396481, 0.10962114603013264], Output: [1.1683337959864695]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8751346504146691, 0.07152846525250776, -0.9837125004388974, -0.9748997330818256]\n",
      "Layer: Layer 1, Input: [-0.8751346504146691, 0.07152846525250776, -0.9837125004388974, -0.9748997330818256], Output: [-0.1766825428981646, 0.6927785927245027, -0.5627977488229211, 0.49526877148120846]\n",
      "Layer: Layer 2, Input: [-0.1766825428981646, 0.6927785927245027, -0.5627977488229211, 0.49526877148120846], Output: [-0.9358050058707681]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.06077534675464292, -0.9023664033779548, 0.3514751691898253, 0.011742234976459544]\n",
      "Layer: Layer 1, Input: [-0.06077534675464292, -0.9023664033779548, 0.3514751691898253, 0.011742234976459544], Output: [-0.6464548827243413, 0.5860260047505385, -0.6184115837477396, -0.15120458971146408]\n",
      "Layer: Layer 2, Input: [-0.6464548827243413, 0.5860260047505385, -0.6184115837477396, -0.15120458971146408], Output: [-0.9766737059209889]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5738683866041203, 0.727563518637089, -0.824584484202651, -0.9764476672383982]\n",
      "Layer: Layer 1, Input: [0.5738683866041203, 0.727563518637089, -0.824584484202651, -0.9764476672383982], Output: [0.9232237407093239, 0.04295683238063575, 0.4018089808161566, 0.21643242248479255]\n",
      "Layer: Layer 2, Input: [0.9232237407093239, 0.04295683238063575, 0.4018089808161566, 0.21643242248479255], Output: [0.766703976339101]\n",
      "Epoch 25/100, Loss: 0.02185710369847842, Accuracy: 0.5108488921443886\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9842245630143509, 0.967872053561828, -0.8721371429774912, -0.9990468623037146]\n",
      "Layer: Layer 1, Input: [0.9842245630143509, 0.967872053561828, -0.8721371429774912, -0.9990468623037146], Output: [0.9771040731965669, -0.220686945850332, 0.6145110121791648, 0.11002712296419878]\n",
      "Layer: Layer 2, Input: [0.9771040731965669, -0.220686945850332, 0.6145110121791648, 0.11002712296419878], Output: [1.174340718026095]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8747797660900517, 0.06144936901345875, -0.9836929226106397, -0.9749251591098969]\n",
      "Layer: Layer 1, Input: [-0.8747797660900517, 0.06144936901345875, -0.9836929226106397, -0.9749251591098969], Output: [-0.18499080335380952, 0.694786026059275, -0.5683767916572064, 0.4890399437120535]\n",
      "Layer: Layer 2, Input: [-0.18499080335380952, 0.694786026059275, -0.5683767916572064, 0.4890399437120535], Output: [-0.9454302916048083]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05943340609578337, -0.9023687088346483, 0.35182735474043697, 0.011065782829290573]\n",
      "Layer: Layer 1, Input: [-0.05943340609578337, -0.9023687088346483, 0.35182735474043697, 0.011065782829290573], Output: [-0.6464254250712419, 0.5862586034201624, -0.6181704192433932, -0.15144903895229456]\n",
      "Layer: Layer 2, Input: [-0.6464254250712419, 0.5862586034201624, -0.6181704192433932, -0.15144903895229456], Output: [-0.9792832427639886]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5786696139569222, 0.7300138975959318, -0.8243628237109099, -0.9764449846804821]\n",
      "Layer: Layer 1, Input: [0.5786696139569222, 0.7300138975959318, -0.8243628237109099, -0.9764449846804821], Output: [0.9240847448291866, 0.03795421046748498, 0.40715074288469066, 0.2153801554814171]\n",
      "Layer: Layer 2, Input: [0.9240847448291866, 0.03795421046748498, 0.40715074288469066, 0.2153801554814171], Output: [0.7767434658020687]\n",
      "Epoch 26/100, Loss: 0.020911300782159633, Accuracy: 0.5271162821447706\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9845848231878312, 0.9684683651743834, -0.8718675047272789, -0.9990471223241494]\n",
      "Layer: Layer 1, Input: [0.9845848231878312, 0.9684683651743834, -0.8718675047272789, -0.9990471223241494], Output: [0.9771233469303111, -0.22219565598864796, 0.6167887122905691, 0.11060556233772185]\n",
      "Layer: Layer 2, Input: [0.9771233469303111, -0.22219565598864796, 0.6167887122905691, 0.11060556233772185], Output: [1.1783490779199266]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8743657521914261, 0.05342434952478379, -0.9836750132524977, -0.9749460085966724]\n",
      "Layer: Layer 1, Input: [-0.8743657521914261, 0.05342434952478379, -0.9836750132524977, -0.9749460085966724], Output: [-0.19151387522548521, 0.6963450798123116, -0.5726365903974664, 0.48401236998628017]\n",
      "Layer: Layer 2, Input: [-0.19151387522548521, 0.6963450798123116, -0.5726365903974664, 0.48401236998628017], Output: [-0.9529106014613136]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05805536726504274, -0.9023253786390156, 0.3521466921355368, 0.010479596365581368]\n",
      "Layer: Layer 1, Input: [-0.05805536726504274, -0.9023253786390156, 0.3521466921355368, 0.010479596365581368], Output: [-0.6462623696864518, 0.5863165106968334, -0.6178571915450797, -0.15177735747952653]\n",
      "Layer: Layer 2, Input: [-0.6462623696864518, 0.5863165106968334, -0.6178571915450797, -0.15177735747952653], Output: [-0.9811075079781697]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5832349936963934, 0.7324455981707702, -0.8241579134495212, -0.976440928535333]\n",
      "Layer: Layer 1, Input: [0.5832349936963934, 0.7324455981707702, -0.8241579134495212, -0.976440928535333], Output: [0.9249250556306452, 0.03393887098488542, 0.41199723421573625, 0.21459717058549369]\n",
      "Layer: Layer 2, Input: [0.9249250556306452, 0.03393887098488542, 0.41199723421573625, 0.21459717058549369], Output: [0.7849480028035589]\n",
      "Epoch 27/100, Loss: 0.02015752320064908, Accuracy: 0.5406170343231156\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9849234896185401, 0.9690426807392158, -0.8716148585276897, -0.9990472750345586]\n",
      "Layer: Layer 1, Input: [0.9849234896185401, 0.9690426807392158, -0.8716148585276897, -0.9990472750345586], Output: [0.9771454638838288, -0.22289226204390522, 0.6187326014788448, 0.11130988035531482]\n",
      "Layer: Layer 2, Input: [0.9771454638838288, -0.22289226204390522, 0.6187326014788448, 0.11130988035531482], Output: [1.1808381842965519]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8739105168550446, 0.04697489751688006, -0.9836583856029194, -0.9749635477702769]\n",
      "Layer: Layer 1, Input: [-0.8739105168550446, 0.04697489751688006, -0.9836583856029194, -0.9749635477702769], Output: [-0.19667601147503694, 0.69756341501408, -0.5759020528410779, 0.47991748904286907]\n",
      "Layer: Layer 2, Input: [-0.19667601147503694, 0.69756341501408, -0.5759020528410779, 0.47991748904286907], Output: [-0.9587596762656493]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05666801772289109, -0.9022483600850918, 0.35244224167045074, 0.009956163645750506]\n",
      "Layer: Layer 1, Input: [-0.05666801772289109, -0.9022483600850918, 0.35244224167045074, 0.009956163645750506], Output: [-0.6460108437001743, 0.5862543334931142, -0.6174927645372726, -0.15215382977563324]\n",
      "Layer: Layer 2, Input: [-0.6460108437001743, 0.5862543334931142, -0.6174927645372726, -0.15215382977563324], Output: [-0.9823588086607847]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5875918842791641, 0.7348469241716713, -0.8239656783466217, -0.9764359934140417]\n",
      "Layer: Layer 1, Input: [0.5875918842791641, 0.7348469241716713, -0.8239656783466217, -0.9764359934140417], Output: [0.9257418823101691, 0.030695284221219626, 0.4164435612236457, 0.21402323627967262]\n",
      "Layer: Layer 2, Input: [0.9257418823101691, 0.030695284221219626, 0.4164435612236457, 0.21402323627967262], Output: [0.791714746751901]\n",
      "Epoch 28/100, Loss: 0.01952429288846981, Accuracy: 0.5519950473817832\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9852429913780236, 0.9695960727848061, -0.8713748963845124, -0.9990473602040814]\n",
      "Layer: Layer 1, Input: [0.9852429913780236, 0.9695960727848061, -0.8713748963845124, -0.9990473602040814], Output: [0.9771694235262706, -0.22297828440735915, 0.6204208127123263, 0.11210412689142968]\n",
      "Layer: Layer 2, Input: [0.9771694235262706, -0.22297828440735915, 0.6204208127123263, 0.11210412689142968], Output: [1.1821824100615423]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.873427273278222, 0.04173902903309964, -0.9836427467462684, -0.9749787066065116]\n",
      "Layer: Layer 1, Input: [-0.873427273278222, 0.04173902903309964, -0.9836427467462684, -0.9749787066065116], Output: [-0.20079621797390199, 0.6985206496768508, -0.5784124273308097, 0.4765479816547431]\n",
      "Layer: Layer 2, Input: [-0.20079621797390199, 0.6985206496768508, -0.5784124273308097, 0.4765479816547431], Output: [-0.9633637243159455]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05528996997024283, -0.9021464743926089, 0.35272064783915114, 0.00947550866320743]\n",
      "Layer: Layer 1, Input: [-0.05528996997024283, -0.9021464743926089, 0.35272064783915114, 0.00947550866320743], Output: [-0.6457037831428767, 0.5861121754627228, -0.6170928186666074, -0.15255279340252673]\n",
      "Layer: Layer 2, Input: [-0.6457037831428767, 0.5861121754627228, -0.6170928186666074, -0.15255279340252673], Output: [-0.9831974450994924]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5917632686320088, 0.7372106187134777, -0.8237831276998046, -0.9764305313679784]\n",
      "Layer: Layer 1, Input: [0.5917632686320088, 0.7372106187134777, -0.8237831276998046, -0.9764305313679784], Output: [0.9265338981812155, 0.028052675574466744, 0.42056627223548876, 0.21361168254699756]\n",
      "Layer: Layer 2, Input: [0.9265338981812155, 0.028052675574466744, 0.42056627223548876, 0.21361168254699756], Output: [0.7973604038269249]\n",
      "Epoch 29/100, Loss: 0.018969444755050385, Accuracy: 0.5617391631808204\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9855453643895132, 0.9701296451900336, -0.8711444778426162, -0.9990474059038255]\n",
      "Layer: Layer 1, Input: [0.9855453643895132, 0.9701296451900336, -0.8711444778426162, -0.9990474059038255], Output: [0.9771945041936816, -0.2226086017385578, 0.6219132642275763, 0.11296082636087335]\n",
      "Layer: Layer 2, Input: [0.9771945041936816, -0.2226086017385578, 0.6219132642275763, 0.11296082636087335], Output: [1.1826708121689948]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8729258117569647, 0.03744204442552453, -0.9836278763204043, -0.9749921648138077]\n",
      "Layer: Layer 1, Input: [-0.8729258117569647, 0.03744204442552453, -0.9836278763204043, -0.9749921648138077], Output: [-0.20411532174969152, 0.6992763020440386, -0.580345604215762, 0.47374409298255354]\n",
      "Layer: Layer 2, Input: [-0.20411532174969152, 0.6992763020440386, -0.580345604215762, 0.47374409298255354], Output: [-0.9670143056258692]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05393386476287771, -0.9020262923889907, 0.35298674027240823, 0.009023294044026119]\n",
      "Layer: Layer 1, Input: [-0.05393386476287771, -0.9020262923889907, 0.35298674027240823, 0.009023294044026119], Output: [-0.6453649940838863, 0.5859192420935344, -0.6166690991797976, -0.15295619660102086]\n",
      "Layer: Layer 2, Input: [-0.6453649940838863, 0.5859192420935344, -0.6166690991797976, -0.15295619660102086], Output: [-0.9837435004675369]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5957682557478553, 0.7395321825325327, -0.8236080674978602, -0.9764247896253189]\n",
      "Layer: Layer 1, Input: [0.5957682557478553, 0.7395321825325327, -0.8236080674978602, -0.9764247896253189], Output: [0.9273006609301487, 0.025877492555541823, 0.42442579544939973, 0.21332644543080698]\n",
      "Layer: Layer 2, Input: [0.9273006609301487, 0.025877492555541823, 0.42442579544939973, 0.21332644543080698], Output: [0.802133636475953]\n",
      "Epoch 30/100, Loss: 0.018468013310775758, Accuracy: 0.5702206304003643\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.985832319254431, 0.9706444509164699, -0.8709213184759103, -0.9990474315853289]\n",
      "Layer: Layer 1, Input: [0.985832319254431, 0.9706444509164699, -0.8709213184759103, -0.9990474315853289], Output: [0.9772201829195557, -0.22190149937308493, 0.6232555826292234, 0.11385914542240008]\n",
      "Layer: Layer 2, Input: [0.9772201829195557, -0.22190149937308493, 0.6232555826292234, 0.11385914542240008], Output: [1.182524734824857]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8724133950847212, 0.03387479522787418, -0.9836136094052942, -0.9750044159369661]\n",
      "Layer: Layer 1, Input: [-0.8724133950847212, 0.03387479522787418, -0.9836136094052942, -0.9750044159369661], Output: [-0.20681583312832924, 0.6998752721297314, -0.5818349576219339, 0.4713827550028406]\n",
      "Layer: Layer 2, Input: [-0.20681583312832924, 0.6998752721297314, -0.5818349576219339, 0.4713827550028406], Output: [-0.9699323002922551]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05260797601544618, -0.901892741518437, 0.3532439949501664, 0.008589379836197173]\n",
      "Layer: Layer 1, Input: [-0.05260797601544618, -0.901892741518437, 0.3532439949501664, 0.008589379836197173], Output: [-0.6450114548516133, 0.58569657535886, -0.6162303663057711, -0.15335169343269003]\n",
      "Layer: Layer 2, Input: [-0.6450114548516133, 0.58569657535886, -0.6162303663057711, -0.15335169343269003], Output: [-0.9840862107235109]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5996227147127755, 0.7418088880417194, -0.8234388882373818, -0.9764189384673929]\n",
      "Layer: Layer 1, Input: [0.5996227147127755, 0.7418088880417194, -0.8234388882373818, -0.9764189384673929], Output: [0.9280422712655944, 0.024066181992318903, 0.4280692915370345, 0.21313968472955075]\n",
      "Layer: Layer 2, Input: [0.9280422712655944, 0.024066181992318903, 0.4280692915370345, 0.21313968472955075], Output: [0.8062276977133168]\n",
      "Epoch 31/100, Loss: 0.018005074802804437, Accuracy: 0.5777214739042257\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9861053025029827, 0.9711414660019074, -0.8707037610249686, -0.9990474503790902]\n",
      "Layer: Layer 1, Input: [0.9861053025029827, 0.9711414660019074, -0.8707037610249686, -0.9990474503790902], Output: [0.9772460803544409, -0.22094689407467455, 0.624482347787519, 0.11478339655427887]\n",
      "Layer: Layer 2, Input: [0.9772460803544409, -0.22094689407467455, 0.624482347787519, 0.11478339655427887], Output: [1.1819126284203032]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8718954021823961, 0.03087752321738638, -0.9835998231056547, -0.9750158152865943]\n",
      "Layer: Layer 1, Input: [-0.8718954021823961, 0.03087752321738638, -0.9835998231056547, -0.9750158152865943], Output: [-0.20903656533010875, 0.7003516919726486, -0.5829811966505851, 0.46936909895591833]\n",
      "Layer: Layer 2, Input: [-0.20903656533010875, 0.7003516919726486, -0.5829811966505851, 0.46936909895591833], Output: [-0.9722855299181563]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.051317394503086075, -0.9017495345893786, 0.3534948845739942, 0.00816673185696185]\n",
      "Layer: Layer 1, Input: [-0.051317394503086075, -0.9017495345893786, 0.3534948845739942, 0.00816673185696185], Output: [-0.6446550538190429, 0.585459125948466, -0.6157831182927562, -0.15373117138938847]\n",
      "Layer: Layer 2, Input: [-0.6446550538190429, 0.585459125948466, -0.6157831182927562, -0.15373117138938847], Output: [-0.984291316142434]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6033398846626774, 0.7440391875826324, -0.8232744091950754, -0.9764130919199769]\n",
      "Layer: Layer 1, Input: [0.6033398846626774, 0.7440391875826324, -0.8232744091950754, -0.9764130919199769], Output: [0.9287591671292396, 0.02253888978355751, 0.4315333428214183, 0.21302990323881876]\n",
      "Layer: Layer 2, Input: [0.9287591671292396, 0.02253888978355751, 0.4315333428214183, 0.21302990323881876], Output: [0.8097917808673216]\n",
      "Epoch 32/100, Loss: 0.017571556401215667, Accuracy: 0.5844559985076088\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9863655477645354, 0.971621587930476, -0.870490607415582, -0.9990474708125809]\n",
      "Layer: Layer 1, Input: [0.9863655477645354, 0.971621587930476, -0.870490607415582, -0.9990474708125809], Output: [0.9772719221363386, -0.21981288747411118, 0.6256196854414816, 0.11572184550145305]\n",
      "Layer: Layer 2, Input: [0.9772719221363386, -0.21981288747411118, 0.6256196854414816, 0.11572184550145305], Output: [1.1809620718587226]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8713757989867444, 0.028327805810908484, -0.9835864261859156, -0.9750266158360403]\n",
      "Layer: Layer 1, Input: [-0.8713757989867444, 0.028327805810908484, -0.9835864261859156, -0.9750266158360403], Output: [-0.21088345069501488, 0.7007316769246614, -0.5838608293625736, 0.4676298973984821]\n",
      "Layer: Layer 2, Input: [-0.21088345069501488, 0.7007316769246614, -0.5838608293625736, 0.4676298973984821], Output: [-0.9742018182575579]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.05006490773140654, -0.901599478023014, 0.35374114292319897, 0.007750597322816606]\n",
      "Layer: Layer 1, Input: [-0.05006490773140654, -0.901599478023014, 0.35374114292319897, 0.007750597322816606], Output: [-0.6443039035800383, 0.5852173216037939, -0.6153321417435533, -0.15408962242151744]\n",
      "Layer: Layer 2, Input: [-0.6443039035800383, 0.5852173216037939, -0.6153321417435533, -0.15408962242151744], Output: [-0.9844067739974568]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6069309014579594, 0.7462223458963589, -0.8231137642485364, -0.9764073231503366]\n",
      "Layer: Layer 1, Input: [0.6069309014579594, 0.7462223458963589, -0.8231137642485364, -0.9764073231503366], Output: [0.9294519958725305, 0.021234238960615187, 0.43484626278144756, 0.21298048121624155]\n",
      "Layer: Layer 2, Input: [0.9294519958725305, 0.021234238960615187, 0.43484626278144756, 0.21298048121624155], Output: [0.8129405863955116]\n",
      "Epoch 33/100, Loss: 0.017161797636959752, Accuracy: 0.5905871067918037\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9866141168816703, 0.9720856430102461, -0.8702809953942287, -0.9990474980934045]\n",
      "Layer: Layer 1, Input: [0.9866141168816703, 0.9720856430102461, -0.8702809953942287, -0.9990474980934045], Output: [0.9772975112887882, -0.2185508996170097, 0.626687294954806, 0.11666577633275452]\n",
      "Layer: Layer 2, Input: [0.9772975112887882, -0.2185508996170097, 0.626687294954806, 0.11666577633275452], Output: [1.1797693022979034]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8708574877607806, 0.026131529691809815, -0.98357335114068, -0.9750369951190926]\n",
      "Layer: Layer 1, Input: [-0.8708574877607806, 0.026131529691809815, -0.98357335114068, -0.9750369951190926], Output: [-0.21243758705263277, 0.7010353219975963, -0.5845322889414576, 0.4661085232137248]\n",
      "Layer: Layer 2, Input: [-0.21243758705263277, 0.7010353219975963, -0.5845322889414576, 0.4661085232137248], Output: [-0.9757787379366174]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.04885165632999279, -0.9014446969080342, 0.35398396327859083, 0.007337884487200917]\n",
      "Layer: Layer 1, Input: [-0.04885165632999279, -0.9014446969080342, 0.35398396327859083, 0.007337884487200917], Output: [-0.643963334867296, 0.5849782519653385, -0.6148809305418633, -0.15442428392391952]\n",
      "Layer: Layer 2, Input: [-0.643963334867296, 0.5849782519653385, -0.6148809305418633, -0.15442428392391952], Output: [-0.9844671639985185]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6104052281966686, 0.7483582021194495, -0.8229563180975996, -0.9764016759290771]\n",
      "Layer: Layer 1, Input: [0.6104052281966686, 0.7483582021194495, -0.8229563180975996, -0.9764016759290771], Output: [0.930121532268979, 0.020105132177810466, 0.4380299826007534, 0.21297854390752818]\n",
      "Layer: Layer 2, Input: [0.930121532268979, 0.020105132177810466, 0.4380299826007534, 0.21297854390752818], Output: [0.8157620917884854]\n",
      "Epoch 34/100, Loss: 0.016772136850255366, Accuracy: 0.5962386914257178\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9868519323075365, 0.972534395833858, -0.8700743078456941, -0.9990475350653841]\n",
      "Layer: Layer 1, Input: [0.9868519323075365, 0.972534395833858, -0.8700743078456941, -0.9990475350653841], Output: [0.9773227081869438, -0.21719964534231073, 0.6277000135625694, 0.11760876669972785]\n",
      "Layer: Layer 2, Input: [0.9773227081869438, -0.21719964534231073, 0.6277000135625694, 0.11760876669972785], Output: [1.1784066543228102]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8703425688746784, 0.024216106277561742, -0.9835605481697476, -0.9750470753711425]\n",
      "Layer: Layer 1, Input: [-0.8703425688746784, 0.024216106277561742, -0.9835605481697476, -0.9750470753711425], Output: [-0.213761254076628, 0.7012781692853944, -0.5850404189869679, 0.4647610850819787]\n",
      "Layer: Layer 2, Input: [-0.213761254076628, 0.7012781692853944, -0.5850404189869679, 0.4647610850819787], Output: [-0.9770909238205808]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.04767762378106011, -0.9012868014049785, 0.3542241466889197, 0.0069266976966082874]\n",
      "Layer: Layer 1, Input: [-0.04767762378106011, -0.9012868014049785, 0.3542241466889197, 0.0069266976966082874], Output: [-0.6436366471485737, 0.5847465615077705, -0.614432004653045, -0.1547339901357778]\n",
      "Layer: Layer 2, Input: [-0.6436366471485737, 0.5847465615077705, -0.614432004653045, -0.1547339901357778], Output: [-0.984497064123396]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.61377099661829, 0.7504470086831421, -0.8228016047122776, -0.9763961731493283]\n",
      "Layer: Layer 1, Input: [0.61377099661829, 0.7504470086831421, -0.8228016047122776, -0.9763961731493283], Output: [0.9307686243243768, 0.019115442984012663, 0.44110154674788715, 0.21301409109034614]\n",
      "Layer: Layer 2, Input: [0.9307686243243768, 0.019115442984012663, 0.44110154674788715, 0.21301409109034614], Output: [0.8183237164247804]\n",
      "Epoch 35/100, Loss: 0.01640009327813771, Accuracy: 0.601505050045947\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9870798024307754, 0.9729685580435552, -0.8698701060880614, -0.9990475829181596]\n",
      "Layer: Layer 1, Input: [0.9870798024307754, 0.9729685580435552, -0.8698701060880614, -0.9990475829181596], Output: [0.9773474158352593, -0.2157881909590573, 0.6286690119696997, 0.11854613049871714]\n",
      "Layer: Layer 2, Input: [0.9773474158352593, -0.2157881909590573, 0.6286690119696997, 0.11854613049871714], Output: [1.1769283068523446]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8698325383773, 0.02252535487888085, -0.983547980623969, -0.9750569385856164]\n",
      "Layer: Layer 1, Input: [-0.8698325383773, 0.02252535487888085, -0.983547980623969, -0.9750569385856164], Output: [-0.2149024316376301, 0.7014722980157472, -0.5854197890490137, 0.4635534688258097]\n",
      "Layer: Layer 2, Input: [-0.2149024316376301, 0.7014722980157472, -0.5854197890490137, 0.4635534688258097], Output: [-0.9781955835306089]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.04654200076421471, -0.9011270110118814, 0.35446221227541647, 0.0065159905862132855]\n",
      "Layer: Layer 1, Input: [-0.04654200076421471, -0.9011270110118814, 0.35446221227541647, 0.0065159905862132855], Output: [-0.6433256738609888, 0.5845251203644731, -0.613987152553524, -0.1550186863161305]\n",
      "Layer: Layer 2, Input: [-0.6433256738609888, 0.5845251203644731, -0.613987152553524, -0.1550186863161305], Output: [-0.984513623200912]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6170352733566323, 0.7524893176793601, -0.8226492820557482, -0.9763908231376931]\n",
      "Layer: Layer 1, Input: [0.6170352733566323, 0.7524893176793601, -0.8226492820557482, -0.9763908231376931], Output: [0.9313941565906736, 0.01823744116956997, 0.44407427629287566, 0.21307933019879685]\n",
      "Layer: Layer 2, Input: [0.9313941565906736, 0.01823744116956997, 0.44407427629287566, 0.21307933019879685], Output: [0.8206771384986365]\n",
      "Epoch 36/100, Loss: 0.016043893716652144, Accuracy: 0.6064580383778128\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987298441358828, 0.9733887955490951, -0.8696680807975379, -0.9990476417109782]\n",
      "Layer: Layer 1, Input: [0.987298441358828, 0.9733887955490951, -0.8696680807975379, -0.9990476417109782], Output: [0.9773715689477848, -0.21433829158305767, 0.6296027024187332, 0.11947449171283302]\n",
      "Layer: Layer 2, Input: [0.9773715689477848, -0.21433829158305767, 0.6296027024187332, 0.11947449171283302], Output: [1.1753746905050695]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8693284377727142, 0.021015632329733684, -0.9835356215775587, -0.9750666377397664]\n",
      "Layer: Layer 1, Input: [-0.8693284377727142, 0.021015632329733684, -0.9835356215775587, -0.9750666377397664], Output: [-0.215898205665167, 0.7016271410766957, -0.5856971647505433, 0.46245907359717625]\n",
      "Layer: Layer 2, Input: [-0.215898205665167, 0.7016271410766957, -0.5856971647505433, 0.46245907359717625], Output: [-0.9791366625821063]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.045443454744871714, -0.9009662480614465, 0.3546984789165559, 0.006105308843500547]\n",
      "Layer: Layer 1, Input: [-0.045443454744871714, -0.9009662480614465, 0.3546984789165559, 0.006105308843500547], Output: [-0.6430312063273678, 0.5843155263388525, -0.6135476153760416, -0.15527906797671623]\n",
      "Layer: Layer 2, Input: [-0.6430312063273678, 0.5843155263388525, -0.6135476153760416, -0.15527906797671623], Output: [-0.9845285115079101]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6202042658983195, 0.7544858979414318, -0.8224990987522424, -0.9763856243057557]\n",
      "Layer: Layer 1, Input: [0.6202042658983195, 0.7544858979414318, -0.8224990987522424, -0.9763856243057557], Output: [0.9319990249485777, 0.01744980670750408, 0.4469586625803091, 0.21316816634627395]\n",
      "Layer: Layer 2, Input: [0.9319990249485777, 0.01744980670750408, 0.4469586625803091, 0.21316816634627395], Output: [0.8228620200626847]\n",
      "Epoch 37/100, Loss: 0.01570219795259884, Accuracy: 0.6111525036476316\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9875084844385039, 0.9737957341672645, -0.8694680159232748, -0.9990477107565858]\n",
      "Layer: Layer 1, Input: [0.9875084844385039, 0.9737957341672645, -0.8694680159232748, -0.9990477107565858], Output: [0.9773951257958315, -0.21286617180245854, 0.630507425342062, 0.120391459913125]\n",
      "Layer: Layer 2, Input: [0.9773951257958315, -0.21286617180245854, 0.630507425342062, 0.120391459913125], Output: [1.1737758502051137]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8688309678356217, 0.019652898174105395, -0.9835234512580396, -0.975076205134688]\n",
      "Layer: Layer 1, Input: [-0.8688309678356217, 0.019652898174105395, -0.9835234512580396, -0.975076205134688], Output: [-0.2167773432400346, 0.7017501006750257, -0.5858933597776513, 0.4614570799231665]\n",
      "Layer: Layer 2, Input: [-0.2167773432400346, 0.7017501006750257, -0.5858933597776513, 0.4614570799231665], Output: [-0.9799479999269307]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.04438032785902708, -0.9008052084559055, 0.35493312542840705, 0.005694600673199093]\n",
      "Layer: Layer 1, Input: [-0.04438032785902708, -0.9008052084559055, 0.35493312542840705, 0.005694600673199093], Output: [-0.6427533100106738, 0.5841184788324376, -0.613114226573818, -0.15551631556856596]\n",
      "Layer: Layer 2, Input: [-0.6427533100106738, 0.5841184788324376, -0.613114226573818, -0.15551631556856596], Output: [-0.9845493926617468]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6232834815394382, 0.7564376730196822, -0.8223508695424442, -0.9763805685549622]\n",
      "Layer: Layer 1, Input: [0.6232834815394382, 0.7564376730196822, -0.8223508695424442, -0.9763805685549622], Output: [0.9325841191893484, 0.016736106776248615, 0.4497630481123223, 0.21327581263094536]\n",
      "Layer: Layer 2, Input: [0.9325841191893484, 0.016736106776248615, 0.4497630481123223, 0.21327581263094536], Output: [0.8249088674688607]\n",
      "Epoch 38/100, Loss: 0.015373938694899584, Accuracy: 0.6156304098524246\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9877105005252527, 0.9741899639439259, -0.8692697621892609, -0.9990477889000439]\n",
      "Layer: Layer 1, Input: [0.9877105005252527, 0.9741899639439259, -0.8692697621892609, -0.9990477889000439], Output: [0.9774180620956768, -0.2113838786677467, 0.63138796697316, 0.12129538393094613]\n",
      "Layer: Layer 2, Input: [0.9774180620956768, -0.2113838786677467, 0.63138796697316, 0.12129538393094613], Output: [1.1721540011271483]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8683405751670314, 0.01841048452464477, -0.9835114551262271, -0.9750856585633805]\n",
      "Layer: Layer 1, Input: [-0.8683405751670314, 0.01841048452464477, -0.9835114551262271, -0.9750856585633805], Output: [-0.21756224445162015, 0.7018470149297423, -0.5860246315691636, 0.4605311243933469]\n",
      "Layer: Layer 2, Input: [-0.21756224445162015, 0.7018470149297423, -0.5860246315691636, 0.4605311243933469], Output: [-0.9806557227111491]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.04335078060125051, -0.9006444153902232, 0.35516623463837704, 0.00528407825889312]\n",
      "Layer: Layer 1, Input: [-0.04335078060125051, -0.9006444153902232, 0.35516623463837704, 0.00528407825889312], Output: [-0.6424915589015949, 0.5839340558145, -0.6126875176527713, -0.15573190156337768]\n",
      "Layer: Layer 2, Input: [-0.6424915589015949, 0.5839340558145, -0.6126875176527713, -0.15573190156337768], Output: [-0.9845810289730154]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6262778503157915, 0.758345674045925, -0.8222044572165644, -0.9763756437466468]\n",
      "Layer: Layer 1, Input: [0.6262778503157915, 0.758345674045925, -0.8222044572165644, -0.9763756437466468], Output: [0.9331503110657177, 0.01608363256314396, 0.4524941424927666, 0.21339849234260008]\n",
      "Layer: Layer 2, Input: [0.9331503110657177, 0.01608363256314396, 0.4524941424927666, 0.21339849234260008], Output: [0.8268412173475768]\n",
      "Epoch 39/100, Loss: 0.015058227461278568, Accuracy: 0.6199239679045929\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987905001777123, 0.9745720424764364, -0.8690732176792021, -0.9990478747188929]\n",
      "Layer: Layer 1, Input: [0.987905001777123, 0.9745720424764364, -0.8690732176792021, -0.9990478747188929], Output: [0.9774403664146287, -0.20990030775689483, 0.632247948664198, 0.12218516530914465]\n",
      "Layer: Layer 2, Input: [0.9774403664146287, -0.20990030775689483, 0.632247948664198, 0.12218516530914465], Output: [1.1705254661851274]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8678575179864801, 0.017267398211368454, -0.9834996224471183, -0.9750950058468757]\n",
      "Layer: Layer 1, Input: [-0.8678575179864801, 0.017267398211368454, -0.9834996224471183, -0.9750950058468757], Output: [-0.2182704249851595, 0.7019225129372857, -0.5861037375569209, 0.45966828506269125]\n",
      "Layer: Layer 2, Input: [-0.2182704249851595, 0.7019225129372857, -0.5861037375569209, 0.45966828506269125], Output: [-0.9812800659947293]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.042352894673961625, -0.900484260264154, 0.3553978254345737, 0.0048741174881243455]\n",
      "Layer: Layer 1, Input: [-0.042352894673961625, -0.900484260264154, 0.3553978254345737, 0.0048741174881243455], Output: [-0.6422452078294225, 0.583761917598835, -0.6122677980399954, -0.15592745208908845]\n",
      "Layer: Layer 2, Input: [-0.6422452078294225, 0.583761917598835, -0.6122677980399954, -0.15592745208908845], Output: [-0.9846261074033554]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6291918205757802, 0.7602110036155105, -0.8220597593294563, -0.9763708354731092]\n",
      "Layer: Layer 1, Input: [0.6291918205757802, 0.7602110036155105, -0.8220597593294563, -0.9763708354731092], Output: [0.933698446263944, 0.015482513221290867, 0.45515741203309096, 0.21353321124391805]\n",
      "Layer: Layer 2, Input: [0.933698446263944, 0.015482513221290867, 0.45515741203309096, 0.21353321124391805], Output: [0.8286773017415242]\n",
      "Epoch 40/100, Loss: 0.014754298514738659, Accuracy: 0.6240580089544815\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9880924515587507, 0.9749424975186974, -0.8688783136563509, -0.9990479666647069]\n",
      "Layer: Layer 1, Input: [0.9880924515587507, 0.9749424975186974, -0.8688783136563509, -0.9990479666647069], Output: [0.9774620367149006, -0.20842198021127814, 0.6330901192360786, 0.12306011728651008]\n",
      "Layer: Layer 2, Input: [0.9774620367149006, -0.20842198021127814, 0.6330901192360786, 0.12306011728651008], Output: [1.1689021417131078]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8673819160653177, 0.01620702593466202, -0.9834879452303439, -0.975104248147073]\n",
      "Layer: Layer 1, Input: [-0.8673819160653177, 0.01620702593466202, -0.9834879452303439, -0.975104248147073], Output: [-0.21891564433563443, 0.7019802858703175, -0.5861407373258943, 0.4588583042023247]\n",
      "Layer: Layer 2, Input: [-0.21891564433563443, 0.7019802858703175, -0.5861407373258943, 0.4588583042023247], Output: [-0.9818367568855123]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.0413847452070899, -0.9003250338930462, 0.35562787586989875, 0.0044651862593138095]\n",
      "Layer: Layer 1, Input: [-0.0413847452070899, -0.9003250338930462, 0.35562787586989875, 0.0044651862593138095], Output: [-0.6420133178725138, 0.583601455548779, -0.6118552152599896, -0.15610464940064034]\n",
      "Layer: Layer 2, Input: [-0.6420133178725138, 0.583601455548779, -0.6118552152599896, -0.15610464940064034], Output: [-0.9846858534257313]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6320294338640176, 0.7620348080477247, -0.821916698449162, -0.9763661283082802]\n",
      "Layer: Layer 1, Input: [0.6320294338640176, 0.7620348080477247, -0.821916698449162, -0.9763661283082802], Output: [0.934229339224859, 0.014925042088657981, 0.457757373357096, 0.21367758322673439]\n",
      "Layer: Layer 2, Input: [0.934229339224859, 0.014925042088657981, 0.457757373357096, 0.21367758322673439], Output: [0.8304313137975549]\n",
      "Epoch 41/100, Loss: 0.014461474825358058, Accuracy: 0.6280517823956907\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9882732708931867, 0.9753018290889551, -0.8686850042513098, -0.9990480631612132]\n",
      "Layer: Layer 1, Input: [0.9882732708931867, 0.9753018290889551, -0.8686850042513098, -0.9990480631612132], Output: [0.9774830777540249, -0.2069536305509408, 0.6339165742501855, 0.1239198583657429]\n",
      "Layer: Layer 2, Input: [0.9774830777540249, -0.2069536305509408, 0.6339165742501855, 0.1239198583657429], Output: [1.1672926044919332]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8669137885325646, 0.015216145105039146, -0.9834764174480183, -0.9751133823653604]\n",
      "Layer: Layer 1, Input: [-0.8669137885325646, 0.015216145105039146, -0.9834764174480183, -0.9751133823653604], Output: [-0.21950876579708437, 0.702023294560899, -0.5861436036651145, 0.4580929923377326]\n",
      "Layer: Layer 2, Input: [-0.21950876579708437, 0.702023294560899, -0.5861436036651145, 0.4580929923377326], Output: [-0.9823380682202878]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.040444450146158856, -0.9001669503439546, 0.3558563396375974, 0.00405779402948566]\n",
      "Layer: Layer 1, Input: [-0.040444450146158856, -0.9001669503439546, 0.3558563396375974, 0.00405779402948566], Output: [-0.6417948464889384, 0.5834518995017342, -0.6114498001377318, -0.15626516469612364]\n",
      "Layer: Layer 2, Input: [-0.6417948464889384, 0.5834518995017342, -0.6114498001377318, -0.15626516469612364], Output: [-0.984760484498207]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.634794384162151, 0.7638182561300454, -0.8217752150171104, -0.9763615066729604]\n",
      "Layer: Layer 1, Input: [0.634794384162151, 0.7638182561300454, -0.8217752150171104, -0.9763615066729604], Output: [0.9347437700457644, 0.014405164824821057, 0.4602978144489465, 0.21382969661002937]\n",
      "Layer: Layer 2, Input: [0.9347437700457644, 0.014405164824821057, 0.4602978144489465, 0.21382969661002937], Output: [0.8321143685775099]\n",
      "Epoch 42/100, Loss: 0.014179146855685797, Accuracy: 0.6319203168040715\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9884478437881595, 0.9756505112396058, -0.8684932590050208, -0.9990481626704432]\n",
      "Layer: Layer 1, Input: [0.9884478437881595, 0.9756505112396058, -0.8684932590050208, -0.9990481626704432], Output: [0.9775034991318983, -0.20549865096973763, 0.6347289203188368, 0.12476423209390503]\n",
      "Layer: Layer 2, Input: [0.9775034991318983, -0.20549865096973763, 0.6347289203188368, 0.12476423209390503], Output: [1.165702946837453]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8664530824065972, 0.014284166906349559, -0.983465034460223, -0.9751224028605046]\n",
      "Layer: Layer 1, Input: [-0.8664530824065972, 0.014284166906349559, -0.983465034460223, -0.9751224028605046], Output: [-0.2200584130613431, 0.7020539288650792, -0.586118689317218, 0.4573657707647733]\n",
      "Layer: Layer 2, Input: [-0.2200584130613431, 0.7020539288650792, -0.586118689317218, 0.4573657707647733], Output: [-0.9827936212883447]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.039530202752434095, -0.9000101651510881, 0.35608315765706666, 0.0036524570534696766]\n",
      "Layer: Layer 1, Input: [-0.039530202752434095, -0.9000101651510881, 0.35608315765706666, 0.0036524570534696766], Output: [-0.6415887112450853, 0.5833123943856287, -0.6110515006346071, -0.15641061330091727]\n",
      "Layer: Layer 2, Input: [-0.6415887112450853, 0.5833123943856287, -0.6110515006346071, -0.15641061330091727], Output: [-0.9848495427170488]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6374900652694687, 0.7655625229290474, -0.821635262138133, -0.9763569554164876]\n",
      "Layer: Layer 1, Input: [0.6374900652694687, 0.7655625229290474, -0.821635262138133, -0.9763569554164876], Output: [0.9352424828992726, 0.013918090728021958, 0.4627819610599201, 0.21398801139123014]\n",
      "Layer: Layer 2, Input: [0.9352424828992726, 0.013918090728021958, 0.4627819610599201, 0.21398801139123014], Output: [0.8337352319205062]\n",
      "Epoch 43/100, Loss: 0.013906758879848755, Accuracy: 0.6356754490884469\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9886165216807865, 0.9759889935983368, -0.8683030575158577, -0.9990482637355366]\n",
      "Layer: Layer 1, Input: [0.9886165216807865, 0.9759889935983368, -0.8683030575158577, -0.9990482637355366], Output: [0.9775233138267316, -0.2040594269130548, 0.6355283981408091, 0.12559324668028213]\n",
      "Layer: Layer 2, Input: [0.9775233138267316, -0.2040594269130548, 0.6355283981408091, 0.12559324668028213], Output: [1.1641374058859013]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8659996940406907, 0.013402556004370727, -0.9834537925954393, -0.9751313026618837]\n",
      "Layer: Layer 1, Input: [-0.8659996940406907, 0.013402556004370727, -0.9834537925954393, -0.9751313026618837], Output: [-0.2205714723586333, 0.7020741303200989, -0.5860710844310519, 0.45667131986597137]\n",
      "Layer: Layer 2, Input: [-0.2205714723586333, 0.7020741303200989, -0.5860710844310519, 0.45667131986597137], Output: [-0.9832109978311581]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.038640291730372936, -0.8998547892403235, 0.35630826607159405, 0.003249675133616901]\n",
      "Layer: Layer 1, Input: [-0.038640291730372936, -0.8998547892403235, 0.35630826607159405, 0.003249675133616901], Output: [-0.6413938339052161, 0.58318205395913, -0.6106602070700863, -0.1565425261853214]\n",
      "Layer: Layer 2, Input: [-0.6413938339052161, 0.58318205395913, -0.6106602070700863, -0.1565425261853214], Output: [-0.9849521368093359]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6401196091441957, 0.7672687775766357, -0.8214968017952852, -0.9763524601914667]\n",
      "Layer: Layer 1, Input: [0.6401196091441957, 0.7672687775766357, -0.8214968017952852, -0.9763524601914667], Output: [0.9357261855487433, 0.013459997594961916, 0.4652126020608586, 0.21415128008820208]\n",
      "Layer: Layer 2, Input: [0.9357261855487433, 0.013459997594961916, 0.4652126020608586, 0.21415128008820208], Output: [0.8353008732295479]\n",
      "Epoch 44/100, Loss: 0.013643799787583219, Accuracy: 0.6393266019841406\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988779627183947, 0.976317702752551, -0.8681143856335888, -0.9990483650066787]\n",
      "Layer: Layer 1, Input: [0.988779627183947, 0.976317702752551, -0.8681143856335888, -0.9990483650066787], Output: [0.9775425371008459, -0.2026375903786181, 0.6363159745733135, 0.12640702961001293]\n",
      "Layer: Layer 2, Input: [0.9775425371008459, -0.2026375903786181, 0.6363159745733135, 0.12640702961001293], Output: [1.1625988373437088]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8655534851625973, 0.012564384783026471, -0.9834426888462651, -0.975140074310569]\n",
      "Layer: Layer 1, Input: [-0.8655534851625973, 0.012564384783026471, -0.9834426888462651, -0.975140074310569], Output: [-0.22105347715129495, 0.7020854867951148, -0.5860048910183404, 0.4560053082907457]\n",
      "Layer: Layer 2, Input: [-0.22105347715129495, 0.7020854867951148, -0.5860048910183404, 0.4560053082907457], Output: [-0.9835962070201476]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.03777311239793135, -0.8997008995747011, 0.35653160162975417, 0.0028499167415183164]\n",
      "Layer: Layer 1, Input: [-0.03777311239793135, -0.8997008995747011, 0.35653160162975417, 0.0028499167415183164], Output: [-0.6412091700167627, 0.5830599976659538, -0.6102757708283709, -0.1566623332754002]\n",
      "Layer: Layer 2, Input: [-0.6412091700167627, 0.5830599976659538, -0.6102757708283709, -0.1566623332754002], Output: [-0.9850671163776306]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6426859173056607, 0.7689381741760977, -0.8213598021151234, -0.9763480076790108]\n",
      "Layer: Layer 1, Input: [0.6426859173056607, 0.7689381741760977, -0.8213598021151234, -0.9763480076790108], Output: [0.9361955496445955, 0.013027807535979865, 0.4675921839916636, 0.21431848657996233]\n",
      "Layer: Layer 2, Input: [0.9361955496445955, 0.013027807535979865, 0.4675921839916636, 0.21431848657996233], Output: [0.8368168847875153]\n",
      "Epoch 45/100, Loss: 0.01338979660834551, Accuracy: 0.6428813708415846\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9889374572728884, 0.9766370435226605, -0.8679272327869079, -0.9990484652549989]\n",
      "Layer: Layer 1, Input: [0.9889374572728884, 0.9766370435226605, -0.8679272327869079, -0.9990484652549989], Output: [0.9775611856861859, -0.20123421099408856, 0.637092411494329, 0.12720579358362247]\n",
      "Layer: Layer 2, Input: [0.9775611856861859, -0.20123421099408856, 0.637092411494329, 0.12720579358362247], Output: [1.1610890718144828]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8651142947986198, 0.011763990149664496, -0.9834317206505951, -0.9751487104276929]\n",
      "Layer: Layer 1, Input: [-0.8651142947986198, 0.011763990149664496, -0.9834317206505951, -0.9751487104276929], Output: [-0.22150890342113302, 0.7020893057334593, -0.5859234342481789, 0.4553641839741339]\n",
      "Layer: Layer 2, Input: [-0.22150890342113302, 0.7020893057334593, -0.5859234342481789, 0.4553641839741339], Output: [-0.983954042119141]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.036927171470254073, -0.8995485472928966, 0.3567531051736447, 0.0024536101653215812]\n",
      "Layer: Layer 1, Input: [-0.036927171470254073, -0.8995485472928966, 0.3567531051736447, 0.0024536101653215812], Output: [-0.6410337278752706, 0.5829453751129577, -0.609898018148717, -0.1567713551602229]\n",
      "Layer: Layer 2, Input: [-0.6410337278752706, 0.5829453751129577, -0.609898018148717, -0.1567713551602229], Output: [-0.9851931957478343]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6451916868624881, 0.7705718451510096, -0.821224235405878, -0.9763435857073894]\n",
      "Layer: Layer 1, Input: [0.6451916868624881, 0.7705718451510096, -0.821224235405878, -0.9763435857073894], Output: [0.936651211563951, 0.012619016577111305, 0.4699228825157356, 0.21448879869925364]\n",
      "Layer: Layer 2, Input: [0.936651211563951, 0.012619016577111305, 0.4699228825157356, 0.21448879869925364], Output: [0.8382877999866835]\n",
      "Epoch 46/100, Loss: 0.013144309726918688, Accuracy: 0.6463459660391758\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9890902860178563, 0.9769474001520739, -0.8677415901381816, -0.9990485633780242]\n",
      "Layer: Layer 1, Input: [0.9890902860178563, 0.9769474001520739, -0.8677415901381816, -0.9990485633780242], Output: [0.9775792771812186, -0.19984994006281717, 0.6378583172782969, 0.12798981100472753]\n",
      "Layer: Layer 2, Input: [0.9775792771812186, -0.19984994006281717, 0.6378583172782969, 0.12798981100472753], Output: [1.159609182549261]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8646819480727288, 0.010996708634836507, -0.98342088573592, -0.9751572040845201]\n",
      "Layer: Layer 1, Input: [-0.8646819480727288, 0.010996708634836507, -0.98342088573592, -0.9751572040845201], Output: [-0.22194139682118946, 0.7020866710016539, -0.5858294255785704, 0.4547450124797227]\n",
      "Layer: Layer 2, Input: [-0.22194139682118946, 0.7020866710016539, -0.5858294255785704, 0.4547450124797227], Output: [-0.9842883532022851]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.03610108737976748, -0.8993977639305243, 0.3569727237703029, 0.002061138936474667]\n",
      "Layer: Layer 1, Input: [-0.03610108737976748, -0.8993977639305243, 0.3569727237703029, 0.002061138936474667], Output: [-0.6408665797943074, 0.5828373815550361, -0.609526760215249, -0.15687080066963208]\n",
      "Layer: Layer 2, Input: [-0.6408665797943074, 0.5828373815550361, -0.609526760215249, -0.15687080066963208], Output: [-0.9853290405190568]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6476394323369208, 0.7721708964993657, -0.8210900767627629, -0.9763391832959329]\n",
      "Layer: Layer 1, Input: [0.6476394323369208, 0.7721708964993657, -0.8210900767627629, -0.9763391832959329], Output: [0.9370937736153858, 0.012231565022670567, 0.472206656561626, 0.21466153135059915]\n",
      "Layer: Layer 2, Input: [0.9370937736153858, 0.012231565022670567, 0.472206656561626, 0.21466153135059915], Output: [0.8397173350335064]\n",
      "Epoch 47/100, Loss: 0.012906929184998037, Accuracy: 0.6497255462055874\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9892383669443726, 0.9772491374302323, -0.8675574493386529, -0.9990486583993335]\n",
      "Layer: Layer 1, Input: [0.9892383669443726, 0.9772491374302323, -0.8675574493386529, -0.9990486583993335], Output: [0.9775968296073728, -0.1984851190758288, 0.6386141852539574, 0.12875939491552177]\n",
      "Layer: Layer 2, Input: [0.9775968296073728, -0.1984851190758288, 0.6386141852539574, 0.12875939491552177], Output: [1.1581596864245665]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8642562626401465, 0.010258671333025602, -0.9834101820100208, -0.9751655490297014]\n",
      "Layer: Layer 1, Input: [-0.8642562626401465, 0.010258671333025602, -0.9834101820100208, -0.9751655490297014], Output: [-0.2223539478433565, 0.7020784871639992, -0.5857250890934667, 0.45414535159393005]\n",
      "Layer: Layer 2, Input: [-0.2223539478433565, 0.7020784871639992, -0.5857250890934667, 0.45414535159393005], Output: [-0.9846022559704586]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.03529358756122632, -0.8992485661753608, 0.3571904118824781, 0.0016728402432237518]\n",
      "Layer: Layer 1, Input: [-0.03529358756122632, -0.8992485661753608, 0.3571904118824781, 0.0016728402432237518], Output: [-0.6407068678731851, 0.5827352669145767, -0.6091618004694738, -0.15696176845711737]\n",
      "Layer: Layer 2, Input: [-0.6407068678731851, 0.5827352669145767, -0.6091618004694738, -0.15696176845711737], Output: [-0.9854733266732647]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6500315041644376, 0.773736404526007, -0.8209573030880006, -0.9763347906477089]\n",
      "Layer: Layer 1, Input: [0.6500315041644376, 0.773736404526007, -0.8209573030880006, -0.9763347906477089], Output: [0.9375238054759331, 0.011863738706320931, 0.47444528948338294, 0.2148361177011474]\n",
      "Layer: Layer 2, Input: [0.9375238054759331, 0.011863738706320931, 0.47444528948338294, 0.2148361177011474], Output: [0.8411085727305921]\n",
      "Epoch 48/100, Loss: 0.01267727170719192, Accuracy: 0.653024468949749\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9893819350848746, 0.9775426017579292, -0.8673748017165351, -0.9990487494643585]\n",
      "Layer: Layer 1, Input: [0.9893819350848746, 0.9775426017579292, -0.8673748017165351, -0.9990487494643585], Output: [0.9776138610856844, -0.1971398613872669, 0.6393604224198641, 0.12951488479297724]\n",
      "Layer: Layer 2, Input: [0.9776138610856844, -0.1971398613872669, 0.6393604224198641, 0.12951488479297724], Output: [1.156740694614591]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8638370533366658, 0.009546644645407358, -0.9833996074855883, -0.9751737398149137]\n",
      "Layer: Layer 1, Input: [-0.8638370533366658, 0.009546644645407358, -0.9833996074855883, -0.9751737398149137], Output: [-0.22274902727599627, 0.7020655140945546, -0.5856122596774941, 0.45356315372321293]\n",
      "Layer: Layer 2, Input: [-0.22274902727599627, 0.7020655140945546, -0.5856122596774941, 0.45356315372321293], Output: [-0.9848982919023321]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.03450350375418545, -0.8991009595015593, 0.35740613187003917, 0.0012890053798002867]\n",
      "Layer: Layer 1, Input: [-0.03450350375418545, -0.8991009595015593, 0.35740613187003917, 0.0012890053798002867], Output: [-0.6405538058974132, 0.5826383402156866, -0.6088029398453492, -0.1570452512209131]\n",
      "Layer: Layer 2, Input: [-0.6405538058974132, 0.5826383402156866, -0.6088029398453492, -0.1570452512209131], Output: [-0.9856247796391815]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6523701045336043, 0.7752694137150691, -0.8208258924127634, -0.9763303991082044]\n",
      "Layer: Layer 1, Input: [0.6523701045336043, 0.7752694137150691, -0.8208258924127634, -0.9763303991082044], Output: [0.9379418457622369, 0.011514093654530308, 0.476640420481563, 0.2150120865780037]\n",
      "Layer: Layer 2, Input: [0.9379418457622369, 0.011514093654530308, 0.476640420481563, 0.2150120865780037], Output: [0.8424641024110942]\n",
      "Epoch 49/100, Loss: 0.012454978231323997, Accuracy: 0.6562464793380167\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9895212087720369, 0.9778281221599683, -0.8671936377744897, -0.9990488358337419]\n",
      "Layer: Layer 1, Input: [0.9895212087720369, 0.9778281221599683, -0.8671936377744897, -0.9990488358337419], Output: [0.9776303896038216, -0.19581411362887402, 0.6400973708721793, 0.1302566360071843]\n",
      "Layer: Layer 2, Input: [0.9776303896038216, -0.19581411362887402, 0.6400973708721793, 0.1302566360071843], Output: [1.155352025383735]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8634241354877227, 0.008857906136582397, -0.9833891602294839, -0.9751817718493337]\n",
      "Layer: Layer 1, Input: [-0.8634241354877227, 0.008857906136582397, -0.9833891602294839, -0.9751817718493337], Output: [-0.22312869128593607, 0.7020483941492714, -0.5854924595928601, 0.45299668964650447]\n",
      "Layer: Layer 2, Input: [-0.22312869128593607, 0.7020483941492714, -0.5854924595928601, 0.45299668964650447], Output: [-0.9851785513231415]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.033729766090566646, -0.8989549409468602, 0.3576198540349718, 0.0009098815366669948]\n",
      "Layer: Layer 1, Input: [-0.033729766090566646, -0.8989549409468602, 0.3576198540349718, 0.0009098815366669948], Output: [-0.6404066785832223, 0.5825459708244625, -0.6084499804564864, -0.15712214157113624]\n",
      "Layer: Layer 2, Input: [-0.6404066785832223, 0.5825459708244625, -0.6084499804564864, -0.15712214157113624], Output: [-0.9857821988377873]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.654657301073084, 0.7767709354753398, -0.8206958234377048, -0.9763260011025336]\n",
      "Layer: Layer 1, Input: [0.654657301073084, 0.7767709354753398, -0.8206958234377048, -0.9763260011025336], Output: [0.9383484036643509, 0.01118139850299571, 0.478793568710449, 0.21518904465025232]\n",
      "Layer: Layer 2, Input: [0.9383484036643509, 0.01118139850299571, 0.478793568710449, 0.21518904465025232], Output: [0.8437861266698075]\n",
      "Epoch 50/100, Loss: 0.012239711805604767, Accuracy: 0.6593948514470012\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9896563912140011, 0.9781060112478982, -0.867013946905723, -0.9990489168752654]\n",
      "Layer: Layer 1, Input: [0.9896563912140011, 0.9781060112478982, -0.867013946905723, -0.9990489168752654], Output: [0.9776464328508887, -0.19450770183323515, 0.6408253237834468, 0.13098501203697802]\n",
      "Layer: Layer 2, Input: [0.9776464328508887, -0.19450770183323515, 0.6408253237834468, 0.13098501203697802], Output: [1.1539932883717727]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8630173272156239, 0.008190147362105701, -0.983378838329754, -0.9751896414053263]\n",
      "Layer: Layer 1, Input: [-0.8630173272156239, 0.008190147362105701, -0.983378838329754, -0.9751896414053263], Output: [-0.22349466322850373, 0.7020276735968533, -0.5853669584573825, 0.4524444887000905]\n",
      "Layer: Layer 2, Input: [-0.22349466322850373, 0.7020276735968533, -0.5853669584573825, 0.4524444887000905], Output: [-0.9854447681976775]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.03297139652039552, -0.8988105012347288, 0.35783155636461506, 0.0005356744290218019]\n",
      "Layer: Layer 1, Input: [-0.03297139652039552, -0.8988105012347288, 0.35783155636461506, 0.0005356744290218019], Output: [-0.6402648390570969, 0.5824575875184865, -0.6081027281354391, -0.1571932388309845]\n",
      "Layer: Layer 2, Input: [-0.6402648390570969, 0.5824575875184865, -0.6081027281354391, -0.1571932388309845], Output: [-0.9859444718251311]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6568950387758056, 0.7782419475484699, -0.8205670752306397, -0.9763215900601687]\n",
      "Layer: Layer 1, Input: [0.6568950387758056, 0.7782419475484699, -0.8205670752306397, -0.9763215900601687], Output: [0.9387439605909292, 0.010864590382555366, 0.4809061518860463, 0.21536666231094165]\n",
      "Layer: Layer 2, Input: [0.9387439605909292, 0.010864590382555366, 0.4809061518860463, 0.21536666231094165], Output: [0.8450765429385079]\n",
      "Epoch 51/100, Loss: 0.012031155764132457, Accuracy: 0.6624724945895437\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.989787671884039, 0.9783765661344185, -0.866835717262266, -0.999048992055068]\n",
      "Layer: Layer 1, Input: [0.989787671884039, 0.9783765661344185, -0.866835717262266, -0.999048992055068], Output: [0.9776620081028986, -0.1932203660207177, 0.6415445373092197, 0.13170037875994134]\n",
      "Layer: Layer 2, Input: [0.9776620081028986, -0.1932203660207177, 0.6415445373092197, 0.13170037875994134], Output: [1.1526639474373706]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8626164510021744, 0.007541397457415368, -0.9833686398753126, -0.9751973455916767]\n",
      "Layer: Layer 1, Input: [-0.8626164510021744, 0.007541397457415368, -0.9833686398753126, -0.9751973455916767], Output: [-0.22384839759553488, 0.7020038196077288, -0.5852368204353119, 0.4519052916341728]\n",
      "Layer: Layer 2, Input: [-0.22384839759553488, 0.7020038196077288, -0.5852368204353119, 0.4519052916341728], Output: [-0.9856983933435779]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.03222750196793955, -0.8986676263958385, 0.3580412240845011, 0.00016655140364321553]\n",
      "Layer: Layer 1, Input: [-0.03222750196793955, -0.8986676263958385, 0.3580412240845011, 0.00016655140364321553], Output: [-0.6401277052198252, 0.582372676132518, -0.607760994126444, -0.15725925626853643]\n",
      "Layer: Layer 2, Input: [-0.6401277052198252, 0.582372676132518, -0.607760994126444, -0.15725925626853643], Output: [-0.9861105810836419]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6590851504633652, 0.7796833939155504, -0.8204396270362001, -0.9763171603335662]\n",
      "Layer: Layer 1, Input: [0.6590851504633652, 0.7796833939155504, -0.8204396270362001, -0.9763171603335662], Output: [0.939128971789887, 0.010562741032445418, 0.48297950075259377, 0.2155446624300284]\n",
      "Layer: Layer 2, Input: [0.939128971789887, 0.010562741032445418, 0.48297950075259377, 0.2155446624300284], Output: [0.8463370059894852]\n",
      "Epoch 52/100, Loss: 0.01182901212155621, Accuracy: 0.6654820329793345\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899152277512372, 0.978640069300596, -0.8666589357270437, -0.9990490609286539]\n",
      "Layer: Layer 1, Input: [0.9899152277512372, 0.978640069300596, -0.8666589357270437, -0.9990490609286539], Output: [0.977677132145986, -0.19195178608650934, 0.6422552394532538, 0.13240310030148852]\n",
      "Layer: Layer 2, Input: [0.977677132145986, -0.19195178608650934, 0.6422552394532538, 0.13240310030148852], Output: [1.1513633673847834]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8622213347016909, 0.0069099627486955756, -0.9833585629445405, -0.9752048823061952]\n",
      "Layer: Layer 1, Input: [-0.8622213347016909, 0.0069099627486955756, -0.9833585629445405, -0.9752048823061952], Output: [-0.2241911302247462, 0.7019772337963324, -0.5851029415511887, 0.4513780132658051]\n",
      "Layer: Layer 2, Input: [-0.2241911302247462, 0.7019772337963324, -0.5851029415511887, 0.4513780132658051], Output: [-0.9859406511571773]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.0314972674907035, -0.898526299006943, 0.35824884910015986, -0.0001973552298747179]\n",
      "Layer: Layer 1, Input: [-0.0314972674907035, -0.898526299006943, 0.35824884910015986, -0.0001973552298747179], Output: [-0.6399947554634435, 0.5822907763208193, -0.6074245961581688, -0.15732082840992023]\n",
      "Layer: Layer 2, Input: [-0.6399947554634435, 0.5822907763208193, -0.6074245961581688, -0.15732082840992023], Output: [-0.9862796057125016]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6612293660286971, 0.7810961850738523, -0.8203134581643535, -0.9763127071151275]\n",
      "Layer: Layer 1, Input: [0.6612293660286971, 0.7810961850738523, -0.8203134581643535, -0.9763127071151275], Output: [0.9395038679201293, 0.010275030686549785, 0.48501487042386465, 0.2157228113435081]\n",
      "Layer: Layer 2, Input: [0.9395038679201293, 0.010275030686549785, 0.48501487042386465, 0.2157228113435081], Output: [0.8475689759672335]\n",
      "Epoch 53/100, Loss: 0.01163300014575684, Accuracy: 0.668425865452129\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9900392243741576, 0.9788967894169458, -0.8664835879546935, -0.999049123132031]\n",
      "Layer: Layer 1, Input: [0.9900392243741576, 0.9788967894169458, -0.8664835879546935, -0.999049123132031], Output: [0.9776918212275959, -0.19070160112979512, 0.6429576366626066, 0.13309353605428567]\n",
      "Layer: Layer 2, Input: [0.9776918212275959, -0.19070160112979512, 0.6429576366626066, 0.13309353605428567], Output: [1.1500908485851518]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8618318121517309, 0.006294378764081927, -0.9833486056000571, -0.9752122501761554]\n",
      "Layer: Layer 1, Input: [-0.8618318121517309, 0.006294378764081927, -0.9833486056000571, -0.9752122501761554], Output: [-0.2245239179161776, 0.7019482630799225, -0.5849660793518274, 0.4508617127276233]\n",
      "Layer: Layer 2, Input: [-0.2245239179161776, 0.7019482630799225, -0.5849660793518274, 0.4508617127276233], Output: [-0.9861725837253835]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.030779949625147213, -0.8983864991373386, 0.35845442938367356, -0.0005559448193014302]\n",
      "Layer: Layer 1, Input: [-0.030779949625147213, -0.8983864991373386, 0.35845442938367356, -0.0005559448193014302], Output: [-0.6398655240741978, 0.582211477822727, -0.607093359066279, -0.15737851819796567]\n",
      "Layer: Layer 2, Input: [-0.6398655240741978, 0.582211477822727, -0.607093359066279, -0.15737851819796567], Output: [-0.9864507196671103]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6633293206460846, 0.7824811985842417, -0.8201885479336274, -0.9763082263555051]\n",
      "Layer: Layer 1, Input: [0.6633293206460846, 0.7824811985842417, -0.8201885479336274, -0.9763082263555051], Output: [0.939869056558512, 0.010000727874127103, 0.48701344936035523, 0.21590091159154048]\n",
      "Layer: Layer 2, Input: [0.939869056558512, 0.010000727874127103, 0.48701344936035523, 0.21590091159154048], Output: [0.848773755427092]\n",
      "Epoch 54/100, Loss: 0.011442855078751677, Accuracy: 0.671306210234434\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9901598168757748, 0.9791469821195453, -0.8663096584559621, -0.9990491783732011]\n",
      "Layer: Layer 1, Input: [0.9901598168757748, 0.9791469821195453, -0.8663096584559621, -0.9990491783732011], Output: [0.9777060910282933, -0.18946942384240104, 0.6436519187296758, 0.13377203857480094]\n",
      "Layer: Layer 2, Input: [0.9777060910282933, -0.18946942384240104, 0.6436519187296758, 0.13377203857480094], Output: [1.148845652513394]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8614477234924557, 0.005693371874039117, -0.9833387658876664, -0.9752194484925638]\n",
      "Layer: Layer 1, Input: [-0.8614477234924557, 0.005693371874039117, -0.9833387658876664, -0.9752194484925638], Output: [-0.22484766985819984, 0.7019172084402265, -0.5848268766203182, 0.4503555696259962]\n",
      "Layer: Layer 2, Input: [-0.22484766985819984, 0.7019172084402265, -0.5848268766203182, 0.4503555696259962], Output: [-0.986395085271131]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.030074870038041684, -0.8982482050718265, 0.3586579683434923, -0.0009091450599023142]\n",
      "Layer: Layer 1, Input: [-0.030074870038041684, -0.8982482050718265, 0.3586579683434923, -0.0009091450599023142], Output: [-0.639739596554201, 0.5821344165040659, -0.6067671150927098, -0.15743282384307006]\n",
      "Layer: Layer 2, Input: [-0.639739596554201, 0.5821344165040659, -0.6067671150927098, -0.15743282384307006], Output: [-0.9866231877486553]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6653865621003666, 0.7838392798124459, -0.8200648756514888, -0.9763037146852184]\n",
      "Layer: Layer 1, Input: [0.6653865621003666, 0.7838392798124459, -0.8200648756514888, -0.9763037146852184], Output: [0.9402249236325059, 0.009739173727125015, 0.4889763665527476, 0.21607879603074368]\n",
      "Layer: Layer 2, Input: [0.9402249236325059, 0.009739173727125015, 0.4889763665527476, 0.21607879603074368], Output: [0.8499525180126687]\n",
      "Epoch 55/100, Loss: 0.011258326983416025, Accuracy: 0.6741251385190609\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9902771508150624, 0.9793908907425236, -0.8661371307077702, -0.9990492264241403]\n",
      "Layer: Layer 1, Input: [0.9902771508150624, 0.9793908907425236, -0.8661371307077702, -0.9990492264241403], Output: [0.977719956648657, -0.18825485117774157, 0.6443382624326711, 0.13443895213587037]\n",
      "Layer: Layer 2, Input: [0.977719956648657, -0.18825485117774157, 0.6443382624326711, 0.13443895213587037], Output: [1.1476270204749135]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8610689152777891, 0.00510582843710512, -0.9833290418380308, -0.975226477142408]\n",
      "Layer: Layer 1, Input: [-0.8610689152777891, 0.00510582843710512, -0.9833290418380308, -0.975226477142408], Output: [-0.2251631727003107, 0.701884332039098, -0.584685880449105, 0.4498588648142641]\n",
      "Layer: Layer 2, Input: [-0.2251631727003107, 0.701884332039098, -0.584685880449105, 0.4498588648142641], Output: [-0.986608929176461]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.029381409555234494, -0.8981113938628, 0.35885947420343584, -0.0012569088313952544]\n",
      "Layer: Layer 1, Input: [-0.029381409555234494, -0.8981113938628, 0.35885947420343584, -0.0012569088313952544], Output: [-0.6396166050203381, 0.5820592703628886, -0.6064457039560989, -0.15748418527267627]\n",
      "Layer: Layer 2, Input: [-0.6396166050203381, 0.5820592703628886, -0.6064457039560989, -0.15748418527267627], Output: [-0.9867963602100871]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6674025573586886, 0.7851712428051351, -0.8199424206192258, -0.9762991693408055]\n",
      "Layer: Layer 1, Input: [0.6674025573586886, 0.7851712428051351, -0.8199424206192258, -0.9762991693408055], Output: [0.9405718347736187, 0.009489769727031302, 0.49090469733946923, 0.21625632303142056]\n",
      "Layer: Layer 2, Input: [0.9405718347736187, 0.009489769727031302, 0.49090469733946923, 0.21625632303142056], Output: [0.8511063307640583]\n",
      "Epoch 56/100, Loss: 0.011079179698586338, Accuracy: 0.6768845996756929\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9903913629682446, 0.9796287470084603, -0.8659659872763737, -0.9990492671133478]\n",
      "Layer: Layer 1, Input: [0.9903913629682446, 0.9796287470084603, -0.8659659872763737, -0.9990492671133478], Output: [0.9777334326071044, -0.18705747222141406, 0.6450168342370386, 0.13509461176859078]\n",
      "Layer: Layer 2, Input: [0.9777334326071044, -0.18705747222141406, 0.6450168342370386, 0.13509461176859078], Output: [1.1464341872335626]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8606952404404354, 0.004530769820214462, -0.9833194314700356, -0.97523333654171]\n",
      "Layer: Layer 1, Input: [-0.8606952404404354, 0.004530769820214462, -0.9833194314700356, -0.97523333654171], Output: [-0.22547111067988967, 0.7018498630361969, -0.5845435576767815, 0.4493709647857305]\n",
      "Layer: Layer 2, Input: [-0.22547111067988967, 0.7018498630361969, -0.5845435576767815, 0.4493709647857305], Output: [-0.986814789292946]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.028699002605804613, -0.8979760417516423, 0.3590589594077075, -0.0015992112286059175]\n",
      "Layer: Layer 1, Input: [-0.028699002605804613, -0.8979760417516423, 0.3590589594077075, -0.0015992112286059175], Output: [-0.6394962237846741, 0.5819857556264304, -0.6061289727633679, -0.15753299012831706]\n",
      "Layer: Layer 2, Input: [-0.6394962237846741, 0.5819857556264304, -0.6061289727633679, -0.15753299012831706], Output: [-0.9869696665963581]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6693786984860749, 0.7864778712556865, -0.8198211621522739, -0.9762945880961821]\n",
      "Layer: Layer 1, Input: [0.6693786984860749, 0.7864778712556865, -0.8198211621522739, -0.9762945880961821], Output: [0.940910136589898, 0.009251968082023504, 0.4927994681795672, 0.21643337253582934]\n",
      "Layer: Layer 2, Input: [0.940910136589898, 0.009251968082023504, 0.4927994681795672, 0.21643337253582934], Output: [0.8522361715654656]\n",
      "Epoch 57/100, Loss: 0.010905189888596015, Accuracy: 0.6795864402212071\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9905025820308021, 0.9798607716783841, -0.8657962099449376, -0.9990493003189972]\n",
      "Layer: Layer 1, Input: [0.9905025820308021, 0.9798607716783841, -0.8657962099449376, -0.9990493003189972], Output: [0.9777465328455383, -0.18587687395855584, 0.6456877922987677, 0.13573934266790885]\n",
      "Layer: Layer 2, Input: [0.9777465328455383, -0.18587687395855584, 0.6456877922987677, 0.13573934266790885], Output: [1.1452663908281884]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8603265581568158, 0.003967332038629334, -0.9833099327951135, -0.9752400275712293]\n",
      "Layer: Layer 1, Input: [-0.8603265581568158, 0.003967332038629334, -0.9833099327951135, -0.9752400275712293], Output: [-0.225772081882623, 0.7018140023777986, -0.584400307462594, 0.44889130891928325]\n",
      "Layer: Layer 2, Input: [-0.225772081882623, 0.7018140023777986, -0.584400307462594, 0.44889130891928325], Output: [-0.9870132568431937]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.028027132095772216, -0.8978421244901148, 0.3592564400622203, -0.0019360468113201322]\n",
      "Layer: Layer 1, Input: [-0.028027132095772216, -0.8978421244901148, 0.3592564400622203, -0.0019360468113201322], Output: [-0.639378165181207, 0.5819136230213428, -0.6058167758140501, -0.15757957928907637]\n",
      "Layer: Layer 2, Input: [-0.639378165181207, 0.5819136230213428, -0.6058167758140501, -0.15757957928907637], Output: [-0.987142609253072]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6713163079888428, 0.7877599195253504, -0.8197010796095711, -0.9762899691995178]\n",
      "Layer: Layer 1, Input: [0.6713163079888428, 0.7877599195253504, -0.8197010796095711, -0.9762899691995178], Output: [0.9412401578581286, 0.009025264120255594, 0.49466166062238076, 0.2166098428035816]\n",
      "Layer: Layer 2, Input: [0.9412401578581286, 0.009025264120255594, 0.49466166062238076, 0.2166098428035816], Output: [0.8533429428755551]\n",
      "Epoch 58/100, Loss: 0.010736146175822676, Accuracy: 0.6822324181436324\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9906109292497305, 0.9800871751631871, -0.865627779839676, -0.9990493259626955]\n",
      "Layer: Layer 1, Input: [0.9906109292497305, 0.9800871751631871, -0.865627779839676, -0.9990493259626955], Output: [0.9777592707404861, -0.18471264546224733, 0.6463512879494375, 0.13637345986727845]\n",
      "Layer: Layer 2, Input: [0.9777592707404861, -0.18471264546224733, 0.6463512879494375, 0.13637345986727845], Output: [1.1441228795455907]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8599627336458741, 0.0034147490471983536, -0.983300543822014, -0.9752465515159544]\n",
      "Layer: Layer 1, Input: [-0.8599627336458741, 0.0034147490471983536, -0.983300543822014, -0.9752465515159544], Output: [-0.22606661146685084, 0.7017769267654635, -0.5842564715964907, 0.44841939898484406]\n",
      "Layer: Layer 2, Input: [-0.22606661146685084, 0.7017769267654635, -0.5842564715964907, 0.44841939898484406], Output: [-0.9872048539087712]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.027365324709093627, -0.8977096175851645, 0.3594519354179192, -0.0022674270838645163]\n",
      "Layer: Layer 1, Input: [-0.027365324709093627, -0.8977096175851645, 0.3594519354179192, -0.0022674270838645163], Output: [-0.6392621756755325, 0.5818426542670032, -0.6055089743351391, -0.15762425192088791]\n",
      "Layer: Layer 2, Input: [-0.6392621756755325, 0.5818426542670032, -0.6055089743351391, -0.15762425192088791], Output: [-0.9873147568026215]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6732166436562338, 0.7890181136939377, -0.8195821524274685, -0.9762853113156651]\n",
      "Layer: Layer 1, Input: [0.6732166436562338, 0.7890181136939377, -0.8195821524274685, -0.9762853113156651], Output: [0.9415622106378907, 0.008809190232739409, 0.4964922146558101, 0.21678564770853176]\n",
      "Layer: Layer 2, Input: [0.9415622106378907, 0.008809190232739409, 0.4964922146558101, 0.21678564770853176], Output: [0.8544274826077494]\n",
      "Epoch 59/100, Loss: 0.010571848346725619, Accuracy: 0.6848242137735514\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9907165189942333, 0.9803081580983428, -0.8654606775507534, -0.9990493440038363]\n",
      "Layer: Layer 1, Input: [0.9907165189942333, 0.9803081580983428, -0.8654606775507534, -0.9990493440038363], Output: [0.977771659118009, -0.18356438089826158, 0.6470074667971747, 0.13699726811113244]\n",
      "Layer: Layer 2, Input: [0.977771659118009, -0.18356438089826158, 0.6470074667971747, 0.13699726811113244], Output: [1.143002916777097]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8596036379265903, 0.0028723389336695374, -0.9832912625616702, -0.9752529100090337]\n",
      "Layer: Layer 1, Input: [-0.8596036379265903, 0.0028723389336695374, -0.9832912625616702, -0.9752529100090337], Output: [-0.22635516249184998, 0.7017387919670173, -0.5841123430078952, 0.44795479044916947]\n",
      "Layer: Layer 2, Input: [-0.22635516249184998, 0.7017387919670173, -0.5841123430078952, 0.44795479044916947], Output: [-0.9873900442654581]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.02671314662268572, -0.8975784964850387, 0.3596454673985585, -0.002593378204657881]\n",
      "Layer: Layer 1, Input: [-0.02671314662268572, -0.8975784964850387, 0.3596454673985585, -0.002593378204657881], Output: [-0.6391480322739663, 0.581772658818721, -0.6052054361738988, -0.15766727006482467]\n",
      "Layer: Layer 2, Input: [-0.6391480322739663, 0.581772658818721, -0.6052054361738988, -0.15766727006482467], Output: [-0.9874857377881666]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6750809029597373, 0.7902531526206693, -0.8194643601551224, -0.9762806134740077]\n",
      "Layer: Layer 1, Input: [0.6750809029597373, 0.7902531526206693, -0.8194643601551224, -0.9762806134740077], Output: [0.9418765913106558, 0.00860331101105736, 0.498292031570303, 0.21696071448093443]\n",
      "Layer: Layer 2, Input: [0.9418765913106558, 0.00860331101105736, 0.498292031570303, 0.21696071448093443], Output: [0.8554905728189074]\n",
      "Epoch 60/100, Loss: 0.010412106623324615, Accuracy: 0.6873634380954351\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9908194592719225, 0.9805239118838576, -0.8652948832456024, -0.9990493544345199]\n",
      "Layer: Layer 1, Input: [0.9908194592719225, 0.9805239118838576, -0.8652948832456024, -0.9990493544345199], Output: [0.9777837102710936, -0.1824316816440862, 0.6476564695435106, 0.1376110618715811]\n",
      "Layer: Layer 2, Input: [0.9777837102710936, -0.1824316816440862, 0.6476564695435106, 0.1376110618715811], Output: [1.141905784304774]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8592491475521806, 0.00233949243224607, -0.9832820870319289, -0.9752591049804353]\n",
      "Layer: Layer 1, Input: [-0.8592491475521806, 0.00233949243224607, -0.9832820870319289, -0.9752591049804353], Output: [-0.2266381448448466, 0.7016997355967777, -0.583968172833277, 0.4474970852246018]\n",
      "Layer: Layer 2, Input: [-0.2266381448448466, 0.7016997355967777, -0.583968172833277, 0.4474970852246018], Output: [-0.9875692421485803]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.026070199615194682, -0.8974487367203748, 0.35983706017318917, -0.0029139389191349084]\n",
      "Layer: Layer 1, Input: [-0.026070199615194682, -0.8974487367203748, 0.35983706017318917, -0.0029139389191349084], Output: [-0.6390355392348009, 0.5817034708715607, -0.6049060354683562, -0.15770886278633128]\n",
      "Layer: Layer 2, Input: [-0.6390355392348009, 0.5817034708715607, -0.6049060354683562, -0.15770886278633128], Output: [-0.9876552346141912]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6769102270607782, 0.7914657090008386, -0.8193476824893157, -0.9762758750214825]\n",
      "Layer: Layer 1, Input: [0.6769102270607782, 0.7914657090008386, -0.8193476824893157, -0.9762758750214825], Output: [0.942183581547716, 0.008407219309791563, 0.5000619764422015, 0.21713498181128918]\n",
      "Layer: Layer 2, Input: [0.942183581547716, 0.008407219309791563, 0.5000619764422015, 0.21713498181128918], Output: [0.8565329467069078]\n",
      "Epoch 61/100, Loss: 0.01025674099323682, Accuracy: 0.6898516391649054\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9909198521966693, 0.9807346191913826, -0.8651303767733522, -0.9990493572750065]\n",
      "Layer: Layer 1, Input: [0.9909198521966693, 0.9807346191913826, -0.8651303767733522, -0.9990493572750065], Output: [0.977795435978582, -0.18131415774666185, 0.6482984325905762, 0.13821512546905426]\n",
      "Layer: Layer 2, Input: [0.977795435978582, -0.18131415774666185, 0.6482984325905762, 0.13821512546905426], Output: [1.1408307844269225]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.858899144333835, 0.0018156633039060587, -0.9832730152619985, -0.9752651386103892]\n",
      "Layer: Layer 1, Input: [-0.858899144333835, 0.0018156633039060587, -0.9832730152619985, -0.9752651386103892], Output: [-0.22691592265053961, 0.7016598794646397, -0.5838241763235061, 0.4470459255816885]\n",
      "Layer: Layer 2, Input: [-0.22691592265053961, 0.7016598794646397, -0.5838241763235061, 0.4470459255816885], Output: [-0.987742819395587]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.025436117545079028, -0.8973203140107122, 0.3600267397721539, -0.0032291587050616377]\n",
      "Layer: Layer 1, Input: [-0.025436117545079028, -0.8973203140107122, 0.3600267397721539, -0.0032291587050616377], Output: [-0.6389245250749859, 0.581634946624467, -0.6046106523094589, -0.1577492299125773]\n",
      "Layer: Layer 2, Input: [-0.6389245250749859, 0.581634946624467, -0.6046106523094589, -0.1577492299125773], Output: [-0.9878229778609428]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6787057044702483, 0.7926564304078061, -0.8192320993073944, -0.9762710955804597]\n",
      "Layer: Layer 1, Input: [0.6787057044702483, 0.7926564304078061, -0.8192320993073944, -0.9762710955804597], Output: [0.9424834492110665, 0.008220533027697355, 0.5018028803149971, 0.21730839824978854]\n",
      "Layer: Layer 2, Input: [0.9424834492110665, 0.008220533027697355, 0.5018028803149971, 0.21730839824978854], Output: [0.8575552942981397]\n",
      "Epoch 62/100, Loss: 0.010105580592334053, Accuracy: 0.6922903071277469\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9910177944134543, 0.9809404544403904, -0.8649671377597817, -0.9990493525696613]\n",
      "Layer: Layer 1, Input: [0.9910177944134543, 0.9809404544403904, -0.8649671377597817, -0.9990493525696613], Output: [0.9778068475249488, -0.18021142888782016, 0.6489334884939758, 0.13880973326666446]\n",
      "Layer: Layer 2, Input: [0.9778068475249488, -0.18021142888782016, 0.6489334884939758, 0.13880973326666446], Output: [1.139777241229864]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8585535150630292, 0.001300360228492553, -0.9832640452965253, -0.9752710132874984]\n",
      "Layer: Layer 1, Input: [-0.8585535150630292, 0.001300360228492553, -0.9832640452965253, -0.9752710132874984], Output: [-0.2271888204619235, 0.7016193315725702, -0.58368053781121, 0.4466009890067709]\n",
      "Layer: Layer 2, Input: [-0.2271888204619235, 0.7016193315725702, -0.58368053781121, 0.4466009890067709], Output: [-0.9879111113098566]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.024810563171459254, -0.8971932043444107, 0.3602145337444501, -0.003539096116687676]\n",
      "Layer: Layer 1, Input: [-0.024810563171459254, -0.8971932043444107, 0.3602145337444501, -0.003539096116687676], Output: [-0.6388148398594256, 0.5815669617970093, -0.6043191724046361, -0.1577885453878159]\n",
      "Layer: Layer 2, Input: [-0.6388148398594256, 0.5815669617970093, -0.6043191724046361, -0.1577885453878159], Output: [-0.9879887410135215]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6804683743974443, 0.7938259403127953, -0.8191175906975205, -0.9762662750111256]\n",
      "Layer: Layer 1, Input: [0.6804683743974443, 0.7938259403127953, -0.8191175906975205, -0.9762662750111256], Output: [0.9427764491914948, 0.008042892450286452, 0.5035155421382032, 0.21748092084882897]\n",
      "Layer: Layer 2, Input: [0.9427764491914948, 0.008042892450286452, 0.5035155421382032, 0.21748092084882897], Output: [0.8585582671154036]\n",
      "Epoch 63/100, Loss: 0.009958463134858004, Accuracy: 0.6946808782089179\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.991113377484891, 0.9811415842452679, -0.8648051456927047, -0.9990493403833539]\n",
      "Layer: Layer 1, Input: [0.991113377484891, 0.9811415842452679, -0.8648051456927047, -0.9990493403833539], Output: [0.9778179557204179, -0.1791231249845809, 0.6495617663024282, 0.13939514991565316]\n",
      "Layer: Layer 2, Input: [0.9778179557204179, -0.1791231249845809, 0.6495617663024282, 0.13939514991565316], Output: [1.1387445012358546]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8582121512386224, 0.0007931399293480883, -0.983255175199255, -0.9752767315713103]\n",
      "Layer: Layer 1, Input: [-0.8582121512386224, 0.0007931399293480883, -0.983255175199255, -0.9752767315713103], Output: [-0.22745712846602612, 0.701578187820797, -0.5835374149115358, 0.4461619838320141]\n",
      "Layer: Layer 2, Input: [-0.22745712846602612, 0.701578187820797, -0.5835374149115358, 0.4461619838320141], Output: [-0.9880744215111006]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.024193225290514105, -0.8970673840380967, 0.3604004708537842, -0.0038438173128442074]\n",
      "Layer: Layer 1, Input: [-0.024193225290514105, -0.8970673840380967, 0.3604004708537842, -0.0038438173128442074], Output: [-0.6387063527563758, 0.5814994093863961, -0.6040314867493722, -0.15782696027758172]\n",
      "Layer: Layer 2, Input: [-0.6387063527563758, 0.5814994093863961, -0.6040314867493722, -0.15782696027758172], Output: [-0.9881523356209054]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6821992298210374, 0.7949748390772186, -0.8190041369858124, -0.976261413378008]\n",
      "Layer: Layer 1, Input: [0.6821992298210374, 0.7949748390772186, -0.8190041369858124, -0.976261413378008], Output: [0.9430628241881066, 0.007873958033388053, 0.5052007305094275, 0.21765251400660124]\n",
      "Layer: Layer 2, Input: [0.9430628241881066, 0.007873958033388053, 0.5052007305094275, 0.21765251400660124], Output: [0.8595424820481585]\n",
      "Epoch 64/100, Loss: 0.009815234386478123, Accuracy: 0.69702473794431\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9912066882435212, 0.9813381678351156, -0.8646443799980249, -0.9990493207982712]\n",
      "Layer: Layer 1, Input: [0.9912066882435212, 0.9813381678351156, -0.8646443799980249, -0.9990493207982712], Output: [0.977828770921057, -0.17804888651991058, 0.6501833918146123, 0.13997163063499796]\n",
      "Layer: Layer 2, Input: [0.977828770921057, -0.17804888651991058, 0.6501833918146123, 0.13997163063499796], Output: [1.1377319335989173]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8578749488028579, 0.0002936013097452523, -0.9832464030562615, -0.9752822961590649]\n",
      "Layer: Layer 1, Input: [-0.8578749488028579, 0.0002936013097452523, -0.9832464030562615, -0.9752822961590649], Output: [-0.22772110688803146, 0.7015365334733389, -0.5833949420935638, 0.44572864550117536]\n",
      "Layer: Layer 2, Input: [-0.22772110688803146, 0.7015365334733389, -0.5833949420935638, 0.44572864550117536], Output: [-0.9882330259777092]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.023583816160495874, -0.8969428297803174, 0.36058458081034644, -0.004143394753649851]\n",
      "Layer: Layer 1, Input: [-0.023583816160495874, -0.8969428297803174, 0.36058458081034644, -0.004143394753649851], Output: [-0.6385989498403803, 0.5814321976496302, -0.6037474913111139, -0.15786460545231304]\n",
      "Layer: Layer 2, Input: [-0.6385989498403803, 0.5814321976496302, -0.6037474913111139, -0.15786460545231304], Output: [-0.9883136068827236]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6838992203105666, 0.7961037049139765, -0.8188917187601948, -0.9762565109202755]\n",
      "Layer: Layer 1, Input: [0.6838992203105666, 0.7961037049139765, -0.8188917187601948, -0.9762565109202755], Output: [0.9433428054334186, 0.007713408535275872, 0.5068591852545874, 0.21782314847799175]\n",
      "Layer: Layer 2, Input: [0.9433428054334186, 0.007713408535275872, 0.5068591852545874, 0.21782314847799175], Output: [0.8605085245950389]\n",
      "Epoch 65/100, Loss: 0.009675747676320557, Accuracy: 0.6993232238565544\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9912978091134752, 0.9815303574479661, -0.8644848201069081, -0.9990492939111041]\n",
      "Layer: Layer 1, Input: [0.9912978091134752, 0.9815303574479661, -0.8644848201069081, -0.9990492939111041], Output: [0.9778393030485967, -0.17698836467576723, 0.650798487775731, 0.14053942151258506]\n",
      "Layer: Layer 2, Input: [0.9778393030485967, -0.17698836467576723, 0.650798487775731, 0.14053942151258506], Output: [1.136738929976777]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8575418078888845, -0.0001986195744284056, -0.9832377269787503, -0.9752877098563142]\n",
      "Layer: Layer 1, Input: [-0.8575418078888845, -0.0001986195744284056, -0.9832377269787503, -0.9752877098563142], Output: [-0.22798098973865827, 0.7014944444227149, -0.5832532337316132, 0.44530073336216147]\n",
      "Layer: Layer 2, Input: [-0.22798098973865827, 0.7014944444227149, -0.5832532337316132, 0.44530073336216147], Output: [-0.9883871764405922]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.022982069189398952, -0.8968195186630029, 0.36076689403525064, -0.004437906050635477]\n",
      "Layer: Layer 1, Input: [-0.022982069189398952, -0.8968195186630029, 0.36076689403525064, -0.004437906050635477], Output: [-0.6384925321233761, 0.5813652482942779, -0.6034670867281687, -0.15790159397993203]\n",
      "Layer: Layer 2, Input: [-0.6384925321233761, 0.5813652482942779, -0.6034670867281687, -0.15790159397993203], Output: [-0.9884724296500759]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6855692546234424, 0.7972130948154796, -0.8187803168909622, -0.9762515680254608]\n",
      "Layer: Layer 1, Input: [0.6855692546234424, 0.7972130948154796, -0.8187803168909622, -0.9762515680254608], Output: [0.94361661336797, 0.007560939426244121, 0.5084916188732092, 0.21799280052549522]\n",
      "Layer: Layer 2, Input: [0.94361661336797, 0.007560939426244121, 0.5084916188732092, 0.21799280052549522], Output: [0.8614569516091044]\n",
      "Epoch 66/100, Loss: 0.009539863444457584, Accuracy: 0.7015776277229955\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9913868184046677, 0.9817182987010489, -0.8643264455146414, -0.9990492598305705]\n",
      "Layer: Layer 1, Input: [0.9913868184046677, 0.9817182987010489, -0.8643264455146414, -0.9990492598305705], Output: [0.9778495616097885, -0.17594122132231327, 0.6514071740303916, 0.1410987598185952]\n",
      "Layer: Layer 2, Input: [0.9778495616097885, -0.17594122132231327, 0.6514071740303916, 0.1410987598185952], Output: [1.1357649041743199]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8572126325812987, -0.0006838538461385764, -0.9832291451054513, -0.9752929755510864]\n",
      "Layer: Layer 1, Input: [-0.8572126325812987, -0.0006838538461385764, -0.9832291451054513, -0.9752929755510864], Output: [-0.2282369880197919, 0.701451988285992, -0.5831123867238984, 0.44487802789901904]\n",
      "Layer: Layer 2, Input: [-0.2282369880197919, 0.701451988285992, -0.5831123867238984, 0.44487802789901904], Output: [-0.9885371032529517]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.022387736860662328, -0.8966974282034985, 0.3609474414546046, -0.004727432955633091]\n",
      "Layer: Layer 1, Input: [-0.022387736860662328, -0.8966974282034985, 0.3609474414546046, -0.004727432955633091], Output: [-0.6383870137945626, 0.5812984948608543, -0.6031901780250645, -0.15793802325537987]\n",
      "Layer: Layer 2, Input: [-0.6383870137945626, 0.5812984948608543, -0.6031901780250645, -0.15793802325537987], Output: [-0.9886287048193474]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6872102030994669, 0.7983035454471082, -0.818669912548158, -0.9762465852062705]\n",
      "Layer: Layer 1, Input: [0.6872102030994669, 0.7983035454471082, -0.818669912548158, -0.9762465852062705], Output: [0.9438844582681982, 0.007416261520731933, 0.510098717869726, 0.21816145118791846]\n",
      "Layer: Layer 2, Input: [0.9438844582681982, 0.007416261520731933, 0.510098717869726, 0.21816145118791846], Output: [0.862388293646281]\n",
      "Epoch 67/100, Loss: 0.009407448821740865, Accuracy: 0.7037891975442603\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9914737905823222, 0.9819021309386469, -0.8641692358318179, -0.9990492186752418]\n",
      "Layer: Layer 1, Input: [0.9914737905823222, 0.9819021309386469, -0.8641692358318179, -0.9990492186752418], Output: [0.9778595557151879, -0.17490712890368415, 0.6520095676440085, 0.1416498743242207]\n",
      "Layer: Layer 2, Input: [0.9778595557151879, -0.17490712890368415, 0.6520095676440085, 0.1416498743242207], Output: [1.1348092916294426]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8568873306904382, -0.0011624035558438191, -0.9832206556046266, -0.975298096191274]\n",
      "Layer: Layer 1, Input: [-0.8568873306904382, -0.0011624035558438191, -0.9832206556046266, -0.975298096191274], Output: [-0.22848929248020483, 0.7014092253583077, -0.5829724827490015, 0.44446032833287114]\n",
      "Layer: Layer 2, Input: [-0.22848929248020483, 0.7014092253583077, -0.5829724827490015, 0.44446032833287114], Output: [-0.9886830178335361]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.021800588873890844, -0.8965765363592949, 0.36112625432029355, -0.005012060474569361]\n",
      "Layer: Layer 1, Input: [-0.021800588873890844, -0.8965765363592949, 0.36112625432029355, -0.005012060474569361], Output: [-0.6382823206501906, 0.5812318812800089, -0.6029166743449886, -0.1579739768932769]\n",
      "Layer: Layer 2, Input: [-0.6382823206501906, 0.5812318812800089, -0.6029166743449886, -0.1579739768932769], Output: [-0.9887823560937475]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6888228998723144, 0.799375574005568, -0.8185604872159565, -0.9762415630801697]\n",
      "Layer: Layer 1, Input: [0.6888228998723144, 0.799375574005568, -0.8185604872159565, -0.9762415630801697], Output: [0.9441465408310975, 0.007279099789436112, 0.5116811439871246, 0.21832908564868025]\n",
      "Layer: Layer 2, Input: [0.9441465408310975, 0.007279099789436112, 0.5116811439871246, 0.21832908564868025], Output: [0.8633030569946396]\n",
      "Epoch 68/100, Loss: 0.009278377239201597, Accuracy: 0.7059591392924807\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9915587965142934, 0.9820819875589969, -0.8640131708285069, -0.9990491705716412]\n",
      "Layer: Layer 1, Input: [0.9915587965142934, 0.9820819875589969, -0.8640131708285069, -0.9990491705716412], Output: [0.9778692940972812, -0.17388577025051208, 0.6526057830016665, 0.14219298562066773]\n",
      "Layer: Layer 2, Input: [0.9778692940972812, -0.17388577025051208, 0.6526057830016665, 0.14219298562066773], Output: [1.1338715487936917]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8565658135405982, -0.0016345449389091975, -0.9832122566757231, -0.9753030747649327]\n",
      "Layer: Layer 1, Input: [-0.8565658135405982, -0.0016345449389091975, -0.9832122566757231, -0.9753030747649327], Output: [-0.22873807599517768, 0.7013662094452541, -0.5828335902173033, 0.4440474505345245]\n",
      "Layer: Layer 2, Input: [-0.22873807599517768, 0.7013662094452541, -0.5828335902173033, 0.4440474505345245], Output: [-0.9888251147602205]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.021220410479277738, -0.8964568215370978, 0.3613033640547143, -0.005291876093216938]\n",
      "Layer: Layer 1, Input: [-0.021220410479277738, -0.8964568215370978, 0.3613033640547143, -0.005291876093216938], Output: [-0.6381783886953004, 0.5811653605882938, -0.6026464886993385, -0.15800952640791058]\n",
      "Layer: Layer 2, Input: [-0.6381783886953004, 0.5811653605882938, -0.6026464886993385, -0.15800952640791058], Output: [-0.9889333270851481]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6904081449152112, 0.8004296790421378, -0.8184520227042663, -0.9762365023514517]\n",
      "Layer: Layer 1, Input: [0.6904081449152112, 0.8004296790421378, -0.8184520227042663, -0.9762365023514517], Output: [0.9444030527189392, 0.007149192318286796, 0.5132395353558465, 0.21849569268873342]\n",
      "Layer: Layer 2, Input: [0.9444030527189392, 0.007149192318286796, 0.5132395353558465, 0.21849569268873342], Output: [0.8642017254447596]\n",
      "Epoch 69/100, Loss: 0.009152528064532196, Accuracy: 0.7080886184964366\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9916419036983768, 0.9822579963216006, -0.8638582304720664, -0.9990491156525801]\n",
      "Layer: Layer 1, Input: [0.9916419036983768, 0.9822579963216006, -0.8638582304720664, -0.9990491156525801], Output: [0.977878785127911, -0.17287683834175427, 0.653195931890965, 0.1427283064347945]\n",
      "Layer: Layer 2, Input: [0.977878785127911, -0.17287683834175427, 0.653195931890965, 0.1427283064347945], Output: [1.132951152446315]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8562479957719675, -0.0021005312564987035, -0.9832039465507019, -0.9753079142831949]\n",
      "Layer: Layer 1, Input: [-0.8562479957719675, -0.0021005312564987035, -0.9832039465507019, -0.9753079142831949], Output: [-0.22898349562971249, 0.701322988591741, -0.5826957659640137, 0.44363922520191823]\n",
      "Layer: Layer 2, Input: [-0.22898349562971249, 0.701322988591741, -0.5826957659640137, 0.44363922520191823], Output: [-0.9889635735748066]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.020647000986154317, -0.896338262597508, 0.3614788021168936, -0.0055669691029623745]\n",
      "Layer: Layer 1, Input: [-0.020647000986154317, -0.896338262597508, 0.3614788021168936, -0.0055669691029623745], Output: [-0.6380751629005541, 0.581098893787162, -0.6023795377340111, -0.15804473270274985]\n",
      "Layer: Layer 2, Input: [-0.6380751629005541, 0.581098893787162, -0.6023795377340111, -0.15804473270274985], Output: [-0.9890815787281959]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6919667059361372, 0.801466341251201, -0.8183445011577967, -0.976231403795522]\n",
      "Layer: Layer 1, Input: [0.6919667059361372, 0.801466341251201, -0.8183445011577967, -0.976231403795522], Output: [0.9446541770671023, 0.007026289388368598, 0.5147745075682292, 0.21866126421168466]\n",
      "Layer: Layer 2, Input: [0.9446541770671023, 0.007026289388368598, 0.5147745075682292, 0.21866126421168466], Output: [0.8650847618481543]\n",
      "Epoch 70/100, Loss: 0.009029786263419952, Accuracy: 0.7101787617048418\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9917231764715468, 0.9824302796362272, -0.8637043949592308, -0.9990490540557125]\n",
      "Layer: Layer 1, Input: [0.9917231764715468, 0.9824302796362272, -0.8637043949592308, -0.9990490540557125], Output: [0.9778880368349775, -0.17188003603260807, 0.6537801235735712, 0.14325604193878994]\n",
      "Layer: Layer 2, Input: [0.9778880368349775, -0.17188003603260807, 0.6537801235735712, 0.14325604193878994], Output: [1.132047598969997]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8559337951558286, -0.002560595281338682, -0.9831957234950754, -0.9753126177655215]\n",
      "Layer: Layer 1, Input: [-0.8559337951558286, -0.002560595281338682, -0.9831957234950754, -0.9753126177655215], Output: [-0.2292256944339652, 0.7012796057219537, -0.582559056722147, 0.4432354962638316]\n",
      "Layer: Layer 2, Input: [-0.2292256944339652, 0.7012796057219537, -0.582559056722147, 0.4432354962638316], Output: [-0.9890985603475868]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.020080172427785398, -0.8962208388562948, 0.3616525998876233, -0.005837430015646502]\n",
      "Layer: Layer 1, Input: [-0.020080172427785398, -0.8962208388562948, 0.3616525998876233, -0.005837430015646502], Output: [-0.6379725960985073, 0.581032448830857, -0.6021157415118014, -0.15807964738972813]\n",
      "Layer: Layer 2, Input: [-0.6379725960985073, 0.581032448830857, -0.6021157415118014, -0.15807964738972813], Output: [-0.9892270869790476]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6934993201362074, 0.8024860242247435, -0.8182379050628353, -0.9762262682451633]\n",
      "Layer: Layer 1, Input: [0.6934993201362074, 0.8024860242247435, -0.8182379050628353, -0.9762262682451633], Output: [0.9449000889578285, 0.006910152656394309, 0.5162866546867724, 0.2188257948307709]\n",
      "Layer: Layer 2, Input: [0.9449000889578285, 0.006910152656394309, 0.5162866546867724, 0.2188257948307709], Output: [0.8659526095005701]\n",
      "Epoch 71/100, Loss: 0.008910042083725003, Accuracy: 0.7122306578572075\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9918026762028479, 0.982598954834805, -0.8635516447430784, -0.9990489859222785]\n",
      "Layer: Layer 1, Input: [0.9918026762028479, 0.982598954834805, -0.8635516447430784, -0.9990489859222785], Output: [0.9778970569184089, -0.17089507576095772, 0.6543584648488854, 0.14377639005207]\n",
      "Layer: Layer 2, Input: [0.9778970569184089, -0.17089507576095772, 0.6543584648488854, 0.14377639005207], Output: [1.1311604036088383]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8556231324224098, -0.0030149514790965837, -0.9831875858086834, -0.9753171882270358]\n",
      "Layer: Layer 1, Input: [-0.8556231324224098, -0.0030149514790965837, -0.9831875858086834, -0.9753171882270358], Output: [-0.22946480301075872, 0.7012360992026019, -0.5824235004071456, 0.4428361194778812]\n",
      "Layer: Layer 2, Input: [-0.22946480301075872, 0.7012360992026019, -0.5824235004071456, 0.4428361194778812], Output: [-0.9892302290406206]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.019519748366181595, -0.8961045300830297, 0.36182478857145156, -0.006103350057528933]\n",
      "Layer: Layer 1, Input: [-0.019519748366181595, -0.8961045300830297, 0.36182478857145156, -0.006103350057528933], Output: [-0.6378706480049251, 0.5809659997299474, -0.6018550233101135, -0.1581143139566351]\n",
      "Layer: Layer 2, Input: [-0.6378706480049251, 0.5809659997299474, -0.6018550233101135, -0.1581143139566351], Output: [-0.9893698407721357]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6950066958434332, 0.8034891751737024, -0.8181322172519806, -0.976221096578551]\n",
      "Layer: Layer 1, Input: [0.6950066958434332, 0.8034891751737024, -0.8181322172519806, -0.976221096578551], Output: [0.9451409558625019, 0.006800554419581615, 0.5177765501929904, 0.21898928150901742]\n",
      "Layer: Layer 2, Input: [0.9451409558625019, 0.006800554419581615, 0.5177765501929904, 0.21898928150901742], Output: [0.8668056933791887]\n",
      "Epoch 72/100, Loss: 0.008793190760689826, Accuracy: 0.7142453595831068\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9918804614714769, 0.9827641344273211, -0.8633999605554327, -0.9990489113960149]\n",
      "Layer: Layer 1, Input: [0.9918804614714769, 0.9827641344273211, -0.8633999605554327, -0.9990489113960149], Output: [0.9779058527654069, -0.16992167924154836, 0.6549310601122513, 0.14428954173417358]\n",
      "Layer: Layer 2, Input: [0.9779058527654069, -0.16992167924154836, 0.6549310601122513, 0.14428954173417358], Output: [1.130289099723374]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.855315931100682, -0.003463797927650105, -0.9831795318262386, -0.9753216286677058]\n",
      "Layer: Layer 1, Input: [-0.855315931100682, -0.003463797927650105, -0.9831795318262386, -0.9753216286677058], Output: [-0.229700940888091, 0.7011925033397142, -0.5822891272395755, 0.44244096119610393]\n",
      "Layer: Layer 2, Input: [-0.229700940888091, 0.7011925033397142, -0.5822891272395755, 0.44244096119610393], Output: [-0.9893587227011947]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.01896556282222483, -0.8959893164976785, 0.36199539911357026, -0.00636482073337126]\n",
      "Layer: Layer 1, Input: [-0.01896556282222483, -0.8959893164976785, 0.36199539911357026, -0.00636482073337126], Output: [-0.6377692843519783, 0.5808995257583498, -0.6015973094330954, -0.15814876879919487]\n",
      "Layer: Layer 2, Input: [-0.6377692843519783, 0.5808995257583498, -0.6015973094330954, -0.15814876879919487], Output: [-0.9895098402098045]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6964895140327828, 0.8044762256171873, -0.8180274209070572, -0.9762158897088287]\n",
      "Layer: Layer 1, Input: [0.6964895140327828, 0.8044762256171873, -0.8180274209070572, -0.9762158897088287], Output: [0.9453769380548448, 0.006697276952067669, 0.5192447478824402, 0.21915172324527496]\n",
      "Layer: Layer 2, Input: [0.9453769380548448, 0.006697276952067669, 0.5192447478824402, 0.21915172324527496], Output: [0.8676444212567631]\n",
      "Epoch 73/100, Loss: 0.008679132241539602, Accuracy: 0.7162238844443882\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9919565882314267, 0.9829259263427728, -0.8632493234252205, -0.9990488306222192]\n",
      "Layer: Layer 1, Input: [0.9919565882314267, 0.9829259263427728, -0.8632493234252205, -0.9990488306222192], Output: [0.9779144314649786, -0.1689595771546284, 0.65549801140943, 0.1447956812678667]\n",
      "Layer: Layer 2, Input: [0.9779144314649786, -0.1689595771546284, 0.65549801140943, 0.1447956812678667], Output: [1.129433238053145]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8550121173693459, -0.003907318009656067, -0.983171559917669, -0.9753259420631616]\n",
      "Layer: Layer 1, Input: [-0.8550121173693459, -0.003907318009656067, -0.983171559917669, -0.9753259420631616], Output: [-0.2299342177239891, 0.7011488488176432, -0.5821559607280261, 0.442049897275708]\n",
      "Layer: Layer 2, Input: [-0.2299342177239891, 0.7011488488176432, -0.5821559607280261, 0.442049897275708], Output: [-0.9894841745110715]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.01841745931786219, -0.895875178765617, 0.36216446212983244, -0.0066219334525301635]\n",
      "Layer: Layer 1, Input: [-0.01841745931786219, -0.895875178765617, 0.36216446212983244, -0.0066219334525301635], Output: [-0.6376684761213677, 0.5808330107527802, -0.601342529037274, -0.15818304213273104]\n",
      "Layer: Layer 2, Input: [-0.6376684761213677, 0.5808330107527802, -0.601342529037274, -0.15818304213273104], Output: [-0.9896470949613815]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6979484297423422, 0.8054475920406897, -0.8179234995604372, -0.9762106485750623]\n",
      "Layer: Layer 1, Input: [0.6979484297423422, 0.8054475920406897, -0.8179234995604372, -0.9762106485750623], Output: [0.9456081889972278, 0.006600111902515682, 0.5206917827106021, 0.21931312079994825]\n",
      "Layer: Layer 2, Input: [0.9456081889972278, 0.006600111902515682, 0.5206917827106021, 0.21931312079994825], Output: [0.8684691847110999]\n",
      "Epoch 74/100, Loss: 0.008567770927984282, Accuracy: 0.7181672161304078\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9920311099639155, 0.9830844341561411, -0.8630997146932528, -0.9990487437469392]\n",
      "Layer: Layer 1, Input: [0.9920311099639155, 0.9830844341561411, -0.8630997146932528, -0.9990487437469392], Output: [0.9779227998217781, -0.1680085088339763, 0.6560594184885356, 0.14529498653200112]\n",
      "Layer: Layer 2, Input: [0.9779227998217781, -0.1680085088339763, 0.6560594184885356, 0.14529498653200112], Output: [1.1285923859941533]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8547116199182523, -0.004345681908289774, -0.983163668488282, -0.975330131356955]\n",
      "Layer: Layer 1, Input: [-0.8547116199182523, -0.004345681908289774, -0.983163668488282, -0.975330131356955], Output: [-0.23016473436660176, 0.7011051630876468, -0.5820240185308836, 0.4416628121160392]\n",
      "Layer: Layer 2, Input: [-0.23016473436660176, 0.7011051630876468, -0.5820240185308836, 0.4416628121160392], Output: [-0.9896067087125034]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.017875290018438746, -0.8957620979914396, 0.3623320078483118, -0.006874779209778053]\n",
      "Layer: Layer 1, Input: [-0.017875290018438746, -0.8957620979914396, 0.3623320078483118, -0.006874779209778053], Output: [-0.6375681988665445, 0.5807664424945969, -0.6010906139697539, -0.15821715879680884]\n",
      "Layer: Layer 2, Input: [-0.6375681988665445, 0.5807664424945969, -0.6010906139697539, -0.15821715879680884], Output: [-0.9897816228500048]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6993840733943757, 0.8064036765244453, -0.8178204370949669, -0.9762053741344144]\n",
      "Layer: Layer 1, Input: [0.6993840733943757, 0.8064036765244453, -0.8178204370949669, -0.9762053741344144], Output: [0.9458348557021139, 0.006508859744545677, 0.5221181715935808, 0.21947347645515305]\n",
      "Layer: Layer 2, Input: [0.9458348557021139, 0.006508859744545677, 0.5221181715935808, 0.21947347645515305], Output: [0.8692803600447083]\n",
      "Epoch 75/100, Loss: 0.008459015435269179, Accuracy: 0.7200763056130632\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9921040778186969, 0.983239757302296, -0.8629511160238633, -0.9990486509162847]\n",
      "Layer: Layer 1, Input: [0.9921040778186969, 0.983239757302296, -0.8629511160238633, -0.9990486509162847], Output: [0.9779309643692772, -0.167068221957846, 0.6566153788502502, 0.14578762926391117]\n",
      "Layer: Layer 2, Input: [0.9779309643692772, -0.167068221957846, 0.6566153788502502, 0.14578762926391117], Output: [1.1277661268961692]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8544143698194987, -0.004779047931488104, -0.9831558559787738, -0.9753341994540913]\n",
      "Layer: Layer 1, Input: [-0.8544143698194987, -0.004779047931488104, -0.9831558559787738, -0.9753341994540913], Output: [-0.23039258378879757, 0.7010614707123494, -0.5818933132128103, 0.44127959780565024]\n",
      "Layer: Layer 2, Input: [-0.23039258378879757, 0.7010614707123494, -0.5818933132128103, 0.44127959780565024], Output: [-0.9897264414283478]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.017338914964472752, -0.8956500557118507, 0.3624980660609836, -0.0071234483143362915]\n",
      "Layer: Layer 1, Input: [-0.017338914964472752, -0.8956500557118507, 0.3624980660609836, -0.0071234483143362915], Output: [-0.637468432114283, 0.5806998121649841, -0.6008414986180752, -0.15825113896482879]\n",
      "Layer: Layer 2, Input: [-0.637468432114283, 0.5806998121649841, -0.6008414986180752, -0.15825113896482879], Output: [-0.9899134486073777]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.700797052029213, 0.8073448673431469, -0.8177182177426846, -0.9762000673553933]\n",
      "Layer: Layer 1, Input: [0.700797052029213, 0.8073448673431469, -0.8177182177426846, -0.9762000673553933], Output: [0.9460570790704921, 0.006423329273149575, 0.5235244141670421, 0.21963279380481016]\n",
      "Layer: Layer 2, Input: [0.9460570790704921, 0.006423329273149575, 0.5235244141670421, 0.21963279380481016], Output: [0.8700783091266646]\n",
      "Epoch 76/100, Loss: 0.008352778366538926, Accuracy: 0.7219520722662209\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9921755407452335, 0.9833919912776729, -0.8628035094137866, -0.9990485522758371]\n",
      "Layer: Layer 1, Input: [0.9921755407452335, 0.9833919912776729, -0.8628035094137866, -0.9990485522758371], Output: [0.9779389313822919, -0.16613847224534337, 0.6571659877968685, 0.14627377531131297]\n",
      "Layer: Layer 2, Input: [0.9779389313822919, -0.16613847224534337, 0.6571659877968685, 0.14627377531131297], Output: [1.1269540593831384]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8541203004074767, -0.005207563686296982, -0.9831481208651075, -0.9753381492156719]\n",
      "Layer: Layer 1, Input: [-0.8541203004074767, -0.005207563686296982, -0.9831481208651075, -0.9753381492156719], Output: [-0.23061785191357861, 0.701017793671482, -0.5817638529094267, 0.44090015336570704]\n",
      "Layer: Layer 2, Input: [-0.23061785191357861, 0.701017793671482, -0.5817638529094267, 0.44090015336570704], Output: [-0.989843481390656]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.01680820138327399, -0.895539033887865, 0.3626626660842631, -0.007368030161304971]\n",
      "Layer: Layer 1, Input: [-0.01680820138327399, -0.895539033887865, 0.3626626660842631, -0.007368030161304971], Output: [-0.6373691588368186, 0.5806331138653271, -0.6005951197708411, -0.15828499876928726]\n",
      "Layer: Layer 2, Input: [-0.6373691588368186, 0.5806331138653271, -0.6005951197708411, -0.15828499876928726], Output: [-0.9900426027783535]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7021879504591103, 0.8082715395382062, -0.8176168260824961, -0.9761947292120537]\n",
      "Layer: Layer 1, Input: [0.7021879504591103, 0.8082715395382062, -0.8176168260824961, -0.9761947292120537], Output: [0.946274994208998, 0.006343337141459394, 0.524910993506363, 0.21979107757082122]\n",
      "Layer: Layer 2, Input: [0.946274994208998, 0.006343337141459394, 0.524910993506363, 0.21979107757082122], Output: [0.870863380166546]\n",
      "Epoch 77/100, Loss: 0.008248976101389768, Accuracy: 0.7237954049524171\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.992245545614615, 0.9835412278305068, -0.8626568771986265, -0.9990484479701499]\n",
      "Layer: Layer 1, Input: [0.992245545614615, 0.9835412278305068, -0.8626568771986265, -0.9990484479701499], Output: [0.9779467068888924, -0.16521902315997752, 0.6577113384805168, 0.1467535848737998]\n",
      "Layer: Layer 2, Input: [0.9779467068888924, -0.16521902315997752, 0.6577113384805168, 0.1467535848737998], Output: [1.1261557966986433]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.853829347167182, -0.005631367121859622, -0.9831404616582745, -0.9753419834545167]\n",
      "Layer: Layer 1, Input: [-0.853829347167182, -0.005631367121859622, -0.9831404616582745, -0.9753419834545167], Output: [-0.23084061834422664, 0.7009741516335828, -0.581635641911766, 0.44052438407790206]\n",
      "Layer: Layer 2, Input: [-0.23084061834422664, 0.7009741516335828, -0.581635641911766, 0.44052438407790206], Output: [-0.989957930589827]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.016283023071826466, -0.8954290148965031, 0.3628258367272723, -0.007608613040307309]\n",
      "Layer: Layer 1, Input: [-0.016283023071826466, -0.8954290148965031, 0.3628258367272723, -0.007608613040307309], Output: [-0.6372703649866996, 0.5805663441954735, -0.600351416488297, -0.15831875085225536]\n",
      "Layer: Layer 2, Input: [-0.6372703649866996, 0.5805663441954735, -0.600351416488297, -0.15831875085225536], Output: [-0.9901691207589929]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7035573323485392, 0.8091840554637544, -0.8175162470369618, -0.9761893606790324]\n",
      "Layer: Layer 1, Input: [0.7035573323485392, 0.8091840554637544, -0.8175162470369618, -0.9761893606790324], Output: [0.9464887307272875, 0.006268707433187763, 0.5262783768106055, 0.21994833344200423]\n",
      "Layer: Layer 2, Input: [0.9464887307272875, 0.006268707433187763, 0.5262783768106055, 0.21994833344200423], Output: [0.8716359084285829]\n",
      "Epoch 78/100, Loss: 0.008147528597578647, Accuracy: 0.7256071630787594\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9923141373330123, 0.9836875551403551, -0.8625112020572265, -0.9990483381423281]\n",
      "Layer: Layer 1, Input: [0.9923141373330123, 0.9836875551403551, -0.8625112020572265, -0.9990483381423281], Output: [0.9779542966817225, -0.16430964562155959, 0.6582515219507687, 0.14722721273412206]\n",
      "Layer: Layer 2, Input: [0.9779542966817225, -0.16430964562155959, 0.6582515219507687, 0.14722721273412206], Output: [1.1253709660774718]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8535414476301334, -0.006050587456982442, -0.9831328769039612, -0.9753457049316369]\n",
      "Layer: Layer 1, Input: [-0.8535414476301334, -0.006050587456982442, -0.9831328769039612, -0.9753457049316369], Output: [-0.23106095701105603, 0.7009305621976853, -0.5815086811804576, 0.4401522008866762]\n",
      "Layer: Layer 2, Input: [-0.23106095701105603, 0.7009305621976853, -0.5815086811804576, 0.4401522008866762], Output: [-0.990069884854451]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.015763259843259343, -0.8953199815221219, 0.36298760626683907, -0.007845283976742687]\n",
      "Layer: Layer 1, Input: [-0.015763259843259343, -0.8953199815221219, 0.36298760626683907, -0.007845283976742687], Output: [-0.6371720390873041, 0.5804995018833383, -0.600110329982064, -0.1583524048495935]\n",
      "Layer: Layer 2, Input: [-0.6371720390873041, 0.5804995018833383, -0.600110329982064, -0.1583524048495935], Output: [-0.9902930419533001]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7049057412267422, 0.8100827653075569, -0.8174164658683273, -0.9761839627273173]\n",
      "Layer: Layer 1, Input: [0.7049057412267422, 0.8100827653075569, -0.8174164658683273, -0.9761839627273173], Output: [0.9466984130170933, 0.00619927126680809, 0.5276270160526579, 0.22010456793293343]\n",
      "Layer: Layer 2, Input: [0.9466984130170933, 0.00619927126680809, 0.5276270160526579, 0.22010456793293343], Output: [0.8723962168928281]\n",
      "Epoch 79/100, Loss: 0.008048359204946249, Accuracy: 0.7273881776231075\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9923813589473823, 0.983831057987588, -0.8623664670142173, -0.9990482229336762]\n",
      "Layer: Layer 1, Input: [0.9923813589473823, 0.983831057987588, -0.8623664670142173, -0.9990482229336762], Output: [0.9779617063287562, -0.16341011772719344, 0.6587866272017682, 0.14769480847950253]\n",
      "Layer: Layer 2, Input: [0.9779617063287562, -0.16341011772719344, 0.6587866272017682, 0.14769480847950253], Output: [1.1245992081436493]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8532565412772984, -0.006465346006088152, -0.9831253651821321, -0.9753493163534511]\n",
      "Layer: Layer 1, Input: [-0.8532565412772984, -0.006465346006088152, -0.9831253651821321, -0.9753493163534511], Output: [-0.23127893674503, 0.7008870411085233, -0.5813829687982442, 0.4397835198669108]\n",
      "Layer: Layer 2, Input: [-0.23127893674503, 0.7008870411085233, -0.5813829687982442, 0.4397835198669108], Output: [-0.9901794343704907]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.015248797030051992, -0.8952119169475004, 0.36314800242834033, -0.008078128601558416]\n",
      "Layer: Layer 1, Input: [-0.015248797030051992, -0.8952119169475004, 0.36314800242834033, -0.008078128601558416], Output: [-0.6370741718727307, 0.5804325874600053, -0.5998718035033077, -0.15838596781648626]\n",
      "Layer: Layer 2, Input: [-0.6370741718727307, 0.5804325874600053, -0.5998718035033077, -0.15838596781648626], Output: [-0.9904144090353441]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.706233701437843, 0.8109680075879793, -0.8173174681739215, -0.9761785363206653]\n",
      "Layer: Layer 1, Input: [0.706233701437843, 0.8109680075879793, -0.8173174681739215, -0.9761785363206653], Output: [0.9469041605142826, 0.006134866428158806, 0.5289573485976303, 0.22025978826019402]\n",
      "Layer: Layer 2, Input: [0.9469041605142826, 0.006134866428158806, 0.5289573485976303, 0.22025978826019402], Output: [0.8731446168690443]\n",
      "Epoch 80/100, Loss: 0.0079513944906878, Accuracy: 0.7291392521312298\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9924472517440638, 0.9839718179134789, -0.8622226554409917, -0.9990481024834068]\n",
      "Layer: Layer 1, Input: [0.9924472517440638, 0.9839718179134789, -0.8622226554409917, -0.9990481024834068], Output: [0.9779689411835187, -0.16252022448180437, 0.6593167412189139, 0.14815651671328844]\n",
      "Layer: Layer 2, Input: [0.9779689411835187, -0.16252022448180437, 0.6593167412189139, 0.14815651671328844], Output: [1.1238401763348405]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8529745694484595, -0.0068757569155277485, -0.9831179251065459, -0.975352820369647]\n",
      "Layer: Layer 1, Input: [-0.8529745694484595, -0.0068757569155277485, -0.9831179251065459, -0.975352820369647], Output: [-0.23149462178706223, 0.7008436024483086, -0.5812585003682978, 0.43941826174940046]\n",
      "Layer: Layer 2, Input: [-0.23149462178706223, 0.7008436024483086, -0.5812585003682978, 0.43941826174940046], Output: [-0.9902866641471386]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.014739525037861552, -0.8951048047447702, 0.36330705237160904, -0.008307231045918913]\n",
      "Layer: Layer 1, Input: [-0.014739525037861552, -0.8951048047447702, 0.36330705237160904, -0.008307231045918913], Output: [-0.6369767559714602, 0.5803656029751197, -0.5996357822386613, -0.15841944460103374]\n",
      "Layer: Layer 2, Input: [-0.6369767559714602, 0.5803656029751197, -0.5996357822386613, -0.15841944460103374], Output: [-0.9905332673048461]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.707541719033314, 0.8118401096281205, -0.8172192398810273, -0.9761730824125825]\n",
      "Layer: Layer 1, Input: [0.707541719033314, 0.8118401096281205, -0.8172192398810273, -0.9761730824125825], Output: [0.9471060879451232, 0.006075337028623808, 0.5302697977914185, 0.22041400223390478]\n",
      "Layer: Layer 2, Input: [0.9471060879451232, 0.006075337028623808, 0.5302697977914185, 0.22041400223390478], Output: [0.873881408568177]\n",
      "Epoch 81/100, Loss: 0.007856564075175865, Accuracy: 0.7308611636853213\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9925118553408491, 0.9841099133714855, -0.8620797510553254, -0.9990479769284005]\n",
      "Layer: Layer 1, Input: [0.9925118553408491, 0.9841099133714855, -0.8620797510553254, -0.9990479769284005], Output: [0.977976006394797, -0.16163975753840398, 0.6598419490251154, 0.14861247725726393]\n",
      "Layer: Layer 2, Input: [0.977976006394797, -0.16163975753840398, 0.6598419490251154, 0.14861247725726393], Output: [1.1230935363526762]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.852695475257506, -0.0072819278206890745, -0.9831105553242145, -0.9753562195716027]\n",
      "Layer: Layer 1, Input: [-0.852695475257506, -0.0072819278206890745, -0.9831105553242145, -0.9753562195716027], Output: [-0.23170807224068152, 0.7008002588077719, -0.581135269364833, 0.4390563514974124]\n",
      "Layer: Layer 2, Input: [-0.23170807224068152, 0.7008002588077719, -0.581135269364833, 0.4390563514974124], Output: [-0.9903916544356727]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.014235338944509198, -0.8949986288662665, 0.3634647826812134, -0.008532673857558425]\n",
      "Layer: Layer 1, Input: [-0.014235338944509198, -0.8949986288662665, 0.3634647826812134, -0.008532673857558425], Output: [-0.6368797856287737, 0.5802985517479172, -0.5994022132132765, -0.1584528381719019]\n",
      "Layer: Layer 2, Input: [-0.6368797856287737, 0.5802985517479172, -0.5994022132132765, -0.1584528381719019], Output: [-0.990649664125543]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7088302826111564, 0.8126993880081818, -0.81712176724132, -0.976167601943804]\n",
      "Layer: Layer 1, Input: [0.7088302826111564, 0.8126993880081818, -0.81712176724132, -0.976167601943804], Output: [0.9473043055578728, 0.00602053318645383, 0.5315647735211649, 0.22056721816263558]\n",
      "Layer: Layer 2, Input: [0.9473043055578728, 0.00602053318645383, 0.5315647735211649, 0.22056721816263558], Output: [0.8746068816355463]\n",
      "Epoch 82/100, Loss: 0.007763800477604546, Accuracy: 0.7325546638440859\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9925752077730523, 0.9842454198702691, -0.8619377379198352, -0.9990478464030135]\n",
      "Layer: Layer 1, Input: [0.9925752077730523, 0.9842454198702691, -0.8619377379198352, -0.9990478464030135], Output: [0.9779829069158671, -0.16076851494813138, 0.6603623337265944, 0.1490628253449734]\n",
      "Layer: Layer 2, Input: [0.9779829069158671, -0.16076851494813138, 0.6603623337265944, 0.1490628253449734], Output: [1.1223589656383306]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8524192035131731, -0.007683960433020219, -0.9831032545148148, -0.9753595164912908]\n",
      "Layer: Layer 1, Input: [-0.8524192035131731, -0.007683960433020219, -0.9831032545148148, -0.9753595164912908], Output: [-0.23191934447472703, 0.7007570214388131, -0.5810132674416852, 0.43869771792846096]\n",
      "Layer: Layer 2, Input: [-0.23191934447472703, 0.7007570214388131, -0.5810132674416852, 0.43869771792846096], Output: [-0.990494481106752]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.013736138139272177, -0.8948933736353587, 0.3636212193605001, -0.008754537935987535]\n",
      "Layer: Layer 1, Input: [-0.013736138139272177, -0.8948933736353587, 0.3636212193605001, -0.008754537935987535], Output: [-0.6367832564634858, 0.5802314381497672, -0.5991710452004285, -0.15848614990534501]\n",
      "Layer: Layer 2, Input: [-0.6367832564634858, 0.5802314381497672, -0.5991710452004285, -0.15848614990534501], Output: [-0.9907636484368036]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7100998641057639, 0.8135461489971038, -0.8170250368249588, -0.976162095840203]\n",
      "Layer: Layer 1, Input: [0.7100998641057639, 0.8135461489971038, -0.8170250368249588, -0.976162095840203], Output: [0.9474989193407107, 0.005970310729104727, 0.5328426727492145, 0.22071944477007868]\n",
      "Layer: Layer 2, Input: [0.9474989193407107, 0.005970310729104727, 0.5328426727492145, 0.22071944477007868], Output: [0.8753213156493498]\n",
      "Epoch 83/100, Loss: 0.007673038970780023, Accuracy: 0.7342204795545748\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9926373455740526, 0.9843784101089628, -0.8617966004394512, -0.9990477110389233]\n",
      "Layer: Layer 1, Input: [0.9926373455740526, 0.9843784101089628, -0.8617966004394512, -0.9990477110389233], Output: [0.9779896475132615, -0.15990630091999072, 0.6608779765582046, 0.1495076918064051]\n",
      "Layer: Layer 2, Input: [0.9779896475132615, -0.15990630091999072, 0.6608779765582046, 0.1495076918064051], Output: [1.1216361528725383]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8521457006447903, -0.008081951064948956, -0.9830960213900667, -0.975362713600599]\n",
      "Layer: Layer 1, Input: [-0.8521457006447903, -0.008081951064948956, -0.9830960213900667, -0.975362713600599], Output: [-0.2321284914818887, 0.700713900390833, -0.5808924847038203, 0.43834229337616093]\n",
      "Layer: Layer 2, Input: [-0.2321284914818887, 0.700713900390833, -0.5808924847038203, 0.43834229337616093], Output: [-0.9905952159908695]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.013241825998137563, -0.8947890237373094, 0.3637763878288659, -0.008972902484042079]\n",
      "Layer: Layer 1, Input: [-0.013241825998137563, -0.8947890237373094, 0.3637763878288659, -0.008972902484042079], Output: [-0.6366871652550232, 0.5801642674145493, -0.5989422286371501, -0.15851937983633058]\n",
      "Layer: Layer 2, Input: [-0.6366871652550232, 0.5801642674145493, -0.5989422286371501, -0.15851937983633058], Output: [-0.9908752703299841]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7113509195320795, 0.8143806889644664, -0.8169290355143993, -0.9761565650110815]\n",
      "Layer: Layer 1, Input: [0.7113509195320795, 0.8143806889644664, -0.8169290355143993, -0.9761565650110815], Output: [0.947690031226956, 0.005924530914743799, 0.5341038800220451, 0.2208706911220595]\n",
      "Layer: Layer 2, Input: [0.947690031226956, 0.005924530914743799, 0.5341038800220451, 0.2208706911220595], Output: [0.8760249805875846]\n",
      "Epoch 84/100, Loss: 0.007584217444437385, Accuracy: 0.7358593140359\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9926983038507428, 0.9845089541051654, -0.8616563233580508, -0.9990475709650105]\n",
      "Layer: Layer 1, Input: [0.9926983038507428, 0.9845089541051654, -0.8616563233580508, -0.9990475709650105], Output: [0.9779962327750996, -0.15905292559011666, 0.6613889569282136, 0.14994720324439453]\n",
      "Layer: Layer 2, Input: [0.9779962327750996, -0.15905292559011666, 0.6613889569282136, 0.14994720324439453], Output: [1.120924797499125]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8518749146326419, -0.008475991099720344, -0.9830888546930784, -0.9753658133110078]\n",
      "Layer: Layer 1, Input: [-0.8518749146326419, -0.008475991099720344, -0.9830888546930784, -0.9753658133110078], Output: [-0.2323355631982023, 0.7006709046325662, -0.5807729099461197, 0.43799001338763877]\n",
      "Layer: Layer 2, Input: [-0.2323355631982023, 0.7006709046325662, -0.5807729099461197, 0.43799001338763877], Output: [-0.9906939271860726]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.012752309591162471, -0.8946855642101993, 0.3639303129217855, -0.009187844973568676]\n",
      "Layer: Layer 1, Input: [-0.012752309591162471, -0.8946855642101993, 0.3639303129217855, -0.009187844973568676], Output: [-0.636591509757335, 0.5800970454736045, -0.5987157155454029, -0.1585525268779564]\n",
      "Layer: Layer 2, Input: [-0.636591509757335, 0.5800970454736045, -0.5987157155454029, -0.1585525268779564], Output: [-0.9909845806819428]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7125838896873475, 0.8152032947735999, -0.816833750497998, -0.9761510103477886]\n",
      "Layer: Layer 1, Input: [0.7125838896873475, 0.8152032947735999, -0.816833750497998, -0.9761510103477886], Output: [0.9478777392884374, 0.005883060171286595, 0.535348767955536, 0.22102096656262804]\n",
      "Layer: Layer 2, Input: [0.9478777392884374, 0.005883060171286595, 0.535348767955536, 0.22102096656262804], Output: [0.876718137266121]\n",
      "Epoch 85/100, Loss: 0.0074972762765094705, Accuracy: 0.7374718476350115\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9927581163542739, 0.9846371193161052, -0.8615168917543876, -0.999047426307269]\n",
      "Layer: Layer 1, Input: [0.9927581163542739, 0.9846371193161052, -0.8615168917543876, -0.999047426307269], Output: [0.9780026671190059, -0.15820820480033806, 0.6618953524625066, 0.15038148220310377]\n",
      "Layer: Layer 2, Input: [0.9780026671190059, -0.15820820480033806, 0.6618953524625066, 0.15038148220310377], Output: [1.1202246092710912]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8516067949425717, -0.008866167412317867, -0.9830817531976729, -0.9753688179735727]\n",
      "Layer: Layer 1, Input: [-0.8516067949425717, -0.008866167412317867, -0.9830817531976729, -0.9753688179735727], Output: [-0.2325406067879554, 0.700628042161021, -0.5806545308632717, 0.4376408164525197]\n",
      "Layer: Layer 2, Input: [-0.2325406067879554, 0.700628042161021, -0.5806545308632717, 0.4376408164525197], Output: [-0.9907906793365413]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.012267499418496211, -0.8945829804359494, 0.3640830188931873, -0.009399441123298352]\n",
      "Layer: Layer 1, Input: [-0.012267499418496211, -0.8945829804359494, 0.3640830188931873, -0.009399441123298352], Output: [-0.6364962885365036, 0.5800297788123644, -0.5984914594583521, -0.15858558901287498]\n",
      "Layer: Layer 2, Input: [-0.6364962885365036, 0.5800297788123644, -0.5984914594583521, -0.15858558901287498], Output: [-0.991091630838987]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7137992008134685, 0.8160142441568164, -0.816739169263458, -0.9761454327226274]\n",
      "Layer: Layer 1, Input: [0.7137992008134685, 0.8160142441568164, -0.816739169263458, -0.9761454327226274], Output: [0.9480621379178158, 0.005845769851533185, 0.5365776976978514, 0.2211702806581439]\n",
      "Layer: Layer 2, Input: [0.9480621379178158, 0.005845769851533185, 0.5365776976978514, 0.2211702806581439], Output: [0.8774010377503225]\n",
      "Epoch 86/100, Loss: 0.007412158211818925, Accuracy: 0.7390587386547596\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9928168155464536, 0.9847629707533866, -0.8613782910374357, -0.9990472771887431]\n",
      "Layer: Layer 1, Input: [0.9928168155464536, 0.9847629707533866, -0.8613782910374357, -0.9990472771887431], Output: [0.9780089547996348, -0.1573719598857726, 0.6623972390481598, 0.15081064732892177]\n",
      "Layer: Layer 2, Input: [0.9780089547996348, -0.1573719598857726, 0.6623972390481598, 0.15081064732892177], Output: [1.1195353078182533]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8513412924645014, -0.009252562746914774, -0.9830747157076967, -0.9753717298791658]\n",
      "Layer: Layer 1, Input: [-0.8513412924645014, -0.009252562746914774, -0.9830747157076967, -0.9753717298791658], Output: [-0.23274366689794318, 0.7005853200989501, -0.5805373342341286, 0.43729464375998]\n",
      "Layer: Layer 2, Input: [-0.23274366689794318, 0.7005853200989501, -0.5805373342341286, 0.43729464375998], Output: [-0.9908855338851627]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.011787309172003024, -0.8944812581314651, 0.3642345294198062, -0.009607764887193062]\n",
      "Layer: Layer 1, Input: [-0.011787309172003024, -0.8944812581314651, 0.3642345294198062, -0.009607764887193062], Output: [-0.6364015008292793, 0.5799624743460883, -0.5982694153513354, -0.15861856346002376]\n",
      "Layer: Layer 2, Input: [-0.6364015008292793, 0.5799624743460883, -0.5982694153513354, -0.15861856346002376], Output: [-0.9911964723452432]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7149972652227141, 0.8168138060736317, -0.8166452795911698, -0.9761398329880084]\n",
      "Layer: Layer 1, Input: [0.7149972652227141, 0.8168138060736317, -0.8166452795911698, -0.9761398329880084], Output: [0.9482433180005965, 0.005812536003101876, 0.5377910193711254, 0.22131864314839267]\n",
      "Layer: Layer 2, Input: [0.9482433180005965, 0.005812536003101876, 0.5377910193711254, 0.22131864314839267], Output: [0.8780739257423554]\n",
      "Epoch 87/100, Loss: 0.007328808247702952, Accuracy: 0.740620624154508\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9928744326621215, 0.9848865710917062, -0.8612405069412464, -0.9990471237294872]\n",
      "Layer: Layer 1, Input: [0.9928744326621215, 0.9848865710917062, -0.8612405069412464, -0.9990471237294872], Output: [0.9780150999158242, -0.15654401747115365, 0.6628946908763363, 0.15123481352413362]\n",
      "Layer: Layer 2, Input: [0.9780150999158242, -0.15654401747115365, 0.6628946908763363, 0.15123481352413362], Output: [1.1188566222354441]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8510783594545565, -0.00963525605564856, -0.9830677410563193, -0.9753745512589366]\n",
      "Layer: Layer 1, Input: [-0.8510783594545565, -0.00963525605564856, -0.9830677410563193, -0.9753745512589366], Output: [-0.2329447858845264, 0.7005427447821017, -0.5804213060834946, 0.43695143898076877]\n",
      "Layer: Layer 2, Input: [-0.2329447858845264, 0.7005427447821017, -0.5804213060834946, 0.43695143898076877], Output: [-0.9909785493028741]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.011311655519752108, -0.894380383339921, 0.3643848676072072, -0.00981288845175704]\n",
      "Layer: Layer 1, Input: [-0.011311655519752108, -0.894380383339921, 0.3643848676072072, -0.00981288845175704], Output: [-0.6363071464200815, 0.5798951393124312, -0.5980495395771551, -0.1586514468195784]\n",
      "Layer: Layer 2, Input: [-0.6363071464200815, 0.5798951393124312, -0.5980495395771551, -0.1586514468195784], Output: [-0.991299156710146]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7161784818893249, 0.8176022410528025, -0.8165520695474842, -0.9761342119758202]\n",
      "Layer: Layer 1, Input: [0.7161784818893249, 0.8176022410528025, -0.8165520695474842, -0.9761342119758202], Output: [0.9484213670775126, 0.005783239152028461, 0.5389890724930662, 0.2214660639038952]\n",
      "Layer: Layer 2, Input: [0.9484213670775126, 0.005783239152028461, 0.5389890724930662, 0.2214660639038952], Output: [0.8787370369460736]\n",
      "Epoch 88/100, Loss: 0.007247173526118063, Accuracy: 0.7421581207236496\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9929309977677971, 0.9850079807718981, -0.8611035255194155, -0.9990469660465431]\n",
      "Layer: Layer 1, Input: [0.9929309977677971, 0.9850079807718981, -0.8611035255194155, -0.9990469660465431], Output: [0.9780211064173976, -0.1557242092755897, 0.663387780484466, 0.15165409209367836]\n",
      "Layer: Layer 2, Input: [0.9780211064173976, -0.1557242092755897, 0.663387780484466, 0.15165409209367836], Output: [1.1181882906903091]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.850817949480524, -0.010014322802980901, -0.9830608281053257, -0.9753772842849574]\n",
      "Layer: Layer 1, Input: [-0.850817949480524, -0.010014322802980901, -0.9830608281053257, -0.9753772842849574], Output: [-0.23314400401655277, 0.700500321837372, -0.5803064318239649, 0.4366111480714422]\n",
      "Layer: Layer 2, Input: [-0.23314400401655277, 0.700500321837372, -0.5803064318239649, 0.4366111480714422], Output: [-0.9910697812972153]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.01084045791094784, -0.894280342422204, 0.3645340559971943, -0.01001488224099141]\n",
      "Layer: Layer 1, Input: [-0.01084045791094784, -0.894280342422204, 0.3645340559971943, -0.01001488224099141], Output: [-0.6362132255342738, 0.5798277811788279, -0.5978317898053611, -0.15868423519871586]\n",
      "Layer: Layer 2, Input: [-0.6362132255342738, 0.5798277811788279, -0.5978317898053611, -0.15868423519871586], Output: [-0.9913997352103152]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7173432370093044, 0.8183798015189725, -0.8164595274779559, -0.9761285704969856]\n",
      "Layer: Layer 1, Input: [0.7173432370093044, 0.8183798015189725, -0.8164595274779559, -0.9761285704969856], Output: [0.9485963694979093, 0.005757764098981977, 0.5401721863795222, 0.22161255288866824]\n",
      "Layer: Layer 2, Input: [0.9485963694979093, 0.005757764098981977, 0.5401721863795222, 0.22161255288866824], Output: [0.8793905994111979]\n",
      "Epoch 89/100, Loss: 0.00716720323180485, Accuracy: 0.7436718252284193\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9929865398168717, 0.9851272580986468, -0.8609673331392302, -0.9990468042539343]\n",
      "Layer: Layer 1, Input: [0.9929865398168717, 0.9851272580986468, -0.8609673331392302, -0.9990468042539343], Output: [0.9780269781116302, -0.1549123719254229, 0.6638765787976706, 0.15206859088533015]\n",
      "Layer: Layer 2, Input: [0.9780269781116302, -0.1549123719254229, 0.6638765787976706, 0.15206859088533015], Output: [1.1175300600497164]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8505600173703904, -0.010389835239383248, -0.9830539757444066, -0.9753799310710211]\n",
      "Layer: Layer 1, Input: [-0.8505600173703904, -0.010389835239383248, -0.9830539757444066, -0.9753799310710211], Output: [-0.2333413596568261, 0.7004580562528384, -0.5801926963801195, 0.43627371909839824]\n",
      "Layer: Layer 2, Input: [-0.2333413596568261, 0.7004580562528384, -0.5801926963801195, 0.43627371909839824], Output: [-0.9911592830022347]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.010373638399131854, -0.8941811220485217, 0.364682116576367, -0.010213814927825979]\n",
      "Layer: Layer 1, Input: [-0.010373638399131854, -0.8941811220485217, 0.364682116576367, -0.010213814927825979], Output: [-0.6361197387457819, 0.5797604075629021, -0.5976161249652111, -0.15871692432047738]\n",
      "Layer: Layer 2, Input: [-0.6361197387457819, 0.5797604075629021, -0.5976161249652111, -0.15871692432047738], Output: [-0.9914982587216454]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7184919045305361, 0.8191467321046736, -0.8163676420005921, -0.9761229093411776]\n",
      "Layer: Layer 1, Input: [0.7184919045305361, 0.8191467321046736, -0.8163676420005921, -0.9761229093411776], Output: [0.9487684065647116, 0.005735999727172794, 0.5413406805289876, 0.22175812012778157]\n",
      "Layer: Layer 2, Input: [0.9487684065647116, 0.005735999727172794, 0.5413406805289876, 0.22175812012778157], Output: [0.8800348338583045]\n",
      "Epoch 90/100, Loss: 0.007088848496123303, Accuracy: 0.7451623155324681\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9930410867015889, 0.9852444593331788, -0.8608319164755707, -0.9990466384626754]\n",
      "Layer: Layer 1, Input: [0.9930410867015889, 0.9852444593331788, -0.8608319164755707, -0.9990466384626754], Output: [0.9780327186694013, -0.15410834677488147, 0.664361155169404, 0.15247841442360077]\n",
      "Layer: Layer 2, Input: [0.9780327186694013, -0.15410834677488147, 0.664361155169404, 0.15247841442360077], Output: [1.1168816855238803]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8503045191637282, -0.0107618626477002, -0.9830471828904509, -0.9753824936735658]\n",
      "Layer: Layer 1, Input: [-0.8503045191637282, -0.0107618626477002, -0.9830471828904509, -0.9753824936735658], Output: [-0.23353688942451994, 0.7004159524405553, -0.5800800842971254, 0.43593910207953857]\n",
      "Layer: Layer 2, Input: [-0.23353688942451994, 0.7004159524405553, -0.5800800842971254, 0.43593910207953857], Output: [-0.991247105151675]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.009911121481730368, -0.8940827091901917, 0.3648290707856135, -0.01040975345101393]\n",
      "Layer: Layer 1, Input: [-0.009911121481730368, -0.8940827091901917, 0.3648290707856135, -0.01040975345101393], Output: [-0.6360266868973387, 0.5796930261643228, -0.5974025051920324, -0.1587495096177612]\n",
      "Layer: Layer 2, Input: [-0.6360266868973387, 0.5796930261643228, -0.5974025051920324, -0.1587495096177612], Output: [-0.9915947775778954]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7196248466551748, 0.819903269948402, -0.8162764019991231, -0.9761172292766724]\n",
      "Layer: Layer 1, Input: [0.7196248466551748, 0.819903269948402, -0.8162764019991231, -0.9761172292766724], Output: [0.9489375566715137, 0.005717838821107585, 0.5424948649899785, 0.22190277567914826]\n",
      "Layer: Layer 2, Input: [0.9489375566715137, 0.005717838821107585, 0.5424948649899785, 0.22190277567914826], Output: [0.8806699539860193]\n",
      "Epoch 91/100, Loss: 0.0070120623061982225, Accuracy: 0.7466301511917094\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9930946653020416, 0.9853596387812292, -0.8606972625046255, -0.9990464687807921]\n",
      "Layer: Layer 1, Input: [0.9930946653020416, 0.9853596387812292, -0.8606972625046255, -0.9990464687807921], Output: [0.9780383316310447, -0.15331197973419694, 0.6648415774212785, 0.15288366403766254]\n",
      "Layer: Layer 2, Input: [0.9780383316310447, -0.15331197973419694, 0.6648415774212785, 0.15288366403766254], Output: [1.1162429303272856]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8500514120657213, -0.011130471565123659, -0.9830404484868398, -0.9753849740927032]\n",
      "Layer: Layer 1, Input: [-0.8500514120657213, -0.011130471565123659, -0.9830404484868398, -0.9753849740927032], Output: [-0.23373062834063205, 0.7003740142928859, -0.5799685798355395, 0.4356072488416648]\n",
      "Layer: Layer 2, Input: [-0.23373062834063205, 0.7003740142928859, -0.5799685798355395, 0.4356072488416648], Output: [-0.9913332962371163]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.00945283395422671, -0.8939850911116113, 0.36497493953035653, -0.010602763036594338]\n",
      "Layer: Layer 1, Input: [-0.00945283395422671, -0.8939850911116113, 0.36497493953035653, -0.010602763036594338], Output: [-0.6359340710318319, 0.5796256447067061, -0.5971908917767228, -0.15878198631423415]\n",
      "Layer: Layer 2, Input: [-0.6359340710318319, 0.5796256447067061, -0.5971908917767228, -0.15878198631423415], Output: [-0.9916893414524938]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7207424143161105, 0.8206496449794459, -0.8161857966163292, -0.9761115310503212]\n",
      "Layer: Layer 1, Input: [0.7207424143161105, 0.8206496449794459, -0.8161857966163292, -0.9761115310503212], Output: [0.9491038954322917, 0.0057031778954170845, 0.5436350407121409, 0.2220465296090353]\n",
      "Layer: Layer 2, Input: [0.9491038954322917, 0.0057031778954170845, 0.5436350407121409, 0.2220465296090353], Output: [0.8812961667616686]\n",
      "Epoch 92/100, Loss: 0.00693679941903865, Accuracy: 0.748075874123993\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9931473015323928, 0.9854728488765572, -0.8605633584974687, -0.9990462953133494]\n",
      "Layer: Layer 1, Input: [0.9931473015323928, 0.9854728488765572, -0.8605633584974687, -0.9990462953133494], Output: [0.9780438204119167, -0.15252312110488617, 0.6653179118820602, 0.1532844379835765]\n",
      "Layer: Layer 2, Input: [0.9780438204119167, -0.15252312110488617, 0.6653179118820602, 0.1532844379835765], Output: [1.115613565355577]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8498006544036409, -0.011495725983416423, -0.9830337715027504, -0.97538737427333]\n",
      "Layer: Layer 1, Input: [-0.8498006544036409, -0.011495725983416423, -0.9830337715027504, -0.97538737427333], Output: [-0.23392260995835884, 0.7003322452330651, -0.5798581670539268, 0.4352781128918989]\n",
      "Layer: Layer 2, Input: [-0.23392260995835884, 0.7003322452330651, -0.5798581670539268, 0.4352781128918989], Output: [-0.9914179026525951]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.008998704777428883, -0.8938882553624177, 0.36511974319139373, -0.01079290722314618]\n",
      "Layer: Layer 1, Input: [-0.008998704777428883, -0.8938882553624177, 0.36511974319139373, -0.01079290722314618], Output: [-0.6358418923334137, 0.5795582708883245, -0.5969812471181604, -0.1588143494937565]\n",
      "Layer: Layer 2, Input: [-0.6358418923334137, 0.5795582708883245, -0.5969812471181604, -0.1588143494937565], Output: [-0.9917819992606622]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7218449476291648, 0.821386080190112, -0.8160958152474318, -0.9761058153876204]\n",
      "Layer: Layer 1, Input: [0.7218449476291648, 0.821386080190112, -0.8160958152474318, -0.9761058153876204], Output: [0.9492674958041998, 0.005691917033066597, 0.544761499881916, 0.22218939197085424]\n",
      "Layer: Layer 2, Input: [0.9492674958041998, 0.005691917033066597, 0.544761499881916, 0.22218939197085424], Output: [0.8819136726965222]\n",
      "Epoch 93/100, Loss: 0.006863016280321111, Accuracy: 0.7495000092542026\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9931990203845077, 0.9855841402602655, -0.8604301920135466, -0.9990461181624928]\n",
      "Layer: Layer 1, Input: [0.9931990203845077, 0.9855841402602655, -0.8604301920135466, -0.9990461181624928], Output: [0.9780491883076936, -0.15174162542188027, 0.6657902234258176, 0.15368083156109974]\n",
      "Layer: Layer 2, Input: [0.9780491883076936, -0.15174162542188027, 0.6657902234258176, 0.15368083156109974], Output: [1.114993368877588]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8495522055855917, -0.011857687529708508, -0.9830271509324642, -0.9753896961063022]\n",
      "Layer: Layer 1, Input: [-0.8495522055855917, -0.011857687529708508, -0.9830271509324642, -0.9753896961063022], Output: [-0.23411286648004423, 0.7002906482606065, -0.5797488298807011, 0.43495164930162716]\n",
      "Layer: Layer 2, Input: [-0.23411286648004423, 0.7002906482606065, -0.5797488298807011, 0.43495164930162716], Output: [-0.9915009688270356]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.008548664956469294, -0.8937921897698385, 0.36526350163619387, -0.010980247890152927]\n",
      "Layer: Layer 1, Input: [-0.008548664956469294, -0.8937921897698385, 0.36526350163619387, -0.010980247890152927], Output: [-0.6357501520771791, 0.5794909123405335, -0.5967735346783076, -0.15884659415971703]\n",
      "Layer: Layer 2, Input: [-0.6357501520771791, 0.5794909123405335, -0.5967735346783076, -0.15884659415971703], Output: [-0.9918727990792816]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7229327763225448, 0.8221127918959645, -0.8160064475335753, -0.9761000829928659]\n",
      "Layer: Layer 1, Input: [0.7229327763225448, 0.8221127918959645, -0.8160064475335753, -0.9761000829928659], Output: [0.9494284282038834, 0.0056839597322985375, 0.5458745262435326, 0.22233137278683798]\n",
      "Layer: Layer 2, Input: [0.9494284282038834, 0.0056839597322985375, 0.5458745262435326, 0.22233137278683798], Output: [0.882522666106683]\n",
      "Epoch 94/100, Loss: 0.006790670947545914, Accuracy: 0.7509030651354123\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9932498459691753, 0.9856935618561681, -0.8602977508941129, -0.9990459374274907]\n",
      "Layer: Layer 1, Input: [0.9932498459691753, 0.9856935618561681, -0.8602977508941129, -0.9990459374274907], Output: [0.9780544384994151, -0.15096735130221436, 0.6662585755092065, 0.15407293722532495]\n",
      "Layer: Layer 2, Input: [0.9780544384994151, -0.15096735130221436, 0.6662585755092065, 0.15407293722532495], Output: [1.1143821262417362]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8493060260613743, -0.012216415629931754, -0.983020585794688, -0.9753919414296637]\n",
      "Layer: Layer 1, Input: [-0.8493060260613743, -0.012216415629931754, -0.983020585794688, -0.9753919414296637], Output: [-0.2343014288621691, 0.7002492259921019, -0.5796405521764426, 0.4346278146016284]\n",
      "Layer: Layer 2, Input: [-0.2343014288621691, 0.7002492259921019, -0.5796405521764426, 0.4346278146016284], Output: [-0.9915825373456841]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.008102647430318265, -0.8936968824312366, 0.36540623423053276, -0.011164845288886017]\n",
      "Layer: Layer 1, Input: [-0.008102647430318265, -0.8936968824312366, 0.36540623423053276, -0.011164845288886017], Output: [-0.6356588515863609, 0.5794235765929439, -0.5965677189398108, -0.1588787152855251]\n",
      "Layer: Layer 2, Input: [-0.6356588515863609, 0.5794235765929439, -0.5965677189398108, -0.1588787152855251], Output: [-0.991961788082236]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7240062201449708, 0.8228299899846591, -0.815917683355402, -0.976094334549381]\n",
      "Layer: Layer 1, Input: [0.7240062201449708, 0.8228299899846591, -0.815917683355402, -0.976094334549381], Output: [0.9495867606177052, 0.005679212761737267, 0.5469743954060562, 0.2224724820322612]\n",
      "Layer: Layer 2, Input: [0.9495867606177052, 0.005679212761737267, 0.5469743954060562, 0.2224724820322612], Output: [0.8831233353605534]\n",
      "Epoch 95/100, Loss: 0.006719723017298453, Accuracy: 0.7522855345467374\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9932998015550779, 0.9858011609424252, -0.8601660232556436, -0.9990457532047871]\n",
      "Layer: Layer 1, Input: [0.9932998015550779, 0.9858011609424252, -0.8601660232556436, -0.9990457532047871], Output: [0.9780595740582848, -0.15020016129998867, 0.6667230302078914, 0.15446084469340754]\n",
      "Layer: Layer 2, Input: [0.9780595740582848, -0.15020016129998867, 0.6667230302078914, 0.15446084469340754], Output: [1.1137796295960485]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8490620772853148, -0.012571967656745021, -0.9830140751318848, -0.9753941120299068]\n",
      "Layer: Layer 1, Input: [-0.8490620772853148, -0.012571967656745021, -0.9830140751318848, -0.9753941120299068], Output: [-0.2344883269096939, 0.7002079806979016, -0.5795333177878118, 0.43430656668718914]\n",
      "Layer: Layer 2, Input: [-0.2344883269096939, 0.7002079806979016, -0.5795333177878118, 0.43430656668718914], Output: [-0.9916626490616254]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.007660586970729613, -0.8936023217068454, 0.3655479598503615, -0.011346758075290977]\n",
      "Layer: Layer 1, Input: [-0.007660586970729613, -0.8936023217068454, 0.3655479598503615, -0.011346758075290977], Output: [-0.635567992196105, 0.5793562710444885, -0.5963637653659177, -0.15891070785735367]\n",
      "Layer: Layer 2, Input: [-0.635567992196105, 0.5793562710444885, -0.5963637653659177, -0.15891070785735367], Output: [-0.9920490124892236]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.725065589253781, 0.8235378781539274, -0.815829512826741, -0.9760885707198002]\n",
      "Layer: Layer 1, Input: [0.725065589253781, 0.8235378781539274, -0.815829512826741, -0.9760885707198002], Output: [0.9497425587062572, 0.0056775860230999006, 0.548061375137189, 0.22261272962189727]\n",
      "Layer: Layer 2, Input: [0.9497425587062572, 0.0056775860230999006, 0.548061375137189, 0.22261272962189727], Output: [0.883715863113778]\n",
      "Epoch 96/100, Loss: 0.006650133556363434, Accuracy: 0.7536478950685785\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.993348909605657, 0.9859069832196629, -0.8600349974832607, -0.9990455655880551]\n",
      "Layer: Layer 1, Input: [0.993348909605657, 0.9859069832196629, -0.8600349974832607, -0.9990455655880551], Output: [0.9780645979502429, -0.14943992176732246, 0.6671836482520966, 0.1548446410466118]\n",
      "Layer: Layer 2, Input: [0.9780645979502429, -0.14943992176732246, 0.6671836482520966, 0.1548446410466118], Output: [1.113185677621118]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8488203216809286, -0.012924399063578788, -0.983007618009618, -0.9753962096432622]\n",
      "Layer: Layer 1, Input: [-0.8488203216809286, -0.012924399063578788, -0.983007618009618, -0.9753962096432622], Output: [-0.2346735893609062, 0.7001669143351084, -0.579427110594037, 0.43398786473215295]\n",
      "Layer: Layer 2, Input: [-0.2346735893609062, 0.7001669143351084, -0.579427110594037, 0.43398786473215295], Output: [-0.9917413431983219]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.007222420089653571, -0.8935084962126997, 0.365688696893824, -0.011526043344430198]\n",
      "Layer: Layer 1, Input: [-0.007222420089653571, -0.8935084962126997, 0.365688696893824, -0.011526043344430198], Output: [-0.6354775752230103, 0.5792890029396306, -0.5961616403625526, -0.15894256691010147]\n",
      "Layer: Layer 2, Input: [-0.6354775752230103, 0.5792890029396306, -0.5961616403625526, -0.15894256691010147], Output: [-0.9921345175262745]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7261111845842245, 0.8242366541392336, -0.8157419262884109, -0.9760827921464038]\n",
      "Layer: Layer 1, Input: [0.7261111845842245, 0.8242366541392336, -0.8157419262884109, -0.9760827921464038], Output: [0.9498958859035026, 0.005678992421038572, 0.5491357256444637, 0.2227521253984428]\n",
      "Layer: Layer 2, Input: [0.9498958859035026, 0.005678992421038572, 0.5491357256444637, 0.2227521253984428], Output: [0.8843004265324347]\n",
      "Epoch 97/100, Loss: 0.006581865036460145, Accuracy: 0.754990609635913\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9933971918140128, 0.986011072875769, -0.8599046622241905, -0.9990453746682573]\n",
      "Layer: Layer 1, Input: [0.9933971918140128, 0.986011072875769, -0.8599046622241905, -0.9990453746682573], Output: [0.9780695130403205, -0.14868650272103953, 0.6676404890612869, 0.15522441082790137]\n",
      "Layer: Layer 2, Input: [0.9780695130403205, -0.14868650272103953, 0.6676404890612869, 0.15522441082790137], Output: [1.1126000752753267]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8485807226072974, -0.0132737635062618, -0.9830012135159072, -0.9753982359570019]\n",
      "Layer: Layer 1, Input: [-0.8485807226072974, -0.0132737635062618, -0.9830012135159072, -0.9753982359570019], Output: [-0.23485724396381014, 0.7001260285772731, -0.5793219145468533, 0.4336716691109543]\n",
      "Layer: Layer 2, Input: [-0.23485724396381014, 0.7001260285772731, -0.5793219145468533, 0.4336716691109543], Output: [-0.9918186574440393]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.0067880849542494405, -0.8934153948137563, 0.36582846329334623, -0.01170275666609623]\n",
      "Layer: Layer 1, Input: [-0.0067880849542494405, -0.8934153948137563, 0.36582846329334623, -0.01170275666609623], Output: [-0.6353876019396987, 0.5792217793490467, -0.5959613112423896, -0.15897428755743429]\n",
      "Layer: Layer 2, Input: [-0.6353876019396987, 0.5792217793490467, -0.5959613112423896, -0.15897428755743429], Output: [-0.992218347396403]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7271432982010649, 0.8249265099316072, -0.8156549143021525, -0.9760769994514922]\n",
      "Layer: Layer 1, Input: [0.7271432982010649, 0.8249265099316072, -0.8156549143021525, -0.9760769994514922], Output: [0.95004680351087, 0.005683347739645087, 0.5501976998444558, 0.22289067912267363]\n",
      "Layer: Layer 2, Input: [0.95004680351087, 0.005683347739645087, 0.5501976998444558, 0.22289067912267363], Output: [0.8848771975052359]\n",
      "Epoch 98/100, Loss: 0.006514881272379687, Accuracy: 0.7563141270703515\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9934446691359619, 0.9861134726475538, -0.8597750063812737, -0.9990451805337057]\n",
      "Layer: Layer 1, Input: [0.9934446691359619, 0.9861134726475538, -0.8597750063812737, -0.9990451805337057], Output: [0.978074322096788, -0.14793977771482889, 0.6680936107779817, 0.15560023613529]\n",
      "Layer: Layer 2, Input: [0.978074322096788, -0.14793977771482889, 0.6680936107779817, 0.15560023613529], Output: [1.1120226335517098]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.848343244327045, -0.013620112953528895, -0.9829948607606005, -0.9754001926107508]\n",
      "Layer: Layer 1, Input: [-0.848343244327045, -0.013620112953528895, -0.9829948607606005, -0.9754001926107508], Output: [-0.23503931754496427, 0.7000853248411386, -0.5792177137046687, 0.43335794132779804]\n",
      "Layer: Layer 2, Input: [-0.23503931754496427, 0.7000853248411386, -0.5792177137046687, 0.43335794132779804], Output: [-0.9918946280389168]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.0063575213087381025, -0.8933230066172041, 0.3659672765277318, -0.011876952121259464]\n",
      "Layer: Layer 1, Input: [-0.0063575213087381025, -0.8933230066172041, 0.3659672765277318, -0.011876952121259464], Output: [-0.635298073553775, 0.5791546071542, -0.5957627461907974, -0.15900586501665478]\n",
      "Layer: Layer 2, Input: [-0.635298073553775, 0.5791546071542, -0.5957627461907974, -0.15900586501665478], Output: [-0.9923005452590264]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.7281622136335297, 0.8256076319861201, -0.8155684676446873, -0.9760711932377925]\n",
      "Layer: Layer 1, Input: [0.7281622136335297, 0.8256076319861201, -0.8155684676446873, -0.9760711932377925], Output: [0.9501953707865983, 0.0056905705252092, 0.551247543620592, 0.22302840046512346]\n",
      "Layer: Layer 2, Input: [0.9501953707865983, 0.0056905705252092, 0.551247543620592, 0.22302840046512346], Output: [0.8854463428454031]\n",
      "Epoch 99/100, Loss: 0.00644914736332235, Accuracy: 0.7576188825916366\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9934913618213722, 0.9862142238794479, -0.8596460191065499, -0.9990449832701264]\n",
      "Layer: Layer 1, Input: [0.9934913618213722, 0.9862142238794479, -0.8596460191065499, -0.9990449832701264], Output: [0.9780790277951089, -0.14719962371663456, 0.6685430703007087, 0.15597219671115287]\n",
      "Layer: Layer 2, Input: [0.9780790277951089, -0.14719962371663456, 0.6685430703007087, 0.15597219671115287], Output: [1.1114531692458625]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.8481078519758116, -0.013963497787568857, -0.982988558874759, -0.975402081197798]\n",
      "Layer: Layer 1, Input: [-0.8481078519758116, -0.013963497787568857, -0.982988558874759, -0.975402081197798], Output: [-0.235219836071595, 0.7000448043107376, -0.5791144922616387, 0.4330466439522377]\n",
      "Layer: Layer 2, Input: [-0.235219836071595, 0.7000448043107376, -0.5791144922616387, 0.4330466439522377], Output: [-0.9919692898553708]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.0059306704024004765, -0.8932313209659627, 0.36610515363421225, -0.012048682339063338]\n",
      "Layer: Layer 1, Input: [-0.0059306704024004765, -0.8932313209659627, 0.36610515363421225, -0.012048682339063338], Output: [-0.6352089911906139, 0.5790874930352845, -0.5955659142335215, -0.1590372946290746]\n",
      "Layer: Layer 2, Input: [-0.6352089911906139, 0.5790874930352845, -0.5955659142335215, -0.1590372946290746], Output: [-0.9923811532169381]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.729168206194579, 0.8262802014214614, -0.8154825773019139, -0.9760653740888899]\n",
      "Layer: Layer 1, Input: [0.729168206194579, 0.8262802014214614, -0.8154825773019139, -0.9760653740888899], Output: [0.9503416450306112, 0.0057005819748342556, 0.5522854960701068, 0.2231652989990968]\n",
      "Layer: Layer 2, Input: [0.9503416450306112, 0.0057005819748342556, 0.5522854960701068, 0.2231652989990968], Output: [0.8860080244828509]\n",
      "Epoch 100/100, Loss: 0.006384629637245003, Accuracy: 0.7589052983092973\n"
     ]
    }
   ],
   "source": [
    "# Run our model training for multiple epochs\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Reset model parameters\n",
    "for param in mlp.parameters():\n",
    "    param.data = random.uniform(-1, 1)  # Random initialization of parameters\n",
    "    param.grad = 0.0\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "y_true = [Value(y_i) for y_i in y]  # Convert labels to Value objects\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_preds = [mlp(i)[0] for i in x]  # Forward pass through the neural network\n",
    "    loss = loss_fn_mse(y_preds, y_true)\n",
    "    losses.append(loss)\n",
    "    accuracy.append(1 - sum([abs(y_true - y_pred.data) for y_true, y_pred in zip(y, y_preds)]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.data}, Accuracy: {accuracy[-1]}\")\n",
    "        \n",
    "    mlp.zero_grad()  # Reset gradients of all parameters\n",
    "    loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "    visited = set()\n",
    "    loss.backward()\n",
    "    for param in mlp.parameters():\n",
    "        param.data = param.data - learning_rate * param.grad  # Update parameters using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "62fd9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds after training: [1.1114531692458625, -0.9919692898553708, -0.9923811532169381, 0.8860080244828509]\n",
      "y_true after training: [1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_preds after training: {[item.data for item in y_preds]}\")\n",
    "print(f\"y_true after training: {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "08b99310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(range(epochs), [item.data for item in losses])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2e370b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy over epochs\n",
    "plt.plot(range(epochs), accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "912faec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.0080,  0.6310,  0.2013, -1.9987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0080,  0.6310,  0.2013, -1.9987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7649,  0.5588,  0.1986, -0.9639], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.7649,  0.5588,  0.1986, -0.9639], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3581, -1.2205, -0.5212,  0.9182], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3581, -1.2205, -0.5212,  0.9182], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8759, -0.8398, -0.4786,  0.7250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8759, -0.8398, -0.4786,  0.7250], grad_fn=<TanhBackward0>),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.8141,  0.5476, -1.5705, -0.6861], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.8141,  0.5476, -1.5705, -0.6861], grad_fn=<ViewBackward0>),), Output: tensor([-0.9482,  0.4987, -0.9171, -0.5955], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9482,  0.4987, -0.9171, -0.5955], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2511, -0.7744,  0.2241, -1.0185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2511, -0.7744,  0.2241, -1.0185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8486, -0.6495,  0.2204, -0.7693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8486, -0.6495,  0.2204, -0.7693], grad_fn=<TanhBackward0>),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7748, -0.7850, -0.5231, -1.7591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7748, -0.7850, -0.5231, -1.7591], grad_fn=<ViewBackward0>),), Output: tensor([-0.6497, -0.6556, -0.4801, -0.9424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6497, -0.6556, -0.4801, -0.9424], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4910, -0.9057,  1.1436, -0.4672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4910, -0.9057,  1.1436, -0.4672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9035, -0.7191,  0.8156, -0.4360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9035, -0.7191,  0.8156, -0.4360], grad_fn=<TanhBackward0>),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3531,  0.4963, -2.6552, -3.9193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3531,  0.4963, -2.6552, -3.9193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9821,  0.4592, -0.9902, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9821,  0.4592, -0.9902, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5757, -1.1224,  0.0079, -1.0246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5757, -1.1224,  0.0079, -1.0246], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9179, -0.8084,  0.0079, -0.7717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9179, -0.8084,  0.0079, -0.7717], grad_fn=<TanhBackward0>),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1021,  0.7992, -0.0230, -2.0032], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1021,  0.7992, -0.0230, -2.0032], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8013,  0.6636, -0.0230, -0.9643], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8013,  0.6636, -0.0230, -0.9643], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1917, -1.1030, -0.8884,  0.7203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1917, -1.1030, -0.8884,  0.7203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8311, -0.8016, -0.7106,  0.6171], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8311, -0.8016, -0.7106,  0.6171], grad_fn=<TanhBackward0>),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7888,  0.6298, -1.6242, -0.6931], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7888,  0.6298, -1.6242, -0.6931], grad_fn=<ViewBackward0>),), Output: tensor([-0.9456,  0.5579, -0.9252, -0.5999], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9456,  0.5579, -0.9252, -0.5999], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2236, -0.8162,  0.0418, -1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2236, -0.8162,  0.0418, -1.0341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8407, -0.6730,  0.0418, -0.7755], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8407, -0.6730,  0.0418, -0.7755], grad_fn=<TanhBackward0>),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7485, -0.7334, -0.5837, -1.7624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7485, -0.7334, -0.5837, -1.7624], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.6251, -0.5254, -0.9428], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.6251, -0.5254, -0.9428], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4321, -0.8981,  0.9794, -0.5130], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4321, -0.8981,  0.9794, -0.5130], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8921, -0.7154,  0.7528, -0.4723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8921, -0.7154,  0.7528, -0.4723], grad_fn=<TanhBackward0>),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3352,  0.4862, -2.7083, -3.9337], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3352,  0.4862, -2.7083, -3.9337], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814,  0.4512, -0.9912, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814,  0.4512, -0.9912, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5461, -1.1419, -0.0660, -1.0364], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5461, -1.1419, -0.0660, -1.0364], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9131, -0.8151, -0.0659, -0.7765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9131, -0.8151, -0.0659, -0.7765], grad_fn=<TanhBackward0>),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1407,  0.8638, -0.1561, -2.0103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1407,  0.8638, -0.1561, -2.0103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8147,  0.6982, -0.1548, -0.9647], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8147,  0.6982, -0.1548, -0.9647], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0857, -1.0351, -1.0761,  0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0857, -1.0351, -1.0761,  0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7953, -0.7760, -0.7918,  0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7953, -0.7760, -0.7918,  0.5320], grad_fn=<TanhBackward0>),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7759,  0.6673, -1.6569, -0.7048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7759,  0.6673, -1.6569, -0.7048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9442,  0.5832, -0.9298, -0.6074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9442,  0.5832, -0.9298, -0.6074], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2069, -0.8486, -0.0589, -1.0438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2069, -0.8486, -0.0589, -1.0438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358, -0.6903, -0.0588, -0.7794], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8358, -0.6903, -0.0588, -0.7794], grad_fn=<TanhBackward0>),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -0.7397, -0.6175, -1.7678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -0.7397, -0.6175, -1.7678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6280, -0.6289, -0.5494, -0.9434], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6280, -0.6289, -0.5494, -0.9434], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3961, -0.8933,  0.9110, -0.5400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3961, -0.8933,  0.9110, -0.5400], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8845, -0.7130,  0.7216, -0.4930], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8845, -0.7130,  0.7216, -0.4930], grad_fn=<TanhBackward0>),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279,  0.4142, -2.7411, -3.9491], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279,  0.4142, -2.7411, -3.9491], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.3921, -0.9917, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.3921, -0.9917, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5162, -1.1395, -0.0601, -1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5162, -1.1395, -0.0601, -1.0477], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9080, -0.8143, -0.0600, -0.7809], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9080, -0.8143, -0.0600, -0.7809], grad_fn=<TanhBackward0>),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1622,  0.8913, -0.2480, -2.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1622,  0.8913, -0.2480, -2.0177], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217,  0.7120, -0.2431, -0.9653], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8217,  0.7120, -0.2431, -0.9653], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0099, -0.9920, -1.1905,  0.5040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0099, -0.9920, -1.1905,  0.5040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7657, -0.7582, -0.8307,  0.4652], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7657, -0.7582, -0.8307,  0.4652], grad_fn=<TanhBackward0>),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7676,  0.6819, -1.6798, -0.7174], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7676,  0.6819, -1.6798, -0.7174], grad_fn=<ViewBackward0>),), Output: tensor([-0.9433,  0.5928, -0.9328, -0.6153], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9433,  0.5928, -0.9328, -0.6153], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1954, -0.8732, -0.1147, -1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1954, -0.8732, -0.1147, -1.0502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8323, -0.7030, -0.1142, -0.7819], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8323, -0.7030, -0.1142, -0.7819], grad_fn=<TanhBackward0>),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7341, -0.7761, -0.6384, -1.7735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7341, -0.7761, -0.6384, -1.7735], grad_fn=<ViewBackward0>),), Output: tensor([-0.6256, -0.6505, -0.5638, -0.9440], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6256, -0.6505, -0.5638, -0.9440], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3708, -0.8863,  0.8927, -0.5579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3708, -0.8863,  0.8927, -0.5579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8789, -0.7096,  0.7127, -0.5064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8789, -0.7096,  0.7127, -0.5064], grad_fn=<TanhBackward0>),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3259,  0.2992, -2.7629, -3.9641], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3259,  0.2992, -2.7629, -3.9641], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.2906, -0.9921, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.2906, -0.9921, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4848, -1.1186,  0.0036, -1.0591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4848, -1.1186,  0.0036, -1.0591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9024, -0.8071,  0.0036, -0.7853], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9024, -0.8071,  0.0036, -0.7853], grad_fn=<TanhBackward0>),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1761,  0.8992, -0.3173, -2.0250], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761,  0.8992, -0.3173, -2.0250], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262,  0.7159, -0.3070, -0.9658], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8262,  0.7159, -0.3070, -0.9658], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9513, -0.9619, -1.2662,  0.4373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9513, -0.9619, -1.2662,  0.4373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7404, -0.7451, -0.8528,  0.4114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7404, -0.7451, -0.8528,  0.4114], grad_fn=<TanhBackward0>),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7616,  0.6820, -1.6972, -0.7299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7616,  0.6820, -1.6972, -0.7299], grad_fn=<ViewBackward0>),), Output: tensor([-0.9427,  0.5928, -0.9351, -0.6230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9427,  0.5928, -0.9351, -0.6230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1864, -0.8918, -0.1448, -1.0549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1864, -0.8918, -0.1448, -1.0549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8295, -0.7123, -0.1438, -0.7837], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8295, -0.7123, -0.1438, -0.7837], grad_fn=<TanhBackward0>),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7332, -0.8333, -0.6523, -1.7790], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7332, -0.8333, -0.6523, -1.7790], grad_fn=<ViewBackward0>),), Output: tensor([-0.6250, -0.6822, -0.5732, -0.9446], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6250, -0.6822, -0.5732, -0.9446], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3513, -0.8767,  0.9032, -0.5706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3513, -0.8767,  0.9032, -0.5706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8744, -0.7048,  0.7179, -0.5158], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8744, -0.7048,  0.7179, -0.5158], grad_fn=<TanhBackward0>),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3264,  0.1554, -2.7784, -3.9786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3264,  0.1554, -2.7784, -3.9786], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.1542, -0.9923, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.1542, -0.9923, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4515, -1.0824,  0.1091, -1.0711], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4515, -1.0824,  0.1091, -1.0711], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8960, -0.7941,  0.1087, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8960, -0.7941,  0.1087, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1863,  0.8956, -0.3723, -2.0321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1863,  0.8956, -0.3723, -2.0321], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8294,  0.7141, -0.3560, -0.9662], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8294,  0.7141, -0.3560, -0.9662], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9035, -0.9396, -1.3204,  0.3847], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9035, -0.9396, -1.3204,  0.3847], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7180, -0.7350, -0.8669,  0.3668], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7180, -0.7350, -0.8669,  0.3668], grad_fn=<TanhBackward0>),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7568,  0.6731, -1.7113, -0.7420], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7568,  0.6731, -1.7113, -0.7420], grad_fn=<ViewBackward0>),), Output: tensor([-0.9421,  0.5870, -0.9368, -0.6304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9421,  0.5870, -0.9368, -0.6304], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1785, -0.9063, -0.1620, -1.0588], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1785, -0.9063, -0.1620, -1.0588], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8270, -0.7193, -0.1606, -0.7852], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8270, -0.7193, -0.1606, -0.7852], grad_fn=<TanhBackward0>),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7338, -0.9042, -0.6623, -1.7843], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7338, -0.9042, -0.6623, -1.7843], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.7183, -0.5799, -0.9452], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.7183, -0.5799, -0.9452], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3355, -0.8654,  0.9283, -0.5804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3355, -0.8654,  0.9283, -0.5804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8706, -0.6990,  0.7298, -0.5230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8706, -0.6990,  0.7298, -0.5230], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3276e+00,  2.5095e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3276e+00,  2.5095e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.0025, -0.9925, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.0025, -0.9925, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4186, -1.0379,  0.2323, -1.0828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4186, -1.0379,  0.2323, -1.0828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8893, -0.7771,  0.2282, -0.7942], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8893, -0.7771,  0.2282, -0.7942], grad_fn=<TanhBackward0>),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1945,  0.8873, -0.4175, -2.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1945,  0.8873, -0.4175, -2.0390], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8320,  0.7100, -0.3948, -0.9667], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8320,  0.7100, -0.3948, -0.9667], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8632, -0.9229, -1.3641,  0.3420], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8632, -0.9229, -1.3641,  0.3420], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6979, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6979, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7524,  0.6612, -1.7234, -0.7538], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7524,  0.6612, -1.7234, -0.7538], grad_fn=<ViewBackward0>),), Output: tensor([-0.9416,  0.5792, -0.9383, -0.6374], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9416,  0.5792, -0.9383, -0.6374], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1714, -0.9188, -0.1769, -1.0623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1714, -0.9188, -0.1769, -1.0623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7349, -0.9794, -0.6698, -1.7895], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7349, -0.9794, -0.6698, -1.7895], grad_fn=<ViewBackward0>),), Output: tensor([-0.6260, -0.7528, -0.5849, -0.9457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6260, -0.7528, -0.5849, -0.9457], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3224, -0.8540,  0.9562, -0.5882], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3224, -0.8540,  0.9562, -0.5882], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8674, -0.6931,  0.7426, -0.5286], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8674, -0.6931,  0.7426, -0.5286], grad_fn=<TanhBackward0>),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -0.1379, -2.8001, -4.0063], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -0.1379, -2.8001, -4.0063], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.1370, -0.9926, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.1370, -0.9926, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3898, -0.9951,  0.3450, -1.0929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3898, -0.9951,  0.3450, -1.0929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8831, -0.7595,  0.3320, -0.7979], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8831, -0.7595,  0.3320, -0.7979], grad_fn=<TanhBackward0>),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2013,  0.8801, -0.4551, -2.0457], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2013,  0.8801, -0.4551, -2.0457], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8341,  0.7065, -0.4261, -0.9671], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8341,  0.7065, -0.4261, -0.9671], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8289, -0.9109, -1.4039,  0.3069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8289, -0.9109, -1.4039,  0.3069], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6799, -0.7216, -0.8862,  0.2976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6799, -0.7216, -0.8862,  0.2976], grad_fn=<TanhBackward0>),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7482,  0.6525, -1.7338, -0.7653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7482,  0.6525, -1.7338, -0.7653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.0490, -0.6758, -1.7944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.0490, -0.6758, -1.7944], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.7814, -0.5888, -0.9462], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.7814, -0.5888, -0.9462], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.8439,  0.9791, -0.5942], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.8439,  0.9791, -0.5942], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.6879,  0.7527, -0.5329], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.6879,  0.7527, -0.5329], grad_fn=<TanhBackward0>),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3297, -0.2561, -2.8077, -4.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3297, -0.2561, -2.8077, -4.0193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.2507, -0.9927, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.2507, -0.9927, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3666, -0.9588,  0.4344, -1.1007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3666, -0.9588,  0.4344, -1.1007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8779, -0.7437,  0.4090, -0.8008], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8779, -0.7437,  0.4090, -0.8008], grad_fn=<TanhBackward0>),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2070,  0.8764, -0.4862, -2.0522], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2070,  0.8764, -0.4862, -2.0522], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8358,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8001, -0.9029, -1.4418,  0.2780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8001, -0.9029, -1.4418,  0.2780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6641, -0.7177, -0.8941,  0.2711], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6641, -0.7177, -0.8941,  0.2711], grad_fn=<TanhBackward0>),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7442,  0.6493, -1.7430, -0.7763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7442,  0.6493, -1.7430, -0.7763], grad_fn=<ViewBackward0>),), Output: tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8211, -0.7366, -0.2205, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8211, -0.7366, -0.2205, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7371, -1.1083, -0.6803, -1.7992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7371, -1.1083, -0.6803, -1.7992], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.8353,  0.9953, -0.5987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.8353,  0.9953, -0.5987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6833,  0.7596, -0.5361], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6833,  0.7596, -0.5361], grad_fn=<TanhBackward0>),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3307, -0.3540, -2.8135, -4.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3307, -0.3540, -2.8135, -4.0317], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.3399, -0.9928, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.3399, -0.9928, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3485, -0.9288,  0.5030, -1.1065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3485, -0.9288,  0.5030, -1.1065], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8737, -0.7300,  0.4644, -0.8028], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8737, -0.7300,  0.4644, -0.8028], grad_fn=<TanhBackward0>),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2117,  0.8755, -0.5119, -2.0584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2117,  0.8755, -0.5119, -2.0584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7760, -0.8979, -1.4773,  0.2544], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7760, -0.8979, -1.4773,  0.2544], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6504, -0.7153, -0.9010,  0.2491], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6504, -0.7153, -0.9010,  0.2491], grad_fn=<TanhBackward0>),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7404,  0.6505, -1.7509, -0.7868], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7404,  0.6505, -1.7509, -0.7868], grad_fn=<ViewBackward0>),), Output: tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1562, -0.9548, -0.2550, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1562, -0.9548, -0.2550, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8198, -0.7419, -0.2496, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8198, -0.7419, -0.2496, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7383, -1.1580, -0.6836, -1.8036], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7383, -1.1580, -0.6836, -1.8036], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.8204, -0.5939, -0.9472], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.8204, -0.5939, -0.9472], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2979, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2979, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8612, -0.6792,  0.7646, -0.5383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8612, -0.6792,  0.7646, -0.5383], grad_fn=<TanhBackward0>),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3319, -0.4362, -2.8175, -4.0432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3319, -0.4362, -2.8175, -4.0432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.4105, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.4105, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3346, -0.9033,  0.5565, -1.1106], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3346, -0.9033,  0.5565, -1.1106], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8704, -0.7179,  0.5054, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8704, -0.7179,  0.5054, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2155,  0.8762, -0.5328, -2.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2155,  0.8762, -0.5328, -2.0641], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7559, -0.8948, -1.5099,  0.2352], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7559, -0.8948, -1.5099,  0.2352], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7370,  0.6546, -1.7576, -0.7966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7370,  0.6546, -1.7576, -0.7966], grad_fn=<ViewBackward0>),), Output: tensor([-0.9399,  0.5748, -0.9422, -0.6621], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9399,  0.5748, -0.9422, -0.6621], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1532, -0.9657, -0.2872, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1532, -0.9657, -0.2872, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7468, -0.2795, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7468, -0.2795, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7396, -1.2004, -0.6858, -1.8078], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7396, -1.2004, -0.6858, -1.8078], grad_fn=<ViewBackward0>),), Output: tensor([-0.6289, -0.8338, -0.5953, -0.9476], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6289, -0.8338, -0.5953, -0.9476], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2938, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2938, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8601, -0.6753,  0.7685, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8601, -0.6753,  0.7685, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3332, -0.5065, -2.8201, -4.0539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3332, -0.5065, -2.8201, -4.0539], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.4672, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.4672, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3239, -0.8809,  0.5996, -1.1134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3239, -0.8809,  0.5996, -1.1134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8677, -0.7069,  0.5368, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8677, -0.7069,  0.5368, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2186,  0.8779, -0.5498, -2.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2186,  0.8779, -0.5498, -2.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8392,  0.7054, -0.5004, -0.9686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8392,  0.7054, -0.5004, -0.9686], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7394, -0.8931, -1.5391,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7394, -0.8931, -1.5391,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6288, -0.7129, -0.9120,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6288, -0.7129, -0.9120,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1511, -0.9754, -0.3191, -1.0732], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1511, -0.9754, -0.3191, -1.0732], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7511, -0.3087, -0.7907], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7511, -0.3087, -0.7907], grad_fn=<TanhBackward0>),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7410, -1.2370, -0.6870, -1.8117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7410, -1.2370, -0.6870, -1.8117], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8594, -0.6713,  0.7721, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8594, -0.6713,  0.7721, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3346, -0.5673, -2.8216, -4.0638], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3346, -0.5673, -2.8216, -4.0638], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.5133, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.5133, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.8609,  0.6352, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.8609,  0.6352, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.6967,  0.5616, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.6967,  0.5616, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2210,  0.8799, -0.5635, -2.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2210,  0.8799, -0.5635, -2.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8399,  0.7064, -0.5105, -0.9689], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8399,  0.7064, -0.5105, -0.9689], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7257, -0.8922, -1.5653,  0.2072], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7257, -0.8922, -1.5653,  0.2072], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6205, -0.7125, -0.9163,  0.2043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6205, -0.7125, -0.9163,  0.2043], grad_fn=<TanhBackward0>),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1495, -0.9841, -0.3499, -1.0741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1495, -0.9841, -0.3499, -1.0741], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8176, -0.7548, -0.3363, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8176, -0.7548, -0.3363, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7424, -1.2691, -0.6876, -1.8152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7424, -1.2691, -0.6876, -1.8152], grad_fn=<ViewBackward0>),), Output: tensor([-0.6306, -0.8536, -0.5964, -0.9484], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6306, -0.8536, -0.5964, -0.9484], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3361, -0.6203, -2.8221, -4.0729], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3361, -0.6203, -2.8221, -4.0729], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5514, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5514, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.8426,  0.6650, -1.1164], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.8426,  0.6650, -1.1164], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6872,  0.5817, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6872,  0.5817, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2229,  0.8821, -0.5744, -2.0791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2229,  0.8821, -0.5744, -2.0791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8405,  0.7075, -0.5186, -0.9692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8405,  0.7075, -0.5186, -0.9692], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7145, -0.8918, -1.5886,  0.1972], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7145, -0.8918, -1.5886,  0.1972], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6135, -0.7123, -0.9199,  0.1947], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6135, -0.7123, -0.9199,  0.1947], grad_fn=<TanhBackward0>),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1484, -0.9916, -0.3794, -1.0747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1484, -0.9916, -0.3794, -1.0747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7580, -0.3622, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7580, -0.3622, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7438, -1.2974, -0.6875, -1.8185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7438, -1.2974, -0.6875, -1.8185], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.8611, -0.5964, -0.9487], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.8611, -0.5964, -0.9487], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7987,  1.0417, -0.6043], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7987,  1.0417, -0.6043], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6633,  0.7786, -0.5401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6633,  0.7786, -0.5401], grad_fn=<TanhBackward0>),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3376, -0.6670, -2.8221, -4.0813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3376, -0.6670, -2.8221, -4.0813], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5830, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5830, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3040, -0.8258,  0.6905, -1.1170], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3040, -0.8258,  0.6905, -1.1170], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.6782,  0.5983, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.6782,  0.5983, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2245,  0.8842, -0.5830, -2.0834], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2245,  0.8842, -0.5830, -2.0834], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8410,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8410,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7054, -0.8919, -1.6093,  0.1892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7054, -0.8919, -1.6093,  0.1892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6078, -0.7123, -0.9231,  0.1870], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6078, -0.7123, -0.9231,  0.1870], grad_fn=<TanhBackward0>),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7261,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7261,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9386,  0.5933, -0.9443, -0.6802], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9386,  0.5933, -0.9443, -0.6802], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1477, -0.9981, -0.4072, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1477, -0.9981, -0.4072, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7608, -0.3861, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7608, -0.3861, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7452, -1.3226, -0.6871, -1.8215], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7452, -1.3226, -0.6871, -1.8215], grad_fn=<ViewBackward0>),), Output: tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7915,  1.0495, -0.6035], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7915,  1.0495, -0.6035], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3389, -0.7083, -2.8215, -4.0891], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3389, -0.7083, -2.8215, -4.0891], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6096, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6096, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3001, -0.8102,  0.7124, -1.1172], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3001, -0.8102,  0.7124, -1.1172], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8618, -0.6697,  0.6122, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8618, -0.6697,  0.6122, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2258,  0.8862, -0.5897, -2.0874], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2258,  0.8862, -0.5897, -2.0874], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6980, -0.8921, -1.6277,  0.1831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6980, -0.8921, -1.6277,  0.1831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1473, -1.0038, -0.4335, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1473, -1.0038, -0.4335, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7465, -1.3450, -0.6864, -1.8242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7465, -1.3450, -0.6864, -1.8242], grad_fn=<ViewBackward0>),), Output: tensor([-0.6330, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6330, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3402, -0.7450, -2.8207, -4.0962], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3402, -0.7450, -2.8207, -4.0962], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6322, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6322, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2971, -0.7957,  0.7315, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2971, -0.7957,  0.7315, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6617,  0.6240, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6617,  0.6240, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2268,  0.8880, -0.5947, -2.0910], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2268,  0.8880, -0.5947, -2.0910], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6921, -0.8924, -1.6439,  0.1783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6921, -0.8924, -1.6439,  0.1783], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5994, -0.7126, -0.9280,  0.1765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5994, -0.7126, -0.9280,  0.1765], grad_fn=<TanhBackward0>),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7220,  0.6983, -1.7822, -0.8424], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7220,  0.6983, -1.7822, -0.8424], grad_fn=<ViewBackward0>),), Output: tensor([-0.9381,  0.6033, -0.9449, -0.6871], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9381,  0.6033, -0.9449, -0.6871], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0087, -0.4582, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0087, -0.4582, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7477, -1.3652, -0.6854, -1.8268], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7477, -1.3652, -0.6854, -1.8268], grad_fn=<ViewBackward0>),), Output: tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2906, -0.7773,  1.0645, -0.6009], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2906, -0.7773,  1.0645, -0.6009], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3413, -0.7778, -2.8196, -4.1028], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3413, -0.7778, -2.8196, -4.1028], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6515, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6515, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2947, -0.7823,  0.7483, -1.1168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2947, -0.7823,  0.7483, -1.1168], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2276,  0.8896, -0.5983, -2.0944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2276,  0.8896, -0.5983, -2.0944], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8419,  0.7112, -0.5359, -0.9701], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8419,  0.7112, -0.5359, -0.9701], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6875, -0.8929, -1.6583,  0.1749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6875, -0.8929, -1.6583,  0.1749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5964, -0.7128, -0.9300,  0.1731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5964, -0.7128, -0.9300,  0.1731], grad_fn=<TanhBackward0>),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7201,  0.7059, -1.7846, -0.8482], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7201,  0.7059, -1.7846, -0.8482], grad_fn=<ViewBackward0>),), Output: tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0129, -0.4814, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0129, -0.4814, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7670, -0.4474, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7670, -0.4474, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7488, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7488, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>),), Output: tensor([-0.6344, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6344, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2917, -0.7704,  1.0715, -0.5994], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2917, -0.7704,  1.0715, -0.5994], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3423, -0.8073, -2.8184, -4.1090], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3423, -0.8073, -2.8184, -4.1090], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6681, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6681, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2929, -0.7697,  0.7630, -1.1163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2929, -0.7697,  0.7630, -1.1163], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6467,  0.6428, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6467,  0.6428, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2282,  0.8909, -0.6008, -2.0975], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2282,  0.8909, -0.6008, -2.0975], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8421,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8421,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6841, -0.8934, -1.6710,  0.1725], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6841, -0.8934, -1.6710,  0.1725], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5942, -0.7131, -0.9317,  0.1708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5942, -0.7131, -0.9317,  0.1708], grad_fn=<TanhBackward0>),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>),), Output: tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1472, -1.0166, -0.5033, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1472, -1.0166, -0.5033, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7685, -0.4647, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7685, -0.4647, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7498, -1.3998, -0.6832, -1.8313], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7498, -1.3998, -0.6832, -1.8313], grad_fn=<ViewBackward0>),), Output: tensor([-0.6350, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6350, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2930, -0.7637,  1.0781, -0.5978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2930, -0.7637,  1.0781, -0.5978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3432, -0.8339, -2.8172, -4.1146], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3432, -0.8339, -2.8172, -4.1146], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6826, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6826, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2915, -0.7579,  0.7761, -1.1158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2915, -0.7579,  0.7761, -1.1158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8595, -0.6398,  0.6505, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8595, -0.6398,  0.6505, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2288,  0.8920, -0.6022, -2.1004], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2288,  0.8920, -0.6022, -2.1004], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8422,  0.7124, -0.5386, -0.9705], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8422,  0.7124, -0.5386, -0.9705], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6815, -0.8939, -1.6822,  0.1710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6815, -0.8939, -1.6822,  0.1710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7168,  0.7203, -1.7885, -0.8584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7168,  0.7203, -1.7885, -0.8584], grad_fn=<ViewBackward0>),), Output: tensor([-0.9375,  0.6171, -0.9456, -0.6954], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9375,  0.6171, -0.9456, -0.6954], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1474, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1474, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8169, -0.7698, -0.4806, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8169, -0.7698, -0.4806, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7507, -1.4147, -0.6820, -1.8334], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7507, -1.4147, -0.6820, -1.8334], grad_fn=<ViewBackward0>),), Output: tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2944, -0.7572,  1.0844, -0.5961], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2944, -0.7572,  1.0844, -0.5961], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8603, -0.6394,  0.7948, -0.5343], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8603, -0.6394,  0.7948, -0.5343], grad_fn=<TanhBackward0>),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3438, -0.8580, -2.8160, -4.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3438, -0.8580, -2.8160, -4.1199], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2292,  0.8927, -0.6027, -2.1031], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2292,  0.8927, -0.6027, -2.1031], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6799, -0.8944, -1.6919,  0.1703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6799, -0.8944, -1.6919,  0.1703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5914, -0.7136, -0.9344,  0.1687], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5914, -0.7136, -0.9344,  0.1687], grad_fn=<TanhBackward0>),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>),), Output: tensor([-0.9373,  0.6213, -0.9458, -0.6978], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9373,  0.6213, -0.9458, -0.6978], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1478, -1.0226, -0.5430, -1.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1478, -1.0226, -0.5430, -1.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7515, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7515, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>),), Output: tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2958, -0.7510,  1.0902, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2958, -0.7510,  1.0902, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8606, -0.6357,  0.7970, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8606, -0.6357,  0.7970, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3444, -0.8799, -2.8148, -4.1248], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3444, -0.8799, -2.8148, -4.1248], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7064, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7064, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2895, -0.7366,  0.7982, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2895, -0.7366,  0.7982, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2295,  0.8932, -0.6025, -2.1057], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2295,  0.8932, -0.6025, -2.1057], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8424,  0.7130, -0.5388, -0.9708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8424,  0.7130, -0.5388, -0.9708], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8949, -1.7004,  0.1703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8949, -1.7004,  0.1703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7138, -0.9355,  0.1686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7138, -0.9355,  0.1686], grad_fn=<TanhBackward0>),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7139,  0.7335, -1.7914, -0.8672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7139,  0.7335, -1.7914, -0.8672], grad_fn=<ViewBackward0>),), Output: tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1482, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1482, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7522, -1.4408, -0.6796, -1.8370], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7522, -1.4408, -0.6796, -1.8370], grad_fn=<ViewBackward0>),), Output: tensor([-0.6365, -0.8939, -0.5913, -0.9505], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6365, -0.8939, -0.5913, -0.9505], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2972, -0.7450,  1.0957, -0.5928], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2972, -0.7450,  1.0957, -0.5928], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3448, -0.9000, -2.8137, -4.1294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3448, -0.9000, -2.8137, -4.1294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7163, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7163, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2889, -0.7269,  0.8075, -1.1139], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2889, -0.7269,  0.8075, -1.1139], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2298,  0.8934, -0.6017, -2.1080], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2298,  0.8934, -0.6017, -2.1080], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8425,  0.7131, -0.5382, -0.9709], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8425,  0.7131, -0.5382, -0.9709], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6786, -0.8955, -1.7078,  0.1709], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6786, -0.8955, -1.7078,  0.1709], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5906, -0.7141, -0.9364,  0.1692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5906, -0.7141, -0.9364,  0.1692], grad_fn=<TanhBackward0>),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7125,  0.7396, -1.7926, -0.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7125,  0.7396, -1.7926, -0.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1487, -1.0271, -0.5780, -1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1487, -1.0271, -0.5780, -1.0739], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2987, -0.7393,  1.1008, -0.5913], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2987, -0.7393,  1.1008, -0.5913], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8614, -0.6287,  0.8008, -0.5308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8614, -0.6287,  0.8008, -0.5308], grad_fn=<TanhBackward0>),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3450, -0.9183, -2.8126, -4.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3450, -0.9183, -2.8126, -4.1337], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2884, -0.7179,  0.8159, -1.1133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2884, -0.7179,  0.8159, -1.1133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8587, -0.6156,  0.6728, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8587, -0.6156,  0.6728, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2300,  0.8934, -0.6002, -2.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2300,  0.8934, -0.6002, -2.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7131, -0.5372, -0.9710], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7131, -0.5372, -0.9710], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8960, -1.7141,  0.1720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8960, -1.7141,  0.1720], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7143, -0.9372,  0.1703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7143, -0.9372,  0.1703], grad_fn=<TanhBackward0>),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>),), Output: tensor([-0.9368,  0.6324, -0.9461, -0.7038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9368,  0.6324, -0.9461, -0.7038], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1492, -1.0290, -0.5939, -1.0735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1492, -1.0290, -0.5939, -1.0735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.4628, -0.6774, -1.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.4628, -0.6774, -1.8402], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3000, -0.7339,  1.1055, -0.5897], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3000, -0.7339,  1.1055, -0.5897], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8617, -0.6254,  0.8025, -0.5297], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8617, -0.6254,  0.8025, -0.5297], grad_fn=<TanhBackward0>),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9353, -2.8117, -4.1378], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9353, -2.8117, -4.1378], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2880, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2880, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8586, -0.6104,  0.6770, -0.8050], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8586, -0.6104,  0.6770, -0.8050], grad_fn=<TanhBackward0>),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2302,  0.8931, -0.5983, -2.1123], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2302,  0.8931, -0.5983, -2.1123], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6797, -0.8965, -1.7195,  0.1735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6797, -0.8965, -1.7195,  0.1735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5913, -0.7146, -0.9378,  0.1718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5913, -0.7146, -0.9378,  0.1718], grad_fn=<TanhBackward0>),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7101,  0.7508, -1.7945, -0.8783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7101,  0.7508, -1.7945, -0.8783], grad_fn=<ViewBackward0>),), Output: tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7537, -1.4726, -0.6764, -1.8417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7537, -1.4726, -0.6764, -1.8417], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3014, -0.7287,  1.1099, -0.5883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3014, -0.7287,  1.1099, -0.5883], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9509, -2.8108, -4.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9509, -2.8108, -4.1416], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2878, -0.7016,  0.8304, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2878, -0.7016,  0.8304, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2303,  0.8926, -0.5959, -2.1143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2303,  0.8926, -0.5959, -2.1143], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7127, -0.5341, -0.9713], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7127, -0.5341, -0.9713], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6809, -0.8970, -1.7240,  0.1755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6809, -0.8970, -1.7240,  0.1755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5921, -0.7148, -0.9383,  0.1737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5921, -0.7148, -0.9383,  0.1737], grad_fn=<TanhBackward0>),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7090,  0.7559, -1.7953, -0.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7090,  0.7559, -1.7953, -0.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.9365,  0.6387, -0.9463, -0.7072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9365,  0.6387, -0.9463, -0.7072], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1504, -1.0320, -0.6229, -1.0727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1504, -1.0320, -0.6229, -1.0727], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8179, -0.7747, -0.5532, -0.7905], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8179, -0.7747, -0.5532, -0.7905], grad_fn=<TanhBackward0>),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.4817, -0.6754, -1.8431], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.4817, -0.6754, -1.8431], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3027, -0.7238,  1.1139, -0.5869], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3027, -0.7238,  1.1139, -0.5869], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3451, -0.9654, -2.8101, -4.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3451, -0.9654, -2.8101, -4.1451], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2876, -0.6942,  0.8367, -1.1116], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2876, -0.6942,  0.8367, -1.1116], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8919, -0.5932, -2.1161], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8919, -0.5932, -2.1161], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6824, -0.8975, -1.7277,  0.1778], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6824, -0.8975, -1.7277,  0.1778], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5931, -0.7151, -0.9388,  0.1759], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5931, -0.7151, -0.9388,  0.1759], grad_fn=<TanhBackward0>),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7079,  0.7607, -1.7960, -0.8845], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7079,  0.7607, -1.7960, -0.8845], grad_fn=<ViewBackward0>),), Output: tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1510, -1.0333, -0.6361, -1.0723], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1510, -1.0333, -0.6361, -1.0723], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7752, -0.5623, -0.7903], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7752, -0.5623, -0.7903], grad_fn=<TanhBackward0>),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.4901, -0.6745, -1.8444], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.4901, -0.6745, -1.8444], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3449, -0.9790, -2.8094, -4.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3449, -0.9790, -2.8094, -4.1485], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2874, -0.6873,  0.8424, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2874, -0.6873,  0.8424, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5962,  0.6871, -0.8045], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5962,  0.6871, -0.8045], grad_fn=<TanhBackward0>),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8909, -0.5901, -2.1178], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8909, -0.5901, -2.1178], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7119, -0.5300, -0.9715], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7119, -0.5300, -0.9715], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6843, -0.8980, -1.7307,  0.1804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6843, -0.8980, -1.7307,  0.1804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7069,  0.7652, -1.7966, -0.8873], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7069,  0.7652, -1.7966, -0.8873], grad_fn=<ViewBackward0>),), Output: tensor([-0.9363,  0.6442, -0.9465, -0.7101], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9363,  0.6442, -0.9465, -0.7101], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1517, -1.0344, -0.6486, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1517, -1.0344, -0.6486, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.4980, -0.6736, -1.8456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.4980, -0.6736, -1.8456], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3050, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3050, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3446, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3446, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7581, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7581, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2873, -0.6808,  0.8476, -1.1107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2873, -0.6808,  0.8476, -1.1107], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5920,  0.6898, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5920,  0.6898, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8898, -0.5868, -2.1195], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8898, -0.5868, -2.1195], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6864, -0.8985, -1.7331,  0.1832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6864, -0.8985, -1.7331,  0.1832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5957, -0.7156, -0.9394,  0.1812], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5957, -0.7156, -0.9394,  0.1812], grad_fn=<TanhBackward0>),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7059,  0.7695, -1.7971, -0.8900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7059,  0.7695, -1.7971, -0.8900], grad_fn=<ViewBackward0>),), Output: tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1524, -1.0354, -0.6603, -1.0715], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1524, -1.0354, -0.6603, -1.0715], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8185, -0.7761, -0.5786, -0.7900], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8185, -0.7761, -0.5786, -0.7900], grad_fn=<TanhBackward0>),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3061, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3061, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.6110,  0.8090, -0.5250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.6110,  0.8090, -0.5250], grad_fn=<TanhBackward0>),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3443, -1.0035, -2.8085, -4.1547], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3443, -1.0035, -2.8085, -4.1547], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7631, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7631, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6747,  0.8524, -1.1103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6747,  0.8524, -1.1103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8886, -0.5833, -2.1210], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8886, -0.5833, -2.1210], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7107, -0.5250, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7107, -0.5250, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6888, -0.8991, -1.7348,  0.1863], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6888, -0.8991, -1.7348,  0.1863], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5972, -0.7158, -0.9396,  0.1842], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5972, -0.7158, -0.9396,  0.1842], grad_fn=<TanhBackward0>),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>),), Output: tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1530, -1.0363, -0.6713, -1.0712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1530, -1.0363, -0.6713, -1.0712], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5124, -0.6721, -1.8479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5124, -0.6721, -1.8479], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9074, -0.5864, -0.9516], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9074, -0.5864, -0.9516], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3071, -0.7066,  1.1270, -0.5822], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3071, -0.7066,  1.1270, -0.5822], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6690,  0.8568, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6690,  0.8568, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5843,  0.6946, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5843,  0.6946, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8871, -0.5795, -2.1225], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8871, -0.5795, -2.1225], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7100, -0.5223, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7100, -0.5223, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6914, -0.8996, -1.7361,  0.1896], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6914, -0.8996, -1.7361,  0.1896], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7041,  0.7772, -1.7979, -0.8948], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7041,  0.7772, -1.7979, -0.8948], grad_fn=<ViewBackward0>),), Output: tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1537, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1537, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8190, -0.7767, -0.5926, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8190, -0.7767, -0.5926, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.7029,  1.1296, -0.5812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.7029,  1.1296, -0.5812], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3434, -1.0253, -2.8079, -4.1603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3434, -1.0253, -2.8079, -4.1603], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6636,  0.8609, -1.1096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6636,  0.8609, -1.1096], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8856, -0.5756, -2.1239], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8856, -0.5756, -2.1239], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7092, -0.5195, -0.9718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7092, -0.5195, -0.9718], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6942, -0.9001, -1.7368,  0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6942, -0.9001, -1.7368,  0.1930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6007, -0.7163, -0.9399,  0.1906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6007, -0.7163, -0.9399,  0.1906], grad_fn=<TanhBackward0>),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7032,  0.7806, -1.7983, -0.8970], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7032,  0.7806, -1.7983, -0.8970], grad_fn=<ViewBackward0>),), Output: tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1544, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1544, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8192, -0.7770, -0.5990, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8192, -0.7770, -0.5990, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.5252, -0.6708, -1.8500], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.5252, -0.6708, -1.8500], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9096, -0.5855, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9096, -0.5855, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3428, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3428, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6586,  0.8648, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6586,  0.8648, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5774,  0.6987, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5774,  0.6987, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8839, -0.5716, -2.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8839, -0.5716, -2.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7084, -0.5165, -0.9719], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7084, -0.5165, -0.9719], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6971, -0.9006, -1.7371,  0.1966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6971, -0.9006, -1.7371,  0.1966], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6025, -0.7166, -0.9399,  0.1941], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6025, -0.7166, -0.9399,  0.1941], grad_fn=<TanhBackward0>),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7024,  0.7839, -1.7985, -0.8991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7024,  0.7839, -1.7985, -0.8991], grad_fn=<ViewBackward0>),), Output: tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1551, -1.0384, -0.7008, -1.0700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1551, -1.0384, -0.7008, -1.0700], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8194, -0.7773, -0.6049, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8194, -0.7773, -0.6049, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7543, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7543, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3098, -0.6960,  1.1341, -0.5794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3098, -0.6960,  1.1341, -0.5794], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.6018,  0.8124, -0.5223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.6018,  0.8124, -0.5223], grad_fn=<TanhBackward0>),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3422, -1.0448, -2.8077, -4.1653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3422, -1.0448, -2.8077, -4.1653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8821, -0.5675, -2.1265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8821, -0.5675, -2.1265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7075, -0.5135, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7075, -0.5135, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7001, -0.9012, -1.7370,  0.2003], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7001, -0.9012, -1.7370,  0.2003], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6044, -0.7169, -0.9399,  0.1976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6044, -0.7169, -0.9399,  0.1976], grad_fn=<TanhBackward0>),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7016,  0.7869, -1.7988, -0.9011], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7016,  0.7869, -1.7988, -0.9011], grad_fn=<ViewBackward0>),), Output: tensor([-0.9356,  0.6567, -0.9467, -0.7168], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9356,  0.6567, -0.9467, -0.7168], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8197, -0.7775, -0.6104, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8197, -0.7775, -0.6104, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>),), Output: tensor([-0.6376, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6376, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3105, -0.6929,  1.1361, -0.5787], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3105, -0.6929,  1.1361, -0.5787], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5998,  0.8131, -0.5217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5998,  0.8131, -0.5217], grad_fn=<TanhBackward0>),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3416, -1.0539, -2.8077, -4.1677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3416, -1.0539, -2.8077, -4.1677], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8802, -0.5632, -2.1277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8802, -0.5632, -2.1277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7065, -0.5104, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7065, -0.5104, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7032, -0.9017, -1.7366,  0.2040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7032, -0.9017, -1.7366,  0.2040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7009,  0.7898, -1.7990, -0.9030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7009,  0.7898, -1.7990, -0.9030], grad_fn=<ViewBackward0>),), Output: tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.5421, -0.6694, -1.8529], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.5421, -0.6694, -1.8529], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3112, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3112, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3409, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3409, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7867, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7867, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6452,  0.8748, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6452,  0.8748, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8782, -0.5589, -2.1288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8782, -0.5589, -2.1288], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7055, -0.5072, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7055, -0.5072, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7064, -0.9022, -1.7358,  0.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7064, -0.9022, -1.7358,  0.2079], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7001,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7001,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1572, -1.0399, -0.7255, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1572, -1.0399, -0.7255, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7538, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7538, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>),), Output: tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6870,  1.1396, -0.5774], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6870,  1.1396, -0.5774], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5960,  0.8143, -0.5208], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5960,  0.8143, -0.5208], grad_fn=<TanhBackward0>),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3402, -1.0709, -2.8081, -4.1721], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3402, -1.0709, -2.8081, -4.1721], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8761, -0.5546, -2.1299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8761, -0.5546, -2.1299], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7045, -0.5040, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7045, -0.5040, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7096, -0.9028, -1.7348,  0.2118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7096, -0.9028, -1.7348,  0.2118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6105, -0.7177, -0.9396,  0.2087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6105, -0.7177, -0.9396,  0.2087], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6994,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6994,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6612, -0.9467, -0.7194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6612, -0.9467, -0.7194], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1578, -1.0403, -0.7329, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1578, -1.0403, -0.7329, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3395, -1.0789, -2.8083, -4.1742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3395, -1.0789, -2.8083, -4.1742], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6374,  0.8805, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6374,  0.8805, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5631,  0.7067, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5631,  0.7067, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8740, -0.5502, -2.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8740, -0.5502, -2.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7034, -0.5007, -0.9722], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7034, -0.5007, -0.9722], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7129, -0.9033, -1.7334,  0.2157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7129, -0.9033, -1.7334,  0.2157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6125, -0.7179, -0.9395,  0.2125], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6125, -0.7179, -0.9395,  0.2125], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6625, -0.9467, -0.7202], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6625, -0.9467, -0.7202], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1585, -1.0407, -0.7398, -1.0684], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1585, -1.0407, -0.7398, -1.0684], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8205, -0.7781, -0.6291, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8205, -0.7781, -0.6291, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.5568, -0.6685, -1.8554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.5568, -0.6685, -1.8554], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.9149, -0.5840, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.9149, -0.5840, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3130, -0.6817,  1.1426, -0.5763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3130, -0.6817,  1.1426, -0.5763], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3387, -1.0866, -2.8087, -4.1762], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3387, -1.0866, -2.8087, -4.1762], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7957, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7957, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6338,  0.8832, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6338,  0.8832, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8718, -0.5459, -2.1320], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8718, -0.5459, -2.1320], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7023, -0.4974, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7023, -0.4974, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7162, -0.9039, -1.7319,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7162, -0.9039, -1.7319,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6981,  0.7994, -1.7996, -0.9096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6981,  0.7994, -1.7996, -0.9096], grad_fn=<ViewBackward0>),), Output: tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1591, -1.0410, -0.7464, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1591, -1.0410, -0.7464, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7530, -1.5613, -0.6683, -1.8561], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7530, -1.5613, -0.6683, -1.8561], grad_fn=<ViewBackward0>),), Output: tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3135, -0.6792,  1.1439, -0.5759], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3135, -0.6792,  1.1439, -0.5759], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3380, -1.0941, -2.8091, -4.1781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3380, -1.0941, -2.8091, -4.1781], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6304,  0.8858, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6304,  0.8858, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8695, -0.5415, -2.1330], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8695, -0.5415, -2.1330], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7195, -0.9045, -1.7301,  0.2237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7195, -0.9045, -1.7301,  0.2237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>),), Output: tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1597, -1.0412, -0.7527, -1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1597, -1.0412, -0.7527, -1.0679], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7527, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7527, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5895,  0.8161, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5895,  0.8161, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6272,  0.8882, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6272,  0.8882, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5561,  0.7105, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5561,  0.7105, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8673, -0.5371, -2.1339], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8673, -0.5371, -2.1339], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7000, -0.4908, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7000, -0.4908, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7228, -0.9050, -1.7282,  0.2277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7228, -0.9050, -1.7282,  0.2277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6969,  0.8033, -1.7997, -0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6969,  0.8033, -1.7997, -0.9125], grad_fn=<ViewBackward0>),), Output: tensor([-0.9350,  0.6659, -0.9468, -0.7223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9350,  0.6659, -0.9468, -0.7223], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1604, -1.0415, -0.7586, -1.0676], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1604, -1.0415, -0.7586, -1.0676], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7524, -1.5698, -0.6680, -1.8576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7524, -1.5698, -0.6680, -1.8576], grad_fn=<ViewBackward0>),), Output: tensor([-0.6366, -0.9170, -0.5837, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6366, -0.9170, -0.5837, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3143, -0.6746,  1.1462, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3143, -0.6746,  1.1462, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3364, -1.1083, -2.8102, -4.1817], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3364, -1.1083, -2.8102, -4.1817], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8035, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8035, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8649, -0.5328, -2.1348], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8649, -0.5328, -2.1348], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6988, -0.4875, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6988, -0.4875, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7261, -0.9056, -1.7261,  0.2317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7261, -0.9056, -1.7261,  0.2317], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6207, -0.7190, -0.9386,  0.2276], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6207, -0.7190, -0.9386,  0.2276], grad_fn=<TanhBackward0>),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6963,  0.8050, -1.7998, -0.9138], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6963,  0.8050, -1.7998, -0.9138], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1610, -1.0417, -0.7642, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1610, -1.0417, -0.7642, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7521, -1.5739, -0.6679, -1.8583], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7521, -1.5739, -0.6679, -1.8583], grad_fn=<ViewBackward0>),), Output: tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6724,  1.1472, -0.5750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6724,  1.1472, -0.5750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5866,  0.8168, -0.5190], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5866,  0.8168, -0.5190], grad_fn=<TanhBackward0>),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3355, -1.1151, -2.8108, -4.1835], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3355, -1.1151, -2.8108, -4.1835], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6212,  0.8928, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6212,  0.8928, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2309,  0.8626, -0.5285, -2.1357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2309,  0.8626, -0.5285, -2.1357], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6976, -0.4842, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6976, -0.4842, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7294, -0.9062, -1.7239,  0.2356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7294, -0.9062, -1.7239,  0.2356], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6227, -0.7193, -0.9383,  0.2314], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6227, -0.7193, -0.9383,  0.2314], grad_fn=<TanhBackward0>),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6957,  0.8066, -1.7999, -0.9151], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6957,  0.8066, -1.7999, -0.9151], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1615, -1.0419, -0.7695, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1615, -1.0419, -0.7695, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8215, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8215, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7517, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7517, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>),), Output: tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3149, -0.6704,  1.1481, -0.5748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3149, -0.6704,  1.1481, -0.5748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5852,  0.8171, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5852,  0.8171, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3347, -1.1216, -2.8115, -4.1851], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3347, -1.1216, -2.8115, -4.1851], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6184,  0.8950, -1.1088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6184,  0.8950, -1.1088], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5500,  0.7139, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5500,  0.7139, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8602, -0.5242, -2.1365], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8602, -0.5242, -2.1365], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6964, -0.4809, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6964, -0.4809, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7326, -0.9068, -1.7216,  0.2396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7326, -0.9068, -1.7216,  0.2396], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6247, -0.7196, -0.9381,  0.2351], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6247, -0.7196, -0.9381,  0.2351], grad_fn=<TanhBackward0>),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6952,  0.8082, -1.7999, -0.9163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6952,  0.8082, -1.7999, -0.9163], grad_fn=<ViewBackward0>),), Output: tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1621, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1621, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>),), Output: tensor([-0.6360, -0.9189, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6360, -0.9189, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3339, -1.1281, -2.8123, -4.1867], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3339, -1.1281, -2.8123, -4.1867], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8104, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8104, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8578, -0.5200, -2.1373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8578, -0.5200, -2.1373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7358, -0.9073, -1.7191,  0.2435], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7358, -0.9073, -1.7191,  0.2435], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6266, -0.7198, -0.9378,  0.2388], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6266, -0.7198, -0.9378,  0.2388], grad_fn=<TanhBackward0>),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6946,  0.8096, -1.8000, -0.9175], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6946,  0.8096, -1.8000, -0.9175], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6694, -0.9468, -0.7247], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6694, -0.9468, -0.7247], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1627, -1.0421, -0.7793, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1627, -1.0421, -0.7793, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8219, -0.7787, -0.6523, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8219, -0.7787, -0.6523, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7510, -1.5854, -0.6680, -1.8603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7510, -1.5854, -0.6680, -1.8603], grad_fn=<ViewBackward0>),), Output: tensor([-0.6357, -0.9194, -0.5837, -0.9527], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6357, -0.9194, -0.5837, -0.9527], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6664,  1.1498, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6664,  1.1498, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5826,  0.8177, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5826,  0.8177, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3330, -1.1343, -2.8131, -4.1883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3330, -1.1343, -2.8131, -4.1883], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6132,  0.8992, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6132,  0.8992, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2311,  0.8554, -0.5158, -2.1381], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2311,  0.8554, -0.5158, -2.1381], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6939, -0.4745, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6939, -0.4745, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7390, -0.9079, -1.7166,  0.2473], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7390, -0.9079, -1.7166,  0.2473], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6285, -0.7201, -0.9375,  0.2424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6285, -0.7201, -0.9375,  0.2424], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6941,  0.8109, -1.8001, -0.9186], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6941,  0.8109, -1.8001, -0.9186], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1632, -1.0422, -0.7838, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1632, -1.0422, -0.7838, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7506, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7506, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>),), Output: tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6108,  0.9013, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6108,  0.9013, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2312,  0.8530, -0.5117, -2.1388], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2312,  0.8530, -0.5117, -2.1388], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7421, -0.9085, -1.7140,  0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7421, -0.9085, -1.7140,  0.2512], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6304, -0.7204, -0.9371,  0.2460], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6304, -0.7204, -0.9371,  0.2460], grad_fn=<TanhBackward0>),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6936,  0.8121, -1.8001, -0.9197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6936,  0.8121, -1.8001, -0.9197], grad_fn=<ViewBackward0>),), Output: tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1637, -1.0423, -0.7881, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1637, -1.0423, -0.7881, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8222, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8222, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7502, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7502, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>),), Output: tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6628,  1.1512, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6628,  1.1512, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5802,  0.8182, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5802,  0.8182, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3313, -1.1464, -2.8148, -4.1912], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3313, -1.1464, -2.8148, -4.1912], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8166, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8166, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6084,  0.9032, -1.1095], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6084,  0.9032, -1.1095], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5430,  0.7179, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5430,  0.7179, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2313,  0.8506, -0.5077, -2.1395], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2313,  0.8506, -0.5077, -2.1395], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6914, -0.4681, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6914, -0.4681, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7452, -0.9090, -1.7113,  0.2549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7452, -0.9090, -1.7113,  0.2549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6323, -0.7207, -0.9368,  0.2495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6323, -0.7207, -0.9368,  0.2495], grad_fn=<TanhBackward0>),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1642, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1642, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7498, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7498, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>),), Output: tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3305, -1.1522, -2.8158, -4.1926], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3305, -1.1522, -2.8158, -4.1926], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5414,  0.7188, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5414,  0.7188, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8482, -0.5037, -2.1402], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8482, -0.5037, -2.1402], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6901, -0.4650, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6901, -0.4650, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7482, -0.9096, -1.7086,  0.2586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7482, -0.9096, -1.7086,  0.2586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6341, -0.7209, -0.9365,  0.2530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6341, -0.7209, -0.9365,  0.2530], grad_fn=<TanhBackward0>),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6926,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6926,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6719, -0.9468, -0.7267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6719, -0.9468, -0.7267], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1647, -1.0424, -0.7960, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1647, -1.0424, -0.7960, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7494, -1.5993, -0.6686, -1.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7494, -1.5993, -0.6686, -1.8627], grad_fn=<ViewBackward0>),), Output: tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6594,  1.1525, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6594,  1.1525, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5780,  0.8186, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5780,  0.8186, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3296, -1.1579, -2.8168, -4.1940], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3296, -1.1579, -2.8168, -4.1940], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6040,  0.9071, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6040,  0.9071, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8458, -0.4998, -2.1409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8458, -0.4998, -2.1409], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6889, -0.4620, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6889, -0.4620, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7512, -0.9101, -1.7059,  0.2623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7512, -0.9101, -1.7059,  0.2623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6922,  0.8153, -1.8003, -0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6922,  0.8153, -1.8003, -0.9227], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7789, -0.6639, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7789, -0.6639, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7490, -1.6025, -0.6689, -1.8633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7490, -1.6025, -0.6689, -1.8633], grad_fn=<ViewBackward0>),), Output: tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6577,  1.1531, -0.5749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6577,  1.1531, -0.5749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5769,  0.8188, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5769,  0.8188, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -1.1636, -2.8178, -4.1953], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -1.1636, -2.8178, -4.1953], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.6019,  0.9090, -1.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.6019,  0.9090, -1.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2316,  0.8434, -0.4960, -2.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2316,  0.8434, -0.4960, -2.1416], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6876, -0.4590, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6876, -0.4590, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7541, -0.9106, -1.7031,  0.2659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7541, -0.9106, -1.7031,  0.2659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6376, -0.7214, -0.9358,  0.2598], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6376, -0.7214, -0.9358,  0.2598], grad_fn=<TanhBackward0>),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6917,  0.8162, -1.8003, -0.9237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6917,  0.8162, -1.8003, -0.9237], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6730, -0.9468, -0.7276], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6730, -0.9468, -0.7276], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1656, -1.0425, -0.8032, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1656, -1.0425, -0.8032, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7486, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7486, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279, -1.1690, -2.8189, -4.1966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279, -1.1690, -2.8189, -4.1966], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2317,  0.8411, -0.4922, -2.1422], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2317,  0.8411, -0.4922, -2.1422], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6864, -0.4560, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6864, -0.4560, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7569, -0.9112, -1.7003,  0.2694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7569, -0.9112, -1.7003,  0.2694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6393, -0.7217, -0.9354,  0.2631], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6393, -0.7217, -0.9354,  0.2631], grad_fn=<TanhBackward0>),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1661, -1.0425, -0.8065, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1661, -1.0425, -0.8065, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7482, -1.6088, -0.6695, -1.8644], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7482, -1.6088, -0.6695, -1.8644], grad_fn=<ViewBackward0>),), Output: tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6546,  1.1541, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6546,  1.1541, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3271, -1.1744, -2.8201, -4.1979], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3271, -1.1744, -2.8201, -4.1979], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5980,  0.9127, -1.1108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5980,  0.9127, -1.1108], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2318,  0.8387, -0.4886, -2.1428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2318,  0.8387, -0.4886, -2.1428], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6851, -0.4531, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6851, -0.4531, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7597, -0.9117, -1.6975,  0.2728], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7597, -0.9117, -1.6975,  0.2728], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6409, -0.7219, -0.9351,  0.2663], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6409, -0.7219, -0.9351,  0.2663], grad_fn=<TanhBackward0>),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6908,  0.8178, -1.8005, -0.9254], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6908,  0.8178, -1.8005, -0.9254], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6739, -0.9469, -0.7285], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6739, -0.9469, -0.7285], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1665, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1665, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8231, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8231, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7478, -1.6118, -0.6698, -1.8649], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7478, -1.6118, -0.6698, -1.8649], grad_fn=<ViewBackward0>),), Output: tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6531,  1.1545, -0.5755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6531,  1.1545, -0.5755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3262, -1.1797, -2.8212, -4.1991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3262, -1.1797, -2.8212, -4.1991], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5961,  0.9145, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5961,  0.9145, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5342,  0.7233, -0.8044], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5342,  0.7233, -0.8044], grad_fn=<TanhBackward0>),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2319,  0.8363, -0.4850, -2.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2319,  0.8363, -0.4850, -2.1434], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6839, -0.4502, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6839, -0.4502, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7624, -0.9122, -1.6946,  0.2762], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7624, -0.9122, -1.6946,  0.2762], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6425, -0.7222, -0.9347,  0.2694], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6425, -0.7222, -0.9347,  0.2694], grad_fn=<TanhBackward0>),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6904,  0.8185, -1.8005, -0.9263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6904,  0.8185, -1.8005, -0.9263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1669, -1.0424, -0.8126, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1669, -1.0424, -0.8126, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8233, -0.7788, -0.6710, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8233, -0.7788, -0.6710, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7474, -1.6148, -0.6702, -1.8654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7474, -1.6148, -0.6702, -1.8654], grad_fn=<ViewBackward0>),), Output: tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6516,  1.1550, -0.5758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6516,  1.1550, -0.5758], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3254, -1.1849, -2.8224, -4.2003], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3254, -1.1849, -2.8224, -4.2003], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2866, -0.5942,  0.9162, -1.1114], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2866, -0.5942,  0.9162, -1.1114], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5329,  0.7241, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5329,  0.7241, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2320,  0.8340, -0.4815, -2.1440], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2320,  0.8340, -0.4815, -2.1440], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6826, -0.4474, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6826, -0.4474, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7651, -0.9127, -1.6918,  0.2795], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7651, -0.9127, -1.6918,  0.2795], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6441, -0.7224, -0.9344,  0.2725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6441, -0.7224, -0.9344,  0.2725], grad_fn=<TanhBackward0>),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6746, -0.9469, -0.7292], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6746, -0.9469, -0.7292], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1673, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1673, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7470, -1.6177, -0.6706, -1.8659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7470, -1.6177, -0.6706, -1.8659], grad_fn=<ViewBackward0>),), Output: tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3245, -1.1900, -2.8237, -4.2015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3245, -1.1900, -2.8237, -4.2015], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5317,  0.7250, -0.8047], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5317,  0.7250, -0.8047], grad_fn=<TanhBackward0>),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2321,  0.8317, -0.4781, -2.1445], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2321,  0.8317, -0.4781, -2.1445], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6814, -0.4447, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6814, -0.4447, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7677, -0.9132, -1.6890,  0.2828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7677, -0.9132, -1.6890,  0.2828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6456, -0.7227, -0.9340,  0.2755], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6456, -0.7227, -0.9340,  0.2755], grad_fn=<TanhBackward0>),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8235, -0.7788, -0.6741, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8235, -0.7788, -0.6741, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>),), Output: tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5708,  0.8197, -0.5201], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5708,  0.8197, -0.5201], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3237, -1.1951, -2.8249, -4.2026], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3237, -1.1951, -2.8249, -4.2026], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5304,  0.7258, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5304,  0.7258, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2323,  0.8294, -0.4747, -2.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2323,  0.8294, -0.4747, -2.1451], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6802, -0.4420, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6802, -0.4420, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7702, -0.9137, -1.6862,  0.2859], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7702, -0.9137, -1.6862,  0.2859], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6470, -0.7229, -0.9337,  0.2784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6470, -0.7229, -0.9337,  0.2784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6892,  0.8203, -1.8008, -0.9286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6892,  0.8203, -1.8008, -0.9286], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1681, -1.0422, -0.8207, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1681, -1.0422, -0.8207, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8237, -0.7788, -0.6755, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8237, -0.7788, -0.6755, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>),), Output: tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3229, -1.2000, -2.8262, -4.2037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3229, -1.2000, -2.8262, -4.2037], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5292,  0.7266, -0.8049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5292,  0.7266, -0.8049], grad_fn=<TanhBackward0>),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2324,  0.8272, -0.4715, -2.1456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2324,  0.8272, -0.4715, -2.1456], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7726, -0.9141, -1.6834,  0.2890], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7726, -0.9141, -1.6834,  0.2890], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6485, -0.7231, -0.9333,  0.2812], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6485, -0.7231, -0.9333,  0.2812], grad_fn=<TanhBackward0>),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6888,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6888,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1684, -1.0421, -0.8231, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1684, -1.0421, -0.8231, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7458, -1.6261, -0.6719, -1.8674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7458, -1.6261, -0.6719, -1.8674], grad_fn=<ViewBackward0>),), Output: tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.6460,  1.1565, -0.5772], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.6460,  1.1565, -0.5772], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5690,  0.8199, -0.5206], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5690,  0.8199, -0.5206], grad_fn=<TanhBackward0>),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3221, -1.2049, -2.8276, -4.2048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3221, -1.2049, -2.8276, -4.2048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2325,  0.8249, -0.4683, -2.1461], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2325,  0.8249, -0.4683, -2.1461], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6777, -0.4368, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6777, -0.4368, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7750, -0.9146, -1.6807,  0.2920], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7750, -0.9146, -1.6807,  0.2920], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6498, -0.7233, -0.9329,  0.2840], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6498, -0.7233, -0.9329,  0.2840], grad_fn=<TanhBackward0>),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6885,  0.8213, -1.8010, -0.9301], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6885,  0.8213, -1.8010, -0.9301], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6758, -0.9469, -0.7306], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6758, -0.9469, -0.7306], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1688, -1.0420, -0.8255, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1688, -1.0420, -0.8255, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7454, -1.6288, -0.6724, -1.8678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7454, -1.6288, -0.6724, -1.8678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6324, -0.9259, -0.5866, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6324, -0.9259, -0.5866, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6447,  1.1568, -0.5776], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6447,  1.1568, -0.5776], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3212, -1.2097, -2.8289, -4.2058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3212, -1.2097, -2.8289, -4.2058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5859,  0.9249, -1.1132], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5859,  0.9249, -1.1132], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5269,  0.7282, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5269,  0.7282, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2327,  0.8227, -0.4652, -2.1466], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2327,  0.8227, -0.4652, -2.1466], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6765, -0.4343, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6765, -0.4343, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7773, -0.9150, -1.6779,  0.2949], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7773, -0.9150, -1.6779,  0.2949], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6512, -0.7235, -0.9326,  0.2867], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6512, -0.7235, -0.9326,  0.2867], grad_fn=<TanhBackward0>),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6881,  0.8217, -1.8011, -0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6881,  0.8217, -1.8011, -0.9308], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1691, -1.0419, -0.8277, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1691, -1.0419, -0.8277, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7449, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7449, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>),), Output: tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6434,  1.1572, -0.5781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6434,  1.1572, -0.5781], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3204, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3204, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2862, -0.5844,  0.9266, -1.1136], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2862, -0.5844,  0.9266, -1.1136], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5258,  0.7290, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5258,  0.7290, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2328,  0.8205, -0.4622, -2.1471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2328,  0.8205, -0.4622, -2.1471], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7796, -0.9154, -1.6752,  0.2978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7796, -0.9154, -1.6752,  0.2978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6525, -0.7237, -0.9322,  0.2893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6525, -0.7237, -0.9322,  0.2893], grad_fn=<TanhBackward0>),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6877,  0.8221, -1.8012, -0.9314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6877,  0.8221, -1.8012, -0.9314], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1694, -1.0418, -0.8297, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1694, -1.0418, -0.8297, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7445, -1.6341, -0.6735, -1.8687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7445, -1.6341, -0.6735, -1.8687], grad_fn=<ViewBackward0>),), Output: tensor([-0.6319, -0.9266, -0.5873, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6319, -0.9266, -0.5873, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3150, -0.6421,  1.1575, -0.5786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3150, -0.6421,  1.1575, -0.5786], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5663,  0.8202, -0.5216], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5663,  0.8202, -0.5216], grad_fn=<TanhBackward0>),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3196, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3196, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5829,  0.9282, -1.1140], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5829,  0.9282, -1.1140], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5247,  0.7298, -0.8055], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5247,  0.7298, -0.8055], grad_fn=<TanhBackward0>),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2330,  0.8183, -0.4593, -2.1476], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2330,  0.8183, -0.4593, -2.1476], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6742, -0.4295, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6742, -0.4295, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7818, -0.9159, -1.6725,  0.3006], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7818, -0.9159, -1.6725,  0.3006], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6537, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6537, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1697, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1697, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7441, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7441, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>),), Output: tensor([-0.6316, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6316, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3148, -0.6409,  1.1577, -0.5791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3148, -0.6409,  1.1577, -0.5791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3188, -1.2236, -2.8331, -4.2088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3188, -1.2236, -2.8331, -4.2088], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2331,  0.8162, -0.4565, -2.1480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2331,  0.8162, -0.4565, -2.1480], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6730, -0.4272, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6730, -0.4272, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7839, -0.9163, -1.6699,  0.3033], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7839, -0.9163, -1.6699,  0.3033], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6550, -0.7241, -0.9315,  0.2943], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6550, -0.7241, -0.9315,  0.2943], grad_fn=<TanhBackward0>),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6870,  0.8227, -1.8014, -0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6870,  0.8227, -1.8014, -0.9327], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1700, -1.0416, -0.8336, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1700, -1.0416, -0.8336, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8243, -0.7785, -0.6824, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8243, -0.7785, -0.6824, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7437, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7437, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6396,  1.1580, -0.5796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6396,  1.1580, -0.5796], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5646,  0.8204, -0.5224], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5646,  0.8204, -0.5224], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3181, -1.2281, -2.8346, -4.2098], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3181, -1.2281, -2.8346, -4.2098], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5226,  0.7313, -0.8058], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5226,  0.7313, -0.8058], grad_fn=<TanhBackward0>),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2333,  0.8141, -0.4537, -2.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2333,  0.8141, -0.4537, -2.1485], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6718, -0.4249, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6718, -0.4249, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7860, -0.9166, -1.6673,  0.3059], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7860, -0.9166, -1.6673,  0.3059], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6561, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6561, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6867,  0.8230, -1.8016, -0.9333], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6867,  0.8230, -1.8016, -0.9333], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1703, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1703, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8244, -0.7784, -0.6834, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8244, -0.7784, -0.6834, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7433, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7433, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>),), Output: tensor([-0.6311, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6311, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3173, -1.2325, -2.8361, -4.2108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3173, -1.2325, -2.8361, -4.2108], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5216,  0.7321, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5216,  0.7321, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2334,  0.8120, -0.4510, -2.1489], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2334,  0.8120, -0.4510, -2.1489], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6707, -0.4227, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6707, -0.4227, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7880, -0.9170, -1.6647,  0.3085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7880, -0.9170, -1.6647,  0.3085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6573, -0.7245, -0.9308,  0.2991], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6573, -0.7245, -0.9308,  0.2991], grad_fn=<TanhBackward0>),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6864,  0.8232, -1.8017, -0.9339], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6864,  0.8232, -1.8017, -0.9339], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1706, -1.0413, -0.8371, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1706, -1.0413, -0.8371, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>),), Output: tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3141, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3141, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3165, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3165, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5772,  0.9348, -1.1157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5772,  0.9348, -1.1157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5206,  0.7328, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5206,  0.7328, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2336,  0.8100, -0.4484, -2.1494], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2336,  0.8100, -0.4484, -2.1494], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6696, -0.4206, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6696, -0.4206, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7900, -0.9174, -1.6622,  0.3110], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7900, -0.9174, -1.6622,  0.3110], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6861,  0.8235, -1.8018, -0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6861,  0.8235, -1.8018, -0.9345], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>),), Output: tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3157, -1.2412, -2.8391, -4.2126], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3157, -1.2412, -2.8391, -4.2126], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2337,  0.8080, -0.4459, -2.1498], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2337,  0.8080, -0.4459, -2.1498], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6685, -0.4185, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6685, -0.4185, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7919, -0.9177, -1.6597,  0.3134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7919, -0.9177, -1.6597,  0.3134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6857,  0.8237, -1.8020, -0.9351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6857,  0.8237, -1.8020, -0.9351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7330], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7330], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1711, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1711, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7782, -0.6860, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7782, -0.6860, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3136, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3136, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8652, -0.5613,  0.8207, -0.5240], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8652, -0.5613,  0.8207, -0.5240], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2339,  0.8060, -0.4434, -2.1502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2339,  0.8060, -0.4434, -2.1502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6674, -0.4165, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6674, -0.4165, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7937, -0.9180, -1.6572,  0.3158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7937, -0.9180, -1.6572,  0.3158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6605, -0.7250, -0.9298,  0.3057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6605, -0.7250, -0.9298,  0.3057], grad_fn=<TanhBackward0>),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6854,  0.8238, -1.8021, -0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6854,  0.8238, -1.8021, -0.9356], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1714, -1.0407, -0.8418, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1714, -1.0407, -0.8418, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7417, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7417, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>),), Output: tensor([-0.6302, -0.9290, -0.5901, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6302, -0.9290, -0.5901, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3134, -0.6336,  1.1592, -0.5825], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3134, -0.6336,  1.1592, -0.5825], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5605,  0.8208, -0.5245], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5605,  0.8208, -0.5245], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3142, -1.2497, -2.8421, -4.2143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3142, -1.2497, -2.8421, -4.2143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2341,  0.8040, -0.4410, -2.1506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2341,  0.8040, -0.4410, -2.1506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6663, -0.4145, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6663, -0.4145, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7955, -0.9183, -1.6548,  0.3180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7955, -0.9183, -1.6548,  0.3180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6851,  0.8240, -1.8023, -0.9362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6851,  0.8240, -1.8023, -0.9362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1716, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1716, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7413, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7413, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>),), Output: tensor([-0.6299, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6299, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5598,  0.8208, -0.5249], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5598,  0.8208, -0.5249], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3135, -1.2538, -2.8437, -4.2152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3135, -1.2538, -2.8437, -4.2152], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5721,  0.9411, -1.1175], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5721,  0.9411, -1.1175], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5169,  0.7358, -0.8067], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5169,  0.7358, -0.8067], grad_fn=<TanhBackward0>),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2342,  0.8021, -0.4387, -2.1510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2342,  0.8021, -0.4387, -2.1510], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6652, -0.4126, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6652, -0.4126, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7973, -0.9186, -1.6524,  0.3203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7973, -0.9186, -1.6524,  0.3203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6848,  0.8241, -1.8025, -0.9367], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6848,  0.8241, -1.8025, -0.9367], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1719, -1.0404, -0.8445, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1719, -1.0404, -0.8445, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8249, -0.7780, -0.6882, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8249, -0.7780, -0.6882, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7409, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7409, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3128, -0.6313,  1.1596, -0.5837], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3128, -0.6313,  1.1596, -0.5837], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3127, -1.2579, -2.8452, -4.2160], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3127, -1.2579, -2.8452, -4.2160], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2855, -0.5708,  0.9427, -1.1180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2855, -0.5708,  0.9427, -1.1180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2344,  0.8001, -0.4365, -2.1514], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2344,  0.8001, -0.4365, -2.1514], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6641, -0.4107, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6641, -0.4107, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7989, -0.9189, -1.6501,  0.3224], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7989, -0.9189, -1.6501,  0.3224], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6634, -0.7254, -0.9289,  0.3117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6634, -0.7254, -0.9289,  0.3117], grad_fn=<TanhBackward0>),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6845,  0.8242, -1.8026, -0.9372], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6845,  0.8242, -1.8026, -0.9372], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6773, -0.9471, -0.7339], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6773, -0.9471, -0.7339], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1721, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1721, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7405, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7405, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>),), Output: tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6302,  1.1598, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6302,  1.1598, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5582,  0.8210, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5582,  0.8210, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3120, -1.2619, -2.8468, -4.2168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3120, -1.2619, -2.8468, -4.2168], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2854, -0.5696,  0.9443, -1.1185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2854, -0.5696,  0.9443, -1.1185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2345,  0.7983, -0.4343, -2.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2345,  0.7983, -0.4343, -2.1517], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6631, -0.4089, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6631, -0.4089, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8006, -0.9192, -1.6478,  0.3245], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8006, -0.9192, -1.6478,  0.3245], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6644, -0.7255, -0.9285,  0.3136], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6644, -0.7255, -0.9285,  0.3136], grad_fn=<TanhBackward0>),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6843,  0.8243, -1.8028, -0.9377], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6843,  0.8243, -1.8028, -0.9377], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1723, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1723, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7401, -1.6598, -0.6805, -1.8731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7401, -1.6598, -0.6805, -1.8731], grad_fn=<ViewBackward0>),), Output: tensor([-0.6292, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6292, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3122, -0.6291,  1.1600, -0.5850], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3122, -0.6291,  1.1600, -0.5850], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5574,  0.8210, -0.5263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5574,  0.8210, -0.5263], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3113, -1.2659, -2.8484, -4.2176], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3113, -1.2659, -2.8484, -4.2176], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5142,  0.7379, -0.8072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5142,  0.7379, -0.8072], grad_fn=<TanhBackward0>),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2347,  0.7964, -0.4321, -2.1521], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2347,  0.7964, -0.4321, -2.1521], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6620, -0.4071, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6620, -0.4071, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8021, -0.9194, -1.6455,  0.3265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8021, -0.9194, -1.6455,  0.3265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6652, -0.7256, -0.9282,  0.3154], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6652, -0.7256, -0.9282,  0.3154], grad_fn=<TanhBackward0>),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1726, -1.0397, -0.8480, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1726, -1.0397, -0.8480, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7398, -1.6620, -0.6812, -1.8734], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7398, -1.6620, -0.6812, -1.8734], grad_fn=<ViewBackward0>),), Output: tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6280,  1.1601, -0.5857], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6280,  1.1601, -0.5857], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3105, -1.2698, -2.8500, -4.2184], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3105, -1.2698, -2.8500, -4.2184], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2349,  0.7946, -0.4301, -2.1525], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2349,  0.7946, -0.4301, -2.1525], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6610, -0.4054, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6610, -0.4054, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8037, -0.9197, -1.6433,  0.3285], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8037, -0.9197, -1.6433,  0.3285], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6661, -0.7257, -0.9279,  0.3172], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6661, -0.7257, -0.9279,  0.3172], grad_fn=<TanhBackward0>),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6837,  0.8244, -1.8032, -0.9387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6837,  0.8244, -1.8032, -0.9387], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1728, -1.0395, -0.8491, -1.0667], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1728, -1.0395, -0.8491, -1.0667], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7394, -1.6640, -0.6820, -1.8738], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7394, -1.6640, -0.6820, -1.8738], grad_fn=<ViewBackward0>),), Output: tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3116, -0.6269,  1.1603, -0.5864], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3116, -0.6269,  1.1603, -0.5864], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5559,  0.8211, -0.5273], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5559,  0.8211, -0.5273], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3098, -1.2736, -2.8516, -4.2192], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3098, -1.2736, -2.8516, -4.2192], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5125,  0.7392, -0.8075], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5125,  0.7392, -0.8075], grad_fn=<TanhBackward0>),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2350,  0.7928, -0.4281, -2.1528], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2350,  0.7928, -0.4281, -2.1528], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6600, -0.4037, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6600, -0.4037, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8052, -0.9199, -1.6411,  0.3304], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8052, -0.9199, -1.6411,  0.3304], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6669, -0.7259, -0.9276,  0.3189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6669, -0.7259, -0.9276,  0.3189], grad_fn=<TanhBackward0>),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6834,  0.8244, -1.8034, -0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6834,  0.8244, -1.8034, -0.9391], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1730, -1.0393, -0.8501, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1730, -1.0393, -0.8501, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7390, -1.6661, -0.6827, -1.8741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7390, -1.6661, -0.6827, -1.8741], grad_fn=<ViewBackward0>),), Output: tensor([-0.6285, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6285, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3112, -0.6258,  1.1605, -0.5871], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3112, -0.6258,  1.1605, -0.5871], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3091, -1.2774, -2.8532, -4.2199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3091, -1.2774, -2.8532, -4.2199], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5651,  0.9503, -1.1203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5651,  0.9503, -1.1203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5117,  0.7399, -0.8077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5117,  0.7399, -0.8077], grad_fn=<TanhBackward0>),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2352,  0.7910, -0.4262, -2.1532], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2352,  0.7910, -0.4262, -2.1532], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6590, -0.4021, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6590, -0.4021, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8066, -0.9201, -1.6390,  0.3323], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8066, -0.9201, -1.6390,  0.3323], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6677, -0.7260, -0.9273,  0.3206], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6677, -0.7260, -0.9273,  0.3206], grad_fn=<TanhBackward0>),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6832,  0.8244, -1.8035, -0.9396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6832,  0.8244, -1.8035, -0.9396], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6775, -0.9472, -0.7350], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6775, -0.9472, -0.7350], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7386, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7386, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>),), Output: tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8645, -0.5544,  0.8212, -0.5283], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8645, -0.5544,  0.8212, -0.5283], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3084, -1.2812, -2.8548, -4.2207], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3084, -1.2812, -2.8548, -4.2207], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2354,  0.7893, -0.4243, -2.1535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2354,  0.7893, -0.4243, -2.1535], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6580, -0.4005, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6580, -0.4005, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8080, -0.9203, -1.6369,  0.3341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8080, -0.9203, -1.6369,  0.3341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6685, -0.7261, -0.9270,  0.3222], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6685, -0.7261, -0.9270,  0.3222], grad_fn=<TanhBackward0>),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6829,  0.8244, -1.8037, -0.9400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6829,  0.8244, -1.8037, -0.9400], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6775, -0.9472, -0.7352], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6775, -0.9472, -0.7352], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1734, -1.0388, -0.8520, -1.0671], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1734, -1.0388, -0.8520, -1.0671], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3106, -0.6237,  1.1608, -0.5885], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3106, -0.6237,  1.1608, -0.5885], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5537,  0.8213, -0.5288], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5537,  0.8213, -0.5288], grad_fn=<TanhBackward0>),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3077, -1.2849, -2.8565, -4.2214], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3077, -1.2849, -2.8565, -4.2214], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5101,  0.7413, -0.8080], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5101,  0.7413, -0.8080], grad_fn=<TanhBackward0>),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2356,  0.7876, -0.4225, -2.1538], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2356,  0.7876, -0.4225, -2.1538], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6570, -0.3990, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6570, -0.3990, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8093, -0.9205, -1.6348,  0.3358], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8093, -0.9205, -1.6348,  0.3358], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6692, -0.7262, -0.9267,  0.3237], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6692, -0.7262, -0.9267,  0.3237], grad_fn=<TanhBackward0>),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6827,  0.8244, -1.8039, -0.9404], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6827,  0.8244, -1.8039, -0.9404], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1736, -1.0386, -0.8529, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1736, -1.0386, -0.8529, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8254, -0.7773, -0.6926, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8254, -0.7773, -0.6926, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>),), Output: tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3102, -0.6227,  1.1609, -0.5892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3102, -0.6227,  1.1609, -0.5892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8643, -0.5530,  0.8213, -0.5293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8643, -0.5530,  0.8213, -0.5293], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3070, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3070, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5618,  0.9547, -1.1218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5618,  0.9547, -1.1218], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5093,  0.7419, -0.8082], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5093,  0.7419, -0.8082], grad_fn=<TanhBackward0>),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2357,  0.7859, -0.4207, -2.1542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2357,  0.7859, -0.4207, -2.1542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6561, -0.3975, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6561, -0.3975, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8107, -0.9207, -1.6328,  0.3375], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8107, -0.9207, -1.6328,  0.3375], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6700, -0.7262, -0.9265,  0.3252], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6700, -0.7262, -0.9265,  0.3252], grad_fn=<TanhBackward0>),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6824,  0.8243, -1.8041, -0.9409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6824,  0.8243, -1.8041, -0.9409], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1737, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1737, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7772, -0.6930, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7772, -0.6930, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>),), Output: tensor([-0.6276, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6276, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3099, -0.6216,  1.1610, -0.5900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3099, -0.6216,  1.1610, -0.5900], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3063, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3063, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2359,  0.7842, -0.4190, -2.1545], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2359,  0.7842, -0.4190, -2.1545], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6551, -0.3961, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6551, -0.3961, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8119, -0.9209, -1.6308,  0.3391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8119, -0.9209, -1.6308,  0.3391], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6707, -0.7263, -0.9262,  0.3267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6707, -0.7263, -0.9262,  0.3267], grad_fn=<TanhBackward0>),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1739, -1.0381, -0.8545, -1.0675], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1739, -1.0381, -0.8545, -1.0675], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7771, -0.6934, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7771, -0.6934, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7371, -1.6759, -0.6866, -1.8758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7371, -1.6759, -0.6866, -1.8758], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3095, -0.6206,  1.1611, -0.5907], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3095, -0.6206,  1.1611, -0.5907], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2848, -0.5598,  0.9576, -1.1227], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2848, -0.5598,  0.9576, -1.1227], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2361,  0.7826, -0.4173, -2.1548], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2361,  0.7826, -0.4173, -2.1548], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6542, -0.3947, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6542, -0.3947, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8132, -0.9211, -1.6289,  0.3407], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8132, -0.9211, -1.6289,  0.3407], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6819,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6819,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7360], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7770, -0.6938, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7770, -0.6938, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>),), Output: tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3092, -0.6196,  1.1613, -0.5914], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3092, -0.6196,  1.1613, -0.5914], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8641, -0.5509,  0.8215, -0.5309], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8641, -0.5509,  0.8215, -0.5309], grad_fn=<TanhBackward0>),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3050, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3050, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2362,  0.7810, -0.4157, -2.1551], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2362,  0.7810, -0.4157, -2.1551], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6533, -0.3933, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6533, -0.3933, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8144, -0.9212, -1.6270,  0.3423], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8144, -0.9212, -1.6270,  0.3423], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6720, -0.7265, -0.9256,  0.3295], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6720, -0.7265, -0.9256,  0.3295], grad_fn=<TanhBackward0>),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6817,  0.8242, -1.8048, -0.9421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6817,  0.8242, -1.8048, -0.9421], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1743, -1.0376, -0.8559, -1.0678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1743, -1.0376, -0.8559, -1.0678], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7769, -0.6941, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7769, -0.6941, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7364, -1.6796, -0.6881, -1.8764], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7364, -1.6796, -0.6881, -1.8764], grad_fn=<ViewBackward0>),), Output: tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3088, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3088, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3043, -1.3027, -2.8647, -4.2249], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3043, -1.3027, -2.8647, -4.2249], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5063,  0.7445, -0.8089], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5063,  0.7445, -0.8089], grad_fn=<TanhBackward0>),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2364,  0.7794, -0.4142, -2.1554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2364,  0.7794, -0.4142, -2.1554], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6523, -0.3920, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6523, -0.3920, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8155, -0.9213, -1.6251,  0.3438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8155, -0.9213, -1.6251,  0.3438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6726, -0.7265, -0.9254,  0.3308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6726, -0.7265, -0.9254,  0.3308], grad_fn=<TanhBackward0>),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6814,  0.8241, -1.8050, -0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6814,  0.8241, -1.8050, -0.9424], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6773, -0.9473, -0.7363], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6773, -0.9473, -0.7363], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1744, -1.0374, -0.8566, -1.0680], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1744, -1.0374, -0.8566, -1.0680], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7768, -0.6945, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7768, -0.6945, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.6814, -0.6889, -1.8767], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.6814, -0.6889, -1.8767], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3037, -1.3062, -2.8663, -4.2256], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3037, -1.3062, -2.8663, -4.2256], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5568,  0.9618, -1.1242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5568,  0.9618, -1.1242], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2366,  0.7778, -0.4126, -2.1557], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2366,  0.7778, -0.4126, -2.1557], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6514, -0.3907, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6514, -0.3907, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8166, -0.9215, -1.6233,  0.3452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8166, -0.9215, -1.6233,  0.3452], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6812,  0.8240, -1.8052, -0.9428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6812,  0.8240, -1.8052, -0.9428], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1746, -1.0371, -0.8572, -1.0682], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1746, -1.0371, -0.8572, -1.0682], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7767, -0.6948, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7767, -0.6948, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7357, -1.6832, -0.6897, -1.8770], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7357, -1.6832, -0.6897, -1.8770], grad_fn=<ViewBackward0>),), Output: tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.6166,  1.1616, -0.5937], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.6166,  1.1616, -0.5937], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3030, -1.3096, -2.8680, -4.2263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3030, -1.3096, -2.8680, -4.2263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2367,  0.7763, -0.4112, -2.1560], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2367,  0.7763, -0.4112, -2.1560], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6506, -0.3895, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6506, -0.3895, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8177, -0.9216, -1.6215,  0.3466], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8177, -0.9216, -1.6215,  0.3466], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6738, -0.7267, -0.9248,  0.3334], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6738, -0.7267, -0.9248,  0.3334], grad_fn=<TanhBackward0>),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1747, -1.0368, -0.8578, -1.0683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1747, -1.0368, -0.8578, -1.0683], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7766, -0.6951, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7766, -0.6951, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7353, -1.6850, -0.6905, -1.8773], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7353, -1.6850, -0.6905, -1.8773], grad_fn=<ViewBackward0>),), Output: tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3077, -0.6156,  1.1617, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3077, -0.6156,  1.1617, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3024, -1.3129, -2.8696, -4.2269], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3024, -1.3129, -2.8696, -4.2269], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2369,  0.7747, -0.4098, -2.1563], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2369,  0.7747, -0.4098, -2.1563], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6497, -0.3883, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6497, -0.3883, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8188, -0.9217, -1.6197,  0.3480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8188, -0.9217, -1.6197,  0.3480], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6744, -0.7267, -0.9246,  0.3346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6744, -0.7267, -0.9246,  0.3346], grad_fn=<TanhBackward0>),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6808,  0.8238, -1.8057, -0.9435], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6808,  0.8238, -1.8057, -0.9435], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6771, -0.9474, -0.7368], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6771, -0.9474, -0.7368], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7350, -1.6867, -0.6913, -1.8776], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7350, -1.6867, -0.6913, -1.8776], grad_fn=<ViewBackward0>),), Output: tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3073, -0.6147,  1.1618, -0.5952], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3073, -0.6147,  1.1618, -0.5952], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3017, -1.3162, -2.8713, -4.2275], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3017, -1.3162, -2.8713, -4.2275], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2371,  0.7732, -0.4084, -2.1565], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2371,  0.7732, -0.4084, -2.1565], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6488, -0.3871, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6488, -0.3871, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8198, -0.9218, -1.6180,  0.3493], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8198, -0.9218, -1.6180,  0.3493], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6750, -0.7268, -0.9243,  0.3358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6750, -0.7268, -0.9243,  0.3358], grad_fn=<TanhBackward0>),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6805,  0.8237, -1.8059, -0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6805,  0.8237, -1.8059, -0.9439], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1750, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1750, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7764, -0.6957, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7764, -0.6957, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7346, -1.6884, -0.6922, -1.8779], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7346, -1.6884, -0.6922, -1.8779], grad_fn=<ViewBackward0>),), Output: tensor([-0.6259, -0.9339, -0.5994, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6259, -0.9339, -0.5994, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3070, -0.6137,  1.1618, -0.5960], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3070, -0.6137,  1.1618, -0.5960], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.5467,  0.8216, -0.5342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.5467,  0.8216, -0.5342], grad_fn=<TanhBackward0>),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5531,  0.9673, -1.1261], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5531,  0.9673, -1.1261], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2372,  0.7718, -0.4070, -2.1568], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2372,  0.7718, -0.4070, -2.1568], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6480, -0.3859, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6480, -0.3859, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8208, -0.9219, -1.6163,  0.3506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8208, -0.9219, -1.6163,  0.3506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6755, -0.7268, -0.9241,  0.3369], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6755, -0.7268, -0.9241,  0.3369], grad_fn=<TanhBackward0>),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6803,  0.8236, -1.8061, -0.9442], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6803,  0.8236, -1.8061, -0.9442], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1752, -1.0360, -0.8593, -1.0688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1752, -1.0360, -0.8593, -1.0688], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7343, -1.6901, -0.6930, -1.8782], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7343, -1.6901, -0.6930, -1.8782], grad_fn=<ViewBackward0>),), Output: tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3066, -0.6127,  1.1619, -0.5968], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3066, -0.6127,  1.1619, -0.5968], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3004, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3004, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5021,  0.7481, -0.8099], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5021,  0.7481, -0.8099], grad_fn=<TanhBackward0>),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2374,  0.7703, -0.4057, -2.1571], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2374,  0.7703, -0.4057, -2.1571], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6471, -0.3848, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6471, -0.3848, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8218, -0.9220, -1.6147,  0.3518], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8218, -0.9220, -1.6147,  0.3518], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6760, -0.7268, -0.9238,  0.3380], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6760, -0.7268, -0.9238,  0.3380], grad_fn=<TanhBackward0>),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1753, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1753, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7762, -0.6962, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7762, -0.6962, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3062, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3062, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2998, -1.3259, -2.8762, -4.2294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2998, -1.3259, -2.8762, -4.2294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2376,  0.7689, -0.4045, -2.1574], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2376,  0.7689, -0.4045, -2.1574], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6463, -0.3838, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6463, -0.3838, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8227, -0.9221, -1.6131,  0.3530], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8227, -0.9221, -1.6131,  0.3530], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6765, -0.7269, -0.9236,  0.3391], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6765, -0.7269, -0.9236,  0.3391], grad_fn=<TanhBackward0>),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6799,  0.8233, -1.8066, -0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6799,  0.8233, -1.8066, -0.9449], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6769, -0.9475, -0.7375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6769, -0.9475, -0.7375], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7761, -0.6964, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7761, -0.6964, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>),), Output: tensor([-0.6252, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6252, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3058, -0.6109,  1.1621, -0.5983], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3058, -0.6109,  1.1621, -0.5983], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8632, -0.5447,  0.8217, -0.5359], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8632, -0.5447,  0.8217, -0.5359], grad_fn=<TanhBackward0>),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2992, -1.3290, -2.8779, -4.2300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2992, -1.3290, -2.8779, -4.2300], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2378,  0.7675, -0.4032, -2.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2378,  0.7675, -0.4032, -2.1576], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6455, -0.3827, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6455, -0.3827, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8236, -0.9221, -1.6115,  0.3542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8236, -0.9221, -1.6115,  0.3542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6770, -0.7269, -0.9234,  0.3401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6770, -0.7269, -0.9234,  0.3401], grad_fn=<TanhBackward0>),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6797,  0.8232, -1.8068, -0.9452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6797,  0.8232, -1.8068, -0.9452], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1756, -1.0352, -0.8607, -1.0693], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1756, -1.0352, -0.8607, -1.0693], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7332, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7332, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>),), Output: tensor([-0.6250, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6250, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3055, -0.6099,  1.1621, -0.5991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3055, -0.6099,  1.1621, -0.5991], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2986, -1.3321, -2.8795, -4.2306], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2986, -1.3321, -2.8795, -4.2306], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5495,  0.9725, -1.1281], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5495,  0.9725, -1.1281], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2379,  0.7661, -0.4020, -2.1579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2379,  0.7661, -0.4020, -2.1579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6446, -0.3817, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6446, -0.3817, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8245, -0.9222, -1.6099,  0.3553], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8245, -0.9222, -1.6099,  0.3553], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6775, -0.7269, -0.9231,  0.3411], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6775, -0.7269, -0.9231,  0.3411], grad_fn=<TanhBackward0>),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1757, -1.0349, -0.8610, -1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1757, -1.0349, -0.8610, -1.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>),), Output: tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3051, -0.6090,  1.1622, -0.5999], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3051, -0.6090,  1.1622, -0.5999], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.5434,  0.8218, -0.5370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.5434,  0.8218, -0.5370], grad_fn=<TanhBackward0>),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2979, -1.3352, -2.8812, -4.2312], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2979, -1.3352, -2.8812, -4.2312], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4995,  0.7504, -0.8105], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4995,  0.7504, -0.8105], grad_fn=<TanhBackward0>),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2381,  0.7647, -0.4009, -2.1581], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2381,  0.7647, -0.4009, -2.1581], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6438, -0.3807, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6438, -0.3807, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8253, -0.9222, -1.6084,  0.3564], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8253, -0.9222, -1.6084,  0.3564], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6780, -0.7270, -0.9229,  0.3421], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6780, -0.7270, -0.9229,  0.3421], grad_fn=<TanhBackward0>),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6793,  0.8229, -1.8073, -0.9459], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6793,  0.8229, -1.8073, -0.9459], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7325, -1.6983, -0.6971, -1.8796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7325, -1.6983, -0.6971, -1.8796], grad_fn=<ViewBackward0>),), Output: tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2973, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2973, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8712, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8712, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5478,  0.9750, -1.1290], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5478,  0.9750, -1.1290], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2383,  0.7634, -0.3998, -2.1584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2383,  0.7634, -0.3998, -2.1584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6430, -0.3797, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6430, -0.3797, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8261, -0.9223, -1.6069,  0.3575], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8261, -0.9223, -1.6069,  0.3575], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1760, -1.0344, -0.8618, -1.0699], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1760, -1.0344, -0.8618, -1.0699], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7757, -0.6972, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7757, -0.6972, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>),), Output: tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3043, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3043, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.5421,  0.8218, -0.5381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.5421,  0.8218, -0.5381], grad_fn=<TanhBackward0>),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2967, -1.3412, -2.8844, -4.2323], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2967, -1.3412, -2.8844, -4.2323], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2384,  0.7620, -0.3987, -2.1586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2384,  0.7620, -0.3987, -2.1586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6423, -0.3788, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6423, -0.3788, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8270, -0.9223, -1.6054,  0.3585], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8270, -0.9223, -1.6054,  0.3585], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1761, -1.0341, -0.8621, -1.0701], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761, -1.0341, -0.8621, -1.0701], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7755, -0.6973, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7755, -0.6973, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7319, -1.7013, -0.6987, -1.8802], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7319, -1.7013, -0.6987, -1.8802], grad_fn=<ViewBackward0>),), Output: tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.6063,  1.1624, -0.6022], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.6063,  1.1624, -0.6022], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.5415,  0.8218, -0.5386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.5415,  0.8218, -0.5386], grad_fn=<TanhBackward0>),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2961, -1.3442, -2.8861, -4.2329], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2961, -1.3442, -2.8861, -4.2329], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2386,  0.7607, -0.3976, -2.1589], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2386,  0.7607, -0.3976, -2.1589], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6415, -0.3779, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6415, -0.3779, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8277, -0.9224, -1.6040,  0.3596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8277, -0.9224, -1.6040,  0.3596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6793, -0.7270, -0.9223,  0.3448], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6793, -0.7270, -0.9223,  0.3448], grad_fn=<TanhBackward0>),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6787,  0.8224, -1.8080, -0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6787,  0.8224, -1.8080, -0.9468], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7383], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7315, -1.7029, -0.6995, -1.8804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7315, -1.7029, -0.6995, -1.8804], grad_fn=<ViewBackward0>),), Output: tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2955, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2955, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4970,  0.7525, -0.8112], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4970,  0.7525, -0.8112], grad_fn=<TanhBackward0>),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2388,  0.7594, -0.3966, -2.1591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2388,  0.7594, -0.3966, -2.1591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6407, -0.3770, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6407, -0.3770, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8285, -0.9224, -1.6026,  0.3605], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8285, -0.9224, -1.6026,  0.3605], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6797, -0.7270, -0.9221,  0.3457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6797, -0.7270, -0.9221,  0.3457], grad_fn=<TanhBackward0>),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6763, -0.9477, -0.7385], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6763, -0.9477, -0.7385], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1764, -1.0335, -0.8627, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1764, -1.0335, -0.8627, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>),), Output: tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3032, -0.6045,  1.1624, -0.6038], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3032, -0.6045,  1.1624, -0.6038], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8625, -0.5402,  0.8218, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8625, -0.5402,  0.8218, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2949, -1.3500, -2.8893, -4.2340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2949, -1.3500, -2.8893, -4.2340], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4964,  0.7531, -0.8114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4964,  0.7531, -0.8114], grad_fn=<TanhBackward0>),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2389,  0.7581, -0.3956, -2.1594], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2389,  0.7581, -0.3956, -2.1594], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6400, -0.3762, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6400, -0.3762, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8292, -0.9224, -1.6012,  0.3615], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8292, -0.9224, -1.6012,  0.3615], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6801, -0.7270, -0.9218,  0.3465], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6801, -0.7270, -0.9218,  0.3465], grad_fn=<TanhBackward0>),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1765, -1.0332, -0.8629, -1.0706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1765, -1.0332, -0.8629, -1.0706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7752, -0.6978, -0.7897], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7752, -0.6978, -0.7897], grad_fn=<TanhBackward0>),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7309, -1.7058, -0.7012, -1.8810], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7309, -1.7058, -0.7012, -1.8810], grad_fn=<ViewBackward0>),), Output: tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3028, -0.6036,  1.1625, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3028, -0.6036,  1.1625, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.5396,  0.8218, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.5396,  0.8218, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2943, -1.3529, -2.8910, -4.2345], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2943, -1.3529, -2.8910, -4.2345], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5438,  0.9812, -1.1314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5438,  0.9812, -1.1314], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2391,  0.7569, -0.3946, -2.1596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2391,  0.7569, -0.3946, -2.1596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6392, -0.3753, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6392, -0.3753, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8299, -0.9224, -1.5998,  0.3624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8299, -0.9224, -1.5998,  0.3624], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6804, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6804, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6781,  0.8218, -1.8087, -0.9477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6781,  0.8218, -1.8087, -0.9477], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1766, -1.0329, -0.8632, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1766, -1.0329, -0.8632, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7305, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7305, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>),), Output: tensor([-0.6234, -0.9363, -0.6057, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6234, -0.9363, -0.6057, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8623, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8623, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9798, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9798, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2393,  0.7556, -0.3937, -2.1598], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2393,  0.7556, -0.3937, -2.1598], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6385, -0.3745, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6385, -0.3745, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8306, -0.9224, -1.5985,  0.3633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8306, -0.9224, -1.5985,  0.3633], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6808, -0.7270, -0.9214,  0.3481], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6808, -0.7270, -0.9214,  0.3481], grad_fn=<TanhBackward0>),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6779,  0.8217, -1.8090, -0.9479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6779,  0.8217, -1.8090, -0.9479], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6760, -0.9477, -0.7388], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6760, -0.9477, -0.7388], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1767, -1.0326, -0.8634, -1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1767, -1.0326, -0.8634, -1.0710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7302, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7302, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3020, -0.6019,  1.1625, -0.6061], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3020, -0.6019,  1.1625, -0.6061], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8622, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8622, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Run model training for multiple epochs with PyTorch model\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "# with torch.no_grad():\n",
    "#     for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "#         param_tmlp.copy_(param_mlp)\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "loss_rmse_list = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_preds = [tmlp(torch.tensor(i)) for i in x]\n",
    "    y_true = [torch.tensor([y_i.data]) for y_i in y_true]\n",
    "    loss_rmse = rmse(y_true, y_preds)  # Calculate loss\n",
    "    loss_rmse_list.append(loss_rmse.item())\n",
    "    loss_rmse.backward()  # Perform backpropagation\n",
    "    optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3c92ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds_tmlp = [0.9358316659927368, -1.0214028358459473, -0.9719010591506958, 1.059489369392395]\n",
      "y_true = [tensor([1.]), tensor([-1.]), tensor([-1.]), tensor([1.])]\n"
     ]
    }
   ],
   "source": [
    "# Print prediction using PyTorch model\n",
    "print(f\"y_preds_tmlp = {[item.item() for item in y_preds]}\")\n",
    "print(f\"y_true = {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a83fc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_rmse_list = [1.5003691911697388, 0.9619162678718567, 0.7609615325927734, 0.655165433883667, 0.5759391188621521, 0.5016622543334961, 0.43051496148109436, 0.36708199977874756, 0.31330305337905884, 0.2682991623878479, 0.2305852323770523, 0.19882233440876007, 0.17192722856998444, 0.14904920756816864, 0.12952131032943726, 0.11281421035528183, 0.09849988669157028, 0.08622519671916962, 0.07569411396980286, 0.06665531545877457, 0.058893948793411255, 0.05222536623477936, 0.04649071767926216, 0.04155323654413223, 0.03729568049311638, 0.03361736610531807, 0.030432311818003654, 0.027667148038744926, 0.025259433314204216, 0.023156164214015007, 0.021312301978468895, 0.019689971581101418, 0.018256904557347298, 0.01698593981564045, 0.01585417240858078, 0.014842196367681026, 0.013933653943240643, 0.013114718720316887, 0.012373685836791992, 0.011700637638568878, 0.011087149381637573, 0.010526053607463837, 0.010011209174990654, 0.009537411853671074, 0.00910014659166336, 0.0086955726146698, 0.00832032784819603, 0.00797151681035757, 0.00764659745618701, 0.007343349978327751, 0.007059840019792318, 0.006794353015720844, 0.0065453508868813515, 0.0063115074299275875, 0.006091567687690258, 0.005884472280740738, 0.00568923307582736, 0.005504969507455826, 0.00533088855445385, 0.005166247952729464, 0.005010389722883701, 0.0048626987263560295, 0.00472262641415, 0.004589674063026905, 0.004463345743715763, 0.004343234933912754, 0.004228922072798014, 0.004120033700019121, 0.0040162717923521996, 0.003917261958122253, 0.0038227392360568047, 0.0037324270233511925, 0.003646071534603834, 0.0035634422674775124, 0.003484305925667286, 0.003408467397093773, 0.003335739718750119, 0.003265946637839079, 0.003198919352144003, 0.00313448254019022, 0.003072521183639765, 0.0030128881335258484, 0.002955453936010599, 0.002900109626352787, 0.002846744377166033, 0.0027952452655881643, 0.00274552870541811, 0.0026974882930517197, 0.0026510474272072315, 0.0026061353273689747, 0.0025626537390053272, 0.002520540729165077, 0.002479751594364643, 0.0024402074050158262, 0.0024018418043851852, 0.0023646228946745396, 0.0023284698836505413, 0.0022933539003133774, 0.0022592328023165464, 0.0022260479163378477]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "print(f\"loss_rmse_list = {loss_rmse_list}\")\n",
    "plt.plot(range(epochs), loss_rmse_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ec98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
