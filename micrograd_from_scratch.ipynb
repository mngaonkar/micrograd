{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "7b5e86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "from IPython import display\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "id": "d5629e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "id": "84ab2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for Jupyter Notebook to find the graphviz executables\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\"/opt/homebrew/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "4eba97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for gradient calculation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "3fbd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-10, 10, 0.5)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "08cde3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "71c90bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = -2\n",
    "c = 1\n",
    "d1 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "id": "4e7752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c + h\n",
    "d2 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "id": "c7b273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dc_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dc_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "id": "68d78e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -5.000002\n",
      "da_dy =  -2.000000000279556\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "a = a + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"da_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1272,
   "id": "49ed6158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.9999970000000005\n",
      "db_dy =  2.9999999995311555\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "b = b + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"db_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "c4f10ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dab_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "d2 = a*b + h + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dab_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "id": "e5c68b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    \"\"\" Basic class to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "        else:\n",
    "            raise ValueError(\"Can only add Value to Value\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "id": "077e5615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d._prev = (Value(data=-6), Value(data=1)) d = -5\n"
     ]
    }
   ],
   "source": [
    "a = Value(3, label=\"a\")\n",
    "b = Value(-2, label=\"b\")\n",
    "c = Value(1, label=\"c\")\n",
    "d = a*b + c; d.label = \"d\"\n",
    "print(f\"d._prev = {d._prev} d = {d.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "id": "db81115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(root):\n",
    "    \"\"\" Vibe codded and it works! \"\"\"\n",
    "    # Initialize a directed graph\n",
    "    dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})  # Left-to-right layout\n",
    "    \n",
    "    def build_graph(node, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        \n",
    "        # Skip if node already visited to avoid cycles\n",
    "        if id(node) in visited:\n",
    "            return\n",
    "        visited.add(id(node))\n",
    "        \n",
    "        # Add node to the graph\n",
    "        node_id = str(id(node))\n",
    "        dot.node(node_id, f\"{{ {node.label} | data = {node.data} grad={node.grad} }}\", shape='record')\n",
    "        \n",
    "        # If node has an operation, create an operation node\n",
    "        if node._op:\n",
    "            op_id = f\"{node_id}_op\"\n",
    "            dot.node(op_id, node._op, shape='circle')\n",
    "            dot.edge(op_id, node_id)  # Edge from operation to result\n",
    "        \n",
    "            # Recursively process children\n",
    "            for child in node._prev:\n",
    "                child_id = str(id(child))\n",
    "                build_graph(child, visited)\n",
    "                dot.edge(child_id, op_id)  # Edge from child to operation\n",
    "    \n",
    "    # Build the graph starting from the root\n",
    "    build_graph(root)\n",
    "    \n",
    "    # Render and display the graph\n",
    "    dot.render('computation_graph', view=True, cleanup=True)\n",
    "    \n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "id": "84c181f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "id": "98dd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "id": "68ed37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142981514304\n"
     ]
    }
   ],
   "source": [
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "id": "ec8210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "id": "70612029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "id": "daba22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "id": "922f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_dn = 1 - math.tanh(o.data)**2\n",
    "y.grad = do_dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "id": "72a71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "2a71919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1_x2w2.grad = y.grad\n",
    "b.grad = y.grad\n",
    "x1w1.grad = x1w1_x2w2.grad\n",
    "x2w2.grad = x1w1_x2w2.grad\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "ef9473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = x1w1.grad * w1.data\n",
    "x2.grad = x2w2.grad * w2.data\n",
    "w1.grad = x1w1.grad * x1.data\n",
    "w2.grad = x2w2.grad * x2.data\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1731,
   "id": "d7edad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement generic backpropagation\n",
    "class Value():\n",
    "    \"\"\" Complete class with backprop to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "\n",
    "    def backward(self, root_node, visited=None):\n",
    "        visited.add(self)\n",
    "        logger.debug(f\"node.data = {self.data}\")\n",
    "        self._backward()  # Compute the gradient for childeren of this node\n",
    "        for item in self._prev:\n",
    "            if item not in visited:\n",
    "                item.backward(root_node, visited)\n",
    "\n",
    "    def _backward(self):\n",
    "        \"\"\" Perform backpropagation to compute gradients. \"\"\"\n",
    "        logger.debug(f\"Backward pass for node: {self.label}, op: {self._op}, data: {self.data}, grad: {self.grad}\")\n",
    "        # For addition operation, local gradient is 1 for each child hence gradient of the child with respect\n",
    "        # to the output is 1 * self gradient.\n",
    "        # Note, we need to accumulate gradients for each child and not simply overwrite them.\n",
    "        if self._op == '+':\n",
    "            for child in self._prev:\n",
    "                child.grad += self.grad\n",
    "\n",
    "        # For multiplication operation, local gradient is the value of the other child hence\n",
    "        # gradient of the child with respect to the output is self.grad * other child's value.\n",
    "        elif self._op == '*':\n",
    "            self._prev[0].grad = self.grad * self._prev[1].data\n",
    "            self._prev[1].grad = self.grad * self._prev[0].data\n",
    "\n",
    "        elif self._op == '/':\n",
    "            # For division operation, local gradient is 1 / other child's value hence\n",
    "            # gradient of the child with respect to the output is self.grad * (1 / other child's value).\n",
    "            self._prev[0].grad = self.grad / self._prev[1].data\n",
    "            self._prev[1].grad = -self.grad * (self._prev[0].data / (self._prev[1].data ** 2))\n",
    "\n",
    "        # For power operation, local gradient is power * base^(power-1) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == '**':\n",
    "            base = self._prev[0].data\n",
    "            power = self._prev[1].data\n",
    "            self._prev[0].grad = self.grad * power * (base ** (power - 1))\n",
    "            print(f\"Power operation: base = {base}, power = {power}, grad = {self.grad}\")\n",
    "\n",
    "        # For subtraction operation, local gradient is 1 for the first child and -1 for the second child\n",
    "        # hence gradient of the first child with respect to the output is self.grad * 1 and for the second child\n",
    "        # it is self.grad * -1.\n",
    "        elif self._op == '-':\n",
    "            self._prev[0].grad = self.grad  # First child\n",
    "            self._prev[1].grad = -self.grad  # Second child\n",
    "\n",
    "        # For tanh operation, local gradient is 1 - tanh^2(self.data) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == 'tanh':\n",
    "            logger.debug(f\"tanh: self.data = {self.data}, self.grad = {self.grad}\")\n",
    "            self._prev[0].grad = self.grad * (1 - np.tanh(self._prev[0].data)**2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data - other.data, _children=(self, other), _op='-')\n",
    "        else:\n",
    "            raise ValueError(\"Can only subtract Value from Value\")\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "        \n",
    "    def __pow__(self, power):\n",
    "        return Value(self.data ** power, _children=(self,Value(power)), _op='**')\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "id": "de7dc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "id": "b1415a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1734,
   "id": "65eb5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0\n",
    "\n",
    "visited = set()\n",
    "o.backward(o, visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1735,
   "id": "b9b0f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1736,
   "id": "160da944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142868995667\n"
     ]
    }
   ],
   "source": [
    "# Verfiy with PyTorch\n",
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2.0])\n",
    "x2 = torch.Tensor([3.0])\n",
    "w1 = torch.Tensor([0.5])\n",
    "w2 = torch.Tensor([-1.5])\n",
    "b = torch.Tensor([1.0])\n",
    "x1.requires_grad = True\n",
    "x2.requires_grad = True\n",
    "w1.requires_grad = True\n",
    "w2.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "y = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(y)\n",
    "\n",
    "print(f\"o = {o.item()}\")\n",
    "\n",
    "o.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "id": "182b150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.grad = 0.013296124525368214\n",
      "x2.grad = -0.039888374507427216\n",
      "w1.grad = 0.053184498101472855\n",
      "w2.grad = 0.07977674901485443\n",
      "b.grad = 0.026592249050736427\n"
     ]
    }
   ],
   "source": [
    "print(f\"x1.grad = {x1.grad.item()}\") \n",
    "print(f\"x2.grad = {x2.grad.item()}\") \n",
    "print(f\"w1.grad = {w1.grad.item()}\")\n",
    "print(f\"w2.grad = {w2.grad.item()}\")\n",
    "print(f\"b.grad = {b.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "id": "f1702ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "class N():\n",
    "    \"\"\" Class to represent a single neuron with forward and backward pass. \"\"\"\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "        self.weights = [Value(random.uniform(-1, 1)) for _ in range(input_size)]\n",
    "        self.b = Value(random.uniform(-1, 1))  # Bias term\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.b]  # Return all parameters (weights and bias)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None) -> Value:\n",
    "        \"\"\" Forward pass for the neuron. \"\"\"\n",
    "        assert len(input) == self.input_size, f\"Input size {len(input)} does not match expected size {self.input_size}\"\n",
    "        wx = [w*x for w, x in zip(self.weights, input)]\n",
    "        wx_sum = Value(0.0)  # Initialize sum of weighted inputs\n",
    "        for item in wx:\n",
    "            wx_sum += item  # Sum the weighted inputs\n",
    "\n",
    "        wx_sum = wx_sum + self.b\n",
    "        if act_fn is None:\n",
    "            return wx_sum\n",
    "        elif act_fn == 'tanh':\n",
    "            return wx_sum.tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {act_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "id": "95f55a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -2.742169638094225\n"
     ]
    }
   ],
   "source": [
    "n = N(2)  # Create a neuron with 2 inputs\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "\n",
    "o = n([x1, x2])\n",
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "id": "f5d28c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\" Class to represent a layer of neurons. \"\"\"\n",
    "    def __init__(self, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.neurons = [N(input) for _ in range(output)]\n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for n in self.neurons:\n",
    "            parameters.extend(n.parameters())  # Collect parameters from each neuron\n",
    "        return parameters\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None):\n",
    "        \"\"\" Forward pass for the layer. \"\"\"\n",
    "        outputs = [n(input, act_fn) for n in self.neurons]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1741,
   "id": "29894ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class NN():\n",
    "    \"\"\" Class to represent a simple neural network with hidden layers. \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                 hidden_layer_num: int, \n",
    "                 hidden_layer_size: int, \n",
    "                 output_size: int):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_num = hidden_layer_num\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.forward_hook = None  # Hook for forward pass\n",
    "\n",
    "        self.layers = []\n",
    "        for i in range(hidden_layer_num):\n",
    "            if i == 0:\n",
    "                # First layer takes the input size\n",
    "                self.layers.append(Layer(input_size, hidden_layer_size))\n",
    "            elif i == hidden_layer_num - 1:\n",
    "                # Last layer is the output layer, use output_size\n",
    "                self.layers.append(Layer(hidden_layer_size, output_size))\n",
    "            else:\n",
    "                # Intermediate layers use hidden_layer_size\n",
    "                self.layers.append(Layer(hidden_layer_size, hidden_layer_size))\n",
    "           \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for layer in self.layers:\n",
    "            parameters.extend(layer.parameters())  # Collect parameters from each layer\n",
    "        return parameters\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def register_forward_hook(self, func: Callable[[str, list[Value], list[Value]], None]): \n",
    "        self.forward_hook = func\n",
    "\n",
    "    def __call__(self, input):\n",
    "        \"\"\" Forward pass for the neural network. \"\"\"\n",
    "        assert len(input) == self.input_size, \"input size mismatch\"\n",
    "\n",
    "        x = [Value(i) for i in input]\n",
    "        for num, layer in enumerate(self.layers):\n",
    "            if num != len(self.layers) - 1:\n",
    "                act_fn = 'tanh'\n",
    "            else:\n",
    "                act_fn = None\n",
    "            input = x.copy()\n",
    "            x = layer(x, act_fn)  # Forward pass through the layer\n",
    "            self.forward_hook(f\"Layer {num}\", [i.data for i in input], [o.data for o in x]) if self.forward_hook else None\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "id": "7e307dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # For reproducibility\n",
    "mlp = NN(input_size=3, hidden_layer_num=3, hidden_layer_size=4, output_size=1)  # Create a neural network with 2 inputs, 2 hidden layers of size 3, and 1 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ae772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model information:\n",
      "input size: 3\n",
      "total model layers: 3\n",
      "[0] layer input: 3, layer output: 4, neurons: 4\n",
      "[1] layer input: 4, layer output: 4, neurons: 4\n",
      "[2] layer input: 4, layer output: 1, neurons: 1\n",
      "total model parameters: 41\n",
      "model parameters:\n",
      "[tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]), tensor([-0.5536, -0.8261,  0.0107,  0.0899]), tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]), tensor([ 0.6116, -0.3268,  0.6143,  0.1041]), tensor([[0.6588, 0.2370, 0.7234, 0.1547]]), tensor([0.4091])]\n"
     ]
    }
   ],
   "source": [
    "print(\"model information:\")\n",
    "print(f\"input size: {mlp.input_size}\")\n",
    "print(f\"total model layers: {len(mlp.layers)}\")\n",
    "for i, layer in enumerate(mlp.layers):\n",
    "    print(f\"[{i}] layer input: {layer.input}, layer output: {layer.output}, neurons: {len(layer.neurons)}\")\n",
    "print(f\"total model parameters: {len(mlp.parameters())}\")\n",
    "\n",
    "# Build tensor parameters for the model, this will be used to set the parameters in PyTorch\n",
    "mlp_tensor_parameters = []\n",
    "print(\"model parameters:\")\n",
    "\n",
    "# Save pre-defined parameters in a list of tensors\n",
    "for layer_num, layer in enumerate(mlp.layers):\n",
    "    layer_params = []\n",
    "    bias_params = []\n",
    "    for neuron_num, neuron in enumerate(layer.neurons):\n",
    "        layer_params.append([x.data for x in neuron.parameters()][:-1])\n",
    "        bias_params.append([x.data for x in neuron.parameters()][-1])\n",
    "    mlp_tensor_parameters.append(torch.tensor(layer_params))\n",
    "    mlp_tensor_parameters.append(torch.tensor(bias_params))\n",
    "    \n",
    "print(mlp_tensor_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1796,
   "id": "4fb2c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch model with the same architecture for verification\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 4),  # First hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 4),  # Second hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1)   # Output layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def hook_fn(module, input, output, name=None):\n",
    "    \"\"\" Hook function to capture the output of each layer. \"\"\"\n",
    "    print(f\"Layer: {module}, Input: {input}, Output: {output}\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\" Calculate Root Mean Squared Error. \"\"\"\n",
    "    diffs = torch.stack([(y_true_i - y_pred_i) ** 2 for y_true_i, y_pred_i in zip(y_true, y_pred)])\n",
    "    return torch.mean(diffs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook for layer: \n",
      "Registering hook for layer: layers\n",
      "Registering hook for layer: layers.0\n",
      "Registering hook for layer: layers.1\n",
      "Registering hook for layer: layers.2\n",
      "Registering hook for layer: layers.3\n",
      "Registering hook for layer: layers.4\n",
      "model parameters = [Parameter containing:\n",
      "tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5536, -0.8261,  0.0107,  0.0899], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.6116, -0.3268,  0.6143,  0.1041], requires_grad=True), Parameter containing:\n",
      "tensor([[0.6588, 0.2370, 0.7234, 0.1547]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4091], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmlp = MLP(input_size=3)  # Create a PyTorch model with the same architecture\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "# Register hooks to capture the output of each layer\n",
    "for name, module in tmlp.named_modules():\n",
    "    print(f\"Registering hook for layer: {name}\")\n",
    "    module.register_forward_hook(hook_fn)\n",
    "\n",
    "print(f\"model parameters = {[p for p in tmlp.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1746,
   "id": "5df68e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model parameters:\n",
      "layers.0.weight: data: tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) grad=None\n",
      "layers.0.bias: data: tensor([-0.5536, -0.8261,  0.0107,  0.0899]) grad=None\n",
      "layers.2.weight: data: tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]) grad=None\n",
      "layers.2.bias: data: tensor([ 0.6116, -0.3268,  0.6143,  0.1041]) grad=None\n",
      "layers.4.weight: data: tensor([[0.6588, 0.2370, 0.7234, 0.1547]]) grad=None\n",
      "layers.4.bias: data: tensor([0.4091]) grad=None\n"
     ]
    }
   ],
   "source": [
    "# Print parameters of the PyTorch model\n",
    "print(\"PyTorch model parameters:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: data: {param.data} grad={param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "id": "bd430978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "\n",
    "y = [1.0, -1.0, -1.0, 1.0]  # Example labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "id": "014ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mse(y_preds, y_true):\n",
    "    \"\"\"Mean squared error loss function.\"\"\"\n",
    "    loss = sum([(i - j)**2 for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss/len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1749,
   "id": "8bb459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mae(y_preds, y_true):\n",
    "    \"\"\"Mean absolute error loss function.\"\"\"\n",
    "    loss = sum([(i - j) for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "id": "cab62bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: , data: 0.2788535969157675, grad: 0.0009631703851826798\n",
      "param: , data: -0.9499784895546661, grad: 0.0014447555777740196\n",
      "param: , data: -0.4499413632617615, grad: -0.0004815851925913399\n",
      "param: , data: -0.5535785237023545, grad: 0.0004815851925913399\n",
      "param: , data: 0.4729424283280248, grad: -0.008087029052452697\n",
      "param: , data: 0.3533989748458226, grad: -0.012130543578679046\n",
      "param: , data: 0.7843591354096908, grad: 0.004043514526226349\n",
      "param: , data: -0.8261223347411677, grad: -0.004043514526226349\n",
      "param: , data: -0.15615636062945915, grad: -0.0007711660821590733\n",
      "param: , data: -0.9404055611238593, grad: -0.00115674912323861\n",
      "param: , data: -0.5627240503927933, grad: 0.00038558304107953663\n",
      "param: , data: 0.010710576206724776, grad: -0.00038558304107953663\n",
      "param: , data: -0.9469280606322728, grad: 8.347651589647732e-05\n",
      "param: , data: -0.602324698626703, grad: 0.000125214773844716\n",
      "param: , data: 0.2997688755590464, grad: -4.173825794823866e-05\n",
      "param: , data: 0.08988296120643335, grad: 4.173825794823866e-05\n",
      "param: , data: -0.5591187559186066, grad: 0.025947853827143978\n",
      "param: , data: 0.17853136775181744, grad: -0.00992436626348306\n",
      "param: , data: 0.6188609133556533, grad: 0.02606870426158594\n",
      "param: , data: -0.987002480643878, grad: 0.02636093958323322\n",
      "param: , data: 0.6116385036656158, grad: -0.026382092010792762\n",
      "param: , data: 0.3962787899764537, grad: 0.02352971157995671\n",
      "param: , data: -0.31949896696401625, grad: -0.008999490954019754\n",
      "param: , data: -0.6890410003764369, grad: 0.023639299674820924\n",
      "param: , data: 0.9144261444135624, grad: 0.02390430089140105\n",
      "param: , data: -0.32681090977474647, grad: -0.02392348207389913\n",
      "param: , data: -0.8145083132397042, grad: 0.18171243535335416\n",
      "param: , data: -0.806567246333072, grad: -0.06950018969159072\n",
      "param: , data: 0.6949887326949196, grad: 0.18255874915264755\n",
      "param: , data: 0.20745206273378214, grad: 0.1846052687741373\n",
      "param: , data: 0.6142565465487604, grad: -0.1847533989104902\n",
      "param: , data: 0.45946357338763577, grad: 0.01677559997402493\n",
      "param: , data: 0.07245618290940148, grad: -0.0064162223026606735\n",
      "param: , data: 0.9462315279587412, grad: 0.01685373123522252\n",
      "param: , data: -0.24293124558329304, grad: 0.017042664889885966\n",
      "param: , data: 0.104081262546454, grad: -0.017056340189029483\n",
      "param: , data: 0.6588093285059897, grad: -0.24688013463515496\n",
      "param: , data: 0.2370395047284921, grad: 0.2113081631240002\n",
      "param: , data: 0.7234138006215545, grad: -0.05743547221069753\n",
      "param: , data: 0.15470429051352408, grad: 0.20531606314719333\n",
      "param: , data: 0.40914367242984695, grad: -0.2677132968107949\n"
     ]
    }
   ],
   "source": [
    "# Print grads for our model\n",
    "for param in mlp.parameters():\n",
    "    print(f\"param: {param.label}, data: {param.data}, grad: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "id": "3d011511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795]\n",
      "Layer: Layer 1, Input: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795], Output: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824]\n",
      "Layer: Layer 2, Input: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824], Output: [0.8661433515946025]\n",
      "y_preds = 0.8661433515946025\n",
      "y = 1.0\n",
      "loss = Value(data=0.017917602322326195)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with our model\n",
    "mlp.register_forward_hook(hook_fn)  # Register the hook to capture outputs\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "id": "0f2e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "id": "7c87c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "y_preds_tmlp = 0.8661433458328247\n",
      "loss_tmlp = Value(data=0.017917603864830767)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with PyTorch model\n",
    "y_preds_tmlp = tmlp(torch.tensor(x[0]))\n",
    "print(f\"y_preds_tmlp = {y_preds_tmlp.item()}\")\n",
    "loss_tmlp = loss_fn_mse([Value(y_preds_tmlp.item())], [Value(y[0])])\n",
    "print(f\"loss_tmlp = {loss_tmlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "id": "dedc339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power operation: base = -0.13385664840539746, power = 2, grad = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with our model\n",
    "mlp.zero_grad()\n",
    "visited = set()\n",
    "loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "loss.backward(loss, visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "id": "494cc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for our model\n",
    "learning_rate = 0.001\n",
    "for param in mlp.parameters():\n",
    "    param.data -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1797,
   "id": "8964c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "output = tensor([0.8685], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with PyTorch model\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "optimizer.zero_grad()\n",
    "output = tmlp(torch.tensor(x[0]))  # Forward pass\n",
    "print(f\"output = {output}\")\n",
    "loss_rmse = rmse([torch.tensor([y[0]])], [output])  # Calculate loss\n",
    "loss_rmse.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1757,
   "id": "6bc150d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmlp loss grad = 0.017917603254318237\n"
     ]
    }
   ],
   "source": [
    "# Print gradients of the loss function\n",
    "print(f\"tmlp loss grad = {loss_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1758,
   "id": "30507a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for PyTorch model\n",
    "optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1759,
   "id": "46a77386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for our model:\n",
      ": 0.2788535969157675 (grad: 0.0009631703851826798)\n",
      ": -0.9499784895546661 (grad: 0.0014447555777740196)\n",
      ": -0.4499413632617615 (grad: -0.0004815851925913399)\n",
      ": -0.5535785237023545 (grad: 0.0004815851925913399)\n",
      ": 0.4729424283280248 (grad: -0.008087029052452697)\n",
      ": 0.3533989748458226 (grad: -0.012130543578679046)\n",
      ": 0.7843591354096908 (grad: 0.004043514526226349)\n",
      ": -0.8261223347411677 (grad: -0.004043514526226349)\n",
      ": -0.15615636062945915 (grad: -0.0007711660821590733)\n",
      ": -0.9404055611238593 (grad: -0.00115674912323861)\n",
      ": -0.5627240503927933 (grad: 0.00038558304107953663)\n",
      ": 0.010710576206724776 (grad: -0.00038558304107953663)\n",
      ": -0.9469280606322728 (grad: 8.347651589647732e-05)\n",
      ": -0.602324698626703 (grad: 0.000125214773844716)\n",
      ": 0.2997688755590464 (grad: -4.173825794823866e-05)\n",
      ": 0.08988296120643335 (grad: 4.173825794823866e-05)\n",
      ": -0.5591187559186066 (grad: 0.025947853827143978)\n",
      ": 0.17853136775181744 (grad: -0.00992436626348306)\n",
      ": 0.6188609133556533 (grad: 0.02606870426158594)\n",
      ": -0.987002480643878 (grad: 0.02636093958323322)\n",
      ": 0.6116385036656158 (grad: -0.026382092010792762)\n",
      ": 0.3962787899764537 (grad: 0.02352971157995671)\n",
      ": -0.31949896696401625 (grad: -0.008999490954019754)\n",
      ": -0.6890410003764369 (grad: 0.023639299674820924)\n",
      ": 0.9144261444135624 (grad: 0.02390430089140105)\n",
      ": -0.32681090977474647 (grad: -0.02392348207389913)\n",
      ": -0.8145083132397042 (grad: 0.18171243535335416)\n",
      ": -0.806567246333072 (grad: -0.06950018969159072)\n",
      ": 0.6949887326949196 (grad: 0.18255874915264755)\n",
      ": 0.20745206273378214 (grad: 0.1846052687741373)\n",
      ": 0.6142565465487604 (grad: -0.1847533989104902)\n",
      ": 0.45946357338763577 (grad: 0.01677559997402493)\n",
      ": 0.07245618290940148 (grad: -0.0064162223026606735)\n",
      ": 0.9462315279587412 (grad: 0.01685373123522252)\n",
      ": -0.24293124558329304 (grad: 0.017042664889885966)\n",
      ": 0.104081262546454 (grad: -0.017056340189029483)\n",
      ": 0.6588093285059897 (grad: -0.24688013463515496)\n",
      ": 0.2370395047284921 (grad: 0.2113081631240002)\n",
      ": 0.7234138006215545 (grad: -0.05743547221069753)\n",
      ": 0.15470429051352408 (grad: 0.20531606314719333)\n",
      ": 0.40914367242984695 (grad: -0.2677132968107949)\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters for out model\n",
    "print(\"Updated parameters for our model:\")\n",
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1760,
   "id": "ea105b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for PyTorch model:\n",
      "layers.0.weight: tensor([[ 0.2788, -0.9500, -0.4499],\n",
      "        [ 0.4727,  0.3530,  0.7845],\n",
      "        [-0.1561, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) (grad: tensor([[ 9.6584e-03,  1.4488e-02, -4.8292e-03],\n",
      "        [ 2.5877e-01,  3.8816e-01, -1.2939e-01],\n",
      "        [-6.8197e-03, -1.0229e-02,  3.4098e-03],\n",
      "        [-9.6238e-05, -1.4436e-04,  4.8119e-05]]))\n",
      "layers.0.bias: tensor([-0.5536, -0.8263,  0.0107,  0.0899]) (grad: tensor([ 4.8292e-03,  1.2939e-01, -3.4098e-03, -4.8119e-05]))\n",
      "layers.2.weight: tensor([[-0.5591,  0.1785,  0.6188, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6891,  0.9144],\n",
      "        [-0.8147, -0.8065,  0.6948,  0.2073],\n",
      "        [ 0.4594,  0.0725,  0.9462, -0.2429]]) (grad: tensor([[ 0.0259, -0.0099,  0.0261,  0.0264],\n",
      "        [ 0.0235, -0.0090,  0.0236,  0.0239],\n",
      "        [ 0.1817, -0.0695,  0.1826,  0.1846],\n",
      "        [ 0.0168, -0.0064,  0.0169,  0.0170]]))\n",
      "layers.2.bias: tensor([ 0.6117, -0.3268,  0.6144,  0.1041]) (grad: tensor([-0.0264, -0.0239, -0.1848, -0.0171]))\n",
      "layers.4.weight: tensor([[0.6591, 0.2368, 0.7235, 0.1545]]) (grad: tensor([[-0.2469,  0.2113, -0.0574,  0.2053]]))\n",
      "layers.4.bias: tensor([0.4094]) (grad: tensor([-0.2677]))\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters of PyTorch model\n",
    "print(\"Updated parameters for PyTorch model:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "id": "d85f718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9837086880999435, 0.4104862500252361, -0.9880359995850213, -0.9991988033317043]\n",
      "Layer: Layer 1, Input: [-0.9837086880999435, 0.4104862500252361, -0.9880359995850213, -0.9991988033317043], Output: [0.9300756159974627, -0.7781620501975345, 0.4325779256190116, -0.7567228577133508]\n",
      "Layer: Layer 2, Input: [0.9300756159974627, -0.7781620501975345, 0.4325779256190116, -0.7567228577133508], Output: [1.218553099743485]\n",
      "y_preds = 1.218553099743485\n",
      "y = 1.0\n",
      "loss = Value(data=0.047765457407485716)\n"
     ]
    }
   ],
   "source": [
    "# Second forward pass with our model\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "id": "20af6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = 0.2781168415395158, grad = 0.73675537625166\n",
      " = -0.95101455180252, grad = 1.0360622478538968\n",
      " = -0.4496190327846514, grad = -0.32233047711010127\n",
      " = -0.5538548069684489, grad = 0.27628326609437254\n",
      " = 0.47874179372064934, grad = -5.7993653926245345\n",
      " = 0.361518086395497, grad = -8.119111549674347\n",
      " = 0.7818460770728869, grad = 2.5130583368039647\n",
      " = -0.8239959007638721, grad = -2.126433977295662\n",
      " = -0.15564021035113365, grad = -0.5161502783255044\n",
      " = -0.939686637521906, grad = -0.7189236019533811\n",
      " = -0.5629452576549328, grad = 0.22120726213950187\n",
      " = 0.010894915591841027, grad = -0.18433938511625153\n",
      " = -0.9469799415771389, grad = 0.05188094486624031\n",
      " = -0.6023965337811332, grad = 0.07183515443017889\n",
      " = 0.29979082518956673, grad = -0.021949630520332438\n",
      " = 0.08986500241782581, grad = 0.017958788607544723\n",
      " = -0.5740049233377658, grad = 14.886167419159179\n",
      " = 0.1837504684843409, grad = -5.219100732523457\n",
      " = 0.6063979977126209, grad = 12.46291564303239\n",
      " = -0.998344845293084, grad = 11.342364649205999\n",
      " = 0.6204674216180595, grad = -8.828917952443646\n",
      " = 0.38390480742858285, grad = 12.373982547870861\n",
      " = -0.3151964939502172, grad = -4.30247301379903\n",
      " = -0.6992123205646679, grad = 10.171320188230926\n",
      " = 0.9052836175729262, grad = 9.14252684063618\n",
      " = -0.31994851256506335, grad = -6.862397209683107\n",
      " = -0.9013813212102605, grad = 86.87300797055632\n",
      " = -0.7766632858850004, grad = -29.903960448071558\n",
      " = 0.6251666420299947, grad = 69.82209066492487\n",
      " = 0.14567285390800375, grad = 61.77920882577839\n",
      " = 0.6584199618508769, grad = -44.16341530211658\n",
      " = 0.4522455085112372, grad = 7.218064876398609\n",
      " = 0.07491015489059694, grad = -2.4539719811954543\n",
      " = 0.9405913304259814, grad = 5.640197532759838\n",
      " = -0.24781989580672836, grad = 4.888650223435316\n",
      " = 0.10734297784801546, grad = -3.2617153015614506\n",
      " = 0.7414291772992669, grad = -82.6198487932772\n",
      " = 0.17642623177240094, grad = 60.613272956091166\n",
      " = 0.7371431643424521, grad = -13.729363720897624\n",
      " = 0.11544132217437869, grad = 39.26296833914538\n",
      " = 0.4347413254715256, grad = -25.597653041678633\n"
     ]
    }
   ],
   "source": [
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label} = {param.data}, grad = {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1824,
   "id": "f4b8b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9548653057683665, -0.9984969896650682, -0.625159978870059, -0.49670243619765225]\n",
      "Layer: Layer 1, Input: [0.9548653057683665, -0.9984969896650682, -0.625159978870059, -0.49670243619765225], Output: [-0.08323072560041145, -0.755524913119868, -0.7948346308936264, 0.014891066079880179]\n",
      "Layer: Layer 2, Input: [-0.08323072560041145, -0.755524913119868, -0.7948346308936264, 0.014891066079880179], Output: [0.22662558029348667]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.774045273549094, -0.8206993393030987, 0.9961599030958793, -0.991757771426443]\n",
      "Layer: Layer 1, Input: [0.774045273549094, -0.8206993393030987, 0.9961599030958793, -0.991757771426443], Output: [0.22671647719063362, 0.37424533426317197, -0.8641421606608078, 0.7371251836039879]\n",
      "Layer: Layer 2, Input: [0.22671647719063362, 0.37424533426317197, -0.8641421606608078, 0.7371251836039879], Output: [0.39667638595566546]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5480377653721663, -0.9480409213172014, -0.39371845465769795, -0.41043401071507857]\n",
      "Layer: Layer 1, Input: [0.5480377653721663, -0.9480409213172014, -0.39371845465769795, -0.41043401071507857], Output: [-0.09722938212671027, -0.6306072021066773, -0.6714374743471679, -0.09630124200894305]\n",
      "Layer: Layer 2, Input: [-0.09722938212671027, -0.6306072021066773, -0.6714374743471679, -0.09630124200894305], Output: [0.29261685918960445]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.23815116350069845, -0.7977167125579208, 0.26899543890087596, -0.6164175405077693]\n",
      "Layer: Layer 1, Input: [0.23815116350069845, -0.7977167125579208, 0.26899543890087596, -0.6164175405077693], Output: [-0.1209353024606171, -0.19147941656022013, -0.6261570436560896, 0.06486353126777396]\n",
      "Layer: Layer 2, Input: [-0.1209353024606171, -0.19147941656022013, -0.6261570436560896, 0.06486353126777396], Output: [0.33178429984099167]\n",
      "Epoch 1/100, Loss: 1.1665458716856891, Accuracy: -3.1308833650107912\n",
      "Power operation: base = -0.7733744197065133, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3966763859556655, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2926168591896046, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6682157001590083, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9557588645052786, -0.9985329080315558, -0.6127654872704614, -0.48614858956533147]\n",
      "Layer: Layer 1, Input: [0.9557588645052786, -0.9985329080315558, -0.6127654872704614, -0.48614858956533147], Output: [-0.07560104809119811, -0.7505203217971965, -0.7924534376253588, 0.035857455974179914]\n",
      "Layer: Layer 2, Input: [-0.07560104809119811, -0.7505203217971965, -0.7924534376253588, 0.035857455974179914], Output: [0.2132900370638533]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7743106829967756, -0.8208366152672235, 0.996197797192902, -0.9917077805343048]\n",
      "Layer: Layer 1, Input: [0.7743106829967756, -0.8208366152672235, 0.996197797192902, -0.9917077805343048], Output: [0.22647549198450828, 0.37434007189714763, -0.8628248228457974, 0.7379891312062268]\n",
      "Layer: Layer 2, Input: [0.22647549198450828, 0.37434007189714763, -0.8628248228457974, 0.7379891312062268], Output: [0.3745027146563812]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5470134089530453, -0.9478202762575708, -0.3923598938792714, -0.40991952124016606]\n",
      "Layer: Layer 1, Input: [0.5470134089530453, -0.9478202762575708, -0.3923598938792714, -0.40991952124016606], Output: [-0.1022208236806973, -0.629888541908997, -0.6705355507568591, -0.09514617234723032]\n",
      "Layer: Layer 2, Input: [-0.1022208236806973, -0.629888541908997, -0.6705355507568591, -0.09514617234723032], Output: [0.2690812502007187]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.24177993154466962, -0.7992803642490652, 0.27825573499058576, -0.6122698361230589]\n",
      "Layer: Layer 1, Input: [0.24177993154466962, -0.7992803642490652, 0.27825573499058576, -0.6122698361230589], Output: [-0.1160783489654684, -0.18275821056553562, -0.6259560025945136, 0.08028506052949884]\n",
      "Layer: Layer 2, Input: [-0.1160783489654684, -0.18275821056553562, -0.6259560025945136, 0.08028506052949884], Output: [0.31186822921577234]\n",
      "Epoch 2/100, Loss: 1.1480657079886027, Accuracy: -3.1184256985774743\n",
      "Power operation: base = -0.7867099629361467, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3745027146563813, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2690812502007187, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6881317707842276, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9566797871829312, -0.9985695364447842, -0.5995477768428106, -0.4749021598360134]\n",
      "Layer: Layer 1, Input: [0.9566797871829312, -0.9985695364447842, -0.5995477768428106, -0.4749021598360134], Output: [-0.06608558072833493, -0.7450683972921547, -0.7896596827656798, 0.05830100882691698]\n",
      "Layer: Layer 2, Input: [-0.06608558072833493, -0.7450683972921547, -0.7896596827656798, 0.05830100882691698], Output: [0.20330936821892265]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7746716703432247, -0.821056691372357, 0.996238556523762, -0.9916504360050838]\n",
      "Layer: Layer 1, Input: [0.7746716703432247, -0.821056691372357, 0.996238556523762, -0.9916504360050838], Output: [0.2276078746333479, 0.3744789464149218, -0.861295353264695, 0.7390117904692411]\n",
      "Layer: Layer 2, Input: [0.2276078746333479, 0.3744789464149218, -0.861295353264695, 0.7390117904692411], Output: [0.3555372397212722]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5461108472067004, -0.9476180097289201, -0.3907044257045574, -0.4091042614300397]\n",
      "Layer: Layer 1, Input: [0.5461108472067004, -0.9476180097289201, -0.3907044257045574, -0.4091042614300397], Output: [-0.10574695795024495, -0.6289771858370738, -0.6691840710633464, -0.09317406266891382]\n",
      "Layer: Layer 2, Input: [-0.10574695795024495, -0.6289771858370738, -0.6691840710633464, -0.09317406266891382], Output: [0.2486656900297325]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.24571704115226384, -0.8009595731354648, 0.2879737751818405, -0.6077608889967757]\n",
      "Layer: Layer 1, Input: [0.24571704115226384, -0.8009595731354648, 0.2879737751818405, -0.6077608889967757], Output: [-0.10940401935871344, -0.17352588398485438, -0.6253011312156052, 0.09685891782218085]\n",
      "Layer: Layer 2, Input: [-0.10940401935871344, -0.17352588398485438, -0.6253011312156052, 0.09685891782218085], Output: [0.2952841954115276]\n",
      "Epoch 3/100, Loss: 1.131996885433276, Accuracy: -3.1056093661205537\n",
      "Power operation: base = -0.7966906317810774, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3555372397212722, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2486656900297324, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7047158045884724, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9576190303241043, -0.9986064844580382, -0.5855619685438886, -0.46302734847756327]\n",
      "Layer: Layer 1, Input: [0.9576190303241043, -0.9986064844580382, -0.5855619685438886, -0.46302734847756327], Output: [-0.05492267457639633, -0.7391783766168224, -0.7865084972434059, 0.08204721596565541]\n",
      "Layer: Layer 2, Input: [-0.05492267457639633, -0.7391783766168224, -0.7865084972434059, 0.08204721596565541], Output: [0.19612778726525681]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7751133266294253, -0.821344954631821, 0.9962815815145732, -0.9915866197016369]\n",
      "Layer: Layer 1, Input: [0.7751133266294253, -0.821344954631821, 0.9962815815145732, -0.9915866197016369], Output: [0.22991422639298195, 0.37463977532504683, -0.8595861902749772, 0.7401706121017522]\n",
      "Layer: Layer 2, Input: [0.22991422639298195, 0.37463977532504683, -0.8595861902749772, 0.7401706121017522], Output: [0.339321741369373]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5453118758801954, -0.9474312212073966, -0.3887932518443408, -0.40802988540340585]\n",
      "Layer: Layer 1, Input: [0.5453118758801954, -0.9474312212073966, -0.3887932518443408, -0.40802988540340585], Output: [-0.10803466640458018, -0.6279043384890528, -0.6674664224578049, -0.09050377810654194]\n",
      "Layer: Layer 2, Input: [-0.10803466640458018, -0.6279043384890528, -0.6674664224578049, -0.09050377810654194], Output: [0.23079306541148098]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.24991274496339358, -0.8027286258675567, 0.29805402895046335, -0.6029312868193208]\n",
      "Layer: Layer 1, Input: [0.24991274496339358, -0.8027286258675567, 0.29805402895046335, -0.6029312868193208], Output: [-0.10118313292400935, -0.16389015154392556, -0.6242633889114524, 0.11437452341767053]\n",
      "Layer: Layer 2, Input: [-0.10118313292400935, -0.16389015154392556, -0.6242633889114524, 0.11437452341767053], Output: [0.28147015227722083]\n",
      "Epoch 4/100, Loss: 1.117782493311313, Accuracy: -3.092516867238376\n",
      "Power operation: base = -0.8038722127347432, power = 2, grad = 0.25\n",
      "Power operation: base = 1.339321741369373, power = 2, grad = 0.25\n",
      "Power operation: base = 1.230793065411481, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7185298477227792, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9585692396207056, -0.9986434422939044, -0.5708554338989595, -0.4505777642397701]\n",
      "Layer: Layer 1, Input: [0.9585692396207056, -0.9986434422939044, -0.5708554338989595, -0.4505777642397701], Output: [-0.042313198869743864, -0.7328553756809774, -0.7830434627550699, 0.10693687975619988]\n",
      "Layer: Layer 2, Input: [-0.042313198869743864, -0.7328553756809774, -0.7830434627550699, 0.10693687975619988], Output: [0.1912918764294822]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7756231119125689, -0.8216890401032266, 0.9963263708572266, -0.9915170589158333]\n",
      "Layer: Layer 1, Input: [0.7756231119125689, -0.8216890401032266, 0.9963263708572266, -0.9915170589158333], Output: [0.23322456901072067, 0.3748047180236215, -0.8577236181986367, 0.7414470311527102]\n",
      "Layer: Layer 2, Input: [0.23322456901072067, 0.3748047180236215, -0.8577236181986367, 0.7414470311527102], Output: [0.32547424670436703]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5446010455144545, -0.9472574092844608, -0.3866609989876132, -0.40673132956607255]\n",
      "Layer: Layer 1, Input: [0.5446010455144545, -0.9472574092844608, -0.3866609989876132, -0.40673132956607255], Output: [-0.10927416919613936, -0.6266957347513594, -0.6654497642579923, -0.08723483470139815]\n",
      "Layer: Layer 2, Input: [-0.10927416919613936, -0.6266957347513594, -0.6654497642579923, -0.08723483470139815], Output: [0.21498569936923]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.2543255706081771, -0.8045661426541661, 0.30841632527982576, -0.5978145425285419]\n",
      "Layer: Layer 1, Input: [0.2543255706081771, -0.8045661426541661, 0.30841632527982576, -0.5978145425285419], Output: [-0.09164295754366446, -0.15394194224702965, -0.6228993743382416, 0.13265173180902365]\n",
      "Layer: Layer 2, Input: [-0.09164295754366446, -0.15394194224702965, -0.6228993743382416, 0.13265173180902365], Output: [0.2699673668296137]\n",
      "Epoch 5/100, Loss: 1.1050071757427204, Accuracy: -3.079200702814501\n",
      "Power operation: base = -0.8087081235705178, power = 2, grad = 0.25\n",
      "Power operation: base = 1.325474246704367, power = 2, grad = 0.25\n",
      "Power operation: base = 1.21498569936923, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7300326331703864, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9595244399606941, -0.9986801660804758, -0.5554698827899015, -0.4375988642755319]\n",
      "Layer: Layer 1, Input: [0.9595244399606941, -0.9986801660804758, -0.5554698827899015, -0.4375988642755319], Output: [-0.028428790660910624, -0.7261013972589592, -0.7792992482983975, 0.13282105898559454]\n",
      "Layer: Layer 2, Input: [-0.028428790660910624, -0.7261013972589592, -0.7792992482983975, 0.13282105898559454], Output: [0.18843193871291336]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7761904377224865, -0.8220784592435258, 0.9963725038124257, -0.9914423595041277]\n",
      "Layer: Layer 1, Input: [0.7761904377224865, -0.8220784592435258, 0.9963725038124257, -0.9914423595041277], Output: [0.23739331015656123, 0.37495964492437156, -0.8557291986297091, 0.7428256614810431]\n",
      "Layer: Layer 2, Input: [0.23739331015656123, 0.37495964492437156, -0.8557291986297091, 0.7428256614810431], Output: [0.3136753042219682]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5439651820732926, -0.9470944084644188, -0.3843370739326455, -0.40523816157728415]\n",
      "Layer: Layer 1, Input: [0.5439651820732926, -0.9470944084644188, -0.3843370739326455, -0.40523816157728415], Output: [-0.1096260035735308, -0.6253727166997876, -0.6631886215711927, -0.083451450177888]\n",
      "Layer: Layer 2, Input: [-0.1096260035735308, -0.6253727166997876, -0.6631886215711927, -0.083451450177888], Output: [0.20084767149377764]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.2589207840170078, -0.8064543381878796, 0.31899295516281884, -0.5924386151147917]\n",
      "Layer: Layer 1, Input: [0.2589207840170078, -0.8064543381878796, 0.31899295516281884, -0.5924386151147917], Output: [-0.08097610556116606, -0.14375840751912047, -0.6212546144261529, 0.15153491807152034]\n",
      "Layer: Layer 2, Input: [-0.08097610556116606, -0.14375840751912047, -0.6212546144261529, 0.15153491807152034], Output: [0.26040145897641104]\n",
      "Epoch 6/100, Loss: 1.0933566637600525, Accuracy: -3.065689578026422\n",
      "Power operation: base = -0.8115680612870866, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3136753042219682, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2008476714937777, power = 2, grad = 0.25\n",
      "Power operation: base = -0.739598541023589, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9604797807532766, -0.9987164655064471, -0.5394429951672569, -0.42412985201965486]\n",
      "Layer: Layer 1, Input: [0.9604797807532766, -0.9987164655064471, -0.5394429951672569, -0.42412985201965486], Output: [-0.013418373097348429, -0.7189161651781575, -0.7753035835882334, 0.15955727631985908]\n",
      "Layer: Layer 2, Input: [-0.013418373097348429, -0.7189161651781575, -0.7753035835882334, 0.15955727631985908], Output: [0.18724659053110632]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7768063217031022, -0.8225042852050917, 0.9964196256173558, -0.9913630317873484]\n",
      "Layer: Layer 1, Input: [0.7768063217031022, -0.8225042852050917, 0.9964196256173558, -0.9913630317873484], Output: [0.24229502524972213, 0.3750935805609489, -0.8536208369358173, 0.744293599480043]\n",
      "Layer: Layer 2, Input: [0.24229502524972213, 0.3750935805609489, -0.8536208369358173, 0.744293599480043], Output: [0.3036567295171693]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5433929882601272, -0.9469403346813262, -0.38184674837199367, -0.4035756526742081]\n",
      "Layer: Layer 1, Input: [0.5433929882601272, -0.9469403346813262, -0.38184674837199367, -0.4035756526742081], Output: [-0.10922669265400031, -0.623953107729573, -0.6607275987875841, -0.079225845901445]\n",
      "Layer: Layer 2, Input: [-0.10922669265400031, -0.623953107729573, -0.6607275987875841, -0.079225845901445], Output: [0.18805026622614213]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.26366914193235685, -0.8083784010571696, 0.3297263414451895, -0.5868270992053415]\n",
      "Layer: Layer 1, Input: [0.26366914193235685, -0.8083784010571696, 0.3297263414451895, -0.5868270992053415], Output: [-0.06934756043331479, -0.1334053529120462, -0.6193660386594337, 0.1708882773404885]\n",
      "Layer: Layer 2, Input: [-0.06934756043331479, -0.1334053529120462, -0.6193660386594337, 0.1708882773404885], Output: [0.2524668198138641]\n",
      "Epoch 7/100, Loss: 1.0825895658944795, Accuracy: -3.051993585398341\n",
      "Power operation: base = -0.8127534094688937, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3036567295171693, power = 2, grad = 0.25\n",
      "Power operation: base = 1.188050266226142, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7475331801861359, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9614313280372756, -0.9987521936204273, -0.5228097022430714, -0.41020516052432715]\n",
      "Layer: Layer 1, Input: [0.9614313280372756, -0.9987521936204273, -0.5228097022430714, -0.41020516052432715], Output: [0.002586706478643911, -0.7112978290336357, -0.771078758402502, 0.1870067772817709]\n",
      "Layer: Layer 2, Input: [0.002586706478643911, -0.7112978290336357, -0.771078758402502, 0.1870067772817709], Output: [0.18749002402185366]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7774631036348213, -0.8229588890662072, 0.9964674355393588, -0.9912795108804902]\n",
      "Layer: Layer 1, Input: [0.7774631036348213, -0.8229588890662072, 0.9964674355393588, -0.9912795108804902], Output: [0.24782096384180735, 0.37519822094531063, -0.851413587724251, 0.7458398301148479]\n",
      "Layer: Layer 2, Input: [0.24782096384180735, 0.37519822094531063, -0.851413587724251, 0.7458398301148479], Output: [0.2951923823360555]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5428747141885554, -0.9467935389625426, -0.37921202786725083, -0.4017656298606757]\n",
      "Layer: Layer 1, Input: [0.5428747141885554, -0.9467935389625426, -0.37921202786725083, -0.4017656298606757], Output: [-0.10819332626509244, -0.6224519214351453, -0.6581034514793642, -0.07462093233520964]\n",
      "Layer: Layer 2, Input: [-0.10819332626509244, -0.6224519214351453, -0.6581034514793642, -0.07462093233520964], Output: [0.17632001387639112]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.2685458816632436, -0.810325977466622, 0.3405671690727283, -0.5810001594082798]\n",
      "Layer: Layer 1, Input: [0.2685458816632436, -0.810325977466622, 0.3405671690727283, -0.5810001594082798], Output: [-0.056900212603649254, -0.1229391995299848, -0.6172638630751408, 0.1905921015048196]\n",
      "Layer: Layer 2, Input: [-0.056900212603649254, -0.1229391995299848, -0.6172638630751408, 0.1905921015048196], Output: [0.24591381940892787]\n",
      "Epoch 8/100, Loss: 1.0725176277824846, Accuracy: -3.038108552781665\n",
      "Power operation: base = -0.8125099759781463, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2951923823360554, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1763200138763912, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7540861805910721, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9623758955436583, -0.99878723847365, -0.505603192900868, -0.3958556152693733]\n",
      "Layer: Layer 1, Input: [0.9623758955436583, -0.99878723847365, -0.505603192900868, -0.3958556152693733], Output: [0.019468643952004074, -0.7032435710979666, -0.7666427771840668, 0.21503268607027776]\n",
      "Layer: Layer 2, Input: [0.019468643952004074, -0.7032435710979666, -0.7666427771840668, 0.21503268607027776], Output: [0.18896146931621727]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7781542130064949, -0.8234357204428098, 0.9965156771528285, -0.9911921726949832]\n",
      "Layer: Layer 1, Input: [0.7781542130064949, -0.8234357204428098, 0.9965156771528285, -0.9911921726949832], Output: [0.25387618198824546, 0.3752675201343962, -0.849120270009486, 0.7474547273263076]\n",
      "Layer: Layer 2, Input: [0.25387618198824546, 0.3752675201343962, -0.849120270009486, 0.7474547273263076], Output: [0.2880906142121802]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5424018868475142, -0.9466525684244044, -0.37645234771114233, -0.39982715236961913]\n",
      "Layer: Layer 1, Input: [0.5424018868475142, -0.9466525684244044, -0.37645234771114233, -0.39982715236961913], Output: [-0.1066272477225979, -0.6208819359118664, -0.6553466833853341, -0.0696924843651555]\n",
      "Layer: Layer 2, Input: [-0.1066272477225979, -0.6208819359118664, -0.6553466833853341, -0.0696924843651555], Output: [0.1654288727690973]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.2735299045010504, -0.8122867446236335, 0.35147288803083143, -0.5749752661262248]\n",
      "Layer: Layer 1, Input: [0.2735299045010504, -0.8122867446236335, 0.35147288803083143, -0.5749752661262248], Output: [-0.043759208483094274, -0.11240856325953638, -0.6149730393591444, 0.21053984720156022]\n",
      "Layer: Layer 2, Input: [-0.043759208483094274, -0.11240856325953638, -0.6149730393591444, 0.21053984720156022], Output: [0.24053831288247207]\n",
      "Epoch 9/100, Loss: 1.062991860089618, Accuracy: -3.024019704782588\n",
      "Power operation: base = -0.8110385306837827, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2880906142121802, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1654288727690973, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7594616871175279, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9633109078436679, -0.9988215163151838, -0.48785569974109144, -0.38110934556276804]\n",
      "Layer: Layer 1, Input: [0.9633109078436679, -0.9988215163151838, -0.48785569974109144, -0.38110934556276804], Output: [0.037120038167442915, -0.6947501376890938, -0.7620102588138461, 0.24349893852075377]\n",
      "Layer: Layer 2, Input: [0.037120038167442915, -0.6947501376890938, -0.7620102588138461, 0.24349893852075377], Output: [0.19149647371895656]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.778873979528252, -0.82392912609742, 0.9965641304671713, -0.9911013465446413]\n",
      "Layer: Layer 1, Input: [0.778873979528252, -0.82392912609742, 0.9965641304671713, -0.9911013465446413], Output: [0.2603772063726194, 0.37529733841647617, -0.8467519411952099, 0.7491296408209294]\n",
      "Layer: Layer 2, Input: [0.2603772063726194, 0.37529733841647617, -0.8467519411952099, 0.7491296408209294], Output: [0.2821880906249597]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5419670889578522, -0.9465161337081698, -0.3735851289471244, -0.3977770472437395]\n",
      "Layer: Layer 1, Input: [0.5419670889578522, -0.9465161337081698, -0.3735851289471244, -0.3977770472437395], Output: [-0.10461700993076936, -0.6192541583096187, -0.6524827868836314, -0.06449089117332472]\n",
      "Layer: Layer 2, Input: [-0.10461700993076936, -0.6192541583096187, -0.6524827868836314, -0.06449089117332472], Output: [0.15518617454288458]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.2786031168139547, -0.8142520599769186, 0.3624065178501969, -0.568767775362342]\n",
      "Layer: Layer 1, Input: [0.2786031168139547, -0.8142520599769186, 0.3624065178501969, -0.568767775362342], Output: [-0.030035353414013664, -0.1018555240505722, -0.6125143784843865, 0.23063584831368444]\n",
      "Layer: Layer 2, Input: [-0.030035353414013664, -0.1018555240505722, -0.6125143784843865, 0.23063584831368444], Output: [0.23617303832730058]\n",
      "Epoch 10/100, Loss: 1.0538927442456332, Accuracy: -3.0097047531215875\n",
      "Power operation: base = -0.8085035262810434, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2821880906249596, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1551861745428846, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7638269616726994, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9642342897211905, -0.9988549660758534, -0.46959910409016253, -0.36599249581479354]\n",
      "Layer: Layer 1, Input: [0.9642342897211905, -0.9988549660758534, -0.46959910409016253, -0.36599249581479354], Output: [0.05544147721450973, -0.6858143101489352, -0.7571931450386821, 0.27226989164000753]\n",
      "Layer: Layer 2, Input: [0.05544147721450973, -0.6858143101489352, -0.7571931450386821, 0.27226989164000753], Output: [0.1949596878515102]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.779617479212706, -0.8244342006753966, 0.996612605586606, -0.9910073250579722]\n",
      "Layer: Layer 1, Input: [0.779617479212706, -0.8244342006753966, 0.996612605586606, -0.9910073250579722], Output: [0.2672501449648585, 0.375285143700105, -0.8443182645858563, 0.7508565616903924]\n",
      "Layer: Layer 2, Input: [0.2672501449648585, 0.375285143700105, -0.8443182645858563, 0.7508565616903924], Output: [0.27734474468770925]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5415637790616815, -0.9463830819775153, -0.37062622045620786, -0.3956303314351183]\n",
      "Layer: Layer 1, Input: [0.5415637790616815, -0.9463830819775153, -0.37062622045620786, -0.3956303314351183], Output: [-0.10224073581376157, -0.6175781996070253, -0.6495332124235099, -0.059062547857646246]\n",
      "Layer: Layer 2, Input: [-0.10224073581376157, -0.6175781996070253, -0.6495332124235099, -0.059062547857646246], Output: [0.1454320183830729]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.2837498993528619, -0.8162146738904902, 0.3733356962412827, -0.5623913846291336]\n",
      "Layer: Layer 1, Input: [0.2837498993528619, -0.8162146738904902, 0.3733356962412827, -0.5623913846291336], Output: [-0.01582775889427064, -0.09131664420693326, -0.6099054272660164, 0.2507935558521932]\n",
      "Layer: Layer 2, Input: [-0.01582775889427064, -0.09131664420693326, -0.6099054272660164, 0.2507935558521932], Output: [0.2326805721802953]\n",
      "Epoch 11/100, Loss: 1.0451232785030315, Accuracy: -2.9951365030389767\n",
      "Power operation: base = -0.8050403121484898, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2773447446877093, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1454320183830728, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7673194278197046, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9651443768535015, -0.9988875449106245, -0.4508653887722792, -0.3505297752411126]\n",
      "Layer: Layer 1, Input: [0.9651443768535015, -0.9988875449106245, -0.4508653887722792, -0.3505297752411126], Output: [0.07433972114321401, -0.6764333251547008, -0.7522012630474686, 0.30121051661257314]\n",
      "Layer: Layer 2, Input: [0.07433972114321401, -0.6764333251547008, -0.7522012630474686, 0.30121051661257314], Output: [0.19923890945900036]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7803804097923187, -0.8249466643497319, 0.9966609376318702, -0.990910371931947]\n",
      "Layer: Layer 1, Input: [0.7803804097923187, -0.8249466643497319, 0.9966609376318702, -0.990910371931947], Output: [0.27442916938299666, 0.3752297578613189, -0.8418277954087324, 0.7526278598328808]\n",
      "Layer: Layer 2, Input: [0.27442916938299666, 0.3752297578613189, -0.8418277954087324, 0.7526278598328808], Output: [0.2734396628496302]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.541186145873538, -0.9462523746581885, -0.3675902473601538, -0.3934005420943295]\n",
      "Layer: Layer 1, Input: [0.541186145873538, -0.9462523746581885, -0.3675902473601538, -0.3934005420943295], Output: [-0.09956799357559945, -0.6158625756053655, -0.6465161295915833, -0.05345094238216259]\n",
      "Layer: Layer 2, Input: [-0.09956799357559945, -0.6158625756053655, -0.6465161295915833, -0.05345094238216259], Output: [0.13603185438189552]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.28895668071942326, -0.8181684949139839, 0.38423192543854806, -0.5558584894474581]\n",
      "Layer: Layer 1, Input: [0.28895668071942326, -0.8181684949139839, 0.38423192543854806, -0.5558584894474581], Output: [-0.0012258848619070171, -0.08082378376288903, -0.6071611548653568, 0.2709342100979132]\n",
      "Layer: Layer 2, Input: [-0.0012258848619070171, -0.08082378376288903, -0.6071611548653568, 0.2709342100979132], Output: [0.22994756812220146]\n",
      "Epoch 12/100, Loss: 1.0366040052635677, Accuracy: -2.980285039650324\n",
      "Power operation: base = -0.8007610905409996, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2734396628496303, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1360318543818955, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7700524318777986, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9660398437239277, -0.9989192246034173, -0.4316869602660418, -0.33474487550900633]\n",
      "Layer: Layer 1, Input: [0.9660398437239277, -0.9989192246034173, -0.4316869602660418, -0.33474487550900633], Output: [0.09372637712580882, -0.6666052499336543, -0.7470427752828035, 0.3301870816320299]\n",
      "Layer: Layer 2, Input: [0.09372637712580882, -0.6666052499336543, -0.7470427752828035, 0.3301870816320299], Output: [0.2042401849000603]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7811589902431854, -0.8254627628305006, 0.9967089826972024, -0.9908107279397004]\n",
      "Layer: Layer 1, Input: [0.7811589902431854, -0.8254627628305006, 0.9967089826972024, -0.9908107279397004], Output: [0.28185530427572364, 0.37513114051938246, -0.8392882036568323, 0.754436086567339]\n",
      "Layer: Layer 2, Input: [0.28185530427572364, 0.37513114051938246, -0.8392882036568323, 0.754436086567339], Output: [0.2703677385994688]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5408289909894406, -0.9461230691801067, -0.3644908816967078, -0.39109999234334536]\n",
      "Layer: Layer 1, Input: [0.5408289909894406, -0.9461230691801067, -0.3644908816967078, -0.39109999234334536], Output: [-0.0966612769665166, -0.6141149469513882, -0.6434470264904832, -0.04769748123230756]\n",
      "Layer: Layer 2, Input: [-0.0966612769665166, -0.6141149469513882, -0.6434470264904832, -0.04769748123230756], Output: [0.1268720421251729]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.29421159537353486, -0.8201083983617677, 0.3950699785772921, -0.549180459356325]\n",
      "Layer: Layer 1, Input: [0.29421159537353486, -0.8201083983617677, 0.3950699785772921, -0.549180459356325], Output: [0.013688902454794424, -0.07040475222075004, -0.6042944914099455, 0.2909858658874257]\n",
      "Layer: Layer 2, Input: [0.013688902454794424, -0.07040475222075004, -0.6042944914099455, 0.2909858658874257], Output: [0.22788005562806896]\n",
      "Epoch 13/100, Loss: 1.0282694206056222, Accuracy: -2.965119540196512\n",
      "Power operation: base = -0.7957598150999396, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2703677385994687, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1268720421251728, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7721199443719311, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9669196454119114, -0.9989499886702696, -0.41209685715972727, -0.3186607794634661]\n",
      "Layer: Layer 1, Input: [0.9669196454119114, -0.9989499886702696, -0.41209685715972727, -0.3186607794634661], Output: [0.1135169818470284, -0.6563293148264725, -0.7417245409205336, 0.35906822574511754]\n",
      "Layer: Layer 2, Input: [0.1135169818470284, -0.6563293148264725, -0.7417245409205336, 0.35906822574511754], Output: [0.20988380748040553]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7819498800431238, -0.8259791858363144, 0.9967566146527604, -0.9907086155151212]\n",
      "Layer: Layer 1, Input: [0.7819498800431238, -0.8259791858363144, 0.9967566146527604, -0.9907086155151212], Output: [0.28947546825813036, 0.37499020367818103, -0.8367064474332097, 0.756273836037174]\n",
      "Layer: Layer 2, Input: [0.28947546825813036, 0.37499020367818103, -0.8367064474332097, 0.756273836037174], Output: [0.26803695904289765]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5404876349766756, -0.9459943040676179, -0.361341048113124, -0.3887399665022042]\n",
      "Layer: Layer 1, Input: [0.5404876349766756, -0.9459943040676179, -0.361341048113124, -0.3887399665022042], Output: [-0.09357716429112092, -0.6123423084751493, -0.6403391827315453, -0.04184208983910718]\n",
      "Layer: Layer 2, Input: [-0.09357716429112092, -0.6123423084751493, -0.6403391827315453, -0.04184208983910718], Output: [0.11785620895609072]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.29950421014111295, -0.8220300703416663, 0.4058274353112582, -0.5423678483011596]\n",
      "Layer: Layer 1, Input: [0.29950421014111295, -0.8220300703416663, 0.4058274353112582, -0.5423678483011596], Output: [0.02884215969246538, -0.060083828849142505, -0.6013167504142765, 0.3108827034766911]\n",
      "Layer: Layer 2, Input: [0.02884215969246538, -0.060083828849142505, -0.6013167504142765, 0.3108827034766911], Output: [0.2263996152385594]\n",
      "Epoch 14/100, Loss: 1.0200653465962881, Accuracy: -2.9496097452800236\n",
      "Power operation: base = -0.7901161925195945, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2680369590428977, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1178562089560908, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7736003847614406, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9677829705153613, -0.9989798300252082, -0.39212885892049776, -0.3022999796079421]\n",
      "Layer: Layer 1, Input: [0.9677829705153613, -0.9989798300252082, -0.39212885892049776, -0.3022999796079421], Output: [0.13363041914539223, -0.6456062033851174, -0.7362524073504875, 0.38772631825865983]\n",
      "Layer: Layer 2, Input: [0.13363041914539223, -0.6456062033851174, -0.7362524073504875, 0.38772631825865983], Output: [0.2161010819545901]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.782750114514456, -0.826493000706876, 0.9968037226333276, -0.9906042421722223]\n",
      "Layer: Layer 1, Input: [0.782750114514456, -0.826493000706876, 0.9968037226333276, -0.9906042421722223], Output: [0.29724171901129665, 0.37480865171104294, -0.8340889072261547, 0.7581336589755641]\n",
      "Layer: Layer 2, Input: [0.29724171901129665, 0.37480865171104294, -0.8340889072261547, 0.7581336589755641], Output: [0.2663662126499423]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.540157842656513, -0.9458652868069615, -0.35815307496339704, -0.38633086621922186]\n",
      "Layer: Layer 1, Input: [0.540157842656513, -0.9458652868069615, -0.35815307496339704, -0.38633086621922186], Output: [-0.09036721676740586, -0.6105511361658147, -0.6372040431446976, -0.03592361889618676]\n",
      "Layer: Layer 2, Input: [-0.09036721676740586, -0.6105511361658147, -0.6372040431446976, -0.03592361889618676], Output: [0.1089022641517996]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3048253060728881, -0.8239298806413151, 0.41648432129612395, -0.53543055132638]\n",
      "Layer: Layer 1, Input: [0.3048253060728881, -0.8239298806413151, 0.41648432129612395, -0.53543055132638], Output: [0.044165502673088955, -0.049882178052724956, -0.5982379592076106, 0.33056456583132837]\n",
      "Layer: Layer 2, Input: [0.044165502673088955, -0.049882178052724956, -0.5982379592076106, 0.33056456583132837], Output: [0.22544028075530273]\n",
      "Epoch 15/100, Loss: 1.0119469720928838, Accuracy: -2.9337271140918486\n",
      "Power operation: base = -0.7838989180454099, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2663662126499422, power = 2, grad = 0.25\n",
      "Power operation: base = 1.1089022641517996, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7745597192446972, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.968629202968899, -0.9990087490977486, -0.3718175073953015, -0.2856846219128642]\n",
      "Layer: Layer 1, Input: [0.968629202968899, -0.9990087490977486, -0.3718175073953015, -0.2856846219128642], Output: [0.15398861020510105, -0.634438298695317, -0.7306314456542338, 0.41603899298192376]\n",
      "Layer: Layer 2, Input: [0.15398861020510105, -0.634438298695317, -0.7306314456542338, 0.41603899298192376], Output: [0.22283174696493024]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7835570532060796, -0.8270015983498961, 0.9968502090795599, -0.9904978029699394]\n",
      "Layer: Layer 1, Input: [0.7835570532060796, -0.8270015983498961, 0.9968502090795599, -0.9904978029699394], Output: [0.305110662135355, 0.3745888421755592, -0.8314414892301152, 0.7600080221981103]\n",
      "Layer: Layer 2, Input: [0.305110662135355, 0.3745888421755592, -0.8314414892301152, 0.7600080221981103], Output: [0.2652835254336243]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.539835764057817, -0.9457352839974147, -0.35493879948657203, -0.38388231703717085]\n",
      "Layer: Layer 1, Input: [0.539835764057817, -0.9457352839974147, -0.35493879948657203, -0.38388231703717085], Output: [-0.08707866641980398, -0.608747498606764, -0.6340515133156435, -0.029980084586333652]\n",
      "Layer: Layer 2, Input: [-0.08707866641980398, -0.608747498606764, -0.6340515133156435, -0.029980084586333652], Output: [0.0999399514143472]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.31016670483773867, -0.8258047789800632, 0.4270228304483782, -0.5283779173642295]\n",
      "Layer: Layer 1, Input: [0.31016670483773867, -0.8258047789800632, 0.4270228304483782, -0.5283779173642295], Output: [0.05959598359673441, -0.039818181727070676, -0.5950671161783715, 0.34997666960162505]\n",
      "Layer: Layer 2, Input: [0.05959598359673441, -0.039818181727070676, -0.5950671161783715, 0.34997666960162505], Output: [0.22494604510862742]\n",
      "Epoch 16/100, Loss: 1.0038773557423695, Accuracy: -2.917445684774414\n",
      "Power operation: base = -0.7771682530350698, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2652835254336243, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0999399514143473, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7750539548913726, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9694578909436755, -0.9990367523117459, -0.3511980527568053, -0.26883658836359775]\n",
      "Layer: Layer 1, Input: [0.9694578909436755, -0.9990367523117459, -0.3511980527568053, -0.26883658836359775], Output: [0.17451642021754007, -0.6228298838060783, -0.7248661409623245, 0.4438907449921076]\n",
      "Layer: Layer 2, Input: [0.17451642021754007, -0.6228298838060783, -0.7248661409623245, 0.4438907449921076], Output: [0.23002196324630542]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7843683387740186, -0.8275026491634933, 0.9968959882190885, -0.9903894821986466]\n",
      "Layer: Layer 1, Input: [0.7843683387740186, -0.8275026491634933, 0.9968959882190885, -0.9903894821986466], Output: [0.31304298936876157, 0.3743336638624142, -0.828769704153127, 0.7618893068896919]\n",
      "Layer: Layer 2, Input: [0.31304298936876157, 0.3743336638624142, -0.828769704153127, 0.7618893068896919], Output: [0.2647246481901395]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5395178880793613, -0.9456036133627375, -0.35170963452402315, -0.3814032434508983]\n",
      "Layer: Layer 1, Input: [0.5395178880793613, -0.9456036133627375, -0.35170963452402315, -0.3814032434508983], Output: [-0.08375493538315495, -0.6069371385614952, -0.6308901936081408, -0.024048768922706975]\n",
      "Layer: Layer 2, Input: [-0.08375493538315495, -0.6069371385614952, -0.6308901936081408, -0.024048768922706975], Output: [0.09090884349725709]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3155211307264948, -0.8276522100768371, 0.43742711232079323, -0.5212188263550854]\n",
      "Layer: Layer 1, Input: [0.3155211307264948, -0.8276522100768371, 0.43742711232079323, -0.5212188263550854], Output: [0.07507565347324537, -0.029907706758906083, -0.5918123896993187, 0.3690694423699301]\n",
      "Layer: Layer 2, Input: [0.07507565347324537, -0.029907706758906083, -0.5918123896993187, 0.3690694423699301], Output: [0.22486886774491407]\n",
      "Epoch 17/100, Loss: 0.9958262474585801, Accuracy: -2.9007426606961775\n",
      "Power operation: base = -0.7699780367536946, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2647246481901395, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0909088434972571, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7751311322550859, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.97026872136353, -0.9990638508527073, -0.3303063354594343, -0.25177753011699766]\n",
      "Layer: Layer 1, Input: [0.97026872136353, -0.9990638508527073, -0.3303063354594343, -0.25177753011699766], Output: [0.19514173046318, -0.610787293960482, -0.7189605463137936, 0.4711744813399776]\n",
      "Layer: Layer 2, Input: [0.19514173046318, -0.610787293960482, -0.7189605463137936, 0.4711744813399776], Output: [0.23762278649403507]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7851818642424516, -0.8279940669623995, 0.9969409848924263, -0.9902794544392916]\n",
      "Layer: Layer 1, Input: [0.7851818642424516, -0.8279940669623995, 0.9969409848924263, -0.9902794544392916], Output: [0.32100311702639245, 0.3740464292782943, -0.8260787267140327, 0.7637698384700345]\n",
      "Layer: Layer 2, Input: [0.32100311702639245, 0.3740464292782943, -0.8260787267140327, 0.7637698384700345], Output: [0.26463192994366846]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5392010063707728, -0.9454696372621557, -0.3484766033641267, -0.3789019193457569]\n",
      "Layer: Layer 1, Input: [0.5392010063707728, -0.9454696372621557, -0.3484766033641267, -0.3789019193457569], Output: [-0.08043602179956517, -0.6051255295624579, -0.6277275649581275, -0.018166205375673178]\n",
      "Layer: Layer 2, Input: [-0.08043602179956517, -0.6051255295624579, -0.6277275649581275, -0.018166205375673178], Output: [0.08175670024680709]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3208821008906051, -0.8294700437861506, 0.44768310974094605, -0.5139617377775576]\n",
      "Layer: Layer 1, Input: [0.3208821008906051, -0.8294700437861506, 0.44768310974094605, -0.5139617377775576], Output: [0.09055126282518909, -0.02016432272039935, -0.5884812706670303, 0.38779844372444444]\n",
      "Layer: Layer 2, Input: [0.09055126282518909, -0.02016432272039935, -0.5884812706670303, 0.38779844372444444], Output: [0.2251670980785332]\n",
      "Epoch 18/100, Loss: 0.9877691295837672, Accuracy: -2.883598745617907\n",
      "Power operation: base = -0.762377213505965, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2646319299436684, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0817567002468071, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7748329019214668, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.971061498860614, -0.9990900596650741, -0.30917861589698886, -0.23452886196676512]\n",
      "Layer: Layer 1, Input: [0.971061498860614, -0.9990900596650741, -0.30917861589698886, -0.23452886196676512], Output: [0.2157956290528738, -0.5983190186767487, -0.7129184069751467, 0.4977929268993459]\n",
      "Layer: Layer 2, Input: [0.2157956290528738, -0.5983190186767487, -0.7129184069751467, 0.4977929268993459], Output: [0.2455890512748216]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7859957468838468, -0.8284739792700999, 0.996985133643638, -0.9901678851267037]\n",
      "Layer: Layer 1, Input: [0.7859957468838468, -0.8284739792700999, 0.996985133643638, -0.9901678851267037], Output: [0.32895890012675544, 0.37373077942629696, -0.8233734400913733, 0.7656419406639255]\n",
      "Layer: Layer 2, Input: [0.32895890012675544, 0.37373077942629696, -0.8233734400913733, 0.7656419406639255], Output: [0.2649534230188104]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5388821853428483, -0.9453327573957303, -0.3452503486668067, -0.3763859997499607]\n",
      "Layer: Layer 1, Input: [0.5388821853428483, -0.9453327573957303, -0.3452503486668067, -0.3763859997499607], Output: [-0.07715878198557005, -0.6033179117328494, -0.6245701371171583, -0.012368074227883366]\n",
      "Layer: Layer 2, Input: [-0.07715878198557005, -0.6033179117328494, -0.6245701371171583, -0.012368074227883366], Output: [0.07243812552375195]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.32624383772164756, -0.8312565172338985, 0.45777843421471104, -0.5066147167736011]\n",
      "Layer: Layer 1, Input: [0.32624383772164756, -0.8312565172338985, 0.45777843421471104, -0.5066147167736011], Output: [0.10597406102808865, -0.010599482178890002, -0.5850806883666718, 0.406124332810967]\n",
      "Layer: Layer 2, Input: [0.10597406102808865, -0.010599482178890002, -0.5850806883666718, 0.406124332810967], Output: [0.22580424278903324]\n",
      "Epoch 19/100, Loss: 0.9796864113809475, Accuracy: -2.8659982544787077\n",
      "Power operation: base = -0.7544109487251784, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2649534230188104, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0724381255237518, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7741957572109668, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9718361282315902, -0.9991153966327997, -0.28785136362330915, -0.21711172783925128]\n",
      "Layer: Layer 1, Input: [0.9718361282315902, -0.9991153966327997, -0.28785136362330915, -0.21711172783925128], Output: [0.23641267773484945, -0.5854357525338963, -0.7067432609211695, 0.523659802204086]\n",
      "Layer: Layer 2, Input: [0.23641267773484945, -0.5854357525338963, -0.7067432609211695, 0.523659802204086], Output: [0.25387859759933284]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7868083072602364, -0.8289407026266497, 0.997028378008772, -0.9900549307330384]\n",
      "Layer: Layer 1, Input: [0.7868083072602364, -0.8289407026266497, 0.997028378008772, -0.9900549307330384], Output: [0.3368814018027793, 0.37339059927840046, -0.820658468843681, 0.7674980064543044]\n",
      "Layer: Layer 2, Input: [0.3368814018027793, 0.37339059927840046, -0.820658468843681, 0.7674980064543044], Output: [0.26564217372387033]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5385587445614841, -0.945192410448212, -0.3420411209221404, -0.3738625390119136]\n",
      "Layer: Layer 1, Input: [0.5385587445614841, -0.945192410448212, -0.3420411209221404, -0.3738625390119136], Output: [-0.07395713390146186, -0.6015193106023791, -0.6214235679531736, -0.006689031282398277]\n",
      "Layer: Layer 2, Input: [-0.07395713390146186, -0.6015193106023791, -0.6214235679531736, -0.006689031282398277], Output: [0.06291346998718222]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.33160119835220375, -0.8330101864591518, 0.467702268633894, -0.4991854433221768]\n",
      "Layer: Layer 1, Input: [0.33160119835220375, -0.8330101864591518, 0.467702268633894, -0.4991854433221768], Output: [0.12129966111722662, -0.0012226737822249704, -0.5816170976425241, 0.42401285051140175]\n",
      "Layer: Layer 2, Input: [0.12129966111722662, -0.0012226737822249704, -0.5816170976425241, 0.42401285051140175], Output: [0.22674801534167177]\n",
      "Epoch 20/100, Loss: 0.9715627338717646, Accuracy: -2.8479290307700484\n",
      "Power operation: base = -0.7461214024006672, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2656421737238703, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0629134699871823, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7732519846583282, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9725925996516495, -0.9991398819062124, -0.26636101803121365, -0.19954694612390486]\n",
      "Layer: Layer 1, Input: [0.9725925996516495, -0.9991398819062124, -0.26636101803121365, -0.19954694612390486], Output: [0.2569312166258316, -0.5721503946621022, -0.7004385202054312, 0.5487007105255612]\n",
      "Layer: Layer 2, Input: [0.2569312166258316, -0.5721503946621022, -0.7004385202054312, 0.5487007105255612], Output: [0.26245177595719243]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7876180522279108, -0.8293927218097186, 0.9970706699465993, -0.9899407386738132]\n",
      "Layer: Layer 1, Input: [0.7876180522279108, -0.8293927218097186, 0.9970706699465993, -0.9899407386738132], Output: [0.3447447013105151, 0.3730299427418065, -0.8179382032121186, 0.7693305789129032]\n",
      "Layer: Layer 2, Input: [0.3447447013105151, 0.3730299427418065, -0.8179382032121186, 0.7693305789129032], Output: [0.2666556598774452]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5382282400766139, -0.9450480644590855, -0.33885875146131006, -0.3713379997727775]\n",
      "Layer: Layer 1, Input: [0.5382282400766139, -0.9450480644590855, -0.33885875146131006, -0.3713379997727775], Output: [-0.07086220292270431, -0.5997345423075379, -0.6182927607346286, -0.0011624923504519268]\n",
      "Layer: Layer 2, Input: [-0.07086220292270431, -0.5997345423075379, -0.6182927607346286, -0.0011624923504519268], Output: [0.05314793608130303]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3369496171708752, -0.8347298855531725, 0.4774452886375766, -0.49168120927092573]\n",
      "Layer: Layer 1, Input: [0.3369496171708752, -0.8347298855531725, 0.4774452886375766, -0.49168120927092573], Output: [0.1364879427743059, 0.007958443698220945, -0.5780965439650906, 0.4414347903494646]\n",
      "Layer: Layer 2, Input: [0.1364879427743059, 0.007958443698220945, -0.5780965439650906, 0.4414347903494646], Output: [0.2279696147665918]\n",
      "Epoch 21/100, Loss: 0.9633863586210546, Accuracy: -2.8293822052349644\n",
      "Power operation: base = -0.7375482240428075, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2666556598774452, power = 2, grad = 0.25\n",
      "Power operation: base = 1.053147936081303, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7720303852334082, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9733309760647232, -0.999163537345972, -0.24474373215646036, -0.18185494270449334]\n",
      "Layer: Layer 1, Input: [0.9733309760647232, -0.999163537345972, -0.24474373215646036, -0.18185494270449334], Output: [0.2772936736624176, -0.5584779982998483, -0.6940075371632846, 0.5728536948598321]\n",
      "Layer: Layer 2, Input: [0.2772936736624176, -0.5584779982998483, -0.6940075371632846, 0.5728536948598321], Output: [0.27127117069091644]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7884236609324631, -0.8298286720796898, 0.9971119693665799, -0.9898254470264852]\n",
      "Layer: Layer 1, Input: [0.7884236609324631, -0.8298286720796898, 0.9971119693665799, -0.9898254470264852], Output: [0.35252572731660925, 0.372652966217482, -0.8152168171979387, 0.7711324354965656]\n",
      "Layer: Layer 2, Input: [0.35252572731660925, 0.372652966217482, -0.8152168171979387, 0.7711324354965656], Output: [0.2679553426597565]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5378884514965696, -0.9448992157450447, -0.335712614610046, -0.3688182564122047]\n",
      "Layer: Layer 1, Input: [0.5378884514965696, -0.9448992157450447, -0.335712614610046, -0.3688182564122047], Output: [-0.06790242732745624, -0.5979682082511586, -0.6151819449271319, 0.004179605801953832]\n",
      "Layer: Layer 2, Input: [-0.06790242732745624, -0.5979682082511586, -0.6151819449271319, 0.004179605801953832], Output: [0.04311084920054015]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3422850580264768, -0.8364146916950452, 0.486999595617003, -0.4841089074299777]\n",
      "Layer: Layer 1, Input: [0.3422850580264768, -0.8364146916950452, 0.486999595617003, -0.4841089074299777], Output: [0.1515029716643149, 0.016937919932818228, -0.5745247118331526, 0.45836593850314356]\n",
      "Layer: Layer 2, Input: [0.1515029716643149, 0.016937919932818228, -0.5745247118331526, 0.45836593850314356], Output: [0.22944318801334487]\n",
      "Epoch 22/100, Loss: 0.9551486254661293, Accuracy: -2.8103518331560355\n",
      "Power operation: base = -0.7287288293090836, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2679553426597565, power = 2, grad = 0.25\n",
      "Power operation: base = 1.04311084920054, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7705568119866552, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9740513822999124, -0.999186386061236, -0.2230351107121488, -0.16405567855829092]\n",
      "Layer: Layer 1, Input: [0.9740513822999124, -0.999186386061236, -0.2230351107121488, -0.16405567855829092], Output: [0.297446851011377, -0.5444356732271095, -0.6874536587324757, 0.5960694497814557]\n",
      "Layer: Layer 2, Input: [0.297446851011377, -0.5444356732271095, -0.6874536587324757, 0.5960694497814557], Output: [0.28030148620750917]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7892239730154748, -0.8302473237424944, 0.997152243718344, -0.9897091841392966]\n",
      "Layer: Layer 1, Input: [0.7892239730154748, -0.8302473237424944, 0.997152243718344, -0.9897091841392966], Output: [0.3602041061780272, 0.37226387005133704, -0.8124982823524995, 0.7728966702405666]\n",
      "Layer: Layer 2, Input: [0.3602041061780272, 0.37226387005133704, -0.8124982823524995, 0.7728966702405666], Output: [0.26950630574170886]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5375373718448325, -0.9447453862350542, -0.3326115831200868, -0.3663085959852528]\n",
      "Layer: Layer 1, Input: [0.5375373718448325, -0.9447453862350542, -0.3326115831200868, -0.3663085959852528], Output: [-0.065103637673122, -0.5962246820025141, -0.6120947448534726, 0.009307049709031564]\n",
      "Layer: Layer 2, Input: [-0.065103637673122, -0.5962246820025141, -0.6120947448534726, 0.009307049709031564], Output: [0.03277506527462892]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3476039734709187, -0.8380638948251136, 0.4963586558524637, -0.4764750163377478]\n",
      "Layer: Layer 1, Input: [0.3476039734709187, -0.8380638948251136, 0.4963586558524637, -0.4764750163377478], Output: [0.16631291836974954, 0.025711399320719756, -0.5709069609655011, 0.4747869696523734]\n",
      "Layer: Layer 2, Input: [0.16631291836974954, 0.025711399320719756, -0.5709069609655011, 0.4747869696523734], Output: [0.2311454365311802]\n",
      "Epoch 23/100, Loss: 0.946843471573231, Accuracy: -2.790834448277648\n",
      "Power operation: base = -0.7196985137924908, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2695063057417089, power = 2, grad = 0.25\n",
      "Power operation: base = 1.0327750652746288, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7688545634688198, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9747539955707376, -0.9992084520241816, -0.20126995254750926, -0.14616857772450884]\n",
      "Layer: Layer 1, Input: [0.9747539955707376, -0.9992084520241816, -0.20126995254750926, -0.14616857772450884], Output: [0.31734216649876357, -0.5300424452885371, -0.6807802716061854, 0.6183111961133967]\n",
      "Layer: Layer 2, Input: [0.31734216649876357, -0.5300424452885371, -0.6807802716061854, 0.6183111961133967], Output: [0.28950954602991447]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7900179784218712, -0.830647568479529, 0.9971914676154202, -0.9895920681959335]\n",
      "Layer: Layer 1, Input: [0.7900179784218712, -0.830647568479529, 0.9971914676154202, -0.9895920681959335], Output: [0.36776201762436844, 0.3718668473039198, -0.8097863788120208, 0.774616769312965]\n",
      "Layer: Layer 2, Input: [0.36776201762436844, 0.3718668473039198, -0.8097863788120208, 0.774616769312965], Output: [0.2712769594861061]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5371731994339617, -0.9445861211077783, -0.32956398051769753, -0.36381371903819015]\n",
      "Layer: Layer 1, Input: [0.5371731994339617, -0.9445861211077783, -0.32956398051769753, -0.36381371903819015], Output: [-0.062489121289778654, -0.5945080909266175, -0.6090342395668544, 0.014191583183922244]\n",
      "Layer: Layer 2, Input: [-0.062489121289778654, -0.5945080909266175, -0.6090342395668544, 0.014191583183922244], Output: [0.022116490198879957]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.35290326897176083, -0.8396769709812819, 0.5055172416351515, -0.4687855837153227]\n",
      "Layer: Layer 1, Input: [0.35290326897176083, -0.8396769709812819, 0.5055172416351515, -0.4687855837153227], Output: [0.1808899648407309, 0.034276011471537075, -0.5672483538798357, 0.4906832914831091]\n",
      "Layer: Layer 2, Input: [0.1808899648407309, 0.034276011471537075, -0.5672483538798357, 0.4906832914831091], Output: [0.23305533340866047]\n",
      "Epoch 24/100, Loss: 0.9384670085130585, Accuracy: -2.7708285702464113\n",
      "Power operation: base = -0.7104904539700856, power = 2, grad = 0.25\n",
      "Power operation: base = 1.271276959486106, power = 2, grad = 0.25\n",
      "Power operation: base = 1.02211649019888, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7669446665913395, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9754390370990177, -0.9992297597470046, -0.17948200649342166, -0.12821246033016978]\n",
      "Layer: Layer 1, Input: [0.9754390370990177, -0.9992297597470046, -0.17948200649342166, -0.12821246033016978], Output: [0.3369358340915103, -0.515319078468928, -0.6739908404266234, 0.6395542461848167]\n",
      "Layer: Layer 2, Input: [0.3369358340915103, -0.515319078468928, -0.6739908404266234, 0.6395542461848167], Output: [0.2988643611139738]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7908048083405022, -0.8310284070250231, 0.997229622473428, -0.9894742067893842]\n",
      "Layer: Layer 1, Input: [0.7908048083405022, -0.8310284070250231, 0.997229622473428, -0.9894742067893842], Output: [0.3751840526015981, 0.3714660393313764, -0.8070847047463462, 0.7762866765348065]\n",
      "Layer: Layer 2, Input: [0.3751840526015981, 0.3714660393313764, -0.8070847047463462, 0.7762866765348065], Output: [0.27323879231440995]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5367943311628538, -0.9444209866467039, -0.32657753347068713, -0.36133774209643876]\n",
      "Layer: Layer 1, Input: [0.5367943311628538, -0.9444209866467039, -0.32657753347068713, -0.36133774209643876], Output: [-0.06007968045758591, -0.5928222947289326, -0.6060030164384265, 0.01880711877023906]\n",
      "Layer: Layer 2, Input: [-0.06007968045758591, -0.5928222947289326, -0.6060030164384265, 0.01880711877023906], Output: [0.011113690858022912]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3581802705234094, -0.8412535585562712, 0.5144713714514532, -0.46104621103685267]\n",
      "Layer: Layer 1, Input: [0.3581802705234094, -0.8412535585562712, 0.5144713714514532, -0.46104621103685267], Output: [0.19521019048138183, 0.04263026352813146, -0.5635536777014903, 0.5060448361755467]\n",
      "Layer: Layer 2, Input: [0.19521019048138183, 0.04263026352813146, -0.5635536777014903, 0.5060448361755467], Output: [0.23515392261885182]\n",
      "Epoch 25/100, Loss: 0.9300171560740591, Accuracy: -2.750334199439607\n",
      "Power operation: base = -0.7011356388860261, power = 2, grad = 0.25\n",
      "Power operation: base = 1.27323879231441, power = 2, grad = 0.25\n",
      "Power operation: base = 1.011113690858023, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7648460773811482, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.976106764672154, -0.999250334010627, -0.15770374807207502, -0.11020548423775614]\n",
      "Layer: Layer 1, Input: [0.976106764672154, -0.999250334010627, -0.15770374807207502, -0.11020548423775614], Output: [0.35618897331542365, -0.5002878659838471, -0.6670889407720281, 0.6597853027516813]\n",
      "Layer: Layer 2, Input: [0.35618897331542365, -0.5002878659838471, -0.6670889407720281, 0.6597853027516813], Output: [0.3083372310010969]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7915837269316109, -0.8313889378797334, 0.9972666961494637, -0.9893556965465001]\n",
      "Layer: Layer 1, Input: [0.7915837269316109, -0.8313889378797334, 0.9972666961494637, -0.9893556965465001], Output: [0.3824570700231093, 0.37106549769587494, -0.8043966850692091, 0.7779008466309877]\n",
      "Layer: Layer 2, Input: [0.3824570700231093, 0.37106549769587494, -0.8043966850692091, 0.7779008466309877], Output: [0.2753661551336345]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5363993567898715, -0.9442495682499638, -0.32365932670966885, -0.3588842030704432]\n",
      "Layer: Layer 1, Input: [0.5363993567898715, -0.9442495682499638, -0.32365932670966885, -0.3588842030704432], Output: [-0.0578936904690811, -0.5911708627874036, -0.6030032202489272, 0.023129917799327784]\n",
      "Layer: Layer 2, Input: [-0.0578936904690811, -0.5911708627874036, -0.6030032202489272, 0.023129917799327784], Output: [-0.00025241887743890357]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3634326945069293, -0.8427934369221933, 0.5232182473794263, -0.45326204107001444]\n",
      "Layer: Layer 1, Input: [0.3634326945069293, -0.8427934369221933, 0.5232182473794263, -0.45326204107001444], Output: [0.20925343365071436, 0.05077393296300149, -0.5598274623804793, 0.5208658018461627]\n",
      "Layer: Layer 2, Input: [0.20925343365071436, 0.05077393296300149, -0.5598274623804793, 0.5208658018461627], Output: [0.23742417674329408]\n",
      "Epoch 26/100, Loss: 0.9214933319639085, Accuracy: -2.7293523285118044\n",
      "Power operation: base = -0.6916627689989031, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2753661551336344, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9997475811225611, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7625758232567059, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9767574659940937, -0.9992701996367357, -0.13596618290086063, -0.09216509778834843]\n",
      "Layer: Layer 1, Input: [0.9767574659940937, -0.9992701996367357, -0.13596618290086063, -0.09216509778834843], Output: [0.37506764294151484, -0.4849723975387517, -0.6600782882813434, 0.6790015447382153]\n",
      "Layer: Layer 2, Input: [0.37506764294151484, -0.4849723975387517, -0.6600782882813434, 0.6790015447382153], Output: [0.3179018488881832]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7923541235949726, -0.8317283468378796, 0.9973026825748815, -0.9892366228334131]\n",
      "Layer: Layer 1, Input: [0.7923541235949726, -0.8317283468378796, 0.9973026825748815, -0.9892366228334131], Output: [0.38957005079393486, 0.37066915192311584, -0.8017255799777301, 0.7794542850725291]\n",
      "Layer: Layer 2, Input: [0.38957005079393486, 0.37066915192311584, -0.8017255799777301, 0.7794542850725291], Output: [0.27763606804012253]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5359870538569107, -0.9440714685498508, -0.32081576246630217, -0.35645607033721965]\n",
      "Layer: Layer 1, Input: [0.5359870538569107, -0.9440714685498508, -0.32081576246630217, -0.35645607033721965], Output: [-0.05594716172412302, -0.5895570518222023, -0.6000365989903664, 0.027138733504288054]\n",
      "Layer: Layer 2, Input: [-0.05594716172412302, -0.5895570518222023, -0.6000365989903664, 0.027138733504288054], Output: [-0.011998830742842942]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3686586189975225, -0.8442965070178813, 0.5317561887550332, -0.4454377496991271]\n",
      "Layer: Layer 1, Input: [0.3686586189975225, -0.8442965070178813, 0.5317561887550332, -0.4454377496991271], Output: [0.22300312740855904, 0.058707960278369276, -0.5560739969172149, 0.5351443505024248]\n",
      "Layer: Layer 2, Input: [0.22300312740855904, 0.058707960278369276, -0.5560739969172149, 0.5351443505024248], Output: [0.239850894004977]\n",
      "Epoch 27/100, Loss: 0.9128961959764315, Accuracy: -2.7078844944041194\n",
      "Power operation: base = -0.6820981511118168, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2776360680401226, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9880011692571571, power = 2, grad = 0.25\n",
      "Power operation: base = -0.760149105995023, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9773914527288047, -0.9992893812966062, -0.11429868091197125, -0.07410800510015872]\n",
      "Layer: Layer 1, Input: [0.9773914527288047, -0.9992893812966062, -0.11429868091197125, -0.07410800510015872], Output: [0.3935427990768956, -0.4693973102593099, -0.6529627648985341, 0.6972095577672618]\n",
      "Layer: Layer 2, Input: [0.3935427990768956, -0.4693973102593099, -0.6529627648985341, 0.6972095577672618], Output: [0.32753438915368227]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7931155056130962, -0.8320458971737844, 0.9973375813780895, -0.9891170595615815]\n",
      "Layer: Layer 1, Input: [0.7931155056130962, -0.8320458971737844, 0.9973375813780895, -0.9891170595615815], Output: [0.39651394873296086, 0.37028078261089675, -0.7990744936525892, 0.7809425743353829]\n",
      "Layer: Layer 2, Input: [0.39651394873296086, 0.37028078261089675, -0.7990744936525892, 0.7809425743353829], Output: [0.28002804136743]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5355563830393244, -0.9438863056115381, -0.3180525258349413, -0.3540557558373665]\n",
      "Layer: Layer 1, Input: [0.5355563830393244, -0.9438863056115381, -0.3180525258349413, -0.3540557558373665], Output: [-0.05425380828114638, -0.5879837851338299, -0.5971045471185895, 0.03081491469117818]\n",
      "Layer: Layer 2, Input: [-0.05425380828114638, -0.5879837851338299, -0.5971045471185895, 0.03081491469117818], Output: [-0.02414064424067533]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.37385645600074063, -0.8457627736095096, 0.5400845619012415, -0.43757754285030714]\n",
      "Layer: Layer 1, Input: [0.37385645600074063, -0.8457627736095096, 0.5400845619012415, -0.43757754285030714], Output: [0.23644611074981617, 0.06643434165290733, -0.5522973447037501, 0.5488822715258097]\n",
      "Layer: Layer 2, Input: [0.23644611074981617, 0.06643434165290733, -0.5522973447037501, 0.5488822715258097], Output: [0.24242061950190905]\n",
      "Epoch 28/100, Loss: 0.9042274461091815, Accuracy: -2.6859323884711634\n",
      "Power operation: base = -0.6724656108463177, power = 2, grad = 0.25\n",
      "Power operation: base = 1.28002804136743, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9758593557593247, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7575793804980909, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9780090551630042, -0.9993079033515226, -0.0927288438378236, -0.0560501444823533]\n",
      "Layer: Layer 1, Input: [0.9780090551630042, -0.9993079033515226, -0.0927288438378236, -0.0560501444823533], Output: [0.41159018177979617, -0.45358803080341786, -0.6457464429036145, 0.7144241674798835]\n",
      "Layer: Layer 2, Input: [0.41159018177979617, -0.45358803080341786, -0.6457464429036145, 0.7144241674798835], Output: [0.33721356287481385]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7938674910666259, -0.8323409203878762, 0.9973713974973681, -0.9889970691050401]\n",
      "Layer: Layer 1, Input: [0.7938674910666259, -0.8323409203878762, 0.9973713974973681, -0.9889970691050401], Output: [0.40328153893633717, 0.36990399937609236, -0.796446383258157, 0.7823618871879857]\n",
      "Layer: Layer 2, Input: [0.40328153893633717, 0.36990399937609236, -0.796446383258157, 0.7823618871879857], Output: [0.2825239055320544]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5351064837751952, -0.9436937111918556, -0.3153745569477108, -0.35168513218630126]\n",
      "Layer: Layer 1, Input: [0.5351064837751952, -0.9436937111918556, -0.3153745569477108, -0.35168513218630126], Output: [-0.05282512389956363, -0.5864536343328423, -0.5942081466418603, 0.03414247008903135]\n",
      "Layer: Layer 2, Input: [-0.05282512389956363, -0.5864536343328423, -0.5942081466418603, 0.03414247008903135], Output: [-0.03669122719281834]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3790249243189229, -0.84719232902119, 0.5482037062757371, -0.4296851589070257]\n",
      "Layer: Layer 1, Input: [0.3790249243189229, -0.84719232902119, 0.5482037062757371, -0.4296851589070257], Output: [0.2495724183443912, 0.07395602201588614, -0.5485013586774535, 0.562084621050139]\n",
      "Layer: Layer 2, Input: [0.2495724183443912, 0.07395602201588614, -0.5485013586774535, 0.562084621050139], Output: [0.245121579156346]\n",
      "Epoch 29/100, Loss: 0.895489662880245, Accuracy: -2.663497536308076\n",
      "Power operation: base = -0.6627864371251861, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2825239055320545, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9633087728071816, power = 2, grad = 0.25\n",
      "Power operation: base = -0.754878420843654, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9786106174342761, -0.9993257897206211, -0.07128240686395056, -0.038006679764193405]\n",
      "Layer: Layer 1, Input: [0.9786106174342761, -0.9993257897206211, -0.07128240686395056, -0.038006679764193405], Output: [0.4291901373816571, -0.4375705158576767, -0.6384336071310762, 0.7306672297806435]\n",
      "Layer: Layer 2, Input: [0.4291901373816571, -0.4375705158576767, -0.6384336071310762, 0.7306672297806435], Output: [0.34692063307217746]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7946098019658383, -0.8326128074507123, 0.9974041407861245, -0.9888767023316994]\n",
      "Layer: Layer 1, Input: [0.7946098019658383, -0.8326128074507123, 0.9974041407861245, -0.9888767023316994], Output: [0.4098672647359112, 0.3695422231150371, -0.7938440682330625, 0.7837089882073294]\n",
      "Layer: Layer 2, Input: [0.4098672647359112, 0.3695422231150371, -0.7938440682330625, 0.7837089882073294], Output: [0.2851076460687511]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5346366700866008, -0.9434933290474523, -0.3127860303958317, -0.34934555353661734]\n",
      "Layer: Layer 1, Input: [0.5346366700866008, -0.9434933290474523, -0.3127860303958317, -0.34934555353661734], Output: [-0.05167046554734629, -0.5849688042000335, -0.5913482061732223, 0.037108095591330395]\n",
      "Layer: Layer 2, Input: [-0.05167046554734629, -0.5849688042000335, -0.5913482061732223, 0.037108095591330395], Output: [-0.049662341715017655]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3841630229144532, -0.8485853381942803, 0.5561148577901914, -0.42176387664501497]\n",
      "Layer: Layer 1, Input: [0.3841630229144532, -0.8485853381942803, 0.5561148577901914, -0.42176387664501497], Output: [0.2623750529714182, 0.08127678930851998, -0.5446896966551988, 0.5747593479640367]\n",
      "Layer: Layer 2, Input: [0.2623750529714182, 0.08127678930851998, -0.5446896966551988, 0.5747593479640367], Output: [0.24794361804137013]\n",
      "Epoch 30/100, Loss: 0.886686196972625, Accuracy: -2.6405810532401857\n",
      "Power operation: base = -0.6530793669278225, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2851076460687512, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9503376582849823, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7520563819586299, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9791964932834704, -0.9993430637727244, -0.04998317399134153, -0.01999200373397513]\n",
      "Layer: Layer 1, Input: [0.9791964932834704, -0.9993430637727244, -0.04998317399134153, -0.01999200373397513], Output: [0.4463273858224872, -0.42137099764413355, -0.631028775558369, 0.7459664254685845]\n",
      "Layer: Layer 2, Input: [0.4463273858224872, -0.42137099764413355, -0.631028775558369, 0.7459664254685845], Output: [0.35663938659869787]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7953422575750229, -0.8328610005108126, 0.9974358256145205, -0.9887559987453538]\n",
      "Layer: Layer 1, Input: [0.7953422575750229, -0.8328610005108126, 0.9974358256145205, -0.9887559987453538], Output: [0.41626708475235547, 0.3691986720486894, -0.7912702397538267, 0.7849812251106332]\n",
      "Layer: Layer 2, Input: [0.41626708475235547, 0.3691986720486894, -0.7912702397538267, 0.7849812251106332], Output: [0.28776524176364104]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5341464265474094, -0.9432848132876613, -0.310290341945606, -0.3470378797431623]\n",
      "Layer: Layer 1, Input: [0.5341464265474094, -0.9432848132876613, -0.310290341945606, -0.3470378797431623], Output: [-0.05079714359393979, -0.5835311210631174, -0.5885252979024389, 0.0397011681202527]\n",
      "Layer: Layer 2, Input: [-0.05079714359393979, -0.5835311210631174, -0.5885252979024389, 0.0397011681202527], Output: [-0.06306424118638396]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.38927000475337026, -0.8499420249767078, 0.5638200703006893, -0.4138165284318174]\n",
      "Layer: Layer 1, Input: [0.38927000475337026, -0.8499420249767078, 0.5638200703006893, -0.4138165284318174], Output: [0.2748497454699714, 0.08840117083387615, -0.540865836963806, 0.586916916815989]\n",
      "Layer: Layer 2, Input: [0.2748497454699714, 0.08840117083387615, -0.540865836963806, 0.586916916815989], Output: [0.25087813739361514]\n",
      "Epoch 31/100, Loss: 0.8778210944872936, Accuracy: -2.6171834765849438\n",
      "Power operation: base = -0.6433606134013021, power = 2, grad = 0.25\n",
      "Power operation: base = 1.287765241763641, power = 2, grad = 0.25\n",
      "Power operation: base = 0.936935758813616, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7491218626063849, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9797670422980993, -0.9993597482392725, -0.028852985522215602, -0.0020197524331052527]\n",
      "Layer: Layer 1, Input: [0.9797670422980993, -0.9993597482392725, -0.028852985522215602, -0.0020197524331052527], Output: [0.46299074353793496, -0.4050157402762938, -0.623536718275577, 0.7603540983407218]\n",
      "Layer: Layer 2, Input: [0.46299074353793496, -0.4050157402762938, -0.623536718275577, 0.7603540983407218], Output: [0.36635606364284257]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7960647679278103, -0.8330849850495149, 0.9974664704721924, -0.9886349867304395]\n",
      "Layer: Layer 1, Input: [0.7960647679278103, -0.8330849850495149, 0.9974664704721924, -0.9886349867304395], Output: [0.4224783216724937, 0.368876351031236, -0.7887274701832991, 0.7861765116932242]\n",
      "Layer: Layer 2, Input: [0.4224783216724937, 0.368876351031236, -0.7887274701832991, 0.7861765116932242], Output: [0.2904845049268088]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5336354043792233, -0.9430678267712856, -0.30789010229280867, -0.3447625032670928]\n",
      "Layer: Layer 1, Input: [0.5336354043792233, -0.9430678267712856, -0.30789010229280867, -0.3447625032670928], Output: [-0.05021051742875485, -0.5821420248608198, -0.5857397923426612, 0.04191371080302269]\n",
      "Layer: Layer 2, Input: [-0.05021051742875485, -0.5821420248608198, -0.5857397923426612, 0.04191371080302269], Output: [-0.07690574262464533]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.3943453511893081, -0.8512626595709445, 0.5713221363857253, -0.4058455182273881]\n",
      "Layer: Layer 1, Input: [0.3943453511893081, -0.8512626595709445, 0.5713221363857253, -0.4058455182273881], Output: [0.28699470721026615, 0.0953343326258953, -0.5370330942996927, 0.5985699368468693]\n",
      "Layer: Layer 2, Input: [0.28699470721026615, 0.0953343326258953, -0.5370330942996927, 0.5985699368468693], Output: [0.2539180267685026]\n",
      "Epoch 32/100, Loss: 0.8688990535796867, Accuracy: -2.5933046718908184\n",
      "Power operation: base = -0.6336439363571574, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2904845049268088, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9230942573753547, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7460819732314974, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9803226266177397, -0.9993758651458476, -0.00791171520686438, 0.015897171250133412]\n",
      "Layer: Layer 1, Input: [0.9803226266177397, -0.9993758651458476, -0.00791171520686438, 0.015897171250133412], Output: [0.4791728128801788, -0.3885308118721448, -0.6159624747191098, 0.7738661667996796]\n",
      "Layer: Layer 2, Input: [0.4791728128801788, -0.3885308118721448, -0.6159624747191098, 0.7738661667996796], Output: [0.37605924874272234]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7967773275434415, -0.8332842824759735, 0.997496097576943, -0.9885136838884178]\n",
      "Layer: Layer 1, Input: [0.7967773275434415, -0.8332842824759735, 0.997496097576943, -0.9885136838884178], Output: [0.4284995143446416, 0.3685780436192639, -0.7862182222767115, 0.7872933042109007]\n",
      "Layer: Layer 2, Input: [0.4284995143446416, 0.3685780436192639, -0.7862182222767115, 0.7872933042109007], Output: [0.293254923644626]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5331034176719792, -0.9428420395487269, -0.30558713737508614, -0.34251937820011513]\n",
      "Layer: Layer 1, Input: [0.5331034176719792, -0.9428420395487269, -0.30558713737508614, -0.34251937820011513], Output: [-0.04991409499813151, -0.5808025648908519, -0.5829918906630297, 0.043740334600804155]\n",
      "Layer: Layer 2, Input: [-0.04991409499813151, -0.5808025648908519, -0.5829918906630297, 0.043740334600804155], Output: [-0.09119427797796291]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.39938874699152144, -0.8525475470851992, 0.5786245085393662, -0.39785284378266306]\n",
      "Layer: Layer 1, Input: [0.39938874699152144, -0.8525475470851992, 0.5786245085393662, -0.39785284378266306], Output: [0.29881037991602805, 0.10208198271123456, -0.5331946356287842, 0.6097328049304077]\n",
      "Layer: Layer 2, Input: [0.29881037991602805, 0.10208198271123456, -0.5331946356287842, 0.6097328049304077], Output: [0.2570575894657218]\n",
      "Epoch 33/100, Loss: 0.8599254060902609, Accuracy: -2.5689438074582185\n",
      "Power operation: base = -0.6239407512572777, power = 2, grad = 0.25\n",
      "Power operation: base = 1.293254923644626, power = 2, grad = 0.25\n",
      "Power operation: base = 0.9088057220220371, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7429424105342781, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.980863608074399, -0.9993914357600912, 0.012822706035937811, 0.03374656641085047]\n",
      "Layer: Layer 1, Input: [0.980863608074399, -0.9993914357600912, 0.012822706035937811, 0.03374656641085047], Output: [0.4948696488464433, -0.3719418763210288, -0.6083113689623784, 0.7865411300889522]\n",
      "Layer: Layer 2, Input: [0.4948696488464433, -0.3719418763210288, -0.6083113689623784, 0.7865411300889522], Output: [0.3857397290958676]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7974800093587472, -0.8334584431597103, 0.9975247324939995, -0.9883920974528033]\n",
      "Layer: Layer 1, Input: [0.7974800093587472, -0.8334584431597103, 0.9975247324939995, -0.9883920974528033], Output: [0.43433027463298823, 0.36830630642731504, -0.78374485790552, 0.7883305729708502]\n",
      "Layer: Layer 2, Input: [0.43433027463298823, 0.36830630642731504, -0.78374485790552, 0.7883305729708502], Output: [0.296067506369503]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5325504397309911, -0.9426071273517839, -0.30338249461368966, -0.3403080507840435]\n",
      "Layer: Layer 1, Input: [0.5325504397309911, -0.9426071273517839, -0.30338249461368966, -0.3403080507840435], Output: [-0.04990963469315451, -0.5795133991044986, -0.5802816544170816, 0.045178161556275014]\n",
      "Layer: Layer 2, Input: [-0.04990963469315451, -0.5795133991044986, -0.5802816544170816, 0.045178161556275014], Output: [-0.10593592717203582]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.40440005613946844, -0.8537970171402138, 0.5857312218381137, -0.3898401223542838]\n",
      "Layer: Layer 1, Input: [0.40440005613946844, -0.8537970171402138, 0.5857312218381137, -0.3898401223542838], Output: [0.3102991872381522, 0.10865027902054052, -0.529353495866807, 0.6204213685612994]\n",
      "Layer: Layer 2, Input: [0.3102991872381522, 0.10865027902054052, -0.529353495866807, 0.6204213685612994], Output: [0.26029246059095223]\n",
      "Epoch 34/100, Loss: 0.8509061179145988, Accuracy: -2.5440993895106474\n",
      "Power operation: base = -0.6142602709041324, power = 2, grad = 0.25\n",
      "Power operation: base = 1.296067506369503, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8940640728279642, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7397075394090478, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9813903457413372, -0.999406480554029, 0.03333424330304272, 0.05151689716186546]\n",
      "Layer: Layer 1, Input: [0.9813903457413372, -0.999406480554029, 0.03333424330304272, 0.05151689716186546], Output: [0.5100804131808757, -0.3552740075701206, -0.6005890227996887, 0.798419182123077]\n",
      "Layer: Layer 2, Input: [0.5100804131808757, -0.3552740075701206, -0.6005890227996887, 0.798419182123077], Output: [0.3953903269451857]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7981729588902592, -0.8336070398985163, 0.9975524037698154, -0.9882702247690838]\n",
      "Layer: Layer 1, Input: [0.7981729588902592, -0.8336070398985163, 0.9975524037698154, -0.9882702247690838], Output: [0.4399711502455968, 0.3680634653326785, -0.7813096460670558, 0.7892877707341331]\n",
      "Layer: Layer 2, Input: [0.4399711502455968, 0.3680634653326785, -0.7813096460670558, 0.7892877707341331], Output: [0.29891462949684006]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5319765995503525, -0.9423627701333847, -0.3012764543749401, -0.3381276908318101]\n",
      "Layer: Layer 1, Input: [0.5319765995503525, -0.9423627701333847, -0.3012764543749401, -0.3381276908318101], Output: [-0.05019724810074289, -0.5782747967151736, -0.5776090325051348, 0.04622673452161213]\n",
      "Layer: Layer 2, Input: [-0.05019724810074289, -0.5782747967151736, -0.5776090325051348, 0.04622673452161213], Output: [-0.12113543527234008]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.40937929850701155, -0.8550114144865166, 0.5926468190153313, -0.3818086192252055]\n",
      "Layer: Layer 1, Input: [0.40937929850701155, -0.8550114144865166, 0.5926468190153313, -0.3818086192252055], Output: [0.32146529188368245, 0.11504574255198188, -0.5255125930500004, 0.6306526133558035]\n",
      "Layer: Layer 2, Input: [0.32146529188368245, 0.11504574255198188, -0.5255125930500004, 0.6306526133558035], Output: [0.26361951798225003]\n",
      "Epoch 35/100, Loss: 0.841847802225749, Accuracy: -2.518769349297064\n",
      "Power operation: base = -0.6046096730548143, power = 2, grad = 0.25\n",
      "Power operation: base = 1.2989146294968401, power = 2, grad = 0.25\n",
      "Power operation: base = 0.87886456472766, power = 2, grad = 0.25\n",
      "Power operation: base = -0.73638048201775, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.981903193863639, -0.9994210191790148, 0.05360869145758248, 0.06919725161912856]\n",
      "Layer: Layer 1, Input: [0.981903193863639, -0.9994210191790148, 0.05360869145758248, 0.06919725161912856], Output: [0.5248070248594277, -0.3385515282955972, -0.592801366330281, 0.8095414388568333]\n",
      "Layer: Layer 2, Input: [0.5248070248594277, -0.3385515282955972, -0.592801366330281, 0.8095414388568333], Output: [0.40500571310119177]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7988563886371216, -0.8337296618174022, 0.9975791425835981, -0.9881480538258719]\n",
      "Layer: Layer 1, Input: [0.7988563886371216, -0.8337296618174022, 0.9975791425835981, -0.9881480538258719], Output: [0.44542349448721225, 0.3678516131355588, -0.7789147699708583, 0.7901647993175003]\n",
      "Layer: Layer 2, Input: [0.44542349448721225, 0.3678516131355588, -0.7789147699708583, 0.7901647993175003], Output: [0.3017898886995143]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.531382178405831, -0.9421086506588147, -0.2992685459171243, -0.3359771235127562]\n",
      "Layer: Layer 1, Input: [0.531382178405831, -0.9421086506588147, -0.2992685459171243, -0.3359771235127562], Output: [-0.05077550230748025, -0.5770866438269734, -0.5749738852555996, 0.04688791769139043]\n",
      "Layer: Layer 2, Input: [-0.05077550230748025, -0.5770866438269734, -0.5749738852555996, 0.04688791769139043], Output: [-0.13679621580152554]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.41432662754788774, -0.8561910905862447, 0.5993762787188991, -0.3737592783314765]\n",
      "Layer: Layer 1, Input: [0.41432662754788774, -0.8561910905862447, 0.5993762787188991, -0.3737592783314765], Output: [0.3323143614222139, 0.12127517621949342, -0.5216747427071662, 0.6404443779440356]\n",
      "Layer: Layer 2, Input: [0.3323143614222139, 0.12127517621949342, -0.5216747427071662, 0.6404443779440356], Output: [0.26703678678074244]\n",
      "Epoch 36/100, Loss: 0.8327577401874451, Accuracy: -2.4929511730160545\n",
      "Power operation: base = -0.5949942868988083, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3017898886995143, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8632037841984744, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7329632132192576, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9824025001433949, -0.9994350704516476, 0.07363359312007746, 0.08677729848562546]\n",
      "Layer: Layer 1, Input: [0.9824025001433949, -0.9994350704516476, 0.07363359312007746, 0.08677729848562546], Output: [0.5390538147025585, -0.32179787389318554, -0.5849546457421592, 0.8199492794311656]\n",
      "Layer: Layer 2, Input: [0.5390538147025585, -0.32179787389318554, -0.5849546457421592, 0.8199492794311656], Output: [0.41458220840682697]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.7995305727298221, -0.8338259086908172, 0.9976049824188536, -0.9880255638243429]\n",
      "Layer: Layer 1, Input: [0.7995305727298221, -0.8338259086908172, 0.9976049824188536, -0.9880255638243429], Output: [0.4506893436166612, 0.36767260832795745, -0.7765623330254928, 0.790961975540799]\n",
      "Layer: Layer 2, Input: [0.4506893436166612, 0.36767260832795745, -0.7765623330254928, 0.790961975540799], Output: [0.3046879547883588]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5307676065506199, -0.9418444531488891, -0.2973575671079343, -0.3338548610372419]\n",
      "Layer: Layer 1, Input: [0.5307676065506199, -0.9418444531488891, -0.2973575671079343, -0.3338548610372419], Output: [-0.0516415206810947, -0.57594845175663, -0.5723760055662321, 0.047165791585162944]\n",
      "Layer: Layer 2, Input: [-0.0516415206810947, -0.57594845175663, -0.5723760055662321, 0.047165791585162944], Output: [-0.15292034205850688]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.41924230907570964, -0.8573363961113866, 0.6059249475547983, -0.3656927543341442]\n",
      "Layer: Layer 1, Input: [0.41924230907570964, -0.8573363961113866, 0.6059249475547983, -0.3656927543341442], Output: [0.342853345189167, 0.12734558964740497, -0.5178426711668908, 0.6498150977206787]\n",
      "Layer: Layer 2, Input: [0.342853345189167, 0.12734558964740497, -0.5178426711668908, 0.6498150977206787], Output: [0.27054333873158337]\n",
      "Epoch 37/100, Loss: 0.8236439044127002, Accuracy: -2.466642065591442\n",
      "Power operation: base = -0.5854177915931731, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3046879547883588, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8470796579414931, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7294566612684166, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9828886043519971, -0.9994486523491731, 0.09339814445054635, 0.10424724273543803]\n",
      "Layer: Layer 1, Input: [0.9828886043519971, -0.9994486523491731, 0.09339814445054635, 0.10424724273543803], Output: [0.5528271905058887, -0.30503548189129503, -0.5770554280052106, 0.8296837969710807]\n",
      "Layer: Layer 2, Input: [0.5528271905058887, -0.30503548189129503, -0.5770554280052106, 0.8296837969710807], Output: [0.4241175793352768]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8001958418233576, -0.8338953856763809, 0.9976299587563473, -0.9879027257741542]\n",
      "Layer: Layer 1, Input: [0.8001958418233576, -0.8338953856763809, 0.9976299587563473, -0.9879027257741542], Output: [0.4557713022306874, 0.3675280746737819, -0.7742543635885144, 0.7916799974206049]\n",
      "Layer: Layer 2, Input: [0.4557713022306874, 0.3675280746737819, -0.7742543635885144, 0.7916799974206049], Output: [0.3076044347852633]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5301334599861701, -0.9415698619742167, -0.2955416072489425, -0.331759133854793]\n",
      "Layer: Layer 1, Input: [0.5301334599861701, -0.9415698619742167, -0.2955416072489425, -0.331759133854793], Output: [-0.05279108131610324, -0.574859367712428, -0.5698151371047026, 0.04706654538017759]\n",
      "Layer: Layer 2, Input: [-0.05279108131610324, -0.574859367712428, -0.5698151371047026, 0.04706654538017759], Output: [-0.1695085281882493]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4241267012104112, -0.8584476743076205, 0.612298476346359, -0.35760944553214447]\n",
      "Layer: Layer 1, Input: [0.4241267012104112, -0.8584476743076205, 0.612298476346359, -0.35760944553214447], Output: [0.3530902640311081, 0.13326413001391987, -0.5140190275710499, 0.6587835777296487]\n",
      "Layer: Layer 2, Input: [0.3530902640311081, 0.13326413001391987, -0.5140190275710499, 0.6587835777296487], Output: [0.27413918742521654]\n",
      "Epoch 38/100, Loss: 0.8145149810711305, Accuracy: -2.4398391398365207\n",
      "Power operation: base = -0.5758824206647233, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3076044347852633, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8304914718117506, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7258608125747834, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9833618372419584, -0.9994617820129976, 0.11289309204946468, 0.1215977817257809]\n",
      "Layer: Layer 1, Input: [0.9833618372419584, -0.9994617820129976, 0.11289309204946468, 0.1215977817257809], Output: [0.5661353177291162, -0.28828570617540217, -0.5691106022059871, 0.838785351808034]\n",
      "Layer: Layer 2, Input: [0.5661353177291162, -0.28828570617540217, -0.5691106022059871, 0.838785351808034], Output: [0.43361083308154325]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8008525782271726, -0.8339376984444689, 0.9976541087890526, -0.9877795031054131]\n",
      "Layer: Layer 1, Input: [0.8008525782271726, -0.8339376984444689, 0.9976541087890526, -0.9877795031054131], Output: [0.46067243686583537, 0.36741940135201445, -0.7719928183837206, 0.7923199112772745]\n",
      "Layer: Layer 2, Input: [0.46067243686583537, 0.36741940135201445, -0.7719928183837206, 0.7923199112772745], Output: [0.3105357387684972]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5294804572690865, -0.94128456039836, -0.29381807241576663, -0.3296879210594659]\n",
      "Layer: Layer 1, Input: [0.5294804572690865, -0.94128456039836, -0.29381807241576663, -0.3296879210594659], Output: [-0.05421871259238797, -0.5738181875007211, -0.5672909896234014, 0.04659836874850459]\n",
      "Layer: Layer 2, Input: [-0.05421871259238797, -0.5738181875007211, -0.5672909896234014, 0.04659836874850459], Output: [-0.18656010172223708]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.42898023554166737, -0.8595252551706529, 0.6185027608768137, -0.3495095270787866]\n",
      "Layer: Layer 1, Input: [0.42898023554166737, -0.8595252551706529, 0.6185027608768137, -0.3495095270787866], Output: [0.3630340140265792, 0.1390380189063869, -0.5102063944110303, 0.6673687940071731]\n",
      "Layer: Layer 2, Input: [0.3630340140265792, 0.1390380189063869, -0.5102063944110303, 0.6673687940071731], Output: [0.277825180686911]\n",
      "Epoch 39/100, Loss: 0.8053803871880261, Accuracy: -2.412539623277806\n",
      "Power operation: base = -0.5663891669184568, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3105357387684973, power = 2, grad = 0.25\n",
      "Power operation: base = 0.8134398982777629, power = 2, grad = 0.25\n",
      "Power operation: base = -0.722174819313089, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9838225197309061, -0.999474475759082, 0.13211062401593548, 0.13882006287727064]\n",
      "Layer: Layer 1, Input: [0.9838225197309061, -0.999474475759082, 0.13211062401593548, 0.13882006287727064], Output: [0.5789878195084589, -0.27156875482331005, -0.5611273772891444, 0.8472932179028143]\n",
      "Layer: Layer 2, Input: [0.5789878195084589, -0.27156875482331005, -0.5611273772891444, 0.8472932179028143], Output: [0.4430620165849134]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8015012112586752, -0.833952448684575, 0.9976774711589208, -0.987655852287734]\n",
      "Layer: Layer 1, Input: [0.8015012112586752, -0.833952448684575, 0.9976774711589208, -0.987655852287734], Output: [0.4653961778158294, 0.3673477434629207, -0.7697795845314229, 0.7928830802121933]\n",
      "Layer: Layer 2, Input: [0.4653961778158294, 0.3673477434629207, -0.7697795845314229, 0.7928830802121933], Output: [0.31347895290471917]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5288094563047225, -0.9409882293663989, -0.2921837128057686, -0.32763897977095596]\n",
      "Layer: Layer 1, Input: [0.5288094563047225, -0.9409882293663989, -0.2921837128057686, -0.32763897977095596], Output: [-0.055917785539710885, -0.5728233699492614, -0.5648032514928997, 0.04577134465198032]\n",
      "Layer: Layer 2, Input: [-0.055917785539710885, -0.5728233699492614, -0.5648032514928997, 0.04577134465198032], Output: [-0.20407296932518246]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.43380339954039726, -0.8605694503804694, 0.624543887238794, -0.3413929840344062]\n",
      "Layer: Layer 1, Input: [0.43380339954039726, -0.8605694503804694, 0.624543887238794, -0.3413929840344062], Output: [0.37269418478730465, 0.14467449503615892, -0.5064072964516658, 0.6755897219932893]\n",
      "Layer: Layer 2, Input: [0.37269418478730465, 0.14467449503615892, -0.5064072964516658, 0.6755897219932893], Output: [0.28160289124133425]\n",
      "Epoch 40/100, Loss: 0.7962502802814456, Accuracy: -2.384741075753289\n",
      "Power operation: base = -0.5569379834150866, power = 2, grad = 0.25\n",
      "Power operation: base = 1.313478952904719, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7959270306748175, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7183971087586658, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9842709623309829, -0.9994867490940924, 0.1510442578730273, 0.15590564387245243]\n",
      "Layer: Layer 1, Input: [0.9842709623309829, -0.9994867490940924, 0.1510442578730273, 0.15590564387245243], Output: [0.5913954986043475, -0.2549036498882246, -0.553113276010455, 0.8552453121671021]\n",
      "Layer: Layer 2, Input: [0.5913954986043475, -0.2549036498882246, -0.553113276010455, 0.8552453121671021], Output: [0.4524720229920342]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.802142212802737, -0.8339392299666417, 0.9977000857146981, -0.9875317234488552]\n",
      "Layer: Layer 1, Input: [0.802142212802737, -0.8339392299666417, 0.9977000857146981, -0.9875317234488552], Output: [0.46994622900718636, 0.36731402274320557, -0.7676164801774094, 0.7933711542309001]\n",
      "Layer: Layer 2, Input: [0.46994622900718636, 0.36731402274320557, -0.7676164801774094, 0.7933711542309001], Output: [0.3164317189385553]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5281214510693314, -0.940680546334259, -0.2906346516713873, -0.3256098733269709]\n",
      "Layer: Layer 1, Input: [0.5281214510693314, -0.940680546334259, -0.2906346516713873, -0.3256098733269709], Output: [-0.057880602914552076, -0.5718730527618966, -0.5623515996000509, 0.04459734392542197]\n",
      "Layer: Layer 2, Input: [-0.057880602914552076, -0.5718730527618966, -0.5623515996000509, 0.04459734392542197], Output: [-0.2220435775231468]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.43859672023321544, -0.8615805489384323, 0.6304280817925868, -0.3332596438559638]\n",
      "Layer: Layer 1, Input: [0.43859672023321544, -0.8615805489384323, 0.6304280817925868, -0.3332596438559638], Output: [0.38208089250890487, 0.15018076257193244, -0.5026242079561128, 0.6834651901253823]\n",
      "Layer: Layer 2, Input: [0.38208089250890487, 0.15018076257193244, -0.5026242079561128, 0.6834651901253823], Output: [0.28547450665638224]\n",
      "Epoch 41/100, Loss: 0.7871355580362198, Accuracy: -2.356441611766992\n",
      "Power operation: base = -0.5475279770079657, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3164317189385553, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7779564224768531, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7145254933436178, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9847074647977749, -0.9994986167363102, 0.1696887277253938, 0.17284645613754263]\n",
      "Layer: Layer 1, Input: [0.9847074647977749, -0.9994986167363102, 0.1696887277253938, 0.17284645613754263], Output: [0.6033700828908887, -0.23830820712513925, -0.5450761249517906, 0.8626779960278377]\n",
      "Layer: Layer 2, Input: [0.6033700828908887, -0.23830820712513925, -0.5450761249517906, 0.8626779960278377], Output: [0.461842408201517]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8027760930565198, -0.8338976239336008, 0.9977219932895341, -0.9874070609866396]\n",
      "Layer: Layer 1, Input: [0.8027760930565198, -0.8338976239336008, 0.9977219932895341, -0.9874070609866396], Output: [0.4743264856603415, 0.3673189283790055, -0.7655052537433882, 0.7937860421387073]\n",
      "Layer: Layer 2, Input: [0.4743264856603415, 0.3673189283790055, -0.7655052537433882, 0.7937860421387073], Output: [0.3193921202819515]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5274175681959337, -0.9403611841331743, -0.289166415500338, -0.3235979981796991]\n",
      "Layer: Layer 1, Input: [0.5274175681959337, -0.9403611841331743, -0.289166415500338, -0.3235979981796991], Output: [-0.060098485070735855, -0.5709650695474471, -0.5599357067896702, 0.04308992195369718]\n",
      "Layer: Layer 2, Input: [-0.060098485070735855, -0.5709650695474471, -0.5599357067896702, 0.04308992195369718], Output: [-0.24046687023485358]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4433607491421389, -0.8625588134526533, 0.6361616656368999, -0.32510920798749465]\n",
      "Layer: Layer 1, Input: [0.4433607491421389, -0.8625588134526533, 0.6361616656368999, -0.32510920798749465], Output: [0.3912046275982779, 0.1555639447874993, -0.4988595581704585, 0.6910137564213652]\n",
      "Layer: Layer 2, Input: [0.3912046275982779, 0.1555639447874993, -0.4988595581704585, 0.6910137564213652], Output: [0.2894427194348551]\n",
      "Epoch 42/100, Loss: 0.7780478462118549, Accuracy: -2.327640122410726\n",
      "Power operation: base = -0.538157591798483, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3193921202819516, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7595331297651464, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7105572805651449, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.985132315974005, -0.9995100926404054, 0.18803987267019356, 0.18963477219750047]\n",
      "Layer: Layer 1, Input: [0.985132315974005, -0.9995100926404054, 0.18803987267019356, 0.18963477219750047], Output: [0.6149239951473785, -0.2217990334265354, -0.5370240404983957, 0.8696259387641436]\n",
      "Layer: Layer 2, Input: [0.6149239951473785, -0.2217990334265354, -0.5370240404983957, 0.8696259387641436], Output: [0.4711752193595021]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8034033964373045, -0.8338271968001588, 0.9977432354967802, -0.9872818041694632]\n",
      "Layer: Layer 1, Input: [0.8034033964373045, -0.8338271968001588, 0.9977432354967802, -0.9872818041694632], Output: [0.4785409593844116, 0.3673629178452088, -0.7634475818553366, 0.7941298852184815]\n",
      "Layer: Layer 2, Input: [0.4785409593844116, 0.3673629178452088, -0.7634475818553366, 0.7941298852184815], Output: [0.32235857473954627]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5266990633546851, -0.94002980986285, -0.2877739651795197, -0.3216006094361264]\n",
      "Layer: Layer 1, Input: [0.5266990633546851, -0.94002980986285, -0.2877739651795197, -0.3216006094361264], Output: [-0.06256185283876443, -0.5700969677937643, -0.5575552470531194, 0.041264217331299584]\n",
      "Layer: Layer 2, Input: [-0.06256185283876443, -0.5700969677937643, -0.5575552470531194, 0.041264217331299584], Output: [-0.25933624496767327]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4480960484830373, -0.8635044770184569, 0.6417510134212324, -0.31694128227138757]\n",
      "Layer: Layer 1, Input: [0.4480960484830373, -0.8635044770184569, 0.6417510134212324, -0.31694128227138757], Output: [0.4000761164515193, 0.16083104268098103, -0.49511573506827716, 0.6982536057126538]\n",
      "Layer: Layer 2, Input: [0.4000761164515193, 0.16083104268098103, -0.49511573506827716, 0.6982536057126538], Output: [0.2935106179938524]\n",
      "Epoch 43/100, Loss: 0.7689994734281725, Accuracy: -2.298336492418519\n",
      "Power operation: base = -0.528824780640498, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3223585747395463, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7406637550323267, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7064893820061475, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9855457938045055, -0.9995211900252859, 0.20609452815116008, 0.20626317733281535]\n",
      "Layer: Layer 1, Input: [0.9855457938045055, -0.9995211900252859, 0.20609452815116008, 0.20626317733281535], Output: [0.626070147223385, -0.2053915396038954, -0.528965410732384, 0.8761220327093291]\n",
      "Layer: Layer 2, Input: [0.626070147223385, -0.2053915396038954, -0.528965410732384, 0.8761220327093291], Output: [0.4804728365209042]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8040246976306816, -0.8337274961323581, 0.9977638545421494, -0.9871558877210108]\n",
      "Layer: Layer 1, Input: [0.8040246976306816, -0.8337274961323581, 0.9977638545421494, -0.9871558877210108], Output: [0.48259371030649467, 0.36744621773548974, -0.761445066035983, 0.794405032613668]\n",
      "Layer: Layer 2, Input: [0.48259371030649467, 0.36744621773548974, -0.761445066035983, 0.794405032613668], Output: [0.3253297338267588]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5259673173566294, -0.9396860838062684, -0.28645172794468965, -0.31961484501863596]\n",
      "Layer: Layer 1, Input: [0.5259673173566294, -0.9396860838062684, -0.28645172794468965, -0.31961484501863596], Output: [-0.06526030772059115, -0.5692660275840012, -0.5552098986836151, 0.03913685208606453]\n",
      "Layer: Layer 2, Input: [-0.06526030772059115, -0.5692660275840012, -0.5552098986836151, 0.03913685208606453], Output: [-0.27864350956154355]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4528031786108589, -0.8644177406428161, 0.6472025162760193, -0.3087554059486658]\n",
      "Layer: Layer 1, Input: [0.4528031786108589, -0.8644177406428161, 0.6472025162760193, -0.3087554059486658], Output: [0.4087061967823966, 0.1659888982049701, -0.491395087391945, 0.7052024651657666]\n",
      "Layer: Layer 2, Input: [0.4087061967823966, 0.1659888982049701, -0.491395087391945, 0.7052024651657666], Output: [0.2976815791625791]\n",
      "Epoch 44/100, Loss: 0.7600034318757996, Accuracy: -2.2685318085817316\n",
      "Power operation: base = -0.5195271634790958, power = 2, grad = 0.25\n",
      "Power operation: base = 1.325329733826759, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7213564904384564, power = 2, grad = 0.25\n",
      "Power operation: base = -0.7023184208374209, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9859481655003542, -0.9995319214043284, 0.22385042163541782, 0.2227245458189606]\n",
      "Layer: Layer 1, Input: [0.9859481655003542, -0.9995319214043284, 0.22385042163541782, 0.2227245458189606], Output: [0.636821758107622, -0.18909996610871424, -0.5209088732532496, 0.8821973512146392]\n",
      "Layer: Layer 2, Input: [0.636821758107622, -0.18909996610871424, -0.5209088732532496, 0.8821973512146392], Output: [0.48973782815816047]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8046405977573448, -0.8335980478824665, 0.9977838930502959, -0.9870292423863273]\n",
      "Layer: Layer 1, Input: [0.8046405977573448, -0.8335980478824665, 0.9977838930502959, -0.9870292423863273], Output: [0.48648878581552096, 0.36756882457948553, -0.7594992282735494, 0.7946140182805725]\n",
      "Layer: Layer 2, Input: [0.48648878581552096, 0.36756882457948553, -0.7594992282735494, 0.7946140182805725], Output: [0.32830438858440036]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5252238319102833, -0.939329658358618, -0.28519362997125686, -0.3176377484495151]\n",
      "Layer: Layer 1, Input: [0.5252238319102833, -0.939329658358618, -0.28519362997125686, -0.3176377484495151], Output: [-0.06818270975915092, -0.5684692808746821, -0.5528993456275649, 0.036725832847640645]\n",
      "Layer: Layer 2, Input: [-0.06818270975915092, -0.5684692808746821, -0.5528993456275649, 0.036725832847640645], Output: [-0.2983788413595608]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4574826866970029, -0.8652987711641961, 0.6525225486029899, -0.3005510790567999]\n",
      "Layer: Layer 1, Input: [0.4574826866970029, -0.8652987711641961, 0.6525225486029899, -0.3005510790567999], Output: [0.41710570579537615, 0.17104416174712742, -0.48769992505906606, 0.7118775358056112]\n",
      "Layer: Layer 2, Input: [0.41710570579537615, 0.17104416174712742, -0.48769992505906606, 0.7118775358056112], Output: [0.30195916274630163]\n",
      "Epoch 45/100, Loss: 0.7510733233677813, Accuracy: -2.2382285563203776\n",
      "Power operation: base = -0.5102621718418395, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3283043885844004, power = 2, grad = 0.25\n",
      "Power operation: base = 0.7016211586404393, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6980408372536984, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9863396878314299, -0.9995422986173799, 0.24130607370771462, 0.23901202189635118]\n",
      "Layer: Layer 1, Input: [0.9863396878314299, -0.9995422986173799, 0.24130607370771462, 0.23901202189635118], Output: [0.6471921950216767, -0.1729374193168984, -0.5128632889958955, 0.8878811412087706]\n",
      "Layer: Layer 2, Input: [0.6471921950216767, -0.1729374193168984, -0.5128632889958955, 0.8878811412087706], Output: [0.4989728207830514]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8052517206386635, -0.8334383536542048, 0.9978033939038514, -0.9869017954766274]\n",
      "Layer: Layer 1, Input: [0.8052517206386635, -0.8334383536542048, 0.9978033939038514, -0.9869017954766274], Output: [0.4902301655005343, 0.36773050567162907, -0.757611505600876, 0.7947595393388989]\n",
      "Layer: Layer 2, Input: [0.4902301655005343, 0.36773050567162907, -0.757611505600876, 0.7947595393388989], Output: [0.331281381765515]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5244702249634358, -0.9389601769625001, -0.283993129502476, -0.3156662902818301]\n",
      "Layer: Layer 1, Input: [0.5244702249634358, -0.9389601769625001, -0.283993129502476, -0.3156662902818301], Output: [-0.07131725345945991, -0.5677035311736098, -0.5506232772648012, 0.03405045223816041]\n",
      "Layer: Layer 2, Input: [-0.07131725345945991, -0.5677035311736098, -0.5506232772648012, 0.03405045223816041], Output: [-0.31853075064716707]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4621350966235833, -0.8661476996220329, 0.6577174384506462, -0.2923277880667772]\n",
      "Layer: Layer 1, Input: [0.4621350966235833, -0.8661476996220329, 0.6577174384506462, -0.2923277880667772], Output: [0.42528538044653497, 0.17600326351497955, -0.48403251802901615, 0.718295437895892]\n",
      "Layer: Layer 2, Input: [0.42528538044653497, 0.17600326351497955, -0.48403251802901615, 0.718295437895892], Output: [0.306347008649521]\n",
      "Epoch 46/100, Loss: 0.7422232904931431, Accuracy: -2.207430801685775\n",
      "Power operation: base = -0.5010271792169486, power = 2, grad = 0.25\n",
      "Power operation: base = 1.331281381765515, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6814692493528329, power = 2, grad = 0.25\n",
      "Power operation: base = -0.693652991350479, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9867206075279985, -0.9995523328640046, 0.2584607054189639, 0.2551190054992463]\n",
      "Layer: Layer 1, Input: [0.9867206075279985, -0.9995523328640046, 0.2584607054189639, 0.2551190054992463], Output: [0.6571948363645997, -0.15691591609039532, -0.5048377121788185, 0.8932008431755993]\n",
      "Layer: Layer 2, Input: [0.6571948363645997, -0.15691591609039532, -0.5048377121788185, 0.8932008431755993], Output: [0.5081803826359648]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8058587091439328, -0.833247888174024, 0.9978224000930144, -0.986773471390863]\n",
      "Layer: Layer 1, Input: [0.8058587091439328, -0.833247888174024, 0.9978224000930144, -0.986773471390863], Output: [0.4938217118781459, 0.3679307999601682, -0.7557832438372756, 0.7948444356348316]\n",
      "Layer: Layer 2, Input: [0.4938217118781459, 0.3679307999601682, -0.7557832438372756, 0.7948444356348316], Output: [0.3342595262632453]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5237082255676738, -0.9385772730413575, -0.2828432504402769, -0.31369738821094634]\n",
      "Layer: Layer 1, Input: [0.5237082255676738, -0.9385772730413575, -0.2828432504402769, -0.31369738821094634], Output: [-0.07465154212559677, -0.5669653734699345, -0.5483813868492738, 0.0311311897462513]\n",
      "Layer: Layer 2, Input: [-0.07465154212559677, -0.5669653734699345, -0.5483813868492738, 0.0311311897462513], Output: [-0.33908605012891296]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4667609000799211, -0.866964620032928, 0.6627934411953033, -0.28408502962825555]\n",
      "Layer: Layer 1, Input: [0.4667609000799211, -0.866964620032928, 0.6627934411953033, -0.28408502962825555], Output: [0.43325576902782076, 0.18087238850329576, -0.4803950937466938, 0.7244721682191401]\n",
      "Layer: Layer 2, Input: [0.43325576902782076, 0.18087238850329576, -0.4803950937466938, 0.7244721682191401], Output: [0.3108487370235473]\n",
      "Epoch 47/100, Loss: 0.7334679329611419, Accuracy: -2.17614435647482\n",
      "Power operation: base = -0.49181961736403523, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3342595262632453, power = 2, grad = 0.25\n",
      "Power operation: base = 0.660913949871087, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6891512629764527, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9870911617732167, -0.9995620347375122, 0.27531415249524144, 0.27103914266530865]\n",
      "Layer: Layer 1, Input: [0.9870911617732167, -0.9995620347375122, 0.27531415249524144, 0.27103914266530865], Output: [0.6668429551345397, -0.1410464344671132, -0.49684135657909506, 0.8981821323527238]\n",
      "Layer: Layer 2, Input: [0.6668429551345397, -0.1410464344671132, -0.49684135657909506, 0.8981821323527238], Output: [0.5173629211755271]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8064622216055142, -0.8330260969449645, 0.9978409545739092, -0.9866441921124198]\n",
      "Layer: Layer 1, Input: [0.8064622216055142, -0.8330260969449645, 0.9978409545739092, -0.9866441921124198], Output: [0.49726712652854427, 0.3681690190648196, -0.7540156906600051, 0.7948716703328224]\n",
      "Layer: Layer 2, Input: [0.49726712652854427, 0.3681690190648196, -0.7540156906600051, 0.7948716703328224], Output: [0.33723752965836445]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5229396682102502, -0.9381805689229278, -0.28173661634195435, -0.3117279259071885]\n",
      "Layer: Layer 1, Input: [0.5229396682102502, -0.9381805689229278, -0.28173661634195435, -0.3117279259071885], Output: [-0.07817266094128565, -0.5662512142791655, -0.5461733688365582, 0.02798961140324581]\n",
      "Layer: Layer 2, Input: [-0.07817266094128565, -0.5662512142791655, -0.5461733688365582, 0.02798961140324581], Output: [-0.3600298321010313]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4713605488476406, -0.867749588533342, 0.6677567162536486, -0.27582233231395503]\n",
      "Layer: Layer 1, Input: [0.4713605488476406, -0.867749588533342, 0.6677567162536486, -0.27582233231395503], Output: [0.44102715333326276, 0.18565745475399548, -0.4767898332985211, 0.7304230675111869]\n",
      "Layer: Layer 2, Input: [0.44102715333326276, 0.18565745475399548, -0.4767898332985211, 0.7304230675111869], Output: [0.3154678518986433]\n",
      "Epoch 48/100, Loss: 0.7248222095419794, Accuracy: -2.144376924483163\n",
      "Power operation: base = -0.48263707882447293, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3372375296583645, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6399701678989687, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6845321481013567, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987451578769625, -0.9995714142593658, 0.2918667868082054, 0.28676632045248324]\n",
      "Layer: Layer 1, Input: [0.987451578769625, -0.9995714142593658, 0.2918667868082054, 0.28676632045248324], Output: [0.676149621330815, -0.1253389685034492, -0.4888835583958571, 0.9028489758849609]\n",
      "Layer: Layer 2, Input: [0.676149621330815, -0.1253389685034492, -0.4888835583958571, 0.9028489758849609], Output: [0.5265225939532164]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8070629282917198, -0.83277239406044, 0.9978591001340988, -0.9865138776795721]\n",
      "Layer: Layer 1, Input: [0.8070629282917198, -0.83277239406044, 0.9978591001340988, -0.9865138776795721], Output: [0.5005699112892069, 0.3684442485072257, -0.7523099881831612, 0.7948443113670604]\n",
      "Layer: Layer 2, Input: [0.5005699112892069, 0.3684442485072257, -0.7523099881831612, 0.7948443113670604], Output: [0.3402139247868249]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5221664865666767, -0.9377696747444312, -0.28066548477443864, -0.30975477061215423]\n",
      "Layer: Layer 1, Input: [0.5221664865666767, -0.9377696747444312, -0.28066548477443864, -0.30975477061215423], Output: [-0.08186724906699046, -0.5655572916732517, -0.5439989153162921, 0.024648267698165142]\n",
      "Layer: Layer 2, Input: [-0.08186724906699046, -0.5655572916732517, -0.5439989153162921, 0.024648267698165142], Output: [-0.38134545482974347]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.47593444826144204, -0.868502622851011, 0.6726133065654459, -0.2675392762733666]\n",
      "Layer: Layer 1, Input: [0.47593444826144204, -0.868502622851011, 0.6726133065654459, -0.2675392762733666], Output: [0.4486094807092857, 0.1903640946539559, -0.4732188664299626, 0.7361627965269165]\n",
      "Layer: Layer 2, Input: [0.4486094807092857, 0.1903640946539559, -0.4732188664299626, 0.7361627965269165], Output: [0.32020764877323316]\n",
      "Epoch 49/100, Loss: 0.7163013263188822, Accuracy: -2.1121382272306315\n",
      "Power operation: base = -0.47347740604678357, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3402139247868248, power = 2, grad = 0.25\n",
      "Power operation: base = 0.6186545451702565, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6797923512267668, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.987802078363787, -0.9995804809136224, 0.30811944532640784, 0.30229466610556177]\n",
      "Layer: Layer 1, Input: [0.987802078363787, -0.9995804809136224, 0.30811944532640784, 0.30229466610556177], Output: [0.685127621777426, -0.10980258549278778, -0.4809737360289865, 0.9072237015247203]\n",
      "Layer: Layer 2, Input: [0.685127621777426, -0.10980258549278778, -0.4809737360289865, 0.9072237015247203], Output: [0.5356612323659872]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.807661507931059, -0.8324861601559475, 0.9978768792638341, -0.9863824466285229]\n",
      "Layer: Layer 1, Input: [0.807661507931059, -0.8324861601559475, 0.9978768792638341, -0.9863824466285229], Output: [0.5037333341863404, 0.3687553492497987, -0.7506671652291805, 0.7947655136079907]\n",
      "Layer: Layer 2, Input: [0.5037333341863404, 0.3687553492497987, -0.7506671652291805, 0.7947655136079907], Output: [0.34318700625626164]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5213907066375957, -0.9373441873311192, -0.27962178197856014, -0.3077747895402792]\n",
      "Layer: Layer 1, Input: [0.5213907066375957, -0.9373441873311192, -0.27962178197856014, -0.3077747895402792], Output: [-0.0857215709594308, -0.5648796951709274, -0.5418577117570719, 0.021130589331313118]\n",
      "Layer: Layer 2, Input: [-0.0857215709594308, -0.5648796951709274, -0.5418577117570719, 0.021130589331313118], Output: [-0.40301453946151905]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4804829518323802, -0.8692237020693496, 0.6773691206022827, -0.2592355107227181]\n",
      "Layer: Layer 1, Input: [0.4804829518323802, -0.8692237020693496, 0.6773691206022827, -0.2592355107227181], Output: [0.4560123053460241, 0.1949976390525775, -0.4696842655847434, 0.741705319433796]\n",
      "Layer: Layer 2, Input: [0.4560123053460241, 0.1949976390525775, -0.4696842655847434, 0.741705319433796], Output: [0.32507112665592586]\n",
      "Epoch 50/100, Loss: 0.7079206122678441, Accuracy: -2.0794401077728297\n",
      "Power operation: base = -0.46433876763401283, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3431870062562616, power = 2, grad = 0.25\n",
      "Power operation: base = 0.596985460538481, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6749288733440741, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9881428727142247, -0.9995892436811017, 0.3240733666066868, 0.31761855014060575]\n",
      "Layer: Layer 1, Input: [0.9881428727142247, -0.9995892436811017, 0.3240733666066868, 0.31761855014060575], Output: [0.6937893957924072, -0.09444548399943331, -0.4731213471634171, 0.9113270742415915]\n",
      "Layer: Layer 2, Input: [0.6937893957924072, -0.09444548399943331, -0.4731213471634171, 0.9113270742415915], Output: [0.5447802777298112]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8082586442851089, -0.8321667404771531, 0.9978943340318449, -0.9862498164079926]\n",
      "Layer: Layer 1, Input: [0.8082586442851089, -0.8321667404771531, 0.9978943340318449, -0.9862498164079926], Output: [0.5067603998128735, 0.3691009596456362, -0.749088129481935, 0.794638501630019]\n",
      "Layer: Layer 2, Input: [0.5067603998128735, 0.3691009596456362, -0.749088129481935, 0.794638501630019], Output: [0.3461547728710872]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.52061443924466, -0.9369036890397106, -0.2785971377904699, -0.30578486512458575]\n",
      "Layer: Layer 1, Input: [0.52061443924466, -0.9369036890397106, -0.2785971377904699, -0.30578486512458575], Output: [-0.08972158704579383, -0.5642143853673135, -0.5397494322589347, 0.017460780600452124]\n",
      "Layer: Layer 2, Input: [-0.08972158704579383, -0.5642143853673135, -0.5397494322589347, 0.017460780600452124], Output: [-0.4250169785763641]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4850063570187438, -0.8699127666507145, 0.6820299166780048, -0.2509107692141398]\n",
      "Layer: Layer 1, Input: [0.4850063570187438, -0.8699127666507145, 0.6820299166780048, -0.2509107692141398], Output: [0.4632447382248634, 0.19956310401623795, -0.46618803913382373, 0.7470638934379753]\n",
      "Layer: Layer 2, Input: [0.4632447382248634, 0.19956310401623795, -0.46618803913382373, 0.7470638934379753], Output: [0.3300609050835712]\n",
      "Epoch 51/100, Loss: 0.6996953834725634, Accuracy: -2.0462966114813406\n",
      "Power operation: base = -0.4552197222701888, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3461547728710872, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5749830214236359, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6699390949164288, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.988474166988707, -0.9995977110730153, 0.33973013474370645, 0.3327325929510305]\n",
      "Layer: Layer 1, Input: [0.988474166988707, -0.9995977110730153, 0.33973013474370645, 0.3327325929510305], Output: [0.7021469851444181, -0.07927505137273329, -0.4653358436101005, 0.9151783777814824]\n",
      "Layer: Layer 2, Input: [0.7021469851444181, -0.07927505137273329, -0.4653358436101005, 0.9151783777814824], Output: [0.5538807290951675]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8088550227706441, -0.8318134430429472, 0.9979115059647039, -0.9861159037644416]\n",
      "Layer: Layer 1, Input: [0.8088550227706441, -0.8318134430429472, 0.9979115059647039, -0.9861159037644416], Output: [0.5096538238860748, 0.36947949790487905, -0.7475736597106335, 0.7944665530008487]\n",
      "Layer: Layer 2, Input: [0.5096538238860748, 0.36947949790487905, -0.7475736597106335, 0.7944665530008487], Output: [0.3491148759542952]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5198398718720381, -0.9364477465580886, -0.2775829207580656, -0.30378190914207986]\n",
      "Layer: Layer 1, Input: [0.5198398718720381, -0.9364477465580886, -0.2775829207580656, -0.30378190914207986], Output: [-0.09385302380986318, -0.5635572131852923, -0.5376737344947923, 0.013663710424241766]\n",
      "Layer: Layer 2, Input: [-0.09385302380986318, -0.5635572131852923, -0.5376737344947923, 0.013663710424241766], Output: [-0.4473309572542526]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.48950490212608444, -0.8705697186855067, 0.6866012893569189, -0.24256488264311982]\n",
      "Layer: Layer 1, Input: [0.48950490212608444, -0.8705697186855067, 0.6866012893569189, -0.24256488264311982], Output: [0.4703154051932938, 0.20406518006894128, -0.4627321239672634, 0.752251063738291]\n",
      "Layer: Layer 2, Input: [0.4703154051932938, 0.20406518006894128, -0.4627321239672634, 0.752251063738291], Output: [0.33517914666375254]\n",
      "Epoch 52/100, Loss: 0.6916407975585175, Accuracy: -2.012724042941123\n",
      "Power operation: base = -0.4461192709048325, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3491148759542952, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5526690427457475, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6648208533362474, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9887961600778001, -0.9996058911638268, 0.35509163057177995, 0.3476316744845082]\n",
      "Layer: Layer 1, Input: [0.9887961600778001, -0.9996058911638268, 0.35509163057177995, 0.3476316744845082], Output: [0.7102119967786988, -0.06429791963398229, -0.45762662441059043, 0.9187954988020932]\n",
      "Layer: Layer 2, Input: [0.7102119967786988, -0.06429791963398229, -0.45762662441059043, 0.9187954988020932], Output: [0.5629631022207787]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8094513271345825, -0.831425536881853, 0.9979284359290231, -0.9859806250971327]\n",
      "Layer: Layer 1, Input: [0.8094513271345825, -0.831425536881853, 0.9979284359290231, -0.9859806250971327], Output: [0.5124160117358978, 0.36988916518118403, -0.746124398250387, 0.7942529820481596]\n",
      "Layer: Layer 2, Input: [0.5124160117358978, 0.36988916518118403, -0.746124398250387, 0.7942529820481596], Output: [0.35206457357658094]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5190692598523803, -0.9359759096524198, -0.2765702733786727, -0.3017628757507897]\n",
      "Layer: Layer 1, Input: [0.5190692598523803, -0.9359759096524198, -0.2765702733786727, -0.3017628757507897], Output: [-0.09810144327528851, -0.5629039386353442, -0.5356302545073017, 0.009764801221301965]\n",
      "Layer: Layer 2, Input: [-0.09810144327528851, -0.5629039386353442, -0.5356302545073017, 0.009764801221301965], Output: [-0.4699329872649651]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4939787643123812, -0.871194422334756, 0.6910886577756187, -0.23419778997038657]\n",
      "Layer: Layer 1, Input: [0.4939787643123812, -0.871194422334756, 0.6910886577756187, -0.23419778997038657], Output: [0.47723241268710015, 0.20850822379616635, -0.45931837762454014, 0.7572786630720793]\n",
      "Layer: Layer 2, Input: [0.47723241268710015, 0.20850822379616635, -0.45931837762454014, 0.7572786630720793], Output: [0.3404274857070635]\n",
      "Epoch 53/100, Loss: 0.6837717001854642, Accuracy: -1.9787409983837736\n",
      "Power operation: base = -0.4370368977792213, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3520645735765808, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5300670127350349, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6595725142929365, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9891090453124084, -0.9996137916231347, 0.37015998980497183, 0.36231094649524975]\n",
      "Layer: Layer 1, Input: [0.9891090453124084, -0.9996137916231347, 0.37015998980497183, 0.36231094649524975], Output: [0.7179955768512591, -0.04952001885322316, -0.45000298776136277, 0.9221950117112099]\n",
      "Layer: Layer 2, Input: [0.7179955768512591, -0.04952001885322316, -0.45000298776136277, 0.9221950117112099], Output: [0.5720273991256274]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8100482361876734, -0.8310022503195995, 0.9979451640159642, -0.9858438967823726]\n",
      "Layer: Layer 1, Input: [0.8100482361876734, -0.8310022503195995, 0.9979451640159642, -0.9858438967823726], Output: [0.5150490404859649, 0.37032794937597824, -0.7447408439183292, 0.7940011240932454]\n",
      "Layer: Layer 2, Input: [0.5150490404859649, 0.37032794937597824, -0.7447408439183292, 0.7940011240932454], Output: [0.3550006907167974]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.518304916908321, -0.9354877098525353, -0.27555014737201405, -0.2997247734675689]\n",
      "Layer: Layer 1, Input: [0.518304916908321, -0.9354877098525353, -0.27555014737201405, -0.2997247734675689], Output: [-0.10245231180612971, -0.5622502489762058, -0.5336186015119272, 0.005789916067284282]\n",
      "Layer: Layer 2, Input: [-0.10245231180612971, -0.5622502489762058, -0.5336186015119272, 0.005789916067284282], Output: [-0.49279795472100485]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.4984280586667447, -0.8717867044340297, 0.6954972557124136, -0.22580954665281613]\n",
      "Layer: Layer 1, Input: [0.4984280586667447, -0.8717867044340297, 0.6954972557124136, -0.22580954665281613], Output: [0.48400332065885765, 0.21289625171113413, -0.45594857013874696, 0.7621578152608939]\n",
      "Layer: Layer 2, Input: [0.48400332065885765, 0.21289625171113413, -0.45594857013874696, 0.7621578152608939], Output: [0.3458069635181722]\n",
      "Epoch 54/100, Loss: 0.6761024656646709, Accuracy: -1.9443683733519928\n",
      "Power operation: base = -0.4279726008743726, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3550006907167975, power = 2, grad = 0.25\n",
      "Power operation: base = 0.5072020452789952, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6541930364818278, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9894130111738472, -0.999621419746401, 0.38493756770810994, 0.3767658468420387]\n",
      "Layer: Layer 1, Input: [0.9894130111738472, -0.999621419746401, 0.38493756770810994, 0.3767658468420387], Output: [0.7255083946773165, -0.03494662734929764, -0.442474082354503, 0.9253922627544172]\n",
      "Layer: Layer 2, Input: [0.7255083946773165, -0.03494662734929764, -0.442474082354503, 0.9253922627544172], Output: [0.58107308764507]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8106464206046069, -0.8305427692947409, 0.9979617294277497, -0.9857056354664331]\n",
      "Layer: Layer 1, Input: [0.8106464206046069, -0.8305427692947409, 0.9979617294277497, -0.9857056354664331], Output: [0.5175546446924317, 0.3707936297480126, -0.7434233455336757, 0.7937143201718992]\n",
      "Layer: Layer 2, Input: [0.5175546446924317, 0.3707936297480126, -0.7434233455336757, 0.7937143201718992], Output: [0.35791958537984797]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5175492050725352, -0.9349826590659981, -0.27451333889113483, -0.2976646761139229]\n",
      "Layer: Layer 1, Input: [0.5175492050725352, -0.9349826590659981, -0.27451333889113483, -0.2976646761139229], Output: [-0.1068910680896659, -0.5615917761765264, -0.5316383528404831, 0.0017652447355691948]\n",
      "Layer: Layer 2, Input: [-0.1068910680896659, -0.5615917761765264, -0.5316383528404831, 0.0017652447355691948], Output: [-0.5158991812607095]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.502852838320647, -0.8723463552263687, 0.6998321232541684, -0.21740033079804016]\n",
      "Layer: Layer 1, Input: [0.502852838320647, -0.8723463552263687, 0.6998321232541684, -0.21740033079804016], Output: [0.4906351222990761, 0.2172329362989071, -0.45262437576743536, 0.7668989422831671]\n",
      "Layer: Layer 2, Input: [0.4906351222990761, 0.2172329362989071, -0.45262437576743536, 0.7668989422831671], Output: [0.35131797090115163]\n",
      "Epoch 55/100, Loss: 0.668646833958316, Accuracy: -1.9096293455729167\n",
      "Power operation: base = -0.41892691235492996, power = 2, grad = 0.25\n",
      "Power operation: base = 1.357919585379848, power = 2, grad = 0.25\n",
      "Power operation: base = 0.48410081873929045, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6486820290988484, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9897082419858251, -0.9996287824843653, 0.3994269098122833, 0.3909921152791354]\n",
      "Layer: Layer 1, Input: [0.9897082419858251, -0.9996287824843653, 0.3994269098122833, 0.3909921152791354], Output: [0.7327606352735179, -0.020582418250143113, -0.4350488587614003, 0.9284014522477577]\n",
      "Layer: Layer 2, Input: [0.7327606352735179, -0.020582418250143113, -0.4350488587614003, 0.9284014522477577], Output: [0.5900990904204353]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8112465397993033, -0.8300462356779039, 0.9979781703660461, -0.985565758326848]\n",
      "Layer: Layer 1, Input: [0.8112465397993033, -0.8300462356779039, 0.9979781703660461, -0.985565758326848], Output: [0.5199342052020602, 0.37128378240170057, -0.7421720961961876, 0.7933959022886272]\n",
      "Layer: Layer 2, Input: [0.5199342052020602, 0.37128378240170057, -0.7421720961961876, 0.7933959022886272], Output: [0.3608171206873347]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5168045240207445, -0.9344602481107417, -0.27345052356461147, -0.2955797327564986]\n",
      "Layer: Layer 1, Input: [0.5168045240207445, -0.9344602481107417, -0.27345052356461147, -0.2955797327564986], Output: [-0.11140319012336629, -0.5609241135881409, -0.5296890491424219, -0.0022828106197840367]\n",
      "Layer: Layer 2, Input: [-0.11140319012336629, -0.5609241135881409, -0.5296890491424219, -0.0022828106197840367], Output: [-0.53920849856322]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5072530955397018, -0.8728731291915057, 0.7040980999235767, -0.2089704470791125]\n",
      "Layer: Layer 1, Input: [0.5072530955397018, -0.8728731291915057, 0.7040980999235767, -0.2089704470791125], Output: [0.49713423015156166, 0.22152160416371872, -0.4493473647777398, 0.7715117744948243]\n",
      "Layer: Layer 2, Input: [0.49713423015156166, 0.22152160416371872, -0.4493473647777398, 0.7715117744948243], Output: [0.35696019840116583]\n",
      "Epoch 56/100, Loss: 0.6614177464666382, Accuracy: -1.8745493333025136\n",
      "Power operation: base = -0.4099009095795647, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3608171206873347, power = 2, grad = 0.25\n",
      "Power operation: base = 0.46079150143678005, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6430398015988341, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9899949185785932, -0.9996358864710106, 0.4136307281234742, 0.40498581017535673]\n",
      "Layer: Layer 1, Input: [0.9899949185785932, -0.9996358864710106, 0.4136307281234742, 0.40498581017535673], Output: [0.7397619992507563, -0.0064315021377715454, -0.42773602150396317, 0.9312357141373828]\n",
      "Layer: Layer 2, Input: [0.7397619992507563, -0.0064315021377715454, -0.42773602150396317, 0.9312357141373828], Output: [0.5991037827504415]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8118492388846064, -0.8295117455686708, 0.9979945239222611, -0.9854241833020195]\n",
      "Layer: Layer 1, Input: [0.8118492388846064, -0.8295117455686708, 0.9979945239222611, -0.9854241833020195], Output: [0.5221887409805401, 0.3717957867102194, -0.7409871284603484, 0.7930491792700078]\n",
      "Layer: Layer 2, Input: [0.5221887409805401, 0.3717957867102194, -0.7409871284603484, 0.7930491792700078], Output: [0.3636886429320845]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5160732998626647, -0.9339199451554883, -0.2723522912570543, -0.29346717666959243]\n",
      "Layer: Layer 1, Input: [0.5160732998626647, -0.9339199451554883, -0.2723522912570543, -0.29346717666959243], Output: [-0.1159742609982861, -0.5602428317549086, -0.5277701899436381, -0.006327749264765284]\n",
      "Layer: Layer 2, Input: [-0.1159742609982861, -0.5602428317549086, -0.5277701899436381, -0.006327749264765284], Output: [-0.5626963357475304]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5116287637320246, -0.8733667459380121, 0.7082998191404476, -0.20052032846858406]\n",
      "Layer: Layer 1, Input: [0.5116287637320246, -0.8733667459380121, 0.7082998191404476, -0.20052032846858406], Output: [0.5035064682283542, 0.22576523620890887, -0.4461189954458458, 0.7760053636892809]\n",
      "Layer: Layer 2, Input: [0.5035064682283542, 0.22576523620890887, -0.4461189954458458, 0.7760053636892809], Output: [0.36273259475024594]\n",
      "Epoch 57/100, Loss: 0.6544271831073366, Accuracy: -1.8391559296838667\n",
      "Power operation: base = -0.4008962172495585, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3636886429320845, power = 2, grad = 0.25\n",
      "Power operation: base = 0.4373036642524696, power = 2, grad = 0.25\n",
      "Power operation: base = -0.637267405249754, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9902732189164666, -0.9996427380499613, 0.4275518822223147, 0.41874332559656324]\n",
      "Layer: Layer 1, Input: [0.9902732189164666, -0.9996427380499613, 0.4275518822223147, 0.41874332559656324], Output: [0.7465217088938455, 0.007502534329314116, -0.42054398246233604, 0.9339071923010026]\n",
      "Layer: Layer 2, Input: [0.7465217088938455, 0.007502534329314116, -0.42054398246233604, 0.9339071923010026], Output: [0.6080849987262611]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8124551457254754, -0.828938347542266, 0.998010825969934, -0.9852808292893299]\n",
      "Layer: Layer 1, Input: [0.8124551457254754, -0.828938347542266, 0.998010825969934, -0.9852808292893299], Output: [0.5243189036466075, 0.3723268327088359, -0.7398683105225347, 0.792677423295903]\n",
      "Layer: Layer 2, Input: [0.5243189036466075, 0.3723268327088359, -0.7398683105225347, 0.792677423295903], Output: [0.36652896555025555]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.515357973445521, -0.9333611940563605, -0.27120918043223313, -0.2913243333490177]\n",
      "Layer: Layer 1, Input: [0.515357973445521, -0.9333611940563605, -0.27120918043223313, -0.2913243333490177], Output: [-0.12059003325540987, -0.559543493297343, -0.5258812296447856, -0.010343084222948733]\n",
      "Layer: Layer 2, Input: [-0.12059003325540987, -0.559543493297343, -0.5258812296447856, -0.010343084222948733], Output: [-0.5863318189825952]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5159797202967112, -0.8738268911243184, 0.7124417038986407, -0.19205053587517296]\n",
      "Layer: Layer 1, Input: [0.5159797202967112, -0.8738268911243184, 0.7124417038986407, -0.19205053587517296], Output: [0.5097570697232682, 0.22996646977724577, -0.442940606420954, 0.7803880987371657]\n",
      "Layer: Layer 2, Input: [0.5097570697232682, 0.22996646977724577, -0.442940606420954, 0.7803880987371657], Output: [0.3686333339096732]\n",
      "Epoch 58/100, Loss: 0.6476860032368772, Accuracy: -1.8034788139317257\n",
      "Power operation: base = -0.3919150012737389, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3665289655502555, power = 2, grad = 0.25\n",
      "Power operation: base = 0.41366818101740477, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6313666660903268, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9905433186809385, -0.9996493432992152, 0.4411933646168294, 0.4322614081986338]\n",
      "Layer: Layer 1, Input: [0.9905433186809385, -0.9996493432992152, 0.4411933646168294, 0.4322614081986338], Output: [0.7530485193451132, 0.021216593776662438, -0.41348081625826805, 0.9364271131930584]\n",
      "Layer: Layer 2, Input: [0.7530485193451132, 0.021216593776662438, -0.41348081625826805, 0.9364271131930584], Output: [0.6170400450606113]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8130648680941626, -0.8283250408162194, 0.9980271110595188, -0.9851356163122611]\n",
      "Layer: Layer 1, Input: [0.8130648680941626, -0.8283250408162194, 0.9980271110595188, -0.9851356163122611], Output: [0.5263249744283395, 0.37287392947103665, -0.7388153435159311, 0.7922838571928438]\n",
      "Layer: Layer 2, Input: [0.5263249744283395, 0.37287392947103665, -0.7388153435159311, 0.7922838571928438], Output: [0.3693323589150872]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5146609882333194, -0.9327834125771733, -0.27001171200450047, -0.2891486276097598]\n",
      "Layer: Layer 1, Input: [0.5146609882333194, -0.9327834125771733, -0.27001171200450047, -0.2891486276097598], Output: [-0.12523649158933992, -0.5588216668322936, -0.5240215740231968, -0.01430245217545527]\n",
      "Layer: Layer 2, Input: [-0.12523649158933992, -0.5588216668322936, -0.5240215740231968, -0.01430245217545527], Output: [-0.6100828824414855]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5203057902236754, -0.8742532173739038, 0.7165279635462223, -0.1835617557902514]\n",
      "Layer: Layer 1, Input: [0.5203057902236754, -0.8742532173739038, 0.7165279635462223, -0.1835617557902514], Output: [0.5158906799087698, 0.23412760267304558, -0.43981340959175313, 0.7846677235763442]\n",
      "Layer: Layer 2, Input: [0.5158906799087698, 0.23412760267304558, -0.43981340959175313, 0.7846677235763442], Output: [0.3746597910071001]\n",
      "Epoch 59/100, Loss: 0.64120379295189, Accuracy: -1.7675496404058904\n",
      "Power operation: base = -0.3829599549393887, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3693323589150872, power = 2, grad = 0.25\n",
      "Power operation: base = 0.38991711755851455, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6253402089928999, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9908053918027108, -0.9996557080541327, 0.4545582896886793, 0.4455371734015523]\n",
      "Layer: Layer 1, Input: [0.9908053918027108, -0.9996557080541327, 0.4545582896886793, 0.4455371734015523], Output: [0.7593507338907641, 0.03470803729397024, -0.4065542182288544, 0.9388058545844227]\n",
      "Layer: Layer 2, Input: [0.7593507338907641, 0.03470803729397024, -0.4065542182288544, 0.9388058545844227], Output: [0.6259657220062109]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8136789909349039, -0.8276707733050721, 0.9980434123159532, -0.9849884656573377]\n",
      "Layer: Layer 1, Input: [0.8136789909349039, -0.8276707733050721, 0.9980434123159532, -0.9849884656573377], Output: [0.5282068632368667, 0.37343391445545626, -0.7378277599834595, 0.7918716425723435]\n",
      "Layer: Layer 2, Input: [0.5282068632368667, 0.37343391445545626, -0.7378277599834595, 0.7918716425723435], Output: [0.37209254579627965]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5139847778325064, -0.9321859904798349, -0.2687504225696465, -0.2869375898037817]\n",
      "Layer: Layer 1, Input: [0.5139847778325064, -0.9321859904798349, -0.2687504225696465, -0.2869375898037817], Output: [-0.12989991368422585, -0.5580729399084315, -0.5221905772846845, -0.01817971996695377]\n",
      "Layer: Layer 2, Input: [-0.12989991368422585, -0.5580729399084315, -0.5221905772846845, -0.01817971996695377], Output: [-0.6339163895754423]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5246067503446403, -0.874645345149426, 0.7205625915606823, -0.17505479607485416]\n",
      "Layer: Layer 1, Input: [0.5246067503446403, -0.874645345149426, 0.7205625915606823, -0.17505479607485416], Output: [0.5219113637811874, 0.2382505989772338, -0.43673848357927814, 0.7888513573374883]\n",
      "Layer: Layer 2, Input: [0.5219113637811874, 0.2382505989772338, -0.43673848357927814, 0.7888513573374883], Output: [0.3808085273558008]\n",
      "Epoch 60/100, Loss: 0.6349887212402054, Accuracy: -1.7314019068588253\n",
      "Power operation: base = -0.3740342779937891, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3720925457962796, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3660836104245577, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6191914726441992, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.991059610937134, -0.9996618379286212, 0.4676498855669659, 0.4585681203499845]\n",
      "Layer: Layer 1, Input: [0.991059610937134, -0.9996618379286212, 0.4676498855669659, 0.4585681203499845], Output: [0.7654362224315161, 0.0479746571715255, -0.3997714655665364, 0.9410530102646582]\n",
      "Layer: Layer 2, Input: [0.7654362224315161, 0.0479746571715255, -0.3997714655665364, 0.9410530102646582], Output: [0.6348583507423655]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8142980737444634, -0.8269744395290957, 0.998059761339477, -0.9848392999820419]\n",
      "Layer: Layer 1, Input: [0.8142980737444634, -0.8269744395290957, 0.998059761339477, -0.9848392999820419], Output: [0.5299641095314365, 0.3740034637861032, -0.7369049235731586, 0.7914438688884966]\n",
      "Layer: Layer 2, Input: [0.5299641095314365, 0.3740034637861032, -0.7369049235731586, 0.7914438688884966], Output: [0.3748027022607961]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5133317532409427, -0.9315682874701275, -0.26741589691570894, -0.28468886119879894]\n",
      "Layer: Layer 1, Input: [0.5133317532409427, -0.9315682874701275, -0.26741589691570894, -0.28468886119879894], Output: [-0.13456692898837597, -0.5572929309616719, -0.5203875396940357, -0.021949086822680163]\n",
      "Layer: Layer 2, Input: [-0.13456692898837597, -0.5572929309616719, -0.5203875396940357, -0.021949086822680163], Output: [-0.6577982635671066]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.528882334125181, -0.8750028635502886, 0.7245493642142535, -0.1665305800400423]\n",
      "Layer: Layer 1, Input: [0.528882334125181, -0.8750028635502886, 0.7245493642142535, -0.1665305800400423], Output: [0.527822617996821, 0.2423370965534652, -0.43371676796413877, 0.7929455163930027]\n",
      "Layer: Layer 2, Input: [0.527822617996821, 0.2423370965534652, -0.43371676796413877, 0.7929455163930027], Output: [0.3870752846202676]\n",
      "Epoch 61/100, Loss: 0.6290474073267964, Accuracy: -1.6950708033310562\n",
      "Power operation: base = -0.3651416492576345, power = 2, grad = 0.25\n",
      "Power operation: base = 1.374802702260796, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3422017364328934, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6129247153797324, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9913061478787861, -0.9996677383344768, 0.48047148827194663, 0.4713521452107493]\n",
      "Layer: Layer 1, Input: [0.9913061478787861, -0.9996677383344768, 0.48047148827194663, 0.4713521452107493], Output: [0.7713124423024882, 0.06101465285419175, -0.3931393821488261, 0.943177450666143]\n",
      "Layer: Layer 2, Input: [0.7713124423024882, 0.06101465285419175, -0.3931393821488261, 0.943177450666143], Output: [0.6437138065926663]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8149226480736389, -0.826234878340953, 0.9980761881102177, -0.9846880433951751]\n",
      "Layer: Layer 1, Input: [0.8149226480736389, -0.826234878340953, 0.9980761881102177, -0.9846880433951751], Output: [0.5315958846299489, 0.374579103402764, -0.7360460299739505, 0.7910035434748351]\n",
      "Layer: Layer 2, Input: [0.5315958846299489, 0.374579103402764, -0.7360460299739505, 0.7910035434748351], Output: [0.37745546371738237]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5127042899023534, -0.9309296309828682, -0.2659987997271904, -0.28240019856347287]\n",
      "Layer: Layer 1, Input: [0.5127042899023534, -0.9309296309828682, -0.2659987997271904, -0.28240019856347287], Output: [-0.13922457526452478, -0.5564773003193606, -0.5186117057961589, -0.02558518148195904]\n",
      "Layer: Layer 2, Input: [-0.13922457526452478, -0.5564773003193606, -0.5186117057961589, -0.02558518148195904], Output: [-0.6816936257480095]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5331322368799877, -0.8753253309981642, 0.7284918400270503, -0.15799013899342515]\n",
      "Layer: Layer 1, Input: [0.5331322368799877, -0.8753253309981642, 0.7284918400270503, -0.15799013899342515], Output: [0.5336273866192657, 0.24638841612871706, -0.43074905833881194, 0.7969561381110616]\n",
      "Layer: Layer 2, Input: [0.5336273866192657, 0.24638841612871706, -0.43074905833881194, 0.7969561381110616], Output: [0.393454988061512]\n",
      "Epoch 62/100, Loss: 0.6233848013836164, Accuracy: -1.6585930433151947\n",
      "Power operation: base = -0.3562861934073337, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3774554637173824, power = 2, grad = 0.25\n",
      "Power operation: base = 0.3183063742519905, power = 2, grad = 0.25\n",
      "Power operation: base = -0.606545011938488, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9915451739122009, -0.9996734144988604, 0.4930265374936019, 0.48388755241163844]\n",
      "Layer: Layer 1, Input: [0.9915451739122009, -0.9996734144988604, 0.4930265374936019, 0.48388755241163844], Output: [0.7769864606914924, 0.07382660972226755, -0.3866643075165754, 0.9451873794396115]\n",
      "Layer: Layer 2, Input: [0.7769864606914924, 0.07382660972226755, -0.3866643075165754, 0.9451873794396115], Output: [0.6525275574242076]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8155532151536908, -0.8254508704323478, 0.9980927208970899, -0.9845346215114515]\n",
      "Layer: Layer 1, Input: [0.8155532151536908, -0.8254508704323478, 0.9980927208970899, -0.9845346215114515], Output: [0.5331009951024358, 0.3751572209935573, -0.7352501090832595, 0.7905535826011023]\n",
      "Layer: Layer 2, Input: [0.5331009951024358, 0.3751572209935573, -0.7352501090832595, 0.7905535826011023], Output: [0.3800429357314572]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5121047146526202, -0.9302693137890905, -0.2644899064119702, -0.2800694780088899]\n",
      "Layer: Layer 1, Input: [0.5121047146526202, -0.9302693137890905, -0.2644899064119702, -0.2800694780088899], Output: [-0.14386035278992249, -0.5556217603072476, -0.5168622632238916, -0.02906315358730736]\n",
      "Layer: Layer 2, Input: [-0.14386035278992249, -0.5556217603072476, -0.5168622632238916, -0.02906315358730736], Output: [-0.7055669407333196]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5373561212884895, -0.8756122757754059, 0.7323933599085289, -0.14943460344169004]\n",
      "Layer: Layer 1, Input: [0.5373561212884895, -0.8756122757754059, 0.7323933599085289, -0.14943460344169004], Output: [0.5393280801788063, 0.2504055718166365, -0.42783600225737733, 0.8008886060852605]\n",
      "Layer: Layer 2, Input: [0.5393280801788063, 0.2504055718166365, -0.42783600225737733, 0.8008886060852605], Output: [0.3999417586620718]\n",
      "Epoch 63/100, Loss: 0.6180040805496475, Accuracy: -1.6220066789118581\n",
      "Power operation: base = -0.34747244257579235, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3800429357314572, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2944330592666804, power = 2, grad = 0.25\n",
      "Power operation: base = -0.6000582413379282, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9917768600970536, -0.999678871479913, 0.5053185734060174, 0.496173063487503]\n",
      "Layer: Layer 1, Input: [0.9917768600970536, -0.999678871479913, 0.5053185734060174, 0.496173063487503], Output: [0.7824649779894947, 0.08640948027930573, -0.38035207038461283, 0.9470903860639475]\n",
      "Layer: Layer 2, Input: [0.7824649779894947, 0.08640948027930573, -0.38035207038461283, 0.9470903860639475], Output: [0.6612947065715561]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8161902436507542, -0.8246211355810418, 0.9981093861715803, -0.9843789614823885]\n",
      "Layer: Layer 1, Input: [0.8161902436507542, -0.8246211355810418, 0.9981093861715803, -0.9843789614823885], Output: [0.5344778868727758, 0.3757340785981798, -0.7345160283722633, 0.790096803567669]\n",
      "Layer: Layer 2, Input: [0.5344778868727758, 0.3757340785981798, -0.7345160283722633, 0.790096803567669], Output: [0.3825567091624761]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5115352926476268, -0.9295865914064607, -0.2628801329982033, -0.27769469814008724]\n",
      "Layer: Layer 1, Input: [0.5115352926476268, -0.9295865914064607, -0.2628801329982033, -0.27769469814008724], Output: [-0.1484622761216642, -0.5547220845382735, -0.5151383420737429, -0.03235875882749747]\n",
      "Layer: Layer 2, Input: [-0.1484622761216642, -0.5547220845382735, -0.5151383420737429, -0.03235875882749747], Output: [-0.7293821670346545]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5415536230860744, -0.8758631963820774, 0.736257047891147, -0.14086519315246868]\n",
      "Layer: Layer 1, Input: [0.5415536230860744, -0.8758631963820774, 0.736257047891147, -0.14086519315246868], Output: [0.544926597530499, 0.25438928293741186, -0.424978096136206, 0.8047477765971066]\n",
      "Layer: Layer 2, Input: [0.544926597530499, 0.25438928293741186, -0.424978096136206, 0.8047477765971066], Output: [0.40652893380032296]\n",
      "Epoch 64/100, Loss: 0.6129065619454162, Accuracy: -1.5853509017559424\n",
      "Power operation: base = -0.3387052934284439, power = 2, grad = 0.25\n",
      "Power operation: base = 1.382556709162476, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2706178329653455, power = 2, grad = 0.25\n",
      "Power operation: base = -0.593471066199677, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9920013774874037, -0.9996841141805228, 0.5173512339667494, 0.508207823266553]\n",
      "Layer: Layer 1, Input: [0.9920013774874037, -0.9996841141805228, 0.5173512339667494, 0.508207823266553], Output: [0.7877543514915558, 0.09876256731855255, -0.3742079669854912, 0.9488934946128436]\n",
      "Layer: Layer 2, Input: [0.7877543514915558, 0.09876256731855255, -0.3742079669854912, 0.9488934946128436], Output: [0.670010039628806]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8168341675507464, -0.8237443295972277, 0.9981262085269887, -0.9842209920057996]\n",
      "Layer: Layer 1, Input: [0.8168341675507464, -0.8237443295972277, 0.9981262085269887, -0.9842209920057996], Output: [0.5357246496472879, 0.37630582574915955, -0.7338424973903274, 0.7896359178302835]\n",
      "Layer: Layer 2, Input: [0.5357246496472879, 0.37630582574915955, -0.7338424973903274, 0.7896359178302835], Output: [0.3849878791056529]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5109982143649182, -0.9288806792926407, -0.26116056506776425, -0.2752739825743824]\n",
      "Layer: Layer 1, Input: [0.5109982143649182, -0.9288806792926407, -0.26116056506776425, -0.2752739825743824], Output: [-0.1530189233855005, -0.5537741164861202, -0.51343901481757, -0.035448437509578296]\n",
      "Layer: Layer 2, Input: [-0.1530189233855005, -0.5537741164861202, -0.51343901481757, -0.035448437509578296], Output: [-0.7531029119555066]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5457243568075997, -0.8760775616785835, 0.7400858123645497, -0.13228320628824305]\n",
      "Layer: Layer 1, Input: [0.5457243568075997, -0.8760775616785835, 0.7400858123645497, -0.13228320628824305], Output: [0.550424349990475, 0.2583399869751309, -0.4221756831401085, 0.8085380060560903]\n",
      "Layer: Layer 2, Input: [0.550424349990475, 0.2583399869751309, -0.4221756831401085, 0.8085380060560903], Output: [0.4132090960215029]\n",
      "Epoch 65/100, Loss: 0.6080916340730272, Accuracy: -1.5486658314998376\n",
      "Power operation: base = -0.329989960371194, power = 2, grad = 0.25\n",
      "Power operation: base = 1.384987879105653, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2468970880444934, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5867909039784971, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9922188972858449, -0.9996891473602902, 0.5291282522091222, 0.519991403200332]\n",
      "Layer: Layer 1, Input: [0.9922188972858449, -0.9996891473602902, 0.5291282522091222, 0.519991403200332], Output: [0.7928606189504402, 0.1108855086498473, -0.36823674445853655, 0.9506032088299551]\n",
      "Layer: Layer 2, Input: [0.7928606189504402, 0.1108855086498473, -0.36823674445853655, 0.9506032088299551], Output: [0.6786680744617659]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8174853841771981, -0.8228190409271715, 0.998143210603702, -0.9840606433163812]\n",
      "Layer: Layer 1, Input: [0.8174853841771981, -0.8228190409271715, 0.998143210603702, -0.9840606433163812], Output: [0.5368390212885278, 0.3768685130000672, -0.733228073328071, 0.7891735251222096]\n",
      "Layer: Layer 2, Input: [0.5368390212885278, 0.3768685130000672, -0.733228073328071, 0.7891735251222096], Output: [0.3873270670570679]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5104955827733959, -0.9281507497997757, -0.25932248571236594, -0.27280558188514475]\n",
      "Layer: Layer 1, Input: [0.5104955827733959, -0.9281507497997757, -0.25932248571236594, -0.27280558188514475], Output: [-0.15751948308812716, -0.5527737774686023, -0.5117632967066396, -0.03830938642000339]\n",
      "Layer: Layer 2, Input: [-0.15751948308812716, -0.5527737774686023, -0.5117632967066396, -0.03830938642000339], Output: [-0.7766925896479111]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5498679214648319, -0.8762548107825215, 0.7438823477244556, -0.12369000782992269]\n",
      "Layer: Layer 1, Input: [0.5498679214648319, -0.8762548107825215, 0.7438823477244556, -0.12369000782992269], Output: [0.555822287231469, 0.2622578535033362, -0.4194289520698145, 0.8122631791527224]\n",
      "Layer: Layer 2, Input: [0.555822287231469, 0.2622578535033362, -0.4194289520698145, 0.8122631791527224], Output: [0.41997410934367463]\n",
      "Epoch 66/100, Loss: 0.6035567076772739, Accuracy: -1.5119922936037162\n",
      "Power operation: base = -0.3213319255382341, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3873270670570679, power = 2, grad = 0.25\n",
      "Power operation: base = 0.2233074103520889, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5800258906563254, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9924295909345956, -0.9996939756457426, 0.5406534531027968, 0.531523801712732]\n",
      "Layer: Layer 1, Input: [0.9924295909345956, -0.9996939756457426, 0.5406534531027968, 0.531523801712732], Output: [0.7977895215673856, 0.12277826299488226, -0.36244258940508695, 0.9522255536847168]\n",
      "Layer: Layer 2, Input: [0.7977895215673856, 0.12277826299488226, -0.36244258940508695, 0.9522255536847168], Output: [0.6872631138104313]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8181442523448579, -0.8218437868713158, 0.9981604130210607, -0.9838978471600055]\n",
      "Layer: Layer 1, Input: [0.8181442523448579, -0.8218437868713158, 0.9981604130210607, -0.9838978471600055], Output: [0.5378183917588553, 0.3774181056745988, -0.7326711675390621, 0.7887121085161286]\n",
      "Layer: Layer 2, Input: [0.5378183917588553, 0.3774181056745988, -0.7326711675390621, 0.7887121085161286], Output: [0.38956444566831006]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5100294007666798, -0.9273959288666963, -0.2573574025173826, -0.27028787503016005]\n",
      "Layer: Layer 1, Input: [0.5100294007666798, -0.9273959288666963, -0.2573574025173826, -0.27028787503016005], Output: [-0.1619537984914917, -0.5517170741855403, -0.5101101466148855, -0.04091962401991507]\n",
      "Layer: Layer 2, Input: [-0.1619537984914917, -0.5517170741855403, -0.5101101466148855, -0.04091962401991507], Output: [-0.800114581306863]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5539839060477986, -0.8763943526904239, 0.747649136357894, -0.11508701750800406]\n",
      "Layer: Layer 1, Input: [0.5539839060477986, -0.8763943526904239, 0.747649136357894, -0.11508701750800406], Output: [0.5611209244295186, 0.2661427989025042, -0.41673793724882174, 0.8159267374554993]\n",
      "Layer: Layer 2, Input: [0.5611209244295186, 0.2661427989025042, -0.41673793724882174, 0.8159267374554993], Output: [0.42681516244483153]\n",
      "Epoch 67/100, Loss: 0.5992971868145752, Accuracy: -1.4753715881061842\n",
      "Power operation: base = -0.31273688618956874, power = 2, grad = 0.25\n",
      "Power operation: base = 1.38956444566831, power = 2, grad = 0.25\n",
      "Power operation: base = 0.19988541869313703, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5731848375551685, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9926336301466432, -0.9996986035388731, 0.551930749631808, 0.5428054415145499]\n",
      "Layer: Layer 1, Input: [0.9926336301466432, -0.9996986035388731, 0.551930749631808, 0.5428054415145499], Output: [0.8025465260843977, 0.13444109669774554, -0.3568291216395752, 0.9537661135948299]\n",
      "Layer: Layer 2, Input: [0.8025465260843977, 0.13444109669774554, -0.3568291216395752, 0.9537661135948299], Output: [0.6957892998795769]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8188110906528919, -0.8208170093736967, 0.9981778343163734, -0.9837325367543929]\n",
      "Layer: Layer 1, Input: [0.8188110906528919, -0.8208170093736967, 0.9981778343163734, -0.9837325367543929], Output: [0.5386598062713951, 0.37795049765916056, -0.7321700529038346, 0.7882540303458985]\n",
      "Layer: Layer 2, Input: [0.5386598062713951, 0.37795049765916056, -0.7321700529038346, 0.7882540303458985], Output: [0.39168976541617573]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5096015589568303, -0.9266152924238276, -0.2552570735956155, -0.2677193703227675]\n",
      "Layer: Layer 1, Input: [0.5096015589568303, -0.9266152924238276, -0.2552570735956155, -0.2677193703227675], Output: [-0.16631240962070745, -0.5506001059721108, -0.5084784682605685, -0.04325804919580014]\n",
      "Layer: Layer 2, Input: [-0.16631240962070745, -0.5506001059721108, -0.5084784682605685, -0.04325804919580014], Output: [-0.8233323965929313]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5580718947515526, -0.8764955655974564, 0.7513884508956566, -0.10647569745487757]\n",
      "Layer: Layer 1, Input: [0.5580718947515526, -0.8764955655974564, 0.7513884508956566, -0.10647569745487757], Output: [0.5663203701744569, 0.2699945016899731, -0.4141025193910186, 0.8195317081844811]\n",
      "Layer: Layer 2, Input: [0.5663203701744569, 0.2699945016899731, -0.4141025193910186, 0.8195317081844811], Output: [0.43372281800563295]\n",
      "Epoch 68/100, Loss: 0.5953064605432418, Accuracy: -1.4388452509380345\n",
      "Power operation: base = -0.30421070012042306, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3916897654161757, power = 2, grad = 0.25\n",
      "Power operation: base = 0.17666760340706866, power = 2, grad = 0.25\n",
      "Power operation: base = -0.566277181994367, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9928311868810203, -0.9997030354240961, 0.5629641378172081, 0.553837163898453]\n",
      "Layer: Layer 1, Input: [0.9928311868810203, -0.9997030354240961, 0.5629641378172081, 0.553837163898453], Output: [0.8071368457188007, 0.14587457094649173, -0.35139939307760665, 0.9552300675100084]\n",
      "Layer: Layer 2, Input: [0.8071368457188007, 0.14587457094649173, -0.35139939307760665, 0.9552300675100084], Output: [0.7042406703521145]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8194861759229779, -0.8197370703395495, 0.9981954908916136, -0.9835646467388123]\n",
      "Layer: Layer 1, Input: [0.8194861759229779, -0.8197370703395495, 0.9981954908916136, -0.9835646467388123], Output: [0.5393599673053433, 0.3784615250542432, -0.7317228719070152, 0.7878015288896278]\n",
      "Layer: Layer 2, Input: [0.5393599673053433, 0.3784615250542432, -0.7317228719070152, 0.7878015288896278], Output: [0.39369238248604166]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5092138239258438, -0.9258078624841818, -0.25301353270785076, -0.26509870600141194]\n",
      "Layer: Layer 1, Input: [0.5092138239258438, -0.9258078624841818, -0.25301353270785076, -0.26509870600141194], Output: [-0.17058659300317144, -0.5494190719412421, -0.5068671117400233, -0.04530449394659054]\n",
      "Layer: Layer 2, Input: [-0.17058659300317144, -0.5494190719412421, -0.5068671117400233, -0.04530449394659054], Output: [-0.8463098354957829]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5621314718441703, -0.8765577958908236, 0.7551023566737343, -0.0978575397830459]\n",
      "Layer: Layer 1, Input: [0.5621314718441703, -0.8765577958908236, 0.7551023566737343, -0.0978575397830459], Output: [0.5714203546869717, 0.2738124182837162, -0.4115224274154162, 0.8230807329026976]\n",
      "Layer: Layer 2, Input: [0.5714203546869717, 0.2738124182837162, -0.4115224274154162, 0.8230807329026976], Output: [0.44068706743295727]\n",
      "Epoch 69/100, Loss: 0.5915759153188661, Accuracy: -1.402454809205187\n",
      "Power operation: base = -0.29575932964788554, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3936923824860417, power = 2, grad = 0.25\n",
      "Power operation: base = 0.15369016450421713, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5593129325670427, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9930224332670999, -0.9997072755737187, 0.5737576904911651, 0.5646202200929927]\n",
      "Layer: Layer 1, Input: [0.9930224332670999, -0.9997072755737187, 0.5737576904911651, 0.5646202200929927], Output: [0.8115654597527144, 0.15707952925701793, -0.34615589161887556, 0.9566222210560139]\n",
      "Layer: Layer 2, Input: [0.8115654597527144, 0.15707952925701793, -0.34615589161887556, 0.9566222210560139], Output: [0.7126112153048213]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8201697417895757, -0.8186022464384222, 0.9982133969683228, -0.9833941131153756]\n",
      "Layer: Layer 1, Input: [0.8201697417895757, -0.8186022464384222, 0.9982133969683228, -0.9833941131153756], Output: [0.5399152351678732, 0.3789469794965806, -0.7313276452890954, 0.7873567157016421]\n",
      "Layer: Layer 2, Input: [0.5399152351678732, 0.3789469794965806, -0.7313276452890954, 0.7873567157016421], Output: [0.39556128715551664]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5088678270328268, -0.9249726028921855, -0.25061911351815847, -0.2624246504491428]\n",
      "Layer: Layer 1, Input: [0.5088678270328268, -0.9249726028921855, -0.25061911351815847, -0.2624246504491428], Output: [-0.1747683992538761, -0.5481702781969374, -0.5052748753037386, -0.04703977052507295]\n",
      "Layer: Layer 2, Input: [-0.1747683992538761, -0.5481702781969374, -0.5052748753037386, -0.04703977052507295], Output: [-0.8690111499736595]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5661622261084323, -0.8765803567955627, 0.7587927143579852, -0.08923405428110227]\n",
      "Layer: Layer 1, Input: [0.5661622261084323, -0.8765803567955627, 0.7587927143579852, -0.08923405428110227], Output: [0.5764202579238877, 0.27759579902634346, -0.4089972411610827, 0.8265760958820021]\n",
      "Layer: Layer 2, Input: [0.5764202579238877, 0.27759579902634346, -0.4089972411610827, 0.8265760958820021], Output: [0.4476973901635378]\n",
      "Epoch 70/100, Loss: 0.5880949678597811, Accuracy: -1.3662415317134977\n",
      "Power operation: base = -0.2873887846951787, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3955612871555165, power = 2, grad = 0.25\n",
      "Power operation: base = 0.13098885002634053, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5523026098364622, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.993207541483454, -0.9997113281520432, 0.5843155497084621, 0.5751562598119233]\n",
      "Layer: Layer 1, Input: [0.993207541483454, -0.9997113281520432, 0.5843155497084621, 0.5751562598119233], Output: [0.8158371316567045, 0.16805708502972147, -0.34110054980679194, 0.9579470359391843]\n",
      "Layer: Layer 2, Input: [0.8158371316567045, 0.16805708502972147, -0.34110054980679194, 0.9579470359391843], Output: [0.7208949345577494]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8208619774520044, -0.8174107233509268, 0.998231564551226, -0.9832208731843162]\n",
      "Layer: Layer 1, Input: [0.8208619774520044, -0.8174107233509268, 0.998231564551226, -0.9832208731843162], Output: [0.5403216268152603, 0.379402620964733, -0.7309822811287555, 0.7869215734725478]\n",
      "Layer: Layer 2, Input: [0.5403216268152603, 0.379402620964733, -0.7309822811287555, 0.7869215734725478], Output: [0.3972851319680676]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5085650538750319, -0.9241084147004983, -0.24806647303873927, -0.25969610210898325]\n",
      "Layer: Layer 1, Input: [0.5085650538750319, -0.9241084147004983, -0.24806647303873927, -0.25969610210898325], Output: [-0.17885068862967246, -0.5468501453041067, -0.5037005073035274, -0.04844571365973567]\n",
      "Layer: Layer 2, Input: [-0.17885068862967246, -0.5468501453041067, -0.5037005073035274, -0.04844571365973567], Output: [-0.8914012048184659]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.570163754807992, -0.8765625266545333, 0.7624611827000687, -0.08060675640277629]\n",
      "Layer: Layer 1, Input: [0.570163754807992, -0.8765625266545333, 0.7624611827000687, -0.08060675640277629], Output: [0.5813191371998365, 0.28134370430476185, -0.4065263949441604, 0.8300197519218879]\n",
      "Layer: Layer 2, Input: [0.5813191371998365, 0.28134370430476185, -0.4065263949441604, 0.8300197519218879], Output: [0.454742816744225]\n",
      "Epoch 71/100, Loss: 0.5848511179453616, Accuracy: -1.3302461758476274\n",
      "Power operation: base = -0.27910506544225056, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3972851319680677, power = 2, grad = 0.25\n",
      "Power operation: base = 0.10859879518153415, power = 2, grad = 0.25\n",
      "Power operation: base = -0.545257183255775, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9933866835973093, -0.9997151972182254, 0.5946419177577079, 0.5854473171853299]\n",
      "Layer: Layer 1, Input: [0.9933866835973093, -0.9997151972182254, 0.5946419177577079, 0.5854473171853299], Output: [0.8199564256873275, 0.1788086090494721, -0.33623475797974084, 0.9592086568102781]\n",
      "Layer: Layer 2, Input: [0.8199564256873275, 0.1788086090494721, -0.33623475797974084, 0.9592086568102781], Output: [0.7290858950452098]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8215630266006172, -0.816160589418513, 0.9982500034010547, -0.9830448654754134]\n",
      "Layer: Layer 1, Input: [0.8215630266006172, -0.816160589418513, 0.9982500034010547, -0.9830448654754134], Output: [0.5405748126804537, 0.3798241898851938, -0.7306845842096109, 0.7864979542943337]\n",
      "Layer: Layer 2, Input: [0.5405748126804537, 0.3798241898851938, -0.7306845842096109, 0.7864979542943337], Output: [0.3988522590043738]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5083068345009825, -0.9232141311433846, -0.24534861432107227, -0.25691208913411184]\n",
      "Layer: Layer 1, Input: [0.5083068345009825, -0.9232141311433846, -0.24534861432107227, -0.25691208913411184], Output: [-0.18282716467271876, -0.5454552161993126, -0.5021427082398708, -0.0495052185586906]\n",
      "Layer: Layer 2, Input: [-0.18282716467271876, -0.5454552161993126, -0.5021427082398708, -0.0495052185586906], Output: [-0.9134456372957253]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5741356671482639, -0.8765035468276557, 0.7661092214074322, -0.07197715570477745]\n",
      "Layer: Layer 1, Input: [0.5741356671482639, -0.8765035468276557, 0.7661092214074322, -0.07197715570477745], Output: [0.5861157540060576, 0.28505502061363563, -0.4041091818897706, 0.8334133534273496]\n",
      "Layer: Layer 2, Input: [0.5861157540060576, 0.28505502061363563, -0.4041091818897706, 0.8334133534273496], Output: [0.46181199490457014]\n",
      "Epoch 72/100, Loss: 0.5818300203292089, Accuracy: -1.2945087317588682\n",
      "Power operation: base = -0.2709141049547902, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3988522590043737, power = 2, grad = 0.25\n",
      "Power operation: base = 0.08655436270427475, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5381880050954299, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9935600313709435, -0.9997188867280196, 0.6047410468061927, 0.5954957943010242]\n",
      "Layer: Layer 1, Input: [0.9935600313709435, -0.9997188867280196, 0.6047410468061927, 0.5954957943010242], Output: [0.8239277219520394, 0.18933571685783598, -0.33155938157227943, 0.9604109357830305]\n",
      "Layer: Layer 2, Input: [0.8239277219520394, 0.18933571685783598, -0.33155938157227943, 0.9604109357830305], Output: [0.7371782878556702]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8222729865321796, -0.8148498286572993, 0.9982687210170539, -0.9828660296774236]\n",
      "Layer: Layer 1, Input: [0.8222729865321796, -0.8148498286572993, 0.9982687210170539, -0.9828660296774236], Output: [0.5406701112922597, 0.38020741836397703, -0.730432265526544, 0.7860875782114765]\n",
      "Layer: Layer 2, Input: [0.5406701112922597, 0.38020741836397703, -0.730432265526544, 0.7860875782114765], Output: [0.40025072559135244]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5080943344737305, -0.922288512173687, -0.24245890844667856, -0.2540717688036084]\n",
      "Layer: Layer 1, Input: [0.5080943344737305, -0.922288512173687, -0.24245890844667856, -0.2540717688036084], Output: [-0.1866924060500015, -0.5439821647206001, -0.5006001328403991, -0.05020227543706744]\n",
      "Layer: Layer 2, Input: [-0.1866924060500015, -0.5439821647206001, -0.5006001328403991, -0.05020227543706744], Output: [-0.9351110151864415]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5780775872221302, -0.8764026191988166, 0.7697380941254568, -0.06334674486722247]\n",
      "Layer: Layer 1, Input: [0.5780775872221302, -0.8764026191988166, 0.7697380941254568, -0.06334674486722247], Output: [0.5908085997641794, 0.2887284764267498, -0.4017447589646864, 0.836758276583959]\n",
      "Layer: Layer 2, Input: [0.5908085997641794, 0.2887284764267498, -0.4017447589646864, 0.836758276583959], Output: [0.4688932578762858]\n",
      "Epoch 73/100, Loss: 0.5790155746932466, Accuracy: -1.2590681646729553\n",
      "Power operation: base = -0.2628217121443298, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4002507255913526, power = 2, grad = 0.25\n",
      "Power operation: base = 0.06488898481355854, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5311067421237142, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9937277560415197, -0.9997224005345448, 0.6146172272775633, 0.6053044426178464]\n",
      "Layer: Layer 1, Input: [0.9937277560415197, -0.9997224005345448, 0.6146172272775633, 0.6053044426178464], Output: [0.8277552299815956, 0.19964025598110424, -0.32707478217900804, 0.9615574547977993]\n",
      "Layer: Layer 2, Input: [0.8277552299815956, 0.19964025598110424, -0.32707478217900804, 0.9615574547977993], Output: [0.7451664846479792]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.822991907472405, -0.8134763130991635, 0.9982877226296366, -0.9826843065670167]\n",
      "Layer: Layer 1, Input: [0.822991907472405, -0.8134763130991635, 0.9982877226296366, -0.9826843065670167], Output: [0.5406024815115875, 0.3805480403796151, -0.7302229517911372, 0.7856920319493853]\n",
      "Layer: Layer 2, Input: [0.5406024815115875, 0.3805480403796151, -0.7302229517911372, 0.7856920319493853], Output: [0.40146832783388786]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5079285468817791, -0.9213302385289788, -0.2393911158616865, -0.2511744267253783]\n",
      "Layer: Layer 1, Input: [0.5079285468817791, -0.9213302385289788, -0.2393911158616865, -0.2511744267253783], Output: [-0.19044189667175304, -0.5424278049232799, -0.4990713921036499, -0.050522001311687784]\n",
      "Layer: Layer 2, Input: [-0.19044189667175304, -0.5424278049232799, -0.4990713921036499, -0.050522001311687784], Output: [-0.9563649929083835]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5819891564501676, -0.876258903282302, 0.7733488715452621, -0.054716989406862995]\n",
      "Layer: Layer 1, Input: [0.5819891564501676, -0.876258903282302, 0.7733488715452621, -0.054716989406862995], Output: [0.5953959203126141, 0.29236265775896053, -0.3994321526318456, 0.8400556465035802]\n",
      "Layer: Layer 2, Input: [0.5953959203126141, 0.29236265775896053, -0.3994321526318456, 0.8400556465035802], Output: [0.47597469426957495]\n",
      "Epoch 74/100, Loss: 0.5763900323394833, Accuracy: -1.2239621560079503\n",
      "Power operation: base = -0.2548335153520208, power = 2, grad = 0.25\n",
      "Power operation: base = 1.401468327833888, power = 2, grad = 0.25\n",
      "Power operation: base = 0.043635007091616496, power = 2, grad = 0.25\n",
      "Power operation: base = -0.524025305730425, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9938900280808431, -0.9997257423882135, 0.6242747751189388, 0.6148763425366952]\n",
      "Layer: Layer 1, Input: [0.9938900280808431, -0.9997257423882135, 0.6242747751189388, 0.6148763425366952], Output: [0.831443000889427, 0.2097242930467143, -0.3227808419597056, 0.9626515460143904]\n",
      "Layer: Layer 2, Input: [0.831443000889427, 0.2097242930467143, -0.3227808419597056, 0.9626515460143904], Output: [0.7530450932097773]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.823719792126319, -0.8120377944259655, 0.9983070112036321, -0.98249963793831]\n",
      "Layer: Layer 1, Input: [0.823719792126319, -0.8120377944259655, 0.9983070112036321, -0.98249963793831], Output: [0.5403665122520223, 0.38084180078704943, -0.7300541948026973, 0.7853127677278696]\n",
      "Layer: Layer 2, Input: [0.5403665122520223, 0.38084180078704943, -0.7300541948026973, 0.7853127677278696], Output: [0.4024926214106205]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5078102853943135, -0.9203379052911412, -0.23613940708443512, -0.24821947583802215]\n",
      "Layer: Layer 1, Input: [0.5078102853943135, -0.9203379052911412, -0.23613940708443512, -0.24821947583802215], Output: [-0.19407205413689987, -0.5407891013321503, -0.4975550552464046, -0.050450669771368764]\n",
      "Layer: Layer 2, Input: [-0.19407205413689987, -0.5407891013321503, -0.4975550552464046, -0.050450669771368764], Output: [-0.977176465412675]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.585870035543845, -0.8760715129241654, 0.7769424346656424, -0.04608931816886249]\n",
      "Layer: Layer 1, Input: [0.585870035543845, -0.8760715129241654, 0.7769424346656424, -0.04608931816886249], Output: [0.5998757389839683, 0.29595602332192494, -0.3971702650449434, 0.8433063612510546]\n",
      "Layer: Layer 2, Input: [0.5998757389839683, 0.29595602332192494, -0.3971702650449434, 0.8433063612510546], Output: [0.4830442188847629]\n",
      "Epoch 75/100, Loss: 0.5739341181146312, Accuracy: -1.189226843903405\n",
      "Power operation: base = -0.2469549067902227, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4024926214106204, power = 2, grad = 0.25\n",
      "Power operation: base = 0.022823534587325, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5169557811152371, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9940470169413695, -0.9997289159359651, 0.6337180181627076, 0.6242148814304584]\n",
      "Layer: Layer 1, Input: [0.9940470169413695, -0.9997289159359651, 0.6337180181627076, 0.6242148814304584], Output: [0.8349949382295682, 0.21959010086277927, -0.31867699094140123, 0.963696310410864]\n",
      "Layer: Layer 2, Input: [0.8349949382295682, 0.21959010086277927, -0.31867699094140123, 0.963696310410864], Output: [0.7608090119786174]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8244565954795957, -0.8105318948661042, 0.9983265874525459, -0.9823119665336557]\n",
      "Layer: Layer 1, Input: [0.8244565954795957, -0.8105318948661042, 0.9983265874525459, -0.9823119665336557], Output: [0.5399564095946076, 0.3810844629975833, -0.7299234805605513, 0.7849511020891761]\n",
      "Layer: Layer 2, Input: [0.5399564095946076, 0.3810844629975833, -0.7299234805605513, 0.7849511020891761], Output: [0.40331093914087524]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5077401784559604, -0.9193100149024289, -0.2326983827947071, -0.24520645521318002]\n",
      "Layer: Layer 1, Input: [0.5077401784559604, -0.9193100149024289, -0.2326983827947071, -0.24520645521318002], Output: [-0.19758025650897248, -0.5390631802593674, -0.4960496514977005, -0.049975739358672056]\n",
      "Layer: Layer 2, Input: [-0.19758025650897248, -0.5390631802593674, -0.4960496514977005, -0.049975739358672056], Output: [-0.9975157195345936]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5897199060374432, -0.8758395125975977, 0.7805194782516195, -0.03746511465827113]\n",
      "Layer: Layer 1, Input: [0.5897199060374432, -0.8758395125975977, 0.7805194782516195, -0.03746511465827113], Output: [0.6042458781919353, 0.29950691919846933, -0.39495788070033266, 0.8465111146992241]\n",
      "Layer: Layer 2, Input: [0.6042458781919353, 0.29950691919846933, -0.39495788070033266, 0.8465111146992241], Output: [0.4900896439150103]\n",
      "Epoch 76/100, Loss: 0.5716271658888105, Accuracy: -1.1548965637126538\n",
      "Power operation: base = -0.2391909880213826, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4033109391408751, power = 2, grad = 0.25\n",
      "Power operation: base = 0.0024842804654063855, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5099103560849897, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9941988907945134, -0.9997319247199468, 0.6429512818272822, 0.6333237304409463]\n",
      "Layer: Layer 1, Input: [0.9941988907945134, -0.9997319247199468, 0.6429512818272822, 0.6333237304409463], Output: [0.8384148076897296, 0.22924014556966113, -0.31476223676088094, 0.9646946347570565]\n",
      "Layer: Layer 2, Input: [0.8384148076897296, 0.22924014556966113, -0.31476223676088094, 0.9646946347570565], Output: [0.768453483395151]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8252022248760531, -0.8089560973267087, 0.9983464498642242, -0.9821212359758509]\n",
      "Layer: Layer 1, Input: [0.8252022248760531, -0.8089560973267087, 0.9983464498642242, -0.9821212359758509], Output: [0.5393659812495819, 0.38127181521742337, -0.7298282380041978, 0.7846082146967339]\n",
      "Layer: Layer 2, Input: [0.5393659812495819, 0.38127181521742337, -0.7298282380041978, 0.7846082146967339], Output: [0.4039104049028496]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5077186647142539, -0.9182449696001401, -0.22906309328718163, -0.24213502864959208]\n",
      "Layer: Layer 1, Input: [0.5077186647142539, -0.9182449696001401, -0.22906309328718163, -0.24213502864959208], Output: [-0.20096486737197344, -0.5372473422912271, -0.49455367168777886, -0.04908588109107851]\n",
      "Layer: Layer 2, Input: [-0.20096486737197344, -0.5372473422912271, -0.49455367168777886, -0.04908588109107851], Output: [-1.017354582423096]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5935384714498079, -0.8755619132952435, 0.784080514544598, -0.028845709248325264]\n",
      "Layer: Layer 1, Input: [0.5935384714498079, -0.8755619132952435, 0.784080514544598, -0.028845709248325264], Output: [0.608503979504003, 0.3030135929825021, -0.3927936734640409, 0.8496704181953193]\n",
      "Layer: Layer 2, Input: [0.608503979504003, 0.3030135929825021, -0.3927936734640409, 0.8496704181953193], Output: [0.49709875007794146]\n",
      "Epoch 77/100, Loss: 0.5694472657626428, Accuracy: -1.1557127538528533\n",
      "Power operation: base = -0.23154651660484904, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4039104049028497, power = 2, grad = 0.25\n",
      "Power operation: base = -0.017354582423096065, power = 2, grad = 0.25\n",
      "Power operation: base = -0.5029012499220585, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9943458162669079, -0.999734772175783, 0.6519788744301146, 0.6422068203500548]\n",
      "Layer: Layer 1, Input: [0.9943458162669079, -0.999734772175783, 0.6519788744301146, 0.6422068203500548], Output: [0.8417062457744163, 0.23867707399824195, -0.31103519638882154, 0.9656492071228637]\n",
      "Layer: Layer 2, Input: [0.8417062457744163, 0.23867707399824195, -0.31103519638882154, 0.9656492071228637], Output: [0.775974145998938]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8259565403980096, -0.8073077347397948, 0.9983665947382723, -0.9819273907014721]\n",
      "Layer: Layer 1, Input: [0.8259565403980096, -0.8073077347397948, 0.9983665947382723, -0.9819273907014721], Output: [0.5385886183606204, 0.38139967514588474, -0.72976584728004, 0.784285147091135]\n",
      "Layer: Layer 2, Input: [0.5385886183606204, 0.38139967514588474, -0.72976584728004, 0.784285147091135], Output: [0.4042779435615107]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5077459897701365, -0.9171410632313699, -0.2252290572409407, -0.23900498304011858]\n",
      "Layer: Layer 1, Input: [0.5077459897701365, -0.9171410632313699, -0.2252290572409407, -0.23900498304011858], Output: [-0.20422525905363703, -0.5353390760168569, -0.4930655695854099, -0.047771005509348576]\n",
      "Layer: Layer 2, Input: [-0.20422525905363703, -0.5353390760168569, -0.4930655695854099, -0.047771005509348576], Output: [-1.0366665665812969]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.5973254581500297, -0.8752376680255468, 0.787625877289582, -0.0202323722799486]\n",
      "Layer: Layer 1, Input: [0.5973254581500297, -0.8752376680255468, 0.787625877289582, -0.0202323722799486], Output: [0.6126475222307095, 0.3064742073530096, -0.3906762138936802, 0.8527846210546307]\n",
      "Layer: Layer 2, Input: [0.6126475222307095, 0.3064742073530096, -0.3906762138936802, 0.8527846210546307], Output: [0.5040593572965797]\n",
      "Epoch 78/100, Loss: 0.5673714210560483, Accuracy: -1.1609110068472899\n",
      "Power operation: base = -0.224025854001062, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4042779435615107, power = 2, grad = 0.25\n",
      "Power operation: base = -0.036666566581296856, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4959406427034203, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9944879581797919, -0.9997374616305807, 0.6608050724050826, 0.6508683168245675]\n",
      "Layer: Layer 1, Input: [0.9944879581797919, -0.9997374616305807, 0.6608050724050826, 0.6508683168245675], Output: [0.8448727676451, 0.24790370138647944, -0.3074941293832275, 0.9665625310721662]\n",
      "Layer: Layer 2, Input: [0.8448727676451, 0.24790370138647944, -0.3074941293832275, 0.9665625310721662], Output: [0.7833670852095247]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8267193555770563, -0.8055839786069626, 0.9983870162355206, -0.9817303758945415]\n",
      "Layer: Layer 1, Input: [0.8267193555770563, -0.8055839786069626, 0.9983870162355206, -0.9817303758945415], Output: [0.5376172746897923, 0.38146389305373707, -0.7297336474463684, 0.7839828014229644]\n",
      "Layer: Layer 2, Input: [0.5376172746897923, 0.38146389305373707, -0.7297336474463684, 0.7839828014229644], Output: [0.40440028664628547]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5078222043379957, -0.9159964724091253, -0.22119227972224834, -0.2358162264836461]\n",
      "Layer: Layer 1, Input: [0.5078222043379957, -0.9159964724091253, -0.22119227972224834, -0.2358162264836461], Output: [-0.20736183383472906, -0.5333360730377312, -0.491583762942003, -0.04602228947223693]\n",
      "Layer: Layer 2, Input: [-0.20736183383472906, -0.5333360730377312, -0.491583762942003, -0.04602228947223693], Output: [-1.0554270109211892]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6010806160114339, -0.8748656669248085, 0.7911557261528249, -0.011626308045974526]\n",
      "Layer: Layer 1, Input: [0.6010806160114339, -0.8748656669248085, 0.7911557261528249, -0.011626308045974526], Output: [0.6166738406120947, 0.3098868530711545, -0.3886039767781228, 0.8558539299262771]\n",
      "Layer: Layer 2, Input: [0.6166738406120947, 0.3098868530711545, -0.3886039767781228, 0.8558539299262771], Output: [0.5109593946291042]\n",
      "Epoch 79/100, Loss: 0.565375713035994, Accuracy: -1.1655008177288457\n",
      "Power operation: base = -0.2166329147904753, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4044002866462855, power = 2, grad = 0.25\n",
      "Power operation: base = -0.05542701092118918, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4890406053708958, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9946254792961464, -0.9997399963008128, 0.6694341057250494, 0.6593125953201064]\n",
      "Layer: Layer 1, Input: [0.9946254792961464, -0.9997399963008128, 0.6694341057250494, 0.6593125953201064], Output: [0.8479177742909371, 0.2569229996139609, -0.30413697223381664, 0.9674369386837248]\n",
      "Layer: Layer 2, Input: [0.8479177742909371, 0.2569229996139609, -0.30413697223381664, 0.9674369386837248], Output: [0.7906288827572119]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8274904384628684, -0.8037818267348966, 0.9984077064397678, -0.9815301374192802]\n",
      "Layer: Layer 1, Input: [0.8274904384628684, -0.8037818267348966, 0.9984077064397678, -0.9815301374192802], Output: [0.5364444432641899, 0.38146035318205573, -0.7297289435415617, 0.7837019392166192]\n",
      "Layer: Layer 2, Input: [0.5364444432641899, 0.38146035318205573, -0.7297289435415617, 0.7837019392166192], Output: [0.404263973601805]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5079471638967912, -0.914809246971435, -0.21694926930050504, -0.23256878610555812]\n",
      "Layer: Layer 1, Input: [0.5079471638967912, -0.914809246971435, -0.21694926930050504, -0.23256878610555812], Output: [-0.2103760428891979, -0.5312362442596182, -0.4901066342054653, -0.04383220272470857]\n",
      "Layer: Layer 2, Input: [-0.2103760428891979, -0.5312362442596182, -0.4901066342054653, -0.04383220272470857], Output: [-1.0736132170731518]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6048037189455739, -0.8744447320018137, 0.7946700516081856, -0.00302864963524064]\n",
      "Layer: Layer 1, Input: [0.6048037189455739, -0.8744447320018137, 0.7946700516081856, -0.00302864963524064], Output: [0.6205801397266867, 0.31324956140816973, -0.38657534882187283, 0.8588784270997595]\n",
      "Layer: Layer 2, Input: [0.6205801397266867, 0.31324956140816973, -0.38657534882187283, 0.8588784270997595], Output: [0.517786969219046]\n",
      "Epoch 80/100, Loss: 0.5634354712685592, Accuracy: -1.169461338698699\n",
      "Power operation: base = -0.20937111724278812, power = 2, grad = 0.25\n",
      "Power operation: base = 1.404263973601805, power = 2, grad = 0.25\n",
      "Power operation: base = -0.07361321707315183, power = 2, grad = 0.25\n",
      "Power operation: base = -0.482213030780954, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9947585400796075, -0.9997423792902231, 0.6778701438291841, 0.6675442159108081]\n",
      "Layer: Layer 1, Input: [0.9947585400796075, -0.9997423792902231, 0.6778701438291841, 0.6675442159108081], Output: [0.8508445592050499, 0.2657380861137311, -0.30096137337912504, 0.9682746025305285]\n",
      "Layer: Layer 2, Input: [0.8508445592050499, 0.2657380861137311, -0.30096137337912504, 0.9682746025305285], Output: [0.7977566647386278]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8282695130768969, -0.8018980901634886, 0.9984286554319366, -0.9813266217502647]\n",
      "Layer: Layer 1, Input: [0.8282695130768969, -0.8018980901634886, 0.9984286554319366, -0.9813266217502647], Output: [0.5350621306085149, 0.3813849734222078, -0.7297490129538087, 0.7834431802538636]\n",
      "Layer: Layer 2, Input: [0.5350621306085149, 0.3813849734222078, -0.7297490129538087, 0.7834431802538636], Output: [0.4038553485182157]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5081205299075304, -0.9135772997062059, -0.2124970541187194, -0.22926280554366782]\n",
      "Layer: Layer 1, Input: [0.5081205299075304, -0.9135772997062059, -0.2124970541187194, -0.22926280554366782], Output: [-0.21327040262305405, -0.5290377374288059, -0.48863253087075154, -0.04119453405758279]\n",
      "Layer: Layer 2, Input: [-0.21327040262305405, -0.5290377374288059, -0.48863253087075154, -0.04119453405758279], Output: [-1.0912045799992136]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6084945654121215, -0.8739736115378907, 0.798168680371919, 0.005559545403683915]\n",
      "Layer: Layer 1, Input: [0.6084945654121215, -0.8739736115378907, 0.798168680371919, 0.005559545403683915], Output: [0.6243635102874325, 0.3165603160279985, -0.3845886364058592, 0.8618580878390428]\n",
      "Layer: Layer 2, Input: [0.6243635102874325, 0.3165603160279985, -0.3845886364058592, 0.8618580878390428], Output: [0.524530434099695]\n",
      "Epoch 81/100, Loss: 0.5615254474327755, Accuracy: -1.1727728296791065\n",
      "Power operation: base = -0.20224333526137217, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4038553485182157, power = 2, grad = 0.25\n",
      "Power operation: base = -0.09120457999921361, power = 2, grad = 0.25\n",
      "Power operation: base = -0.475469565900305, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9948872984685548, -0.9997446135879064, 0.6861172823439805, 0.6755678982883073]\n",
      "Layer: Layer 1, Input: [0.9948872984685548, -0.9997446135879064, 0.6861172823439805, 0.6755678982883073], Output: [0.8536563147386695, 0.2743522136120977, -0.29796472850293554, 0.9690775467389734]\n",
      "Layer: Layer 2, Input: [0.8536563147386695, 0.2743522136120977, -0.29796472850293554, 0.9690775467389734], Output: [0.8047481482714595]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8290562612760562, -0.7999293793002432, 0.9984498513766722, -0.9811197758979389]\n",
      "Layer: Layer 1, Input: [0.8290562612760562, -0.7999293793002432, 0.9984498513766722, -0.9811197758979389], Output: [0.5334618287327357, 0.3812337032580692, -0.7297911110437219, 0.7832070016990921]\n",
      "Layer: Layer 2, Input: [0.5334618287327357, 0.3812337032580692, -0.7297911110437219, 0.7832070016990921], Output: [0.4031605523299061]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.508341772664551, -0.9122983953066707, -0.2078331967217811, -0.2258985420516027]\n",
      "Layer: Layer 1, Input: [0.508341772664551, -0.9122983953066707, -0.2078331967217811, -0.2258985420516027], Output: [-0.2160485080020696, -0.5267389558331587, -0.48715976543741607, -0.038104416657268846]\n",
      "Layer: Layer 2, Input: [-0.2160485080020696, -0.5267389558331587, -0.48715976543741607, -0.038104416657268846], Output: [-1.1081827117454592]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.612152979001511, -0.8734509741723566, 0.8016512814632979, 0.01413729863133107]\n",
      "Layer: Layer 1, Input: [0.612152979001511, -0.8734509741723566, 0.8016512814632979, 0.01413729863133107], Output: [0.6280209425223461, 0.3198170643620649, -0.3826420733618283, 0.8647927968425867]\n",
      "Layer: Layer 2, Input: [0.6280209425223461, 0.3198170643620649, -0.3826420733618283, 0.8647927968425867], Output: [0.5311784547364028]\n",
      "Epoch 82/100, Loss: 0.5596199904105348, Accuracy: -1.1754166610675028\n",
      "Power operation: base = -0.19525185172854054, power = 2, grad = 0.25\n",
      "Power operation: base = 1.403160552329906, power = 2, grad = 0.25\n",
      "Power operation: base = -0.10818271174545924, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4688215452635972, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.995011909668137, -0.9997467020667138, 0.6941795308673823, 0.6833884971475309]\n",
      "Layer: Layer 1, Input: [0.995011909668137, -0.9997467020667138, 0.6941795308673823, 0.6833884971475309], Output: [0.8563561382991435, 0.2827687608310202, -0.2951442157448653, 0.9698476572389594]\n",
      "Layer: Layer 2, Input: [0.8563561382991435, 0.2827687608310202, -0.2951442157448653, 0.9698476572389594], Output: [0.8116016867104653]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8298503250488093, -0.7978720892893162, 0.9984712806212833, -0.9809095473271267]\n",
      "Layer: Layer 1, Input: [0.8298503250488093, -0.7978720892893162, 0.9984712806212833, -0.9809095473271267], Output: [0.5316344850914277, 0.3810025199723849, -0.7298524759838546, 0.7829937376186353]\n",
      "Layer: Layer 2, Input: [0.5316344850914277, 0.3810025199723849, -0.7298524759838546, 0.7829937376186353], Output: [0.40216551055237415]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5086101758386088, -0.9109701385256357, -0.20295580741022343, -0.22247636316899383]\n",
      "Layer: Layer 1, Input: [0.5086101758386088, -0.9109701385256357, -0.20295580741022343, -0.22247636316899383], Output: [-0.21871504238213754, -0.5243385780468217, -0.48568661494724774, -0.03455835202331311]\n",
      "Layer: Layer 2, Input: [-0.21871504238213754, -0.5243385780468217, -0.48568661494724774, -0.03455835202331311], Output: [-1.1245315569422676]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6157788091849287, -0.8728754027117831, 0.805117372962108, 0.022703713579056827]\n",
      "Layer: Layer 1, Input: [0.6157788091849287, -0.8728754027117831, 0.805117372962108, 0.022703713579056827], Output: [0.6315493393654567, 0.3230177285238759, -0.38073382870354033, 0.8676823639327739]\n",
      "Layer: Layer 2, Input: [0.6315493393654567, 0.3230177285238759, -0.38073382870354033, 0.8676823639327739], Output: [0.5377200742266853]\n",
      "Epoch 83/100, Loss: 0.5576932204700971, Accuracy: -1.177375306557491\n",
      "Power operation: base = -0.1883983132895347, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4021655105523743, power = 2, grad = 0.25\n",
      "Power operation: base = -0.12453155694226758, power = 2, grad = 0.25\n",
      "Power operation: base = -0.46227992577331467, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9951325259623535, -0.9997486474821466, 0.7020608020577349, 0.6910109781485856]\n",
      "Layer: Layer 1, Input: [0.9951325259623535, -0.9997486474821466, 0.7020608020577349, 0.6910109781485856], Output: [0.8589470385486814, 0.29099122426473883, -0.2924968304902547, 0.9705866913055243]\n",
      "Layer: Layer 2, Input: [0.8589470385486814, 0.29099122426473883, -0.2924968304902547, 0.9705866913055243], Output: [0.8183163133637105]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.830651309262326, -0.7957223846617476, 0.9984929278067675, -0.9806958838659979]\n",
      "Layer: Layer 1, Input: [0.830651309262326, -0.7957223846617476, 0.9984929278067675, -0.9806958838659979], Output: [0.5295704707833662, 0.38068742314049214, -0.7299303327912401, 0.7828035790724021]\n",
      "Layer: Layer 2, Input: [0.5295704707833662, 0.38068742314049214, -0.7299303327912401, 0.7828035790724021], Output: [0.40085591670668885]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5089248427584973, -0.9095899615017433, -0.19786355585625662, -0.21899674290782406]\n",
      "Layer: Layer 1, Input: [0.5089248427584973, -0.9095899615017433, -0.19786355585625662, -0.21899674290782406], Output: [-0.22127578328401457, -0.5218355785564235, -0.4842113200773692, -0.03055423161823862]\n",
      "Layer: Layer 2, Input: [-0.22127578328401457, -0.5218355785564235, -0.4842113200773692, -0.03055423161823862], Output: [-1.1402374984321657]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6193719323207906, -0.8722453877117821, 0.8085663295235174, 0.03125797796801877]\n",
      "Layer: Layer 1, Input: [0.6193719323207906, -0.8722453877117821, 0.8085663295235174, 0.03125797796801877], Output: [0.6349455292065513, 0.3261602158182002, -0.37886201426460125, 0.8705265390765166]\n",
      "Layer: Layer 2, Input: [0.6349455292065513, 0.3261602158182002, -0.37886201426460125, 0.8705265390765166], Output: [0.5441447771000726]\n",
      "Epoch 84/100, Loss: 0.5557192003933862, Accuracy: -1.1786323246750716\n",
      "Power operation: base = -0.18168368663628953, power = 2, grad = 0.25\n",
      "Power operation: base = 1.4008559167066887, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1402374984321657, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4558552228999274, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.995249296547692, -0.9997504524719131, 0.7097649022342859, 0.6984403946144868]\n",
      "Layer: Layer 1, Input: [0.995249296547692, -0.9997504524719131, 0.7097649022342859, 0.6984403946144868], Output: [0.8614319417494039, 0.299023211113444, -0.29001941943575915, 0.9712962864820347]\n",
      "Layer: Layer 2, Input: [0.8614319417494039, 0.299023211113444, -0.29001941943575915, 0.9712962864820347], Output: [0.8248917836146203]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8314587848746557, -0.793476183336013, 0.9985147759904902, -0.9804787336028417]\n",
      "Layer: Layer 1, Input: [0.8314587848746557, -0.793476183336013, 0.9985147759904902, -0.9804787336028417], Output: [0.5272595473184535, 0.3802844274568869, -0.7300218965406919, 0.7826365749762347]\n",
      "Layer: Layer 2, Input: [0.5272595473184535, 0.3802844274568869, -0.7300218965406919, 0.7826365749762347], Output: [0.39921721166050705]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5092847044647412, -0.9081551102380611, -0.19255568069493514, -0.21546025740728653]\n",
      "Layer: Layer 1, Input: [0.5092847044647412, -0.9081551102380611, -0.19255568069493514, -0.21546025740728653], Output: [-0.22373760348879904, -0.5192292490678324, -0.48273208376621646, -0.02609135521891239]\n",
      "Layer: Layer 2, Input: [-0.22373760348879904, -0.5192292490678324, -0.48273208376621646, -0.02609135521891239], Output: [-1.1552894511866414]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6229322529983297, -0.8715593208924898, 0.8119973906961278, 0.03979936534945492]\n",
      "Layer: Layer 1, Input: [0.6229322529983297, -0.8715593208924898, 0.8119973906961278, 0.03979936534945492], Output: [0.6382062784669533, 0.32924242890349986, -0.37702469220009543, 0.8733250268306945]\n",
      "Layer: Layer 2, Input: [0.6382062784669533, 0.32924242890349986, -0.37702469220009543, 0.8733250268306945], Output: [0.5504425516678833]\n",
      "Epoch 85/100, Loss: 0.5536721014633513, Accuracy: -1.179172327564645\n",
      "Power operation: base = -0.17510821638537966, power = 2, grad = 0.25\n",
      "Power operation: base = 1.399217211660507, power = 2, grad = 0.25\n",
      "Power operation: base = -0.1552894511866414, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44955744833211675, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9953623673892171, -0.9997521195563338, 0.7172955236546188, 0.705681865094397]\n",
      "Layer: Layer 1, Input: [0.9953623673892171, -0.9997521195563338, 0.7172955236546188, 0.705681865094397], Output: [0.8638136983873865, 0.3068684334228822, -0.28770871365823436, 0.971977968964263]\n",
      "Layer: Layer 2, Input: [0.8638136983873865, 0.3068684334228822, -0.28770871365823436, 0.971977968964263], Output: [0.8313286153132332]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8322722926201196, -0.7911291400658585, 0.9985368067798864, -0.9802580447680638]\n",
      "Layer: Layer 1, Input: [0.8322722926201196, -0.7911291400658585, 0.9985368067798864, -0.9802580447680638], Output: [0.5246908323469043, 0.37978955396379227, -0.730124374757852, 0.7824926339461805]\n",
      "Layer: Layer 2, Input: [0.5246908323469043, 0.37978955396379227, -0.730124374757852, 0.7824926339461805], Output: [0.3972345591959495]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5096885295538272, -0.9066626302230809, -0.18703199678878044, -0.21186758001576547]\n",
      "Layer: Layer 1, Input: [0.5096885295538272, -0.9066626302230809, -0.18703199678878044, -0.21186758001576547], Output: [-0.22610846677423566, -0.5165192202573369, -0.48124706935194816, -0.021170444772301657]\n",
      "Layer: Layer 2, Input: [-0.22610846677423566, -0.5165192202573369, -0.48124706935194816, -0.021170444772301657], Output: [-1.1696789424792002]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6264597057875215, -0.8708154884641438, 0.8154096700702945, 0.04832723622551433]\n",
      "Layer: Layer 1, Input: [0.6264597057875215, -0.8708154884641438, 0.8154096700702945, 0.04832723622551433], Output: [0.6413283042844122, 0.33226227566734073, -0.3752198823174113, 0.8760775002919831]\n",
      "Layer: Layer 2, Input: [0.6413283042844122, 0.33226227566734073, -0.3752198823174113, 0.8760775002919831], Output: [0.5566039508690411]\n",
      "Epoch 86/100, Loss: 0.5515263623323635, Accuracy: -1.1789809354928753\n",
      "Power operation: base = -0.1686713846867668, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3972345591959496, power = 2, grad = 0.25\n",
      "Power operation: base = -0.16967894247920023, power = 2, grad = 0.25\n",
      "Power operation: base = -0.44339604913095887, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9954718810994401, -0.9997536511398069, 0.7246562385878373, 0.7127405518920568]\n",
      "Layer: Layer 1, Input: [0.9954718810994401, -0.9997536511398069, 0.7246562385878373, 0.7127405518920568], Output: [0.866095090194586, 0.31453070344094924, -0.28556136044481867, 0.9726331615139363]\n",
      "Layer: Layer 2, Input: [0.866095090194586, 0.31453070344094924, -0.28556136044481867, 0.9726331615139363], Output: [0.8376281272504655]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8330913471694944, -0.7886766294667661, 0.9985590004763399, -0.9800337655990413]\n",
      "Layer: Layer 1, Input: [0.8330913471694944, -0.7886766294667661, 0.9985590004763399, -0.9800337655990413], Output: [0.5218527648262253, 0.3791988197768443, -0.7302349690021265, 0.7823715273401987]\n",
      "Layer: Layer 2, Input: [0.5218527648262253, 0.3791988197768443, -0.7302349690021265, 0.7823715273401987], Output: [0.394892818200981]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5101349358144206, -0.905109351197384, -0.18129289986133446, -0.20821947576832]\n",
      "Layer: Layer 1, Input: [0.5101349358144206, -0.905109351197384, -0.18129289986133446, -0.20821947576832], Output: [-0.22839741756714968, -0.5137054837010032, -0.47975439820545396, -0.015793652432361856]\n",
      "Layer: Layer 2, Input: [-0.22839741756714968, -0.5137054837010032, -0.47975439820545396, -0.015793652432361856], Output: [-1.1834001761275286]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6299542574505251, -0.8700120644577273, 0.8188021652614176, 0.05684103870054667]\n",
      "Layer: Layer 1, Input: [0.6299542574505251, -0.8700120644577273, 0.8188021652614176, 0.05684103870054667], Output: [0.6443082876045266, 0.33521767887328763, -0.37344556921107774, 0.8787836146112676]\n",
      "Layer: Layer 2, Input: [0.6443082876045266, 0.33521767887328763, -0.37344556921107774, 0.8787836146112676], Output: [0.5626201515440414]\n",
      "Epoch 87/100, Loss: 0.549256838941958, Accuracy: -1.1780447155340026\n",
      "Power operation: base = -0.16237187274953446, power = 2, grad = 0.25\n",
      "Power operation: base = 1.394892818200981, power = 2, grad = 0.25\n",
      "Power operation: base = -0.18340017612752857, power = 2, grad = 0.25\n",
      "Power operation: base = -0.43737984845595856, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9955779768397645, -0.9997550495135641, 0.7318504952517685, 0.7196216406297806]\n",
      "Layer: Layer 1, Input: [0.9955779768397645, -0.9997550495135641, 0.7318504952517685, 0.7196216406297806], Output: [0.8682788376732744, 0.3220139301616277, -0.28357395367084703, 0.9732631909596153]\n",
      "Layer: Layer 2, Input: [0.8682788376732744, 0.3220139301616277, -0.28357395367084703, 0.9732631909596153], Output: [0.8437924754740961]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8339154417590864, -0.7861137287946439, 0.9985813362281649, -0.9798058441858578]\n",
      "Layer: Layer 1, Input: [0.8339154417590864, -0.7861137287946439, 0.9985813362281649, -0.9798058441858578], Output: [0.5187330701990304, 0.37850822643213705, -0.7303508756610745, 0.7822728937076483]\n",
      "Layer: Layer 2, Input: [0.5187330701990304, 0.37850822643213705, -0.7303508756610745, 0.7822728937076483], Output: [0.39217651197671166]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5106224036382766, -0.9034918710866559, -0.17533936820604196, -0.20451679524142474]\n",
      "Layer: Layer 1, Input: [0.5106224036382766, -0.9034918710866559, -0.17533936820604196, -0.20451679524142474], Output: [-0.23061456375551986, -0.510788413692385, -0.47825214684381995, -0.009964561379851206]\n",
      "Layer: Layer 2, Input: [-0.23061456375551986, -0.510788413692385, -0.47825214684381995, -0.009964561379851206], Output: [-1.1964500785177163]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6334159096534242, -0.8691471041782841, 0.8221737687073524, 0.0653403086989201]\n",
      "Layer: Layer 1, Input: [0.6334159096534242, -0.8691471041782841, 0.8221737687073524, 0.0653403086989201], Output: [0.6471428869906979, 0.33810658563501267, -0.3716997091874337, 0.8814430201091605]\n",
      "Layer: Layer 2, Input: [0.6471428869906979, 0.33810658563501267, -0.3716997091874337, 0.8814430201091605], Output: [0.5684830120486163]\n",
      "Epoch 88/100, Loss: 0.5468389438646015, Accuracy: -1.1763511029717155\n",
      "Power operation: base = -0.15620752452590392, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3921765119767118, power = 2, grad = 0.25\n",
      "Power operation: base = -0.19645007851771634, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4315169879513837, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9956807902438176, -0.9997563168599835, 0.7388816156293201, 0.7263303208901934]\n",
      "Layer: Layer 1, Input: [0.9956807902438176, -0.9997563168599835, 0.7388816156293201, 0.7263303208901934], Output: [0.8703676082133815, 0.32932211698428604, -0.2817430625389418, 0.9738692953321384]\n",
      "Layer: Layer 2, Input: [0.8703676082133815, 0.32932211698428604, -0.2817430625389418, 0.9738692953321384], Output: [0.8498246871464875]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8347440532746293, -0.78343520070217, 0.9986037921913813, -0.9795742282965478]\n",
      "Layer: Layer 1, Input: [0.8347440532746293, -0.78343520070217, 0.9986037921913813, -0.9795742282965478], Output: [0.5153187262741329, 0.3777137470124097, -0.7304692859900198, 0.7821962448415203]\n",
      "Layer: Layer 2, Input: [0.5153187262741329, 0.3777137470124097, -0.7304692859900198, 0.7821962448415203], Output: [0.3890697952641552]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5111492911682531, -0.9018065391445964, -0.16917296120330833, -0.2007604677837357]\n",
      "Layer: Layer 1, Input: [0.5111492911682531, -0.9018065391445964, -0.16917296120330833, -0.2007604677837357], Output: [-0.23277105188592623, -0.5077687886428464, -0.47673834351552447, -0.003688178013439214]\n",
      "Layer: Layer 2, Input: [-0.23277105188592623, -0.5077687886428464, -0.47673834351552447, -0.003688178013439214], Output: [-1.208828324092663]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6368447021986531, -0.8682185379260299, 0.8255232792311035, 0.07382466976723877]\n",
      "Layer: Layer 1, Input: [0.6368447021986531, -0.8682185379260299, 0.8255232792311035, 0.07382466976723877], Output: [0.6498287534814199, 0.34092697677008554, -0.3699802369780041, 0.8840553750022525]\n",
      "Layer: Layer 2, Input: [0.6498287534814199, 0.34092697677008554, -0.3699802369780041, 0.8840553750022525], Output: [0.5741851280956823]\n",
      "Epoch 89/100, Loss: 0.5442487736960232, Accuracy: -1.173888304114648\n",
      "Power operation: base = -0.1501753128535125, power = 2, grad = 0.25\n",
      "Power operation: base = 1.389069795264155, power = 2, grad = 0.25\n",
      "Power operation: base = -0.20882832409266294, power = 2, grad = 0.25\n",
      "Power operation: base = -0.42581487190431766, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9957804533615274, -0.9997574552587548, 0.7457527951249214, 0.7328717679512087]\n",
      "Layer: Layer 1, Input: [0.9957804533615274, -0.9997574552587548, 0.7457527951249214, 0.7328717679512087], Output: [0.8723640248792742, 0.3364593603735729, -0.2800652585169046, 0.9744526306714378]\n",
      "Layer: Layer 2, Input: [0.8723640248792742, 0.3364593603735729, -0.2800652585169046, 0.9744526306714378], Output: [0.8557286915836769]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8355766477672516, -0.7806354762615848, 0.9986263456967374, -0.9793388651812884]\n",
      "Layer: Layer 1, Input: [0.8355766477672516, -0.7806354762615848, 0.9986263456967374, -0.9793388651812884], Output: [0.5115959306506656, 0.376811312249549, -0.7305873854442563, 0.7821409736024852]\n",
      "Layer: Layer 2, Input: [0.5115959306506656, 0.376811312249549, -0.7305873854442563, 0.7821409736024852], Output: [0.3855564197280782]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5117138511243129, -0.9000494383788299, -0.16279581442175597, -0.19695149414216823]\n",
      "Layer: Layer 1, Input: [0.5117138511243129, -0.9000494383788299, -0.16279581442175597, -0.19695149414216823], Output: [-0.234879033968438, -0.5046478117514968, -0.4752109642565402, 0.0030290858427500598]\n",
      "Layer: Layer 2, Input: [-0.234879033968438, -0.5046478117514968, -0.4752109642565402, 0.0030290858427500598], Output: [-1.2205373380376794]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6402407167784544, -0.8672241651637561, 0.8288494142904189, 0.0822938324565422]\n",
      "Layer: Layer 1, Input: [0.6402407167784544, -0.8672241651637561, 0.8288494142904189, 0.0822938324565422], Output: [0.6523625468449167, 0.3436768760833992, -0.3682850722561434, 0.8866203577209224]\n",
      "Layer: Layer 2, Input: [0.6523625468449167, 0.3436768760833992, -0.3682850722561434, 0.8866203577209224], Output: [0.5797198866936498]\n",
      "Epoch 90/100, Loss: 0.5414632234478481, Accuracy: -1.1706451794884307\n",
      "Power operation: base = -0.14427130841632307, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3855564197280783, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2205373380376794, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4202801133063502, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9958770946224056, -0.9997584666952517, 0.7524671039683583, 0.7392511256048693]\n",
      "Layer: Layer 1, Input: [0.9958770946224056, -0.9997584666952517, 0.7524671039683583, 0.7392511256048693], Output: [0.8742706759292803, 0.34342984936316867, -0.278537140333737, 0.9750142775314495]\n",
      "Layer: Layer 2, Input: [0.8742706759292803, 0.34342984936316867, -0.278537140333737, 0.9750142775314495], Output: [0.8615093480552057]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8364126863697021, -0.777708638619893, 0.9986489734212113, -0.9790997013560232]\n",
      "Layer: Layer 1, Input: [0.8364126863697021, -0.777708638619893, 0.9986489734212113, -0.9790997013560232], Output: [0.5075500707069884, 0.3757967958475193, -0.7307023523669711, 0.7821063636475181]\n",
      "Layer: Layer 2, Input: [0.5075500707069884, 0.3757967958475193, -0.7307023523669711, 0.7821063636475181], Output: [0.3816196988017603]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.51231424922606, -0.8982163673708969, -0.15621063114012, -0.19309093852634107]\n",
      "Layer: Layer 1, Input: [0.51231424922606, -0.8982163673708969, -0.15621063114012, -0.19309093852634107], Output: [-0.2369516251202689, -0.5014271306334476, -0.4736679284278295, 0.010179441936660883]\n",
      "Layer: Layer 2, Input: [-0.2369516251202689, -0.5014271306334476, -0.4736679284278295, 0.010179441936660883], Output: [-1.2315822740385178]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6436040812284713, -0.8661616493492791, 0.8321508228058947, 0.09074759325404488]\n",
      "Layer: Layer 1, Input: [0.6436040812284713, -0.8661616493492791, 0.8321508228058947, 0.09074759325404488], Output: [0.6547409536089863, 0.34635435962983824, -0.36661212599043014, 0.8891376787701355]\n",
      "Layer: Layer 2, Input: [0.6547409536089863, 0.34635435962983824, -0.36661212599043014, 0.8891376787701355], Output: [0.5850815180362595]\n",
      "Epoch 91/100, Loss: 0.5384600872792766, Accuracy: -1.1666111067488125\n",
      "Power operation: base = -0.13849065194479426, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3816196988017602, power = 2, grad = 0.25\n",
      "Power operation: base = -0.23158227403851783, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4149184819637405, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9959708388161435, -0.9997593530714936, 0.7590274902219727, 0.7454734900278439]\n",
      "Layer: Layer 1, Input: [0.9959708388161435, -0.9997593530714936, 0.7590274902219727, 0.7454734900278439], Output: [0.8760901251187165, 0.3502378657066362, -0.27715535691206267, 0.9755552472002128]\n",
      "Layer: Layer 2, Input: [0.8760901251187165, 0.3502378657066362, -0.27715535691206267, 0.9755552472002128], Output: [0.867172469865176]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8372516315718238, -0.7746484077460006, 0.9986716515620141, -0.9788566823672723]\n",
      "Layer: Layer 1, Input: [0.8372516315718238, -0.7746484077460006, 0.9986716515620141, -0.9788566823672723], Output: [0.5031656974009162, 0.3746659993262721, -0.7308113561147495, 0.7820916011497442]\n",
      "Layer: Layer 2, Input: [0.5031656974009162, 0.3746659993262721, -0.7308113561147495, 0.7820916011497442], Output: [0.37724247300583136]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5129485841076469, -0.8963028216497615, -0.14942067020360758, -0.1891799201810468]\n",
      "Layer: Layer 1, Input: [0.5129485841076469, -0.8963028216497615, -0.14942067020360758, -0.1891799201810468], Output: [-0.23900285129950957, -0.49810885560557694, -0.4721070937604385, 0.017753766799075324]\n",
      "Layer: Layer 2, Input: [-0.23900285129950957, -0.49810885560557694, -0.4721070937604385, 0.017753766799075324], Output: [-1.2419709652264084]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6469349742385053, -0.8650285137000607, 0.8354260984298973, 0.09918583300470174]\n",
      "Layer: Layer 1, Input: [0.6469349742385053, -0.8650285137000607, 0.8354260984298973, 0.09918583300470174], Output: [0.6569607072807299, 0.3489575650092579, -0.36495930669114074, 0.8916070920561369]\n",
      "Layer: Layer 2, Input: [0.6569607072807299, 0.3489575650092579, -0.36495930669114074, 0.8916070920561369], Output: [0.5902651451992246]\n",
      "Epoch 92/100, Loss: 0.535218145366037, Accuracy: -1.1617758231678388\n",
      "Power operation: base = -0.13282753013482396, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3772424730058312, power = 2, grad = 0.25\n",
      "Power operation: base = -0.24197096522640837, power = 2, grad = 0.25\n",
      "Power operation: base = -0.4097348548007754, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9960618070883119, -0.9997601162201615, 0.7654367841999262, 0.7515438946507614]\n",
      "Layer: Layer 1, Input: [0.9960618070883119, -0.9997601162201615, 0.7654367841999262, 0.7515438946507614], Output: [0.8778249228252879, 0.35688778444165964, -0.27591662813144036, 0.9760764876432747]\n",
      "Layer: Layer 2, Input: [0.8778249228252879, 0.35688778444165964, -0.27591662813144036, 0.9760764876432747], Output: [0.8727248441783713]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8380929538050857, -0.7714481268421841, 0.9986943560109451, -0.9786097525414047]\n",
      "Layer: Layer 1, Input: [0.8380929538050857, -0.7714481268421841, 0.9986943560109451, -0.9786097525414047], Output: [0.49842650440399844, 0.3734146367553895, -0.7309115547252276, 0.7820957885412699]\n",
      "Layer: Layer 2, Input: [0.49842650440399844, 0.3734146367553895, -0.7309115547252276, 0.7820957885412699], Output: [0.3724070771193082]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.513614908598309, -0.8943039748393218, -0.14242973022161085, -0.1852196045652823]\n",
      "Layer: Layer 1, Input: [0.513614908598309, -0.8943039748393218, -0.14242973022161085, -0.1852196045652823], Output: [-0.2410475864073615, -0.49469557634714356, -0.47052625095565326, 0.02574165588307286]\n",
      "Layer: Layer 2, Input: [-0.2410475864073615, -0.49469557634714356, -0.47052625095565326, 0.02574165588307286], Output: [-1.2517138467616706]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6502336304549772, -0.8638221382148574, 0.8386737930913305, 0.1076085147309381]\n",
      "Layer: Layer 1, Input: [0.6502336304549772, -0.8638221382148574, 0.8386737930913305, 0.1076085147309381], Output: [0.6590186112187403, 0.35148470075573957, -0.36332452663358156, 0.8940284055756086]\n",
      "Layer: Layer 2, Input: [0.6590186112187403, 0.35148470075573957, -0.36332452663358156, 0.8940284055756086], Output: [0.5952668315170166]\n",
      "Epoch 93/100, Loss: 0.5317172372346038, Accuracy: -1.1561292481855912\n",
      "Power operation: base = -0.12727515582162874, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3724070771193082, power = 2, grad = 0.25\n",
      "Power operation: base = -0.25171384676167063, power = 2, grad = 0.25\n",
      "Power operation: base = -0.40473316848298335, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9961501169486907, -0.9997607579221817, 0.7716977040667036, 0.7574672959553082]\n",
      "Layer: Layer 1, Input: [0.9961501169486907, -0.9997607579221817, 0.7716977040667036, 0.7574672959553082], Output: [0.8794776180240934, 0.36338407460097355, -0.27481776333048574, 0.9765788891703123]\n",
      "Layer: Layer 2, Input: [0.8794776180240934, 0.36338407460097355, -0.27481776333048574, 0.9765788891703123], Output: [0.8781742470006513]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8389361382770095, -0.7681007511275543, 0.9987170625268103, -0.978358854723387]\n",
      "Layer: Layer 1, Input: [0.8389361382770095, -0.7681007511275543, 0.9987170625268103, -0.978358854723387], Output: [0.4933153144297088, 0.3720383198285298, -0.7310000922591364, 0.7821179602486867]\n",
      "Layer: Layer 2, Input: [0.4933153144297088, 0.3720383198285298, -0.7310000922591364, 0.7821179602486867], Output: [0.3670953109153179]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5143112522197644, -0.8922146598769651, -0.13524213022020176, -0.18121119426684418]\n",
      "Layer: Layer 1, Input: [0.5143112522197644, -0.8922146598769651, -0.13524213022020176, -0.18121119426684418], Output: [-0.24310147806693524, -0.49119037667640225, -0.4689231179157091, 0.03413149098013162]\n",
      "Layer: Layer 2, Input: [-0.24310147806693524, -0.49119037667640225, -0.4689231179157091, 0.03413149098013162], Output: [-1.260823848937142]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6535003458870323, -0.8625397583456963, 0.8418924306273152, 0.11601568072492652]\n",
      "Layer: Layer 1, Input: [0.6535003458870323, -0.8625397583456963, 0.8418924306273152, 0.11601568072492652], Output: [0.6609115646811077, 0.3539340558991138, -0.36170570817475683, 0.8964014913410396]\n",
      "Layer: Layer 2, Input: [0.6609115646811077, 0.3539340558991138, -0.36170570817475683, 0.8964014913410396], Output: [0.6000836255534292]\n",
      "Epoch 94/100, Loss: 0.5279383224863456, Accuracy: -1.1496612872983794\n",
      "Power operation: base = -0.12182575299934872, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3670953109153179, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26082384893714194, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3999163744465708, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9962358822895173, -0.9997612799284676, 0.7778128623479066, 0.7632485601122112]\n",
      "Layer: Layer 1, Input: [0.9962358822895173, -0.9997612799284676, 0.7778128623479066, 0.7632485601122112], Output: [0.8810507711275017, 0.36973129977493085, -0.27385567746639755, 0.9770632898176308]\n",
      "Layer: Layer 2, Input: [0.8810507711275017, 0.36973129977493085, -0.27385567746639755, 0.9770632898176308], Output: [0.8835294526690471]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8397806919876464, -0.7645988398621023, 0.9987397469035321, -0.9781039300120012]\n",
      "Layer: Layer 1, Input: [0.8397806919876464, -0.7645988398621023, 0.9987397469035321, -0.9781039300120012], Output: [0.48781407502310103, 0.37053254382885537, -0.7310740959827116, 0.7821571003235592]\n",
      "Layer: Layer 2, Input: [0.48781407502310103, 0.37053254382885537, -0.7310740959827116, 0.7821571003235592], Output: [0.36128841559234015]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5150356447306365, -0.8900293506953371, -0.12786268697956088, -0.1771559198127359]\n",
      "Layer: Layer 1, Input: [0.5150356447306365, -0.8900293506953371, -0.12786268697956088, -0.1771559198127359], Output: [-0.2451808614133671, -0.4875968472107712, -0.46729533371666543, 0.04291052082799688]\n",
      "Layer: Layer 2, Input: [-0.2451808614133671, -0.4875968472107712, -0.46729533371666543, 0.04291052082799688], Output: [-1.2693162601937809]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6567354835057558, -0.8611784657938828, 0.8450805202935058, 0.12440744875256693]\n",
      "Layer: Layer 1, Input: [0.6567354835057558, -0.8611784657938828, 0.8450805202935058, 0.12440744875256693], Output: [0.6626365926473721, 0.3563040098014395, -0.3601007903183462, 0.8987262943978114]\n",
      "Layer: Layer 2, Input: [0.6626365926473721, 0.3563040098014395, -0.3601007903183462, 0.8987262943978114], Output: [0.6047136036449958]\n",
      "Epoch 95/100, Loss: 0.5238635304923913, Accuracy: -1.1423616194720783\n",
      "Power operation: base = -0.11647054733095286, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3612884155923402, power = 2, grad = 0.25\n",
      "Power operation: base = -0.26931626019378085, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3952863963550042, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9963192134107473, -0.9997616839864871, 0.7837847730610671, 0.7688924503599388]\n",
      "Layer: Layer 1, Input: [0.9963192134107473, -0.9997616839864871, 0.7837847730610671, 0.7688924503599388], Output: [0.8825469676918434, 0.37593411820734024, -0.2730274048583766, 0.9775304804330146]\n",
      "Layer: Layer 2, Input: [0.8825469676918434, 0.37593411820734024, -0.2730274048583766, 0.9775304804330146], Output: [0.8888002371515737]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8406261508519404, -0.7609345526695863, 0.998762385131551, -0.9778449175007057]\n",
      "Layer: Layer 1, Input: [0.8406261508519404, -0.7609345526695863, 0.998762385131551, -0.9778449175007057], Output: [0.48190386656682427, 0.36889267515401714, -0.7311306735972923, 0.7822121617997954]\n",
      "Layer: Layer 2, Input: [0.48190386656682427, 0.36889267515401714, -0.7311306735972923, 0.7822121617997954], Output: [0.35496705854844857]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.515786140528062, -0.8877421448767163, -0.12029668940920467, -0.1730550305668103]\n",
      "Layer: Layer 1, Input: [0.515786140528062, -0.8877421448767163, -0.12029668940920467, -0.1730550305668103], Output: [-0.2473026602480849, -0.4839190957029195, -0.4656404524806444, 0.052064954341021895]\n",
      "Layer: Layer 2, Input: [-0.2473026602480849, -0.4839190957029195, -0.4656404524806444, 0.052064954341021895], Output: [-1.27720856001664]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6599394789037057, -0.8597352119972166, 0.8482365699311984, 0.13278400717260894]\n",
      "Layer: Layer 1, Input: [0.6599394789037057, -0.8597352119972166, 0.8482365699311984, 0.13278400717260894], Output: [0.6641908801015335, 0.3585930424056923, -0.3585077357276116, 0.9010028407757049]\n",
      "Layer: Layer 2, Input: [0.6641908801015335, 0.3585930424056923, -0.3585077357276116, 0.9010028407757049], Output: [0.6091559100879096]\n",
      "Epoch 96/100, Loss: 0.5194762013436727, Accuracy: -1.134219471325605\n",
      "Power operation: base = -0.11119976284842625, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3549670585484486, power = 2, grad = 0.25\n",
      "Power operation: base = -0.27720856001664007, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3908440899120904, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.996400217049252, -0.9997619718723977, 0.7896158591588575, 0.7744036150132546]\n",
      "Layer: Layer 1, Input: [0.996400217049252, -0.9997619718723977, 0.7896158591588575, 0.7744036150132546], Output: [0.8839688329767971, 0.3819972820879503, -0.27233011044644473, 0.9779812094444097]\n",
      "Layer: Layer 2, Input: [0.8839688329767971, 0.3819972820879503, -0.27233011044644473, 0.9779812094444097], Output: [0.8939973743958511]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8414720868437537, -0.7570996514385331, 0.9987849535501522, -0.9775817540356909]\n",
      "Layer: Layer 1, Input: [0.8414720868437537, -0.7570996514385331, 0.9987849535501522, -0.9775817540356909], Output: [0.47556492583281945, 0.36711394120943336, -0.731166910771871, 0.7822820875386803]\n",
      "Layer: Layer 2, Input: [0.47556492583281945, 0.36711394120943336, -0.731166910771871, 0.7822820875386803], Output: [0.34811132977380255]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.516560843697636, -0.8853467479323928, -0.11254987043753101, -0.16890978593623482]\n",
      "Layer: Layer 1, Input: [0.516560843697636, -0.8853467479323928, -0.11254987043753101, -0.16890978593623482], Output: [-0.24948427491422046, -0.4801617548631988, -0.4639559373610727, 0.06158006537566607]\n",
      "Layer: Layer 2, Input: [-0.24948427491422046, -0.4801617548631988, -0.4639559373610727, 0.06158006537566607], Output: [-1.2845202222981331]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6631128458598615, -0.858206814982811, 0.8513590985625848, 0.14114560873897863]\n",
      "Layer: Layer 1, Input: [0.6631128458598615, -0.858206814982811, 0.8513590985625848, 0.14114560873897863], Output: [0.6655718115650976, 0.3607997450791863, -0.3569245384367261, 0.9032312442107461]\n",
      "Layer: Layer 2, Input: [0.6655718115650976, 0.3607997450791863, -0.3569245384367261, 0.9032312442107461], Output: [0.6134107951552614]\n",
      "Epoch 97/100, Loss: 0.5147609210746324, Accuracy: -1.125223382520823\n",
      "Power operation: base = -0.10600262560414886, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3481113297738025, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2845202222981331, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3865892048447386, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9964789964087282, -0.9997621454295682, 0.7953084599725472, 0.7797865759827407]\n",
      "Layer: Layer 1, Input: [0.9964789964087282, -0.9997621454295682, 0.7953084599725472, 0.7797865759827407], Output: [0.8853190473226064, 0.3879256356914263, -0.27176109849916924, 0.9784161872901657]\n",
      "Layer: Layer 2, Input: [0.8853190473226064, 0.3879256356914263, -0.27176109849916924, 0.9784161872901657], Output: [0.8991326248938789]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8423181150693492, -0.7530855093346283, 0.998807428988459, -0.9773143740052433]\n",
      "Layer: Layer 1, Input: [0.8423181150693492, -0.7530855093346283, 0.998807428988459, -0.9773143740052433], Output: [0.46877668907456777, 0.36519142364237744, -0.7311798692921577, 0.7823658322529388]\n",
      "Layer: Layer 2, Input: [0.46877668907456777, 0.36519142364237744, -0.7311798692921577, 0.7823658322529388], Output: [0.3407007538849529]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5173579334843635, -0.882836460031971, -0.1046283770111302, -0.16472144713665882]\n",
      "Layer: Layer 1, Input: [0.5173579334843635, -0.882836460031971, -0.1046283770111302, -0.16472144713665882], Output: [-0.2517434562368332, -0.47632998748405564, -0.46223915492316775, 0.07144030741335959]\n",
      "Layer: Layer 2, Input: [-0.2517434562368332, -0.47632998748405564, -0.46223915492316775, 0.07144030741335959], Output: [-1.291272490392396]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6662561816328048, -0.85658997038086, 0.854446648186217, 0.14949256282018084]\n",
      "Layer: Layer 1, Input: [0.6662561816328048, -0.85658997038086, 0.854446648186217, 0.14949256282018084], Output: [0.6667770167805941, 0.3629228322902455, -0.35534923256769013, 0.905411711472725]\n",
      "Layer: Layer 2, Input: [0.6667770167805941, 0.3629228322902455, -0.35534923256769013, 0.905411711472725], Output: [0.6174796512671883]\n",
      "Epoch 98/100, Loss: 0.5097035549206351, Accuracy: -1.1153609681162817\n",
      "Power operation: base = -0.1008673751061211, power = 2, grad = 0.25\n",
      "Power operation: base = 1.340700753884953, power = 2, grad = 0.25\n",
      "Power operation: base = -0.291272490392396, power = 2, grad = 0.25\n",
      "Power operation: base = -0.3825203487328117, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9965556511869661, -0.9997622066143701, 0.8008648383502858, 0.7850457176811485]\n",
      "Layer: Layer 1, Input: [0.9965556511869661, -0.9997622066143701, 0.8008648383502858, 0.7850457176811485], Output: [0.8866003622824192, 0.3937241120031833, -0.2713178187025626, 0.9788360904860902]\n",
      "Layer: Layer 2, Input: [0.8866003622824192, 0.3937241120031833, -0.2713178187025626, 0.9788360904860902], Output: [0.9042187155412857]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.8431639006698689, -0.7488831287444824, 0.9988297888930083, -0.9770427091772338]\n",
      "Layer: Layer 1, Input: [0.8431639006698689, -0.7488831287444824, 0.9988297888930083, -0.9770427091772338], Output: [0.4615178594096586, 0.3631200560776948, -0.7311665862068079, 0.7824623853356206]\n",
      "Layer: Layer 2, Input: [0.4615178594096586, 0.3631200560776948, -0.7311665862068079, 0.7824623853356206], Output: [0.3327143226964713]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5181756899384059, -0.8802041662130043, -0.09653873890741341, -0.16049126979149134]\n",
      "Layer: Layer 1, Input: [0.5181756899384059, -0.8802041662130043, -0.09653873890741341, -0.16049126979149134], Output: [-0.2540981648397362, -0.4724294886677767, -0.4604873702837622, 0.08162943602349262]\n",
      "Layer: Layer 2, Input: [-0.2540981648397362, -0.4724294886677767, -0.4604873702837622, 0.08162943602349262], Output: [-1.2974881257135453]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.66937017178204, -0.8548812675282045, 0.8574977945534202, 0.15782522573755786]\n",
      "Layer: Layer 1, Input: [0.66937017178204, -0.8548812675282045, 0.8574977945534202, 0.15782522573755786], Output: [0.6678044235610759, 0.36496115442246396, -0.3537799024214267, 0.9075445461392809]\n",
      "Layer: Layer 2, Input: [0.6678044235610759, 0.36496115442246396, -0.3537799024214267, 0.9075445461392809], Output: [0.6213650477830959]\n",
      "Epoch 99/100, Loss: 0.5042912830884326, Accuracy: -1.1046186850856348\n",
      "Power operation: base = -0.09578128445871426, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3327143226964713, power = 2, grad = 0.25\n",
      "Power operation: base = -0.2974881257135453, power = 2, grad = 0.25\n",
      "Power operation: base = -0.37863495221690413, power = 2, grad = 0.25\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [0.9966302775970044, -0.9997621575501617, 0.8062871872028794, 0.7901852761902074]\n",
      "Layer: Layer 1, Input: [0.9966302775970044, -0.9997621575501617, 0.8062871872028794, 0.7901852761902074], Output: [0.8878156174091354, 0.39939772746601543, -0.27099786955762456, 0.979241565303359]\n",
      "Layer: Layer 2, Input: [0.8878156174091354, 0.39939772746601543, -0.27099786955762456, 0.979241565303359], Output: [0.9092693097556452]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [0.844009165443311, -0.7444831702871576, 0.9988520114400642, -0.9767666886043905]\n",
      "Layer: Layer 1, Input: [0.844009165443311, -0.7444831702871576, 0.9988520114400642, -0.9767666886043905], Output: [0.45376650407597285, 0.360894627728055, -0.731124074427662, 0.7825707940597221]\n",
      "Layer: Layer 2, Input: [0.45376650407597285, 0.360894627728055, -0.731124074427662, 0.7825707940597221], Output: [0.32413055421437353]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [0.5190125194687298, -0.8774423313423525, -0.08828783715515819, -0.1562204976626866]\n",
      "Layer: Layer 1, Input: [0.5190125194687298, -0.8774423313423525, -0.08828783715515819, -0.1562204976626866], Output: [-0.2565664151038539, -0.46846648491832205, -0.45869774347038905, 0.09213063648513872]\n",
      "Layer: Layer 2, Input: [-0.2565664151038539, -0.46846648491832205, -0.45869774347038905, 0.09213063648513872], Output: [-1.3031911323279683]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [0.6724555942930928, -0.8530772117337136, 0.8605111567231741, 0.16614398889519727]\n",
      "Layer: Layer 1, Input: [0.6724555942930928, -0.8530772117337136, 0.8605111567231741, 0.16614398889519727], Output: [0.6686523189301563, 0.36691371210429374, -0.35221469437583325, 0.909630150668671]\n",
      "Layer: Layer 2, Input: [0.6686523189301563, 0.36691371210429374, -0.35221469437583325, 0.909630150668671], Output: [0.625070765028632]\n",
      "Epoch 100/100, Loss: 0.498512644178703, Accuracy: -1.0929816117580646\n",
      "Power operation: base = -0.09073069024435476, power = 2, grad = 0.25\n",
      "Power operation: base = 1.3241305542143735, power = 2, grad = 0.25\n",
      "Power operation: base = -0.30319113232796835, power = 2, grad = 0.25\n",
      "Power operation: base = -0.374929234971368, power = 2, grad = 0.25\n"
     ]
    }
   ],
   "source": [
    "# Run our model training for multiple epochs\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Reset model parameters\n",
    "for param in mlp.parameters():\n",
    "    param.data = random.uniform(-1, 1)  # Random initialization of parameters\n",
    "    param.grad = 0.0\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "y_true = [Value(y_i) for y_i in y]  # Convert labels to Value objects\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_preds = [mlp(i)[0] for i in x]  # Forward pass through the neural network\n",
    "    loss = loss_fn_mse(y_preds, y_true)\n",
    "    losses.append(loss)\n",
    "    accuracy.append(1 - sum([abs(y_true - y_pred.data) for y_true, y_pred in zip(y, y_preds)]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.data}, Accuracy: {accuracy[-1]}\")\n",
    "        \n",
    "    mlp.zero_grad()  # Reset gradients of all parameters\n",
    "    loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "    visited = set()\n",
    "    loss.backward(loss, visited)\n",
    "    for param in mlp.parameters():\n",
    "        param.data = param.data - learning_rate * param.grad  # Update parameters using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1825,
   "id": "62fd9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds after training: [0.9092693097556452, 0.32413055421437353, -1.3031911323279683, 0.625070765028632]\n",
      "y_true after training: [1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_preds after training: {[item.data for item in y_preds]}\")\n",
    "print(f\"y_true after training: {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1826,
   "id": "08b99310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(range(epochs), [item.data for item in losses])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "2e370b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy over epochs\n",
    "plt.plot(range(epochs), accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "id": "912faec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.0080,  0.6315,  0.2013, -1.9987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0080,  0.6315,  0.2013, -1.9987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7649,  0.5591,  0.1986, -0.9639], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.7649,  0.5591,  0.1986, -0.9639], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3581, -1.2206, -0.5217,  0.9181], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3581, -1.2206, -0.5217,  0.9181], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8759, -0.8398, -0.4790,  0.7250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8759, -0.8398, -0.4790,  0.7250], grad_fn=<TanhBackward0>),), Output: tensor([0.5528], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5528], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5528], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.8141,  0.5481, -1.5705, -0.6861], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.8141,  0.5481, -1.5705, -0.6861], grad_fn=<ViewBackward0>),), Output: tensor([-0.9482,  0.4991, -0.9171, -0.5955], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9482,  0.4991, -0.9171, -0.5955], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2511, -0.7747,  0.2231, -1.0186], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2511, -0.7747,  0.2231, -1.0186], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8486, -0.6496,  0.2195, -0.7693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8486, -0.6496,  0.2195, -0.7693], grad_fn=<TanhBackward0>),), Output: tensor([0.8540], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8540], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8540], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7748, -0.7841, -0.5231, -1.7591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7748, -0.7841, -0.5231, -1.7591], grad_fn=<ViewBackward0>),), Output: tensor([-0.6497, -0.6551, -0.4801, -0.9424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6497, -0.6551, -0.4801, -0.9424], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4910, -0.9059,  1.1426, -0.4672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4910, -0.9059,  1.1426, -0.4672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9035, -0.7192,  0.8153, -0.4360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9035, -0.7192,  0.8153, -0.4360], grad_fn=<TanhBackward0>),), Output: tensor([1.3563], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3563], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3563], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3531,  0.4977, -2.6552, -3.9193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3531,  0.4977, -2.6552, -3.9193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9821,  0.4603, -0.9902, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9821,  0.4603, -0.9902, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5759, -1.1228,  0.0065, -1.0245], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5759, -1.1228,  0.0065, -1.0245], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9180, -0.8085,  0.0065, -0.7717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9180, -0.8085,  0.0065, -0.7717], grad_fn=<TanhBackward0>),), Output: tensor([0.4844], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4844], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4844], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1020,  0.7994, -0.0229, -2.0033], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1020,  0.7994, -0.0229, -2.0033], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8012,  0.6637, -0.0229, -0.9643], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8012,  0.6637, -0.0229, -0.9643], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1919, -1.1032, -0.8885,  0.7204], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1919, -1.1032, -0.8885,  0.7204], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8312, -0.8016, -0.7107,  0.6172], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8312, -0.8016, -0.7107,  0.6172], grad_fn=<TanhBackward0>),), Output: tensor([0.1431], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1431], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1431], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7888,  0.6301, -1.6242, -0.6931], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7888,  0.6301, -1.6242, -0.6931], grad_fn=<ViewBackward0>),), Output: tensor([-0.9456,  0.5582, -0.9252, -0.6000], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9456,  0.5582, -0.9252, -0.6000], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2236, -0.8163,  0.0412, -1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2236, -0.8163,  0.0412, -1.0341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8407, -0.6731,  0.0412, -0.7756], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8407, -0.6731,  0.0412, -0.7756], grad_fn=<TanhBackward0>),), Output: tensor([0.5052], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5052], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5052], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7485, -0.7327, -0.5837, -1.7624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7485, -0.7327, -0.5837, -1.7624], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.6247, -0.5254, -0.9428], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.6247, -0.5254, -0.9428], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4322, -0.8983,  0.9788, -0.5130], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4322, -0.8983,  0.9788, -0.5130], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8921, -0.7155,  0.7525, -0.4723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8921, -0.7155,  0.7525, -0.4723], grad_fn=<TanhBackward0>),), Output: tensor([1.0877], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0877], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0877], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3352,  0.4874, -2.7083, -3.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3352,  0.4874, -2.7083, -3.9338], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814,  0.4521, -0.9912, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814,  0.4521, -0.9912, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5463, -1.1423, -0.0671, -1.0364], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5463, -1.1423, -0.0671, -1.0364], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9132, -0.8152, -0.0670, -0.7765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9132, -0.8152, -0.0670, -0.7765], grad_fn=<TanhBackward0>),), Output: tensor([0.2931], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2931], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2931], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1406,  0.8638, -0.1559, -2.0103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1406,  0.8638, -0.1559, -2.0103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8146,  0.6982, -0.1547, -0.9647], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8146,  0.6982, -0.1547, -0.9647], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0858, -1.0353, -1.0761,  0.5931], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0858, -1.0353, -1.0761,  0.5931], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7953, -0.7760, -0.7917,  0.5321], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7953, -0.7760, -0.7917,  0.5321], grad_fn=<TanhBackward0>),), Output: tensor([-0.0771], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0771], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0771], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7759,  0.6675, -1.6569, -0.7048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7759,  0.6675, -1.6569, -0.7048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9443,  0.5833, -0.9298, -0.6074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9443,  0.5833, -0.9298, -0.6074], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2070, -0.8487, -0.0593, -1.0438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2070, -0.8487, -0.0593, -1.0438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358, -0.6904, -0.0592, -0.7794], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8358, -0.6904, -0.0592, -0.7794], grad_fn=<TanhBackward0>),), Output: tensor([0.2998], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.2998], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.2998], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -0.7391, -0.6174, -1.7678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -0.7391, -0.6174, -1.7678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.6286, -0.5493, -0.9434], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.6286, -0.5493, -0.9434], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3962, -0.8934,  0.9105, -0.5400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3962, -0.8934,  0.9105, -0.5400], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8845, -0.7131,  0.7214, -0.4930], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8845, -0.7131,  0.7214, -0.4930], grad_fn=<TanhBackward0>),), Output: tensor([0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279,  0.4153, -2.7410, -3.9491], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279,  0.4153, -2.7410, -3.9491], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.3930, -0.9917, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.3930, -0.9917, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5164, -1.1398, -0.0610, -1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5164, -1.1398, -0.0610, -1.0477], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9081, -0.8144, -0.0610, -0.7809], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9081, -0.8144, -0.0610, -0.7809], grad_fn=<TanhBackward0>),), Output: tensor([0.2119], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2119], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2119], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1620,  0.8913, -0.2479, -2.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1620,  0.8913, -0.2479, -2.0177], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217,  0.7121, -0.2429, -0.9653], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8217,  0.7121, -0.2429, -0.9653], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0101, -0.9921, -1.1904,  0.5040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0101, -0.9921, -1.1904,  0.5040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7658, -0.7583, -0.8307,  0.4653], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7658, -0.7583, -0.8307,  0.4653], grad_fn=<TanhBackward0>),), Output: tensor([-0.2211], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2211], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2211], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7677,  0.6821, -1.6797, -0.7174], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7677,  0.6821, -1.6797, -0.7174], grad_fn=<ViewBackward0>),), Output: tensor([-0.9434,  0.5929, -0.9328, -0.6153], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9434,  0.5929, -0.9328, -0.6153], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1955, -0.8733, -0.1150, -1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1955, -0.8733, -0.1150, -1.0502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8323, -0.7030, -0.1145, -0.7819], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8323, -0.7030, -0.1145, -0.7819], grad_fn=<TanhBackward0>),), Output: tensor([0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7342, -0.7756, -0.6383, -1.7735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7342, -0.7756, -0.6383, -1.7735], grad_fn=<ViewBackward0>),), Output: tensor([-0.6256, -0.6502, -0.5638, -0.9440], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6256, -0.6502, -0.5638, -0.9440], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3709, -0.8864,  0.8924, -0.5578], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3709, -0.8864,  0.8924, -0.5578], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8789, -0.7096,  0.7126, -0.5064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8789, -0.7096,  0.7126, -0.5064], grad_fn=<TanhBackward0>),), Output: tensor([0.8706], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8706], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8706], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3260,  0.3002, -2.7628, -3.9642], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3260,  0.3002, -2.7628, -3.9642], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.2915, -0.9921, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.2915, -0.9921, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4850, -1.1189,  0.0027, -1.0591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4850, -1.1189,  0.0027, -1.0591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9024, -0.8072,  0.0027, -0.7853], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9024, -0.8072,  0.0027, -0.7853], grad_fn=<TanhBackward0>),), Output: tensor([0.2056], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2056], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2056], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1759,  0.8992, -0.3171, -2.0250], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1759,  0.8992, -0.3171, -2.0250], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262,  0.7159, -0.3069, -0.9658], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8262,  0.7159, -0.3069, -0.9658], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9515, -0.9620, -1.2661,  0.4373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9515, -0.9620, -1.2661,  0.4373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7405, -0.7452, -0.8527,  0.4114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7405, -0.7452, -0.8527,  0.4114], grad_fn=<TanhBackward0>),), Output: tensor([-0.3261], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3261], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3261], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7617,  0.6822, -1.6971, -0.7299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7617,  0.6822, -1.6971, -0.7299], grad_fn=<ViewBackward0>),), Output: tensor([-0.9427,  0.5930, -0.9350, -0.6230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9427,  0.5930, -0.9350, -0.6230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1865, -0.8918, -0.1450, -1.0549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1865, -0.8918, -0.1450, -1.0549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8295, -0.7123, -0.1440, -0.7837], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8295, -0.7123, -0.1440, -0.7837], grad_fn=<TanhBackward0>),), Output: tensor([0.0919], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0919], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0919], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7333, -0.8328, -0.6522, -1.7790], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7333, -0.8328, -0.6522, -1.7790], grad_fn=<ViewBackward0>),), Output: tensor([-0.6251, -0.6820, -0.5732, -0.9446], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6251, -0.6820, -0.5732, -0.9446], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3514, -0.8768,  0.9030, -0.5706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3514, -0.8768,  0.9030, -0.5706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8744, -0.7048,  0.7177, -0.5158], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8744, -0.7048,  0.7177, -0.5158], grad_fn=<TanhBackward0>),), Output: tensor([0.8348], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8348], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8348], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3265,  0.1563, -2.7783, -3.9787], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3265,  0.1563, -2.7783, -3.9787], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.1551, -0.9923, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.1551, -0.9923, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4517, -1.0827,  0.1083, -1.0711], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4517, -1.0827,  0.1083, -1.0711], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8960, -0.7942,  0.1078, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8960, -0.7942,  0.1078, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1862,  0.8956, -0.3722, -2.0321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1862,  0.8956, -0.3722, -2.0321], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8294,  0.7141, -0.3559, -0.9662], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8294,  0.7141, -0.3559, -0.9662], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9037, -0.9397, -1.3203,  0.3848], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9037, -0.9397, -1.3203,  0.3848], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7181, -0.7351, -0.8669,  0.3669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7181, -0.7351, -0.8669,  0.3669], grad_fn=<TanhBackward0>),), Output: tensor([-0.4106], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4106], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4106], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7568,  0.6732, -1.7113, -0.7421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7568,  0.6732, -1.7113, -0.7421], grad_fn=<ViewBackward0>),), Output: tensor([-0.9421,  0.5871, -0.9368, -0.6304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9421,  0.5871, -0.9368, -0.6304], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1786, -0.9063, -0.1621, -1.0588], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1786, -0.9063, -0.1621, -1.0588], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8270, -0.7194, -0.1607, -0.7852], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8270, -0.7194, -0.1607, -0.7852], grad_fn=<TanhBackward0>),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7338, -0.9037, -0.6622, -1.7844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7338, -0.9037, -0.6622, -1.7844], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.7181, -0.5798, -0.9452], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.7181, -0.5798, -0.9452], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3356, -0.8655,  0.9281, -0.5804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3356, -0.8655,  0.9281, -0.5804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8706, -0.6991,  0.7297, -0.5230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8706, -0.6991,  0.7297, -0.5230], grad_fn=<TanhBackward0>),), Output: tensor([0.8196], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8196], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8196], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3277e+00,  3.3126e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3277e+00,  3.3126e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.0033, -0.9925, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.0033, -0.9925, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4188, -1.0382,  0.2316, -1.0828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4188, -1.0382,  0.2316, -1.0828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8894, -0.7772,  0.2275, -0.7942], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8894, -0.7772,  0.2275, -0.7942], grad_fn=<TanhBackward0>),), Output: tensor([0.3211], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3211], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3211], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1943,  0.8872, -0.4174, -2.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1943,  0.8872, -0.4174, -2.0390], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8319,  0.7100, -0.3947, -0.9667], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8319,  0.7100, -0.3947, -0.9667], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8633, -0.9229, -1.3639,  0.3421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8633, -0.9229, -1.3639,  0.3421], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6980, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6980, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>),), Output: tensor([-0.4851], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4851], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4851], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7524,  0.6613, -1.7233, -0.7539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7524,  0.6613, -1.7233, -0.7539], grad_fn=<ViewBackward0>),), Output: tensor([-0.9417,  0.5792, -0.9383, -0.6375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9417,  0.5792, -0.9383, -0.6375], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1715, -0.9188, -0.1770, -1.0623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1715, -0.9188, -0.1770, -1.0623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8248, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8248, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>),), Output: tensor([-0.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7349, -0.9790, -0.6698, -1.7895], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7349, -0.9790, -0.6698, -1.7895], grad_fn=<ViewBackward0>),), Output: tensor([-0.6261, -0.7527, -0.5848, -0.9457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6261, -0.7527, -0.5848, -0.9457], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3225, -0.8541,  0.9561, -0.5881], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3225, -0.8541,  0.9561, -0.5881], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8674, -0.6932,  0.7426, -0.5286], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8674, -0.6932,  0.7426, -0.5286], grad_fn=<TanhBackward0>),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -0.1373, -2.8000, -4.0063], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -0.1373, -2.8000, -4.0063], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.1364, -0.9926, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.1364, -0.9926, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3899, -0.9953,  0.3445, -1.0929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3899, -0.9953,  0.3445, -1.0929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8832, -0.7596,  0.3315, -0.7979], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8832, -0.7596,  0.3315, -0.7979], grad_fn=<TanhBackward0>),), Output: tensor([0.3864], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3864], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3864], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2012,  0.8800, -0.4550, -2.0458], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2012,  0.8800, -0.4550, -2.0458], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8340,  0.7064, -0.4260, -0.9671], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8340,  0.7064, -0.4260, -0.9671], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8291, -0.9110, -1.4037,  0.3069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8291, -0.9110, -1.4037,  0.3069], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6800, -0.7216, -0.8861,  0.2976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6800, -0.7216, -0.8861,  0.2976], grad_fn=<TanhBackward0>),), Output: tensor([-0.5542], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5542], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5542], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7482,  0.6526, -1.7338, -0.7653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7482,  0.6526, -1.7338, -0.7653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1653, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1653, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8228, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8228, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>),), Output: tensor([-0.0744], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0744], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0744], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.0487, -0.6757, -1.7944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.0487, -0.6757, -1.7944], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.7813, -0.5887, -0.9462], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.7813, -0.5887, -0.9462], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3120, -0.8440,  0.9790, -0.5942], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3120, -0.8440,  0.9790, -0.5942], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.6879,  0.7526, -0.5329], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.6879,  0.7526, -0.5329], grad_fn=<TanhBackward0>),), Output: tensor([0.8071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3298, -0.2556, -2.8077, -4.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3298, -0.2556, -2.8077, -4.0194], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.2502, -0.9927, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.2502, -0.9927, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3667, -0.9590,  0.4341, -1.1007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3667, -0.9590,  0.4341, -1.1007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8779, -0.7438,  0.4087, -0.8008], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8779, -0.7438,  0.4087, -0.8008], grad_fn=<TanhBackward0>),), Output: tensor([0.4358], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4358], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4358], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2069,  0.8763, -0.4862, -2.0522], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2069,  0.8763, -0.4862, -2.0522], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8357,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8357,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8002, -0.9030, -1.4416,  0.2780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8002, -0.9030, -1.4416,  0.2780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6641, -0.7177, -0.8940,  0.2711], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6641, -0.7177, -0.8940,  0.2711], grad_fn=<TanhBackward0>),), Output: tensor([-0.6184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7442,  0.6493, -1.7429, -0.7764], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7442,  0.6493, -1.7429, -0.7764], grad_fn=<ViewBackward0>),), Output: tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8211, -0.7366, -0.2204, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8211, -0.7366, -0.2204, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.1335], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1335], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1335], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7372, -1.1080, -0.6803, -1.7992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7372, -1.1080, -0.6803, -1.7992], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3040, -0.8354,  0.9953, -0.5987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3040, -0.8354,  0.9953, -0.5987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6834,  0.7596, -0.5361], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6834,  0.7596, -0.5361], grad_fn=<TanhBackward0>),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3308, -0.3536, -2.8134, -4.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3308, -0.3536, -2.8134, -4.0317], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.3396, -0.9928, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.3396, -0.9928, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3486, -0.9289,  0.5027, -1.1065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3486, -0.9289,  0.5027, -1.1065], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8737, -0.7301,  0.4642, -0.8028], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8737, -0.7301,  0.4642, -0.8028], grad_fn=<TanhBackward0>),), Output: tensor([0.4729], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4729], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4729], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2116,  0.8754, -0.5119, -2.0584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2116,  0.8754, -0.5119, -2.0584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7760, -0.8979, -1.4771,  0.2544], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7760, -0.8979, -1.4771,  0.2544], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6504, -0.7153, -0.9009,  0.2490], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6504, -0.7153, -0.9009,  0.2490], grad_fn=<TanhBackward0>),), Output: tensor([-0.6767], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6767], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6767], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7405,  0.6505, -1.7508, -0.7868], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7405,  0.6505, -1.7508, -0.7868], grad_fn=<ViewBackward0>),), Output: tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1563, -0.9548, -0.2549, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1563, -0.9548, -0.2549, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8198, -0.7419, -0.2495, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8198, -0.7419, -0.2495, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7383, -1.1578, -0.6836, -1.8037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7383, -1.1578, -0.6836, -1.8037], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.8203, -0.5938, -0.9472], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.8203, -0.5938, -0.9472], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2980, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2980, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8612, -0.6793,  0.7646, -0.5383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8612, -0.6793,  0.7646, -0.5383], grad_fn=<TanhBackward0>),), Output: tensor([0.7999], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7999], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7999], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3320, -0.4359, -2.8175, -4.0432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3320, -0.4359, -2.8175, -4.0432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.4102, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.4102, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3347, -0.9034,  0.5563, -1.1106], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3347, -0.9034,  0.5563, -1.1106], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8704, -0.7179,  0.5052, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8704, -0.7179,  0.5052, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2154,  0.8761, -0.5328, -2.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2154,  0.8761, -0.5328, -2.0642], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7560, -0.8948, -1.5097,  0.2352], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7560, -0.8948, -1.5097,  0.2352], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>),), Output: tensor([-0.7288], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7288], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7288], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7370,  0.6546, -1.7576, -0.7967], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7370,  0.6546, -1.7576, -0.7967], grad_fn=<ViewBackward0>),), Output: tensor([-0.9399,  0.5748, -0.9422, -0.6622], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9399,  0.5748, -0.9422, -0.6622], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1533, -0.9657, -0.2871, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1533, -0.9657, -0.2871, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7468, -0.2794, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7468, -0.2794, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.2499], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2499], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2499], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7396, -1.2002, -0.6858, -1.8078], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7396, -1.2002, -0.6858, -1.8078], grad_fn=<ViewBackward0>),), Output: tensor([-0.6289, -0.8337, -0.5953, -0.9476], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6289, -0.8337, -0.5953, -0.9476], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2939, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2939, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8601, -0.6753,  0.7686, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8601, -0.6753,  0.7686, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([0.8009], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8009], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8009], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3333, -0.5062, -2.8201, -4.0539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3333, -0.5062, -2.8201, -4.0539], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.4670, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.4670, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3239, -0.8810,  0.5994, -1.1134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3239, -0.8810,  0.5994, -1.1134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8678, -0.7069,  0.5367, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8678, -0.7069,  0.5367, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.5299], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5299], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5299], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2184,  0.8778, -0.5498, -2.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2184,  0.8778, -0.5498, -2.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8392,  0.7053, -0.5004, -0.9686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8392,  0.7053, -0.5004, -0.9686], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7394, -0.8931, -1.5390,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7394, -0.8931, -1.5390,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6288, -0.7129, -0.9119,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6288, -0.7129, -0.9119,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-0.7748], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7748], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7748], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1511, -0.9755, -0.3190, -1.0732], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1511, -0.9755, -0.3190, -1.0732], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7511, -0.3086, -0.7907], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7511, -0.3086, -0.7907], grad_fn=<TanhBackward0>),), Output: tensor([-0.3029], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3029], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3029], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7410, -1.2369, -0.6870, -1.8117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7410, -1.2369, -0.6870, -1.8117], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8595, -0.6714,  0.7721, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8595, -0.6714,  0.7721, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([0.8053], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8053], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8053], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3347, -0.5670, -2.8215, -4.0638], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3347, -0.5670, -2.8215, -4.0638], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.5132, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.5132, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.8609,  0.6350, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.8609,  0.6350, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.6967,  0.5615, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.6967,  0.5615, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.5548], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5548], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5548], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2209,  0.8798, -0.5635, -2.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2209,  0.8798, -0.5635, -2.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8399,  0.7063, -0.5105, -0.9689], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8399,  0.7063, -0.5105, -0.9689], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7258, -0.8922, -1.5651,  0.2071], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7258, -0.8922, -1.5651,  0.2071], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6205, -0.7125, -0.9162,  0.2042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6205, -0.7125, -0.9162,  0.2042], grad_fn=<TanhBackward0>),), Output: tensor([-0.8153], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8153], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8153], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1495, -0.9841, -0.3498, -1.0741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1495, -0.9841, -0.3498, -1.0741], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8176, -0.7548, -0.3362, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8176, -0.7548, -0.3362, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.3515], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3515], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3515], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7424, -1.2690, -0.6875, -1.8152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7424, -1.2690, -0.6875, -1.8152], grad_fn=<ViewBackward0>),), Output: tensor([-0.6306, -0.8535, -0.5964, -0.9484], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6306, -0.8535, -0.5964, -0.9484], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8591, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8591, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3362, -0.6201, -2.8221, -4.0730], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3362, -0.6201, -2.8221, -4.0730], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5512, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5512, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3091, -0.8427,  0.6649, -1.1164], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3091, -0.8427,  0.6649, -1.1164], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6872,  0.5816, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6872,  0.5816, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2228,  0.8820, -0.5744, -2.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2228,  0.8820, -0.5744, -2.0792], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8405,  0.7074, -0.5186, -0.9692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8405,  0.7074, -0.5186, -0.9692], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7146, -0.8918, -1.5884,  0.1971], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7146, -0.8918, -1.5884,  0.1971], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6135, -0.7123, -0.9199,  0.1946], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6135, -0.7123, -0.9199,  0.1946], grad_fn=<TanhBackward0>),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1484, -0.9916, -0.3793, -1.0747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1484, -0.9916, -0.3793, -1.0747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7581, -0.3621, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7581, -0.3621, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.3959], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3959], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3959], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7438, -1.2973, -0.6875, -1.8185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7438, -1.2973, -0.6875, -1.8185], grad_fn=<ViewBackward0>),), Output: tensor([-0.6315, -0.8610, -0.5964, -0.9487], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6315, -0.8610, -0.5964, -0.9487], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7988,  1.0417, -0.6044], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7988,  1.0417, -0.6044], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6634,  0.7786, -0.5401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6634,  0.7786, -0.5401], grad_fn=<TanhBackward0>),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3376, -0.6668, -2.8220, -4.0814], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3376, -0.6668, -2.8220, -4.0814], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5829, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5829, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3041, -0.8259,  0.6904, -1.1170], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3041, -0.8259,  0.6904, -1.1170], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.6783,  0.5982, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.6783,  0.5982, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2244,  0.8841, -0.5830, -2.0834], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2244,  0.8841, -0.5830, -2.0834], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8409,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8409,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7054, -0.8918, -1.6091,  0.1892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7054, -0.8918, -1.6091,  0.1892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6078, -0.7123, -0.9230,  0.1870], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6078, -0.7123, -0.9230,  0.1870], grad_fn=<TanhBackward0>),), Output: tensor([-0.8823], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8823], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8823], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7262,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7262,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9386,  0.5932, -0.9443, -0.6802], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9386,  0.5932, -0.9443, -0.6802], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1477, -0.9982, -0.4071, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1477, -0.9982, -0.4071, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7608, -0.3860, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7608, -0.3860, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.4364], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4364], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4364], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7452, -1.3225, -0.6871, -1.8215], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7452, -1.3225, -0.6871, -1.8215], grad_fn=<ViewBackward0>),), Output: tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2892, -0.7916,  1.0495, -0.6035], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2892, -0.7916,  1.0495, -0.6035], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3390, -0.7081, -2.8215, -4.0891], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3390, -0.7081, -2.8215, -4.0891], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6095, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6095, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3002, -0.8103,  0.7123, -1.1172], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3002, -0.8103,  0.7123, -1.1172], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8618, -0.6698,  0.6121, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8618, -0.6698,  0.6121, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2256,  0.8861, -0.5897, -2.0874], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2256,  0.8861, -0.5897, -2.0874], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6981, -0.8921, -1.6275,  0.1830], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6981, -0.8921, -1.6275,  0.1830], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>),), Output: tensor([-0.9099], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9099], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9099], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1473, -1.0038, -0.4334, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1473, -1.0038, -0.4334, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8169, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8169, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.4733], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4733], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4733], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7465, -1.3449, -0.6863, -1.8243], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7465, -1.3449, -0.6863, -1.8243], grad_fn=<ViewBackward0>),), Output: tensor([-0.6331, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6331, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8591, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8591, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3403, -0.7448, -2.8206, -4.0963], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3403, -0.7448, -2.8206, -4.0963], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6321, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6321, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2971, -0.7958,  0.7314, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2971, -0.7958,  0.7314, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6617,  0.6239, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6617,  0.6239, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.6436], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6436], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6436], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2267,  0.8879, -0.5947, -2.0910], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2267,  0.8879, -0.5947, -2.0910], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6922, -0.8924, -1.6438,  0.1783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6922, -0.8924, -1.6438,  0.1783], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5994, -0.7126, -0.9280,  0.1764], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5994, -0.7126, -0.9280,  0.1764], grad_fn=<TanhBackward0>),), Output: tensor([-0.9342], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9342], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9342], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7220,  0.6982, -1.7822, -0.8425], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7220,  0.6982, -1.7822, -0.8425], grad_fn=<ViewBackward0>),), Output: tensor([-0.9381,  0.6032, -0.9449, -0.6871], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9381,  0.6032, -0.9449, -0.6871], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0087, -0.4581, -1.0753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0087, -0.4581, -1.0753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7477, -1.3651, -0.6854, -1.8268], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7477, -1.3651, -0.6854, -1.8268], grad_fn=<ViewBackward0>),), Output: tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2906, -0.7774,  1.0645, -0.6009], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2906, -0.7774,  1.0645, -0.6009], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3414, -0.7777, -2.8196, -4.1029], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3414, -0.7777, -2.8196, -4.1029], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6514, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6514, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2948, -0.7823,  0.7482, -1.1168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2948, -0.7823,  0.7482, -1.1168], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2275,  0.8895, -0.5984, -2.0944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2275,  0.8895, -0.5984, -2.0944], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8418,  0.7111, -0.5359, -0.9701], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8418,  0.7111, -0.5359, -0.9701], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6876, -0.8929, -1.6582,  0.1748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6876, -0.8929, -1.6582,  0.1748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5964, -0.7128, -0.9300,  0.1730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5964, -0.7128, -0.9300,  0.1730], grad_fn=<TanhBackward0>),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7202,  0.7058, -1.7846, -0.8482], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7202,  0.7058, -1.7846, -0.8482], grad_fn=<ViewBackward0>),), Output: tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0130, -0.4814, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0130, -0.4814, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7670, -0.4473, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7670, -0.4473, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7489, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7489, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>),), Output: tensor([-0.6345, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6345, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2918, -0.7705,  1.0715, -0.5994], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2918, -0.7705,  1.0715, -0.5994], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3424, -0.8072, -2.8184, -4.1090], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3424, -0.8072, -2.8184, -4.1090], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6680, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6680, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2929, -0.7697,  0.7629, -1.1163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2929, -0.7697,  0.7629, -1.1163], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6468,  0.6428, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6468,  0.6428, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.6819], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6819], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6819], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2281,  0.8908, -0.6008, -2.0976], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2281,  0.8908, -0.6008, -2.0976], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8420,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8420,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6841, -0.8934, -1.6709,  0.1724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6841, -0.8934, -1.6709,  0.1724], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5942, -0.7131, -0.9317,  0.1707], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5942, -0.7131, -0.9317,  0.1707], grad_fn=<TanhBackward0>),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>),), Output: tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1472, -1.0166, -0.5032, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1472, -1.0166, -0.5032, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7685, -0.4646, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7685, -0.4646, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7499, -1.3997, -0.6832, -1.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7499, -1.3997, -0.6832, -1.8314], grad_fn=<ViewBackward0>),), Output: tensor([-0.6351, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6351, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2930, -0.7638,  1.0781, -0.5978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2930, -0.7638,  1.0781, -0.5978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3432, -0.8338, -2.8172, -4.1147], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3432, -0.8338, -2.8172, -4.1147], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6825, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6825, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2915, -0.7579,  0.7760, -1.1158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2915, -0.7579,  0.7760, -1.1158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8595, -0.6399,  0.6504, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8595, -0.6399,  0.6504, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.6994], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6994], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6994], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2287,  0.8918, -0.6022, -2.1005], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2287,  0.8918, -0.6022, -2.1005], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8422,  0.7123, -0.5386, -0.9705], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8422,  0.7123, -0.5386, -0.9705], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6816, -0.8939, -1.6820,  0.1709], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6816, -0.8939, -1.6820,  0.1709], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7168,  0.7202, -1.7885, -0.8585], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7168,  0.7202, -1.7885, -0.8585], grad_fn=<ViewBackward0>),), Output: tensor([-0.9375,  0.6171, -0.9456, -0.6955], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9375,  0.6171, -0.9456, -0.6955], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1475, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1475, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8169, -0.7698, -0.4805, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8169, -0.7698, -0.4805, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7508, -1.4146, -0.6820, -1.8334], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7508, -1.4146, -0.6820, -1.8334], grad_fn=<ViewBackward0>),), Output: tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2944, -0.7573,  1.0844, -0.5961], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2944, -0.7573,  1.0844, -0.5961], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8603, -0.6395,  0.7948, -0.5343], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8603, -0.6395,  0.7948, -0.5343], grad_fn=<TanhBackward0>),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3439, -0.8579, -2.8160, -4.1200], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3439, -0.8579, -2.8160, -4.1200], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2291,  0.8926, -0.6028, -2.1032], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2291,  0.8926, -0.6028, -2.1032], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6799, -0.8944, -1.6918,  0.1702], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6799, -0.8944, -1.6918,  0.1702], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5915, -0.7136, -0.9344,  0.1686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5915, -0.7136, -0.9344,  0.1686], grad_fn=<TanhBackward0>),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>),), Output: tensor([-0.9373,  0.6212, -0.9458, -0.6978], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9373,  0.6212, -0.9458, -0.6978], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1478, -1.0226, -0.5429, -1.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1478, -1.0226, -0.5429, -1.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.6166], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6166], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6166], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7516, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7516, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>),), Output: tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2958, -0.7511,  1.0902, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2958, -0.7511,  1.0902, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8606, -0.6358,  0.7970, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8606, -0.6358,  0.7970, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3444, -0.8798, -2.8148, -4.1249], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3444, -0.8798, -2.8148, -4.1249], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7063, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7063, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2896, -0.7366,  0.7981, -1.1146], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2896, -0.7366,  0.7981, -1.1146], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2294,  0.8931, -0.6026, -2.1057], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2294,  0.8931, -0.6026, -2.1057], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8424,  0.7129, -0.5389, -0.9708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8424,  0.7129, -0.5389, -0.9708], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6790, -0.8949, -1.7003,  0.1702], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6790, -0.8949, -1.7003,  0.1702], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7138, -0.9354,  0.1686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7138, -0.9354,  0.1686], grad_fn=<TanhBackward0>),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7139,  0.7334, -1.7914, -0.8673], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7139,  0.7334, -1.7914, -0.8673], grad_fn=<ViewBackward0>),), Output: tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1483, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1483, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.6388], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6388], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6388], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7522, -1.4407, -0.6796, -1.8371], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7522, -1.4407, -0.6796, -1.8371], grad_fn=<ViewBackward0>),), Output: tensor([-0.6365, -0.8938, -0.5913, -0.9505], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6365, -0.8938, -0.5913, -0.9505], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2973, -0.7451,  1.0957, -0.5929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2973, -0.7451,  1.0957, -0.5929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3448, -0.8999, -2.8137, -4.1295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3448, -0.8999, -2.8137, -4.1295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7162, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7162, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2889, -0.7270,  0.8074, -1.1139], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2889, -0.7270,  0.8074, -1.1139], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2297,  0.8933, -0.6017, -2.1081], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2297,  0.8933, -0.6017, -2.1081], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8425,  0.7130, -0.5382, -0.9709], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8425,  0.7130, -0.5382, -0.9709], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6787, -0.8955, -1.7077,  0.1708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6787, -0.8955, -1.7077,  0.1708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5907, -0.7141, -0.9364,  0.1691], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5907, -0.7141, -0.9364,  0.1691], grad_fn=<TanhBackward0>),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7126,  0.7395, -1.7926, -0.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7126,  0.7395, -1.7926, -0.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1487, -1.0272, -0.5779, -1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1487, -1.0272, -0.5779, -1.0739], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>),), Output: tensor([-0.6593], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6593], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6593], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2987, -0.7394,  1.1008, -0.5913], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2987, -0.7394,  1.1008, -0.5913], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8614, -0.6288,  0.8008, -0.5308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8614, -0.6288,  0.8008, -0.5308], grad_fn=<TanhBackward0>),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3451, -0.9183, -2.8126, -4.1338], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3451, -0.9183, -2.8126, -4.1338], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2884, -0.7180,  0.8159, -1.1133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2884, -0.7180,  0.8159, -1.1133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8587, -0.6157,  0.6728, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8587, -0.6157,  0.6728, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2299,  0.8933, -0.6002, -2.1103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2299,  0.8933, -0.6002, -2.1103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8425,  0.7130, -0.5372, -0.9710], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8425,  0.7130, -0.5372, -0.9710], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8960, -1.7140,  0.1719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8960, -1.7140,  0.1719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7143, -0.9371,  0.1702], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7143, -0.9371,  0.1702], grad_fn=<TanhBackward0>),), Output: tensor([-1.0389], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0389], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0389], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>),), Output: tensor([-0.9368,  0.6323, -0.9461, -0.7039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9368,  0.6323, -0.9461, -0.7039], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1493, -1.0290, -0.5938, -1.0735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1493, -1.0290, -0.5938, -1.0735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.4628, -0.6774, -1.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.4628, -0.6774, -1.8403], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3001, -0.7339,  1.1056, -0.5898], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3001, -0.7339,  1.1056, -0.5898], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8617, -0.6255,  0.8025, -0.5297], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8617, -0.6255,  0.8025, -0.5297], grad_fn=<TanhBackward0>),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9352, -2.8117, -4.1378], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9352, -2.8117, -4.1378], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2881, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2881, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8586, -0.6104,  0.6769, -0.8050], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8586, -0.6104,  0.6769, -0.8050], grad_fn=<TanhBackward0>),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2300,  0.8930, -0.5983, -2.1124], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2300,  0.8930, -0.5983, -2.1124], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6797, -0.8965, -1.7194,  0.1734], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6797, -0.8965, -1.7194,  0.1734], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5913, -0.7146, -0.9378,  0.1717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5913, -0.7146, -0.9378,  0.1717], grad_fn=<TanhBackward0>),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7101,  0.7507, -1.7945, -0.8783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7101,  0.7507, -1.7945, -0.8783], grad_fn=<ViewBackward0>),), Output: tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7537, -1.4726, -0.6763, -1.8417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7537, -1.4726, -0.6763, -1.8417], grad_fn=<ViewBackward0>),), Output: tensor([-0.6374, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6374, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3014, -0.7288,  1.1099, -0.5883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3014, -0.7288,  1.1099, -0.5883], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9508, -2.8108, -4.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9508, -2.8108, -4.1416], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2878, -0.7016,  0.8303, -1.1122], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2878, -0.7016,  0.8303, -1.1122], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2302,  0.8925, -0.5960, -2.1143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2302,  0.8925, -0.5960, -2.1143], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7126, -0.5342, -0.9713], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7126, -0.5342, -0.9713], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6809, -0.8970, -1.7239,  0.1754], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6809, -0.8970, -1.7239,  0.1754], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5921, -0.7148, -0.9383,  0.1736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5921, -0.7148, -0.9383,  0.1736], grad_fn=<TanhBackward0>),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7090,  0.7559, -1.7953, -0.8816], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7090,  0.7559, -1.7953, -0.8816], grad_fn=<ViewBackward0>),), Output: tensor([-0.9365,  0.6386, -0.9463, -0.7072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9365,  0.6386, -0.9463, -0.7072], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1505, -1.0321, -0.6229, -1.0727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1505, -1.0321, -0.6229, -1.0727], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8179, -0.7747, -0.5531, -0.7905], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8179, -0.7747, -0.5531, -0.7905], grad_fn=<TanhBackward0>),), Output: tensor([-0.7121], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7121], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7121], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.4816, -0.6754, -1.8431], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.4816, -0.6754, -1.8431], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3027, -0.7239,  1.1139, -0.5869], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3027, -0.7239,  1.1139, -0.5869], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9654, -2.8101, -4.1452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9654, -2.8101, -4.1452], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2876, -0.6943,  0.8366, -1.1116], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2876, -0.6943,  0.8366, -1.1116], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2303,  0.8917, -0.5932, -2.1161], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2303,  0.8917, -0.5932, -2.1161], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6824, -0.8975, -1.7276,  0.1777], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6824, -0.8975, -1.7276,  0.1777], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5931, -0.7151, -0.9388,  0.1758], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5931, -0.7151, -0.9388,  0.1758], grad_fn=<TanhBackward0>),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7079,  0.7607, -1.7960, -0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7079,  0.7607, -1.7960, -0.8846], grad_fn=<ViewBackward0>),), Output: tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1511, -1.0333, -0.6361, -1.0724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1511, -1.0333, -0.6361, -1.0724], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7752, -0.5622, -0.7903], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7752, -0.5622, -0.7903], grad_fn=<TanhBackward0>),), Output: tensor([-0.7272], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7272], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7272], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7543, -1.4901, -0.6744, -1.8444], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7543, -1.4901, -0.6744, -1.8444], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3450, -0.9789, -2.8094, -4.1486], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3450, -0.9789, -2.8094, -4.1486], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2874, -0.6873,  0.8423, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2874, -0.6873,  0.8423, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.5963,  0.6870, -0.8045], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.5963,  0.6870, -0.8045], grad_fn=<TanhBackward0>),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2303,  0.8908, -0.5902, -2.1179], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2303,  0.8908, -0.5902, -2.1179], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7118, -0.5300, -0.9715], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7118, -0.5300, -0.9715], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6843, -0.8980, -1.7306,  0.1803], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6843, -0.8980, -1.7306,  0.1803], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7069,  0.7652, -1.7966, -0.8874], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7069,  0.7652, -1.7966, -0.8874], grad_fn=<ViewBackward0>),), Output: tensor([-0.9363,  0.6441, -0.9465, -0.7101], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9363,  0.6441, -0.9465, -0.7101], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1517, -1.0345, -0.6485, -1.0720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1517, -1.0345, -0.6485, -1.0720], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.7412], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7412], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7412], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.4980, -0.6736, -1.8457], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.4980, -0.6736, -1.8457], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3051, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3051, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3447, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3447, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7580, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7580, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2873, -0.6809,  0.8476, -1.1107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2873, -0.6809,  0.8476, -1.1107], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5921,  0.6898, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5921,  0.6898, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8897, -0.5869, -2.1195], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8897, -0.5869, -2.1195], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6865, -0.8985, -1.7330,  0.1831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6865, -0.8985, -1.7330,  0.1831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5957, -0.7156, -0.9394,  0.1811], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5957, -0.7156, -0.9394,  0.1811], grad_fn=<TanhBackward0>),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7059,  0.7694, -1.7971, -0.8900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7059,  0.7694, -1.7971, -0.8900], grad_fn=<ViewBackward0>),), Output: tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1524, -1.0355, -0.6602, -1.0716], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1524, -1.0355, -0.6602, -1.0716], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8186, -0.7761, -0.5785, -0.7901], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8186, -0.7761, -0.5785, -0.7901], grad_fn=<TanhBackward0>),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3062, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3062, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.6111,  0.8090, -0.5250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.6111,  0.8090, -0.5250], grad_fn=<TanhBackward0>),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3444, -1.0035, -2.8084, -4.1548], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3444, -1.0035, -2.8084, -4.1548], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7630, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7630, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2873, -0.6748,  0.8524, -1.1103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2873, -0.6748,  0.8524, -1.1103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8884, -0.5833, -2.1211], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8884, -0.5833, -2.1211], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7106, -0.5251, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7106, -0.5251, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6889, -0.8990, -1.7347,  0.1862], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6889, -0.8990, -1.7347,  0.1862], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5972, -0.7158, -0.9396,  0.1841], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5972, -0.7158, -0.9396,  0.1841], grad_fn=<TanhBackward0>),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>),), Output: tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1531, -1.0364, -0.6713, -1.0712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1531, -1.0364, -0.6713, -1.0712], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7546, -1.5124, -0.6721, -1.8480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7546, -1.5124, -0.6721, -1.8480], grad_fn=<ViewBackward0>),), Output: tensor([-0.6379, -0.9074, -0.5863, -0.9516], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6379, -0.9074, -0.5863, -0.9516], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3072, -0.7067,  1.1270, -0.5822], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3072, -0.7067,  1.1270, -0.5822], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8636, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8636, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6691,  0.8568, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6691,  0.8568, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5844,  0.6946, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5844,  0.6946, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8870, -0.5796, -2.1225], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8870, -0.5796, -2.1225], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7099, -0.5224, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7099, -0.5224, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6914, -0.8996, -1.7360,  0.1895], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6914, -0.8996, -1.7360,  0.1895], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7041,  0.7771, -1.7979, -0.8949], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7041,  0.7771, -1.7979, -0.8949], grad_fn=<ViewBackward0>),), Output: tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1538, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1538, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8190, -0.7768, -0.5926, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8190, -0.7768, -0.5926, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>),), Output: tensor([-0.6379, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6379, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.7030,  1.1296, -0.5812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.7030,  1.1296, -0.5812], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3434, -1.0252, -2.8079, -4.1603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3434, -1.0252, -2.8079, -4.1603], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6637,  0.8609, -1.1096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6637,  0.8609, -1.1096], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8855, -0.5757, -2.1239], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8855, -0.5757, -2.1239], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7091, -0.5195, -0.9718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7091, -0.5195, -0.9718], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6942, -0.9001, -1.7367,  0.1929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6942, -0.9001, -1.7367,  0.1929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6007, -0.7163, -0.9398,  0.1906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6007, -0.7163, -0.9398,  0.1906], grad_fn=<TanhBackward0>),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7033,  0.7806, -1.7983, -0.8971], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7033,  0.7806, -1.7983, -0.8971], grad_fn=<ViewBackward0>),), Output: tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1545, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1545, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8192, -0.7770, -0.5989, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8192, -0.7770, -0.5989, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5252, -0.6708, -1.8501], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5252, -0.6708, -1.8501], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9096, -0.5855, -0.9518], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9096, -0.5855, -0.9518], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3429, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3429, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6587,  0.8647, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6587,  0.8647, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5775,  0.6987, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5775,  0.6987, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8838, -0.5716, -2.1253], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8838, -0.5716, -2.1253], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7083, -0.5166, -0.9719], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7083, -0.5166, -0.9719], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6971, -0.9006, -1.7370,  0.1965], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6971, -0.9006, -1.7370,  0.1965], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6025, -0.7166, -0.9399,  0.1940], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6025, -0.7166, -0.9399,  0.1940], grad_fn=<TanhBackward0>),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7024,  0.7839, -1.7985, -0.8992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7024,  0.7839, -1.7985, -0.8992], grad_fn=<ViewBackward0>),), Output: tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1552, -1.0385, -0.7007, -1.0701], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1552, -1.0385, -0.7007, -1.0701], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8195, -0.7773, -0.6048, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8195, -0.7773, -0.6048, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.7980], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7980], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7980], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3098, -0.6961,  1.1342, -0.5794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3098, -0.6961,  1.1342, -0.5794], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.6019,  0.8124, -0.5223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.6019,  0.8124, -0.5223], grad_fn=<TanhBackward0>),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3423, -1.0448, -2.8077, -4.1654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3423, -1.0448, -2.8077, -4.1654], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8820, -0.5675, -2.1265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8820, -0.5675, -2.1265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7074, -0.5135, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7074, -0.5135, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7001, -0.9011, -1.7369,  0.2002], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7001, -0.9011, -1.7369,  0.2002], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6045, -0.7169, -0.9399,  0.1975], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6045, -0.7169, -0.9399,  0.1975], grad_fn=<TanhBackward0>),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7017,  0.7869, -1.7988, -0.9012], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7017,  0.7869, -1.7988, -0.9012], grad_fn=<ViewBackward0>),), Output: tensor([-0.9356,  0.6567, -0.9467, -0.7169], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9356,  0.6567, -0.9467, -0.7169], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8197, -0.7775, -0.6103, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8197, -0.7775, -0.6103, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3106, -0.6929,  1.1362, -0.5787], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3106, -0.6929,  1.1362, -0.5787], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5999,  0.8131, -0.5217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5999,  0.8131, -0.5217], grad_fn=<TanhBackward0>),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3417, -1.0539, -2.8077, -4.1678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3417, -1.0539, -2.8077, -4.1678], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8801, -0.5633, -2.1277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8801, -0.5633, -2.1277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7064, -0.5104, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7064, -0.5104, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7032, -0.9017, -1.7365,  0.2040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7032, -0.9017, -1.7365,  0.2040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7009,  0.7897, -1.7990, -0.9030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7009,  0.7897, -1.7990, -0.9030], grad_fn=<ViewBackward0>),), Output: tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7541, -1.5420, -0.6694, -1.8529], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7541, -1.5420, -0.6694, -1.8529], grad_fn=<ViewBackward0>),), Output: tensor([-0.6376, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6376, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3113, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3113, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3410, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3410, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7866, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7866, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6452,  0.8747, -1.1088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6452,  0.8747, -1.1088], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8781, -0.5590, -2.1289], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8781, -0.5590, -2.1289], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7054, -0.5072, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7054, -0.5072, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7064, -0.9022, -1.7357,  0.2078], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7064, -0.9022, -1.7357,  0.2078], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7002,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7002,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1572, -1.0400, -0.7255, -1.0691], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1572, -1.0400, -0.7255, -1.0691], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7539, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7539, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>),), Output: tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6870,  1.1397, -0.5774], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6870,  1.1397, -0.5774], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5961,  0.8143, -0.5208], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5961,  0.8143, -0.5208], grad_fn=<TanhBackward0>),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3403, -1.0709, -2.8080, -4.1722], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3403, -1.0709, -2.8080, -4.1722], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8760, -0.5546, -2.1300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8760, -0.5546, -2.1300], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7044, -0.5040, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7044, -0.5040, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7097, -0.9028, -1.7346,  0.2117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7097, -0.9028, -1.7346,  0.2117], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6105, -0.7176, -0.9396,  0.2086], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6105, -0.7176, -0.9396,  0.2086], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6995,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6995,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6612, -0.9467, -0.7195], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6612, -0.9467, -0.7195], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1579, -1.0403, -0.7328, -1.0688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1579, -1.0403, -0.7328, -1.0688], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3396, -1.0789, -2.8083, -4.1743], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3396, -1.0789, -2.8083, -4.1743], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6375,  0.8805, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6375,  0.8805, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5632,  0.7067, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5632,  0.7067, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8739, -0.5503, -2.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8739, -0.5503, -2.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7033, -0.5007, -0.9722], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7033, -0.5007, -0.9722], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7129, -0.9033, -1.7333,  0.2157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7129, -0.9033, -1.7333,  0.2157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6125, -0.7179, -0.9394,  0.2124], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6125, -0.7179, -0.9394,  0.2124], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6625, -0.9468, -0.7202], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6625, -0.9468, -0.7202], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1585, -1.0407, -0.7398, -1.0685], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1585, -1.0407, -0.7398, -1.0685], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8206, -0.7782, -0.6290, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8206, -0.7782, -0.6290, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7534, -1.5568, -0.6684, -1.8554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7534, -1.5568, -0.6684, -1.8554], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.9149, -0.5840, -0.9523], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.9149, -0.5840, -0.9523], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3130, -0.6817,  1.1426, -0.5764], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3130, -0.6817,  1.1426, -0.5764], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3388, -1.0866, -2.8087, -4.1763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3388, -1.0866, -2.8087, -4.1763], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7956, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7956, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6339,  0.8832, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6339,  0.8832, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8717, -0.5459, -2.1320], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8717, -0.5459, -2.1320], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7022, -0.4974, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7022, -0.4974, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7162, -0.9039, -1.7318,  0.2196], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7162, -0.9039, -1.7318,  0.2196], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6982,  0.7993, -1.7996, -0.9097], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6982,  0.7993, -1.7996, -0.9097], grad_fn=<ViewBackward0>),), Output: tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1592, -1.0410, -0.7464, -1.0682], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1592, -1.0410, -0.7464, -1.0682], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.8450], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8450], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8450], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7531, -1.5613, -0.6682, -1.8562], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7531, -1.5613, -0.6682, -1.8562], grad_fn=<ViewBackward0>),), Output: tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3135, -0.6793,  1.1439, -0.5759], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3135, -0.6793,  1.1439, -0.5759], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8652, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8652, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3380, -1.0941, -2.8091, -4.1782], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3380, -1.0941, -2.8091, -4.1782], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6305,  0.8857, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6305,  0.8857, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8694, -0.5415, -2.1330], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8694, -0.5415, -2.1330], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7195, -0.9045, -1.7300,  0.2236], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7195, -0.9045, -1.7300,  0.2236], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>),), Output: tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1598, -1.0413, -0.7526, -1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1598, -1.0413, -0.7526, -1.0679], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7528, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7528, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5895,  0.8161, -0.5195], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5895,  0.8161, -0.5195], grad_fn=<TanhBackward0>),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6273,  0.8882, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6273,  0.8882, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5562,  0.7105, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5562,  0.7105, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8671, -0.5372, -2.1340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8671, -0.5372, -2.1340], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6999, -0.4908, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6999, -0.4908, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7228, -0.9050, -1.7281,  0.2276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7228, -0.9050, -1.7281,  0.2276], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6969,  0.8032, -1.7998, -0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6969,  0.8032, -1.7998, -0.9125], grad_fn=<ViewBackward0>),), Output: tensor([-0.9350,  0.6658, -0.9468, -0.7223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9350,  0.6658, -0.9468, -0.7223], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1604, -1.0415, -0.7585, -1.0677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1604, -1.0415, -0.7585, -1.0677], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7525, -1.5698, -0.6680, -1.8577], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7525, -1.5698, -0.6680, -1.8577], grad_fn=<ViewBackward0>),), Output: tensor([-0.6366, -0.9170, -0.5836, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6366, -0.9170, -0.5836, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3143, -0.6747,  1.1462, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3143, -0.6747,  1.1462, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3364, -1.1083, -2.8102, -4.1818], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3364, -1.1083, -2.8102, -4.1818], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8034, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8034, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8648, -0.5328, -2.1348], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8648, -0.5328, -2.1348], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6987, -0.4875, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6987, -0.4875, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7261, -0.9056, -1.7260,  0.2316], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7261, -0.9056, -1.7260,  0.2316], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6207, -0.7190, -0.9386,  0.2275], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6207, -0.7190, -0.9386,  0.2275], grad_fn=<TanhBackward0>),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6963,  0.8050, -1.7998, -0.9139], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6963,  0.8050, -1.7998, -0.9139], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1610, -1.0417, -0.7641, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1610, -1.0417, -0.7641, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7521, -1.5739, -0.6679, -1.8584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7521, -1.5739, -0.6679, -1.8584], grad_fn=<ViewBackward0>),), Output: tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3147, -0.6725,  1.1472, -0.5751], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3147, -0.6725,  1.1472, -0.5751], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5866,  0.8168, -0.5191], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5866,  0.8168, -0.5191], grad_fn=<TanhBackward0>),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3356, -1.1150, -2.8108, -4.1835], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3356, -1.1150, -2.8108, -4.1835], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6213,  0.8928, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6213,  0.8928, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8625, -0.5285, -2.1357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8625, -0.5285, -2.1357], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6975, -0.4842, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6975, -0.4842, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7294, -0.9062, -1.7238,  0.2356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7294, -0.9062, -1.7238,  0.2356], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6227, -0.7193, -0.9383,  0.2313], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6227, -0.7193, -0.9383,  0.2313], grad_fn=<TanhBackward0>),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6958,  0.8066, -1.7999, -0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6958,  0.8066, -1.7999, -0.9152], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1616, -1.0419, -0.7694, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1616, -1.0419, -0.7694, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8216, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8216, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7518, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7518, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>),), Output: tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3149, -0.6704,  1.1482, -0.5749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3149, -0.6704,  1.1482, -0.5749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5853,  0.8171, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5853,  0.8171, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3348, -1.1216, -2.8115, -4.1852], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3348, -1.1216, -2.8115, -4.1852], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6185,  0.8950, -1.1088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6185,  0.8950, -1.1088], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5501,  0.7138, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5501,  0.7138, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8601, -0.5242, -2.1365], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8601, -0.5242, -2.1365], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6963, -0.4810, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6963, -0.4810, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7326, -0.9067, -1.7215,  0.2395], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7326, -0.9067, -1.7215,  0.2395], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6247, -0.7196, -0.9380,  0.2350], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6247, -0.7196, -0.9380,  0.2350], grad_fn=<TanhBackward0>),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6952,  0.8081, -1.8000, -0.9164], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6952,  0.8081, -1.8000, -0.9164], grad_fn=<ViewBackward0>),), Output: tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1622, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1622, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>),), Output: tensor([-0.6360, -0.9189, -0.5836, -0.9527], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6360, -0.9189, -0.5836, -0.9527], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3339, -1.1280, -2.8122, -4.1868], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3339, -1.1280, -2.8122, -4.1868], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8103, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8103, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2309,  0.8577, -0.5200, -2.1373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2309,  0.8577, -0.5200, -2.1373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7359, -0.9073, -1.7190,  0.2434], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7359, -0.9073, -1.7190,  0.2434], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6266, -0.7198, -0.9377,  0.2387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6266, -0.7198, -0.9377,  0.2387], grad_fn=<TanhBackward0>),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6947,  0.8095, -1.8000, -0.9176], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6947,  0.8095, -1.8000, -0.9176], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6693, -0.9468, -0.7247], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6693, -0.9468, -0.7247], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1627, -1.0422, -0.7792, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1627, -1.0422, -0.7792, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8219, -0.7787, -0.6523, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8219, -0.7787, -0.6523, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7510, -1.5854, -0.6680, -1.8604], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7510, -1.5854, -0.6680, -1.8604], grad_fn=<ViewBackward0>),), Output: tensor([-0.6358, -0.9194, -0.5836, -0.9527], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6358, -0.9194, -0.5836, -0.9527], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6665,  1.1498, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6665,  1.1498, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5827,  0.8177, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5827,  0.8177, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3331, -1.1343, -2.8130, -4.1883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3331, -1.1343, -2.8130, -4.1883], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6133,  0.8992, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6133,  0.8992, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8553, -0.5159, -2.1381], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8553, -0.5159, -2.1381], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6938, -0.4745, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6938, -0.4745, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7390, -0.9079, -1.7165,  0.2473], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7390, -0.9079, -1.7165,  0.2473], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6286, -0.7201, -0.9374,  0.2423], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6286, -0.7201, -0.9374,  0.2423], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6941,  0.8108, -1.8001, -0.9187], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6941,  0.8108, -1.8001, -0.9187], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1632, -1.0423, -0.7838, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1632, -1.0423, -0.7838, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7507, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7507, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>),), Output: tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6108,  0.9012, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6108,  0.9012, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2311,  0.8529, -0.5117, -2.1389], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2311,  0.8529, -0.5117, -2.1389], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7421, -0.9084, -1.7139,  0.2511], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7421, -0.9084, -1.7139,  0.2511], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6304, -0.7204, -0.9371,  0.2459], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6304, -0.7204, -0.9371,  0.2459], grad_fn=<TanhBackward0>),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6936,  0.8121, -1.8001, -0.9198], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6936,  0.8121, -1.8001, -0.9198], grad_fn=<ViewBackward0>),), Output: tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1638, -1.0424, -0.7880, -1.0665], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1638, -1.0424, -0.7880, -1.0665], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8223, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8223, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8861], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8861], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8861], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7503, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7503, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>),), Output: tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6628,  1.1513, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6628,  1.1513, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5803,  0.8182, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5803,  0.8182, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3314, -1.1464, -2.8148, -4.1913], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3314, -1.1464, -2.8148, -4.1913], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8165, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8165, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6085,  0.9032, -1.1095], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6085,  0.9032, -1.1095], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5431,  0.7179, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5431,  0.7179, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2311,  0.8505, -0.5077, -2.1396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2311,  0.8505, -0.5077, -2.1396], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6913, -0.4682, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6913, -0.4682, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7452, -0.9090, -1.7112,  0.2549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7452, -0.9090, -1.7112,  0.2549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6323, -0.7206, -0.9368,  0.2495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6323, -0.7206, -0.9368,  0.2495], grad_fn=<TanhBackward0>),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1643, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1643, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7499, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7499, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>),), Output: tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3305, -1.1522, -2.8158, -4.1927], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3305, -1.1522, -2.8158, -4.1927], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5415,  0.7188, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5415,  0.7188, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2312,  0.8481, -0.5037, -2.1403], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2312,  0.8481, -0.5037, -2.1403], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6901, -0.4651, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6901, -0.4651, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7482, -0.9095, -1.7085,  0.2586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7482, -0.9095, -1.7085,  0.2586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6341, -0.7209, -0.9365,  0.2529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6341, -0.7209, -0.9365,  0.2529], grad_fn=<TanhBackward0>),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6927,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6927,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6719, -0.9468, -0.7268], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6719, -0.9468, -0.7268], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1648, -1.0425, -0.7960, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1648, -1.0425, -0.7960, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7495, -1.5993, -0.6686, -1.8628], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7495, -1.5993, -0.6686, -1.8628], grad_fn=<ViewBackward0>),), Output: tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6594,  1.1525, -0.5748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6594,  1.1525, -0.5748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5780,  0.8186, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5780,  0.8186, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3297, -1.1579, -2.8168, -4.1941], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3297, -1.1579, -2.8168, -4.1941], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6041,  0.9071, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6041,  0.9071, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2313,  0.8457, -0.4998, -2.1409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2313,  0.8457, -0.4998, -2.1409], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6888, -0.4620, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6888, -0.4620, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7512, -0.9101, -1.7057,  0.2622], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7512, -0.9101, -1.7057,  0.2622], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6922,  0.8152, -1.8003, -0.9228], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6922,  0.8152, -1.8003, -0.9228], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7789, -0.6638, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7789, -0.6638, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7491, -1.6025, -0.6688, -1.8633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7491, -1.6025, -0.6688, -1.8633], grad_fn=<ViewBackward0>),), Output: tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6578,  1.1531, -0.5749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6578,  1.1531, -0.5749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5769,  0.8188, -0.5190], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5769,  0.8188, -0.5190], grad_fn=<TanhBackward0>),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -1.1635, -2.8178, -4.1954], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -1.1635, -2.8178, -4.1954], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6020,  0.9090, -1.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6020,  0.9090, -1.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8433, -0.4960, -2.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8433, -0.4960, -2.1416], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6875, -0.4590, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6875, -0.4590, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7541, -0.9106, -1.7029,  0.2658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7541, -0.9106, -1.7029,  0.2658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6376, -0.7214, -0.9358,  0.2597], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6376, -0.7214, -0.9358,  0.2597], grad_fn=<TanhBackward0>),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6917,  0.8161, -1.8003, -0.9237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6917,  0.8161, -1.8003, -0.9237], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6730, -0.9468, -0.7277], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6730, -0.9468, -0.7277], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1657, -1.0425, -0.8031, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1657, -1.0425, -0.8031, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7487, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7487, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>),), Output: tensor([-0.6344, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6344, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3280, -1.1690, -2.8189, -4.1967], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3280, -1.1690, -2.8189, -4.1967], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2315,  0.8409, -0.4923, -2.1422], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2315,  0.8409, -0.4923, -2.1422], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6863, -0.4560, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6863, -0.4560, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7569, -0.9112, -1.7001,  0.2693], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7569, -0.9112, -1.7001,  0.2693], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6393, -0.7217, -0.9354,  0.2630], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6393, -0.7217, -0.9354,  0.2630], grad_fn=<TanhBackward0>),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1661, -1.0425, -0.8064, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1661, -1.0425, -0.8064, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7483, -1.6088, -0.6694, -1.8644], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7483, -1.6088, -0.6694, -1.8644], grad_fn=<ViewBackward0>),), Output: tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6547,  1.1541, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6547,  1.1541, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3271, -1.1744, -2.8200, -4.1979], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3271, -1.1744, -2.8200, -4.1979], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.5980,  0.9126, -1.1108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.5980,  0.9126, -1.1108], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2317,  0.8385, -0.4886, -2.1428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2317,  0.8385, -0.4886, -2.1428], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6850, -0.4531, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6850, -0.4531, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7597, -0.9117, -1.6973,  0.2728], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7597, -0.9117, -1.6973,  0.2728], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6409, -0.7219, -0.9351,  0.2662], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6409, -0.7219, -0.9351,  0.2662], grad_fn=<TanhBackward0>),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6909,  0.8177, -1.8005, -0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6909,  0.8177, -1.8005, -0.9255], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6738, -0.9469, -0.7285], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6738, -0.9469, -0.7285], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1666, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1666, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8232, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8232, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7479, -1.6119, -0.6698, -1.8649], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7479, -1.6119, -0.6698, -1.8649], grad_fn=<ViewBackward0>),), Output: tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6532,  1.1546, -0.5755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6532,  1.1546, -0.5755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3263, -1.1797, -2.8212, -4.1992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3263, -1.1797, -2.8212, -4.1992], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5961,  0.9144, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5961,  0.9144, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5343,  0.7233, -0.8045], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5343,  0.7233, -0.8045], grad_fn=<TanhBackward0>),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2318,  0.8362, -0.4850, -2.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2318,  0.8362, -0.4850, -2.1434], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6838, -0.4503, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6838, -0.4503, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7624, -0.9122, -1.6945,  0.2761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7624, -0.9122, -1.6945,  0.2761], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6425, -0.7222, -0.9347,  0.2693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6425, -0.7222, -0.9347,  0.2693], grad_fn=<TanhBackward0>),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6904,  0.8184, -1.8005, -0.9263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6904,  0.8184, -1.8005, -0.9263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1670, -1.0424, -0.8126, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1670, -1.0424, -0.8126, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8233, -0.7789, -0.6710, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8233, -0.7789, -0.6710, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7475, -1.6148, -0.6701, -1.8655], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7475, -1.6148, -0.6701, -1.8655], grad_fn=<ViewBackward0>),), Output: tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6517,  1.1550, -0.5758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6517,  1.1550, -0.5758], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3254, -1.1849, -2.8224, -4.2004], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3254, -1.1849, -2.8224, -4.2004], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2866, -0.5943,  0.9162, -1.1114], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2866, -0.5943,  0.9162, -1.1114], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5330,  0.7241, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5330,  0.7241, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2319,  0.8339, -0.4815, -2.1440], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2319,  0.8339, -0.4815, -2.1440], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6825, -0.4475, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6825, -0.4475, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7651, -0.9127, -1.6917,  0.2794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7651, -0.9127, -1.6917,  0.2794], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6441, -0.7224, -0.9344,  0.2724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6441, -0.7224, -0.9344,  0.2724], grad_fn=<TanhBackward0>),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>),), Output: tensor([-0.9342,  0.6746, -0.9469, -0.7293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9342,  0.6746, -0.9469, -0.7293], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1674, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1674, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7470, -1.6177, -0.6705, -1.8660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7470, -1.6177, -0.6705, -1.8660], grad_fn=<ViewBackward0>),), Output: tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3246, -1.1900, -2.8236, -4.2015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3246, -1.1900, -2.8236, -4.2015], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2866, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2866, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5317,  0.7249, -0.8047], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5317,  0.7249, -0.8047], grad_fn=<TanhBackward0>),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2320,  0.8316, -0.4781, -2.1446], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2320,  0.8316, -0.4781, -2.1446], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6813, -0.4447, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6813, -0.4447, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7677, -0.9132, -1.6889,  0.2827], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7677, -0.9132, -1.6889,  0.2827], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6456, -0.7227, -0.9340,  0.2754], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6456, -0.7227, -0.9340,  0.2754], grad_fn=<TanhBackward0>),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8235, -0.7788, -0.6740, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8235, -0.7788, -0.6740, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>),), Output: tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5709,  0.8197, -0.5201], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5709,  0.8197, -0.5201], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3238, -1.1951, -2.8249, -4.2027], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3238, -1.1951, -2.8249, -4.2027], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5305,  0.7258, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5305,  0.7258, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2322,  0.8293, -0.4748, -2.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2322,  0.8293, -0.4748, -2.1451], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6801, -0.4420, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6801, -0.4420, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7702, -0.9137, -1.6861,  0.2858], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7702, -0.9137, -1.6861,  0.2858], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6470, -0.7229, -0.9336,  0.2783], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6470, -0.7229, -0.9336,  0.2783], grad_fn=<TanhBackward0>),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6892,  0.8203, -1.8008, -0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6892,  0.8203, -1.8008, -0.9287], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1681, -1.0423, -0.8207, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1681, -1.0423, -0.8207, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8237, -0.7788, -0.6754, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8237, -0.7788, -0.6754, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>),), Output: tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3229, -1.2000, -2.8262, -4.2038], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3229, -1.2000, -2.8262, -4.2038], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5293,  0.7266, -0.8049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5293,  0.7266, -0.8049], grad_fn=<TanhBackward0>),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2323,  0.8270, -0.4715, -2.1456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2323,  0.8270, -0.4715, -2.1456], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7726, -0.9141, -1.6833,  0.2889], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7726, -0.9141, -1.6833,  0.2889], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6485, -0.7231, -0.9333,  0.2811], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6485, -0.7231, -0.9333,  0.2811], grad_fn=<TanhBackward0>),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6889,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6889,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1685, -1.0422, -0.8231, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1685, -1.0422, -0.8231, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7458, -1.6262, -0.6719, -1.8674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7458, -1.6262, -0.6719, -1.8674], grad_fn=<ViewBackward0>),), Output: tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.6461,  1.1565, -0.5772], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.6461,  1.1565, -0.5772], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5690,  0.8199, -0.5207], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5690,  0.8199, -0.5207], grad_fn=<TanhBackward0>),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3221, -1.2049, -2.8275, -4.2048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3221, -1.2049, -2.8275, -4.2048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2864, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2864, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2324,  0.8248, -0.4683, -2.1462], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2324,  0.8248, -0.4683, -2.1462], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6777, -0.4369, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6777, -0.4369, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7750, -0.9146, -1.6805,  0.2919], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7750, -0.9146, -1.6805,  0.2919], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6498, -0.7233, -0.9329,  0.2839], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6498, -0.7233, -0.9329,  0.2839], grad_fn=<TanhBackward0>),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6885,  0.8212, -1.8010, -0.9301], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6885,  0.8212, -1.8010, -0.9301], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6757, -0.9469, -0.7307], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6757, -0.9469, -0.7307], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1688, -1.0421, -0.8254, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1688, -1.0421, -0.8254, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7454, -1.6288, -0.6724, -1.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7454, -1.6288, -0.6724, -1.8679], grad_fn=<ViewBackward0>),), Output: tensor([-0.6324, -0.9259, -0.5865, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6324, -0.9259, -0.5865, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6448,  1.1569, -0.5777], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6448,  1.1569, -0.5777], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3213, -1.2096, -2.8289, -4.2059], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3213, -1.2096, -2.8289, -4.2059], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5859,  0.9249, -1.1133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5859,  0.9249, -1.1133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5270,  0.7282, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5270,  0.7282, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.9104], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9104], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9104], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2326,  0.8225, -0.4653, -2.1467], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2326,  0.8225, -0.4653, -2.1467], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6765, -0.4344, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6765, -0.4344, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7774, -0.9150, -1.6778,  0.2949], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7774, -0.9150, -1.6778,  0.2949], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6512, -0.7235, -0.9326,  0.2866], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6512, -0.7235, -0.9326,  0.2866], grad_fn=<TanhBackward0>),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6881,  0.8216, -1.8011, -0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6881,  0.8216, -1.8011, -0.9308], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1692, -1.0420, -0.8276, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1692, -1.0420, -0.8276, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7450, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7450, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>),), Output: tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6435,  1.1572, -0.5781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6435,  1.1572, -0.5781], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3205, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3205, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2862, -0.5844,  0.9266, -1.1137], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2862, -0.5844,  0.9266, -1.1137], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5258,  0.7290, -0.8054], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5258,  0.7290, -0.8054], grad_fn=<TanhBackward0>),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2327,  0.8204, -0.4623, -2.1471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2327,  0.8204, -0.4623, -2.1471], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7796, -0.9154, -1.6751,  0.2977], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7796, -0.9154, -1.6751,  0.2977], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6525, -0.7237, -0.9322,  0.2892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6525, -0.7237, -0.9322,  0.2892], grad_fn=<TanhBackward0>),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6878,  0.8220, -1.8012, -0.9315], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6878,  0.8220, -1.8012, -0.9315], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1695, -1.0419, -0.8297, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1695, -1.0419, -0.8297, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7446, -1.6341, -0.6734, -1.8688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7446, -1.6341, -0.6734, -1.8688], grad_fn=<ViewBackward0>),), Output: tensor([-0.6319, -0.9266, -0.5872, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6319, -0.9266, -0.5872, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3150, -0.6422,  1.1575, -0.5786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3150, -0.6422,  1.1575, -0.5786], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5664,  0.8202, -0.5216], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5664,  0.8202, -0.5216], grad_fn=<TanhBackward0>),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3197, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3197, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2862, -0.5829,  0.9282, -1.1141], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2862, -0.5829,  0.9282, -1.1141], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5248,  0.7298, -0.8055], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5248,  0.7298, -0.8055], grad_fn=<TanhBackward0>),), Output: tensor([0.9124], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9124], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9124], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2329,  0.8182, -0.4593, -2.1476], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2329,  0.8182, -0.4593, -2.1476], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6741, -0.4295, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6741, -0.4295, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7818, -0.9158, -1.6724,  0.3005], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7818, -0.9158, -1.6724,  0.3005], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6538, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6538, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1698, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1698, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7442, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7442, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>),), Output: tensor([-0.6317, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6317, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3148, -0.6409,  1.1578, -0.5791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3148, -0.6409,  1.1578, -0.5791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3189, -1.2236, -2.8331, -4.2089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3189, -1.2236, -2.8331, -4.2089], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2330,  0.8161, -0.4565, -2.1481], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2330,  0.8161, -0.4565, -2.1481], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6729, -0.4272, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6729, -0.4272, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7840, -0.9162, -1.6698,  0.3032], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7840, -0.9162, -1.6698,  0.3032], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6550, -0.7241, -0.9315,  0.2942], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6550, -0.7241, -0.9315,  0.2942], grad_fn=<TanhBackward0>),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6871,  0.8227, -1.8014, -0.9328], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6871,  0.8227, -1.8014, -0.9328], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1701, -1.0416, -0.8336, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1701, -1.0416, -0.8336, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8243, -0.7785, -0.6824, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8243, -0.7785, -0.6824, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7438, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7438, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6397,  1.1580, -0.5796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6397,  1.1580, -0.5796], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5647,  0.8204, -0.5224], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5647,  0.8204, -0.5224], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3181, -1.2281, -2.8346, -4.2099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3181, -1.2281, -2.8346, -4.2099], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5227,  0.7313, -0.8058], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5227,  0.7313, -0.8058], grad_fn=<TanhBackward0>),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2332,  0.8139, -0.4537, -2.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2332,  0.8139, -0.4537, -2.1485], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6718, -0.4250, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6718, -0.4250, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7860, -0.9166, -1.6671,  0.3058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7860, -0.9166, -1.6671,  0.3058], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6562, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6562, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6867,  0.8230, -1.8016, -0.9334], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6867,  0.8230, -1.8016, -0.9334], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1704, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1704, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8244, -0.7785, -0.6834, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8244, -0.7785, -0.6834, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7434, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7434, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>),), Output: tensor([-0.6312, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6312, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3173, -1.2325, -2.8360, -4.2108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3173, -1.2325, -2.8360, -4.2108], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5217,  0.7321, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5217,  0.7321, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2333,  0.8119, -0.4510, -2.1490], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2333,  0.8119, -0.4510, -2.1490], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6706, -0.4228, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6706, -0.4228, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7881, -0.9170, -1.6646,  0.3084], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7881, -0.9170, -1.6646,  0.3084], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6573, -0.7245, -0.9308,  0.2990], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6573, -0.7245, -0.9308,  0.2990], grad_fn=<TanhBackward0>),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6864,  0.8232, -1.8017, -0.9340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6864,  0.8232, -1.8017, -0.9340], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1707, -1.0413, -0.8371, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1707, -1.0413, -0.8371, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>),), Output: tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3142, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3142, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3166, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3166, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2859, -0.5773,  0.9348, -1.1158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2859, -0.5773,  0.9348, -1.1158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5207,  0.7328, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5207,  0.7328, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2335,  0.8098, -0.4484, -2.1494], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2335,  0.8098, -0.4484, -2.1494], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6695, -0.4206, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6695, -0.4206, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7900, -0.9173, -1.6620,  0.3109], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7900, -0.9173, -1.6620,  0.3109], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6861,  0.8234, -1.8018, -0.9346], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6861,  0.8234, -1.8018, -0.9346], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>),), Output: tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3158, -1.2412, -2.8390, -4.2126], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3158, -1.2412, -2.8390, -4.2126], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2336,  0.8078, -0.4459, -2.1498], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2336,  0.8078, -0.4459, -2.1498], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6684, -0.4185, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6684, -0.4185, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7919, -0.9177, -1.6595,  0.3133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7919, -0.9177, -1.6595,  0.3133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6858,  0.8236, -1.8020, -0.9351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6858,  0.8236, -1.8020, -0.9351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6770, -0.9470, -0.7330], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6770, -0.9470, -0.7330], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1712, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1712, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7783, -0.6859, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7783, -0.6859, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3137, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3137, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8652, -0.5614,  0.8207, -0.5240], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8652, -0.5614,  0.8207, -0.5240], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2338,  0.8058, -0.4434, -2.1502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2338,  0.8058, -0.4434, -2.1502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6673, -0.4165, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6673, -0.4165, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7937, -0.9180, -1.6570,  0.3157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7937, -0.9180, -1.6570,  0.3157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6605, -0.7249, -0.9298,  0.3056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6605, -0.7249, -0.9298,  0.3056], grad_fn=<TanhBackward0>),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6855,  0.8238, -1.8021, -0.9357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6855,  0.8238, -1.8021, -0.9357], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1715, -1.0408, -0.8417, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1715, -1.0408, -0.8417, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7418, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7418, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>),), Output: tensor([-0.6302, -0.9290, -0.5900, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6302, -0.9290, -0.5900, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3134, -0.6337,  1.1592, -0.5825], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3134, -0.6337,  1.1592, -0.5825], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5606,  0.8208, -0.5245], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5606,  0.8208, -0.5245], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3143, -1.2497, -2.8421, -4.2144], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3143, -1.2497, -2.8421, -4.2144], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2857, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2857, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2339,  0.8038, -0.4410, -2.1506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2339,  0.8038, -0.4410, -2.1506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6662, -0.4145, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6662, -0.4145, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7955, -0.9183, -1.6546,  0.3180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7955, -0.9183, -1.6546,  0.3180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6852,  0.8239, -1.8023, -0.9362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6852,  0.8239, -1.8023, -0.9362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1717, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1717, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7414, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7414, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>),), Output: tensor([-0.6300, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6300, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5598,  0.8209, -0.5249], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5598,  0.8209, -0.5249], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3135, -1.2538, -2.8436, -4.2152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3135, -1.2538, -2.8436, -4.2152], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5721,  0.9411, -1.1176], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5721,  0.9411, -1.1176], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5169,  0.7357, -0.8067], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5169,  0.7357, -0.8067], grad_fn=<TanhBackward0>),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2341,  0.8019, -0.4387, -2.1510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2341,  0.8019, -0.4387, -2.1510], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6651, -0.4126, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6651, -0.4126, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7973, -0.9186, -1.6522,  0.3202], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7973, -0.9186, -1.6522,  0.3202], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6849,  0.8240, -1.8025, -0.9367], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6849,  0.8240, -1.8025, -0.9367], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1719, -1.0404, -0.8444, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1719, -1.0404, -0.8444, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8249, -0.7780, -0.6882, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8249, -0.7780, -0.6882, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7410, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7410, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3128, -0.6314,  1.1596, -0.5837], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3128, -0.6314,  1.1596, -0.5837], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3128, -1.2579, -2.8452, -4.2161], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3128, -1.2579, -2.8452, -4.2161], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2855, -0.5709,  0.9427, -1.1180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2855, -0.5709,  0.9427, -1.1180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2343,  0.8000, -0.4365, -2.1514], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2343,  0.8000, -0.4365, -2.1514], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6640, -0.4107, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6640, -0.4107, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7990, -0.9189, -1.6499,  0.3223], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7990, -0.9189, -1.6499,  0.3223], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6634, -0.7254, -0.9288,  0.3116], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6634, -0.7254, -0.9288,  0.3116], grad_fn=<TanhBackward0>),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6846,  0.8241, -1.8026, -0.9373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6846,  0.8241, -1.8026, -0.9373], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6773, -0.9471, -0.7340], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6773, -0.9471, -0.7340], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1722, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1722, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7406, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7406, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>),), Output: tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6303,  1.1598, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6303,  1.1598, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5582,  0.8210, -0.5259], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5582,  0.8210, -0.5259], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3121, -1.2619, -2.8468, -4.2169], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3121, -1.2619, -2.8468, -4.2169], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2854, -0.5697,  0.9442, -1.1185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2854, -0.5697,  0.9442, -1.1185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2344,  0.7981, -0.4343, -2.1518], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2344,  0.7981, -0.4343, -2.1518], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6630, -0.4089, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6630, -0.4089, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8006, -0.9192, -1.6476,  0.3244], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8006, -0.9192, -1.6476,  0.3244], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6644, -0.7255, -0.9285,  0.3135], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6644, -0.7255, -0.9285,  0.3135], grad_fn=<TanhBackward0>),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6843,  0.8242, -1.8028, -0.9377], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6843,  0.8242, -1.8028, -0.9377], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1724, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1724, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7402, -1.6599, -0.6805, -1.8731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7402, -1.6599, -0.6805, -1.8731], grad_fn=<ViewBackward0>),), Output: tensor([-0.6293, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6293, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3122, -0.6292,  1.1600, -0.5851], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3122, -0.6292,  1.1600, -0.5851], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5575,  0.8210, -0.5263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5575,  0.8210, -0.5263], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3113, -1.2659, -2.8484, -4.2177], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3113, -1.2659, -2.8484, -4.2177], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2854, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2854, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5143,  0.7379, -0.8072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5143,  0.7379, -0.8072], grad_fn=<TanhBackward0>),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2346,  0.7963, -0.4322, -2.1521], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2346,  0.7963, -0.4322, -2.1521], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6619, -0.4071, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6619, -0.4071, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8022, -0.9194, -1.6453,  0.3265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8022, -0.9194, -1.6453,  0.3265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6652, -0.7256, -0.9282,  0.3153], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6652, -0.7256, -0.9282,  0.3153], grad_fn=<TanhBackward0>),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1726, -1.0398, -0.8480, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1726, -1.0398, -0.8480, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7398, -1.6620, -0.6812, -1.8735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7398, -1.6620, -0.6812, -1.8735], grad_fn=<ViewBackward0>),), Output: tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6281,  1.1602, -0.5857], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6281,  1.1602, -0.5857], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3106, -1.2698, -2.8500, -4.2185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3106, -1.2698, -2.8500, -4.2185], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2348,  0.7944, -0.4301, -2.1525], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2348,  0.7944, -0.4301, -2.1525], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6609, -0.4054, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6609, -0.4054, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8037, -0.9197, -1.6431,  0.3284], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8037, -0.9197, -1.6431,  0.3284], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6661, -0.7257, -0.9279,  0.3171], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6661, -0.7257, -0.9279,  0.3171], grad_fn=<TanhBackward0>),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6837,  0.8243, -1.8032, -0.9387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6837,  0.8243, -1.8032, -0.9387], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1728, -1.0396, -0.8491, -1.0667], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1728, -1.0396, -0.8491, -1.0667], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7394, -1.6641, -0.6820, -1.8738], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7394, -1.6641, -0.6820, -1.8738], grad_fn=<ViewBackward0>),), Output: tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3116, -0.6270,  1.1603, -0.5864], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3116, -0.6270,  1.1603, -0.5864], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5560,  0.8211, -0.5273], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5560,  0.8211, -0.5273], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3099, -1.2736, -2.8516, -4.2193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3099, -1.2736, -2.8516, -4.2193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5126,  0.7392, -0.8075], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5126,  0.7392, -0.8075], grad_fn=<TanhBackward0>),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2349,  0.7926, -0.4281, -2.1529], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2349,  0.7926, -0.4281, -2.1529], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6599, -0.4038, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6599, -0.4038, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8052, -0.9199, -1.6409,  0.3303], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8052, -0.9199, -1.6409,  0.3303], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6669, -0.7258, -0.9276,  0.3188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6669, -0.7258, -0.9276,  0.3188], grad_fn=<TanhBackward0>),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6835,  0.8244, -1.8034, -0.9392], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6835,  0.8244, -1.8034, -0.9392], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1730, -1.0393, -0.8501, -1.0669], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1730, -1.0393, -0.8501, -1.0669], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7390, -1.6661, -0.6827, -1.8742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7390, -1.6661, -0.6827, -1.8742], grad_fn=<ViewBackward0>),), Output: tensor([-0.6286, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6286, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3113, -0.6259,  1.1605, -0.5871], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3113, -0.6259,  1.1605, -0.5871], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3092, -1.2774, -2.8532, -4.2200], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3092, -1.2774, -2.8532, -4.2200], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2852, -0.5651,  0.9503, -1.1204], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2852, -0.5651,  0.9503, -1.1204], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5118,  0.7399, -0.8077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5118,  0.7399, -0.8077], grad_fn=<TanhBackward0>),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2351,  0.7909, -0.4262, -2.1532], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2351,  0.7909, -0.4262, -2.1532], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6589, -0.4021, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6589, -0.4021, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8066, -0.9201, -1.6388,  0.3322], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8066, -0.9201, -1.6388,  0.3322], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6677, -0.7259, -0.9273,  0.3205], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6677, -0.7259, -0.9273,  0.3205], grad_fn=<TanhBackward0>),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6832,  0.8244, -1.8036, -0.9396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6832,  0.8244, -1.8036, -0.9396], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9472, -0.7350], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9472, -0.7350], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7387, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7387, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>),), Output: tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8645, -0.5545,  0.8212, -0.5283], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8645, -0.5545,  0.8212, -0.5283], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3085, -1.2812, -2.8548, -4.2208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3085, -1.2812, -2.8548, -4.2208], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2353,  0.7891, -0.4243, -2.1535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2353,  0.7891, -0.4243, -2.1535], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6579, -0.4006, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6579, -0.4006, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8080, -0.9203, -1.6367,  0.3340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8080, -0.9203, -1.6367,  0.3340], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6685, -0.7260, -0.9270,  0.3221], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6685, -0.7260, -0.9270,  0.3221], grad_fn=<TanhBackward0>),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6829,  0.8244, -1.8038, -0.9401], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6829,  0.8244, -1.8038, -0.9401], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7352], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7352], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1734, -1.0389, -0.8520, -1.0671], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1734, -1.0389, -0.8520, -1.0671], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8254, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8254, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9532], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9532], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9532], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7383, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7383, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3106, -0.6238,  1.1608, -0.5885], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3106, -0.6238,  1.1608, -0.5885], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5538,  0.8213, -0.5288], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5538,  0.8213, -0.5288], grad_fn=<TanhBackward0>),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3078, -1.2849, -2.8564, -4.2215], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3078, -1.2849, -2.8564, -4.2215], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5102,  0.7413, -0.8080], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5102,  0.7413, -0.8080], grad_fn=<TanhBackward0>),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2354,  0.7874, -0.4225, -2.1539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2354,  0.7874, -0.4225, -2.1539], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6569, -0.3990, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6569, -0.3990, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8094, -0.9205, -1.6346,  0.3357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8094, -0.9205, -1.6346,  0.3357], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6692, -0.7261, -0.9267,  0.3237], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6692, -0.7261, -0.9267,  0.3237], grad_fn=<TanhBackward0>),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6827,  0.8243, -1.8040, -0.9405], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6827,  0.8243, -1.8040, -0.9405], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1736, -1.0386, -0.8528, -1.0673], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1736, -1.0386, -0.8528, -1.0673], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8254, -0.7773, -0.6925, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8254, -0.7773, -0.6925, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>),), Output: tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3103, -0.6227,  1.1609, -0.5893], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3103, -0.6227,  1.1609, -0.5893], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8643, -0.5530,  0.8213, -0.5294], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8643, -0.5530,  0.8213, -0.5294], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3071, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3071, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2850, -0.5619,  0.9547, -1.1218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2850, -0.5619,  0.9547, -1.1218], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5094,  0.7419, -0.8082], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5094,  0.7419, -0.8082], grad_fn=<TanhBackward0>),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2356,  0.7857, -0.4207, -2.1542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2356,  0.7857, -0.4207, -2.1542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6560, -0.3975, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6560, -0.3975, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8107, -0.9207, -1.6326,  0.3374], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8107, -0.9207, -1.6326,  0.3374], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6700, -0.7262, -0.9264,  0.3252], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6700, -0.7262, -0.9264,  0.3252], grad_fn=<TanhBackward0>),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6824,  0.8243, -1.8042, -0.9409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6824,  0.8243, -1.8042, -0.9409], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1738, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1738, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7773, -0.6930, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7773, -0.6930, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>),), Output: tensor([-0.6277, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6277, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3099, -0.6217,  1.1610, -0.5900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3099, -0.6217,  1.1610, -0.5900], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8643, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8643, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3064, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3064, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2358,  0.7840, -0.4190, -2.1545], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2358,  0.7840, -0.4190, -2.1545], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6550, -0.3961, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6550, -0.3961, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8119, -0.9209, -1.6307,  0.3391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8119, -0.9209, -1.6307,  0.3391], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6707, -0.7263, -0.9262,  0.3266], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6707, -0.7263, -0.9262,  0.3266], grad_fn=<TanhBackward0>),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1740, -1.0382, -0.8544, -1.0676], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1740, -1.0382, -0.8544, -1.0676], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7772, -0.6934, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7772, -0.6934, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7372, -1.6759, -0.6865, -1.8758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7372, -1.6759, -0.6865, -1.8758], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3096, -0.6207,  1.1612, -0.5907], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3096, -0.6207,  1.1612, -0.5907], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2848, -0.5598,  0.9576, -1.1228], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2848, -0.5598,  0.9576, -1.1228], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2359,  0.7824, -0.4174, -2.1548], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2359,  0.7824, -0.4174, -2.1548], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6541, -0.3947, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6541, -0.3947, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8132, -0.9210, -1.6287,  0.3407], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8132, -0.9210, -1.6287,  0.3407], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6820,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6820,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7360], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7771, -0.6938, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7771, -0.6938, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>),), Output: tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3092, -0.6197,  1.1613, -0.5915], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3092, -0.6197,  1.1613, -0.5915], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8641, -0.5509,  0.8215, -0.5310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8641, -0.5509,  0.8215, -0.5310], grad_fn=<TanhBackward0>),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3051, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3051, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2848, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2848, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2361,  0.7808, -0.4158, -2.1551], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2361,  0.7808, -0.4158, -2.1551], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6532, -0.3933, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6532, -0.3933, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8144, -0.9212, -1.6268,  0.3422], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8144, -0.9212, -1.6268,  0.3422], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6720, -0.7265, -0.9256,  0.3294], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6720, -0.7265, -0.9256,  0.3294], grad_fn=<TanhBackward0>),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6817,  0.8241, -1.8048, -0.9421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6817,  0.8241, -1.8048, -0.9421], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1743, -1.0377, -0.8559, -1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1743, -1.0377, -0.8559, -1.0679], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7770, -0.6941, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7770, -0.6941, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7364, -1.6796, -0.6881, -1.8765], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7364, -1.6796, -0.6881, -1.8765], grad_fn=<ViewBackward0>),), Output: tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3089, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3089, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3044, -1.3028, -2.8646, -4.2250], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3044, -1.3028, -2.8646, -4.2250], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5064,  0.7445, -0.8089], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5064,  0.7445, -0.8089], grad_fn=<TanhBackward0>),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2363,  0.7792, -0.4142, -2.1554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2363,  0.7792, -0.4142, -2.1554], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6522, -0.3920, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6522, -0.3920, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8155, -0.9213, -1.6249,  0.3437], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8155, -0.9213, -1.6249,  0.3437], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6726, -0.7265, -0.9253,  0.3308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6726, -0.7265, -0.9253,  0.3308], grad_fn=<TanhBackward0>),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6815,  0.8241, -1.8050, -0.9425], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6815,  0.8241, -1.8050, -0.9425], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7364], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7364], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1745, -1.0374, -0.8565, -1.0680], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1745, -1.0374, -0.8565, -1.0680], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7769, -0.6945, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7769, -0.6945, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7361, -1.6814, -0.6889, -1.8768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7361, -1.6814, -0.6889, -1.8768], grad_fn=<ViewBackward0>),), Output: tensor([-0.6268, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6268, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3037, -1.3062, -2.8663, -4.2257], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3037, -1.3062, -2.8663, -4.2257], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5569,  0.9618, -1.1242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5569,  0.9618, -1.1242], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2364,  0.7776, -0.4127, -2.1557], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2364,  0.7776, -0.4127, -2.1557], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6513, -0.3907, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6513, -0.3907, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8166, -0.9214, -1.6231,  0.3451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8166, -0.9214, -1.6231,  0.3451], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6812,  0.8240, -1.8052, -0.9429], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6812,  0.8240, -1.8052, -0.9429], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1746, -1.0371, -0.8571, -1.0682], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1746, -1.0371, -0.8571, -1.0682], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7768, -0.6948, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7768, -0.6948, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7357, -1.6832, -0.6897, -1.8771], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7357, -1.6832, -0.6897, -1.8771], grad_fn=<ViewBackward0>),), Output: tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.6167,  1.1616, -0.5937], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.6167,  1.1616, -0.5937], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3031, -1.3096, -2.8679, -4.2263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3031, -1.3096, -2.8679, -4.2263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2366,  0.7761, -0.4112, -2.1560], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2366,  0.7761, -0.4112, -2.1560], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6505, -0.3895, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6505, -0.3895, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8177, -0.9216, -1.6213,  0.3465], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8177, -0.9216, -1.6213,  0.3465], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6738, -0.7266, -0.9248,  0.3333], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6738, -0.7266, -0.9248,  0.3333], grad_fn=<TanhBackward0>),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1748, -1.0369, -0.8577, -1.0683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1748, -1.0369, -0.8577, -1.0683], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7767, -0.6951, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7767, -0.6951, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7354, -1.6850, -0.6905, -1.8774], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7354, -1.6850, -0.6905, -1.8774], grad_fn=<ViewBackward0>),), Output: tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3078, -0.6157,  1.1617, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3078, -0.6157,  1.1617, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3024, -1.3129, -2.8696, -4.2270], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3024, -1.3129, -2.8696, -4.2270], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2368,  0.7746, -0.4098, -2.1563], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2368,  0.7746, -0.4098, -2.1563], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6496, -0.3883, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6496, -0.3883, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8188, -0.9217, -1.6196,  0.3479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8188, -0.9217, -1.6196,  0.3479], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6744, -0.7267, -0.9246,  0.3345], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6744, -0.7267, -0.9246,  0.3345], grad_fn=<TanhBackward0>),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6808,  0.8238, -1.8057, -0.9436], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6808,  0.8238, -1.8057, -0.9436], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6771, -0.9474, -0.7369], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6771, -0.9474, -0.7369], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7350, -1.6867, -0.6913, -1.8777], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7350, -1.6867, -0.6913, -1.8777], grad_fn=<ViewBackward0>),), Output: tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3074, -0.6147,  1.1618, -0.5953], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3074, -0.6147,  1.1618, -0.5953], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3018, -1.3162, -2.8713, -4.2276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3018, -1.3162, -2.8713, -4.2276], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2845, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2845, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2370,  0.7731, -0.4084, -2.1566], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2370,  0.7731, -0.4084, -2.1566], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6487, -0.3871, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6487, -0.3871, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8198, -0.9218, -1.6178,  0.3492], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8198, -0.9218, -1.6178,  0.3492], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6750, -0.7267, -0.9243,  0.3357], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6750, -0.7267, -0.9243,  0.3357], grad_fn=<TanhBackward0>),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6806,  0.8236, -1.8059, -0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6806,  0.8236, -1.8059, -0.9439], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1751, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1751, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7764, -0.6956, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7764, -0.6956, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7346, -1.6885, -0.6921, -1.8780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7346, -1.6885, -0.6921, -1.8780], grad_fn=<ViewBackward0>),), Output: tensor([-0.6259, -0.9340, -0.5994, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6259, -0.9340, -0.5994, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3070, -0.6137,  1.1619, -0.5960], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3070, -0.6137,  1.1619, -0.5960], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.5468,  0.8216, -0.5342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.5468,  0.8216, -0.5342], grad_fn=<TanhBackward0>),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5531,  0.9673, -1.1262], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5531,  0.9673, -1.1262], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2371,  0.7716, -0.4071, -2.1569], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2371,  0.7716, -0.4071, -2.1569], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6479, -0.3860, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6479, -0.3860, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8208, -0.9219, -1.6162,  0.3505], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8208, -0.9219, -1.6162,  0.3505], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6755, -0.7268, -0.9241,  0.3368], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6755, -0.7268, -0.9241,  0.3368], grad_fn=<TanhBackward0>),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6804,  0.8235, -1.8061, -0.9443], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6804,  0.8235, -1.8061, -0.9443], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1752, -1.0361, -0.8593, -1.0688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1752, -1.0361, -0.8593, -1.0688], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7343, -1.6902, -0.6930, -1.8783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7343, -1.6902, -0.6930, -1.8783], grad_fn=<ViewBackward0>),), Output: tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3066, -0.6128,  1.1619, -0.5968], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3066, -0.6128,  1.1619, -0.5968], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3005, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3005, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5022,  0.7481, -0.8099], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5022,  0.7481, -0.8099], grad_fn=<TanhBackward0>),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2373,  0.7701, -0.4058, -2.1571], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2373,  0.7701, -0.4058, -2.1571], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6470, -0.3849, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6470, -0.3849, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8218, -0.9220, -1.6145,  0.3518], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8218, -0.9220, -1.6145,  0.3518], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6760, -0.7268, -0.9238,  0.3379], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6760, -0.7268, -0.9238,  0.3379], grad_fn=<TanhBackward0>),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1754, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1754, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7762, -0.6961, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7762, -0.6961, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>),), Output: tensor([-0.6255, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6255, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3063, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3063, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2999, -1.3259, -2.8762, -4.2295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2999, -1.3259, -2.8762, -4.2295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2375,  0.7687, -0.4045, -2.1574], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2375,  0.7687, -0.4045, -2.1574], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6462, -0.3838, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6462, -0.3838, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8227, -0.9220, -1.6129,  0.3530], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8227, -0.9220, -1.6129,  0.3530], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6765, -0.7269, -0.9236,  0.3390], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6765, -0.7269, -0.9236,  0.3390], grad_fn=<TanhBackward0>),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6799,  0.8233, -1.8066, -0.9450], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6799,  0.8233, -1.8066, -0.9450], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6768, -0.9475, -0.7375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6768, -0.9475, -0.7375], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7761, -0.6964, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7761, -0.6964, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>),), Output: tensor([-0.6253, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6253, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3059, -0.6109,  1.1621, -0.5984], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3059, -0.6109,  1.1621, -0.5984], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8632, -0.5448,  0.8217, -0.5359], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8632, -0.5448,  0.8217, -0.5359], grad_fn=<TanhBackward0>),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2992, -1.3290, -2.8779, -4.2301], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2992, -1.3290, -2.8779, -4.2301], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2376,  0.7673, -0.4033, -2.1577], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2376,  0.7673, -0.4033, -2.1577], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6454, -0.3827, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6454, -0.3827, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8236, -0.9221, -1.6113,  0.3541], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8236, -0.9221, -1.6113,  0.3541], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6770, -0.7269, -0.9234,  0.3400], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6770, -0.7269, -0.9234,  0.3400], grad_fn=<TanhBackward0>),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6797,  0.8231, -1.8068, -0.9453], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6797,  0.8231, -1.8068, -0.9453], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1757, -1.0352, -0.8606, -1.0694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1757, -1.0352, -0.8606, -1.0694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7333, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7333, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>),), Output: tensor([-0.6251, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6251, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3055, -0.6100,  1.1622, -0.5991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3055, -0.6100,  1.1622, -0.5991], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2986, -1.3321, -2.8795, -4.2307], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2986, -1.3321, -2.8795, -4.2307], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5496,  0.9725, -1.1281], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5496,  0.9725, -1.1281], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2378,  0.7659, -0.4021, -2.1579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2378,  0.7659, -0.4021, -2.1579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6445, -0.3817, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6445, -0.3817, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8245, -0.9222, -1.6097,  0.3553], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8245, -0.9222, -1.6097,  0.3553], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6775, -0.7269, -0.9231,  0.3410], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6775, -0.7269, -0.9231,  0.3410], grad_fn=<TanhBackward0>),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1758, -1.0350, -0.8610, -1.0696], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1758, -1.0350, -0.8610, -1.0696], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>),), Output: tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3051, -0.6091,  1.1622, -0.5999], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3051, -0.6091,  1.1622, -0.5999], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.5435,  0.8218, -0.5370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.5435,  0.8218, -0.5370], grad_fn=<TanhBackward0>),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2980, -1.3352, -2.8811, -4.2312], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2980, -1.3352, -2.8811, -4.2312], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4996,  0.7504, -0.8105], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4996,  0.7504, -0.8105], grad_fn=<TanhBackward0>),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2380,  0.7645, -0.4009, -2.1582], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2380,  0.7645, -0.4009, -2.1582], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6437, -0.3807, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6437, -0.3807, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8253, -0.9222, -1.6082,  0.3564], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8253, -0.9222, -1.6082,  0.3564], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6780, -0.7269, -0.9229,  0.3420], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6780, -0.7269, -0.9229,  0.3420], grad_fn=<TanhBackward0>),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6793,  0.8228, -1.8073, -0.9459], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6793,  0.8228, -1.8073, -0.9459], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7326, -1.6983, -0.6971, -1.8797], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7326, -1.6983, -0.6971, -1.8797], grad_fn=<ViewBackward0>),), Output: tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2974, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2974, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8713, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8713, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5479,  0.9750, -1.1291], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5479,  0.9750, -1.1291], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2381,  0.7632, -0.3998, -2.1584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2381,  0.7632, -0.3998, -2.1584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6429, -0.3798, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6429, -0.3798, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8262, -0.9223, -1.6067,  0.3574], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8262, -0.9223, -1.6067,  0.3574], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1761, -1.0344, -0.8617, -1.0699], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761, -1.0344, -0.8617, -1.0699], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7757, -0.6971, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7757, -0.6971, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>),), Output: tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3044, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3044, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.5422,  0.8218, -0.5381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.5422,  0.8218, -0.5381], grad_fn=<TanhBackward0>),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2968, -1.3412, -2.8844, -4.2324], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2968, -1.3412, -2.8844, -4.2324], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2383,  0.7618, -0.3987, -2.1587], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2383,  0.7618, -0.3987, -2.1587], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6422, -0.3788, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6422, -0.3788, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8270, -0.9223, -1.6052,  0.3585], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8270, -0.9223, -1.6052,  0.3585], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1762, -1.0341, -0.8620, -1.0701], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1762, -1.0341, -0.8620, -1.0701], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7756, -0.6973, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7756, -0.6973, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7319, -1.7014, -0.6987, -1.8802], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7319, -1.7014, -0.6987, -1.8802], grad_fn=<ViewBackward0>),), Output: tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3040, -0.6063,  1.1624, -0.6023], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3040, -0.6063,  1.1624, -0.6023], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.5415,  0.8218, -0.5387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.5415,  0.8218, -0.5387], grad_fn=<TanhBackward0>),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2962, -1.3442, -2.8861, -4.2330], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2962, -1.3442, -2.8861, -4.2330], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2385,  0.7605, -0.3976, -2.1589], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2385,  0.7605, -0.3976, -2.1589], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6414, -0.3779, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6414, -0.3779, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8277, -0.9223, -1.6038,  0.3595], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8277, -0.9223, -1.6038,  0.3595], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6793, -0.7270, -0.9222,  0.3448], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6793, -0.7270, -0.9222,  0.3448], grad_fn=<TanhBackward0>),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6787,  0.8223, -1.8080, -0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6787,  0.8223, -1.8080, -0.9468], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6763, -0.9476, -0.7384], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6763, -0.9476, -0.7384], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7316, -1.7029, -0.6995, -1.8805], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7316, -1.7029, -0.6995, -1.8805], grad_fn=<ViewBackward0>),), Output: tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2956, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2956, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4971,  0.7525, -0.8112], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4971,  0.7525, -0.8112], grad_fn=<TanhBackward0>),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2386,  0.7592, -0.3966, -2.1592], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2386,  0.7592, -0.3966, -2.1592], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6406, -0.3770, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6406, -0.3770, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8285, -0.9224, -1.6024,  0.3605], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8285, -0.9224, -1.6024,  0.3605], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6797, -0.7270, -0.9220,  0.3456], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6797, -0.7270, -0.9220,  0.3456], grad_fn=<TanhBackward0>),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6762, -0.9477, -0.7385], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6762, -0.9477, -0.7385], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1764, -1.0335, -0.8626, -1.0705], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1764, -1.0335, -0.8626, -1.0705], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>),), Output: tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3032, -0.6046,  1.1625, -0.6038], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3032, -0.6046,  1.1625, -0.6038], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8625, -0.5403,  0.8218, -0.5398], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8625, -0.5403,  0.8218, -0.5398], grad_fn=<TanhBackward0>),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2950, -1.3500, -2.8893, -4.2341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2950, -1.3500, -2.8893, -4.2341], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4965,  0.7531, -0.8114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4965,  0.7531, -0.8114], grad_fn=<TanhBackward0>),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2388,  0.7580, -0.3956, -2.1594], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2388,  0.7580, -0.3956, -2.1594], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6399, -0.3762, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6399, -0.3762, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8292, -0.9224, -1.6010,  0.3614], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8292, -0.9224, -1.6010,  0.3614], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6801, -0.7270, -0.9218,  0.3464], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6801, -0.7270, -0.9218,  0.3464], grad_fn=<TanhBackward0>),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1766, -1.0333, -0.8629, -1.0707], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1766, -1.0333, -0.8629, -1.0707], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7752, -0.6977, -0.7897], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7752, -0.6977, -0.7897], grad_fn=<TanhBackward0>),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7309, -1.7059, -0.7012, -1.8810], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7309, -1.7059, -0.7012, -1.8810], grad_fn=<ViewBackward0>),), Output: tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3028, -0.6037,  1.1625, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3028, -0.6037,  1.1625, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.5397,  0.8219, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.5397,  0.8219, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2944, -1.3529, -2.8909, -4.2346], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2944, -1.3529, -2.8909, -4.2346], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5438,  0.9812, -1.1315], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5438,  0.9812, -1.1315], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2390,  0.7567, -0.3946, -2.1596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2390,  0.7567, -0.3946, -2.1596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6391, -0.3754, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6391, -0.3754, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8300, -0.9224, -1.5996,  0.3623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8300, -0.9224, -1.5996,  0.3623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6805, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6805, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6781,  0.8218, -1.8088, -0.9477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6781,  0.8218, -1.8088, -0.9477], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1767, -1.0330, -0.8631, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1767, -1.0330, -0.8631, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9714], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9714], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9714], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7306, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7306, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>),), Output: tensor([-0.6234, -0.9363, -0.6056, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6234, -0.9363, -0.6056, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2391,  0.7555, -0.3937, -2.1599], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2391,  0.7555, -0.3937, -2.1599], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6384, -0.3745, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6384, -0.3745, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8306, -0.9224, -1.5983,  0.3632], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8306, -0.9224, -1.5983,  0.3632], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6808, -0.7270, -0.9214,  0.3480], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6808, -0.7270, -0.9214,  0.3480], grad_fn=<TanhBackward0>),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6780,  0.8216, -1.8090, -0.9480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6780,  0.8216, -1.8090, -0.9480], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6760, -0.9477, -0.7389], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6760, -0.9477, -0.7389], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1768, -1.0327, -0.8634, -1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1768, -1.0327, -0.8634, -1.0710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7303, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7303, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3021, -0.6019,  1.1626, -0.6062], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3021, -0.6019,  1.1626, -0.6062], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8623, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8623, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Run model training for multiple epochs with PyTorch model\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "loss_rmse_list = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_preds = [tmlp(torch.tensor(i)) for i in x]\n",
    "    y_true = [torch.tensor([y_i.data]) for y_i in y_true]\n",
    "    loss_rmse = rmse(y_true, y_preds)  # Calculate loss\n",
    "    loss_rmse_list.append(loss_rmse.item())\n",
    "    loss_rmse.backward()  # Perform backpropagation\n",
    "    optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1820,
   "id": "3c92ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds_tmlp = [0.9358289241790771, -1.0214004516601562, -0.9719018936157227, 1.059492588043213]\n",
      "y_true = [tensor([1.]), tensor([-1.]), tensor([-1.]), tensor([1.])]\n"
     ]
    }
   ],
   "source": [
    "# Print prediction using PyTorch model\n",
    "print(f\"y_preds_tmlp = {[item.item() for item in y_preds]}\")\n",
    "print(f\"y_true = {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "id": "a83fc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_rmse_list = [1.498351812362671, 0.9614522457122803, 0.7609688639640808, 0.655349612236023, 0.5761975646018982, 0.501936674118042, 0.4307599663734436, 0.367279976606369, 0.31345903873443604, 0.26842188835144043, 0.23068277537822723, 0.1989007443189621, 0.1719910055398941, 0.14910173416137695, 0.12956500053405762, 0.11285087466239929, 0.0985308513045311, 0.08625147491693497, 0.0757165253162384, 0.06667446345090866, 0.05891042947769165, 0.05223962664604187, 0.04650302976369858, 0.04156395420432091, 0.03730503097176552, 0.03362554311752319, 0.030439501628279686, 0.02767348289489746, 0.025265028700232506, 0.0231611430644989, 0.021316811442375183, 0.019693993031978607, 0.018260536715388298, 0.016989244148135185, 0.015857156366109848, 0.014844922348856926, 0.013936166651546955, 0.013117010705173016, 0.012375819496810436, 0.011702601797878742, 0.011088969185948372, 0.01052772719413042, 0.010012799873948097, 0.009538893587887287, 0.009101547300815582, 0.00869688205420971, 0.008321563713252544, 0.007972671650350094, 0.007647679187357426, 0.007344385609030724, 0.007060816511511803, 0.006795275490731001, 0.006546230521053076, 0.006312322802841663, 0.006092341151088476, 0.005885200574994087, 0.00568993529304862, 0.0055056409910321236, 0.005331522785127163, 0.0051668500527739525, 0.0050109680742025375, 0.004863264970481396, 0.004723159596323967, 0.00459018861874938, 0.0044638412073254585, 0.00434370432049036, 0.004229375626891851, 0.004120480269193649, 0.004016675986349583, 0.003917653113603592, 0.0038231173530220985, 0.0037327874451875687, 0.0036464272998273373, 0.003563774051144719, 0.003484630025923252, 0.0034087826497852802, 0.0033360389061272144, 0.0032662374433130026, 0.0031991833820939064, 0.0031347484327852726, 0.00307278661057353, 0.0030131349340081215, 0.0029557019006460905, 0.0029003508388996124, 0.0028469834942370653, 0.002795466687530279, 0.0027457408141344786, 0.0026976950466632843, 0.00265124486759305, 0.002606324851512909, 0.0025628400035202503, 0.0025207330472767353, 0.002479939954355359, 0.0024403859861195087, 0.002402015496045351, 0.0023647777270525694, 0.00232863612473011, 0.0022935112938284874, 0.0022593820467591286, 0.002226194366812706]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "print(f\"loss_rmse_list = {loss_rmse_list}\")\n",
    "plt.plot(range(epochs), loss_rmse_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ec98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
