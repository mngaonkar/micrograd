{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5e86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from graphviz import Digraph\n",
    "import os\n",
    "from IPython import display\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5629e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ab2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for Jupyter Notebook to find the graphviz executables\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.abspath(\"/opt/homebrew/bin/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eba97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for gradient calculation\n",
    "def f(x):\n",
    "    return 3*x**2 - 4*x + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fbd74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.arange(-10, 10, 0.5)\n",
    "ys = f(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cde3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71c90bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 3\n",
    "b = -2\n",
    "c = 1\n",
    "d1 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e7752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c + h\n",
    "d2 = a*b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dc_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dc_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68d78e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -5.000002\n",
      "da_dy =  -2.000000000279556\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "a = a + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"da_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ed6158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.9999970000000005\n",
      "db_dy =  2.9999999995311555\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "b = b + h\n",
    "d2 = a*b + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"db_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f10ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 =  -5\n",
      "d2 =  -4.999999\n",
      "dab_dy =  1.000000000139778\n"
     ]
    }
   ],
   "source": [
    "a = 3; b = -2; c = 1\n",
    "d1 = a*b + c\n",
    "d2 = a*b + h + c\n",
    "print(\"d1 = \", d1)\n",
    "print(\"d2 = \", d2)\n",
    "print(\"dab_dy = \", (d2 - d1) / h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5c68b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value():\n",
    "    \"\"\" Basic class to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "        else:\n",
    "            raise ValueError(\"Can only add Value to Value\")\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "077e5615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d._prev = (Value(data=-6), Value(data=1)) d = -5\n"
     ]
    }
   ],
   "source": [
    "a = Value(3, label=\"a\")\n",
    "b = Value(-2, label=\"b\")\n",
    "c = Value(1, label=\"c\")\n",
    "d = a*b + c; d.label = \"d\"\n",
    "print(f\"d._prev = {d._prev} d = {d.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db81115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(root):\n",
    "    \"\"\" Vibe codded and it works! \"\"\"\n",
    "    # Initialize a directed graph\n",
    "    dot = Digraph(format='png', graph_attr={'rankdir': 'LR'})  # Left-to-right layout\n",
    "    \n",
    "    def build_graph(node, visited=None):\n",
    "        if visited is None:\n",
    "            visited = set()\n",
    "        \n",
    "        # Skip if node already visited to avoid cycles\n",
    "        if id(node) in visited:\n",
    "            return\n",
    "        visited.add(id(node))\n",
    "        \n",
    "        # Add node to the graph\n",
    "        node_id = str(id(node))\n",
    "        dot.node(node_id, f\"{{ {node.label} | data = {node.data} grad={node.grad} }}\", shape='record')\n",
    "        \n",
    "        # If node has an operation, create an operation node\n",
    "        if node._op:\n",
    "            op_id = f\"{node_id}_op\"\n",
    "            dot.node(op_id, node._op, shape='circle')\n",
    "            dot.edge(op_id, node_id)  # Edge from operation to result\n",
    "        \n",
    "            # Recursively process children\n",
    "            for child in node._prev:\n",
    "                child_id = str(id(child))\n",
    "                build_graph(child, visited)\n",
    "                dot.edge(child_id, op_id)  # Edge from child to operation\n",
    "    \n",
    "    # Build the graph starting from the root\n",
    "    build_graph(root)\n",
    "    \n",
    "    # Render and display the graph\n",
    "    dot.render('computation_graph', view=True, cleanup=True)\n",
    "    \n",
    "    return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84c181f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98dd4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ed37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142981514304\n"
     ]
    }
   ],
   "source": [
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec8210b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70612029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daba22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "922f3c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_dn = 1 - math.tanh(o.data)**2\n",
    "y.grad = do_dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72a71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a71919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1_x2w2.grad = y.grad\n",
    "b.grad = y.grad\n",
    "x1w1.grad = x1w1_x2w2.grad\n",
    "x2w2.grad = x1w1_x2w2.grad\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef9473d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.grad = x1w1.grad * w1.data\n",
    "x2.grad = x2w2.grad * w2.data\n",
    "w1.grad = x1w1.grad * x1.data\n",
    "w2.grad = x2w2.grad * x2.data\n",
    "\n",
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "d7edad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement generic backpropagation\n",
    "class Value():\n",
    "    \"\"\" Complete class with backprop to represent a scale value with arithmeti operations and gradients. \"\"\"\n",
    "    visited = set()  # Set to keep track of visited nodes during backpropagation\n",
    "    def __init__(self, data, _children=(), _op = '', grad=0.0, label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = _children\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self.grad = 0.0  # Gradient initialized to zero\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []  # Topological order of nodes for backpropagation\n",
    "        def build_topo(v, visited=None):\n",
    "            if visited is None:\n",
    "                visited = set()\n",
    "            if id(v) not in visited:\n",
    "                visited.add(id(v))\n",
    "                for child in v._prev:\n",
    "                    build_topo(child, visited)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        for item in reversed(topo):\n",
    "            item._backward()\n",
    "            \n",
    "    def _backward(self):\n",
    "        \"\"\" Perform backpropagation to compute gradients. \"\"\"\n",
    "        logger.debug(f\"Backward pass for node: {self.label}, op: {self._op}, data: {self.data}, grad: {self.grad}\")\n",
    "        # For addition operation, local gradient is 1 for each child hence gradient of the child with respect\n",
    "        # to the output is 1 * self gradient.\n",
    "        # Note, we need to accumulate gradients for each child and not simply overwrite them.\n",
    "        if self._op == '+':\n",
    "            for child in self._prev:\n",
    "                child.grad += self.grad\n",
    "\n",
    "        # For multiplication operation, local gradient is the value of the other child hence\n",
    "        # gradient of the child with respect to the output is self.grad * other child's value.\n",
    "        elif self._op == '*':\n",
    "            self._prev[0].grad += self.grad * self._prev[1].data\n",
    "            self._prev[1].grad += self.grad * self._prev[0].data\n",
    "\n",
    "        elif self._op == '/':\n",
    "            # For division operation, local gradient is 1 / other child's value hence\n",
    "            # gradient of the child with respect to the output is self.grad * (1 / other child's value).\n",
    "            self._prev[0].grad += self.grad / self._prev[1].data\n",
    "            self._prev[1].grad += -self.grad * (self._prev[0].data / (self._prev[1].data ** 2))\n",
    "\n",
    "        # For power operation, local gradient is power * base^(power-1) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == '**':\n",
    "            base = self._prev[0].data\n",
    "            power = self._prev[1].data\n",
    "            self._prev[0].grad += self.grad * power * (base ** (power - 1))\n",
    "\n",
    "        # For subtraction operation, local gradient is 1 for the first child and -1 for the second child\n",
    "        # hence gradient of the first child with respect to the output is self.grad * 1 and for the second child\n",
    "        # it is self.grad * -1.\n",
    "        elif self._op == '-':\n",
    "            self._prev[0].grad += self.grad  # First child\n",
    "            self._prev[1].grad += -self.grad  # Second child\n",
    "\n",
    "        # For tanh operation, local gradient is 1 - tanh^2(self.data) hence\n",
    "        # gradient of the child with respect to the output is self.grad * local gradient.\n",
    "        elif self._op == 'tanh':\n",
    "            logger.debug(f\"tanh: self.data = {self.data}, self.grad = {self.grad}\")\n",
    "            self._prev[0].grad += self.grad * (1 - np.tanh(self._prev[0].data)**2)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data + other.data, _children=(self, other), _op='+')\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data - other.data, _children=(self, other), _op='-')\n",
    "        else:\n",
    "            raise ValueError(\"Can only subtract Value from Value\")\n",
    "        \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Value):\n",
    "            return Value(self.data * other.data, _children=(self, other), _op='*')\n",
    "        else:\n",
    "            raise ValueError(\"Can only multiply Value to Value\")\n",
    "        \n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, Value):\n",
    "            other = Value(other)  # Convert to Value if not already\n",
    "        return Value(self.data / other.data, _children=(self, other), _op='/')\n",
    "        \n",
    "    def __pow__(self, power):\n",
    "        return Value(self.data ** power, _children=(self,Value(power)), _op='**')\n",
    "        \n",
    "    def tanh(self):\n",
    "        return Value((np.exp(self.data*2) - 1)/(np.exp(self.data*2) + 1), _op='tanh', _children=(self,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "de7dc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "w1 = Value(0.5, label=\"w1\")\n",
    "w2 = Value(-1.5, label=\"w2\")\n",
    "b = Value(1, label=\"b\")\n",
    "x1w1 = x1 * w1; x1w1.label = \"x1w1\"\n",
    "x2w2 = x2 * w2; x2w2.label = \"x2w2\"\n",
    "x1w1_x2w2 = x1w1 + x2w2; x1w1_x2w2.label = \"x1w1_x2w2\"\n",
    "y = x1w1_x2w2 + b; y.label = \"y\"\n",
    "o = y.tanh(); o.label = \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "b1415a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "65eb5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backpropagation\n",
    "o.grad = 1.0  # Set the gradient of the output to 1.0\n",
    "\n",
    "o.visited = set()  # Reset visited set for each backward pass\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "b9b0f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "160da944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -0.9866142868995667\n"
     ]
    }
   ],
   "source": [
    "# Verfiy with PyTorch\n",
    "# Forward pass for neural network with one neuron\n",
    "# Inputs: x1, x2; Weights: w1, w2; Bias: b; Output: y\n",
    "\n",
    "import torch\n",
    "\n",
    "x1 = torch.Tensor([2.0])\n",
    "x2 = torch.Tensor([3.0])\n",
    "w1 = torch.Tensor([0.5])\n",
    "w2 = torch.Tensor([-1.5])\n",
    "b = torch.Tensor([1.0])\n",
    "x1.requires_grad = True\n",
    "x2.requires_grad = True\n",
    "w1.requires_grad = True\n",
    "w2.requires_grad = True\n",
    "b.requires_grad = True\n",
    "\n",
    "y = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(y)\n",
    "\n",
    "print(f\"o = {o.item()}\")\n",
    "\n",
    "o.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "182b150b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.grad = 0.013296124525368214\n",
      "x2.grad = -0.039888374507427216\n",
      "w1.grad = 0.053184498101472855\n",
      "w2.grad = 0.07977674901485443\n",
      "b.grad = 0.026592249050736427\n"
     ]
    }
   ],
   "source": [
    "print(f\"x1.grad = {x1.grad.item()}\") \n",
    "print(f\"x2.grad = {x2.grad.item()}\") \n",
    "print(f\"w1.grad = {w1.grad.item()}\")\n",
    "print(f\"w2.grad = {w2.grad.item()}\")\n",
    "print(f\"b.grad = {b.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "f1702ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "class N():\n",
    "    \"\"\" Class to represent a single neuron with forward and backward pass. \"\"\"\n",
    "    def __init__(self, input_size, label=\"\"):\n",
    "        self.input_size = input_size\n",
    "        self.weights = [Value(random.uniform(-1, 1), label = f\"{label} w{i}\") for i in range(input_size)]\n",
    "        self.b = Value(random.uniform(-1, 1), label=f\"{label} b\")  # Bias term\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.weights + [self.b]  # Return all parameters (weights and bias)\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None) -> Value:\n",
    "        \"\"\" Forward pass for the neuron. \"\"\"\n",
    "        assert len(input) == self.input_size, f\"Input size {len(input)} does not match expected size {self.input_size}\"\n",
    "        wx = [w*x for w, x in zip(self.weights, input)]\n",
    "        wx_sum = Value(0.0)  # Initialize sum of weighted inputs\n",
    "        for item in wx:\n",
    "            wx_sum += item  # Sum the weighted inputs\n",
    "\n",
    "        wx_sum = wx_sum + self.b\n",
    "        if act_fn is None:\n",
    "            return wx_sum\n",
    "        elif act_fn == 'tanh':\n",
    "            return wx_sum.tanh()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {act_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "95f55a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o = -2.742169638094225\n"
     ]
    }
   ],
   "source": [
    "n = N(2)  # Create a neuron with 2 inputs\n",
    "x1 = Value(2, label=\"x1\")\n",
    "x2 = Value(3, label=\"x2\")\n",
    "\n",
    "o = n([x1, x2])\n",
    "print(f\"o = {o.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "f5d28c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    \"\"\" Class to represent a layer of neurons. \"\"\"\n",
    "    def __init__(self, input, output, label=\"\"):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        self.neurons = [N(input, label=f\"{label} Neuron {i}\") for i in range(output)]\n",
    "    \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for n in self.neurons:\n",
    "            parameters.extend(n.parameters())  # Collect parameters from each neuron\n",
    "        return parameters\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def __call__(self, input, act_fn=None):\n",
    "        \"\"\" Forward pass for the layer. \"\"\"\n",
    "        outputs = [n(input, act_fn) for n in self.neurons]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "29894ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "class NN():\n",
    "    \"\"\" Class to represent a simple neural network with hidden layers. \"\"\"\n",
    "    def __init__(self, input_size: int, \n",
    "                 hidden_layer_num: int, \n",
    "                 hidden_layer_size: int, \n",
    "                 output_size: int):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_num = hidden_layer_num\n",
    "        self.output_size = output_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.forward_hook = None  # Hook for forward pass\n",
    "\n",
    "        self.layers = []\n",
    "        for i in range(hidden_layer_num):\n",
    "            if i == 0:\n",
    "                # First layer takes the input size\n",
    "                self.layers.append(Layer(input_size, hidden_layer_size, label=f\"Layer {i}\"))\n",
    "            elif i == hidden_layer_num - 1:\n",
    "                # Last layer is the output layer, use output_size\n",
    "                self.layers.append(Layer(hidden_layer_size, output_size, label=f\"Layer {i}\"))\n",
    "            else:\n",
    "                # Intermediate layers use hidden_layer_size\n",
    "                self.layers.append(Layer(hidden_layer_size, hidden_layer_size, label=f\"Layer {i}\"))\n",
    "           \n",
    "    def parameters(self):\n",
    "        parameters = []\n",
    "        for layer in self.layers:\n",
    "            parameters.extend(layer.parameters())  # Collect parameters from each layer\n",
    "        return parameters\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\" Reset gradients of all parameters to zero. \"\"\"\n",
    "        for param in self.parameters():\n",
    "            param.grad = 0.0\n",
    "            \n",
    "    def register_forward_hook(self, func: Callable[[str, list[Value], list[Value]], None]): \n",
    "        self.forward_hook = func\n",
    "\n",
    "    def __call__(self, input):\n",
    "        \"\"\" Forward pass for the neural network. \"\"\"\n",
    "        assert len(input) == self.input_size, \"input size mismatch\"\n",
    "\n",
    "        x = [Value(i) for i in input]\n",
    "        for num, layer in enumerate(self.layers):\n",
    "            if num != len(self.layers) - 1:\n",
    "                act_fn = 'tanh'\n",
    "            else:\n",
    "                act_fn = None\n",
    "            input = x.copy()\n",
    "            x = layer(x, act_fn)  # Forward pass through the layer\n",
    "            self.forward_hook(f\"Layer {num}\", [i.data for i in input], [o.data for o in x]) if self.forward_hook else None\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "7e307dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)  # For reproducibility\n",
    "mlp = NN(input_size=3, hidden_layer_num=3, hidden_layer_size=4, output_size=1)  # Create a neural network with 2 inputs, 2 hidden layers of size 3, and 1 output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "b87ae772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model information:\n",
      "input size: 3\n",
      "total model layers: 3\n",
      "[0] layer input: 3, layer output: 4, neurons: 4\n",
      "[1] layer input: 4, layer output: 4, neurons: 4\n",
      "[2] layer input: 4, layer output: 1, neurons: 1\n",
      "total model parameters: 41\n",
      "model parameters:\n",
      "[tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]), tensor([-0.5536, -0.8261,  0.0107,  0.0899]), tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]), tensor([ 0.6116, -0.3268,  0.6143,  0.1041]), tensor([[0.6588, 0.2370, 0.7234, 0.1547]]), tensor([0.4091])]\n"
     ]
    }
   ],
   "source": [
    "print(\"model information:\")\n",
    "print(f\"input size: {mlp.input_size}\")\n",
    "print(f\"total model layers: {len(mlp.layers)}\")\n",
    "for i, layer in enumerate(mlp.layers):\n",
    "    print(f\"[{i}] layer input: {layer.input}, layer output: {layer.output}, neurons: {len(layer.neurons)}\")\n",
    "print(f\"total model parameters: {len(mlp.parameters())}\")\n",
    "\n",
    "# Build tensor parameters for the model, this will be used to set the parameters in PyTorch\n",
    "mlp_tensor_parameters = []\n",
    "print(\"model parameters:\")\n",
    "\n",
    "# Save pre-defined parameters in a list of tensors\n",
    "for layer_num, layer in enumerate(mlp.layers):\n",
    "    layer_params = []\n",
    "    bias_params = []\n",
    "    for neuron_num, neuron in enumerate(layer.neurons):\n",
    "        layer_params.append([x.data for x in neuron.parameters()][:-1])\n",
    "        bias_params.append([x.data for x in neuron.parameters()][-1])\n",
    "    mlp_tensor_parameters.append(torch.tensor(layer_params))\n",
    "    mlp_tensor_parameters.append(torch.tensor(bias_params))\n",
    "    \n",
    "print(mlp_tensor_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "4fb2c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch model with the same architecture for verification\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 4),  # First hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 4),  # Second hidden layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1)   # Output layer\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def hook_fn(module, input, output, name=None):\n",
    "    \"\"\" Hook function to capture the output of each layer. \"\"\"\n",
    "    print(f\"Layer: {module}, Input: {input}, Output: {output}\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\" Calculate Root Mean Squared Error. \"\"\"\n",
    "    diffs = torch.stack([(y_true_i - y_pred_i) ** 2 for y_true_i, y_pred_i in zip(y_true, y_pred)])\n",
    "    return torch.mean(diffs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "bd7853c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering hook for layer: \n",
      "Registering hook for layer: layers\n",
      "Registering hook for layer: layers.0\n",
      "Registering hook for layer: layers.1\n",
      "Registering hook for layer: layers.2\n",
      "Registering hook for layer: layers.3\n",
      "Registering hook for layer: layers.4\n",
      "model parameters = [Parameter containing:\n",
      "tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5536, -0.8261,  0.0107,  0.0899], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.6116, -0.3268,  0.6143,  0.1041], requires_grad=True), Parameter containing:\n",
      "tensor([[0.6588, 0.2370, 0.7234, 0.1547]], requires_grad=True), Parameter containing:\n",
      "tensor([0.4091], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "tmlp = MLP(input_size=3)  # Create a PyTorch model with the same architecture\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "with torch.no_grad():\n",
    "    for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "        param_tmlp.copy_(param_mlp)\n",
    "\n",
    "# Register hooks to capture the output of each layer\n",
    "for name, module in tmlp.named_modules():\n",
    "    print(f\"Registering hook for layer: {name}\")\n",
    "    module.register_forward_hook(hook_fn)\n",
    "\n",
    "print(f\"model parameters = {[p for p in tmlp.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "5df68e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model parameters:\n",
      "layers.0.weight: data: tensor([[ 0.2789, -0.9500, -0.4499],\n",
      "        [ 0.4729,  0.3534,  0.7844],\n",
      "        [-0.1562, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) grad=None\n",
      "layers.0.bias: data: tensor([-0.5536, -0.8261,  0.0107,  0.0899]) grad=None\n",
      "layers.2.weight: data: tensor([[-0.5591,  0.1785,  0.6189, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6890,  0.9144],\n",
      "        [-0.8145, -0.8066,  0.6950,  0.2075],\n",
      "        [ 0.4595,  0.0725,  0.9462, -0.2429]]) grad=None\n",
      "layers.2.bias: data: tensor([ 0.6116, -0.3268,  0.6143,  0.1041]) grad=None\n",
      "layers.4.weight: data: tensor([[0.6588, 0.2370, 0.7234, 0.1547]]) grad=None\n",
      "layers.4.bias: data: tensor([0.4091]) grad=None\n"
     ]
    }
   ],
   "source": [
    "# Print parameters of the PyTorch model\n",
    "print(\"PyTorch model parameters:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: data: {param.data} grad={param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "bd430978",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "\n",
    "y = [1.0, -1.0, -1.0, 1.0]  # Example labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "014ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mse(y_preds, y_true):\n",
    "    \"\"\"Mean squared error loss function.\"\"\"\n",
    "    loss = sum([(i - j)**2 for i, j in zip(y_true, y_preds)])\n",
    "\n",
    "    return loss/len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "8bb459c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_mae(y_preds, y_true):\n",
    "    \"\"\"Mean absolute error loss function.\"\"\"\n",
    "    loss = sum([(i - j) for i, j in zip(y_preds, y_true)])\n",
    "\n",
    "    return loss / len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "cab62bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param: Layer 0 Neuron 0 w0, data: 0.2788535969157675, grad: 0.0\n",
      "param: Layer 0 Neuron 0 w1, data: -0.9499784895546661, grad: 0.0\n",
      "param: Layer 0 Neuron 0 w2, data: -0.4499413632617615, grad: 0.0\n",
      "param: Layer 0 Neuron 0 b, data: -0.5535785237023545, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w0, data: 0.4729424283280248, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w1, data: 0.3533989748458226, grad: 0.0\n",
      "param: Layer 0 Neuron 1 w2, data: 0.7843591354096908, grad: 0.0\n",
      "param: Layer 0 Neuron 1 b, data: -0.8261223347411677, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w0, data: -0.15615636062945915, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w1, data: -0.9404055611238593, grad: 0.0\n",
      "param: Layer 0 Neuron 2 w2, data: -0.5627240503927933, grad: 0.0\n",
      "param: Layer 0 Neuron 2 b, data: 0.010710576206724776, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w0, data: -0.9469280606322728, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w1, data: -0.602324698626703, grad: 0.0\n",
      "param: Layer 0 Neuron 3 w2, data: 0.2997688755590464, grad: 0.0\n",
      "param: Layer 0 Neuron 3 b, data: 0.08988296120643335, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w0, data: -0.5591187559186066, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w1, data: 0.17853136775181744, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w2, data: 0.6188609133556533, grad: 0.0\n",
      "param: Layer 1 Neuron 0 w3, data: -0.987002480643878, grad: 0.0\n",
      "param: Layer 1 Neuron 0 b, data: 0.6116385036656158, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w0, data: 0.3962787899764537, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w1, data: -0.31949896696401625, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w2, data: -0.6890410003764369, grad: 0.0\n",
      "param: Layer 1 Neuron 1 w3, data: 0.9144261444135624, grad: 0.0\n",
      "param: Layer 1 Neuron 1 b, data: -0.32681090977474647, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w0, data: -0.8145083132397042, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w1, data: -0.806567246333072, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w2, data: 0.6949887326949196, grad: 0.0\n",
      "param: Layer 1 Neuron 2 w3, data: 0.20745206273378214, grad: 0.0\n",
      "param: Layer 1 Neuron 2 b, data: 0.6142565465487604, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w0, data: 0.45946357338763577, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w1, data: 0.07245618290940148, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w2, data: 0.9462315279587412, grad: 0.0\n",
      "param: Layer 1 Neuron 3 w3, data: -0.24293124558329304, grad: 0.0\n",
      "param: Layer 1 Neuron 3 b, data: 0.104081262546454, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w0, data: 0.6588093285059897, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w1, data: 0.2370395047284921, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w2, data: 0.7234138006215545, grad: 0.0\n",
      "param: Layer 2 Neuron 0 w3, data: 0.15470429051352408, grad: 0.0\n",
      "param: Layer 2 Neuron 0 b, data: 0.40914367242984695, grad: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Print grads for our model\n",
    "for param in mlp.parameters():\n",
    "    print(f\"param: {param.label}, data: {param.data}, grad: {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "3d011511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795]\n",
      "Layer: Layer 1, Input: [-0.983540418876898, 0.3761781385427304, -0.9881211941388645, -0.9991982278148795], Output: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824]\n",
      "Layer: Layer 2, Input: [0.9221810704816664, -0.7893076871461533, 0.2145409768394499, -0.7669251605843824], Output: [0.8661433515946025]\n",
      "y_preds = 0.8661433515946025\n",
      "y = 1.0\n",
      "loss = Value(data=0.017917602322326195)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with our model\n",
    "mlp.register_forward_hook(hook_fn)  # Register the hook to capture outputs\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "0f2e8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "7c87c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "y_preds_tmlp = 0.8661433458328247\n",
      "loss_tmlp = Value(data=0.017917603864830767)\n"
     ]
    }
   ],
   "source": [
    "# First forward pass with PyTorch model\n",
    "y_preds_tmlp = tmlp(torch.tensor(x[0]))\n",
    "print(f\"y_preds_tmlp = {y_preds_tmlp.item()}\")\n",
    "loss_tmlp = loss_fn_mse([Value(y_preds_tmlp.item())], [Value(y[0])])\n",
    "print(f\"loss_tmlp = {loss_tmlp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "dedc339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass with our model\n",
    "mlp.zero_grad()\n",
    "loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "loss.visited = set()  # Reset visited set for each backward pass\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "494cc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for our model\n",
    "learning_rate = 0.001\n",
    "for param in mlp.parameters():\n",
    "    param.data -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "8964c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3956, -2.5601, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3762, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6034, -1.0696,  0.2179, -1.0128], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7893,  0.2145, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8661], grad_fn=<ViewBackward0>)\n",
      "output = tensor([0.8661], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass with PyTorch model\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "optimizer.zero_grad()\n",
    "output = tmlp(torch.tensor(x[0]))  # Forward pass\n",
    "print(f\"output = {output}\")\n",
    "loss_rmse = rmse([torch.tensor([y[0]])], [output])  # Calculate loss\n",
    "loss_rmse.backward()  # Perform backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "6bc150d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmlp loss grad = 0.017917603254318237\n"
     ]
    }
   ],
   "source": [
    "# Print gradients of the loss function\n",
    "print(f\"tmlp loss grad = {loss_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "30507a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters with gradients for PyTorch model\n",
    "optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "46a77386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for our model:\n",
      "Layer 0 Neuron 0 w0: 0.2788439384702872 (grad: 0.009658445480288656)\n",
      "Layer 0 Neuron 0 w1: -0.9499929772228866 (grad: 0.014487668220432983)\n",
      "Layer 0 Neuron 0 w2: -0.44993653403902134 (grad: -0.004829222740144328)\n",
      "Layer 0 Neuron 0 b: -0.5535833529250946 (grad: 0.004829222740144328)\n",
      "Layer 0 Neuron 1 w0: 0.47268365591740313 (grad: 0.2587724106216494)\n",
      "Layer 0 Neuron 1 w1: 0.3530108162298901 (grad: 0.38815861593247414)\n",
      "Layer 0 Neuron 1 w2: 0.7844885216150016 (grad: -0.1293862053108247)\n",
      "Layer 0 Neuron 1 b: -0.8262517209464785 (grad: 0.1293862053108247)\n",
      "Layer 0 Neuron 2 w0: -0.156149540968433 (grad: -0.006819661026130761)\n",
      "Layer 0 Neuron 2 w1: -0.9403953316323201 (grad: -0.010229491539196141)\n",
      "Layer 0 Neuron 2 w2: -0.5627274602233063 (grad: 0.0034098305130653805)\n",
      "Layer 0 Neuron 2 b: 0.010713986037237841 (grad: -0.0034098305130653805)\n",
      "Layer 0 Neuron 3 w0: -0.9469279643907854 (grad: -9.624148732860756e-05)\n",
      "Layer 0 Neuron 3 w1: -0.6023245542644721 (grad: -0.00014436223099291136)\n",
      "Layer 0 Neuron 3 w2: 0.29976882743830274 (grad: 4.812074366430378e-05)\n",
      "Layer 0 Neuron 3 b: 0.08988300932717702 (grad: -4.812074366430378e-05)\n",
      "Layer 1 Neuron 0 w0: -0.5591447037724337 (grad: 0.025947853827143978)\n",
      "Layer 1 Neuron 0 w1: 0.17854129211808092 (grad: -0.00992436626348306)\n",
      "Layer 1 Neuron 0 w2: 0.6188348446513917 (grad: 0.02606870426158594)\n",
      "Layer 1 Neuron 0 w3: -0.9870288415834612 (grad: 0.02636093958323322)\n",
      "Layer 1 Neuron 0 b: 0.6116648857576266 (grad: -0.026382092010792762)\n",
      "Layer 1 Neuron 1 w0: 0.39625526026487373 (grad: 0.02352971157995671)\n",
      "Layer 1 Neuron 1 w1: -0.31948996747306224 (grad: -0.008999490954019754)\n",
      "Layer 1 Neuron 1 w2: -0.6890646396761118 (grad: 0.023639299674820924)\n",
      "Layer 1 Neuron 1 w3: 0.914402240112671 (grad: 0.02390430089140105)\n",
      "Layer 1 Neuron 1 b: -0.32678698629267255 (grad: -0.02392348207389913)\n",
      "Layer 1 Neuron 2 w0: -0.8146900256750575 (grad: 0.18171243535335416)\n",
      "Layer 1 Neuron 2 w1: -0.8064977461433804 (grad: -0.06950018969159072)\n",
      "Layer 1 Neuron 2 w2: 0.6948061739457669 (grad: 0.18255874915264755)\n",
      "Layer 1 Neuron 2 w3: 0.207267457465008 (grad: 0.1846052687741373)\n",
      "Layer 1 Neuron 2 b: 0.6144412999476708 (grad: -0.1847533989104902)\n",
      "Layer 1 Neuron 3 w0: 0.45944679778766173 (grad: 0.01677559997402493)\n",
      "Layer 1 Neuron 3 w1: 0.07246259913170414 (grad: -0.0064162223026606735)\n",
      "Layer 1 Neuron 3 w2: 0.9462146742275059 (grad: 0.01685373123522252)\n",
      "Layer 1 Neuron 3 w3: -0.24294828824818293 (grad: 0.017042664889885966)\n",
      "Layer 1 Neuron 3 b: 0.10409831888664303 (grad: -0.017056340189029483)\n",
      "Layer 2 Neuron 0 w0: 0.6590562086406249 (grad: -0.24688013463515496)\n",
      "Layer 2 Neuron 0 w1: 0.2368281965653681 (grad: 0.2113081631240002)\n",
      "Layer 2 Neuron 0 w2: 0.7234712360937652 (grad: -0.05743547221069753)\n",
      "Layer 2 Neuron 0 w3: 0.15449897445037689 (grad: 0.20531606314719333)\n",
      "Layer 2 Neuron 0 b: 0.40941138572665775 (grad: -0.2677132968107949)\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters for out model\n",
    "print(\"Updated parameters for our model:\")\n",
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "ea105b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated parameters for PyTorch model:\n",
      "layers.0.weight: tensor([[ 0.2788, -0.9500, -0.4499],\n",
      "        [ 0.4727,  0.3530,  0.7845],\n",
      "        [-0.1561, -0.9404, -0.5627],\n",
      "        [-0.9469, -0.6023,  0.2998]]) (grad: tensor([[ 9.6584e-03,  1.4488e-02, -4.8292e-03],\n",
      "        [ 2.5877e-01,  3.8816e-01, -1.2939e-01],\n",
      "        [-6.8197e-03, -1.0229e-02,  3.4098e-03],\n",
      "        [-9.6238e-05, -1.4436e-04,  4.8119e-05]]))\n",
      "layers.0.bias: tensor([-0.5536, -0.8263,  0.0107,  0.0899]) (grad: tensor([ 4.8292e-03,  1.2939e-01, -3.4098e-03, -4.8119e-05]))\n",
      "layers.2.weight: tensor([[-0.5591,  0.1785,  0.6188, -0.9870],\n",
      "        [ 0.3963, -0.3195, -0.6891,  0.9144],\n",
      "        [-0.8147, -0.8065,  0.6948,  0.2073],\n",
      "        [ 0.4594,  0.0725,  0.9462, -0.2429]]) (grad: tensor([[ 0.0259, -0.0099,  0.0261,  0.0264],\n",
      "        [ 0.0235, -0.0090,  0.0236,  0.0239],\n",
      "        [ 0.1817, -0.0695,  0.1826,  0.1846],\n",
      "        [ 0.0168, -0.0064,  0.0169,  0.0170]]))\n",
      "layers.2.bias: tensor([ 0.6117, -0.3268,  0.6144,  0.1041]) (grad: tensor([-0.0264, -0.0239, -0.1848, -0.0171]))\n",
      "layers.4.weight: tensor([[0.6591, 0.2368, 0.7235, 0.1545]]) (grad: tensor([[-0.2469,  0.2113, -0.0574,  0.2053]]))\n",
      "layers.4.bias: tensor([0.4094]) (grad: tensor([-0.2677]))\n"
     ]
    }
   ],
   "source": [
    "# Print updated parameters of PyTorch model\n",
    "print(\"Updated parameters for PyTorch model:\")\n",
    "for name, param in tmlp.named_parameters():\n",
    "    print(f\"{name}: {param.data} (grad: {param.grad})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "696d9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "d85f718c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9835427836930768, 0.3745107718519387, -0.9881199861535883, -0.9991982266578866]\n",
      "Layer: Layer 1, Input: [-0.9835427836930768, 0.3745107718519387, -0.9881199861535883, -0.9991982266578866], Output: [0.9221529606207961, -0.7890705788700002, 0.21654528178218366, -0.7669462096196659]\n",
      "Layer: Layer 2, Input: [0.9221529606207961, -0.7890705788700002, 0.21654528178218366, -0.7669462096196659], Output: [0.8684597374199408]\n",
      "y_preds = 0.8684597374199408\n",
      "y = 1.0\n",
      "loss = Value(data=0.017302840679630935)\n"
     ]
    }
   ],
   "source": [
    "# Second forward pass with our model\n",
    "y_preds = mlp(x[0])\n",
    "print(f\"y_preds = {y_preds[0].data}\")\n",
    "print(f\"y = {y[0]}\")\n",
    "loss = loss_fn_mse([y_preds[0]], [Value(y[0])])\n",
    "print(f\"loss = {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "20af6cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Neuron 0 w0 = 0.2788439384702872, grad = 0.009658445480288656\n",
      "Layer 0 Neuron 0 w1 = -0.9499929772228866, grad = 0.014487668220432983\n",
      "Layer 0 Neuron 0 w2 = -0.44993653403902134, grad = -0.004829222740144328\n",
      "Layer 0 Neuron 0 b = -0.5535833529250946, grad = 0.004829222740144328\n",
      "Layer 0 Neuron 1 w0 = 0.47268365591740313, grad = 0.2587724106216494\n",
      "Layer 0 Neuron 1 w1 = 0.3530108162298901, grad = 0.38815861593247414\n",
      "Layer 0 Neuron 1 w2 = 0.7844885216150016, grad = -0.1293862053108247\n",
      "Layer 0 Neuron 1 b = -0.8262517209464785, grad = 0.1293862053108247\n",
      "Layer 0 Neuron 2 w0 = -0.156149540968433, grad = -0.006819661026130761\n",
      "Layer 0 Neuron 2 w1 = -0.9403953316323201, grad = -0.010229491539196141\n",
      "Layer 0 Neuron 2 w2 = -0.5627274602233063, grad = 0.0034098305130653805\n",
      "Layer 0 Neuron 2 b = 0.010713986037237841, grad = -0.0034098305130653805\n",
      "Layer 0 Neuron 3 w0 = -0.9469279643907854, grad = -9.624148732860756e-05\n",
      "Layer 0 Neuron 3 w1 = -0.6023245542644721, grad = -0.00014436223099291136\n",
      "Layer 0 Neuron 3 w2 = 0.29976882743830274, grad = 4.812074366430378e-05\n",
      "Layer 0 Neuron 3 b = 0.08988300932717702, grad = -4.812074366430378e-05\n",
      "Layer 1 Neuron 0 w0 = -0.5591447037724337, grad = 0.025947853827143978\n",
      "Layer 1 Neuron 0 w1 = 0.17854129211808092, grad = -0.00992436626348306\n",
      "Layer 1 Neuron 0 w2 = 0.6188348446513917, grad = 0.02606870426158594\n",
      "Layer 1 Neuron 0 w3 = -0.9870288415834612, grad = 0.02636093958323322\n",
      "Layer 1 Neuron 0 b = 0.6116648857576266, grad = -0.026382092010792762\n",
      "Layer 1 Neuron 1 w0 = 0.39625526026487373, grad = 0.02352971157995671\n",
      "Layer 1 Neuron 1 w1 = -0.31948996747306224, grad = -0.008999490954019754\n",
      "Layer 1 Neuron 1 w2 = -0.6890646396761118, grad = 0.023639299674820924\n",
      "Layer 1 Neuron 1 w3 = 0.914402240112671, grad = 0.02390430089140105\n",
      "Layer 1 Neuron 1 b = -0.32678698629267255, grad = -0.02392348207389913\n",
      "Layer 1 Neuron 2 w0 = -0.8146900256750575, grad = 0.18171243535335416\n",
      "Layer 1 Neuron 2 w1 = -0.8064977461433804, grad = -0.06950018969159072\n",
      "Layer 1 Neuron 2 w2 = 0.6948061739457669, grad = 0.18255874915264755\n",
      "Layer 1 Neuron 2 w3 = 0.207267457465008, grad = 0.1846052687741373\n",
      "Layer 1 Neuron 2 b = 0.6144412999476708, grad = -0.1847533989104902\n",
      "Layer 1 Neuron 3 w0 = 0.45944679778766173, grad = 0.01677559997402493\n",
      "Layer 1 Neuron 3 w1 = 0.07246259913170414, grad = -0.0064162223026606735\n",
      "Layer 1 Neuron 3 w2 = 0.9462146742275059, grad = 0.01685373123522252\n",
      "Layer 1 Neuron 3 w3 = -0.24294828824818293, grad = 0.017042664889885966\n",
      "Layer 1 Neuron 3 b = 0.10409831888664303, grad = -0.017056340189029483\n",
      "Layer 2 Neuron 0 w0 = 0.6590562086406249, grad = -0.24688013463515496\n",
      "Layer 2 Neuron 0 w1 = 0.2368281965653681, grad = 0.2113081631240002\n",
      "Layer 2 Neuron 0 w2 = 0.7234712360937652, grad = -0.05743547221069753\n",
      "Layer 2 Neuron 0 w3 = 0.15449897445037689, grad = 0.20531606314719333\n",
      "Layer 2 Neuron 0 b = 0.40941138572665775, grad = -0.2677132968107949\n"
     ]
    }
   ],
   "source": [
    "for param in mlp.parameters():\n",
    "    print(f\"{param.label} = {param.data}, grad = {param.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "f4b8b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.98977805119148, 0.9935359999439295, -0.09571457411570347, 0.9997694357600397]\n",
      "Layer: Layer 1, Input: [-0.98977805119148, 0.9935359999439295, -0.09571457411570347, 0.9997694357600397], Output: [-0.35984638044141426, -0.7724880076554739, 0.8676491821114196, 0.9954520561335383]\n",
      "Layer: Layer 2, Input: [-0.35984638044141426, -0.7724880076554739, 0.8676491821114196, 0.9954520561335383], Output: [1.3977302626392123]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982124784959681, 0.9212014421613409, -0.7089819386371037, 0.9760082276985881]\n",
      "Layer: Layer 1, Input: [-0.9982124784959681, 0.9212014421613409, -0.7089819386371037, 0.9760082276985881], Output: [0.1379858380225528, -0.9152847694718999, 0.6766781144620915, 0.9870274595420396]\n",
      "Layer: Layer 2, Input: [0.1379858380225528, -0.9152847694718999, 0.6766781144620915, 0.9870274595420396], Output: [1.825684350665944]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9640345145780096, 0.5018069482974178, -0.9581734968488274, 0.9604230351233444]\n",
      "Layer: Layer 1, Input: [-0.9640345145780096, 0.5018069482974178, -0.9581734968488274, 0.9604230351233444], Output: [0.5589730747172751, -0.9661705068749575, 0.35602184469443054, 0.9591380645214981]\n",
      "Layer: Layer 2, Input: [0.5589730747172751, -0.9661705068749575, 0.35602184469443054, 0.9591380645214981], Output: [2.052838980931323]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9077380007195399, 0.9441566430179797, 0.08964172727048704, 0.9733357982815241]\n",
      "Layer: Layer 1, Input: [-0.9077380007195399, 0.9441566430179797, 0.08964172727048704, 0.9733357982815241], Output: [-0.4271383959505544, -0.6912205049007271, 0.8805038439848908, 0.9955494909781069]\n",
      "Layer: Layer 2, Input: [-0.4271383959505544, -0.6912205049007271, 0.8805038439848908, 0.9955494909781069], Output: [1.275208091658546]\n",
      "Epoch 1/100, Loss: 4.3845616871564035, Accuracy: -5.551461685895025\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9895992697525157, 0.9943903542352065, 0.11005006772370815, 0.9997736604720561]\n",
      "Layer: Layer 1, Input: [-0.9895992697525157, 0.9943903542352065, 0.11005006772370815, 0.9997736604720561], Output: [-0.719440559230812, -0.6504527200865443, 0.8620651106392418, 0.9966952295725505]\n",
      "Layer: Layer 2, Input: [-0.719440559230812, -0.6504527200865443, 0.8620651106392418, 0.9966952295725505], Output: [0.539055279296585]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9981972169655863, 0.9331875929641127, -0.5728854987138459, 0.9766032423584895]\n",
      "Layer: Layer 1, Input: [-0.9981972169655863, 0.9331875929641127, -0.5728854987138459, 0.9766032423584895], Output: [-0.3737019654355337, -0.8740101913894669, 0.6211771652889223, 0.9897997639205279]\n",
      "Layer: Layer 2, Input: [-0.3737019654355337, -0.8740101913894669, 0.6211771652889223, 0.9897997639205279], Output: [0.8767264822767802]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9636572348688844, 0.5384193451225636, -0.9517167410557725, 0.9609497772952932]\n",
      "Layer: Layer 1, Input: [-0.9636572348688844, 0.5384193451225636, -0.9517167410557725, 0.9609497772952932], Output: [0.18457183200987684, -0.9572055686812929, 0.1877051543881964, 0.9627621628004331]\n",
      "Layer: Layer 2, Input: [0.18457183200987684, -0.9572055686812929, 0.1877051543881964, 0.9627621628004331], Output: [1.1906664098720174]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9070614048544988, 0.9477227947571525, 0.20193546264549594, 0.9735697042332921]\n",
      "Layer: Layer 1, Input: [-0.9070614048544988, 0.9477227947571525, 0.20193546264549594, 0.9735697042332921], Output: [-0.7146851254854005, -0.5894648738450453, 0.8607254649782513, 0.9963066255028785]\n",
      "Layer: Layer 2, Input: [-0.7146851254854005, -0.5894648738450453, 0.8607254649782513, 0.9963066255028785], Output: [0.49337790310645013]\n",
      "Epoch 2/100, Loss: 2.1975643983064246, Accuracy: -4.034959709745762\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.989671504529937, 0.9951295152464865, 0.020782888658689807, 0.9997779007203931]\n",
      "Layer: Layer 1, Input: [-0.989671504529937, 0.9951295152464865, 0.020782888658689807, 0.9997779007203931], Output: [-0.7845116855854487, -0.6884878922051172, 0.8097374844426161, 0.9963051517854684]\n",
      "Layer: Layer 2, Input: [-0.7845116855854487, -0.6884878922051172, 0.8097374844426161, 0.9963051517854684], Output: [0.28936585664021397]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.998199825338691, 0.9411757487736077, -0.5030161559076306, 0.9770613151774695]\n",
      "Layer: Layer 1, Input: [-0.998199825338691, 0.9411757487736077, -0.5030161559076306, 0.9770613151774695], Output: [-0.5921422769848871, -0.8573079364195418, 0.5865730453589891, 0.9910810050592803]\n",
      "Layer: Layer 2, Input: [-0.5921422769848871, -0.8573079364195418, 0.5865730453589891, 0.9910810050592803], Output: [0.46866707004087144]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9636432204609289, 0.5788840532992672, -0.952278102511356, 0.9614782223787675]\n",
      "Layer: Layer 1, Input: [-0.9636432204609289, 0.5788840532992672, -0.952278102511356, 0.9614782223787675], Output: [-0.08683308461316287, -0.9536721693888175, 0.09169071218854198, 0.9658870882104827]\n",
      "Layer: Layer 2, Input: [-0.08683308461316287, -0.9536721693888175, 0.09169071218854198, 0.9658870882104827], Output: [0.7292195671609996]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9074540447933288, 0.9505988198852982, 0.16612813012711453, 0.9737930268921365]\n",
      "Layer: Layer 1, Input: [-0.9074540447933288, 0.9505988198852982, 0.16612813012711453, 0.9737930268921365], Output: [-0.7891035262836316, -0.6069881146492397, 0.8253686869389553, 0.9961914403291708]\n",
      "Layer: Layer 2, Input: [-0.7891035262836316, -0.6069881146492397, 0.8253686869389553, 0.9961914403291708], Output: [0.2331161509842758]\n",
      "Epoch 3/100, Loss: 1.5600737494161954, Accuracy: -3.6754046295773817\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9898060031545496, 0.9956177848605107, -0.1035182585132952, 0.9997814195527508]\n",
      "Layer: Layer 1, Input: [-0.9898060031545496, 0.9956177848605107, -0.1035182585132952, 0.9997814195527508], Output: [-0.806853165718734, -0.7456885346479211, 0.7393103157136656, 0.9956414931707412]\n",
      "Layer: Layer 2, Input: [-0.806853165718734, -0.7456885346479211, 0.7393103157136656, 0.9956414931707412], Output: [0.17527086949523318]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982068953767701, 0.9459854848154325, -0.4780375294093922, 0.9773908297931833]\n",
      "Layer: Layer 1, Input: [-0.9982068953767701, 0.9459854848154325, -0.4780375294093922, 0.9773908297931833], Output: [-0.691112959373144, -0.8562384390678766, 0.5480928116832068, 0.9915973622274361]\n",
      "Layer: Layer 2, Input: [-0.691112959373144, -0.8562384390678766, 0.5480928116832068, 0.9915973622274361], Output: [0.2628118209193425]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9637247174507214, 0.6087066298989885, -0.9542489954730218, 0.9619196906825648]\n",
      "Layer: Layer 1, Input: [-0.9637247174507214, 0.6087066298989885, -0.9542489954730218, 0.9619196906825648], Output: [-0.26239194915111547, -0.9529621038348364, 0.02126558769871343, 0.9680012632764261]\n",
      "Layer: Layer 2, Input: [-0.26239194915111547, -0.9529621038348364, 0.02126558769871343, 0.9680012632764261], Output: [0.44914674542158384]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9081111102286183, 0.9525360481987426, 0.10862721530464174, 0.9739745641979125]\n",
      "Layer: Layer 1, Input: [-0.9081111102286183, 0.9525360481987426, 0.10862721530464174, 0.9739745641979125], Output: [-0.8208674792240926, -0.6472860191546538, 0.7856493535488591, 0.9959305624528397]\n",
      "Layer: Layer 2, Input: [-0.8208674792240926, -0.6472860191546538, 0.7856493535488591, 0.9959305624528397], Output: [0.11620716084896726]\n",
      "Epoch 4/100, Loss: 1.2889969765143463, Accuracy: -3.4204805359967256\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9899524958747274, 0.9959374340432949, -0.20623093252822106, 0.999784260891211]\n",
      "Layer: Layer 1, Input: [-0.9899524958747274, 0.9959374340432949, -0.20623093252822106, 0.999784260891211], Output: [-0.819170431600255, -0.7887689022568868, 0.6664765702849866, 0.995005764777822]\n",
      "Layer: Layer 2, Input: [-0.819170431600255, -0.7887689022568868, 0.6664765702849866, 0.995005764777822], Output: [0.10759243033279259]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982149062977818, 0.949078196188184, -0.47468830541084966, 0.9776499074756722]\n",
      "Layer: Layer 1, Input: [-0.9982149062977818, 0.949078196188184, -0.47468830541084966, 0.9776499074756722], Output: [-0.7427363380358115, -0.8614386298499861, 0.5074910591013816, 0.9917845553676389]\n",
      "Layer: Layer 2, Input: [-0.7427363380358115, -0.8614386298499861, 0.5074910591013816, 0.9917845553676389], Output: [0.14861300543014277]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.963825842677778, 0.6296665808732249, -0.9560975452277608, 0.9622829068509388]\n",
      "Layer: Layer 1, Input: [-0.963825842677778, 0.6296665808732249, -0.9560975452277608, 0.9622829068509388], Output: [-0.37545184318827524, -0.9534736458033415, -0.03488703719024651, 0.9694479158589411]\n",
      "Layer: Layer 2, Input: [-0.37545184318827524, -0.9534736458033415, -0.03488703719024651, 0.9694479158589411], Output: [0.27051259121082283]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9088237532394383, 0.9538390620744007, 0.05749653452066088, 0.9741203245964741]\n",
      "Layer: Layer 1, Input: [-0.9088237532394383, 0.9538390620744007, 0.05749653452066088, 0.9741203245964741], Output: [-0.8384556988307549, -0.6837282905206307, 0.7472907491916765, 0.9956781262239517]\n",
      "Layer: Layer 2, Input: [-0.8384556988307549, -0.6837282905206307, 0.7472907491916765, 0.9956781262239517], Output: [0.0574385600909455]\n",
      "Epoch 5/100, Loss: 1.1545818547678164, Accuracy: -3.254094606217227\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9901009881352442, 0.9961576208033834, -0.27578845427578713, 0.9997866005949798]\n",
      "Layer: Layer 1, Input: [-0.9901009881352442, 0.9961576208033834, -0.27578845427578713, 0.9997866005949798], Output: [-0.8293909767996743, -0.8168362829567914, 0.6035544687610376, 0.9945355212772412]\n",
      "Layer: Layer 2, Input: [-0.8293909767996743, -0.8168362829567914, 0.6035544687610376, 0.9945355212772412], Output: [0.06443300416717901]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982230913761581, 0.9512136397681344, -0.4813614919244282, 0.977869781646631]\n",
      "Layer: Layer 1, Input: [-0.9982230913761581, 0.9512136397681344, -0.4813614919244282, 0.977869781646631], Output: [-0.7732737690190797, -0.8686562565750351, 0.4674632542720235, 0.9918210063475567]\n",
      "Layer: Layer 2, Input: [-0.7732737690190797, -0.8686562565750351, 0.4674632542720235, 0.9918210063475567], Output: [0.08242808087042786]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.963928924782092, 0.644850440141274, -0.9574501636962395, 0.9625899371582105]\n",
      "Layer: Layer 1, Input: [-0.963928924782092, 0.644850440141274, -0.9574501636962395, 0.9625899371582105], Output: [-0.4518710174931297, -0.9544713052766822, -0.08060393785528397, 0.9705016420663372]\n",
      "Layer: Layer 2, Input: [-0.4518710174931297, -0.9544713052766822, -0.08060393785528397, 0.9705016420663372], Output: [0.1518992779282407]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.909551392330362, 0.9547557482820759, 0.02014088225090315, 0.9742402047346267]\n",
      "Layer: Layer 1, Input: [-0.909551392330362, 0.9547557482820759, 0.02014088225090315, 0.9742402047346267], Output: [-0.8504098429378644, -0.7116582462020038, 0.7142678562917147, 0.995490461236329]\n",
      "Layer: Layer 2, Input: [-0.8504098429378644, -0.7116582462020038, 0.7142678562917147, 0.995490461236329], Output: [0.02871698533166034]\n",
      "Epoch 6/100, Loss: 1.079299698755827, Accuracy: -3.1411773692998297\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9902504379397116, 0.9963176122687724, -0.3156863412432015, 0.9997885886735047]\n",
      "Layer: Layer 1, Input: [-0.9902504379397116, 0.9963176122687724, -0.3156863412432015, 0.9997885886735047], Output: [-0.8394169574693499, -0.8344260322378736, 0.5559081225788962, 0.9942637219066726]\n",
      "Layer: Layer 2, Input: [-0.8394169574693499, -0.8344260322378736, 0.5559081225788962, 0.9942637219066726], Output: [0.03851091722380451]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982313342609638, 0.9527719201278123, -0.4933518552405253, 0.9780670305696717]\n",
      "Layer: Layer 1, Input: [-0.9982313342609638, 0.9527719201278123, -0.4933518552405253, 0.9780670305696717], Output: [-0.7932066812526214, -0.8763751442321333, 0.4286325880908559, 0.991775509703225]\n",
      "Layer: Layer 2, Input: [-0.7932066812526214, -0.8763751442321333, 0.4286325880908559, 0.991775509703225], Output: [0.04334802184717157]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9640308361735641, 0.6563008041094961, -0.9583089705581685, 0.9628582886131724]\n",
      "Layer: Layer 1, Input: [-0.9640308361735641, 0.6563008041094961, -0.9583089705581685, 0.9628582886131724], Output: [-0.5067756311480587, -0.9556534437404668, -0.11854617412856094, 0.9713160914073797]\n",
      "Layer: Layer 2, Input: [-0.5067756311480587, -0.9556534437404668, -0.11854617412856094, 0.9713160914073797], Output: [0.06993838827150284]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9102904968176638, 0.955431980779709, -0.003326804243360302, 0.974342164912086]\n",
      "Layer: Layer 1, Input: [-0.9102904968176638, 0.955431980779709, -0.003326804243360302, 0.974342164912086], Output: [-0.8598599726990603, -0.7320853553571466, 0.6882607405465755, 0.9953807791176733]\n",
      "Layer: Layer 2, Input: [-0.8598599726990603, -0.7320853553571466, 0.6882607405465755, 0.9953807791176733], Output: [0.017978526172263143]\n",
      "Epoch 7/100, Loss: 1.0305426701865092, Accuracy: -3.0567969667226063\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9904008005774045, 0.9964388026004891, -0.3318895226786782, 0.9997903323981868]\n",
      "Layer: Layer 1, Input: [-0.9904008005774045, 0.9964388026004891, -0.3318895226786782, 0.9997903323981868], Output: [-0.8496116680909439, -0.8451081180177952, 0.5239604805605239, 0.9941745436847231]\n",
      "Layer: Layer 2, Input: [-0.8496116680909439, -0.8451081180177952, 0.5239604805605239, 0.9941745436847231], Output: [0.025569058843085413]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982396207250901, 0.9539515736452024, -0.5088666732687585, 0.978251120252399]\n",
      "Layer: Layer 1, Input: [-0.9982396207250901, 0.9539515736452024, -0.5088666732687585, 0.978251120252399], Output: [-0.8072698060460972, -0.8841014128433919, 0.3902060759391273, 0.9916749303464067]\n",
      "Layer: Layer 2, Input: [-0.8072698060460972, -0.8841014128433919, 0.3902060759391273, 0.9916749303464067], Output: [0.01954172339638538]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9641312035614584, 0.6652222252794397, -0.9587597411232105, 0.9630998081503112]\n",
      "Layer: Layer 1, Input: [-0.9641312035614584, 0.6652222252794397, -0.9587597411232105, 0.9630998081503112], Output: [-0.5486211311015398, -0.9568980302110932, -0.15120101282626217, 0.971975829206696]\n",
      "Layer: Layer 2, Input: [-0.5486211311015398, -0.9568980302110932, -0.15120101282626217, 0.971975829206696], Output: [0.010463245005785882]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9110412045111712, 0.9559495236941045, -0.014822748387260448, 0.9744319050409566]\n",
      "Layer: Layer 1, Input: [-0.9110412045111712, 0.9559495236941045, -0.014822748387260448, 0.9744319050409566], Output: [-0.8680993525237939, -0.7468078179756109, 0.6692557580058378, 0.9953442278521879]\n",
      "Layer: Layer 2, Input: [-0.8680993525237939, -0.7468078179756109, 0.6692557580058378, 0.9953442278521879], Output: [0.01866340292309865]\n",
      "Epoch 8/100, Loss: 0.9932596177750294, Accuracy: -2.9857725066359873\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9905517027919396, 0.9965331833870559, -0.3290804175583197, 0.9997919050424992]\n",
      "Layer: Layer 1, Input: [-0.9905517027919396, 0.9965331833870559, -0.3290804175583197, 0.9997919050424992], Output: [-0.8599826788157502, -0.8510232411164822, 0.506154950536618, 0.994239195644774]\n",
      "Layer: Layer 2, Input: [-0.8599826788157502, -0.8510232411164822, 0.506154950536618, 0.994239195644774], Output: [0.022510522720726178]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982479317743848, 0.9548620818512552, -0.5271845130481233, 0.9784277734879443]\n",
      "Layer: Layer 1, Input: [-0.9982479317743848, 0.9548620818512552, -0.5271845130481233, 0.9784277734879443], Output: [-0.817834148946542, -0.8916807893422167, 0.35081964432538615, 0.9915304576482349]\n",
      "Layer: Layer 2, Input: [-0.817834148946542, -0.8916807893422167, 0.35081964432538615, 0.9915304576482349], Output: [0.0036279034257504783]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9642299013754038, 0.6723274034653823, -0.9588842679044937, 0.9633222259467318]\n",
      "Layer: Layer 1, Input: [-0.9642299013754038, 0.6723274034653823, -0.9588842679044937, 0.9633222259467318], Output: [-0.5821811498953663, -0.958157138558513, -0.18079236014186512, 0.9725295956564095]\n",
      "Layer: Layer 2, Input: [-0.5821811498953663, -0.958157138558513, -0.18079236014186512, 0.9725295956564095], Output: [-0.035511876177224955]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9118018260725091, 0.9563548573432274, -0.01637517458141556, 0.9745133742021616]\n",
      "Layer: Layer 1, Input: [-0.9118018260725091, 0.9563548573432274, -0.01637517458141556, 0.9745133742021616], Output: [-0.8757010654204623, -0.7573046371126866, 0.6564200631006387, 0.9953704422501385]\n",
      "Layer: Layer 2, Input: [-0.8757010654204623, -0.7573046371126866, 0.6564200631006387, 0.9953704422501385], Output: [0.026773128180459627]\n",
      "Epoch 9/100, Loss: 0.960040632938325, Accuracy: -2.9188323763473396\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9907025052861936, 0.9966077995791605, -0.310282490633882, 0.9997933558268385]\n",
      "Layer: Layer 1, Input: [-0.9907025052861936, 0.9966077995791605, -0.310282490633882, 0.9997933558268385], Output: [-0.8704520861869887, -0.8533548689496553, 0.5006049419040726, 0.9944292625742596]\n",
      "Layer: Layer 2, Input: [-0.8704520861869887, -0.8533548689496553, 0.5006049419040726, 0.9944292625742596], Output: [0.02721924190669406]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982562374376658, 0.955567227701922, -0.5478956331912791, 0.9786005570652643]\n",
      "Layer: Layer 1, Input: [-0.9982562374376658, 0.955567227701922, -0.5478956331912791, 0.9786005570652643], Output: [-0.826189624541921, -0.8990566663291852, 0.30906478840076235, 0.991347925105434]\n",
      "Layer: Layer 2, Input: [-0.826189624541921, -0.8990566663291852, 0.30906478840076235, 0.991347925105434], Output: [-0.009241745273103286]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9643267336562649, 0.6780536668918422, -0.958743237047953, 0.9635305428529434]\n",
      "Layer: Layer 1, Input: [-0.9643267336562649, 0.6780536668918422, -0.958743237047953, 0.9635305428529434], Output: [-0.6102118896465849, -0.9594145687961675, -0.2091553922594032, 0.9730070264161489]\n",
      "Layer: Layer 2, Input: [-0.6102118896465849, -0.9594145687961675, -0.2091553922594032, 0.9730070264161489], Output: [-0.07382974076103699]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9125692487103138, 0.9566753309578725, -0.009631200184298864, 0.9745892662081163]\n",
      "Layer: Layer 1, Input: [-0.9125692487103138, 0.9566753309578725, -0.009631200184298864, 0.9745892662081163], Output: [-0.8829189269154167, -0.7646381544193351, 0.6486931353716, 0.9954485037693821]\n",
      "Layer: Layer 2, Input: [-0.8829189269154167, -0.7646381544193351, 0.6486931353716, 0.9954485037693821], Output: [0.03985019643109827]\n",
      "Epoch 10/100, Loss: 0.9268958292545605, Accuracy: -2.8498590756280677\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9908524767244984, 0.9966670303652405, -0.2773613928321941, 0.9997947173437678]\n",
      "Layer: Layer 1, Input: [-0.9908524767244984, 0.9966670303652405, -0.2773613928321941, 0.9997947173437678], Output: [-0.880903148438941, -0.8527297820085403, 0.5056305429173586, 0.9947186911351815]\n",
      "Layer: Layer 2, Input: [-0.880903148438941, -0.8527297820085403, 0.5056305429173586, 0.9947186911351815], Output: [0.038433479508685586]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982645042318921, 0.9561064431272815, -0.5706034711950498, 0.9787716810048465]\n",
      "Layer: Layer 1, Input: [-0.9982645042318921, 0.9561064431272815, -0.5706034711950498, 0.9787716810048465], Output: [-0.8330890367283341, -0.9061886988944752, 0.26375110817373737, 0.9911320581300426]\n",
      "Layer: Layer 2, Input: [-0.8330890367283341, -0.9061886988944752, 0.26375110817373737, 0.9911320581300426], Output: [-0.02236003242514739]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9644214907858257, 0.6826835429508082, -0.9583792397665131, 0.9637279687567847]\n",
      "Layer: Layer 1, Input: [-0.9644214907858257, 0.6826835429508082, -0.9583792397665131, 0.9637279687567847], Output: [-0.6343427321729413, -0.9606674359071316, -0.2377099278954784, 0.9734270328043503]\n",
      "Layer: Layer 2, Input: [-0.6343427321729413, -0.9606674359071316, -0.2377099278954784, 0.9734270328043503], Output: [-0.10835511420273225]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9133397747728949, 0.9569278529408959, 0.0041316194141079315, 0.9746613852235254]\n",
      "Layer: Layer 1, Input: [-0.9133397747728949, 0.9569278529408959, 0.0041316194141079315, 0.9746613852235254], Output: [-0.8898496674299577, -0.7695620220621038, 0.6450592806002, 0.9955682317461835]\n",
      "Layer: Layer 2, Input: [-0.8898496674299577, -0.7695620220621038, 0.6450592806002, 0.9955682317461835], Output: [0.056463120149758905]\n",
      "Epoch 11/100, Loss: 0.8914206313838708, Accuracy: -2.774388253713676\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9910008797516336, 0.9967137852497846, -0.23166603365106922, 0.9997960105377625]\n",
      "Layer: Layer 1, Input: [-0.9910008797516336, 0.9967137852497846, -0.23166603365106922, 0.9997960105377625], Output: [-0.8911811586419467, -0.8494819806077041, 0.5197214097265, 0.995081998805781]\n",
      "Layer: Layer 2, Input: [-0.8911811586419467, -0.8494819806077041, 0.5197214097265, 0.995081998805781], Output: [0.05550795983728046]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982726998756128, 0.9565059461272767, -0.5948238995252652, 0.9789424096485263]\n",
      "Layer: Layer 1, Input: [-0.9982726998756128, 0.9565059461272767, -0.5948238995252652, 0.9789424096485263], Output: [-0.8389982026848987, -0.9130302223550533, 0.21403412003681746, 0.990888241126281]\n",
      "Layer: Layer 2, Input: [-0.8389982026848987, -0.9130302223550533, 0.21403412003681746, 0.990888241126281], Output: [-0.03802023430483037]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9645140082987931, 0.6864114495175015, -0.9578244452090089, 0.9639165102944096]\n",
      "Layer: Layer 1, Input: [-0.9645140082987931, 0.6864114495175015, -0.9578244452090089, 0.9639165102944096], Output: [-0.6555564342056873, -0.9619173989619936, -0.26747748895000756, 0.9738021338583289]\n",
      "Layer: Layer 2, Input: [-0.6555564342056873, -0.9619173989619936, -0.26747748895000756, 0.9738021338583289], Output: [-0.14167878154842017]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9141095347921703, 0.957123632330047, 0.023845771812546636, 0.9747308915998989]\n",
      "Layer: Layer 1, Input: [-0.9141095347921703, 0.957123632330047, 0.023845771812546636, 0.9747308915998989], Output: [-0.8965053608102177, -0.772640673039318, 0.6446202451356705, 0.995720041189518]\n",
      "Layer: Layer 2, Input: [-0.8965053608102177, -0.772640673039318, 0.6446202451356705, 0.995720041189518], Output: [0.07586190466012738]\n",
      "Epoch 12/100, Loss: 0.8520542042100704, Accuracy: -2.6889311196493417\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9911469936814005, 0.9967501570038099, -0.17464306826572526, 0.9997972478572617]\n",
      "Layer: Layer 1, Input: [-0.9911469936814005, 0.9967501570038099, -0.17464306826572526, 0.9997972478572617], Output: [-0.9010928543173125, -0.8438427068676745, 0.5412803037129565, 0.9954923888183428]\n",
      "Layer: Layer 2, Input: [-0.9010928543173125, -0.8438427068676745, 0.5412803037129565, 0.9954923888183428], Output: [0.07811992569013276]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982807949272134, 0.9567849338366262, -0.6199745458937388, 0.9791132647646482]\n",
      "Layer: Layer 1, Input: [-0.9982807949272134, 0.9567849338366262, -0.6199745458937388, 0.9791132647646482], Output: [-0.8442167851421886, -0.9195273911685857, 0.15950248197167446, 0.9906231342850225]\n",
      "Layer: Layer 2, Input: [-0.8442167851421886, -0.9195273911685857, 0.15950248197167446, 0.9906231342850225], Output: [-0.05782037231610904]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9646041901522602, 0.6893814829194439, -0.9571085661303022, 0.9640973253157719]\n",
      "Layer: Layer 1, Input: [-0.9646041901522602, 0.6893814829194439, -0.9571085661303022, 0.9640973253157719], Output: [-0.674453353315468, -0.9631661359055287, -0.2990898807931253, 0.9741407618909168]\n",
      "Layer: Layer 2, Input: [-0.674453353315468, -0.9631661359055287, -0.2990898807931253, 0.9741407618909168], Output: [-0.17553143683515637]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9148745956794154, 0.9572708568880776, 0.04847604343225438, 0.974798456075458]\n",
      "Layer: Layer 1, Input: [-0.9148745956794154, 0.9572708568880776, 0.04847604343225438, 0.974798456075458], Output: [-0.9028494936535779, -0.7743431921880907, 0.6465792851471065, 0.9958944789959191]\n",
      "Layer: Layer 2, Input: [-0.9028494936535779, -0.7743431921880907, 0.6465792851471065, 0.9958944789959191], Output: [0.09772398725729942]\n",
      "Epoch 13/100, Loss: 0.8078539342625223, Accuracy: -2.5908042779013023\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9912901177213849, 0.9967777946337819, -0.10832254933776769, 0.9997984351977247]\n",
      "Layer: Layer 1, Input: [-0.9912901177213849, 0.9967777946337819, -0.10832254933776769, 0.9997984351977247], Output: [-0.9104204233222775, -0.836094582778674, 0.5683934396407759, 0.9959217103601472]\n",
      "Layer: Layer 2, Input: [-0.9104204233222775, -0.836094582778674, 0.5683934396407759, 0.9959217103601472], Output: [0.10599231338004594]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982887631894324, 0.956959259593206, -0.6454039449974205, 0.9792841185417391]\n",
      "Layer: Layer 1, Input: [-0.9982887631894324, 0.956959259593206, -0.6454039449974205, 0.9792841185417391], Output: [-0.8489392889702081, -0.9256249972416021, 0.10027272760208003, 0.9903447010914767]\n",
      "Layer: Layer 2, Input: [-0.8489392889702081, -0.9256249972416021, 0.10027272760208003, 0.9903447010914767], Output: [-0.08278429449258407]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9646920144672908, 0.6917095117589832, -0.9562650091853557, 0.964270934831274]\n",
      "Layer: Layer 1, Input: [-0.9646920144672908, 0.6917095117589832, -0.9562650091853557, 0.964270934831274], Output: [-0.6914019418403085, -0.9644128358567722, -0.33277071189335133, 0.9744485619302022]\n",
      "Layer: Layer 2, Input: [-0.6914019418403085, -0.9644128358567722, -0.33277071189335133, 0.9744485619302022], Output: [-0.210996965653938]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9156309728422566, 0.9573762718163867, 0.07689228218926794, 0.974864352073923]\n",
      "Layer: Layer 1, Input: [-0.9156309728422566, 0.9573762718163867, 0.07689228218926794, 0.974864352073923], Output: [-0.9088197720263963, -0.775102747309327, 0.6502161699516384, 0.9960820469181029]\n",
      "Layer: Layer 2, Input: [-0.9088197720263963, -0.775102747309327, 0.6502161699516384, 0.9960820469181029], Output: [0.12196668587139203]\n",
      "Epoch 14/100, Loss: 0.7585006707729972, Accuracy: -2.4782597406020397\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9914295788334709, 0.9967981210484406, -0.03550612782089555, 0.9997995732122429]\n",
      "Layer: Layer 1, Input: [-0.9914295788334709, 0.9967981210484406, -0.03550612782089555, 0.9997995732122429], Output: [-0.9189557711662175, -0.8266802620390808, 0.5988275518243542, 0.9963429681479796]\n",
      "Layer: Layer 2, Input: [-0.9189557711662175, -0.8266802620390808, 0.5988275518243542, 0.9963429681479796], Output: [0.13871480483561255]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9982965818441146, 0.9570436816227293, -0.6704341004445216, 0.9794542455733968]\n",
      "Layer: Layer 1, Input: [-0.9982965818441146, 0.9570436816227293, -0.6704341004445216, 0.9794542455733968], Output: [-0.8532889954377854, -0.9312727736066716, 0.03708731608977788, 0.9900619256756559]\n",
      "Layer: Layer 2, Input: [-0.8532889954377854, -0.9312727736066716, 0.03708731608977788, 0.9900619256756559], Output: [-0.11335082321952994]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9647775313710301, 0.6934961564128823, -0.9553329927000566, 0.9644373622357003]\n",
      "Layer: Layer 1, Input: [-0.9647775313710301, 0.6934961564128823, -0.9553329927000566, 0.9644373622357003], Output: [-0.7066303066506289, -0.9656528022122817, -0.3683074246828473, 0.9747292556050916]\n",
      "Layer: Layer 2, Input: [-0.7066303066506289, -0.9656528022122817, -0.3683074246828473, 0.9747292556050916], Output: [-0.248596230969932]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9163746676448536, 0.9574461194743638, 0.10784796289806031, 0.9749285171694617]\n",
      "Layer: Layer 1, Input: [-0.9163746676448536, 0.9574461194743638, 0.10784796289806031, 0.9749285171694617], Output: [-0.9143483209638267, -0.7753334957317932, 0.6549019684093739, 0.9962736120181253]\n",
      "Layer: Layer 2, Input: [-0.9143483209638267, -0.7753334957317932, 0.6549019684093739, 0.9962736120181253], Output: [0.14861449834223966]\n",
      "Epoch 15/100, Loss: 0.7043559616601175, Accuracy: -2.3507236426326856\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9915647448676613, 0.9968124493210776, 0.04047228632572454, 0.9998006585252781]\n",
      "Layer: Layer 1, Input: [-0.9915647448676613, 0.9968124493210776, 0.04047228632572454, 0.9998006585252781], Output: [-0.9265453213721451, -0.8162247876338387, 0.6303187410727514, 0.9967343247540122]\n",
      "Layer: Layer 2, Input: [-0.9265453213721451, -0.8162247876338387, 0.6303187410727514, 0.9967343247540122], Output: [0.17570942091999753]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983042310027788, 0.9570530820136876, -0.6944092193152802, 0.9796223953806494]\n",
      "Layer: Layer 1, Input: [-0.9983042310027788, 0.9570530820136876, -0.6944092193152802, 0.9796223953806494], Output: [-0.8573402315000703, -0.9364308804381286, -0.028653450486755258, 0.9897842815134783]\n",
      "Layer: Layer 2, Input: [-0.8573402315000703, -0.9364308804381286, -0.028653450486755258, 0.9897842815134783], Output: [-0.14931341183968838]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9648608437057782, 0.6948336623859063, -0.9543543836147081, 0.9645962556256398]\n",
      "Layer: Layer 1, Input: [-0.9648608437057782, 0.6948336623859063, -0.9543543836147081, 0.9645962556256398], Output: [-0.720287507836693, -0.9668769895146426, -0.4050636118607179, 0.9749853618916868]\n",
      "Layer: Layer 2, Input: [-0.720287507836693, -0.9668769895146426, -0.4050636118607179, 0.9749853618916868], Output: [-0.288323720438336]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9171017428285766, 0.9574866187019666, 0.14008050647168188, 0.9749906160732493]\n",
      "Layer: Layer 1, Input: [-0.9171017428285766, 0.9574866187019666, 0.14008050647168188, 0.9749906160732493], Output: [-0.9193811009906777, -0.7754054078109037, 0.6601572552606947, 0.9964612927539442]\n",
      "Layer: Layer 2, Input: [-0.9193811009906777, -0.7754054078109037, 0.6601572552606947, 0.9964612927539442], Output: [0.17770788861560738]\n",
      "Epoch 16/100, Loss: 0.6464425183429029, Accuracy: -2.208945558186371\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9916950305040753, 0.9968220199486743, 0.11630660613961812, 0.9998016852379294]\n",
      "Layer: Layer 1, Input: [-0.9916950305040753, 0.9968220199486743, 0.11630660613961812, 0.9998016852379294], Output: [-0.9331220340803662, -0.8054538834006202, 0.6609816757719547, 0.9970821407550255]\n",
      "Layer: Layer 2, Input: [-0.9331220340803662, -0.8054538834006202, 0.6609816757719547, 0.9970821407550255], Output: [0.21629246368294275]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983116918321961, 0.9570027482847638, -0.7167565463540693, 0.9797869363367948]\n",
      "Layer: Layer 1, Input: [-0.9983116918321961, 0.9570027482847638, -0.7167565463540693, 0.9797869363367948], Output: [-0.8611345488595166, -0.9410752446273615, -0.09502981379771162, 0.9895208448025412]\n",
      "Layer: Layer 2, Input: [-0.8611345488595166, -0.9410752446273615, -0.09502981379771162, 0.9895208448025412], Output: [-0.18983089183572266]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9649420558234557, 0.6958080992179255, -0.9533672048057389, 0.9647470309158835]\n",
      "Layer: Layer 1, Input: [-0.9649420558234557, 0.6958080992179255, -0.9533672048057389, 0.9647470309158835], Output: [-0.7324868869079213, -0.9680726585671454, -0.44208482441982977, 0.975218817056977]\n",
      "Layer: Layer 2, Input: [-0.7324868869079213, -0.9680726585671454, -0.44208482441982977, 0.975218817056977], Output: [-0.32972379393562223]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9178083813960132, 0.9575040374565074, 0.17247159045998114, 0.9750501309503838]\n",
      "Layer: Layer 1, Input: [-0.9178083813960132, 0.9575040374565074, 0.17247159045998114, 0.9750501309503838], Output: [-0.9238917650434363, -0.7755999082170564, 0.6657040572306278, 0.996639291330348]\n",
      "Layer: Layer 2, Input: [-0.9238917650434363, -0.7755999082170564, 0.6657040572306278, 0.996639291330348], Output: [0.20923299412416813]\n",
      "Epoch 17/100, Loss: 0.586288534075434, Accuracy: -2.0549198564215443\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9918198918340443, 0.9968279791919964, 0.18926501244742014, 0.9998026467618819]\n",
      "Layer: Layer 1, Input: [-0.9918198918340443, 0.9968279791919964, 0.18926501244742014, 0.9998026467618819], Output: [-0.9387069509873313, -0.7950564438807957, 0.6895609375435702, 0.9973812415948271]\n",
      "Layer: Layer 2, Input: [-0.9387069509873313, -0.7950564438807957, 0.6895609375435702, 0.9973812415948271], Output: [0.2597275527247287]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983189434357352, 0.9569078386879037, -0.7370550769075332, 0.979946084701925]\n",
      "Layer: Layer 1, Input: [-0.9983189434357352, 0.9569078386879037, -0.7370550769075332, 0.979946084701925], Output: [-0.8646922174590534, -0.9452020256691972, -0.15994214247317667, 0.9892790970664678]\n",
      "Layer: Layer 2, Input: [-0.8646922174590534, -0.9452020256691972, -0.15994214247317667, 0.9892790970664678], Output: [-0.23359746423493577]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.965021197831775, 0.6964982304055222, -0.952400373596108, 0.9648890415040686]\n",
      "Layer: Layer 1, Input: [-0.965021197831775, 0.6964982304055222, -0.952400373596108, 0.9648890415040686], Output: [-0.7433341115259028, -0.9692251716567302, -0.4783003569569556, 0.9754313853276352]\n",
      "Layer: Layer 2, Input: [-0.7433341115259028, -0.9692251716567302, -0.4783003569569556, 0.9754313853276352], Output: [-0.37205002054235325]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9184909048110638, 0.9575044350383692, 0.20416172051480772, 0.9751064826314767]\n",
      "Layer: Layer 1, Input: [-0.9184909048110638, 0.9575044350383692, 0.20416172051480772, 0.9751064826314767], Output: [-0.9278849179339335, -0.7760825417957381, 0.6714516338937802, 0.996804141604297]\n",
      "Layer: Layer 2, Input: [-0.9278849179339335, -0.7760825417957381, 0.6714516338937802, 0.996804141604297], Output: [0.24305717013764389]\n",
      "Epoch 18/100, Loss: 0.5256649418507326, Accuracy: -1.8915677923603385\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9919388246891713, 0.9968313307405876, 0.25745479521263304, 0.9998035376020781]\n",
      "Layer: Layer 1, Input: [-0.9919388246891713, 0.9968313307405876, 0.25745479521263304, 0.9998035376020781], Output: [-0.9433847162924274, -0.7855706296323439, 0.7154155168766929, 0.9976328038931354]\n",
      "Layer: Layer 2, Input: [-0.9433847162924274, -0.7855706296323439, 0.7154155168766929, 0.9976328038931354], Output: [0.3052280826920325]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983259603911598, 0.9567823963514227, -0.7550835615491143, 0.9800981722888119]\n",
      "Layer: Layer 1, Input: [-0.9983259603911598, 0.9567823963514227, -0.7550835615491143, 0.9800981722888119], Output: [-0.8680204360913739, -0.9488285935811162, -0.22152757822510438, 0.9890638789164373]\n",
      "Layer: Layer 2, Input: [-0.8680204360913739, -0.9488285935811162, -0.22152757822510438, 0.9890638789164373], Output: [-0.2791377478850573]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9650981644809489, 0.6969729756789683, -0.9514726341368301, 0.9650217436098468]\n",
      "Layer: Layer 1, Input: [-0.9650981644809489, 0.6969729756789683, -0.9514726341368301, 0.9650217436098468], Output: [-0.7529403302727627, -0.970320390197152, -0.5127489582470203, 0.9756248055735148]\n",
      "Layer: Layer 2, Input: [-0.7529403302727627, -0.970320390197152, -0.5127489582470203, 0.9756248055735148], Output: [-0.4144711455025343]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9191458138639804, 0.9574932538004403, 0.23456544050489558, 0.9751591565343251]\n",
      "Layer: Layer 1, Input: [-0.9191458138639804, 0.9574932538004403, 0.23456544050489558, 0.9751591565343251], Output: [-0.9313897271813016, -0.7769110664437775, 0.677413740169082, 0.9969543278729041]\n",
      "Layer: Layer 2, Input: [-0.9313897271813016, -0.7769110664437775, 0.677413740169082, 0.9969543278729041], Output: [0.2788809049890548]\n",
      "Epoch 19/100, Loss: 0.4663017980606339, Accuracy: -1.722282118931321\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.992051383991948, 0.996832896334967, 0.31980067470441836, 0.9998043545704263]\n",
      "Layer: Layer 1, Input: [-0.992051383991948, 0.996832896334967, 0.31980067470441836, 0.9998043545704263], Output: [-0.9472716756286159, -0.777335144673555, 0.7383484774226889, 0.9978415672021298]\n",
      "Layer: Layer 2, Input: [-0.9472716756286159, -0.777335144673555, 0.7383484774226889, 0.9978415672021298], Output: [0.3519551374330737]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983327130149329, 0.9566384313697753, -0.7708196582045496, 0.9802418684265701]\n",
      "Layer: Layer 1, Input: [-0.9983327130149329, 0.9566384313697753, -0.7708196582045496, 0.9802418684265701], Output: [-0.8711198824554651, -0.9519897184830509, -0.27845931560580206, 0.9888770460206538]\n",
      "Layer: Layer 2, Input: [-0.8711198824554651, -0.9519897184830509, -0.27845931560580206, 0.9888770460206538], Output: [-0.3250927904065598]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.965172708213877, 0.6972894360839708, -0.950594698552902, 0.9651448125570139]\n",
      "Layer: Layer 1, Input: [-0.965172708213877, 0.6972894360839708, -0.950594698552902, 0.9651448125570139], Output: [-0.7614235550077771, -0.9713467959364342, -0.5447347463472995, 0.9758007663845186]\n",
      "Layer: Layer 2, Input: [-0.7614235550077771, -0.9713467959364342, -0.5447347463472995, 0.9758007663845186], Output: [-0.45624302717564635]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9197699293295383, 0.9574749827623247, 0.26331914237330684, 0.9752077946659008]\n",
      "Layer: Layer 1, Input: [-0.9197699293295383, 0.9574749827623247, 0.26331914237330684, 0.9752077946659008], Output: [-0.9344497544146095, -0.778067485305969, 0.6836144478644633, 0.9970896480384751]\n",
      "Layer: Layer 2, Input: [-0.9344497544146095, -0.778067485305969, 0.6836144478644633, 0.9970896480384751], Output: [0.3162330761197707]\n",
      "Epoch 20/100, Loss: 0.4096676842870816, Accuracy: -1.5504759688649496\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9921572215167606, 0.9968333054210429, 0.37587921052641304, 0.999805097180459]\n",
      "Layer: Layer 1, Input: [-0.9921572215167606, 0.9968333054210429, 0.37587921052641304, 0.999805097180459], Output: [-0.9504907691567721, -0.7704974669938034, 0.7584286894717186, 0.9980136308663232]\n",
      "Layer: Layer 2, Input: [-0.9504907691567721, -0.7704974669938034, 0.7584286894717186, 0.9980136308663232], Output: [0.39905385742862176]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983391705221907, 0.956485440971086, -0.7843935526147168, 0.9803762940417845]\n",
      "Layer: Layer 1, Input: [-0.9983391705221907, 0.956485440971086, -0.7843935526147168, 0.9803762940417845], Output: [-0.8739899719406783, -0.9547308122807177, -0.3300299312134017, 0.9887179192348153]\n",
      "Layer: Layer 2, Input: [-0.8739899719406783, -0.9547308122807177, -0.3300299312134017, 0.9887179192348153], Output: [-0.3703874390082792]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9652444891371152, 0.697492530725375, -0.9497720208121364, 0.9652581862864805]\n",
      "Layer: Layer 1, Input: [-0.9652444891371152, 0.697492530725375, -0.9497720208121364, 0.9652581862864805], Output: [-0.7689038598978677, -0.9722967078488801, -0.5738723124091186, 0.9759608442392497]\n",
      "Layer: Layer 2, Input: [-0.7689038598978677, -0.9722967078488801, -0.5738723124091186, 0.9759608442392497], Output: [-0.49679576686385296]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9203606180150293, 0.9574530260147197, 0.2902175866580778, 0.9752522318577467]\n",
      "Layer: Layer 1, Input: [-0.9203606180150293, 0.9574530260147197, 0.2902175866580778, 0.9752522318577467], Output: [-0.937114122084645, -0.7794928461832376, 0.6900341585239194, 0.9972106633788683]\n",
      "Layer: Layer 2, Input: [-0.937114122084645, -0.7794928461832376, 0.6900341585239194, 0.9972106633788683], Output: [0.35451815604628917]\n",
      "Epoch 21/100, Loss: 0.3568523885874983, Accuracy: -1.3792447806529573\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9922561226985931, 0.9968330125476419, 0.42572629827531905, 0.999805767361503]\n",
      "Layer: Layer 1, Input: [-0.9922561226985931, 0.9968330125476419, 0.42572629827531905, 0.999805767361503], Output: [-0.9531568394355768, -0.7650534097298132, 0.7758649222255327, 0.9981551346769075]\n",
      "Layer: Layer 2, Input: [-0.9531568394355768, -0.7650534097298132, 0.7758649222255327, 0.9981551346769075], Output: [0.4457182343443562]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983453053702706, 0.9563304207900387, -0.7960241638469793, 0.9805010240811366]\n",
      "Layer: Layer 1, Input: [-0.9983453053702706, 0.9563304207900387, -0.7960241638469793, 0.9805010240811366], Output: [-0.8766322857982138, -0.9571012217023203, -0.37606156529474943, 0.9885841550913379]\n",
      "Layer: Layer 2, Input: [-0.8766322857982138, -0.9571012217023203, -0.37606156529474943, 0.9885841550913379], Output: [-0.4142662656805782]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9653131507807778, 0.6976161323577291, -0.9490067994752751, 0.9653620460159232]\n",
      "Layer: Layer 1, Input: [-0.9653131507807778, 0.6976161323577291, -0.9490067994752751, 0.9653620460159232], Output: [-0.7754974157420256, -0.9731665018520534, -0.6000456279826314, 0.9761064718278591]\n",
      "Layer: Layer 2, Input: [-0.7754974157420256, -0.9731665018520534, -0.6000456279826314, 0.9761064718278591], Output: [-0.5357427986866399]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9209160082102616, 0.9574297701313002, 0.31516603544729554, 0.9752924823820879]\n",
      "Layer: Layer 1, Input: [-0.9209160082102616, 0.9574297701313002, 0.31516603544729554, 0.9752924823820879], Output: [-0.9394317534871983, -0.7811132092090864, 0.6966028112158266, 0.9973183359276551]\n",
      "Layer: Layer 2, Input: [-0.9394317534871983, -0.7811132092090864, 0.6966028112158266, 0.9973183359276551], Output: [0.39309330915604596]\n",
      "Epoch 22/100, Loss: 0.3085456909051464, Accuracy: -1.2111793921323795\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9923480252887786, 0.9968323298602944, 0.46966879860263117, 0.9998063688243145]\n",
      "Layer: Layer 1, Input: [-0.9923480252887786, 0.9968323298602944, 0.46966879860263117, 0.9998063688243145], Output: [-0.9553701117354697, -0.7608965723093805, 0.7909288001574647, 0.99827162219264]\n",
      "Layer: Layer 2, Input: [-0.9553701117354697, -0.7608965723093805, 0.7909288001574647, 0.99827162219264], Output: [0.49125123170325513]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983510968456657, 0.9561782008932427, -0.8059637111473482, 0.9806160170016538]\n",
      "Layer: Layer 1, Input: [-0.9983510968456657, 0.9561782008932427, -0.8059637111473482, 0.9806160170016538], Output: [-0.8790520040936315, -0.9591493614480515, -0.41674409198727413, 0.9884726062909827]\n",
      "Layer: Layer 2, Input: [-0.8790520040936315, -0.9591493614480515, -0.41674409198727413, 0.9884726062909827], Output: [-0.45624892312796317]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9653783870418067, 0.6976849989383238, -0.9482991500968043, 0.9654567623152701]\n",
      "Layer: Layer 1, Input: [-0.9653783870418067, 0.6976849989383238, -0.9482991500968043, 0.9654567623152701], Output: [-0.7813120284153363, -0.9739561134460626, -0.6233302456776417, 0.9762389383238405]\n",
      "Layer: Layer 2, Input: [-0.7813120284153363, -0.9739561134460626, -0.6233302456776417, 0.9762389383238405], Output: [-0.5728481708957733]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9214351068596658, 0.9574067661791249, 0.33814829849484024, 0.9753286989117966]\n",
      "Layer: Layer 1, Input: [-0.9214351068596658, 0.9574067661791249, 0.33814829849484024, 0.9753286989117966], Output: [-0.9414482700413622, -0.7828554151941081, 0.7032190998181899, 0.9974138123617013]\n",
      "Layer: Layer 2, Input: [-0.9414482700413622, -0.7828554151941081, 0.7032190998181899, 0.9974138123617013], Output: [0.43134347491913816]\n",
      "Epoch 23/100, Loss: 0.2650798678667705, Accuracy: -1.0483081993538703\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9924330152556337, 0.9968314623741172, 0.5081944195725205, 0.9998069063729124]\n",
      "Layer: Layer 1, Input: [-0.9924330152556337, 0.9968314623741172, 0.5081944195725205, 0.9998069063729124], Output: [-0.9572146244047872, -0.7578641511767735, 0.8039093229455373, 0.9983678159385339]\n",
      "Layer: Layer 2, Input: [-0.9572146244047872, -0.7578641511767735, 0.8039093229455373, 0.9983678159385339], Output: [0.5350996305177114]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983565329197975, 0.9560319042701494, -0.8144610128689082, 0.9807215167691249]\n",
      "Layer: Layer 1, Input: [-0.9983565329197975, 0.9560319042701494, -0.8144610128689082, 0.9807215167691249], Output: [-0.881257858320883, -0.9609199291812339, -0.4524791031562321, 0.9883799491885454]\n",
      "Layer: Layer 2, Input: [-0.881257858320883, -0.9609199291812339, -0.4524791031562321, 0.9883799491885454], Output: [-0.49605970421831747]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.965439982620443, 0.6977168361969505, -0.9476477939845457, 0.9655428329976287]\n",
      "Layer: Layer 1, Input: [-0.965439982620443, 0.6977168361969505, -0.9476477939845457, 0.9655428329976287], Output: [-0.786444794424664, -0.9746681958259593, -0.6439165192811163, 0.9763594043077374]\n",
      "Layer: Layer 2, Input: [-0.786444794424664, -0.9746681958259593, -0.6439165192811163, 0.9763594043077374], Output: [-0.6079841736408178]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9219177926536816, 0.9573849410736827, 0.35920428728741105, 0.9753611249484413]\n",
      "Layer: Layer 1, Input: [-0.9219177926536816, 0.9573849410736827, 0.35920428728741105, 0.9753611249484413], Output: [-0.9432046333127095, -0.7846551629728399, 0.7097742987600039, 0.9974982959197382]\n",
      "Layer: Layer 2, Input: [-0.9432046333127095, -0.7846551629728399, 0.7097742987600039, 0.9974982959197382], Output: [0.4687342329385692]\n",
      "Epoch 24/100, Loss: 0.2265019746561853, Accuracy: -0.8921222586845841\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9925113053595244, 0.9968305389079164, 0.5418596502844483, 0.9998073853265603]\n",
      "Layer: Layer 1, Input: [-0.9925113053595244, 0.9968305389079164, 0.5418596502844483, 0.9998073853265603], Output: [-0.9587591875535044, -0.7557724459979408, 0.8150866719109242, 0.9984476073334482]\n",
      "Layer: Layer 2, Input: [-0.9587591875535044, -0.7557724459979408, 0.8150866719109242, 0.9984476073334482], Output: [0.5768616851055788]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983616104041919, 0.9558933914127952, -0.821742208167364, 0.9808179582771348]\n",
      "Layer: Layer 1, Input: [-0.9983616104041919, 0.9558933914127952, -0.821742208167364, 0.9808179582771348], Output: [-0.883261332170582, -0.9624526900994991, -0.4837629230347589, 0.9883030517120611]\n",
      "Layer: Layer 2, Input: [-0.883261332170582, -0.9624526900994991, -0.4837629230347589, 0.9883030517120611], Output: [-0.5335629400619941]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9654978263111826, 0.6977241144122022, -0.9470505123269922, 0.9656208283199891]\n",
      "Layer: Layer 1, Input: [-0.9654978263111826, 0.6977241144122022, -0.9470505123269922, 0.9656208283199891], Output: [-0.7909814681354861, -0.9753072266265452, -0.6620505461687597, 0.9764689192065742]\n",
      "Layer: Layer 2, Input: [-0.7909814681354861, -0.9753072266265452, -0.6620505461687597, 0.9764689192065742], Output: [-0.6410956496838627]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9223647111546556, 0.9573647870406555, 0.3784128888582319, 0.9753900532964921]\n",
      "Layer: Layer 1, Input: [-0.9223647111546556, 0.9573647870406555, 0.3784128888582319, 0.9753900532964921], Output: [-0.9447367967618063, -0.7864601299899747, 0.7161699170175005, 0.9975729696669917]\n",
      "Layer: Layer 2, Input: [-0.9447367967618063, -0.7864601299899747, 0.7161699170175005, 0.9975729696669917], Output: [0.5048381099798104]\n",
      "Epoch 25/100, Loss: 0.19265179860487908, Accuracy: -0.7436416151687539\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9925832051113122, 0.996829636260756, 0.5712298418447225, 0.9998078111027089]\n",
      "Layer: Layer 1, Input: [-0.9925832051113122, 0.996829636260756, 0.5712298418447225, 0.9998078111027089], Output: [-0.9600593851187246, -0.754440601358388, 0.8247182419319299, 0.9985141424264095]\n",
      "Layer: Layer 2, Input: [-0.9600593851187246, -0.754440601358388, 0.8247182419319299, 0.9985141424264095], Output: [0.6162754328295762]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983663339385249, 0.9557636303913947, -0.8280034378811447, 0.980905890107077]\n",
      "Layer: Layer 1, Input: [-0.9983663339385249, 0.9557636303913947, -0.8280034378811447, 0.980905890107077], Output: [-0.8850756643017795, -0.9637822248516642, -0.5111116001508355, 0.988239144451741]\n",
      "Layer: Layer 2, Input: [-0.8850756643017795, -0.9637822248516642, -0.5111116001508355, 0.988239144451741], Output: [-0.5687147063874748]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9655519049582, 0.6977155144956909, -0.9465044755032521, 0.9656913490441522]\n",
      "Layer: Layer 1, Input: [-0.9655519049582, 0.6977155144956909, -0.9465044755032521, 0.9656913490441522], Output: [-0.794996898170666, -0.9758787308034157, -0.6779950656868405, 0.9765684365430948]\n",
      "Layer: Layer 2, Input: [-0.794996898170666, -0.9758787308034157, -0.6779950656868405, 0.9765684365430948], Output: [-0.6721750403077175]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9227771170122129, 0.9573465101939133, 0.3958784371708507, 0.9754157951016131]\n",
      "Layer: Layer 1, Input: [-0.9227771170122129, 0.9573465101939133, 0.3958784371708507, 0.9754157951016131], Output: [-0.9460758898596132, -0.7882302128077963, 0.7223269955483428, 0.997638951679833]\n",
      "Layer: Layer 2, Input: [-0.9460758898596132, -0.7882302128077963, 0.7223269955483428, 0.997638951679833], Output: [0.5393394988784845]\n",
      "Epoch 26/100, Loss: 0.1632322123568359, Accuracy: -0.6034953215967469\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9926490895124865, 0.9968287968512118, 0.5968436499855493, 0.9998081889490488]\n",
      "Layer: Layer 1, Input: [-0.9926490895124865, 0.9968287968512118, 0.5968436499855493, 0.9998081889490488], Output: [-0.9611598137898653, -0.7537041891216923, 0.8330325076504109, 0.9985699388059099]\n",
      "Layer: Layer 2, Input: [-0.9611598137898653, -0.7537041891216923, 0.8330325076504109, 0.9985699388059099], Output: [0.6531969733843598]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983707144069592, 0.955642980448024, -0.8334103089536969, 0.9809859173528847]\n",
      "Layer: Layer 1, Input: [-0.9983707144069592, 0.955642980448024, -0.8334103089536969, 0.9809859173528847], Output: [-0.8867149476358046, -0.9649381887157837, -0.5350186158037692, 0.9881858698512902]\n",
      "Layer: Layer 2, Input: [-0.8867149476358046, -0.9649381887157837, -0.5350186158037692, 0.9881858698512902], Output: [-0.6015302473670379]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9656022870943441, 0.6976970163461683, -0.9460064897935, 0.965754997185626]\n",
      "Layer: Layer 1, Input: [-0.9656022870943441, 0.6976970163461683, -0.9460064897935, 0.965754997185626], Output: [-0.7985560008435751, -0.9763886832694963, -0.692006411323937, 0.9766588261325738]\n",
      "Layer: Layer 2, Input: [-0.7985560008435751, -0.9763886832694963, -0.692006411323937, 0.9766588261325738], Output: [-0.7012465217723389]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9231567033272773, 0.9573301380197432, 0.411720115584629, 0.975438659223504]\n",
      "Layer: Layer 1, Input: [-0.9231567033272773, 0.9573301380197432, 0.411720115584629, 0.975438659223504], Output: [-0.9472486491834838, -0.7899363037753455, 0.7281887854051068, 0.9976972711022306]\n",
      "Layer: Layer 2, Input: [-0.9472486491834838, -0.7899363037753455, 0.7281887854051068, 0.9976972711022306], Output: [0.5720260520121133]\n",
      "Epoch 27/100, Loss: 0.13786645598565161, Accuracy: -0.4720002054641501\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9927093711509046, 0.9968280410410797, 0.6191944332960453, 0.9998085237902808]\n",
      "Layer: Layer 1, Input: [-0.9927093711509046, 0.9968280410410797, 0.6191944332960453, 0.9998085237902808], Output: [-0.9620961744152269, -0.7534213602667054, 0.8402277149221816, 0.9986170020827455]\n",
      "Layer: Layer 2, Input: [-0.9620961744152269, -0.7534213602667054, 0.8402277149221816, 0.9986170020827455], Output: [0.6875757962670167]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983747672322929, 0.955531399115938, -0.8381005829524961, 0.9810586620401802]\n",
      "Layer: Layer 1, Input: [-0.9983747672322929, 0.955531399115938, -0.8381005829524961, 0.9810586620401802], Output: [-0.8881934309980988, -0.9659458015707055, -0.5559343729411798, 0.988141266756162]\n",
      "Layer: Layer 2, Input: [-0.8881934309980988, -0.9659458015707055, -0.5559343729411798, 0.988141266756162], Output: [-0.6320630247208956]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9656491031618741, 0.697672693193702, -0.9455531815494398, 0.9658123570438785]\n",
      "Layer: Layer 1, Input: [-0.9656491031618741, 0.697672693193702, -0.9455531815494398, 0.9658123570438785], Output: [-0.8017149245449711, -0.9768430913679224, -0.7043224954449775, 0.9767408836398641]\n",
      "Layer: Layer 2, Input: [-0.8017149245449711, -0.9768430913679224, -0.7043224954449775, 0.9767408836398641], Output: [-0.7283562394629808]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9235054443503787, 0.9573155930846523, 0.4260638926276459, 0.9754589398247986]\n",
      "Layer: Layer 1, Input: [-0.9235054443503787, 0.9573155930846523, 0.4260638926276459, 0.9754589398247986], Output: [-0.9482779360361169, -0.7915584919491206, 0.7337193812948859, 0.9977488579373911]\n",
      "Layer: Layer 2, Input: [-0.9482779360361169, -0.7915584919491206, 0.7337193812948859, 0.9977488579373911], Output: [0.6027733972416444]\n",
      "Epoch 28/100, Loss: 0.11614145185834072, Accuracy: -0.34923154230746256\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9927644776771867, 0.996827375497953, 0.6387226416762168, 0.9998088201540621]\n",
      "Layer: Layer 1, Input: [-0.9927644776771867, 0.996827375497953, 0.6387226416762168, 0.9998088201540621], Output: [-0.9628970689522091, -0.7534742130448453, 0.8464733129246852, 0.9986569287981258]\n",
      "Layer: Layer 2, Input: [-0.9628970689522091, -0.7534742130448453, 0.8464733129246852, 0.9986569287981258], Output: [0.7194313862264466]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983785108140626, 0.9554285890743575, -0.8421880216941887, 0.9811247371772239]\n",
      "Layer: Layer 1, Input: [-0.9983785108140626, 0.9554285890743575, -0.8421880216941887, 0.9811247371772239], Output: [-0.8895250292062107, -0.9668264113674128, -0.5742587741867171, 0.9881037263652092]\n",
      "Layer: Layer 2, Input: [-0.8895250292062107, -0.9668264113674128, -0.5742587741867171, 0.9881037263652092], Output: [-0.6603913504252432]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9656925264891499, 0.6976452818322015, -0.9451411323751546, 0.9658639837752327]\n",
      "Layer: Layer 1, Input: [-0.9656925264891499, 0.6976452818322015, -0.9451411323751546, 0.9658639837752327], Output: [-0.8045222129129606, -0.9772477279333792, -0.7151576723360312, 0.9768153381351375]\n",
      "Layer: Layer 2, Input: [-0.8045222129129606, -0.9772477279333792, -0.7151576723360312, 0.9768153381351375], Output: [-0.7535661277286851]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9238254643603004, 0.9573027416231532, 0.4390366193419156, 0.9754769097839271]\n",
      "Layer: Layer 1, Input: [-0.9238254643603004, 0.9573027416231532, 0.4390366193419156, 0.9754769097839271], Output: [-0.9491832565825566, -0.7930841902571689, 0.7389004289497292, 0.99779454164654]\n",
      "Layer: Layer 2, Input: [-0.9491832565825566, -0.7930841902571689, 0.7389004289497292, 0.99779454164654], Output: [0.631527890308747]\n",
      "Epoch 29/100, Loss: 0.0976385327309402, Accuracy: -0.235083245310878\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9928148349835547, 0.996826798746634, 0.6558148620280402, 0.9998090821475054]\n",
      "Layer: Layer 1, Input: [-0.9928148349835547, 0.996826798746634, 0.6558148620280402, 0.9998090821475054], Output: [-0.9635854764549603, -0.7537674430275259, 0.8519127451244892, 0.9986909920410431]\n",
      "Layer: Layer 2, Input: [-0.9635854764549603, -0.7537674430275259, 0.8519127451244892, 0.9986909920410431], Output: [0.7488331039447701]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983819652308137, 0.9553341001817549, -0.8457663338554252, 0.9811847306750225]\n",
      "Layer: Layer 1, Input: [-0.9983819652308137, 0.9553341001817549, -0.8457663338554252, 0.9811847306750225], Output: [-0.8907230079909924, -0.9675980494818157, -0.5903410201111272, 0.9880719396222951]\n",
      "Layer: Layer 2, Input: [-0.8907230079909924, -0.9675980494818157, -0.5903410201111272, 0.9880719396222951], Output: [-0.686609661184533]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9657327570287835, 0.6976165882643658, -0.9447669759984731, 0.9659103971870849]\n",
      "Layer: Layer 1, Input: [-0.9657327570287835, 0.6976165882643658, -0.9447669759984731, 0.9659103971870849], Output: [-0.8070198754197485, -0.977607977887478, -0.7247015788460615, 0.9768828582083886]\n",
      "Layer: Layer 2, Input: [-0.8070198754197485, -0.977607977887478, -0.7247015788460615, 0.9768828582083886], Output: [-0.7769496805472439]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9241189361655049, 0.9572914244896492, 0.45076190974601327, 0.9754928179265132]\n",
      "Layer: Layer 1, Input: [-0.9241189361655049, 0.9572914244896492, 0.45076190974601327, 0.9754928179265132], Output: [-0.9499812446779523, -0.7945064351591157, 0.7437272851001678, 0.9978350551180212]\n",
      "Layer: Layer 2, Input: [-0.9499812446779523, -0.7945064351591157, 0.7437272851001678, 0.9978350551180212], Output: [0.6582901429908791]\n",
      "Epoch 30/100, Loss: 0.08195384638051556, Accuracy: -0.1293174113325739\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9928608554971997, 0.9968263047828568, 0.6708065875787377, 0.9998093134637932]\n",
      "Layer: Layer 1, Input: [-0.9928608554971997, 0.9968263047828568, 0.6708065875787377, 0.9998093134637932], Output: [-0.964179934949398, -0.7542256889806216, 0.8566667404369762, 0.9987202103738041]\n",
      "Layer: Layer 2, Input: [-0.964179934949398, -0.7542256889806216, 0.8566667404369762, 0.9987202103738041], Output: [0.7758839269909809]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983851512335838, 0.9552473991875828, -0.848912755791021, 0.9812391961194344]\n",
      "Layer: Layer 1, Input: [-0.9983851512335838, 0.9552473991875828, -0.848912755791021, 0.9812391961194344], Output: [-0.8917998013703914, -0.9682759395920311, -0.6044830137598581, 0.988044846002042]\n",
      "Layer: Layer 2, Input: [-0.8917998013703914, -0.9682759395920311, -0.6044830137598581, 0.988044846002042], Output: [-0.7108225756994474]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9657700084744474, 0.6975877746623514, -0.9444274653914815, 0.9659520790102585]\n",
      "Layer: Layer 1, Input: [-0.9657700084744474, 0.6975877746623514, -0.9444274653914815, 0.9659520790102585], Output: [-0.8092443316996082, -0.9779287642461552, -0.7331201040797379, 0.9769440570710678]\n",
      "Layer: Layer 2, Input: [-0.8092443316996082, -0.9779287642461552, -0.7331201040797379, 0.9769440570710678], Output: [-0.7985887617218331]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9243880072958259, 0.9572814761739351, 0.461357437976435, 0.9755068886041073]\n",
      "Layer: Layer 1, Input: [-0.9243880072958259, 0.9572814761739351, 0.461357437976435, 0.9755068886041073], Output: [-0.9506860916567113, -0.7958224525027584, 0.7482053842581209, 0.9978710416466126]\n",
      "Layer: Layer 2, Input: [-0.9506860916567113, -0.7958224525027584, 0.7482053842581209, 0.9978710416466126], Output: [0.683100642127873]\n",
      "Epoch 31/100, Loss: 0.0687108217076492, Accuracy: -0.03160409345986559\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9929029306419104, 0.996825885376465, 0.683986828484066, 0.9998095174053337]\n",
      "Layer: Layer 1, Input: [-0.9929029306419104, 0.996825885376465, 0.683986828484066, 0.9998095174053337], Output: [-0.9646954743699983, -0.7547904494972896, 0.8608366109060881, 0.9987454023064196]\n",
      "Layer: Layer 2, Input: [-0.9646954743699983, -0.7547904494972896, 0.8608366109060881, 0.9987454023064196], Output: [0.8007078769798993]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983880895079623, 0.9551679165406657, -0.8516911102529265, 0.9812886481604146]\n",
      "Layer: Layer 1, Input: [-0.9983880895079623, 0.9551679165406657, -0.8516911102529265, 0.9812886481604146], Output: [-0.8927669231850696, -0.9688729454143412, -0.6169442840947622, 0.988021587931108]\n",
      "Layer: Layer 2, Input: [-0.8927669231850696, -0.9688729454143412, -0.6169442840947622, 0.988021587931108], Output: [-0.733140650440598]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9658044986220319, 0.6975595615062471, -0.9441195169676044, 0.9659894724174227]\n",
      "Layer: Layer 1, Input: [-0.9658044986220319, 0.6975595615062471, -0.9441195169676044, 0.9659894724174227], Output: [-0.8112272256033131, -0.978214526261936, -0.7405573778013628, 0.9769994969530007]\n",
      "Layer: Layer 2, Input: [-0.8112272256033131, -0.978214526261936, -0.7405573778013628, 0.9769994969530007], Output: [-0.8185710067873733]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.924634749540001, 0.957272735946387, 0.4709333193095531, 0.9755193226213069]\n",
      "Layer: Layer 1, Input: [-0.924634749540001, 0.957272735946387, 0.4709333193095531, 0.9755193226213069], Output: [-0.9513099197628277, -0.7970325017573695, 0.7523471454885723, 0.9979030633447242]\n",
      "Layer: Layer 2, Input: [-0.9513099197628277, -0.7970325017573695, 0.7523471454885723, 0.9979030633447242], Output: [0.7060278876942886]\n",
      "Epoch 32/100, Loss: 0.05756683628418881, Accuracy: 0.058447421902159125\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9929414264815232, 0.9968255315006737, 0.6956034134619533, 0.9998096969148996]\n",
      "Layer: Layer 1, Input: [-0.9929414264815232, 0.9968255315006737, 0.6956034134619533, 0.9998096969148996], Output: [-0.9651443475071024, -0.7554170604405324, 0.8645073004969414, 0.998767228922788]\n",
      "Layer: Layer 2, Input: [-0.9651443475071024, -0.7554170604405324, 0.8645073004969414, 0.998767228922788], Output: [0.8234406251667971]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983908001613168, 0.9550950771488596, -0.854154335325273, 0.9813335609316647]\n",
      "Layer: Layer 1, Input: [-0.9983908001613168, 0.9550950771488596, -0.854154335325273, 0.9813335609316647], Output: [-0.8936349423954039, -0.9693999550713392, -0.6279472893605961, 0.9880014721048491]\n",
      "Layer: Layer 2, Input: [-0.8936349423954039, -0.9693999550713392, -0.6279472893605961, 0.9880014721048491], Output: [-0.753677227980073]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9658364425095323, 0.6975323693860958, -0.9438402373145885, 0.9660229829445354]\n",
      "Layer: Layer 1, Input: [-0.9658364425095323, 0.6975323693860958, -0.9438402373145885, 0.9660229829445354], Output: [-0.8129961184686954, -0.9784692296520737, -0.7471381413843013, 0.977049693006246]\n",
      "Layer: Layer 2, Input: [-0.8129961184686954, -0.9784692296520737, -0.7471381413843013, 0.977049693006246], Output: [-0.8369876222144097]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9248611268850785, 0.9572650539270127, 0.4795912894959153, 0.9755302988676186]\n",
      "Layer: Layer 1, Input: [-0.9248611268850785, 0.9572650539270127, 0.4795912894959153, 0.9755302988676186], Output: [-0.9518631018689576, -0.7981389728672206, 0.7561695067422286, 0.9979316099672231]\n",
      "Layer: Layer 2, Input: [-0.9518631018689576, -0.7981389728672206, 0.7561695067422286, 0.9979316099672231], Output: [0.727158991151965]\n",
      "Epoch 33/100, Loss: 0.04821584306939948, Accuracy: 0.14126446651324476\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9929766816711054, 0.9968252341859959, 0.70586831723446, 0.9998098546095816]\n",
      "Layer: Layer 1, Input: [-0.9929766816711054, 0.9968252341859959, 0.70586831723446, 0.9998098546095816], Output: [-0.9655366009071027, -0.7560719736026502, 0.8677500755953559, 0.9987862270782468]\n",
      "Layer: Layer 2, Input: [-0.9655366009071027, -0.7560719736026502, 0.8677500755953559, 0.9987862270782468], Output: [0.8442226777066725]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983933023875687, 0.9550283199927024, -0.8563465380598931, 0.9813743684015644]\n",
      "Layer: Layer 1, Input: [-0.9983933023875687, 0.9550283199927024, -0.8563465380598931, 0.9813743684015644], Output: [-0.8944134995926762, -0.9698662059789435, -0.6376825199251377, 0.9879839375361467]\n",
      "Layer: Layer 2, Input: [-0.8944134995926762, -0.9698662059789435, -0.6376825199251377, 0.9879839375361467], Output: [-0.7725460418525858]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9658660477796064, 0.6975064180189967, -0.9435869368453906, 0.9660529802490065]\n",
      "Layer: Layer 1, Input: [-0.9658660477796064, 0.6975064180189967, -0.9435869368453906, 0.9660529802490065], Output: [-0.8145750760503294, -0.9786963950184637, -0.7529701545129615, 0.9770951168546752]\n",
      "Layer: Layer 2, Input: [-0.8145750760503294, -0.9786963950184637, -0.7529701545129615, 0.9770951168546752], Output: [-0.8539315073693319]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9250689772562761, 0.9572582939539689, 0.48742444900856763, 0.9755399762563276]\n",
      "Layer: Layer 1, Input: [-0.9250689772562761, 0.9572582939539689, 0.48742444900856763, 0.9755399762563276], Output: [-0.9523545326913174, -0.7991456962900126, 0.7596920496494138, 0.9979571075250689]\n",
      "Layer: Layer 2, Input: [-0.9523545326913174, -0.7991456962900126, 0.7596920496494138, 0.9979571075250689], Output: [0.7465924474965522]\n",
      "Epoch 34/100, Loss: 0.04038831735574702, Accuracy: 0.21729267442514233\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9930090070070537, 0.9968249850006691, 0.7149626577224579, 0.9998099928145817]\n",
      "Layer: Layer 1, Input: [-0.9930090070070537, 0.9968249850006691, 0.7149626577224579, 0.9998099928145817], Output: [-0.9658805206455767, -0.7567304273031403, 0.870624831506075, 0.9988028352186008]\n",
      "Layer: Layer 2, Input: [-0.9658805206455767, -0.7567304273031403, 0.870624831506075, 0.9988028352186008], Output: [0.8631945724656824]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983956142658892, 0.954967110067104, -0.8583046464161266, 0.9814114659063345]\n",
      "Layer: Layer 1, Input: [-0.9983956142658892, 0.954967110067104, -0.8583046464161266, 0.9814114659063345], Output: [-0.8951113486992016, -0.9702795567583425, -0.6463131362947345, 0.9879685295836376]\n",
      "Layer: Layer 2, Input: [-0.8951113486992016, -0.9702795567583425, -0.6463131362947345, 0.9879685295836376], Output: [-0.7898593850347142]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9658935117386604, 0.6974817950123157, -0.9433571338768403, 0.9660798003288856]\n",
      "Layer: Layer 1, Input: [-0.9658935117386604, 0.6974817950123157, -0.9433571338768403, 0.9660798003288856], Output: [-0.8159851643245334, -0.9788991352783319, -0.7581464614390743, 0.9771361998758571]\n",
      "Layer: Layer 2, Input: [-0.8159851643245334, -0.9788991352783319, -0.7581464614390743, 0.9771361998758571], Output: [-0.8694956714548103]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9252600041873744, 0.9572523344897916, 0.4945173893352382, 0.9755484957344829]\n",
      "Layer: Layer 1, Input: [-0.9252600041873744, 0.9572523344897916, 0.4945173893352382, 0.9755484957344829], Output: [-0.9527918575195448, -0.800057425355976, 0.7629356261859264, 0.9979799263326613]\n",
      "Layer: Layer 2, Input: [-0.9527918575195448, -0.800057425355976, 0.7629356261859264, 0.9979799263326613], Output: [0.7644327181507878]\n",
      "Epoch 35/100, Loss: 0.03384953177692322, Accuracy: 0.2869823471059948\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9930386860334252, 0.9968247762928065, 0.7230411970172144, 0.9998101135952342]\n",
      "Layer: Layer 1, Input: [-0.9930386860334252, 0.9968247762928065, 0.7230411970172144, 0.9998101135952342], Output: [-0.9661829809690834, -0.7573745168986883, 0.8731820333267306, 0.9988174134775026]\n",
      "Layer: Layer 2, Input: [-0.9661829809690834, -0.7573745168986883, 0.8731820333267306, 0.9988174134775026], Output: [0.8804936001817619]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983977526568245, 0.9549109450982565, -0.8600597325005215, 0.9814452123616724]\n",
      "Layer: Layer 1, Input: [-0.9983977526568245, 0.9549109450982565, -0.8600597325005215, 0.9814452123616724], Output: [-0.895736412816946, -0.9706467134203807, -0.6539790502795111, 0.9879548790364796]\n",
      "Layer: Layer 2, Input: [-0.895736412816946, -0.9706467134203807, -0.6539790502795111, 0.9879548790364796], Output: [-0.8057267219259844]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9659190196652895, 0.6974585032987128, -0.9431485519194873, 0.9661037479567526]\n",
      "Layer: Layer 1, Input: [-0.9659190196652895, 0.6974585032987128, -0.9431485519194873, 0.9661037479567526], Output: [-0.8172448683167897, -0.9790801963063499, -0.7627474382786681, 0.9771733362664247]\n",
      "Layer: Layer 2, Input: [-0.8172448683167897, -0.9790801963063499, -0.7627474382786681, 0.9771733362664247], Output: [-0.8837719295704743]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9254357753640063, 0.9572470683713595, 0.5009465633085897, 0.9755559822309985]\n",
      "Layer: Layer 1, Input: [-0.9254357753640063, 0.9572470683713595, 0.5009465633085897, 0.9755559822309985], Output: [-0.953181664427465, -0.8008794540871318, 0.7659213868689546, 0.9980003883132071]\n",
      "Layer: Layer 2, Input: [-0.953181664427465, -0.8008794540871318, 0.7659213868689546, 0.9980003883132071], Output: [0.7807862655989481]\n",
      "Epoch 36/100, Loss: 0.028396877969241514, Accuracy: 0.3507785172771688\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9930659763060629, 0.9968246012841129, 0.7302362923478296, 0.9998102187864775]\n",
      "Layer: Layer 1, Input: [-0.9930659763060629, 0.9968246012841129, 0.7302362923478296, 0.9998102187864775], Output: [-0.9664497177743543, -0.7579916321749173, 0.8754643297900906, 0.9988302593566157]\n",
      "Layer: Layer 2, Input: [-0.9664497177743543, -0.7579916321749173, 0.8754643297900906, 0.9988302593566157], Output: [0.8962516557533631]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9983997331670227, 0.9548593587511538, -0.8616380716376432, 0.9814759328186963]\n",
      "Layer: Layer 1, Input: [-0.9983997331670227, 0.9548593587511538, -0.8616380716376432, 0.9814759328186963], Output: [-0.8962958468216405, -0.9709734168511404, -0.6608004467139511, 0.9879426853577514]\n",
      "Layer: Layer 2, Input: [-0.8962958468216405, -0.9709734168511404, -0.6608004467139511, 0.9879426853577514], Output: [-0.8202536602362576]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9659427440109439, 0.6974364935876003, -0.9429591123501644, 0.966125099169276]\n",
      "Layer: Layer 1, Input: [-0.9659427440109439, 0.6974364935876003, -0.9429591123501644, 0.966125099169276], Output: [-0.8183704463657645, -0.9792419973064977, -0.7668425969825715, 0.9772068859194875]\n",
      "Layer: Layer 2, Input: [-0.8183704463657645, -0.9792419973064977, -0.7668425969825715, 0.9772068859194875], Output: [-0.896849860232974]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9255977257265479, 0.9572424019206566, 0.5067807988638077, 0.975562546473574]\n",
      "Layer: Layer 1, Input: [-0.9255977257265479, 0.9572424019206566, 0.5067807988638077, 0.975562546473574], Output: [-0.9535296454749351, -0.801617339466775, 0.7686701174071928, 0.9980187735013305]\n",
      "Layer: Layer 2, Input: [-0.9535296454749351, -0.801617339466775, 0.7686701174071928, 0.9980187735013305], Output: [0.7957587209488635]\n",
      "Epoch 37/100, Loss: 0.02385672924869566, Accuracy: 0.4091138971714581\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993091111031788, 0.9968244540742798, 0.7366613059674672, 0.999810310019488]\n",
      "Layer: Layer 1, Input: [-0.993091111031788, 0.9968244540742798, 0.7366613059674672, 0.999810310019488], Output: [-0.9666855439549596, -0.7585732120344184, 0.8775078852794512, 0.9988416200003669]\n",
      "Layer: Layer 2, Input: [-0.9666855439549596, -0.7585732120344184, 0.8775078852794512, 0.9988416200003669], Output: [0.9105939123336477]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984015701606205, 0.9548119215239586, -0.8630619911890706, 0.9815039211463287]\n",
      "Layer: Layer 1, Input: [-0.9984015701606205, 0.9548119215239586, -0.8630619911890706, 0.9815039211463287], Output: [-0.8967961018766476, -0.9712645979644571, -0.6668807860285222, 0.987931703292457]\n",
      "Layer: Layer 2, Input: [-0.8967961018766476, -0.9712645979644571, -0.6668807860285222, 0.987931703292457], Output: [-0.8335412181884878]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9659648442190235, 0.6974156863326789, -0.9427869241269221, 0.966144103712151]\n",
      "Layer: Layer 1, Input: [-0.9659648442190235, 0.6974156863326789, -0.9427869241269221, 0.966144103712151], Output: [-0.8193762303983569, -0.9793866689635046, -0.7704921502596614, 0.977237177129203]\n",
      "Layer: Layer 2, Input: [-0.8193762303983569, -0.9793866689635046, -0.7704921502596614, 0.977237177129203], Output: [-0.9088160015035809]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9257471634394638, 0.9572382537421991, 0.5120818853021138, 0.9755682866435685]\n",
      "Layer: Layer 1, Input: [-0.9257471634394638, 0.9572382537421991, 0.5120818853021138, 0.9755682866435685], Output: [-0.9538407317944092, -0.8022767031109391, 0.7712018053160242, 0.9980353257521359]\n",
      "Layer: Layer 2, Input: [-0.9538407317944092, -0.8022767031109391, 0.7712018053160242, 0.9980353257521359], Output: [0.8094529180802997]\n",
      "Epoch 38/100, Loss: 0.020081171640971004, Accuracy: 0.46240405010601615\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9931143008881139, 0.996824329594497, 0.7424135150130121, 0.999810388745467]\n",
      "Layer: Layer 1, Input: [-0.9931143008881139, 0.996824329594497, 0.7424135150130121, 0.999810388745467], Output: [-0.9668945197300612, -0.7591137637135895, 0.8793434746062793, 0.9988517018436999]\n",
      "Layer: Layer 2, Input: [-0.9668945197300612, -0.7591137637135895, 0.8793434746062793, 0.9988517018436999], Output: [0.9236380846850596]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984032768010932, 0.9547682401583073, -0.8643505528009687, 0.9815294427014867]\n",
      "Layer: Layer 1, Input: [-0.9984032768010932, 0.9547682401583073, -0.8643505528009687, 0.9815294427014867], Output: [-0.8972429888286838, -0.9715245060634838, -0.6723093453776126, 0.9879217321717099]\n",
      "Layer: Layer 2, Input: [-0.8972429888286838, -0.9715245060634838, -0.6723093453776126, 0.9879217321717099], Output: [-0.8456853335328678]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9659854669585703, 0.6973959863984185, -0.9426302717854383, 0.9661609873795725]\n",
      "Layer: Layer 1, Input: [-0.9659854669585703, 0.6973959863984185, -0.9426302717854383, 0.9661609873795725], Output: [-0.8202748810828675, -0.9795160884025786, -0.7737483557052122, 0.977264509130358]\n",
      "Layer: Layer 2, Input: [-0.8202748810828675, -0.9795160884025786, -0.7737483557052122, 0.977264509130358], Output: [-0.919753258587501]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9258852775218874, 0.9572345534075963, 0.5169051838073452, 0.9755732898604825]\n",
      "Layer: Layer 1, Input: [-0.9258852775218874, 0.9572345534075963, 0.5169051838073452, 0.9755732898604825], Output: [-0.9541192068041477, -0.8028630926253834, 0.7735353738958654, 0.9980502577055455]\n",
      "Layer: Layer 2, Input: [-0.9541192068041477, -0.8028630926253834, 0.7735353738958654, 0.9980502577055455], Output: [0.8219675802083131]\n",
      "Epoch 39/100, Loss: 0.016944810100409078, Accuracy: 0.5110442570137415\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9931357358938586, 0.9968242235346815, 0.7475765762343871, 0.9998104562567235]\n",
      "Layer: Layer 1, Input: [-0.9931357358938586, 0.9968242235346815, 0.7475765762343871, 0.9998104562567235], Output: [-0.9670800880241524, -0.7596100972383979, 0.880997381081801, 0.9988606782292683]\n",
      "Layer: Layer 2, Input: [-0.9670800880241524, -0.7596100972383979, 0.880997381081801, 0.9988606782292683], Output: [0.9354941075444156]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984048651118697, 0.9547279561357741, -0.8655201028562839, 0.9815527369020688]\n",
      "Layer: Layer 1, Input: [-0.9984048651118697, 0.9547279561357741, -0.8655201028562839, 0.9815527369020688], Output: [-0.8976417386661892, -0.9717568151188527, -0.6771633599719081, 0.9879126073659081]\n",
      "Layer: Layer 2, Input: [-0.8976417386661892, -0.9717568151188527, -0.6771633599719081, 0.9879126073659081], Output: [-0.8567765685922986]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9660047466242383, 0.6973772926703067, -0.9424876026182054, 0.9661759542137778]\n",
      "Layer: Layer 1, Input: [-0.9660047466242383, 0.6973772926703067, -0.9424876026182054, 0.9661759542137778], Output: [-0.8210776052364969, -0.979631910590137, -0.7766566630964873, 0.9772891544774693]\n",
      "Layer: Layer 2, Input: [-0.8210776052364969, -0.979631910590137, -0.7766566630964873, 0.9772891544774693], Output: [-0.92974049366277]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9260131463035206, 0.957231240146263, 0.5213002307135308, 0.9755776335003445]\n",
      "Layer: Layer 1, Input: [-0.9260131463035206, 0.957231240146263, 0.5213002307135308, 0.9755776335003445], Output: [-0.9543688011664184, -0.8033818873964566, 0.7756885354263758, 0.9980637550744239]\n",
      "Layer: Layer 2, Input: [-0.9543688011664184, -0.8033818873964566, 0.7756885354263758, 0.9980637550744239], Output: [0.8333964909905446]\n",
      "Epoch 40/100, Loss: 0.014341772227675732, Accuracy: 0.5554076607900288\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9931555872474762, 0.9968241322598204, 0.7522226038330725, 0.9998105137052683]\n",
      "Layer: Layer 1, Input: [-0.9931555872474762, 0.9968241322598204, 0.7522226038330725, 0.9998105137052683], Output: [-0.9672451826234256, -0.7600607321026425, 0.8824921330606116, 0.998868695450474]\n",
      "Layer: Layer 2, Input: [-0.9672451826234256, -0.7600607321026425, 0.8824921330606116, 0.998868695450474], Output: [0.9462641007776675]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984063460474479, 0.9546907436488012, -0.8665847185538824, 0.9815740196537164]\n",
      "Layer: Layer 1, Input: [-0.9984063460474479, 0.9546907436488012, -0.8665847185538824, 0.9815740196537164], Output: [-0.8979970590379815, -0.971964711898412, -0.6815098234897953, 0.9879041934462849]\n",
      "Layer: Layer 2, Input: [-0.8979970590379815, -0.971964711898412, -0.6815098234897953, 0.9879041934462849], Output: [-0.8668999718864788]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9660228059967187, 0.6973595041869776, -0.9423575136729461, 0.966189188547682]\n",
      "Layer: Layer 1, Input: [-0.9660228059967187, 0.6973595041869776, -0.9423575136729461, 0.966189188547682], Output: [-0.821794341601289, -0.9797355961650579, -0.7792566900206775, 0.9773113612668889]\n",
      "Layer: Layer 2, Input: [-0.821794341601289, -0.9797355961650579, -0.7792566900206775, 0.9773113612668889], Output: [-0.9388522687030872]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9261317461417189, 0.9572282616090095, 0.5253113140470479, 0.9755813863589248]\n",
      "Layer: Layer 1, Input: [-0.9261317461417189, 0.9572282616090095, 0.5253113140470479, 0.9755813863589248], Output: [-0.9545927725431559, -0.8038382371623704, 0.7776777274830741, 0.9980759803321746]\n",
      "Layer: Layer 2, Input: [-0.9545927725431559, -0.8038382371623704, 0.7776777274830741, 0.9980759803321746], Output: [0.8438280209318055]\n",
      "Epoch 41/100, Loss: 0.012182974109472203, Accuracy: 0.5958443622990391\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9931740090824227, 0.996824052724764, 0.7564139163236698, 0.999810562119163]\n",
      "Layer: Layer 1, Input: [-0.9931740090824227, 0.996824052724764, 0.7564139163236698, 0.999810562119163], Output: [-0.9673923150425122, -0.760465440125959, 0.8838471086300931, 0.9988758775697717]\n",
      "Layer: Layer 2, Input: [-0.9673923150425122, -0.760465440125959, 0.8838471086300931, 0.9988758775697717], Output: [0.9560425280102812]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984077295693066, 0.9546563073070954, -0.8675565711361314, 0.9815934856052038]\n",
      "Layer: Layer 1, Input: [-0.9984077295693066, 0.9546563073070954, -0.8675565711361314, 0.9815934856052038], Output: [-0.8983131863671311, -0.9721509692030932, -0.6854070006781473, 0.9878963787034618]\n",
      "Layer: Layer 2, Input: [-0.8983131863671311, -0.9721509692030932, -0.6854070006781473, 0.9878963787034618], Output: [-0.8761350625457783]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9660397569894977, 0.6973425238996627, -0.9422387390038064, 0.9662008568850724]\n",
      "Layer: Layer 1, Input: [-0.9660397569894977, 0.6973425238996627, -0.9422387390038064, 0.9662008568850724], Output: [-0.8224339200516, -0.9798284358878453, -0.7815830498746976, 0.9773313552056176]\n",
      "Layer: Layer 2, Input: [-0.8224339200516, -0.9798284358878453, -0.7815830498746976, 0.9773313552056176], Output: [-0.9471587136469856]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9262419600312031, 0.9572255727381896, 0.5289780122686432, 0.9755846096737055]\n",
      "Layer: Layer 1, Input: [-0.9262419600312031, 0.9572255727381896, 0.5289780122686432, 0.9755846096737055], Output: [-0.9547939727043324, -0.8042370245415652, 0.7795181058362983, 0.9980870758751187]\n",
      "Layer: Layer 2, Input: [-0.9547939727043324, -0.8042370245415652, 0.7795181058362983, 0.9980870758751187], Output: [0.8533449108582417]\n",
      "Epoch 42/100, Loss: 0.010393674697220873, Accuracy: 0.6326812150612868\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993191140111115, 0.9968239823928539, 0.760204503253053, 0.9998106024168711]\n",
      "Layer: Layer 1, Input: [-0.993191140111115, 0.9968239823928539, 0.760204503253053, 0.9998106024168711], Output: [-0.9675236446689621, -0.7608248950765433, 0.8850790330229588, 0.9988823302802302]\n",
      "Layer: Layer 2, Input: [-0.9675236446689621, -0.7608248950765433, 0.8850790330229588, 0.9988823302802302], Output: [0.9649164814642118]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984090247227454, 0.954624379751838, -0.8684462231288428, 0.9816113102228924]\n",
      "Layer: Layer 1, Input: [-0.9984090247227454, 0.954624379751838, -0.8684462231288428, 0.9816113102228924], Output: [-0.898593933440112, -0.9723180068820984, -0.688905698500997, 0.9878890707443364]\n",
      "Layer: Layer 2, Input: [-0.898593933440112, -0.9723180068820984, -0.688905698500997, 0.9878890707443364], Output: [-0.8845559089266302]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9660557014310511, 0.6973262608302234, -0.9421301374569578, 0.9662111096201532]\n",
      "Layer: Layer 1, Input: [-0.9660557014310511, 0.6973262608302234, -0.9421301374569578, 0.9662111096201532], Output: [-0.8230041984282584, -0.9799115719933883, -0.7836660540671346, 0.9773493415313028]\n",
      "Layer: Layer 2, Input: [-0.8230041984282584, -0.9799115719933883, -0.7836660540671346, 0.9773493415313028], Output: [-0.9547254948402486]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9263445858759447, 0.9572231347576619, 0.5323356898491975, 0.9755873580194346]\n",
      "Layer: Layer 1, Input: [-0.9263445858759447, 0.9572231347576619, 0.5323356898491975, 0.9755873580194346], Output: [-0.9549749041166049, -0.8045828448851197, 0.7812235747197259, 0.9980971667304217]\n",
      "Layer: Layer 2, Input: [-0.9549749041166049, -0.8045828448851197, 0.7812235747197259, 0.9980971667304217], Output: [0.8620242385326787]\n",
      "Epoch 43/100, Loss: 0.008911320751638748, Accuracy: 0.6662221237637693\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9932071051439196, 0.9968239191612279, 0.7636412564819504, 0.9998106354198452]\n",
      "Layer: Layer 1, Input: [-0.9932071051439196, 0.9968239191612279, 0.7636412564819504, 0.9998106354198452], Output: [-0.9676410357116074, -0.761140405475118, 0.8862023888690466, 0.9988881440164327]\n",
      "Layer: Layer 2, Input: [-0.9676410357116074, -0.761140405475118, 0.8862023888690466, 0.9988881440164327], Output: [0.9729660449407916]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984102397121373, 0.9545947192886867, -0.8692628728150318, 0.98162765168461]\n",
      "Layer: Layer 1, Input: [-0.9984102397121373, 0.9545947192886867, -0.8692628728150318, 0.98162765168461], Output: [-0.8988427325657325, -0.972467942813549, -0.6920503354859862, 0.9878821929468993]\n",
      "Layer: Layer 2, Input: [-0.8988427325657325, -0.972467942813549, -0.6920503354859862, 0.9878821929468993], Output: [-0.8922312775836655]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9660707318483363, 0.6973106311634041, -0.9420306811609893, 0.9662200826027355]\n",
      "Layer: Layer 1, Input: [-0.9660707318483363, 0.6973106311634041, -0.9420306811609893, 0.9662200826027355], Output: [-0.8235121804806531, -0.9799860167707428, -0.785532307655348, 0.9773655067888171]\n",
      "Layer: Layer 2, Input: [-0.8235121804806531, -0.9799860167707428, -0.785532307655348, 0.9773655067888171], Output: [-0.9616138617393907]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9264403442885591, 0.9572209142835953, 0.5354159480718345, 0.9755896800917877]\n",
      "Layer: Layer 1, Input: [-0.9264403442885591, 0.9572209142835953, 0.5354159480718345, 0.9755896800917877], Output: [-0.9551377677772929, -0.8048799984962636, 0.7828068407499843, 0.9981063628737082]\n",
      "Layer: Layer 2, Input: [-0.9551377677772929, -0.8048799984962636, 0.7828068407499843, 0.9981063628737082], Output: [0.8699375132005795]\n",
      "Epoch 44/100, Loss: 0.007683669585101073, Accuracy: 0.6967486974644274\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993222016479318, 0.9968238612940562, 0.76676500450394, 0.999810661863565]\n",
      "Layer: Layer 1, Input: [-0.993222016479318, 0.9968238612940562, 0.76676500450394, 0.999810661863565], Output: [-0.9677461036848287, -0.7614137119029389, 0.8872297556267696, 0.9988933964737059]\n",
      "Layer: Layer 2, Input: [-0.9677461036848287, -0.7614137119029389, 0.8872297556267696, 0.9988933964737059], Output: [0.9802647009351134]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984113819730037, 0.9545671076083942, -0.8700145563286014, 0.9816426525994143]\n",
      "Layer: Layer 1, Input: [-0.9984113819730037, 0.9545671076083942, -0.8700145563286014, 0.9816426525994143], Output: [-0.8990626745249258, -0.97260263563395, -0.6948798427421526, 0.9878756815988177]\n",
      "Layer: Layer 2, Input: [-0.8990626745249258, -0.97260263563395, -0.6948798427421526, 0.9878756815988177], Output: [-0.8992248330017752]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9660849322293857, 0.6972955586432977, -0.9419394448128764, 0.9662278985579934]\n",
      "Layer: Layer 1, Input: [-0.9660849322293857, 0.6972955586432977, -0.9419394448128764, 0.9662278985579934], Output: [-0.8239641178114268, -0.9800526686957384, -0.7872052150394799, 0.9773800204696678]\n",
      "Layer: Layer 2, Input: [-0.8239641178114268, -0.9800526686957384, -0.7872052150394799, 0.9773800204696678], Output: [-0.9678807530466195]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9265298858477441, 0.9572188825502224, 0.538247031831768, 0.9755916193927379]\n",
      "Layer: Layer 1, Input: [-0.9265298858477441, 0.9572188825502224, 0.538247031831768, 0.9755916193927379], Output: [-0.9552845037546971, -0.8051324915324588, 0.7842794808317719, 0.9981147612131452]\n",
      "Layer: Layer 2, Input: [-0.9552845037546971, -0.8051324915324588, 0.7842794808317719, 0.9981147612131452], Output: [0.8771508571084883]\n",
      "Epoch 45/100, Loss: 0.006667168561682977, Accuracy: 0.7245211440919964\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9932359751674962, 0.9968238073639784, 0.7696113824398458, 0.9998106824072233]\n",
      "Layer: Layer 1, Input: [-0.9932359751674962, 0.9968238073639784, 0.7696113824398458, 0.9998106824072233], Output: [-0.9678402535539002, -0.7616468341489424, 0.8881720914067109, 0.998898154658796]\n",
      "Layer: Layer 2, Input: [-0.9678402535539002, -0.7616468341489424, 0.8881720914067109, 0.998898154658796], Output: [0.9868797580731938]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984124582399899, 0.9545413476351807, -0.870708315550778, 0.9816564415632134]\n",
      "Layer: Layer 1, Input: [-0.9984124582399899, 0.9545413476351807, -0.870708315550778, 0.9816564415632134], Output: [-0.8992565436007687, -0.9727237206696497, -0.6974284246716884, 0.9878694835821199]\n",
      "Layer: Layer 2, Input: [-0.8992565436007687, -0.9727237206696497, -0.6974284246716884, 0.9878694835821199], Output: [-0.9055953722177194]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9660983787512116, 0.697280974527921, -0.9418555957947857, 0.9662346683710404]\n",
      "Layer: Layer 1, Input: [-0.9660983787512116, 0.697280974527921, -0.9418555957947857, 0.9662346683710404], Output: [-0.8243655982363506, -0.9801123264251513, -0.7887054098980014, 0.9773930365211568]\n",
      "Layer: Layer 2, Input: [-0.8243655982363506, -0.9801123264251513, -0.7887054098980014, 0.9773930365211568], Output: [-0.9735789465125394]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.926613797787755, 0.9572170147410454, 0.5408541946282758, 0.9755932148300078]\n",
      "Layer: Layer 1, Input: [-0.926613797787755, 0.9572170147410454, 0.5408541946282758, 0.9755932148300078], Output: [-0.9554168256425865, -0.8053440428657479, 0.7856520173352831, 0.9981224472894452]\n",
      "Layer: Layer 2, Input: [-0.9554168256425865, -0.8053440428657479, 0.7856520173352831, 0.9981224472894452], Output: [0.883725243802448]\n",
      "Epoch 46/100, Loss: 0.005825566372779072, Accuracy: 0.7497793206059006\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9932490721532773, 0.9968237562014499, 0.7722115651239353, 0.9998106976422295]\n",
      "Layer: Layer 1, Input: [-0.9932490721532773, 0.9968237562014499, 0.7722115651239353, 0.9998106976422295], Output: [-0.9679247112015849, -0.76184195675108, 0.8890389678444628, 0.9989024765677085]\n",
      "Layer: Layer 2, Input: [-0.9679247112015849, -0.76184195675108, 0.8890389678444628, 0.9989024765677085], Output: [0.9928727824407801]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984134746102588, 0.9545172615237215, -0.8713503382794421, 0.9816691345620285]\n",
      "Layer: Layer 1, Input: [-0.9984134746102588, 0.9545172615237215, -0.8713503382794421, 0.9816691345620285], Output: [-0.899426849008376, -0.9728326402543075, -0.6997262027095338, 0.9878635544950413]\n",
      "Layer: Layer 2, Input: [-0.899426849008376, -0.9728326402543075, -0.6997262027095338, 0.9878635544950413], Output: [-0.9113970816666374]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661111404650811, 0.6972668172746858, -0.9417783851193966, 0.9662404922470872]\n",
      "Layer: Layer 1, Input: [-0.9661111404650811, 0.6972668172746858, -0.9417783851193966, 0.9662404922470872], Output: [-0.8247216225751934, -0.9801657009345219, -0.7900511213682988, 0.9774046947326734]\n",
      "Layer: Layer 2, Input: [-0.8247216225751934, -0.9801657009345219, -0.7900511213682988, 0.9774046947326734], Output: [-0.9787572394530458]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9266926101220738, 0.9572152894145065, 0.5432600247185058, 0.9755945012416655]\n",
      "Layer: Layer 1, Input: [-0.9266926101220738, 0.9572152894145065, 0.5432600247185058, 0.9755945012416655], Output: [-0.9555362499270155, -0.8055180948984946, 0.7869339959616843, 0.9981294967343717]\n",
      "Layer: Layer 2, Input: [-0.9555362499270155, -0.8055180948984946, 0.7869339959616843, 0.9981294967343717], Output: [0.8897167711003142]\n",
      "Epoch 47/100, Loss: 0.005128729954880176, Accuracy: 0.7727438746607775\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993261389306318, 0.9968237068513973, 0.7745928861604847, 0.9998107080996855]\n",
      "Layer: Layer 1, Input: [-0.993261389306318, 0.9968237068513973, 0.7745928861604847, 0.9998107080996855], Output: [-0.9680005495186845, -0.7620013440378559, 0.8898387666110308, 0.9989064125654465]\n",
      "Layer: Layer 2, Input: [-0.9680005495186845, -0.7620013440378559, 0.8898387666110308, 0.9989064125654465], Output: [0.9983000216822866]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984144366021372, 0.9544946888128769, -0.8719460758079304, 0.9816808362353725]\n",
      "Layer: Layer 1, Input: [-0.9984144366021372, 0.9544946888128769, -0.8719460758079304, 0.9816808362353725], Output: [-0.8995758530503899, -0.972930669397777, -0.7017997614571784, 0.9878578571246731]\n",
      "Layer: Layer 2, Input: [-0.8995758530503899, -0.972930669397777, -0.7017997614571784, 0.9878578571246731], Output: [-0.916679806298944]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661232799352315, 0.6972530320731006, -0.9417071391769806, 0.966245460757895]\n",
      "Layer: Layer 1, Input: [-0.9661232799352315, 0.6972530320731006, -0.9417071391769806, 0.966245460757895], Output: [-0.8250366715622628, -0.980213426051396, -0.7912584865739507, 0.9774151220067521]\n",
      "Layer: Layer 2, Input: [-0.8250366715622628, -0.980213426051396, -0.7912584865739507, 0.9774151220067521], Output: [-0.9834606495142636]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9267668012209953, 0.9572136880128687, 0.5454847357499603, 0.9755955098556252]\n",
      "Layer: Layer 1, Input: [-0.9267668012209953, 0.9572136880128687, 0.5454847357499603, 0.9755955098556252], Output: [-0.9556441210905761, -0.8056578268716922, 0.7881340632339582, 0.9981359765241221]\n",
      "Layer: Layer 2, Input: [-0.9556441210905761, -0.8056578268716922, 0.7881340632339582, 0.9981359765241221], Output: [0.8951769526818563]\n",
      "Epoch 48/100, Loss: 0.004551641492053506, Accuracy: 0.7936174301773504\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9932730003474339, 0.9968236585364377, 0.776779361960122, 0.9998107142569643]\n",
      "Layer: Layer 1, Input: [-0.9932730003474339, 0.9968236585364377, 0.776779361960122, 0.9998107142569643], Output: [-0.9680687101454173, -0.7621272777791946, 0.8905788444839324, 0.9989100065262446]\n",
      "Layer: Layer 2, Input: [-0.9680687101454173, -0.7621272777791946, 0.8905788444839324, 0.9989100065262446], Output: [1.003212814553383]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984153492090398, 0.9544734847360703, -0.8725003420088048, 0.9816916410121989]\n",
      "Layer: Layer 1, Input: [-0.9984153492090398, 0.9544734847360703, -0.8725003420088048, 0.9816916410121989], Output: [-0.8997055963149625, -0.9730189375945983, -0.7036726132557576, 0.9878523602018214]\n",
      "Layer: Layer 2, Input: [-0.8997055963149625, -0.9730189375945983, -0.7036726132557576, 0.9878523602018214], Output: [-0.9214893232694886]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661348538297976, 0.6972395703019117, -0.9416412522424649, 0.9662496557848618]\n",
      "Layer: Layer 1, Input: [-0.9661348538297976, 0.6972395703019117, -0.9416412522424649, 0.9662496557848618], Output: [-0.8253147642949767, -0.9802560676052334, -0.7923418179698084, 0.9774244335226026]\n",
      "Layer: Layer 2, Input: [-0.8253147642949767, -0.9802560676052334, -0.7923418179698084, 0.9774244335226026], Output: [-0.9877306273644962]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9268368028731723, 0.9572121944435266, 0.5475464252610767, 0.9755962686926029]\n",
      "Layer: Layer 1, Input: [-0.9268368028731723, 0.9572121944435266, 0.5475464252610767, 0.9755962686926029], Output: [-0.9557416331366956, -0.8057661696060459, 0.7892600416287379, 0.9981419460584912]\n",
      "Layer: Layer 2, Input: [-0.9557416331366956, -0.8057661696060459, 0.7892600416287379, 0.9981419460584912], Output: [0.90015301675356]\n",
      "Epoch 49/100, Loss: 0.004073551526580253, Accuracy: 0.8061601528341619\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9932839716801428, 0.9968236106258807, 0.7787921365086903, 0.9998107165435077]\n",
      "Layer: Layer 1, Input: [-0.9932839716801428, 0.9968236106258807, 0.7787921365086903, 0.9998107165435077], Output: [-0.9681300216768187, -0.7622220121190265, 0.8912656725663364, 0.9989132967804523]\n",
      "Layer: Layer 2, Input: [-0.9681300216768187, -0.7622220121190265, 0.8912656725663364, 0.9989132967804523], Output: [1.0076579813244773]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984162169488234, 0.954453518683106, -0.8730173972026505, 0.9817016341314215]\n",
      "Layer: Layer 1, Input: [-0.9984162169488234, 0.954453518683106, -0.8730173972026505, 0.9817016341314215], Output: [-0.8998179202156803, -0.9730984474167693, -0.7053655944828531, 0.9878470373834609]\n",
      "Layer: Layer 2, Input: [-0.8998179202156803, -0.9730984474167693, -0.7053655944828531, 0.9878470373834609], Output: [-0.9258676143543337]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661459134644986, 0.6972263889609107, -0.9415801796923582, 0.9662531513684972]\n",
      "Layer: Layer 1, Input: [-0.9661459134644986, 0.6972263889609107, -0.9415801796923582, 0.9662531513684972], Output: [-0.8255595094149702, -0.980294131386361, -0.7933138325938887, 0.9774327337997357]\n",
      "Layer: Layer 2, Input: [-0.8255595094149702, -0.980294131386361, -0.7933138325938887, 0.9774327337997357], Output: [-0.9916052748050829]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9269030048665803, 0.9572107947228082, 0.5494613043430069, 0.9755968029199614]\n",
      "Layer: Layer 1, Input: [-0.9269030048665803, 0.9572107947228082, 0.5494613043430069, 0.9755968029199614], Output: [-0.9558298480994254, -0.8058458209159375, 0.7903190011221551, 0.9981474580919714]\n",
      "Layer: Layer 2, Input: [-0.9558298480994254, -0.8058458209159375, 0.7903190011221551, 0.9981474580919714], Output: [0.9046882036033033]\n",
      "Epoch 50/100, Loss: 0.0036772663057368445, Accuracy: 0.8145031114382426\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9932943631363265, 0.9968235626097505, 0.7806498599044174, 0.999810715345944]\n",
      "Layer: Layer 1, Input: [-0.9932943631363265, 0.9968235626097505, 0.7806498599044174, 0.999810715345944], Output: [-0.9681852149791619, -0.7622877416768955, 0.8919049541719122, 0.9989163169045795]\n",
      "Layer: Layer 2, Input: [-0.9681852149791619, -0.7622877416768955, 0.8919049541719122, 0.9989163169045795], Output: [1.0116781923564369]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984170439088097, 0.954434672805208, -0.8735010194509158, 0.9817108925582992]\n",
      "Layer: Layer 1, Input: [-0.9984170439088097, 0.954434672805208, -0.8735010194509158, 0.9817108925582992], Output: [-0.8999144871508711, -0.9731700904191987, -0.7068972045731788, 0.9878418664191998]\n",
      "Layer: Layer 2, Input: [-0.8999144871508711, -0.9731700904191987, -0.7068972045731788, 0.9878418664191998], Output: [-0.9298531327546243]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661565053007668, 0.6972134501091595, -0.9415234318776379, 0.9662560144733566]\n",
      "Layer: Layer 1, Input: [-0.9661565053007668, 0.6972134501091595, -0.9415234318776379, 0.9662560144733566], Output: [-0.8257741500303857, -0.9803280700800405, -0.794185849152513, 0.9774401176691125]\n",
      "Layer: Layer 2, Input: [-0.8257741500303857, -0.9803280700800405, -0.794185849152513, 0.9774401176691125], Output: [-0.995119563299328]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9269657591265523, 0.957209476673344, 0.551243901561974, 0.9755971351628968]\n",
      "Layer: Layer 1, Input: [-0.9269657591265523, 0.957209476673344, 0.551243901561974, 0.9755971351628968], Output: [-0.9559097120078583, -0.805899261158886, 0.7913173264493462, 0.9981525595388823]\n",
      "Layer: Layer 2, Input: [-0.9559097120078583, -0.805899261158886, 0.7913173264493462, 0.9981525595388823], Output: [0.9088220563531445]\n",
      "Epoch 51/100, Loss: 0.0033485498077781804, Accuracy: 0.82211656005066\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993304228644457, 0.9968235140771173, 0.782369011446064, 0.9998107110126122]\n",
      "Layer: Layer 1, Input: [-0.993304228644457, 0.9968235140771173, 0.782369011446064, 0.9998107110126122], Output: [-0.968234936134543, -0.7623265796474438, 0.8925017250368416, 0.9989190963835202]\n",
      "Layer: Layer 2, Input: [-0.968234936134543, -0.7623265796474438, 0.8925017250368416, 0.9989190963835202], Output: [1.015312313523388]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984178337867486, 0.9544168407534631, -0.8739545654058168, 0.981719485807143]\n",
      "Layer: Layer 1, Input: [-0.9984178337867486, 0.9544168407534631, -0.8739545654058168, 0.981719485807143], Output: [-0.8999967985358821, -0.9732346607920321, -0.7082838968786876, 0.9878368284668796]\n",
      "Layer: Layer 2, Input: [-0.8999967985358821, -0.9732346607920321, -0.7082838968786876, 0.9878368284668796], Output: [-0.9334810611540476]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661666714006776, 0.6972007203288244, -0.9414705685980151, 0.9662583056767803]\n",
      "Layer: Layer 1, Input: [-0.9661666714006776, 0.6972007203288244, -0.9414705685980151, 0.9662583056767803], Output: [-0.8259616032333567, -0.9803582893183281, -0.7949679578922638, 0.977446671158963]\n",
      "Layer: Layer 2, Input: [-0.8259616032333567, -0.9803582893183281, -0.7949679578922638, 0.977446671158963], Output: [-0.9983055491546668]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9270253834486257, 0.9572082296671262, 0.5529072439978289, 0.9755972857785389]\n",
      "Layer: Layer 1, Input: [-0.9270253834486257, 0.9572082296671262, 0.5529072439978289, 0.9755972857785389], Output: [-0.9559820686951491, -0.8059287685476215, 0.7922607797388733, 0.9981572921711592]\n",
      "Layer: Layer 2, Input: [-0.9559820686951491, -0.8059287685476215, 0.7922607797388733, 0.9981572921711592], Output: [0.912590701064082]\n",
      "Epoch 52/100, Loss: 0.003075623218691501, Accuracy: 0.8290649978494086\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933136168282467, 0.9968234646980956, 0.7839641761937725, 0.9998107038575663]\n",
      "Layer: Layer 1, Input: [-0.9933136168282467, 0.9968234646980956, 0.7839641761937725, 0.9998107038575663], Output: [-0.9682797574289156, -0.7623405434550318, 0.8930604388347607, 0.998921661168111]\n",
      "Layer: Layer 2, Input: [-0.9682797574289156, -0.7623405434550318, 0.8930604388347607, 0.998921661168111], Output: [1.018595728099163]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984185899280119, 0.9543999265401982, -0.8743810224492935, 0.9817274766799273]\n",
      "Layer: Layer 1, Input: [-0.9984185899280119, 0.9543999265401982, -0.8743810224492935, 0.9817274766799273], Output: [-0.9000662109378686, -0.9732928671175441, -0.7095403289310723, 0.9878319075293378]\n",
      "Layer: Layer 2, Input: [-0.9000662109378686, -0.9732928671175441, -0.7095403289310723, 0.9878319075293378], Output: [-0.9367835588545897]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661764498414105, 0.6971881702253722, -0.9414211941243006, 0.966260079789055]\n",
      "Layer: Layer 1, Input: [-0.9661764498414105, 0.6971881702253722, -0.9414211941243006, 0.966260079789055], Output: [-0.8261244949376864, -0.9803851529719336, -0.7956691674009825, 0.9774524723020753]\n",
      "Layer: Layer 2, Input: [-0.8261244949376864, -0.9803851529719336, -0.7956691674009825, 0.9774524723020753], Output: [-1.001192582594586]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9270821648627409, 0.9572070444074068, 0.554463017991286, 0.9755972730977837]\n",
      "Layer: Layer 1, Input: [-0.9270821648627409, 0.9572070444074068, 0.554463017991286, 0.9755972730977837], Output: [-0.9560476717770148, -0.805936433973041, 0.7931545584275796, 0.9981616932245121]\n",
      "Layer: Layer 2, Input: [-0.9560476717770148, -0.805936433973041, 0.7931545584275796, 0.9981616932245121], Output: [0.9160271137081253]\n",
      "Epoch 53/100, Loss: 0.002848746855015538, Accuracy: 0.8330223618689659\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933225715429358, 0.996823414208944, 0.7854482823910991, 0.9998106941641269]\n",
      "Layer: Layer 1, Input: [-0.9933225715429358, 0.996823414208944, 0.7854482823910991, 0.9998106941641269], Output: [-0.9683201867185798, -0.7623315460836743, 0.8935850404206176, 0.9989240341465959]\n",
      "Layer: Layer 2, Input: [-0.9683201867185798, -0.7623315460836743, 0.8935850404206176, 0.9989240341465959], Output: [1.0215606353688975]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984193153593215, 0.9543838435127586, -0.874783053533754, 0.9817349219295052]\n",
      "Layer: Layer 1, Input: [-0.9984193153593215, 0.9543838435127586, -0.874783053533754, 0.9817349219295052], Output: [-0.9001239505194393, -0.9733453425271302, -0.7106795783914392, 0.9878270899898384]\n",
      "Layer: Layer 2, Input: [-0.9001239505194393, -0.9733453425271302, -0.7106795783914392, 0.9878270899898384], Output: [-0.9397899965678129]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9661858750921367, 0.6971757739692994, -0.9413749527181452, 0.9662613864119091]\n",
      "Layer: Layer 1, Input: [-0.9661858750921367, 0.6971757739692994, -0.9413749527181452, 0.9662613864119091], Output: [-0.8262651906538682, -0.9804089877865565, -0.7962975318047564, 0.9774575918709809]\n",
      "Layer: Layer 2, Input: [-0.8262651906538682, -0.9804089877865565, -0.7962975318047564, 0.9774575918709809], Output: [-1.0038075087590812]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9271363626633594, 0.9572059127435175, 0.5559217119289882, 0.9755971136390098]\n",
      "Layer: Layer 1, Input: [-0.9271363626633594, 0.9572059127435175, 0.5559217119289882, 0.9755971136390098], Output: [-0.9561071950709816, -0.8059241751750553, 0.7940033485226619, 0.9981657959262028]\n",
      "Layer: Layer 2, Input: [-0.9561071950709816, -0.8059241751750553, 0.7940033485226619, 0.9981657959262028], Output: [0.9191613725223942]\n",
      "Epoch 54/100, Loss: 0.0026598715815570363, Accuracy: 0.8335832249622284\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933311323557731, 0.9968233623997704, 0.7868328058752565, 0.9998106821880353]\n",
      "Layer: Layer 1, Input: [-0.9933311323557731, 0.9968233623997704, 0.7868328058752565, 0.9998106821880353], Output: [-0.9683566754466154, -0.7623013916372469, 0.8940790287878184, 0.9989262355449463]\n",
      "Layer: Layer 2, Input: [-0.9683566754466154, -0.7623013916372469, 0.8940790287878184, 0.9989262355449463], Output: [1.0242363266586105]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984200128192959, 0.954368513429481, -0.8751630358821375, 0.9817418728552835]\n",
      "Layer: Layer 1, Input: [-0.9984200128192959, 0.954368513429481, -0.8751630358821375, 0.9817418728552835], Output: [-0.9001711259757296, -0.9733926535032837, -0.7117133299195166, 0.9878223642280345]\n",
      "Layer: Layer 2, Input: [-0.9001711259757296, -0.9733926535032837, -0.7117133299195166, 0.9878223642280345], Output: [-0.9425271780230899]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.966194978356247, 0.6971635088809369, -0.9413315246016625, 0.9662622704415891]\n",
      "Layer: Layer 1, Input: [-0.966194978356247, 0.6971635088809369, -0.9413315246016625, 0.9662622704415891], Output: [-0.8263858227281782, -0.98043008745296, -0.7968602612664526, 0.9774620940470546]\n",
      "Layer: Layer 2, Input: [-0.8263858227281782, -0.98043008745296, -0.7968602612664526, 0.9774620940470546], Output: [-1.0061748593082371]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9271882111376935, 0.9572048275135464, 0.5572927431434789, 0.975596822297263]\n",
      "Layer: Layer 1, Input: [-0.9271882111376935, 0.9572048275135464, 0.5572927431434789, 0.975596822297263], Output: [-0.956161241683459, -0.8058937501629415, 0.7948113733807043, 0.9981696299556269]\n",
      "Layer: Layer 2, Input: [-0.956161241683459, -0.8058937501629415, 0.7948113733807043, 0.9981696299556269], Output: [0.9220208949885548]\n",
      "Epoch 55/100, Loss: 0.002502348625438749, Accuracy: 0.834136887044797\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993339334976605, 0.9968233091044171, 0.788127946565259, 0.9998106681602582]\n",
      "Layer: Layer 1, Input: [-0.993339334976605, 0.9968233091044171, 0.788127946565259, 0.9998106681602582], Output: [-0.9683896255302439, -0.7622517740206636, 0.8945455113675538, 0.9989282832681327]\n",
      "Layer: Layer 2, Input: [-0.9683896255302439, -0.7622517740206636, 0.8945455113675538, 0.9989282832681327], Output: [1.0266494397536707]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984206847860962, 0.9543538656281954, -0.875523094499902, 0.9817483758384256]\n",
      "Layer: Layer 1, Input: [-0.9984206847860962, 0.9543538656281954, -0.875523094499902, 0.9817483758384256], Output: [-0.9002087401294265, -0.9734353075301017, -0.7126520373277044, 0.9878177203018106]\n",
      "Layer: Layer 2, Input: [-0.9002087401294265, -0.9734353075301017, -0.7126520373277044, 0.9878177203018106], Output: [-0.945019548002148]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.966203787881764, 0.6971513550575984, -0.9412906223330259, 0.9662627725221453]\n",
      "Layer: Layer 1, Input: [-0.966203787881764, 0.6971513550575984, -0.9412906223330259, 0.9662627725221453], Output: [-0.8264883144966061, -0.9804487161870331, -0.7973638182247929, 0.97746603702915]\n",
      "Layer: Layer 2, Input: [-0.8264883144966061, -0.9804487161870331, -0.7973638182247929, 0.97746603702915], Output: [-1.0083170338019376]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9272379220216935, 0.9572037824105571, 0.5585845707706519, 0.9755964125119996]\n",
      "Layer: Layer 1, Input: [-0.9272379220216935, 0.9572037824105571, 0.5585845707706519, 0.9755964125119996], Output: [-0.9562103519552299, -0.8058467698333937, 0.795582438235691, 0.9981732218471505]\n",
      "Layer: Layer 2, Input: [-0.9562103519552299, -0.8058467698333937, 0.795582438235691, 0.9981732218471505], Output: [0.9246306592068787]\n",
      "Epoch 56/100, Loss: 0.002370688330981215, Accuracy: 0.8346837336534184\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933472116438902, 0.9968232541921632, 0.7893427812645238, 0.9998106522894868]\n",
      "Layer: Layer 1, Input: [-0.9933472116438902, 0.9968232541921632, 0.7893427812645238, 0.9998106522894868], Output: [-0.9684193952998127, -0.7621842778919685, 0.8949872510122909, 0.9989301931921682]\n",
      "Layer: Layer 2, Input: [-0.9684193952998127, -0.7621842778919685, 0.8949872510122909, 0.9989301931921682], Output: [1.0288241928454123]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984213335024286, 0.9543398362782531, -0.8758651312862914, 0.9817544728229138]\n",
      "Layer: Layer 1, Input: [-0.9984213335024286, 0.9543398362782531, -0.8758651312862914, 0.9817544728229138], Output: [-0.9002377003300395, -0.9734737597620264, -0.7135050646701594, 0.9878131496831307]\n",
      "Layer: Layer 2, Input: [-0.9002377003300395, -0.9734737597620264, -0.7135050646701594, 0.9878131496831307], Output: [-0.9472893867475417]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662123292426663, 0.697139295040971, -0.9412519875477993, 0.9662629294539863]\n",
      "Layer: Layer 1, Input: [-0.9662123292426663, 0.697139295040971, -0.9412519875477993, 0.9662629294539863], Output: [-0.8265744017404235, -0.9804651118850085, -0.7978140014251219, 0.9774694735869806]\n",
      "Layer: Layer 2, Input: [-0.8265744017404235, -0.9804651118850085, -0.7978140014251219, 0.9774694735869806], Output: [-1.0102544704147722]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9272856867108782, 0.9572027718686891, 0.5598047961932741, 0.9755958964160628]\n",
      "Layer: Layer 1, Input: [-0.9272856867108782, 0.9572027718686891, 0.5598047961932741, 0.9755958964160628], Output: [-0.9562550104257642, -0.8057847097676986, 0.7963199707421897, 0.9981765953432035]\n",
      "Layer: Layer 2, Input: [-0.9562550104257642, -0.8057847097676986, 0.7963199707421897, 0.9981765953432035], Output: [0.9270134098087257]\n",
      "Epoch 57/100, Loss: 0.0022603598384690507, Accuracy: 0.8352241332960829\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993354791470892, 0.9968231975609341, 0.790485396312335, 0.9998106347643656]\n",
      "Layer: Layer 1, Input: [-0.993354791470892, 0.9968231975609341, 0.790485396312335, 0.9998106347643656], Output: [-0.9684463046377775, -0.7621003812354756, 0.8954067067732336, 0.9989319794149398]\n",
      "Layer: Layer 2, Input: [-0.9684463046377775, -0.7621003812354756, 0.8954067067732336, 0.9989319794149398], Output: [1.0307825992356396]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984219609981524, 0.9543263677077944, -0.8761908503984162, 0.981760201748142]\n",
      "Layer: Layer 1, Input: [-0.9984219609981524, 0.9543263677077944, -0.8761908503984162, 0.981760201748142], Output: [-0.9002588277873163, -0.9735084188527723, -0.714280809326526, 0.9878086450382558]\n",
      "Layer: Layer 2, Input: [-0.9002588277873163, -0.9735084188527723, -0.714280809326526, 0.9878086450382558], Output: [-0.9493569909435902]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662206255936819, 0.6971273135218968, -0.9412153880293558, 0.9662627745622432]\n",
      "Layer: Layer 1, Input: [-0.9662206255936819, 0.6971273135218968, -0.9412153880293558, 0.9662627745622432], Output: [-0.8266456517761551, -0.9804794889095931, -0.7982160194703852, 0.977472451564068]\n",
      "Layer: Layer 2, Input: [-0.8266456517761551, -0.9804794889095931, -0.7982160194703852, 0.977472451564068], Output: [-1.0120058058401824]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9273316782506101, 0.9572017909660404, 0.5609602525065353, 0.975595284968197]\n",
      "Layer: Layer 1, Input: [-0.9273316782506101, 0.9572017909660404, 0.5609602525065353, 0.975595284968197], Output: [-0.9562956519517287, -0.805708921212762, 0.7970270578149223, 0.9981797717044166]\n",
      "Layer: Layer 2, Input: [-0.9562956519517287, -0.805708921212762, 0.7970270578149223, 0.9981797717044166], Output: [0.9291898488125488]\n",
      "Epoch 58/100, Loss: 0.0021676249167628648, Accuracy: 0.835758434680317\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933621007563015, 0.99682313913176, 0.791563003040074, 0.9998106157554824]\n",
      "Layer: Layer 1, Input: [-0.9933621007563015, 0.99682313913176, 0.791563003040074, 0.9998106157554824], Output: [-0.9684706394400588, -0.7620014590606791, 0.8958060693930753, 0.9989336544723896]\n",
      "Layer: Layer 2, Input: [-0.9684706394400588, -0.7620014590606791, 0.8958060693930753, 0.9989336544723896], Output: [1.0325446640642069]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984225691107111, 0.9543134077986845, -0.8765017804128378, 0.981765596938098]\n",
      "Layer: Layer 1, Input: [-0.9984225691107111, 0.9543134077986845, -0.8765017804128378, 0.981765596938098], Output: [-0.9002728659540136, -0.9735396520635429, -0.7149868096513537, 0.9878042000444888]\n",
      "Layer: Layer 2, Input: [-0.9002728659540136, -0.9735396520635429, -0.7149868096513537, 0.9878042000444888], Output: [-0.9512408416500059]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662286979009523, 0.6971153970793367, -0.9411806150751895, 0.9662623380290187]\n",
      "Layer: Layer 1, Input: [-0.9662286979009523, 0.6971153970793367, -0.9411806150751895, 0.9662623380290187], Output: [-0.8267034804670084, -0.9804920405547758, -0.7985745553521724, 0.9774750143347022]\n",
      "Layer: Layer 2, Input: [-0.8267034804670084, -0.9804920405547758, -0.7985745553521724, 0.9774750143347022], Output: [-1.0135880244597244]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9273760531280688, 0.9572008353417222, 0.562057084269847, 0.9755945880711004]\n",
      "Layer: Layer 1, Input: [-0.9273760531280688, 0.9572008353417222, 0.562057084269847, 0.9755945880711004], Output: [-0.9563326670942929, -0.8056206412666777, 0.7977064790480989, 0.9981827699825695]\n",
      "Layer: Layer 2, Input: [-0.9563326670942929, -0.8056206412666777, 0.7977064790480989, 0.9981827699825695], Output: [0.9311788120054091]\n",
      "Epoch 59/100, Loss: 0.0020894002519391925, Accuracy: 0.8362869651314837\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933691632630712, 0.9968230788442647, 0.792582038510794, 0.9998105954171496]\n",
      "Layer: Layer 1, Input: [-0.9933691632630712, 0.9968230788442647, 0.792582038510794, 0.9998105954171496], Output: [-0.9684926555011308, -0.7618887878510077, 0.8961872922818768, 0.9989352295254476]\n",
      "Layer: Layer 2, Input: [-0.9684926555011308, -0.7618887878510077, 0.8961872922818768, 0.9989352295254476], Output: [1.0341285643220919]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984231595035958, 0.9543009094422512, -0.8767992937404695, 0.981770689451659]\n",
      "Layer: Layer 1, Input: [-0.9984231595035958, 0.9543009094422512, -0.8767992937404695, 0.981770689451659], Output: [-0.9002804880601973, -0.9735677897508087, -0.7156298393553452, 0.9877998092370477]\n",
      "Layer: Layer 2, Input: [-0.9002804880601973, -0.9735677897508087, -0.7156298393553452, 0.9877998092370477], Output: [-0.9529577596957953]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662365651507683, 0.6971035339502287, -0.9411474811291295, 0.9662616471931681]\n",
      "Layer: Layer 1, Input: [-0.9662365651507683, 0.6971035339502287, -0.9411474811291295, 0.9662616471931681], Output: [-0.8267491674040199, -0.9805029412302951, -0.7988938231976473, 0.9774772012189973]\n",
      "Layer: Layer 2, Input: [-0.8267491674040199, -0.9805029412302951, -0.7988938231976473, 0.9774772012189973], Output: [-1.0150165970166585]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9274189528859907, 0.9571999011248795, 0.5631008186570279, 0.975593814676749]\n",
      "Layer: Layer 1, Input: [-0.9274189528859907, 0.9571999011248795, 0.5631008186570279, 0.975593814676749], Output: [-0.9563664068725034, -0.8055210023001075, 0.7983607369916634, 0.9981856072612614]\n",
      "Layer: Layer 2, Input: [-0.9563664068725034, -0.8055210023001075, 0.7983607369916634, 0.9981856072612614], Output: [0.9329974315460668]\n",
      "Epoch 60/100, Loss: 0.002023143410227604, Accuracy: 0.8368100299031118\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933760004688409, 0.9968230166530017, 0.7935482536261738, 0.9998105738889977]\n",
      "Layer: Layer 1, Input: [-0.9933760004688409, 0.9968230166530017, 0.7935482536261738, 0.9998105738889977], Output: [-0.9685125819071381, -0.7617635504786374, 0.8965521186185013, 0.9989367145221765]\n",
      "Layer: Layer 2, Input: [-0.9685125819071381, -0.7617635504786374, 0.8965521186185013, 0.9989367145221765], Output: [1.0355508133834488]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.998423733683029, 0.9542888300496184, -0.8770846236777264, 0.9817755073980334]\n",
      "Layer: Layer 1, Input: [-0.998423733683029, 0.9542888300496184, -0.8770846236777264, 0.9817755073980334], Output: [-0.9002823038896528, -0.973593129318321, -0.7162159904483256, 0.9877954678808464]\n",
      "Layer: Layer 2, Input: [-0.9002823038896528, -0.973593129318321, -0.7162159904483256, 0.9877954678808464], Output: [-0.9545230491259743]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662442445384236, 0.6970917138270206, -0.9411158176524544, 0.9662607268208847]\n",
      "Layer: Layer 1, Input: [-0.9662442445384236, 0.6970917138270206, -0.9411158176524544, 0.9662607268208847], Output: [-0.8267838694721783, -0.9805123484009978, -0.7991776182810831, 0.9774790478597947]\n",
      "Layer: Layer 2, Input: [-0.8267838694721783, -0.9805123484009978, -0.7991776182810831, 0.9774790478597947], Output: [-1.016305609150164]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9274605055762338, 0.9571989848738274, 0.5640964289830187, 0.9755929728804942]\n",
      "Layer: Layer 1, Input: [-0.9274605055762338, 0.9571989848738274, 0.5640964289830187, 0.9755929728804942], Output: [-0.9563971869655619, -0.8054110406513737, 0.7989920845500875, 0.9981882988685025]\n",
      "Layer: Layer 2, Input: [-0.9563971869655619, -0.8054110406513737, 0.7989920845500875, 0.9981882988685025], Output: [0.9346612855533617]\n",
      "Epoch 61/100, Loss: 0.001966758472080151, Accuracy: 0.8373279121457231\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933826317909497, 0.9968229525244867, 0.7944667903581513, 0.9998105512974057]\n",
      "Layer: Layer 1, Input: [-0.9933826317909497, 0.9968229525244867, 0.7944667903581513, 0.9998105512974057], Output: [-0.9685306240074449, -0.7616268413726239, 0.8969021051172127, 0.9989381183388291]\n",
      "Layer: Layer 2, Input: [-0.9685306240074449, -0.7616268413726239, 0.8969021051172127, 0.9989381183388291], Output: [1.0368264112438714]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984242930130364, 0.954277131111042, -0.8773588794168488, 0.9817800762209468]\n",
      "Layer: Layer 1, Input: [-0.9984242930130364, 0.954277131111042, -0.8773588794168488, 0.9817800762209468], Output: [-0.9002788658787629, -0.9736159387051038, -0.7167507462939967, 0.9877911718628973]\n",
      "Layer: Layer 2, Input: [-0.9002788658787629, -0.9736159387051038, -0.7167507462939967, 0.9877911718628973], Output: [-0.9559506293458885]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662517516390418, 0.6970799276798347, -0.9410854732096202, 0.9662595993500199]\n",
      "Layer: Layer 1, Input: [-0.9662517516390418, 0.6970799276798347, -0.9410854732096202, 0.9662595993500199], Output: [-0.8268086329886379, -0.9805204043114312, -0.7994293611921781, 0.9774805865648433]\n",
      "Layer: Layer 2, Input: [-0.8268086329886379, -0.9805204043114312, -0.7994293611921781, 0.9774805865648433], Output: [-1.0174678802271497]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9275008270693945, 0.9571980835237424, 0.5650483914675903, 0.9755920700052452]\n",
      "Layer: Layer 1, Input: [-0.9275008270693945, 0.9571980835237424, 0.5650483914675903, 0.9755920700052452], Output: [-0.9564252914347379, -0.8052917046369132, 0.799602549754705, 0.9981908585648156]\n",
      "Layer: Layer 2, Input: [-0.9564252914347379, -0.8052917046369132, 0.799602549754705, 0.9981908585648156], Output: [0.9361845354770328]\n",
      "Epoch 62/100, Loss: 0.0019185179930095424, Accuracy: 0.8378408733519002\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933890747887167, 0.9968228864348017, 0.7953422495913391, 0.9998105277567828]\n",
      "Layer: Layer 1, Input: [-0.9933890747887167, 0.9968228864348017, 0.7953422495913391, 0.9998105277567828], Output: [-0.9685469660236453, -0.7614796717824031, 0.897238642914453, 0.998939448902897]\n",
      "Layer: Layer 2, Input: [-0.9685469660236453, -0.7614796717824031, 0.897238642914453, 0.998939448902897], Output: [1.0379689815948836]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984248387290673, 0.9542657777992285, -0.8776230592887462, 0.9817844189547846]\n",
      "Layer: Layer 1, Input: [-0.9984248387290673, 0.9542657777992285, -0.8776230592887462, 0.9817844189547846], Output: [-0.9002706746091541, -0.9736364594703997, -0.7172390460931171, 0.9877869176018297]\n",
      "Layer: Layer 2, Input: [-0.9002706746091541, -0.9736364594703997, -0.7172390460931171, 0.9877869176018297], Output: [-0.957253156635108]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662591005620825, 0.6970681676004422, -0.9410563117467834, 0.966258285110762]\n",
      "Layer: Layer 1, Input: [-0.9662591005620825, 0.6970681676004422, -0.9410563117467834, 0.966258285110762], Output: [-0.8268244045760885, -0.9805272375218593, -0.7996521369220866, 0.9774818466174]\n",
      "Layer: Layer 2, Input: [-0.8268244045760885, -0.9805272375218593, -0.7996521369220866, 0.9774818466174], Output: [-1.0185150729608714]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9275400222350416, 0.9571971943415998, 0.565960735993395, 0.9755911126768742]\n",
      "Layer: Layer 1, Input: [-0.9275400222350416, 0.9571971943415998, 0.565960735993395, 0.9755911126768742], Output: [-0.9564509760255048, -0.8051638619204492, 0.8001939581443245, 0.9981932987099313]\n",
      "Layer: Layer 2, Input: [-0.9564509760255048, -0.8051638619204492, 0.8001939581443245, 0.9981932987099313], Output: [0.9375800520567703]\n",
      "Epoch 63/100, Loss: 0.001876998502249279, Accuracy: 0.8383491541361233\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9933953453453659, 0.9968228183676621, 0.796178750836721, 0.9998105033707214]\n",
      "Layer: Layer 1, Input: [-0.9933953453453659, 0.9968228183676621, 0.796178750836721, 0.9998105033707214], Output: [-0.9685617733457318, -0.7613229750208318, 0.8975629759609481, 0.9989407133007305]\n",
      "Layer: Layer 2, Input: [-0.9685617733457318, -0.7613229750208318, 0.8975629759609481, 0.9989407133007305], Output: [1.0389908968010477]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984253719502989, 0.9542547386121271, -0.8778780624705524, 0.9817885564555602]\n",
      "Layer: Layer 1, Input: [-0.9984253719502989, 0.9542547386121271, -0.8778780624705524, 0.9817885564555602], Output: [-0.9002581837574362, -0.9736549095275572, -0.7176853419166032, 0.9877827019716349]\n",
      "Layer: Layer 2, Input: [-0.9002581837574362, -0.9736549095275572, -0.7176853419166032, 0.9877827019716349], Output: [-0.9584421357111772]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662663040910728, 0.6970564266654822, -0.9410282110435471, 0.9662568025250283]\n",
      "Layer: Layer 1, Input: [-0.9662663040910728, 0.6970564266654822, -0.9410282110435471, 0.9662568025250283], Output: [-0.826832040913708, -0.9805329642783547, -0.7998487295178781, 0.9774828545581158]\n",
      "Layer: Layer 2, Input: [-0.826832040913708, -0.9805329642783547, -0.7998487295178781, 0.9774828545581158], Output: [-1.0194577943359424]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9275781860056381, 0.9571963148872552, 0.5668370915254713, 0.9755901068918418]\n",
      "Layer: Layer 1, Input: [-0.9275781860056381, 0.9571963148872552, 0.5668370915254713, 0.9755901068918418], Output: [-0.9564744711019448, -0.8050283062844726, 0.8007679529719446, 0.9981956304107297]\n",
      "Layer: Layer 2, Input: [-0.9564744711019448, -0.8050283062844726, 0.8007679529719446, 0.9981956304107297], Output: [0.9388595306660111]\n",
      "Epoch 64/100, Loss: 0.0018410272170996081, Accuracy: 0.8388529752401982\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934014578317142, 0.9968227483128665, 0.7969799848889676, 0.9998104782330337]\n",
      "Layer: Layer 1, Input: [-0.9934014578317142, 0.9968227483128665, 0.7969799848889676, 0.9998104782330337], Output: [-0.9685751945574204, -0.7611576116033045, 0.8978762172464004, 0.9989419178718881]\n",
      "Layer: Layer 2, Input: [-0.9685751945574204, -0.7611576116033045, 0.8978762172464004, 0.9989419178718881], Output: [1.039903391779406]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984258936907544, 0.9542439850511573, -0.8781246993558293, 0.9817925076092656]\n",
      "Layer: Layer 1, Input: [-0.9984258936907544, 0.9542439850511573, -0.8781246993558293, 0.9817925076092656], Output: [-0.9002418045583226, -0.9736714855713288, -0.7180936492464791, 0.9877785222372624]\n",
      "Layer: Layer 2, Input: [-0.9002418045583226, -0.9736714855713288, -0.7180936492464791, 0.9877785222372624], Output: [-0.959528022017706]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662733738099721, 0.6970446988166031, -0.9410010613203608, 0.9662551682866819]\n",
      "Layer: Layer 1, Input: [-0.9662733738099721, 0.6970446988166031, -0.9410010613203608, 0.9662551682866819], Output: [-0.8268323174904166, -0.9805376897366036, -0.8000216528633165, 0.9774836344408245]\n",
      "Layer: Layer 2, Input: [-0.8268323174904166, -0.9805376897366036, -0.8000216528633165, 0.9774836344408245], Output: [-1.0203056883728603]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9276154043358681, 0.9571954429797448, 0.5676807267804093, 0.9755890580779122]\n",
      "Layer: Layer 1, Input: [-0.9276154043358681, 0.9571954429797448, 0.5676807267804093, 0.9755890580779122], Output: [-0.9564959842582665, -0.804885763846851, 0.8013260134385608, 0.9981978636527161]\n",
      "Layer: Layer 2, Input: [-0.9564959842582665, -0.804885763846851, 0.8013260134385608, 0.9981978636527161], Output: [0.9400335968152499]\n",
      "Epoch 65/100, Loss: 0.0018096380421279445, Accuracy: 0.8393525386806896\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934074252535197, 0.9968226762650529, 0.7977492603423786, 0.9998104524286842]\n",
      "Layer: Layer 1, Input: [-0.9934074252535197, 0.9968226762650529, 0.7977492603423786, 0.9998104524286842], Output: [-0.9685873632262602, -0.7609843742242633, 0.8981793631358531, 0.9989430682920402]\n",
      "Layer: Layer 2, Input: [-0.9685873632262602, -0.7609843742242633, 0.8981793631358531, 0.9989430682920402], Output: [1.0407166677134958]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984264048693503, 0.9542334913312532, -0.8783637007567087, 0.9817962895198973]\n",
      "Layer: Layer 1, Input: [-0.9984264048693503, 0.9542334913312532, -0.8783637007567087, 0.9817962895198973], Output: [-0.9002219098312049, -0.9736863652367207, -0.7184675918451797, 0.9877743760001054]\n",
      "Layer: Layer 2, Input: [-0.9002219098312049, -0.9736863652367207, -0.7184675918451797, 0.9877743760001054], Output: [-0.9605203153952967]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662803202174451, 0.6970329787554602, -0.9409747639858148, 0.9662533975244637]\n",
      "Layer: Layer 1, Input: [-0.9662803202174451, 0.6970329787554602, -0.9409747639858148, 0.9662533975244637], Output: [-0.8268259364698743, -0.9805415090564913, -0.8001731780655501, 0.9774842080646218]\n",
      "Layer: Layer 2, Input: [-0.8268259364698743, -0.9805415090564913, -0.8001731780655501, 0.9774842080646218], Output: [-1.0210675212660938]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9276517550678817, 0.9571945766680249, 0.5684945866643554, 0.9755879711487229]\n",
      "Layer: Layer 1, Input: [-0.9276517550678817, 0.9571945766680249, 0.5684945866643554, 0.9755879711487229], Output: [-0.956515702646177, -0.8047368987639241, 0.8018694711386787, 0.998200007417013]\n",
      "Layer: Layer 2, Input: [-0.956515702646177, -0.8047368987639241, 0.8018694711386787, 0.998200007417013], Output: [0.9411119025593004]\n",
      "Epoch 66/100, Loss: 0.0017820352496651795, Accuracy: 0.8398480289750075\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993413259384168, 0.9968226022227058, 0.7984895447485401, 0.9998104260346304]\n",
      "Layer: Layer 1, Input: [-0.993413259384168, 0.9968226022227058, 0.7984895447485401, 0.9998104260346304], Output: [-0.9685983994888666, -0.7608039925313066, 0.8984733060565935, 0.9989441696459656]\n",
      "Layer: Layer 2, Input: [-0.9685983994888666, -0.7608039925313066, 0.8984733060565935, 0.9989441696459656], Output: [1.0414399864675947]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984269063189762, 0.9542232341194882, -0.8785957260832475, 0.9817999176792006]\n",
      "Layer: Layer 1, Input: [-0.9984269063189762, 0.9542232341194882, -0.8785957260832475, 0.9817999176792006], Output: [-0.9001988376147766, -0.9736997090222229, -0.7188104416579452, 0.9877702611517566]\n",
      "Layer: Layer 2, Input: [-0.9001988376147766, -0.9736997090222229, -0.7188104416579452, 0.9877702611517566], Output: [-0.961427645770502]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662871528302042, 0.6970212618517271, -0.9409492305096927, 0.9662515039493423]\n",
      "Layer: Layer 1, Input: [-0.9662871528302042, 0.6970212618517271, -0.9409492305096927, 0.9662515039493423], Output: [-0.826813533763477, -0.9805445083823168, -0.8003053578610686, 0.977484595184404]\n",
      "Layer: Layer 2, Input: [-0.826813533763477, -0.9805445083823168, -0.8003053578610686, 0.977484595184404], Output: [-1.0217512594213478]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9276873087118873, 0.9571937142054969, 0.5692813249386813, 0.9755868505528783]\n",
      "Layer: Layer 1, Input: [-0.9276873087118873, 0.9571937142054969, 0.5692813249386813, 0.9755868505528783], Output: [-0.9565337950516817, -0.8045823184595476, 0.8023995248865258, 0.9982020697845817]\n",
      "Layer: Layer 2, Input: [-0.9565337950516817, -0.8045823184595476, 0.8023995248865258, 0.9982020697845817], Output: [0.9421032145170741]\n",
      "Epoch 67/100, Loss: 0.0017575635112277537, Accuracy: 0.8403396143986336\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934189708842028, 0.9968225261873661, 0.7992035010878784, 0.9998103991205808]\n",
      "Layer: Layer 1, Input: [-0.9934189708842028, 0.9968225261873661, 0.7992035010878784, 0.9998103991205808], Output: [-0.9686084114571987, -0.7606171376714497, 0.8987588457407435, 0.9989452264919516]\n",
      "Layer: Layer 2, Input: [-0.9686084114571987, -0.7606171376714497, 0.8987588457407435, 0.9989452264919516], Output: [1.0420817565022298]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984273987947002, 0.9542131922993762, -0.8788213706250374, 0.9818034061199643]\n",
      "Layer: Layer 1, Input: [-0.9984273987947002, 0.9542131922993762, -0.8788213706250374, 0.9818034061199643], Output: [-0.90017289444946, -0.9737116620057451, -0.7191251543552784, 0.9877661758346901]\n",
      "Layer: Layer 2, Input: [-0.90017289444946, -0.9737116620057451, -0.7191251543552784, 0.9877661758346901], Output: [-0.9622578514698286]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9662938802764618, 0.6970095440624998, -0.9409243814090977, 0.9662494999878048]\n",
      "Layer: Layer 1, Input: [-0.9662938802764618, 0.6970095440624998, -0.9409243814090977, 0.9662494999878048], Output: [-0.826795685396184, -0.9805467657216147, -0.8004200483981319, 0.9774848137018499]\n",
      "Layer: Layer 2, Input: [-0.826795685396184, -0.9805467657216147, -0.8004200483981319, 0.9774848137018499], Output: [-1.0223641409023698]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9277221291505431, 0.9571928540277653, 0.570043333519276, 0.9755857003181586]\n",
      "Layer: Layer 1, Input: [-0.9277221291505431, 0.9571928540277653, 0.570043333519276, 0.9755857003181586], Output: [-0.9565504137504777, -0.8044225784173827, 0.8029172540772443, 0.9982040580291714]\n",
      "Layer: Layer 2, Input: [-0.9565504137504777, -0.8044225784173827, 0.8029172540772443, 0.9982040580291714], Output: [0.9430154941732848]\n",
      "Epoch 68/100, Loss: 0.001735683177150618, Accuracy: 0.8408274482385137\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934245694090442, 0.996822448163003, 0.7998935201337584, 0.9998103717496775]\n",
      "Layer: Layer 1, Input: [-0.9934245694090442, 0.996822448163003, 0.7998935201337584, 0.9998103717496775], Output: [-0.9686174964681152, -0.7604244265949046, 0.8990366992003277, 0.9989462429187087]\n",
      "Layer: Layer 2, Input: [-0.9686174964681152, -0.7604244265949046, 0.8990366992003277, 0.9989462429187087], Output: [1.0426496110300805]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984278829811863, 0.9542033467582589, -0.8790411720430349, 0.9818067675545061]\n",
      "Layer: Layer 1, Input: [-0.9984278829811863, 0.9542033467582589, -0.8790411720430349, 0.9818067675545061], Output: [-0.9001443583431192, -0.973722355377774, -0.7194144010396516, 0.9877621184087585]\n",
      "Layer: Layer 2, Input: [-0.9001443583431192, -0.973722355377774, -0.7194144010396516, 0.9877621184087585], Output: [-0.9630180507344357]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663005103804491, 0.6969978218616621, -0.9409001453362669, 0.9662473969024624]\n",
      "Layer: Layer 1, Input: [-0.9663005103804491, 0.6969978218616621, -0.9409001453362669, 0.9662473969024624], Output: [-0.8267729132401005, -0.980548351733919, -0.8005189287051445, 0.9774848798386412]\n",
      "Layer: Layer 2, Input: [-0.8267729132401005, -0.980548351733919, -0.8005189287051445, 0.9774848798386412], Output: [-1.022912740777673]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9277562742747422, 0.9571919947331621, 0.5707827687691057, 0.975584524091363]\n",
      "Layer: Layer 1, Input: [-0.9277562742747422, 0.9571919947331621, 0.5707827687691057, 0.975584524091363], Output: [-0.9565656961673464, -0.8042581865714346, 0.8034236307236028, 0.9982059787002926]\n",
      "Layer: Layer 2, Input: [-0.9565656961673464, -0.8042581865714346, 0.8034236307236028, 0.9982059787002926], Output: [0.9438559710906551]\n",
      "Epoch 69/100, Loss: 0.0017159498911540323, Accuracy: 0.8413116700173373\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993430063706095, 0.996822368155518, 0.8005617492086824, 0.9998103439791148]\n",
      "Layer: Layer 1, Input: [-0.993430063706095, 0.996822368155518, 0.8005617492086824, 0.9998103439791148], Output: [-0.968625742195339, -0.7602264261098289, 0.8993075095876409, 0.9989472225957551]\n",
      "Layer: Layer 2, Input: [-0.968625742195339, -0.7602264261098289, 0.8993075095876409, 0.9989472225957551], Output: [1.0431504790926733]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.998428359499398, 0.95419368019545, -0.8792556161650992, 0.9818100134998171]\n",
      "Layer: Layer 1, Input: [-0.998428359499398, 0.95419368019545, -0.8792556161650992, 0.9818100134998171], Output: [-0.9001134814517504, -0.9737319078130329, -0.7196805965703603, 0.9877580874225811]\n",
      "Layer: Layer 2, Input: [-0.9001134814517504, -0.9737319078130329, -0.7196805965703603, 0.9877580874225811], Output: [-0.9637147069780855]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663070502388507, 0.6969860921779565, -0.940876458257849, 0.9662452049012024]\n",
      "Layer: Layer 1, Input: [-0.9663070502388507, 0.6969860921779565, -0.940876458257849, 0.9662452049012024], Output: [-0.8267456901821018, -0.9805493304394169, -0.8006035181137883, 0.9774848082935632]\n",
      "Layer: Layer 2, Input: [-0.8267456901821018, -0.9805493304394169, -0.8006035181137883, 0.9774848082935632], Output: [-1.02340303083438]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9277897965575972, 0.9571911350656478, 0.5715015751030617, 0.9755833251742463]\n",
      "Layer: Layer 1, Input: [-0.9277897965575972, 0.9571911350656478, 0.5715015751030617, 0.9755833251742463], Output: [-0.9565797663617411, -0.8040896073274985, 0.803919530296037, 0.9982078376973548]\n",
      "Layer: Layer 2, Input: [-0.9565797663617411, -0.8040896073274985, 0.803919530296037, 0.9982078376973548], Output: [0.9446312096199845]\n",
      "Epoch 70/100, Loss: 0.0016979977839986192, Accuracy: 0.8417924066710166\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934354617023045, 0.9968222861723526, 0.8012101177650687, 0.9998103158606958]\n",
      "Layer: Layer 1, Input: [-0.9934354617023045, 0.9968222861723526, 0.8012101177650687, 0.9998103158606958], Output: [-0.9686332276403365, -0.7600236566874601, 0.8995718540734416, 0.9989481688180865]\n",
      "Layer: Layer 2, Input: [-0.9686332276403365, -0.7600236566874601, 0.8995718540734416, 0.9989481688180865], Output: [1.0435906501829502]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984288289126605, 0.9541841769490571, -0.8794651421664116, 0.9818131543906832]\n",
      "Layer: Layer 1, Input: [-0.9984288289126605, 0.9541841769490571, -0.8794651421664116, 0.9818131543906832], Output: [-0.900080492503499, -0.973740426699157, -0.7199259249005877, 0.987754081589051]\n",
      "Layer: Layer 2, Input: [-0.900080492503499, -0.973740426699157, -0.7199259249005877, 0.987754081589051], Output: [-0.9643536882970667]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663135062899364, 0.6969743523406638, -0.9408532627164713, 0.9662429332359962]\n",
      "Layer: Layer 1, Input: [-0.9663135062899364, 0.6969743523406638, -0.9408532627164713, 0.9662429332359962], Output: [-0.8267144447842656, -0.9805497598562256, -0.8006751918709852, 0.9774846123849732]\n",
      "Layer: Layer 2, Input: [-0.8267144447842656, -0.9805497598562256, -0.8006751918709852, 0.9774846123849732], Output: [-1.0238404341012726]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9278227435727483, 0.9571902738997551, 0.5722015061884049, 0.9755821065559588]\n",
      "Layer: Layer 1, Input: [-0.9278227435727483, 0.9571902738997551, 0.5722015061884049, 0.9755821065559588], Output: [-0.9565927363589881, -0.8039172652458619, 0.8044057414820864, 0.998209640335963]\n",
      "Layer: Layer 2, Input: [-0.9565927363589881, -0.8039172652458619, 0.8044057414820864, 0.998209640335963], Output: [0.9453471696546724]\n",
      "Epoch 71/100, Loss: 0.0016815256210718247, Accuracy: 0.8422697736675163\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934407705831556, 0.9968222022221815, 0.8018403601659998, 0.9998102874413367]\n",
      "Layer: Layer 1, Input: [-0.9934407705831556, 0.9968222022221815, 0.8018403601659998, 0.9998102874413367], Output: [-0.9686400240164227, -0.759816596021407, 0.8998302508582103, 0.9989490845458352]\n",
      "Layer: Layer 2, Input: [-0.9686400240164227, -0.759816596021407, 0.8998302508582103, 0.9989490845458352], Output: [1.0439758329870172]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984292917321406, 0.9541748228396132, -0.8796701472054536, 0.9818161996819661]\n",
      "Layer: Layer 1, Input: [-0.9984292917321406, 0.9541748228396132, -0.8796701472054536, 0.9818161996819661], Output: [-0.9000455989913753, -0.9737480092385417, -0.7201523617696722, 0.9877500997643236]\n",
      "Layer: Layer 2, Input: [-0.9000455989913753, -0.9737480092385417, -0.7201523617696722, 0.9877500997643236], Output: [-0.9649403217070511]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663198843760872, 0.6969626000319308, -0.9408305071663404, 0.966240590292362]\n",
      "Layer: Layer 1, Input: [-0.9663198843760872, 0.6969626000319308, -0.9408305071663404, 0.966240590292362], Output: [-0.8266795654892946, -0.9805496925739813, -0.8007351951440135, 0.9774843041799895]\n",
      "Layer: Layer 2, Input: [-0.8266795654892946, -0.9805496925739813, -0.8007351951440135, 0.9774843041799895], Output: [-1.024229874596971]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9278551584624846, 0.9571894102272953, 0.5728841439927259, 0.975580870942345]\n",
      "Layer: Layer 1, Input: [-0.9278551584624846, 0.9571894102272953, 0.5728841439927259, 0.975580870942345], Output: [-0.9566047073441564, -0.8037415484133489, 0.8048829749705053, 0.9982113914072474]\n",
      "Layer: Layer 2, Input: [-0.9566047073441564, -0.8037415484133489, 0.8048829749705053, 0.9982113914072474], Output: [0.946009261936599]\n",
      "Epoch 72/100, Loss: 0.0016662853871307055, Accuracy: 0.842743876059662\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934459968639294, 0.9968221163146708, 0.8024540359926491, 0.9998102587635228]\n",
      "Layer: Layer 1, Input: [-0.9934459968639294, 0.9968221163146708, 0.8024540359926491, 0.9998102587635228], Output: [-0.9686461955384984, -0.7596056823479482, 0.9000831654169632, 0.9989499724395263]\n",
      "Layer: Layer 2, Input: [-0.9686461955384984, -0.7596056823479482, 0.9000831654169632, 0.9989499724395263], Output: [1.04431120877015]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984297484218001, 0.9541656050288463, -0.8798709905772348, 0.9818191579411054]\n",
      "Layer: Layer 1, Input: [-0.9984297484218001, 0.9541656050288463, -0.8798709905772348, 0.9818191579411054], Output: [-0.9000089891574109, -0.9737547434374961, -0.7203616950498624, 0.9877461409297483]\n",
      "Layer: Layer 2, Input: [-0.9000089891574109, -0.9737547434374961, -0.7203616950498624, 0.9877461409297483], Output: [-0.9654794425486953]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663261898003521, 0.6969508332449076, -0.9408081453754685, 0.9662381836703816]\n",
      "Layer: Layer 1, Input: [-0.9663261898003521, 0.6969508332449076, -0.9408081453754685, 0.9662381836703816], Output: [-0.8266414044173424, -0.9805491762705263, -0.8007846555975473, 0.9774838946116322]\n",
      "Layer: Layer 2, Input: [-0.8266414044173424, -0.9805491762705263, -0.8007846555975473, 0.9774838946116322], Output: [-1.0245758226927233]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9278870803606204, 0.9571885431455887, 0.5735509159036608, 0.9755796207824267]\n",
      "Layer: Layer 1, Input: [-0.9278870803606204, 0.9571885431455887, 0.5735509159036608, 0.9755796207824267], Output: [-0.9566157707335856, -0.8035628115306392, 0.8053518713554618, 0.9982130952309946]\n",
      "Layer: Layer 2, Input: [-0.9566157707335856, -0.8035628115306392, 0.8053518713554618, 0.9982130952309946], Output: [0.9466223983821391]\n",
      "Epoch 73/100, Loss: 0.0016520728812299712, Accuracy: 0.8432148094679611\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934511464540227, 0.9968220284602892, 0.8030525481634071, 0.9998102298657209]\n",
      "Layer: Layer 1, Input: [-0.9934511464540227, 0.9968220284602892, 0.8030525481634071, 0.9998102298657209], Output: [-0.9686518001292498, -0.7593913175363354, 0.9003310160654694, 0.9989508348914538]\n",
      "Layer: Layer 2, Input: [-0.9686518001292498, -0.7593913175363354, 0.9003310160654694, 0.9989508348914538], Output: [1.044601479887365]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.998430199402878, 0.9541565118920852, -0.8800679974377543, 0.9818220369317961]\n",
      "Layer: Layer 1, Input: [-0.998430199402878, 0.9541565118920852, -0.8800679974377543, 0.9818220369317961], Output: [-0.899970833788649, -0.9737607089950899, -0.7205555430093316, 0.9877422041762973]\n",
      "Layer: Layer 2, Input: [-0.899970833788649, -0.9737607089950899, -0.7205555430093316, 0.9877422041762973], Output: [-0.9659754394717099]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663324273776059, 0.6969390502469618, -0.9407861358878593, 0.9662357202580798]\n",
      "Layer: Layer 1, Input: [-0.9663324273776059, 0.6969390502469618, -0.9407861358878593, 0.9662357202580798], Output: [-0.8266002807955889, -0.9805482541776819, -0.8008245946994209, 0.9774833935850311]\n",
      "Layer: Layer 2, Input: [-0.8266002807955889, -0.9805482541776819, -0.8008245946994209, 0.9774833935850311], Output: [-1.0248823364530801]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9279185447745674, 0.957187671847018, 0.5742031101201979, 0.9755783582923502]\n",
      "Layer: Layer 1, Input: [-0.9279185447745674, 0.957187671847018, 0.5742031101201979, 0.9755783582923502], Output: [-0.9566260091372883, -0.8033813787387537, 0.8058130082472079, 0.9982147557032572]\n",
      "Layer: Layer 2, Input: [-0.9566260091372883, -0.8033813787387537, 0.8058130082472079, 0.9982147557032572], Output: [0.9471910378607217]\n",
      "Epoch 74/100, Loss: 0.0016387199692195792, Accuracy: 0.8436826609919864\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934562247150065, 0.9968219386701618, 0.8036371591139626, 0.9998102007827524]\n",
      "Layer: Layer 1, Input: [-0.9934562247150065, 0.9968219386701618, 0.8036371591139626, 0.9998102007827524], Output: [-0.9686568900512521, -0.7591738699594878, 0.9005741789248507, 0.9989516740536366]\n",
      "Layer: Layer 2, Input: [-0.9686568900512521, -0.7591738699594878, 0.9005741789248507, 0.9989516740536366], Output: [1.0448509138574802]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984306450579427, 0.9541475329029561, -0.8802614621470362, 0.9818248436896989]\n",
      "Layer: Layer 1, Input: [-0.9984306450579427, 0.9541475329029561, -0.8802614621470362, 0.9818248436896989], Output: [-0.8999312878432775, -0.9737659781025844, -0.7207353707209491, 0.9877382886911145]\n",
      "Layer: Layer 2, Input: [-0.8999312878432775, -0.9737659781025844, -0.7207353707209491, 0.9877382886911145], Output: [-0.9664322953763205]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663386014808262, 0.6969272495473354, -0.94076444153966, 0.9662332062979001]\n",
      "Layer: Layer 1, Input: [-0.9663386014808262, 0.6969272495473354, -0.94076444153966, 0.9662332062979001], Output: [-0.8265564840574524, -0.9805469655014221, -0.8008559378929154, 0.9774828100737185]\n",
      "Layer: Layer 2, Input: [-0.8265564840574524, -0.9805469655014221, -0.8008559378929154, 0.9774828100737185], Output: [-1.0251530992920834]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9279495839305975, 0.9571867956097315, 0.5748418894938342, 0.9755770854770563]\n",
      "Layer: Layer 1, Input: [-0.9279495839305975, 0.9571867956097315, 0.5748418894938342, 0.9755770854770563], Output: [-0.9566354972238956, -0.8031975462066632, 0.8062669066674013, 0.9982163763390417]\n",
      "Layer: Layer 2, Input: [-0.9566354972238956, -0.8031975462066632, 0.8062669066674013, 0.9982163763390417], Output: [0.9477192278240156]\n",
      "Epoch 75/100, Loss: 0.0016260882027170735, Accuracy: 0.8441475100507725\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934612365130484, 0.9968218469559548, 0.8042090052567997, 0.9998101715461318]\n",
      "Layer: Layer 1, Input: [-0.9934612365130484, 0.9968218469559548, 0.8042090052567997, 0.9998101715461318], Output: [-0.9686615124732524, -0.7589536771563181, 0.9008129923521665, 0.9989524918627499]\n",
      "Layer: Layer 2, Input: [-0.9686615124732524, -0.7589536771563181, 0.9008129923521665, 0.9989524918627499], Output: [1.0450633834013816]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984310857345547, 0.9541386585291589, -0.8804516512723614, 0.9818275845909566]\n",
      "Layer: Layer 1, Input: [-0.9984310857345547, 0.9541386585291589, -0.8804516512723614, 0.9818275845909566], Output: [-0.8998904919233606, -0.9737706161630395, -0.7209025048184762, 0.9877343937458709]\n",
      "Layer: Layer 2, Input: [-0.8998904919233606, -0.9737706161630395, -0.7209025048184762, 0.9877343937458709], Output: [-0.9668536246618061]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663447160829579, 0.6969154298686864, -0.9407430290238854, 0.9662306474469325]\n",
      "Layer: Layer 1, Input: [-0.9663447160829579, 0.6969154298686864, -0.9407430290238854, 0.9662306474469325], Output: [-0.826510276644388, -0.9805453458011482, -0.8008795237569635, 0.9774821522069242]\n",
      "Layer: Layer 2, Input: [-0.826510276644388, -0.9805453458011482, -0.8008795237569635, 0.9774821522069242], Output: [-1.0253914542578917]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9279802270858906, 0.9571859137893495, 0.5754683039787499, 0.9755758041498958]\n",
      "Layer: Layer 1, Input: [-0.9279802270858906, 0.9571859137893495, 0.5754683039787499, 0.9755758041498958], Output: [-0.9566443024984733, -0.8030115845001936, 0.8067140367997623, 0.9982179603105995]\n",
      "Layer: Layer 2, Input: [-0.9566443024984733, -0.8030115845001936, 0.8067140367997623, 0.9982179603105995], Output: [0.9482106421515024]\n",
      "Epoch 76/100, Loss: 0.0016140635643326715, Accuracy: 0.8446094291540353\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993466186266253, 0.996821753329787, 0.8047691099119895, 0.9998101421843733]\n",
      "Layer: Layer 1, Input: [-0.993466186266253, 0.996821753329787, 0.8047691099119895, 0.9998101421843733], Output: [-0.9686657099778957, -0.7587310482973602, 0.9010477608964781, 0.9989532900623784]\n",
      "Layer: Layer 2, Input: [-0.9686657099778957, -0.7587310482973602, 0.9010477608964781, 0.9989532900623784], Output: [1.0452424028100946]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984315217485835, 0.9541298801382384, -0.880638806288353, 0.9818302654142098]\n",
      "Layer: Layer 1, Input: [-0.9984315217485835, 0.9541298801382384, -0.880638806288353, 0.9818302654142098], Output: [-0.8998485736089593, -0.9737746824395591, -0.7210581467777529, 0.9877305186866617]\n",
      "Layer: Layer 2, Input: [-0.8998485736089593, -0.9737746824395591, -0.7210581467777529, 0.9877305186866617], Output: [-0.967242707104114]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663507747947878, 0.6969035901220316, -0.9407218684988671, 0.9662280488314895]\n",
      "Layer: Layer 1, Input: [-0.9663507747947878, 0.6969035901220316, -0.9407218684988671, 0.9662280488314895], Output: [-0.8264618965397478, -0.9805434273322539, -0.8008961122614223, 0.9774814273487135]\n",
      "Layer: Layer 2, Input: [-0.8264618965397478, -0.9805434273322539, -0.8008961122614223, 0.9774814273487135], Output: [-1.0256004352351331]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9280105008106045, 0.9571850258115489, 0.5760833018332486, 0.9755745159503943]\n",
      "Layer: Layer 1, Input: [-0.9280105008106045, 0.9571850258115489, 0.5760833018332486, 0.9755745159503943], Output: [-0.9566524860023575, -0.8028237407507222, 0.8071548231599588, 0.9982195104817944]\n",
      "Layer: Layer 2, Input: [-0.9566524860023575, -0.8028237407507222, 0.8071548231599588, 0.9982195104817944], Output: [0.9486686155480274]\n",
      "Epoch 77/100, Loss: 0.0016025521409705457, Accuracy: 0.8450684846069136\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934710779874232, 0.99682165780416, 0.8053183948781455, 0.9998101127232673]\n",
      "Layer: Layer 1, Input: [-0.9934710779874232, 0.99682165780416, 0.8053183948781455, 0.9998101127232673], Output: [-0.9686695210172842, -0.7585062664654766, 0.90127875883284, 0.9989540702228966]\n",
      "Layer: Layer 2, Input: [-0.9686695210172842, -0.7585062664654766, 0.90127875883284, 0.9989540702228966], Output: [1.0453911609759343]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984319533872048, 0.9541211899123718, -0.8808231460062728, 0.9818328913967388]\n",
      "Layer: Layer 1, Input: [-0.9984319533872048, 0.9541211899123718, -0.8808231460062728, 0.9818328913967388], Output: [-0.8998056486669571, -0.9737782306396662, -0.7212033848795868, 0.9877266629252205]\n",
      "Layer: Layer 2, Input: [-0.8998056486669571, -0.9737782306396662, -0.7212033848795868, 0.9877266629252205], Output: [-0.967602518658608]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663567808992096, 0.6968917293846701, -0.9407009332360553, 0.9662254150965665]\n",
      "Layer: Layer 1, Input: [-0.9663567808992096, 0.6968917293846701, -0.9407009332360553, 0.9662254150965665], Output: [-0.8264115595610992, -0.9805412393556957, -0.8009063922121744, 0.9774806421697232]\n",
      "Layer: Layer 2, Input: [-0.8264115595610992, -0.9805412393556957, -0.8009063922121744, 0.9774806421697232], Output: [-1.0257827953318146]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9280404292428814, 0.9571841311654187, 0.5766877396996951, 0.9755732223603487]\n",
      "Layer: Layer 1, Input: [-0.9280404292428814, 0.9571841311654187, 0.5766877396996951, 0.9755732223603487], Output: [-0.9566601029431401, -0.8026342406406193, 0.8075896492424393, 0.9982210294389577]\n",
      "Layer: Layer 2, Input: [-0.9566601029431401, -0.8026342406406193, 0.8075896492424393, 0.9982210294389577], Output: [0.9490961748007818]\n",
      "Epoch 78/100, Loss: 0.0015914765617609569, Accuracy: 0.8455247371516409\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934759153226913, 0.9968215603919042, 0.8058576907924379, 0.9998100831861334]\n",
      "Layer: Layer 1, Input: [-0.9934759153226913, 0.9968215603919042, 0.8058576907924379, 0.9998100831861334], Output: [-0.9686729803220002, -0.7582795907633364, 0.9015062333205436, 0.9989548337592411]\n",
      "Layer: Layer 2, Input: [-0.9686729803220002, -0.7582795907633364, 0.9015062333205436, 0.9989548337592411], Output: [1.045512551390436]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984323809116138, 0.9541125807712965, -0.8810048687611415, 0.9818354672852965]\n",
      "Layer: Layer 1, Input: [-0.9984323809116138, 0.9541125807712965, -0.8810048687611415, 0.9818354672852965], Output: [-0.8997618221465811, -0.9737813094424366, -0.721339204992878, 0.987722825931264]\n",
      "Layer: Layer 2, Input: [-0.8997618221465811, -0.9737813094424366, -0.721339204992878, 0.987722825931264], Output: [-0.9679357594596818]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663627373822277, 0.6968798468807179, -0.9406801993032484, 0.9662227504506721]\n",
      "Layer: Layer 1, Input: [-0.9663627373822277, 0.6968798468807179, -0.9406801993032484, 0.9662227504506721], Output: [-0.8263594614346623, -0.9805388084178926, -0.8009109879700274, 0.97747980271219]\n",
      "Layer: Layer 2, Input: [-0.8263594614346623, -0.9805388084178926, -0.8009109879700274, 0.97747980271219], Output: [-1.0259410326964686]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9280700343194173, 0.9571832293974927, 0.5772823916768383, 0.9755719247184149]\n",
      "Layer: Layer 1, Input: [-0.9280700343194173, 0.9571832293974927, 0.5772823916768383, 0.9755719247184149], Output: [-0.9566672032620223, -0.802443290220961, 0.808018861696328, 0.9982225195186043]\n",
      "Layer: Layer 2, Input: [-0.9566672032620223, -0.802443290220961, 0.808018861696328, 0.9982225195186043], Output: [0.9494960671770878]\n",
      "Epoch 79/100, Loss: 0.0015807730658587362, Accuracy: 0.845978242549865\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934807015864244, 0.9968214611061352, 0.8063877464111837, 0.9998100535940478]\n",
      "Layer: Layer 1, Input: [-0.9934807015864244, 0.9968214611061352, 0.8063877464111837, 0.9998100535940478], Output: [-0.9686761192685733, -0.7580512582590536, 0.9017304072265871, 0.9989555819468096]\n",
      "Layer: Layer 2, Input: [-0.9686761192685733, -0.7580512582590536, 0.9017304072265871, 0.9989555819468096], Output: [1.0456091993856294]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984328045594779, 0.9541040463025849, -0.8811841543820373, 0.9818379973821391]\n",
      "Layer: Layer 1, Input: [-0.9984328045594779, 0.9541040463025849, -0.8811841543820373, 0.9818379973821391], Output: [-0.8997171893724237, -0.9737839629742828, -0.7214665003007165, 0.9877190072258072]\n",
      "Layer: Layer 2, Input: [-0.8997171893724237, -0.9737839629742828, -0.7214665003007165, 0.9877190072258072], Output: [-0.968244879266359]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663686469610064, 0.6968679419639339, -0.9406596452797087, 0.9662200587064644]\n",
      "Layer: Layer 1, Input: [-0.9663686469610064, 0.6968679419639339, -0.9406596452797087, 0.9662200587064644], Output: [-0.8263057796731044, -0.9805361586039091, -0.8009104655179514, 0.9774789144488912]\n",
      "Layer: Layer 2, Input: [-0.8263057796731044, -0.9805361586039091, -0.8009104655179514, 0.9774789144488912], Output: [-1.0260774139913313]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9280993359839608, 0.9571823201063815, 0.5778679574865326, 0.9755706242333345]\n",
      "Layer: Layer 1, Input: [-0.9280993359839608, 0.9571823201063815, 0.5778679574865326, 0.9755706242333345], Output: [-0.9566738321449749, -0.802251077575724, 0.8084427740774245, 0.998223982832333]\n",
      "Layer: Layer 2, Input: [-0.9566738321449749, -0.802251077575724, 0.8084427740774245, 0.998223982832333], Output: [0.9498707862202028]\n",
      "Epoch 80/100, Loss: 0.0015703890890155243, Accuracy: 0.8464290521096012\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934854397927682, 0.9968213599602206, 0.806909236927366, 0.9998100239660509]\n",
      "Layer: Layer 1, Input: [-0.9934854397927682, 0.9968213599602206, 0.806909236927366, 0.9998100239660509], Output: [-0.9686789662097967, -0.7578214857810155, 0.9019514816506713, 0.9989563159356926]\n",
      "Layer: Layer 2, Input: [-0.9686789662097967, -0.7578214857810155, 0.9019514816506713, 0.9989563159356926], Output: [1.0456834868704141]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984332245471584, 0.9540955806985582, -0.8813611659680601, 0.9818404855867157]\n",
      "Layer: Layer 1, Input: [-0.9984332245471584, 0.9540955806985582, -0.8813611659680601, 0.9818404855867157], Output: [-0.8996718368447104, -0.9737862312386251, -0.7215860800783573, 0.9877152063753133]\n",
      "Layer: Layer 2, Input: [-0.8996718368447104, -0.9737862312386251, -0.7215860800783573, 0.9877152063753133], Output: [-0.9685321005819736]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663745121092554, 0.6968560141025596, -0.9406392519999773, 0.9662173433175923]\n",
      "Layer: Layer 1, Input: [-0.9663745121092554, 0.6968560141025596, -0.9406392519999773, 0.9662173433175923], Output: [-0.8262506752757699, -0.9805333117665743, -0.8009053379429272, 0.9774779823365692]\n",
      "Layer: Layer 2, Input: [-0.8262506752757699, -0.9805333117665743, -0.8009053379429272, 0.9774779823365692], Output: [-1.0261939957288049]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9281283523758745, 0.9571814029379343, 0.5784450698262954, 0.9755693219959309]\n",
      "Layer: Layer 1, Input: [-0.9281283523758745, 0.9571814029379343, 0.5784450698262954, 0.9755693219959309], Output: [-0.9566800304834396, -0.8020577743454721, 0.8088616702187514, 0.9982254212892098]\n",
      "Layer: Layer 2, Input: [-0.9566800304834396, -0.8020577743454721, 0.8088616702187514, 0.9982254212892098], Output: [0.9502225951780768]\n",
      "Epoch 81/100, Loss: 0.0015602812773671485, Accuracy: 0.8468772131608314\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934901326841562, 0.9968212569677516, 0.807422771428179, 0.9998099943193344]\n",
      "Layer: Layer 1, Input: [-0.9934901326841562, 0.9968212569677516, 0.807422771428179, 0.9998099943193344], Output: [-0.9686815467717943, -0.7575904715724433, 0.9021696381839124, 0.9989570367634195]\n",
      "Layer: Layer 2, Input: [-0.9686815467717943, -0.7575904715724433, 0.9021696381839124, 0.9989570367634195], Output: [1.045737574791143]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984336410717187, 0.9540871786991936, -0.8815360514899633, 0.9818429354334282]\n",
      "Layer: Layer 1, Input: [-0.9984336410717187, 0.9540871786991936, -0.8815360514899633, 0.9818429354334282], Output: [-0.899625843055604, -0.9737881505041097, -0.7216986776198874, 0.9877114229865659]\n",
      "Layer: Layer 2, Input: [-0.899625843055604, -0.9737881505041097, -0.7216986776198874, 0.9877114229865659], Output: [-0.9687994396565723]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663803350801954, 0.6968440628659242, -0.9406190023235238, 0.9662146074120951]\n",
      "Layer: Layer 1, Input: [-0.9663803350801954, 0.6968440628659242, -0.9406190023235238, 0.9662146074120951], Output: [-0.8261942942684937, -0.9805302877338997, -0.8008960703914403, 0.9774770108643537]\n",
      "Layer: Layer 2, Input: [-0.8261942942684937, -0.9805302877338997, -0.8008960703914403, 0.9774770108643537], Output: [-1.0262926436611588]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9281571000006853, 0.9571804775808705, 0.5790143009897013, 0.9755680189899917]\n",
      "Layer: Layer 1, Input: [-0.9281571000006853, 0.9571804775808705, 0.5790143009897013, 0.9755680189899917], Output: [-0.9566858352896895, -0.8018635371224327, 0.8092758072579281, 0.9982268366158891]\n",
      "Layer: Layer 2, Input: [-0.9566858352896895, -0.8018635371224327, 0.8092758072579281, 0.9982268366158891], Output: [0.950553548279477]\n",
      "Epoch 82/100, Loss: 0.0015504138529904895, Accuracy: 0.8473227694837475\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934947827570833, 0.9968211521425208, 0.8079288995840752, 0.9998099646694122]\n",
      "Layer: Layer 1, Input: [-0.9934947827570833, 0.9968211521425208, 0.8079288995840752, 0.9998099646694122], Output: [-0.9686838841213156, -0.757358396815728, 0.9023850409298664, 0.9989577453663804]\n",
      "Layer: Layer 2, Input: [-0.9686838841213156, -0.757358396815728, 0.9023850409298664, 0.9989577453663804], Output: [1.045773423524803]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984340543127415, 0.9540788355404523, -0.8817089452352449, 0.9818453501258387]\n",
      "Layer: Layer 1, Input: [-0.9984340543127415, 0.9540788355404523, -0.8817089452352449, 0.9818453501258387], Output: [-0.8995792792294824, -0.9737897536555369, -0.7218049573997767, 0.9877076567021643]\n",
      "Layer: Layer 2, Input: [-0.8995792792294824, -0.9737897536555369, -0.7218049573997767, 0.9877076567021643], Output: [-0.9690487255627035]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663861179273441, 0.696832087912605, -0.9405988809276405, 0.966211853822688]\n",
      "Layer: Layer 1, Input: [-0.9663861179273441, 0.696832087912605, -0.9405988809276405, 0.966211853822688], Output: [-0.8261367690984356, -0.9805271044969212, -0.8008830845512674, 0.9774760040976476]\n",
      "Layer: Layer 2, Input: [-0.8261367690984356, -0.9805271044969212, -0.8008830845512674, 0.9774760040976476], Output: [-1.026375050397387]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9281855938843564, 0.9571795437628304, 0.5795761688281976, 0.9755667161021426]\n",
      "Layer: Layer 1, Input: [-0.9281855938843564, 0.9571795437628304, 0.5795761688281976, 0.9755667161021426], Output: [-0.9566912800714303, -0.8016685087278494, 0.8096854183558848, 0.9982282303747098]\n",
      "Layer: Layer 2, Input: [-0.9566912800714303, -0.8016685087278494, 0.8096854183558848, 0.9982282303747098], Output: [0.9508655100530091]\n",
      "Epoch 83/100, Loss: 0.0015407572690723723, Accuracy: 0.8477657616935226\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9934993922854022, 0.9968210454985021, 0.8084281176505869, 0.9998099350302752]\n",
      "Layer: Layer 1, Input: [-0.9934993922854022, 0.9968210454985021, 0.8084281176505869, 0.9998099350302752], Output: [-0.9686859992063331, -0.7571254270360376, 0.9025978383132756, 0.9989584425900645]\n",
      "Layer: Layer 2, Input: [-0.9686859992063331, -0.7571254270360376, 0.9025978383132756, 0.9989584425900645], Output: [1.0457928113943187]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984344644339744, 0.9540705469075037, -0.8818799691125678, 0.981847732567659]\n",
      "Layer: Layer 1, Input: [-0.9984344644339744, 0.9540705469075037, -0.8818799691125678, 0.981847732567659], Output: [-0.8995322099943617, -0.9737910705112109, -0.7219055215461772, 0.9877039071965584]\n",
      "Layer: Layer 2, Input: [-0.8995322099943617, -0.9737910705112109, -0.7219055215461772, 0.9877039071965584], Output: [-0.9692816175186975]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663918625233255, 0.6968200889799574, -0.9405788741212602, 0.966209085114225]\n",
      "Layer: Layer 1, Input: [-0.9663918625233255, 0.6968200889799574, -0.9405788741212602, 0.966209085114225], Output: [-0.8260782198978265, -0.9805237783798654, -0.8008667627065874, 0.9774749657179014]\n",
      "Layer: Layer 2, Input: [-0.8260782198978265, -0.9805237783798654, -0.8008667627065874, 0.9774749657179014], Output: [-1.0264427514062957]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9282138477128504, 0.957178601246799, 0.5801311421203981, 0.9755654141308105]\n",
      "Layer: Layer 1, Input: [-0.9282138477128504, 0.957178601246799, 0.5801311421203981, 0.9755654141308105], Output: [-0.9566963951697312, -0.8014728193815659, 0.8100907151380243, 0.9982296039799717]\n",
      "Layer: Layer 2, Input: [-0.9566963951697312, -0.8014728193815659, 0.8100907151380243, 0.9982296039799717], Output: [0.9511601728672713]\n",
      "Epoch 84/100, Loss: 0.001531287103488304, Accuracy: 0.8482062275853544\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935039633413909, 0.9968209370498354, 0.8089208738552144, 0.9998099054145313]\n",
      "Layer: Layer 1, Input: [-0.9935039633413909, 0.9968209370498354, 0.8089208738552144, 0.9998099054145313], Output: [-0.9686879109726998, -0.7568917133931365, 0.9028081646991548, 0.998959129198244]\n",
      "Layer: Layer 2, Input: [-0.9686879109726998, -0.7568917133931365, 0.9028081646991548, 0.998959129198244], Output: [1.0457973514782857]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984348715848191, 0.9540623088923791, -0.8820492338296672, 0.9818500853908283]\n",
      "Layer: Layer 1, Input: [-0.9984348715848191, 0.9540623088923791, -0.8820492338296672, 0.9818500853908283], Output: [-0.8994846939909364, -0.9737921281100366, -0.7220009156945958, 0.9877001741725552]\n",
      "Layer: Layer 2, Input: [-0.8994846939909364, -0.9737921281100366, -0.7220009156945958, 0.9877001741725552], Output: [-0.9694996206182992]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9663975705768931, 0.6968080658748468, -0.9405589696776006, 0.9662063036086023]\n",
      "Layer: Layer 1, Input: [-0.9663975705768931, 0.6968080658748468, -0.9405589696776006, 0.9662063036086023], Output: [-0.8260187556291573, -0.9805203241943516, -0.8008474514084872, 0.9774738990586609]\n",
      "Layer: Layer 2, Input: [-0.8260187556291573, -0.9805203241943516, -0.8008474514084872, 0.9774738990586609], Output: [-1.0264971395511875]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9282418739583943, 0.9571776498278642, 0.5806796454081797, 0.9755641137943595]\n",
      "Layer: Layer 1, Input: [-0.9282418739583943, 0.9571776498278642, 0.5806796454081797, 0.9755641137943595], Output: [-0.9567012080639573, -0.8012765877729557, 0.8104918898858587, 0.9982309587125798]\n",
      "Layer: Layer 2, Input: [-0.9567012080639573, -0.8012765877729557, 0.8104918898858587, 0.9982309587125798], Output: [0.9514390728544789]\n",
      "Epoch 85/100, Loss: 0.001521983148620256, Accuracy: 0.848644202443305\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935084978148011, 0.9968208268108103, 0.8094075732337539, 0.9998098758335331]\n",
      "Layer: Layer 1, Input: [-0.9935084978148011, 0.9968208268108103, 0.8094075732337539, 0.9998098758335331], Output: [-0.9686896365593097, -0.7566573938698192, 0.9030161418423563, 0.9989598058812121]\n",
      "Layer: Layer 2, Input: [-0.9686896365593097, -0.7566573938698192, 0.9030161418423563, 0.9989598058812121], Output: [1.0457885068717596]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.998435275901677, 0.9540541179556287, -0.8822168399574009, 0.9818524109809555]\n",
      "Layer: Layer 1, Input: [-0.998435275901677, 0.9540541179556287, -0.8822168399574009, 0.9818524109809555], Output: [-0.8994367844251003, -0.9737929509713348, -0.7220916342833062, 0.9876964573582316]\n",
      "Layer: Layer 2, Input: [-0.8994367844251003, -0.9737929509713348, -0.7220916342833062, 0.9876964573582316], Output: [-0.9697041001114995]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664032436483349, 0.6967960184654459, -0.9405391566837472, 0.9662035114073445]\n",
      "Layer: Layer 1, Input: [-0.9664032436483349, 0.6967960184654459, -0.9405391566837472, 0.9662035114073445], Output: [-0.8259584751230934, -0.9805167553791628, -0.8008254647985339, 0.9774728071382348]\n",
      "Layer: Layer 2, Input: [-0.8259584751230934, -0.9805167553791628, -0.8008254647985339, 0.9774728071382348], Output: [-1.026539478288862]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9282696839937266, 0.9571766893302744, 0.5812220633528911, 0.9755628157384771]\n",
      "Layer: Layer 1, Input: [-0.9282696839937266, 0.9571766893302744, 0.5812220633528911, 0.9755628157384771], Output: [-0.9567057436469869, -0.8010799220415228, 0.8108891175043685, 0.9982322957332217]\n",
      "Layer: Layer 2, Input: [-0.9567057436469869, -0.8010799220415228, 0.8108891175043685, 0.9982322957332217], Output: [0.9517036043653915]\n",
      "Epoch 86/100, Loss: 0.0015128286626847067, Accuracy: 0.8490797193162695\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935129974300848, 0.9968207147958529, 0.8098885819734457, 0.9998098462974936]\n",
      "Layer: Layer 1, Input: [-0.9935129974300848, 0.9968207147958529, 0.8098885819734457, 0.9998098462974936], Output: [-0.9686911914739537, -0.7564225943648057, 0.9032218801855633, 0.9989604732631775]\n",
      "Layer: Layer 2, Input: [-0.9686911914739537, -0.7564225943648057, 0.9032218801855633, 0.9989604732631775], Output: [1.045767604540436]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984356775091704, 0.9540459708916019, -0.8823828788912672, 0.9818547115003748]\n",
      "Layer: Layer 1, Input: [-0.9984356775091704, 0.9540459708916019, -0.8823828788912672, 0.9818547115003748], Output: [-0.8993885295692384, -0.9737935613300472, -0.7221781253454389, 0.9876927565042064]\n",
      "Layer: Layer 2, Input: [-0.8993885295692384, -0.9737935613300472, -0.7221781253454389, 0.9876927565042064], Output: [-0.9698962943686081]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664088831634182, 0.6967839466739673, -0.9405194254054763, 0.9662007104120895]\n",
      "Layer: Layer 1, Input: [-0.9664088831634182, 0.6967839466739673, -0.9405194254054763, 0.9662007104120895], Output: [-0.8258974680193089, -0.9805130841269706, -0.8008010876191911, 0.9774716926893006]\n",
      "Layer: Layer 2, Input: [-0.8258974680193089, -0.9805130841269706, -0.8008010876191911, 0.9774716926893006], Output: [-1.026570913654044]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9282972881954725, 0.957175719604765, 0.5817587446595744, 0.9755615205428833]\n",
      "Layer: Layer 1, Input: [-0.9282972881954725, 0.957175719604765, 0.5817587446595744, 0.9755615205428833], Output: [-0.9567100244736613, -0.8008829206747982, 0.8112825572878181, 0.9982336160942271]\n",
      "Layer: Layer 2, Input: [-0.9567100244736613, -0.8008829206747982, 0.8112825572878181, 0.9982336160942271], Output: [0.9519550330900736]\n",
      "Epoch 87/100, Loss: 0.0015038097539744556, Accuracy: 0.8495128092642017\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935174637619753, 0.9968206010195135, 0.8103642313141384, 0.9998098168155917]\n",
      "Layer: Layer 1, Input: [-0.9935174637619753, 0.9968206010195135, 0.8103642313141384, 0.9998098168155917], Output: [-0.9686925897518228, -0.7561874296974307, 0.9034254800217185, 0.9989611319089028]\n",
      "Layer: Layer 2, Input: [-0.9686925897518228, -0.7561874296974307, 0.9034254800217185, 0.9989611319089028], Output: [1.0457358478975671]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984360765212447, 0.9540378647970043, -0.8825474337205295, 0.981856988909039]\n",
      "Layer: Layer 1, Input: [-0.9984360765212447, 0.9540378647970043, -0.8825474337205295, 0.981856988909039], Output: [-0.8993399732170843, -0.9737939793497219, -0.7222607948469841, 0.9876890713812219]\n",
      "Layer: Layer 2, Input: [-0.8993399732170843, -0.9737939793497219, -0.7222607948469841, 0.9876890713812219], Output: [-0.9700773266477953]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664144904260101, 0.6967718504702233, -0.9404997671657878, 0.9661979023431672]\n",
      "Layer: Layer 1, Input: [-0.9664144904260101, 0.6967718504702233, -0.9404997671657878, 0.9661979023431672], Output: [-0.8258358156194315, -0.980509321499253, -0.8007745779414057, 0.9774705581857333]\n",
      "Layer: Layer 2, Input: [-0.8258358156194315, -0.980509321499253, -0.8007745779414057, 0.9774705581857333], Output: [-1.0265924851396724]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.928324696037697, 0.9571747405261273, 0.5822900056122772, 0.9755602287274222]\n",
      "Layer: Layer 1, Input: [-0.928324696037697, 0.9571747405261273, 0.5822900056122772, 0.9755602287274222], Output: [-0.9567140709851165, -0.80068567333051, 0.8116723545044895, 0.9982349207502442]\n",
      "Layer: Layer 2, Input: [-0.9567140709851165, -0.80068567333051, 0.8116723545044895, 0.9982349207502442], Output: [0.9521945079668857]\n",
      "Epoch 88/100, Loss: 0.0014949148744709977, Accuracy: 0.8499435015774415\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935218982495797, 0.9968204854964541, 0.8108348210531787, 0.9998097873960667]\n",
      "Layer: Layer 1, Input: [-0.9935218982495797, 0.9968204854964541, 0.8108348210531787, 0.9998097873960667], Output: [-0.9686938440984115, -0.7559520045309531, 0.9036270325351777, 0.9989617823296656]\n",
      "Layer: Layer 2, Input: [-0.9686938440984115, -0.7559520045309531, 0.9036270325351777, 0.9989617823296656], Output: [1.0456943282211175]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984364730421688, 0.9540297970424192, -0.882710580014043, 0.9818592449834556]\n",
      "Layer: Layer 1, Input: [-0.9984364730421688, 0.9540297970424192, -0.882710580014043, 0.9818592449834556], Output: [-0.8992911550964771, -0.973794223315428, -0.7223400106148903, 0.9876854017780002]\n",
      "Layer: Layer 2, Input: [-0.8992911550964771, -0.973794223315428, -0.7223400106148903, 0.9876854017780002], Output: [-0.9702482157756105]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664200666295012, 0.6967597298659178, -0.9404801742357728, 0.9661950887564527]\n",
      "Layer: Layer 1, Input: [-0.9664200666295012, 0.6967597298659178, -0.9404801742357728, 0.9661950887564527], Output: [-0.8257735916604054, -0.980505477530532, -0.8007461696366039, 0.9774694058669188]\n",
      "Layer: Layer 2, Input: [-0.8257735916604054, -0.980505477530532, -0.8007461696366039, 0.9774694058669188], Output: [-1.0266051355736785]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9283519161765669, 0.9571737519909959, 0.5828161332591882, 0.9755589407575966]\n",
      "Layer: Layer 1, Input: [-0.9283519161765669, 0.9571737519909959, 0.5828161332591882, 0.9755589407575966], Output: [-0.9567179017113724, -0.8004882615893995, 0.8120586418187598, 0.9982362105678504]\n",
      "Layer: Layer 2, Input: [-0.9567179017113724, -0.8004882615893995, 0.8120586418187598, 0.9982362105678504], Output: [0.9524230719910274]\n",
      "Epoch 89/100, Loss: 0.0014861344034446564, Accuracy: 0.8503718239718419\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935263022091276, 0.9968203682414366, 0.811300622694879, 0.9998097580463065]\n",
      "Layer: Layer 1, Input: [-0.9935263022091276, 0.9968203682414366, 0.811300622694879, 0.9998097580463065], Output: [-0.9686949660183828, -0.755716414220828, 0.9038266207343382, 0.998962424988613]\n",
      "Layer: Layer 2, Input: [-0.9686949660183828, -0.755716414220828, 0.9038266207343382, 0.998962424988613], Output: [1.045644035017908]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984368671674376, 0.9540217652465143, -0.8828723865309414, 0.98186148133385]\n",
      "Layer: Layer 1, Input: [-0.9984368671674376, 0.9540217652465143, -0.8828723865309414, 0.98186148133385], Output: [-0.8992421112439453, -0.9737943098085358, -0.7224161058949351, 0.987681747499339]\n",
      "Layer: Layer 2, Input: [-0.8992421112439453, -0.9737943098085358, -0.7224161058949351, 0.987681747499339], Output: [-0.9704098858401119]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664256128671462, 0.6967475849095848, -0.94046063973657, 0.9661922710586532]\n",
      "Layer: Layer 1, Input: [-0.9664256128671462, 0.6967475849095848, -0.94046063973657, 0.9661922710586532], Output: [-0.8257108630157745, -0.9805015613229373, -0.8007160746176005, 0.9774682377597863]\n",
      "Layer: Layer 2, Input: [-0.8257108630157745, -0.9805015613229373, -0.8007160746176005, 0.9774682377597863], Output: [-1.0266097200839353]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9283789565269776, 0.957172753915834, 0.5833373882824376, 0.9755576570495947]\n",
      "Layer: Layer 1, Input: [-0.9283789565269776, 0.957172753915834, 0.5833373882824376, 0.9755576570495947], Output: [-0.9567215334543149, -0.8002907596445316, 0.8124415405670873, 0.9982374863342071]\n",
      "Layer: Layer 2, Input: [-0.9567215334543149, -0.8002907596445316, 0.8124415405670873, 0.9982374863342071], Output: [0.9526416720238455]\n",
      "Epoch 90/100, Loss: 0.0014774603050884043, Accuracy: 0.8507978027621143\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935306768455037, 0.9968202492693115, 0.8117618822810878, 0.9998097287729246]\n",
      "Layer: Layer 1, Input: [-0.9935306768455037, 0.9968202492693115, 0.8117618822810878, 0.9998097287729246], Output: [-0.9686959659318036, -0.7554807455938333, 0.9040243202871412, 0.9989630603055728]\n",
      "Layer: Layer 2, Input: [-0.9686959659318036, -0.7554807455938333, 0.9040243202871412, 0.9989630603055728], Output: [1.0455858654317076]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984372589845928, 0.9540137672526754, -0.8830329158635116, 0.9818636994197212]\n",
      "Layer: Layer 1, Input: [-0.9984372589845928, 0.9540137672526754, -0.8830329158635116, 0.9818636994197212], Output: [-0.899192874344671, -0.973794253865101, -0.7224893825750425, 0.9876781083644173]\n",
      "Layer: Layer 2, Input: [-0.899192874344671, -0.973794253865101, -0.7224893825750425, 0.9876781083644173], Output: [-0.9705631749872642]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664311301414235, 0.6967354156820964, -0.9404411575512999, 0.9661894505211751]\n",
      "Layer: Layer 1, Input: [-0.9664311301414235, 0.6967354156820964, -0.9404411575512999, 0.9661894505211751], Output: [-0.8256476903316698, -0.9804975811320098, -0.8006844848704815, 0.9774670556987732]\n",
      "Layer: Layer 2, Input: [-0.8256476903316698, -0.9804975811320098, -0.8006844848704815, 0.9774670556987732], Output: [-1.0266070142348345]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9284058243319093, 0.9571717462350967, 0.5838540075839126, 0.9755563779748575]\n",
      "Layer: Layer 1, Input: [-0.9284058243319093, 0.9571717462350967, 0.5838540075839126, 0.9755563779748575], Output: [-0.9567249814529958, -0.8000932349324383, 0.8128211619028161, 0.9982387487648523]\n",
      "Layer: Layer 2, Input: [-0.9567249814529958, -0.8000932349324383, 0.8128211619028161, 0.9982387487648523], Output: [0.9528511676949024]\n",
      "Epoch 91/100, Loss: 0.0014688858470537705, Accuracy: 0.8512214630156245\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935350232626832, 0.9968201285950065, 0.8122188229355504, 0.9998096995818333]\n",
      "Layer: Layer 1, Input: [-0.9935350232626832, 0.9968201285950065, 0.8122188229355504, 0.9998096995818333], Output: [-0.9686968532790062, -0.7552450776635017, 0.9042202002696281, 0.998963688661377]\n",
      "Layer: Layer 2, Input: [-0.9686968532790062, -0.7552450776635017, 0.9042202002696281, 0.998963688661377], Output: [1.045520632783329]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984376485739623, 0.954005801107841, -0.8831922250188504, 0.9818659005639434]\n",
      "Layer: Layer 1, Input: [-0.9984376485739623, 0.954005801107841, -0.8831922250188504, 0.9818659005639434], Output: [-0.8991434740410534, -0.9737940691194168, -0.7225601141061415, 0.9876744842052887]\n",
      "Layer: Layer 2, Input: [-0.8991434740410534, -0.9737940691194168, -0.7225601141061415, 0.9876744842052887], Output: [-0.9707088434030506]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664366193725104, 0.6967232222926805, -0.940421722245968, 0.9661866282927032]\n",
      "Layer: Layer 1, Input: [-0.9664366193725104, 0.6967232222926805, -0.940421722245968, 0.9661866282927032], Output: [-0.8255841286036341, -0.9804935444445679, -0.800651574297325, 0.9774658613439173]\n",
      "Layer: Layer 2, Input: [-0.8255841286036341, -0.9804935444445679, -0.800651574297325, 0.9774658613439173], Output: [-1.0265977214114463]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9284325262252071, 0.9571707288995568, 0.5843662066152997, 0.9755551038642283]\n",
      "Layer: Layer 1, Input: [-0.9284325262252071, 0.9571707288995568, 0.5843662066152997, 0.9755551038642283], Output: [-0.956728259532978, -0.7998957487109893, 0.8131976078232058, 0.9982399985107206]\n",
      "Layer: Layer 2, Input: [-0.956728259532978, -0.7998957487109893, 0.8131976078232058, 0.9982399985107206], Output: [0.9530523394804186]\n",
      "Epoch 92/100, Loss: 0.00146040536908112, Accuracy: 0.8516428286886938\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935393424731715, 0.9968200062335159, 0.8126716471513196, 0.9998096704783076]\n",
      "Layer: Layer 1, Input: [-0.9935393424731715, 0.9968200062335159, 0.8126716471513196, 0.9998096704783076], Output: [-0.9686976366152072, -0.7550094822869208, 0.9044143238366542, 0.9989643104017468]\n",
      "Layer: Layer 2, Input: [-0.9686976366152072, -0.7550094822869208, 0.9044143238366542, 0.9989643104017468], Output: [1.045449074322705]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984380360093321, 0.9539978650433263, -0.8833503659452208, 0.9818680859655473]\n",
      "Layer: Layer 1, Input: [-0.9984380360093321, 0.9539978650433263, -0.8833503659452208, 0.9818680859655473], Output: [-0.8990939372127889, -0.9737937679341507, -0.7226285481494705, 0.9876708748655375]\n",
      "Layer: Layer 2, Input: [-0.8990939372127889, -0.9737937679341507, -0.7226285481494705, 0.9876708748655375], Output: [-0.9708475805562632]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664420814059526, 0.6967110048753848, -0.9404023289984333, 0.9661838054106131]\n",
      "Layer: Layer 1, Input: [-0.9664420814059526, 0.6967110048753848, -0.9404023289984333, 0.9661838054106131], Output: [-0.8255202276998291, -0.9804894580493821, -0.800617500387679, 0.9774646561972508]\n",
      "Layer: Layer 2, Input: [-0.8255202276998291, -0.9804894580493821, -0.800617500387679, 0.9774646561972508], Output: [-1.0265824795203677]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9284590682884121, 0.9571697018747777, 0.5848741814777406, 0.9755538350117232]\n",
      "Layer: Layer 1, Input: [-0.9284590682884121, 0.9571697018747777, 0.5848741814777406, 0.9755538350117232], Output: [-0.9567313802412835, -0.7996983565884698, 0.813570972090736, 0.998241236164464]\n",
      "Layer: Layer 2, Input: [-0.9567313802412835, -0.7996983565884698, 0.813570972090736, 0.998241236164464], Output: [0.9532458960340451]\n",
      "Epoch 93/100, Loss: 0.0014520140928311037, Accuracy: 0.8520619227472356\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.993543635406549, 0.9968198821998893, 0.8131205388474322, 0.999809641467045]\n",
      "Layer: Layer 1, Input: [-0.993543635406549, 0.9968198821998893, 0.8131205388474322, 0.999809641467045], Output: [-0.9686983236958976, -0.7547740247675652, 0.9046067488229019, 0.9989649258407869]\n",
      "Layer: Layer 2, Input: [-0.9686983236958976, -0.7547740247675652, 0.9046067488229019, 0.9989649258407869], Output: [1.0453718582655664]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.998438421358554, 0.953989957457451, -0.88350738600845, 0.9818702567113077]\n",
      "Layer: Layer 1, Input: [-0.998438421358554, 0.953989957457451, -0.88350738600845, 0.9818702567113077], Output: [-0.899044288231112, -0.9737933615183343, -0.7226949089763729, 0.98766728019908]\n",
      "Layer: Layer 2, Input: [-0.899044288231112, -0.9737933615183343, -0.7226949089763729, 0.98766728019908], Output: [-0.9709800117701083]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664475170196101, 0.6966987635859394, -0.9403829735346273, 0.9661809828113245]\n",
      "Layer: Layer 1, Input: [-0.9664475170196101, 0.6966987635859394, -0.9403829735346273, 0.9661809828113245], Output: [-0.8254560328356493, -0.980485328101328, -0.8005824057349603, 0.9774634416176562]\n",
      "Layer: Layer 2, Input: [-0.8254560328356493, -0.980485328101328, -0.8005824057349603, 0.9774634416176562], Output: [-1.0265618670701078]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9284854561022102, 0.9571686651397193, 0.5853781108139637, 0.9755525716779577]\n",
      "Layer: Layer 1, Input: [-0.9284854561022102, 0.9571686651397193, 0.5853781108139637, 0.9755525716779577], Output: [-0.9567343549683444, -0.7995011090079647, 0.8139413410595198, 0.9982424622661477]\n",
      "Layer: Layer 2, Input: [-0.9567343549683444, -0.7995011090079647, 0.8139413410595198, 0.9982424622661477], Output: [0.95343248083898]\n",
      "Epoch 94/100, Loss: 0.0014437079655989357, Accuracy: 0.8524787672734141\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935479029172009, 0.996819756509221, 0.8135656652183387, 0.9998096125522187]\n",
      "Layer: Layer 1, Input: [-0.9935479029172009, 0.996819756509221, 0.8135656652183387, 0.9998096125522187], Output: [-0.9686989215539173, -0.7545387644084861, 0.9047975282814749, 0.9989655352641256]\n",
      "Layer: Layer 2, Input: [-0.9686989215539173, -0.7545387644084861, 0.9047975282814749, 0.9989655352641256], Output: [1.04528959018067]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984388046840943, 0.9539820768997993, -0.8836633284231715, 0.9818724137862475]\n",
      "Layer: Layer 1, Input: [-0.9984388046840943, 0.9539820768997993, -0.8836633284231715, 0.9818724137862475], Output: [-0.8989945491895895, -0.9737928600343586, -0.7227593996440711, 0.9876637000690949]\n",
      "Layer: Layer 2, Input: [-0.8989945491895895, -0.9737928600343586, -0.7227593996440711, 0.9876637000690949], Output: [-0.9711067041845473]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664529269299443, 0.696686498598972, -0.9403636520712918, 0.9661781613396933]\n",
      "Layer: Layer 1, Input: [-0.9664529269299443, 0.696686498598972, -0.9403636520712918, 0.9661781613396933], Output: [-0.8253915850042826, -0.9804811601796274, -0.8005464194123617, 0.977462218834327]\n",
      "Layer: Layer 2, Input: [-0.8253915850042826, -0.9804811601796274, -0.8005464194123617, 0.977462218834327], Output: [-1.026536408688139]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9285116947930109, 0.9571676186854666, 0.5858781575134651, 0.9755513140932593]\n",
      "Layer: Layer 1, Input: [-0.9285116947930109, 0.9571676186854666, 0.5858781575134651, 0.9755513140932593], Output: [-0.9567371940582234, -0.7993040516908048, 0.8143087944165649, 0.9982436773083806]\n",
      "Layer: Layer 2, Input: [-0.9567371940582234, -0.7993040516908048, 0.8143087944165649, 0.9982436773083806], Output: [0.9536126782441053]\n",
      "Epoch 95/100, Loss: 0.0014354835318902848, Accuracy: 0.8528933835598436\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935521457913142, 0.9968196291766401, 0.814007178397148, 0.9998095837375263]\n",
      "Layer: Layer 1, Input: [-0.9935521457913142, 0.9968196291766401, 0.814007178397148, 0.9998095837375263], Output: [-0.9686994365690316, -0.754303755019843, 0.9049867109665893, 0.9989661389317399]\n",
      "Layer: Layer 2, Input: [-0.9686994365690316, -0.754303755019843, 0.9049867109665893, 0.9989661389317399], Output: [1.045202818787443]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984391860435338, 0.9539742220569585, -0.883818232643243, 0.9818745580831597]\n",
      "Layer: Layer 1, Input: [-0.9984391860435338, 0.9539742220569585, -0.883818232643243, 0.9818745580831597], Output: [-0.8989447401136423, -0.9737922726950117, -0.7228222039686147, 0.9876601343470665]\n",
      "Layer: Layer 2, Input: [-0.8989447401136423, -0.9737922726950117, -0.7228222039686147, 0.9876601343470665], Output: [-0.9712281721656322]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664583117977112, 0.6966742101055362, -0.9403443612645748, 0.9661753417575335]\n",
      "Layer: Layer 1, Input: [-0.9664583117977112, 0.6966742101055362, -0.9403443612645748, 0.9661753417575335], Output: [-0.8253269213673331, -0.9804769593407269, -0.8005096582214541, 0.977460988958966]\n",
      "Layer: Layer 2, Input: [-0.8253269213673331, -0.9804769593407269, -0.8005096582214541, 0.977460988958966], Output: [-1.0265065801265678]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9285377890751203, 0.957166562514068, 0.5863744702492674, 0.9755500624604974]\n",
      "Layer: Layer 1, Input: [-0.9285377890751203, 0.957166562514068, 0.5863744702492674, 0.9755500624604974], Output: [-0.9567399069082396, -0.7991072260425159, 0.8146734058466254, 0.998244881740938]\n",
      "Layer: Layer 2, Input: [-0.9567399069082396, -0.7991072260425159, 0.8146734058466254, 0.998244881740938], Output: [0.9537870189410579]\n",
      "Epoch 96/100, Loss: 0.001427337827905302, Accuracy: 0.8533057921926793\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935563647532106, 0.9968195002172994, 0.8144452169515769, 0.9998095550262346]\n",
      "Layer: Layer 1, Input: [-0.9935563647532106, 0.9968195002172994, 0.8144452169515769, 0.9998095550262346], Output: [-0.9686998745307485, -0.7540690453844608, 0.9051743417661933, 0.9989667370804952]\n",
      "Layer: Layer 2, Input: [-0.9686998745307485, -0.7540690453844608, 0.9051743417661933, 0.9989667370804952], Output: [1.045112041218421]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984395654900171, 0.9539663917395971, -0.8839721347152453, 0.9818766904112411]\n",
      "Layer: Layer 1, Input: [-0.9984395654900171, 0.9539663917395971, -0.8839721347152453, 0.9818766904112411], Output: [-0.8988948791507627, -0.9737916078514938, -0.7228834883141392, 0.9876565829119307]\n",
      "Layer: Layer 2, Input: [-0.8988948791507627, -0.9737916078514938, -0.7228834883141392, 0.9876565829119307], Output: [-0.9713448822129487]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664636722331157, 0.6966618983109178, -0.9403250981638902, 0.9661725247513483]\n",
      "Layer: Layer 1, Input: [-0.9664636722331157, 0.6966618983109178, -0.9403250981638902, 0.9661725247513483], Output: [-0.8252620756092302, -0.9804727301663143, -0.8004722278253932, 0.977459752996837]\n",
      "Layer: Layer 2, Input: [-0.8252620756092302, -0.9804727301663143, -0.8004722278253932, 0.977459752996837], Output: [-1.0264728128036016]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9285637432889259, 0.9571654966374744, 0.5868671848629465, 0.9755488169576538]\n",
      "Layer: Layer 1, Input: [-0.9285637432889259, 0.9571654966374744, 0.5868671848629465, 0.9755488169576538], Output: [-0.9567425020590276, -0.7989106695244179, 0.815035243628507, 0.9982460759749264]\n",
      "Layer: Layer 2, Input: [-0.9567425020590276, -0.7989106695244179, 0.815035243628507, 0.9982460759749264], Output: [0.9539559849339324]\n",
      "Epoch 97/100, Loss: 0.0014192682948552717, Accuracy: 0.8537160131248586\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935605604710785, 0.996819369646366, 0.8148799072295534, 0.9998095264212196]\n",
      "Layer: Layer 1, Input: [-0.9935605604710785, 0.996819369646366, 0.8148799072295534, 0.9998095264212196], Output: [-0.9687002406950405, -0.7538346796848022, 0.9053604620897369, 0.9989673299264307]\n",
      "Layer: Layer 2, Input: [-0.9687002406950405, -0.7538346796848022, 0.9053604620897369, 0.9989673299264307], Output: [1.0450177077958327]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984399430726627, 0.9539585848707562, -0.8841250675985867, 0.9818788115039189]\n",
      "Layer: Layer 1, Input: [-0.9984399430726627, 0.9539585848707562, -0.8841250675985867, 0.9818788115039189], Output: [-0.8988449827432112, -0.9737908730732597, -0.7229434032157172, 0.9876530456493097]\n",
      "Layer: Layer 2, Input: [-0.8988449827432112, -0.9737908730732597, -0.7229434032157172, 0.9876530456493097], Output: [-0.9714572574115709]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664690088004786, 0.6966495634326878, -0.9403058601705113, 0.9661697109393445]\n",
      "Layer: Layer 1, Input: [-0.9664690088004786, 0.6966495634326878, -0.9403058601705113, 0.9661697109393445], Output: [-0.8251970782587972, -0.9804684768069192, -0.8004342237775046, 0.9774585118567802]\n",
      "Layer: Layer 2, Input: [-0.8251970782587972, -0.9804684768069192, -0.8004342237775046, 0.9774585118567802], Output: [-1.0264354979237136]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9285895614354741, 0.9571644210765721, 0.5873564256129459, 0.97554757774016]\n",
      "Layer: Layer 1, Input: [-0.9285895614354741, 0.9571644210765721, 0.5873564256129459, 0.97554757774016], Output: [-0.9567449872759544, -0.7987144159937628, 0.815394371169879, 0.9982472603865377]\n",
      "Layer: Layer 2, Input: [-0.9567449872759544, -0.7987144159937628, 0.815394371169879, 0.9982472603865377], Output: [0.954120014048533]\n",
      "Epoch 98/100, Loss: 0.001411272707760445, Accuracy: 0.8541240657405575\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935647335621597, 0.9968192374790115, 0.8153113645696789, 0.9998094979250026]\n",
      "Layer: Layer 1, Input: [-0.9935647335621597, 0.9968192374790115, 0.8153113645696789, 0.9998094979250026], Output: [-0.9687005398355673, -0.7536006978944911, 0.9055451102157609, 0.9989679176668144]\n",
      "Layer: Layer 2, Input: [-0.9687005398355673, -0.7536006978944911, 0.9055451102157609, 0.9989679176668144], Output: [1.0449202263671378]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984403188369314, 0.9539508004752406, -0.8842770614553926, 0.9818809220259453]\n",
      "Layer: Layer 1, Input: [-0.9984403188369314, 0.9539508004752406, -0.8842770614553926, 0.9818809220259453], Output: [-0.8987950657848135, -0.973790075220453, -0.723002084851429, 0.987649522450827]\n",
      "Layer: Layer 2, Input: [-0.8987950657848135, -0.973790075220453, -0.723002084851429, 0.987649522450827], Output: [-0.971565681470687]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664743220224639, 0.696637205698975, -0.9402866450004133, 0.9661669008777967]\n",
      "Layer: Layer 1, Input: [-0.9664743220224639, 0.696637205698975, -0.9402866450004133, 0.9661669008777967], Output: [-0.8251319569810402, -0.9804642030215106, -0.8003957324549932, 0.9774572663602866]\n",
      "Layer: Layer 2, Input: [-0.8251319569810402, -0.9804642030215106, -0.8003957324549932, 0.9774572663602866], Output: [-1.0263949902154335]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9286152472077817, 0.9571633358602969, 0.5878423062997176, 0.9755463449430193]\n",
      "Layer: Layer 1, Input: [-0.9286152472077817, 0.9571633358602969, 0.5878423062997176, 0.9755463449430193], Output: [-0.9567473696227307, -0.7985184960150513, 0.8157508474869337, 0.998248435320431]\n",
      "Layer: Layer 2, Input: [-0.9567473696227307, -0.7985184960150513, 0.8157508474869337, 0.998248435320431], Output: [0.9542795040237855]\n",
      "Epoch 99/100, Loss: 0.001403349116971302, Accuracy: 0.8545299689119012\n",
      "Layer: Layer 0, Input: [2.0, 3.0, -1.0], Output: [-0.9935688845974479, 0.9968191037304026, 0.8157396943902115, 0.9998094695397846]\n",
      "Layer: Layer 1, Input: [-0.9935688845974479, 0.9968191037304026, 0.8157396943902115, 0.9998094695397846], Output: [-0.9687007762899355, -0.7533671361372636, 0.9057283216034946, 0.9989685004819929]\n",
      "Layer: Layer 2, Input: [-0.9687007762899355, -0.7533671361372636, 0.9057283216034946, 0.9989685004819929], Output: [1.0448199662402151]\n",
      "Layer: Layer 0, Input: [3.0, -1.0, 0.5], Output: [-0.9984406928249623, 0.9539430376700037, -0.8844281439130556, 0.9818830225798323]\n",
      "Layer: Layer 1, Input: [-0.9984406928249623, 0.9539430376700037, -0.8844281439130556, 0.9818830225798323], Output: [-0.8987451417633259, -0.9737892205096246, -0.7230596563777839, 0.9876460132134947]\n",
      "Layer: Layer 2, Input: [-0.8987451417633259, -0.9737892205096246, -0.7230596563777839, 0.9876460132134947], Output: [-0.9716705023871761]\n",
      "Layer: Layer 0, Input: [0.5, 1.0, 1.0], Output: [-0.9664796123839056, 0.6966248253469334, -0.940267450650935, 0.9661640950668212]\n",
      "Layer: Layer 1, Input: [-0.9664796123839056, 0.6966248253469334, -0.940267450650935, 0.9661640950668212], Output: [-0.8250667368419214, -0.9804599122134603, -0.8003568319065977, 0.9774560172497205]\n",
      "Layer: Layer 2, Input: [-0.8250667368419214, -0.9804599122134603, -0.8003568319065977, 0.9774560172497205], Output: [-1.0263516113221638]\n",
      "Layer: Layer 0, Input: [1.0, 1.0, -1.0], Output: [-0.9286408040191912, 0.9571622410248276, 0.5883249312798771, 0.9755451186827374]\n",
      "Layer: Layer 1, Input: [-0.9286408040191912, 0.9571622410248276, 0.5883249312798771, 0.9755451186827374], Output: [-0.9567496555279689, -0.7983229371449543, 0.8161047276345806, 0.9982496010927815]\n",
      "Layer: Layer 2, Input: [-0.9567496555279689, -0.7983229371449543, 0.8161047276345806, 0.9982496010927815], Output: [0.9544348162239752]\n",
      "Epoch 100/100, Loss: 0.0013954958001465806, Accuracy: 0.8549337410487724\n"
     ]
    }
   ],
   "source": [
    "# Run our model training for multiple epochs\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Reset model parameters\n",
    "for param in mlp.parameters():\n",
    "    param.data = random.uniform(-1, 1)  # Random initialization of parameters\n",
    "    param.grad = 0.0\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "y_true = [Value(y_i) for y_i in y]  # Convert labels to Value objects\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_preds = [mlp(i)[0] for i in x]  # Forward pass through the neural network\n",
    "    loss = loss_fn_mse(y_preds, y_true)\n",
    "    losses.append(loss)\n",
    "    accuracy.append(1 - sum([abs(y_true - y_pred.data) for y_true, y_pred in zip(y, y_preds)]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.data}, Accuracy: {accuracy[-1]}\")\n",
    "        \n",
    "    mlp.zero_grad()  # Reset gradients of all parameters\n",
    "    loss.grad = 1.0  # Set the gradient of the loss to 1.0\n",
    "    visited = set()\n",
    "    loss.backward()\n",
    "\n",
    "    for param in mlp.parameters():\n",
    "        param.data = param.data - learning_rate * param.grad  # Update parameters using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "62fd9d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds after training: [1.0448199662402151, -0.9716705023871761, -1.0263516113221638, 0.9544348162239752]\n",
      "y_true after training: [1.0, -1.0, -1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_preds after training: {[item.data for item in y_preds]}\")\n",
    "print(f\"y_true after training: {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "08b99310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "\n",
    "plt.plot(range(epochs), [item.data for item in losses])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2e370b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy over epochs\n",
    "plt.plot(range(epochs), accuracy)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "912faec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3959,  0.3937, -2.5600, -3.9107], grad_fn=<ViewBackward0>),), Output: tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9835,  0.3745, -0.9881, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.6032, -1.0690,  0.2200, -1.0129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9222, -0.7891,  0.2165, -0.7669], grad_fn=<TanhBackward0>),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8685], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.0080,  0.6310,  0.2013, -1.9987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0080,  0.6310,  0.2013, -1.9987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7649,  0.5588,  0.1986, -0.9639], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.7649,  0.5588,  0.1986, -0.9639], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3581, -1.2205, -0.5212,  0.9182], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3581, -1.2205, -0.5212,  0.9182], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8759, -0.8398, -0.4786,  0.7250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8759, -0.8398, -0.4786,  0.7250], grad_fn=<TanhBackward0>),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.5536], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.8141,  0.5476, -1.5705, -0.6861], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.8141,  0.5476, -1.5705, -0.6861], grad_fn=<ViewBackward0>),), Output: tensor([-0.9482,  0.4987, -0.9171, -0.5955], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9482,  0.4987, -0.9171, -0.5955], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2511, -0.7744,  0.2241, -1.0185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2511, -0.7744,  0.2241, -1.0185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8486, -0.6495,  0.2204, -0.7693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8486, -0.6495,  0.2204, -0.7693], grad_fn=<TanhBackward0>),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.8555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7748, -0.7850, -0.5231, -1.7591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7748, -0.7850, -0.5231, -1.7591], grad_fn=<ViewBackward0>),), Output: tensor([-0.6497, -0.6556, -0.4801, -0.9424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6497, -0.6556, -0.4801, -0.9424], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4910, -0.9057,  1.1436, -0.4672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4910, -0.9057,  1.1436, -0.4672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9035, -0.7191,  0.8156, -0.4360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9035, -0.7191,  0.8156, -0.4360], grad_fn=<TanhBackward0>),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.3573], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3531,  0.4963, -2.6552, -3.9193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3531,  0.4963, -2.6552, -3.9193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9821,  0.4592, -0.9902, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9821,  0.4592, -0.9902, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5757, -1.1224,  0.0079, -1.0246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5757, -1.1224,  0.0079, -1.0246], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9179, -0.8084,  0.0079, -0.7717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9179, -0.8084,  0.0079, -0.7717], grad_fn=<TanhBackward0>),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4859], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1021,  0.7992, -0.0230, -2.0032], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1021,  0.7992, -0.0230, -2.0032], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8013,  0.6636, -0.0230, -0.9643], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8013,  0.6636, -0.0230, -0.9643], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1917, -1.1030, -0.8884,  0.7203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1917, -1.1030, -0.8884,  0.7203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8311, -0.8016, -0.7106,  0.6171], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8311, -0.8016, -0.7106,  0.6171], grad_fn=<TanhBackward0>),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([0.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7888,  0.6298, -1.6242, -0.6931], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7888,  0.6298, -1.6242, -0.6931], grad_fn=<ViewBackward0>),), Output: tensor([-0.9456,  0.5579, -0.9252, -0.5999], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9456,  0.5579, -0.9252, -0.5999], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2236, -0.8162,  0.0418, -1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2236, -0.8162,  0.0418, -1.0341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8407, -0.6730,  0.0418, -0.7755], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8407, -0.6730,  0.0418, -0.7755], grad_fn=<TanhBackward0>),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.5061], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7485, -0.7334, -0.5837, -1.7624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7485, -0.7334, -0.5837, -1.7624], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.6251, -0.5254, -0.9428], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.6251, -0.5254, -0.9428], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4321, -0.8981,  0.9794, -0.5130], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4321, -0.8981,  0.9794, -0.5130], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8921, -0.7154,  0.7528, -0.4723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8921, -0.7154,  0.7528, -0.4723], grad_fn=<TanhBackward0>),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0883], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3352,  0.4862, -2.7083, -3.9337], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3352,  0.4862, -2.7083, -3.9337], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814,  0.4512, -0.9912, -0.9992], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814,  0.4512, -0.9912, -0.9992], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5461, -1.1419, -0.0660, -1.0364], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5461, -1.1419, -0.0660, -1.0364], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9131, -0.8151, -0.0659, -0.7765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9131, -0.8151, -0.0659, -0.7765], grad_fn=<TanhBackward0>),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2942], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1407,  0.8638, -0.1561, -2.0103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1407,  0.8638, -0.1561, -2.0103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8147,  0.6982, -0.1548, -0.9647], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8147,  0.6982, -0.1548, -0.9647], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0857, -1.0351, -1.0761,  0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0857, -1.0351, -1.0761,  0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7953, -0.7760, -0.7918,  0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7953, -0.7760, -0.7918,  0.5320], grad_fn=<TanhBackward0>),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.0770], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7759,  0.6673, -1.6569, -0.7048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7759,  0.6673, -1.6569, -0.7048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9442,  0.5832, -0.9298, -0.6074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9442,  0.5832, -0.9298, -0.6074], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2069, -0.8486, -0.0589, -1.0438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2069, -0.8486, -0.0589, -1.0438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358, -0.6903, -0.0588, -0.7794], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8358, -0.6903, -0.0588, -0.7794], grad_fn=<TanhBackward0>),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.3003], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -0.7397, -0.6175, -1.7678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -0.7397, -0.6175, -1.7678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6280, -0.6289, -0.5494, -0.9434], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6280, -0.6289, -0.5494, -0.9434], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3961, -0.8933,  0.9110, -0.5400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3961, -0.8933,  0.9110, -0.5400], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8845, -0.7130,  0.7216, -0.4930], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8845, -0.7130,  0.7216, -0.4930], grad_fn=<TanhBackward0>),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279,  0.4142, -2.7411, -3.9491], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279,  0.4142, -2.7411, -3.9491], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.3921, -0.9917, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.3921, -0.9917, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.5162, -1.1395, -0.0601, -1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.5162, -1.1395, -0.0601, -1.0477], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9080, -0.8143, -0.0600, -0.7809], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9080, -0.8143, -0.0600, -0.7809], grad_fn=<TanhBackward0>),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2127], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1622,  0.8913, -0.2480, -2.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1622,  0.8913, -0.2480, -2.0177], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217,  0.7120, -0.2431, -0.9653], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8217,  0.7120, -0.2431, -0.9653], grad_fn=<TanhBackward0>),), Output: tensor([ 1.0099, -0.9920, -1.1905,  0.5040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.0099, -0.9920, -1.1905,  0.5040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7657, -0.7582, -0.8307,  0.4652], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7657, -0.7582, -0.8307,  0.4652], grad_fn=<TanhBackward0>),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.2212], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7676,  0.6819, -1.6798, -0.7174], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7676,  0.6819, -1.6798, -0.7174], grad_fn=<ViewBackward0>),), Output: tensor([-0.9433,  0.5928, -0.9328, -0.6153], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9433,  0.5928, -0.9328, -0.6153], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1954, -0.8732, -0.1147, -1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1954, -0.8732, -0.1147, -1.0502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8323, -0.7030, -0.1142, -0.7819], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8323, -0.7030, -0.1142, -0.7819], grad_fn=<TanhBackward0>),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.1737], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7341, -0.7761, -0.6384, -1.7735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7341, -0.7761, -0.6384, -1.7735], grad_fn=<ViewBackward0>),), Output: tensor([-0.6256, -0.6505, -0.5638, -0.9440], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6256, -0.6505, -0.5638, -0.9440], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3708, -0.8863,  0.8927, -0.5579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3708, -0.8863,  0.8927, -0.5579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8789, -0.7096,  0.7127, -0.5064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8789, -0.7096,  0.7127, -0.5064], grad_fn=<TanhBackward0>),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3259,  0.2992, -2.7629, -3.9641], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3259,  0.2992, -2.7629, -3.9641], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.2906, -0.9921, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.2906, -0.9921, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4848, -1.1186,  0.0036, -1.0591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4848, -1.1186,  0.0036, -1.0591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.9024, -0.8071,  0.0036, -0.7853], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.9024, -0.8071,  0.0036, -0.7853], grad_fn=<TanhBackward0>),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2063], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1761,  0.8992, -0.3173, -2.0250], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761,  0.8992, -0.3173, -2.0250], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262,  0.7159, -0.3070, -0.9658], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8262,  0.7159, -0.3070, -0.9658], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9513, -0.9619, -1.2662,  0.4373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9513, -0.9619, -1.2662,  0.4373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7404, -0.7451, -0.8528,  0.4114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7404, -0.7451, -0.8528,  0.4114], grad_fn=<TanhBackward0>),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.3262], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7616,  0.6820, -1.6972, -0.7299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7616,  0.6820, -1.6972, -0.7299], grad_fn=<ViewBackward0>),), Output: tensor([-0.9427,  0.5928, -0.9351, -0.6230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9427,  0.5928, -0.9351, -0.6230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1864, -0.8918, -0.1448, -1.0549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1864, -0.8918, -0.1448, -1.0549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8295, -0.7123, -0.1438, -0.7837], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8295, -0.7123, -0.1438, -0.7837], grad_fn=<TanhBackward0>),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0920], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7332, -0.8333, -0.6523, -1.7790], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7332, -0.8333, -0.6523, -1.7790], grad_fn=<ViewBackward0>),), Output: tensor([-0.6250, -0.6822, -0.5732, -0.9446], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6250, -0.6822, -0.5732, -0.9446], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3513, -0.8767,  0.9032, -0.5706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3513, -0.8767,  0.9032, -0.5706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8744, -0.7048,  0.7179, -0.5158], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8744, -0.7048,  0.7179, -0.5158], grad_fn=<TanhBackward0>),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8349], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3264,  0.1554, -2.7784, -3.9786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3264,  0.1554, -2.7784, -3.9786], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811,  0.1542, -0.9923, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811,  0.1542, -0.9923, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4515, -1.0824,  0.1091, -1.0711], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4515, -1.0824,  0.1091, -1.0711], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8960, -0.7941,  0.1087, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8960, -0.7941,  0.1087, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.2518], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1863,  0.8956, -0.3723, -2.0321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1863,  0.8956, -0.3723, -2.0321], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8294,  0.7141, -0.3560, -0.9662], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8294,  0.7141, -0.3560, -0.9662], grad_fn=<TanhBackward0>),), Output: tensor([ 0.9035, -0.9396, -1.3204,  0.3847], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.9035, -0.9396, -1.3204,  0.3847], grad_fn=<ViewBackward0>),), Output: tensor([ 0.7180, -0.7350, -0.8669,  0.3668], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.7180, -0.7350, -0.8669,  0.3668], grad_fn=<TanhBackward0>),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4107], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7568,  0.6731, -1.7113, -0.7420], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7568,  0.6731, -1.7113, -0.7420], grad_fn=<ViewBackward0>),), Output: tensor([-0.9421,  0.5870, -0.9368, -0.6304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9421,  0.5870, -0.9368, -0.6304], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1785, -0.9063, -0.1620, -1.0588], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1785, -0.9063, -0.1620, -1.0588], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8270, -0.7193, -0.1606, -0.7852], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8270, -0.7193, -0.1606, -0.7852], grad_fn=<TanhBackward0>),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([0.0330], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7338, -0.9042, -0.6623, -1.7843], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7338, -0.9042, -0.6623, -1.7843], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.7183, -0.5799, -0.9452], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.7183, -0.5799, -0.9452], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3355, -0.8654,  0.9283, -0.5804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3355, -0.8654,  0.9283, -0.5804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8706, -0.6990,  0.7298, -0.5230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8706, -0.6990,  0.7298, -0.5230], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3276e+00,  2.5095e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3276e+00,  2.5095e-03, -2.7904e+00, -3.9927e+00],\n",
      "       grad_fn=<ViewBackward0>),), Output: tensor([-0.9812,  0.0025, -0.9925, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812,  0.0025, -0.9925, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.4186, -1.0379,  0.2323, -1.0828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.4186, -1.0379,  0.2323, -1.0828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8893, -0.7771,  0.2282, -0.7942], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8893, -0.7771,  0.2282, -0.7942], grad_fn=<TanhBackward0>),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3215], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.1945,  0.8873, -0.4175, -2.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1945,  0.8873, -0.4175, -2.0390], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8320,  0.7100, -0.3948, -0.9667], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8320,  0.7100, -0.3948, -0.9667], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8632, -0.9229, -1.3641,  0.3420], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8632, -0.9229, -1.3641,  0.3420], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6979, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6979, -0.7273, -0.8773,  0.3293], grad_fn=<TanhBackward0>),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.4852], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7524,  0.6612, -1.7234, -0.7538], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7524,  0.6612, -1.7234, -0.7538], grad_fn=<ViewBackward0>),), Output: tensor([-0.9416,  0.5792, -0.9383, -0.6374], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9416,  0.5792, -0.9383, -0.6374], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1714, -0.9188, -0.1769, -1.0623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1714, -0.9188, -0.1769, -1.0623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7253, -0.1751, -0.7865], grad_fn=<TanhBackward0>),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0194], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7349, -0.9794, -0.6698, -1.7895], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7349, -0.9794, -0.6698, -1.7895], grad_fn=<ViewBackward0>),), Output: tensor([-0.6260, -0.7528, -0.5849, -0.9457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6260, -0.7528, -0.5849, -0.9457], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3224, -0.8540,  0.9562, -0.5882], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3224, -0.8540,  0.9562, -0.5882], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8674, -0.6931,  0.7426, -0.5286], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8674, -0.6931,  0.7426, -0.5286], grad_fn=<TanhBackward0>),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8125], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -0.1379, -2.8001, -4.0063], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -0.1379, -2.8001, -4.0063], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.1370, -0.9926, -0.9993], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.1370, -0.9926, -0.9993], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3898, -0.9951,  0.3450, -1.0929], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3898, -0.9951,  0.3450, -1.0929], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8831, -0.7595,  0.3320, -0.7979], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8831, -0.7595,  0.3320, -0.7979], grad_fn=<TanhBackward0>),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.3867], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2013,  0.8801, -0.4551, -2.0457], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2013,  0.8801, -0.4551, -2.0457], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8341,  0.7065, -0.4261, -0.9671], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8341,  0.7065, -0.4261, -0.9671], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8289, -0.9109, -1.4039,  0.3069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8289, -0.9109, -1.4039,  0.3069], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6799, -0.7216, -0.8862,  0.2976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6799, -0.7216, -0.8862,  0.2976], grad_fn=<TanhBackward0>),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.5544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7482,  0.6525, -1.7338, -0.7653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7482,  0.6525, -1.7338, -0.7653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9412,  0.5734, -0.9395, -0.6442], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -0.9308, -0.1972, -1.0654], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7310, -0.1947, -0.7877], grad_fn=<TanhBackward0>),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.0746], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.0490, -0.6758, -1.7944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.0490, -0.6758, -1.7944], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.7814, -0.5888, -0.9462], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.7814, -0.5888, -0.9462], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.8439,  0.9791, -0.5942], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.8439,  0.9791, -0.5942], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.6879,  0.7527, -0.5329], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.6879,  0.7527, -0.5329], grad_fn=<TanhBackward0>),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8070], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3297, -0.2561, -2.8077, -4.0193], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3297, -0.2561, -2.8077, -4.0193], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.2507, -0.9927, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.2507, -0.9927, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3666, -0.9588,  0.4344, -1.1007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3666, -0.9588,  0.4344, -1.1007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8779, -0.7437,  0.4090, -0.8008], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8779, -0.7437,  0.4090, -0.8008], grad_fn=<TanhBackward0>),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4360], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2070,  0.8764, -0.4862, -2.0522], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2070,  0.8764, -0.4862, -2.0522], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8358,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8358,  0.7046, -0.4512, -0.9675], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8001, -0.9029, -1.4418,  0.2780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8001, -0.9029, -1.4418,  0.2780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6641, -0.7177, -0.8941,  0.2711], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6641, -0.7177, -0.8941,  0.2711], grad_fn=<TanhBackward0>),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6186], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7442,  0.6493, -1.7430, -0.7763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7442,  0.6493, -1.7430, -0.7763], grad_fn=<ViewBackward0>),), Output: tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9407,  0.5712, -0.9406, -0.6506], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1602, -0.9430, -0.2241, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8211, -0.7366, -0.2205, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8211, -0.7366, -0.2205, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7371, -1.1083, -0.6803, -1.7992], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7371, -1.1083, -0.6803, -1.7992], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.8034, -0.5917, -0.9467], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.8353,  0.9953, -0.5987], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.8353,  0.9953, -0.5987], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6833,  0.7596, -0.5361], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6833,  0.7596, -0.5361], grad_fn=<TanhBackward0>),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8023], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3307, -0.3540, -2.8135, -4.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3307, -0.3540, -2.8135, -4.0317], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.3399, -0.9928, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.3399, -0.9928, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3485, -0.9288,  0.5030, -1.1065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3485, -0.9288,  0.5030, -1.1065], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8737, -0.7300,  0.4644, -0.8028], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8737, -0.7300,  0.4644, -0.8028], grad_fn=<TanhBackward0>),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.4730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2117,  0.8755, -0.5119, -2.0584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2117,  0.8755, -0.5119, -2.0584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8372,  0.7041, -0.4714, -0.9679], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7760, -0.8979, -1.4773,  0.2544], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7760, -0.8979, -1.4773,  0.2544], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6504, -0.7153, -0.9010,  0.2491], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6504, -0.7153, -0.9010,  0.2491], grad_fn=<TanhBackward0>),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.6769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7404,  0.6505, -1.7509, -0.7868], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7404,  0.6505, -1.7509, -0.7868], grad_fn=<ViewBackward0>),), Output: tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9403,  0.5720, -0.9415, -0.6566], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1562, -0.9548, -0.2550, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1562, -0.9548, -0.2550, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8198, -0.7419, -0.2496, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8198, -0.7419, -0.2496, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.1932], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7383, -1.1580, -0.6836, -1.8036], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7383, -1.1580, -0.6836, -1.8036], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.8204, -0.5939, -0.9472], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.8204, -0.5939, -0.9472], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2979, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2979, -0.8277,  1.0071, -0.6018], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8612, -0.6792,  0.7646, -0.5383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8612, -0.6792,  0.7646, -0.5383], grad_fn=<TanhBackward0>),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.7998], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3319, -0.4362, -2.8175, -4.0432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3319, -0.4362, -2.8175, -4.0432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.4105, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.4105, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3346, -0.9033,  0.5565, -1.1106], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3346, -0.9033,  0.5565, -1.1106], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8704, -0.7179,  0.5054, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8704, -0.7179,  0.5054, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5032], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2155,  0.8762, -0.5328, -2.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2155,  0.8762, -0.5328, -2.0641], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8383,  0.7045, -0.4875, -0.9683], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7559, -0.8948, -1.5099,  0.2352], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7559, -0.8948, -1.5099,  0.2352], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6387, -0.7138, -0.9069,  0.2310], grad_fn=<TanhBackward0>),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7370,  0.6546, -1.7576, -0.7966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7370,  0.6546, -1.7576, -0.7966], grad_fn=<ViewBackward0>),), Output: tensor([-0.9399,  0.5748, -0.9422, -0.6621], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9399,  0.5748, -0.9422, -0.6621], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1532, -0.9657, -0.2872, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1532, -0.9657, -0.2872, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7468, -0.2795, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7468, -0.2795, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.2501], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7396, -1.2004, -0.6858, -1.8078], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7396, -1.2004, -0.6858, -1.8078], grad_fn=<ViewBackward0>),), Output: tensor([-0.6289, -0.8338, -0.5953, -0.9476], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6289, -0.8338, -0.5953, -0.9476], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2938, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2938, -0.8204,  1.0168, -0.6037], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8601, -0.6753,  0.7685, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8601, -0.6753,  0.7685, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8008], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3332, -0.5065, -2.8201, -4.0539], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3332, -0.5065, -2.8201, -4.0539], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.4672, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.4672, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3239, -0.8809,  0.5996, -1.1134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3239, -0.8809,  0.5996, -1.1134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8677, -0.7069,  0.5368, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8677, -0.7069,  0.5368, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5300], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2186,  0.8779, -0.5498, -2.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2186,  0.8779, -0.5498, -2.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8392,  0.7054, -0.5004, -0.9686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8392,  0.7054, -0.5004, -0.9686], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7394, -0.8931, -1.5391,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7394, -0.8931, -1.5391,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6288, -0.7129, -0.9120,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6288, -0.7129, -0.9120,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.7749], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7339,  0.6605, -1.7634, -0.8058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9395,  0.5787, -0.9429, -0.6673], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1511, -0.9754, -0.3191, -1.0732], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1511, -0.9754, -0.3191, -1.0732], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7511, -0.3087, -0.7907], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7511, -0.3087, -0.7907], grad_fn=<TanhBackward0>),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3030], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7410, -1.2370, -0.6870, -1.8117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7410, -1.2370, -0.6870, -1.8117], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.8446, -0.5961, -0.9480], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2912, -0.8132,  1.0255, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8594, -0.6713,  0.7721, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8594, -0.6713,  0.7721, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8052], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3346, -0.5673, -2.8216, -4.0638], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3346, -0.5673, -2.8216, -4.0638], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.5133, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.5133, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.8609,  0.6352, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.8609,  0.6352, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.6967,  0.5616, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.6967,  0.5616, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2210,  0.8799, -0.5635, -2.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2210,  0.8799, -0.5635, -2.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8399,  0.7064, -0.5105, -0.9689], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8399,  0.7064, -0.5105, -0.9689], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7257, -0.8922, -1.5653,  0.2072], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7257, -0.8922, -1.5653,  0.2072], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6205, -0.7125, -0.9163,  0.2043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6205, -0.7125, -0.9163,  0.2043], grad_fn=<TanhBackward0>),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8154], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7311,  0.6674, -1.7684, -0.8143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9392,  0.5833, -0.9434, -0.6720], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1495, -0.9841, -0.3499, -1.0741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1495, -0.9841, -0.3499, -1.0741], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8176, -0.7548, -0.3363, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8176, -0.7548, -0.3363, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7424, -1.2691, -0.6876, -1.8152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7424, -1.2691, -0.6876, -1.8152], grad_fn=<ViewBackward0>),), Output: tensor([-0.6306, -0.8536, -0.5964, -0.9484], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6306, -0.8536, -0.5964, -0.9484], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.8060,  1.0337, -0.6048], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6674,  0.7754, -0.5404], grad_fn=<TanhBackward0>),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8126], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3361, -0.6203, -2.8221, -4.0729], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3361, -0.6203, -2.8221, -4.0729], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5514, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5514, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.8426,  0.6650, -1.1164], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.8426,  0.6650, -1.1164], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6872,  0.5817, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6872,  0.5817, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.5785], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2229,  0.8821, -0.5744, -2.0791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2229,  0.8821, -0.5744, -2.0791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8405,  0.7075, -0.5186, -0.9692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8405,  0.7075, -0.5186, -0.9692], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7145, -0.8918, -1.5886,  0.1972], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7145, -0.8918, -1.5886,  0.1972], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6135, -0.7123, -0.9199,  0.1947], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6135, -0.7123, -0.9199,  0.1947], grad_fn=<TanhBackward0>),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7285,  0.6749, -1.7727, -0.8222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9389,  0.5882, -0.9439, -0.6763], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1484, -0.9916, -0.3794, -1.0747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1484, -0.9916, -0.3794, -1.0747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7580, -0.3622, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7580, -0.3622, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.3960], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7438, -1.2974, -0.6875, -1.8185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7438, -1.2974, -0.6875, -1.8185], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.8611, -0.5964, -0.9487], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.8611, -0.5964, -0.9487], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7987,  1.0417, -0.6043], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7987,  1.0417, -0.6043], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6633,  0.7786, -0.5401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6633,  0.7786, -0.5401], grad_fn=<TanhBackward0>),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3376, -0.6670, -2.8221, -4.0813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3376, -0.6670, -2.8221, -4.0813], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.5830, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.5830, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3040, -0.8258,  0.6905, -1.1170], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3040, -0.8258,  0.6905, -1.1170], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.6782,  0.5983, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.6782,  0.5983, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6012], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2245,  0.8842, -0.5830, -2.0834], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2245,  0.8842, -0.5830, -2.0834], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8410,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8410,  0.7085, -0.5248, -0.9695], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7054, -0.8919, -1.6093,  0.1892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7054, -0.8919, -1.6093,  0.1892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6078, -0.7123, -0.9231,  0.1870], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6078, -0.7123, -0.9231,  0.1870], grad_fn=<TanhBackward0>),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.8824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7261,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7261,  0.6827, -1.7763, -0.8295], grad_fn=<ViewBackward0>),), Output: tensor([-0.9386,  0.5933, -0.9443, -0.6802], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9386,  0.5933, -0.9443, -0.6802], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1477, -0.9981, -0.4072, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1477, -0.9981, -0.4072, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7608, -0.3861, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7608, -0.3861, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4365], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7452, -1.3226, -0.6871, -1.8215], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7452, -1.3226, -0.6871, -1.8215], grad_fn=<ViewBackward0>),), Output: tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6323, -0.8674, -0.5961, -0.9490], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2891, -0.7915,  1.0495, -0.6035], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2891, -0.7915,  1.0495, -0.6035], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8589, -0.6593,  0.7816, -0.5395], grad_fn=<TanhBackward0>),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8337], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3389, -0.7083, -2.8215, -4.0891], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3389, -0.7083, -2.8215, -4.0891], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6096, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6096, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3001, -0.8102,  0.7124, -1.1172], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3001, -0.8102,  0.7124, -1.1172], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8618, -0.6697,  0.6122, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8618, -0.6697,  0.6122, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6229], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2258,  0.8862, -0.5897, -2.0874], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2258,  0.8862, -0.5897, -2.0874], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8413,  0.7095, -0.5297, -0.9697], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6980, -0.8921, -1.6277,  0.1831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6980, -0.8921, -1.6277,  0.1831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6031, -0.7124, -0.9257,  0.1810], grad_fn=<TanhBackward0>),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9100], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7240,  0.6905, -1.7795, -0.8362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9383,  0.5983, -0.9446, -0.6838], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1473, -1.0038, -0.4335, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1473, -1.0038, -0.4335, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7632, -0.4082, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.4734], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7465, -1.3450, -0.6864, -1.8242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7465, -1.3450, -0.6864, -1.8242], grad_fn=<ViewBackward0>),), Output: tensor([-0.6330, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6330, -0.8729, -0.5956, -0.9493], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2897, -0.7844,  1.0571, -0.6023], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6552,  0.7846, -0.5387], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3402, -0.7450, -2.8207, -4.0962], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3402, -0.7450, -2.8207, -4.0962], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.6322, -0.9929, -0.9994], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.6322, -0.9929, -0.9994], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2971, -0.7957,  0.7315, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2971, -0.7957,  0.7315, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6617,  0.6240, -0.8065], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6617,  0.6240, -0.8065], grad_fn=<TanhBackward0>),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6437], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2268,  0.8880, -0.5947, -2.0910], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2268,  0.8880, -0.5947, -2.0910], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8416,  0.7104, -0.5333, -0.9699], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6921, -0.8924, -1.6439,  0.1783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6921, -0.8924, -1.6439,  0.1783], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5994, -0.7126, -0.9280,  0.1765], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5994, -0.7126, -0.9280,  0.1765], grad_fn=<TanhBackward0>),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7220,  0.6983, -1.7822, -0.8424], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7220,  0.6983, -1.7822, -0.8424], grad_fn=<ViewBackward0>),), Output: tensor([-0.9381,  0.6033, -0.9449, -0.6871], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9381,  0.6033, -0.9449, -0.6871], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0087, -0.4582, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0087, -0.4582, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7652, -0.4286, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7477, -1.3652, -0.6854, -1.8268], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7477, -1.3652, -0.6854, -1.8268], grad_fn=<ViewBackward0>),), Output: tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6338, -0.8776, -0.5950, -0.9495], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2906, -0.7773,  1.0645, -0.6009], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2906, -0.7773,  1.0645, -0.6009], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8593, -0.6512,  0.7874, -0.5377], grad_fn=<TanhBackward0>),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8592], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3413, -0.7778, -2.8196, -4.1028], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3413, -0.7778, -2.8196, -4.1028], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6515, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6515, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2947, -0.7823,  0.7483, -1.1168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2947, -0.7823,  0.7483, -1.1168], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8604, -0.6540,  0.6341, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2276,  0.8896, -0.5983, -2.0944], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2276,  0.8896, -0.5983, -2.0944], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8419,  0.7112, -0.5359, -0.9701], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8419,  0.7112, -0.5359, -0.9701], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6875, -0.8929, -1.6583,  0.1749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6875, -0.8929, -1.6583,  0.1749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5964, -0.7128, -0.9300,  0.1731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5964, -0.7128, -0.9300,  0.1731], grad_fn=<TanhBackward0>),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9556], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7201,  0.7059, -1.7846, -0.8482], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7201,  0.7059, -1.7846, -0.8482], grad_fn=<ViewBackward0>),), Output: tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9379,  0.6081, -0.9452, -0.6901], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1471, -1.0129, -0.4814, -1.0752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1471, -1.0129, -0.4814, -1.0752], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7670, -0.4474, -0.7914], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7670, -0.4474, -0.7914], grad_fn=<TanhBackward0>),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5381], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7488, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7488, -1.3833, -0.6843, -1.8292], grad_fn=<ViewBackward0>),), Output: tensor([-0.6344, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6344, -0.8817, -0.5943, -0.9497], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2917, -0.7704,  1.0715, -0.5994], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2917, -0.7704,  1.0715, -0.5994], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8596, -0.6472,  0.7900, -0.5366], grad_fn=<TanhBackward0>),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3423, -0.8073, -2.8184, -4.1090], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3423, -0.8073, -2.8184, -4.1090], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6681, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6681, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2929, -0.7697,  0.7630, -1.1163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2929, -0.7697,  0.7630, -1.1163], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6467,  0.6428, -0.8063], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6467,  0.6428, -0.8063], grad_fn=<TanhBackward0>),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2282,  0.8909, -0.6008, -2.0975], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2282,  0.8909, -0.6008, -2.0975], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8421,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8421,  0.7118, -0.5376, -0.9703], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6841, -0.8934, -1.6710,  0.1725], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6841, -0.8934, -1.6710,  0.1725], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5942, -0.7131, -0.9317,  0.1708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5942, -0.7131, -0.9317,  0.1708], grad_fn=<TanhBackward0>),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9744], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7184,  0.7132, -1.7867, -0.8535], grad_fn=<ViewBackward0>),), Output: tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9377,  0.6127, -0.9454, -0.6929], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1472, -1.0166, -0.5033, -1.0750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1472, -1.0166, -0.5033, -1.0750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8168, -0.7685, -0.4647, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8168, -0.7685, -0.4647, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5665], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7498, -1.3998, -0.6832, -1.8313], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7498, -1.3998, -0.6832, -1.8313], grad_fn=<ViewBackward0>),), Output: tensor([-0.6350, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6350, -0.8853, -0.5936, -0.9500], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2930, -0.7637,  1.0781, -0.5978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2930, -0.7637,  1.0781, -0.5978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8599, -0.6433,  0.7925, -0.5355], grad_fn=<TanhBackward0>),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8856], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3432, -0.8339, -2.8172, -4.1146], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3432, -0.8339, -2.8172, -4.1146], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.6826, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.6826, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2915, -0.7579,  0.7761, -1.1158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2915, -0.7579,  0.7761, -1.1158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8595, -0.6398,  0.6505, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8595, -0.6398,  0.6505, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.6995], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2288,  0.8920, -0.6022, -2.1004], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2288,  0.8920, -0.6022, -2.1004], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8422,  0.7124, -0.5386, -0.9705], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8422,  0.7124, -0.5386, -0.9705], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6815, -0.8939, -1.6822,  0.1710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6815, -0.8939, -1.6822,  0.1710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5925, -0.7133, -0.9331,  0.1693], grad_fn=<TanhBackward0>),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-0.9910], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7168,  0.7203, -1.7885, -0.8584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7168,  0.7203, -1.7885, -0.8584], grad_fn=<ViewBackward0>),), Output: tensor([-0.9375,  0.6171, -0.9456, -0.6954], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9375,  0.6171, -0.9456, -0.6954], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1474, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1474, -1.0198, -0.5237, -1.0748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8169, -0.7698, -0.4806, -0.7913], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8169, -0.7698, -0.4806, -0.7913], grad_fn=<TanhBackward0>),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.5926], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7507, -1.4147, -0.6820, -1.8334], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7507, -1.4147, -0.6820, -1.8334], grad_fn=<ViewBackward0>),), Output: tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6356, -0.8885, -0.5928, -0.9502], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2944, -0.7572,  1.0844, -0.5961], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2944, -0.7572,  1.0844, -0.5961], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8603, -0.6394,  0.7948, -0.5343], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8603, -0.6394,  0.7948, -0.5343], grad_fn=<TanhBackward0>),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.8985], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3438, -0.8580, -2.8160, -4.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3438, -0.8580, -2.8160, -4.1199], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.6952, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2904, -0.7469,  0.7877, -1.1152], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8592, -0.6333,  0.6571, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7159], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2292,  0.8927, -0.6027, -2.1031], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2292,  0.8927, -0.6027, -2.1031], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8423,  0.7127, -0.5390, -0.9706], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6799, -0.8944, -1.6919,  0.1703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6799, -0.8944, -1.6919,  0.1703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5914, -0.7136, -0.9344,  0.1687], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5914, -0.7136, -0.9344,  0.1687], grad_fn=<TanhBackward0>),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0055], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7153,  0.7270, -1.7900, -0.8630], grad_fn=<ViewBackward0>),), Output: tensor([-0.9373,  0.6213, -0.9458, -0.6978], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9373,  0.6213, -0.9458, -0.6978], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1478, -1.0226, -0.5430, -1.0745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1478, -1.0226, -0.5430, -1.0745], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8170, -0.7709, -0.4952, -0.7912], grad_fn=<TanhBackward0>),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6167], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7515, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7515, -1.4283, -0.6808, -1.8353], grad_fn=<ViewBackward0>),), Output: tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6361, -0.8913, -0.5920, -0.9503], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2958, -0.7510,  1.0902, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2958, -0.7510,  1.0902, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8606, -0.6357,  0.7970, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8606, -0.6357,  0.7970, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9110], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3444, -0.8799, -2.8148, -4.1248], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3444, -0.8799, -2.8148, -4.1248], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7064, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7064, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2895, -0.7366,  0.7982, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2895, -0.7366,  0.7982, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8590, -0.6271,  0.6630, -0.8057], grad_fn=<TanhBackward0>),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7312], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2295,  0.8932, -0.6025, -2.1057], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2295,  0.8932, -0.6025, -2.1057], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8424,  0.7130, -0.5388, -0.9708], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8424,  0.7130, -0.5388, -0.9708], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8949, -1.7004,  0.1703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8949, -1.7004,  0.1703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7138, -0.9355,  0.1686], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7138, -0.9355,  0.1686], grad_fn=<TanhBackward0>),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0182], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7139,  0.7335, -1.7914, -0.8672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7139,  0.7335, -1.7914, -0.8672], grad_fn=<ViewBackward0>),), Output: tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9371,  0.6252, -0.9459, -0.7000], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1482, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1482, -1.0250, -0.5610, -1.0742], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8172, -0.7719, -0.5087, -0.7910], grad_fn=<TanhBackward0>),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6389], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7522, -1.4408, -0.6796, -1.8370], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7522, -1.4408, -0.6796, -1.8370], grad_fn=<ViewBackward0>),), Output: tensor([-0.6365, -0.8939, -0.5913, -0.9505], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6365, -0.8939, -0.5913, -0.9505], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2972, -0.7450,  1.0957, -0.5928], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2972, -0.7450,  1.0957, -0.5928], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8610, -0.6322,  0.7990, -0.5319], grad_fn=<TanhBackward0>),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9230], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3448, -0.9000, -2.8137, -4.1294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3448, -0.9000, -2.8137, -4.1294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7163, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7163, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2889, -0.7269,  0.8075, -1.1139], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2889, -0.7269,  0.8075, -1.1139], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8588, -0.6212,  0.6682, -0.8054], grad_fn=<TanhBackward0>),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7455], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2298,  0.8934, -0.6017, -2.1080], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2298,  0.8934, -0.6017, -2.1080], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8425,  0.7131, -0.5382, -0.9709], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8425,  0.7131, -0.5382, -0.9709], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6786, -0.8955, -1.7078,  0.1709], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6786, -0.8955, -1.7078,  0.1709], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5906, -0.7141, -0.9364,  0.1692], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5906, -0.7141, -0.9364,  0.1692], grad_fn=<TanhBackward0>),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0293], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7125,  0.7396, -1.7926, -0.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7125,  0.7396, -1.7926, -0.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9370,  0.6289, -0.9460, -0.7020], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1487, -1.0271, -0.5780, -1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1487, -1.0271, -0.5780, -1.0739], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8173, -0.7728, -0.5212, -0.7909], grad_fn=<TanhBackward0>),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6594], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7528, -1.4522, -0.6785, -1.8387], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.8961, -0.5905, -0.9507], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2987, -0.7393,  1.1008, -0.5913], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2987, -0.7393,  1.1008, -0.5913], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8614, -0.6287,  0.8008, -0.5308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8614, -0.6287,  0.8008, -0.5308], grad_fn=<TanhBackward0>),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9343], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3450, -0.9183, -2.8126, -4.1337], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3450, -0.9183, -2.8126, -4.1337], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7251, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2884, -0.7179,  0.8159, -1.1133], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2884, -0.7179,  0.8159, -1.1133], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8587, -0.6156,  0.6728, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8587, -0.6156,  0.6728, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2300,  0.8934, -0.6002, -2.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2300,  0.8934, -0.6002, -2.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7131, -0.5372, -0.9710], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7131, -0.5372, -0.9710], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6789, -0.8960, -1.7141,  0.1720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6789, -0.8960, -1.7141,  0.1720], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5908, -0.7143, -0.9372,  0.1703], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5908, -0.7143, -0.9372,  0.1703], grad_fn=<TanhBackward0>),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0390], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7113,  0.7453, -1.7936, -0.8749], grad_fn=<ViewBackward0>),), Output: tensor([-0.9368,  0.6324, -0.9461, -0.7038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9368,  0.6324, -0.9461, -0.7038], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1492, -1.0290, -0.5939, -1.0735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1492, -1.0290, -0.5939, -1.0735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8175, -0.7735, -0.5327, -0.7908], grad_fn=<TanhBackward0>),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6783], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.4628, -0.6774, -1.8402], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.4628, -0.6774, -1.8402], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.8982, -0.5898, -0.9508], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3000, -0.7339,  1.1055, -0.5897], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3000, -0.7339,  1.1055, -0.5897], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8617, -0.6254,  0.8025, -0.5297], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8617, -0.6254,  0.8025, -0.5297], grad_fn=<TanhBackward0>),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9353, -2.8117, -4.1378], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9353, -2.8117, -4.1378], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7330, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2880, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2880, -0.7095,  0.8235, -1.1127], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8586, -0.6104,  0.6770, -0.8050], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8586, -0.6104,  0.6770, -0.8050], grad_fn=<TanhBackward0>),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2302,  0.8931, -0.5983, -2.1123], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2302,  0.8931, -0.5983, -2.1123], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8426,  0.7129, -0.5358, -0.9712], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6797, -0.8965, -1.7195,  0.1735], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6797, -0.8965, -1.7195,  0.1735], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5913, -0.7146, -0.9378,  0.1718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5913, -0.7146, -0.9378,  0.1718], grad_fn=<TanhBackward0>),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0473], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7101,  0.7508, -1.7945, -0.8783], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7101,  0.7508, -1.7945, -0.8783], grad_fn=<ViewBackward0>),), Output: tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9367,  0.6356, -0.9462, -0.7056], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1498, -1.0306, -0.6088, -1.0731], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8177, -0.7742, -0.5433, -0.7906], grad_fn=<TanhBackward0>),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.6959], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7537, -1.4726, -0.6764, -1.8417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7537, -1.4726, -0.6764, -1.8417], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9001, -0.5891, -0.9510], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3014, -0.7287,  1.1099, -0.5883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3014, -0.7287,  1.1099, -0.5883], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8621, -0.6223,  0.8040, -0.5287], grad_fn=<TanhBackward0>),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9549], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3452, -0.9509, -2.8108, -4.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3452, -0.9509, -2.8108, -4.1416], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7402, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2878, -0.7016,  0.8304, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2878, -0.7016,  0.8304, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6054,  0.6807, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7823], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2303,  0.8926, -0.5959, -2.1143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2303,  0.8926, -0.5959, -2.1143], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7127, -0.5341, -0.9713], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7127, -0.5341, -0.9713], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6809, -0.8970, -1.7240,  0.1755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6809, -0.8970, -1.7240,  0.1755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5921, -0.7148, -0.9383,  0.1737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5921, -0.7148, -0.9383,  0.1737], grad_fn=<TanhBackward0>),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0545], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7090,  0.7559, -1.7953, -0.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7090,  0.7559, -1.7953, -0.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.9365,  0.6387, -0.9463, -0.7072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9365,  0.6387, -0.9463, -0.7072], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1504, -1.0320, -0.6229, -1.0727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1504, -1.0320, -0.6229, -1.0727], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8179, -0.7747, -0.5532, -0.7905], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8179, -0.7747, -0.5532, -0.7905], grad_fn=<TanhBackward0>),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7122], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.4817, -0.6754, -1.8431], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.4817, -0.6754, -1.8431], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9018, -0.5885, -0.9511], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3027, -0.7238,  1.1139, -0.5869], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3027, -0.7238,  1.1139, -0.5869], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.6193,  0.8054, -0.5277], grad_fn=<TanhBackward0>),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3451, -0.9654, -2.8101, -4.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3451, -0.9654, -2.8101, -4.1451], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7467, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2876, -0.6942,  0.8367, -1.1116], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2876, -0.6942,  0.8367, -1.1116], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8585, -0.6007,  0.6840, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.7928], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8919, -0.5932, -2.1161], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8919, -0.5932, -2.1161], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7123, -0.5322, -0.9714], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6824, -0.8975, -1.7277,  0.1778], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6824, -0.8975, -1.7277,  0.1778], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5931, -0.7151, -0.9388,  0.1759], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5931, -0.7151, -0.9388,  0.1759], grad_fn=<TanhBackward0>),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7079,  0.7607, -1.7960, -0.8845], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7079,  0.7607, -1.7960, -0.8845], grad_fn=<ViewBackward0>),), Output: tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9364,  0.6415, -0.9464, -0.7087], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1510, -1.0333, -0.6361, -1.0723], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1510, -1.0333, -0.6361, -1.0723], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8181, -0.7752, -0.5623, -0.7903], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8181, -0.7752, -0.5623, -0.7903], grad_fn=<TanhBackward0>),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7273], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.4901, -0.6745, -1.8444], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.4901, -0.6745, -1.8444], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9033, -0.5879, -0.9512], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.7192,  1.1176, -0.5856], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.6164,  0.8067, -0.5267], grad_fn=<TanhBackward0>),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9730], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3449, -0.9790, -2.8094, -4.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3449, -0.9790, -2.8094, -4.1485], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7526, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2874, -0.6873,  0.8424, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2874, -0.6873,  0.8424, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5962,  0.6871, -0.8045], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5962,  0.6871, -0.8045], grad_fn=<TanhBackward0>),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8024], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2304,  0.8909, -0.5901, -2.1178], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2304,  0.8909, -0.5901, -2.1178], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7119, -0.5300, -0.9715], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7119, -0.5300, -0.9715], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6843, -0.8980, -1.7307,  0.1804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6843, -0.8980, -1.7307,  0.1804], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5943, -0.7153, -0.9391,  0.1784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7069,  0.7652, -1.7966, -0.8873], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7069,  0.7652, -1.7966, -0.8873], grad_fn=<ViewBackward0>),), Output: tensor([-0.9363,  0.6442, -0.9465, -0.7101], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9363,  0.6442, -0.9465, -0.7101], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1517, -1.0344, -0.6486, -1.0719], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1517, -1.0344, -0.6486, -1.0719], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8183, -0.7757, -0.5707, -0.7902], grad_fn=<TanhBackward0>),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7413], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.4980, -0.6736, -1.8456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.4980, -0.6736, -1.8456], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9048, -0.5873, -0.9513], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3050, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3050, -0.7148,  1.1210, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.6137,  0.8079, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3446, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3446, -0.9916, -2.8089, -4.1517], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7581, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7581, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2873, -0.6808,  0.8476, -1.1107], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2873, -0.6808,  0.8476, -1.1107], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5920,  0.6898, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5920,  0.6898, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8113], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8898, -0.5868, -2.1195], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8898, -0.5868, -2.1195], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7113, -0.5276, -0.9716], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6864, -0.8985, -1.7331,  0.1832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6864, -0.8985, -1.7331,  0.1832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5957, -0.7156, -0.9394,  0.1812], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5957, -0.7156, -0.9394,  0.1812], grad_fn=<TanhBackward0>),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7059,  0.7695, -1.7971, -0.8900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7059,  0.7695, -1.7971, -0.8900], grad_fn=<ViewBackward0>),), Output: tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9361,  0.6466, -0.9465, -0.7114], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1524, -1.0354, -0.6603, -1.0715], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1524, -1.0354, -0.6603, -1.0715], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8185, -0.7761, -0.5786, -0.7900], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8185, -0.7761, -0.5786, -0.7900], grad_fn=<TanhBackward0>),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5054, -0.6728, -1.8468], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9061, -0.5868, -0.9514], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3061, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3061, -0.7106,  1.1241, -0.5832], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.6110,  0.8090, -0.5250], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.6110,  0.8090, -0.5250], grad_fn=<TanhBackward0>),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9885], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3443, -1.0035, -2.8085, -4.1547], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3443, -1.0035, -2.8085, -4.1547], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7631, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7631, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6747,  0.8524, -1.1103], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6747,  0.8524, -1.1103], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5881,  0.6923, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8195], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2305,  0.8886, -0.5833, -2.1210], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2305,  0.8886, -0.5833, -2.1210], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7107, -0.5250, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7107, -0.5250, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6888, -0.8991, -1.7348,  0.1863], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6888, -0.8991, -1.7348,  0.1863], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5972, -0.7158, -0.9396,  0.1842], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5972, -0.7158, -0.9396,  0.1842], grad_fn=<TanhBackward0>),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0739], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7050,  0.7734, -1.7975, -0.8925], grad_fn=<ViewBackward0>),), Output: tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9360,  0.6489, -0.9466, -0.7126], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1530, -1.0363, -0.6713, -1.0712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1530, -1.0363, -0.6713, -1.0712], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8188, -0.7764, -0.5858, -0.7899], grad_fn=<TanhBackward0>),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5124, -0.6721, -1.8479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5124, -0.6721, -1.8479], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9074, -0.5864, -0.9516], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9074, -0.5864, -0.9516], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3071, -0.7066,  1.1270, -0.5822], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3071, -0.7066,  1.1270, -0.5822], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.6086,  0.8100, -0.5242], grad_fn=<TanhBackward0>),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([0.9953], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3439, -1.0147, -2.8081, -4.1576], grad_fn=<ViewBackward0>),), Output: tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9818, -0.7677, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6690,  0.8568, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6690,  0.8568, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5843,  0.6946, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5843,  0.6946, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8871, -0.5795, -2.1225], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8871, -0.5795, -2.1225], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7100, -0.5223, -0.9717], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7100, -0.5223, -0.9717], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6914, -0.8996, -1.7361,  0.1896], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6914, -0.8996, -1.7361,  0.1896], grad_fn=<ViewBackward0>),), Output: tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.5989, -0.7161, -0.9398,  0.1873], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7041,  0.7772, -1.7979, -0.8948], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7041,  0.7772, -1.7979, -0.8948], grad_fn=<ViewBackward0>),), Output: tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9359,  0.6511, -0.9466, -0.7138], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1537, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1537, -1.0371, -0.6817, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8190, -0.7767, -0.5926, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8190, -0.7767, -0.5926, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7777], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7545, -1.5190, -0.6714, -1.8490], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9085, -0.5859, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.7029,  1.1296, -0.5812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.7029,  1.1296, -0.5812], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.6062,  0.8109, -0.5235], grad_fn=<TanhBackward0>),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0017], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3434, -1.0253, -2.8079, -4.1603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3434, -1.0253, -2.8079, -4.1603], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7720, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6636,  0.8609, -1.1096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6636,  0.8609, -1.1096], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5808,  0.6967, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8339], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8856, -0.5756, -2.1239], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8856, -0.5756, -2.1239], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8427,  0.7092, -0.5195, -0.9718], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8427,  0.7092, -0.5195, -0.9718], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6942, -0.9001, -1.7368,  0.1930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6942, -0.9001, -1.7368,  0.1930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6007, -0.7163, -0.9399,  0.1906], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6007, -0.7163, -0.9399,  0.1906], grad_fn=<TanhBackward0>),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0792], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7032,  0.7806, -1.7983, -0.8970], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7032,  0.7806, -1.7983, -0.8970], grad_fn=<ViewBackward0>),), Output: tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9358,  0.6531, -0.9466, -0.7149], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1544, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1544, -1.0378, -0.6915, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8192, -0.7770, -0.5990, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8192, -0.7770, -0.5990, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7882], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7544, -1.5252, -0.6708, -1.8500], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7544, -1.5252, -0.6708, -1.8500], grad_fn=<ViewBackward0>),), Output: tensor([-0.6378, -0.9096, -0.5855, -0.9517], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6378, -0.9096, -0.5855, -0.9517], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3090, -0.6994,  1.1320, -0.5803], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.6040,  0.8117, -0.5229], grad_fn=<TanhBackward0>),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0075], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3428, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3428, -1.0353, -2.8077, -4.1629], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7760, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6586,  0.8648, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6586,  0.8648, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5774,  0.6987, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5774,  0.6987, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8403], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8839, -0.5716, -2.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8839, -0.5716, -2.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7084, -0.5165, -0.9719], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7084, -0.5165, -0.9719], grad_fn=<TanhBackward0>),), Output: tensor([ 0.6971, -0.9006, -1.7371,  0.1966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.6971, -0.9006, -1.7371,  0.1966], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6025, -0.7166, -0.9399,  0.1941], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6025, -0.7166, -0.9399,  0.1941], grad_fn=<TanhBackward0>),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0810], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7024,  0.7839, -1.7985, -0.8991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7024,  0.7839, -1.7985, -0.8991], grad_fn=<ViewBackward0>),), Output: tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9357,  0.6549, -0.9467, -0.7159], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1551, -1.0384, -0.7008, -1.0700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1551, -1.0384, -0.7008, -1.0700], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8194, -0.7773, -0.6049, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8194, -0.7773, -0.6049, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.7981], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7543, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7543, -1.5311, -0.6703, -1.8510], grad_fn=<ViewBackward0>),), Output: tensor([-0.6377, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6377, -0.9106, -0.5852, -0.9518], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3098, -0.6960,  1.1341, -0.5794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3098, -0.6960,  1.1341, -0.5794], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.6018,  0.8124, -0.5223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.6018,  0.8124, -0.5223], grad_fn=<TanhBackward0>),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0128], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3422, -1.0448, -2.8077, -4.1653], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3422, -1.0448, -2.8077, -4.1653], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7798, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6539,  0.8683, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5743,  0.7005, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8461], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8821, -0.5675, -2.1265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8821, -0.5675, -2.1265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7075, -0.5135, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7075, -0.5135, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7001, -0.9012, -1.7370,  0.2003], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7001, -0.9012, -1.7370,  0.2003], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6044, -0.7169, -0.9399,  0.1976], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6044, -0.7169, -0.9399,  0.1976], grad_fn=<TanhBackward0>),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0824], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7016,  0.7869, -1.7988, -0.9011], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7016,  0.7869, -1.7988, -0.9011], grad_fn=<ViewBackward0>),), Output: tensor([-0.9356,  0.6567, -0.9467, -0.7168], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9356,  0.6567, -0.9467, -0.7168], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1558, -1.0390, -0.7095, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8197, -0.7775, -0.6104, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8197, -0.7775, -0.6104, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8072], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7542, -1.5367, -0.6698, -1.8520], grad_fn=<ViewBackward0>),), Output: tensor([-0.6376, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6376, -0.9116, -0.5849, -0.9519], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3105, -0.6929,  1.1361, -0.5787], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3105, -0.6929,  1.1361, -0.5787], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5998,  0.8131, -0.5217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5998,  0.8131, -0.5217], grad_fn=<TanhBackward0>),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3416, -1.0539, -2.8077, -4.1677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3416, -1.0539, -2.8077, -4.1677], grad_fn=<ViewBackward0>),), Output: tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9817, -0.7833, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6494,  0.8716, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5713,  0.7022, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8515], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8802, -0.5632, -2.1277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8802, -0.5632, -2.1277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7065, -0.5104, -0.9720], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7065, -0.5104, -0.9720], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7032, -0.9017, -1.7366,  0.2040], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7032, -0.9017, -1.7366,  0.2040], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6064, -0.7171, -0.9398,  0.2012], grad_fn=<TanhBackward0>),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0833], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7009,  0.7898, -1.7990, -0.9030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7009,  0.7898, -1.7990, -0.9030], grad_fn=<ViewBackward0>),), Output: tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9355,  0.6583, -0.9467, -0.7178], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1565, -1.0395, -0.7177, -1.0694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8199, -0.7777, -0.6155, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7540, -1.5421, -0.6694, -1.8529], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7540, -1.5421, -0.6694, -1.8529], grad_fn=<ViewBackward0>),), Output: tensor([-0.6375, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6375, -0.9125, -0.5846, -0.9520], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3112, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3112, -0.6899,  1.1380, -0.5780], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5979,  0.8137, -0.5212], grad_fn=<TanhBackward0>),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0222], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3409, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3409, -1.0626, -2.8078, -4.1700], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7867, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7867, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6452,  0.8748, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6452,  0.8748, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5684,  0.7038, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8564], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2306,  0.8782, -0.5589, -2.1288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2306,  0.8782, -0.5589, -2.1288], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7055, -0.5072, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7055, -0.5072, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7064, -0.9022, -1.7358,  0.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7064, -0.9022, -1.7358,  0.2079], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6084, -0.7174, -0.9397,  0.2049], grad_fn=<TanhBackward0>),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0839], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.7001,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.7001,  0.7924, -1.7992, -0.9048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9354,  0.6598, -0.9467, -0.7186], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1572, -1.0399, -0.7255, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1572, -1.0399, -0.7255, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8201, -0.7779, -0.6203, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8238], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7538, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7538, -1.5472, -0.6690, -1.8537], grad_fn=<ViewBackward0>),), Output: tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6374, -0.9133, -0.5843, -0.9521], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6870,  1.1396, -0.5774], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6870,  1.1396, -0.5774], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5960,  0.8143, -0.5208], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5960,  0.8143, -0.5208], grad_fn=<TanhBackward0>),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0263], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3402, -1.0709, -2.8081, -4.1721], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3402, -1.0709, -2.8081, -4.1721], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7898, -0.9927, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6412,  0.8777, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5657,  0.7053, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8761, -0.5546, -2.1299], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8761, -0.5546, -2.1299], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7045, -0.5040, -0.9721], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7045, -0.5040, -0.9721], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7096, -0.9028, -1.7348,  0.2118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7096, -0.9028, -1.7348,  0.2118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6105, -0.7177, -0.9396,  0.2087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6105, -0.7177, -0.9396,  0.2087], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6994,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6994,  0.7949, -1.7993, -0.9065], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6612, -0.9467, -0.7194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6612, -0.9467, -0.7194], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1578, -1.0403, -0.7329, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1578, -1.0403, -0.7329, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8203, -0.7780, -0.6248, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8314], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7536, -1.5521, -0.6687, -1.8546], grad_fn=<ViewBackward0>),), Output: tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6373, -0.9141, -0.5841, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6843,  1.1412, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5943,  0.8148, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0301], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3395, -1.0789, -2.8083, -4.1742], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3395, -1.0789, -2.8083, -4.1742], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7928, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6374,  0.8805, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6374,  0.8805, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5631,  0.7067, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5631,  0.7067, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8652], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8740, -0.5502, -2.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8740, -0.5502, -2.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7034, -0.5007, -0.9722], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7034, -0.5007, -0.9722], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7129, -0.9033, -1.7334,  0.2157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7129, -0.9033, -1.7334,  0.2157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6125, -0.7179, -0.9395,  0.2125], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6125, -0.7179, -0.9395,  0.2125], grad_fn=<TanhBackward0>),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0841], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6988,  0.7972, -1.7995, -0.9081], grad_fn=<ViewBackward0>),), Output: tensor([-0.9353,  0.6625, -0.9467, -0.7202], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9353,  0.6625, -0.9467, -0.7202], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1585, -1.0407, -0.7398, -1.0684], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1585, -1.0407, -0.7398, -1.0684], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8205, -0.7781, -0.6291, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8205, -0.7781, -0.6291, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8384], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7533, -1.5568, -0.6685, -1.8554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7533, -1.5568, -0.6685, -1.8554], grad_fn=<ViewBackward0>),), Output: tensor([-0.6371, -0.9149, -0.5840, -0.9522], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6371, -0.9149, -0.5840, -0.9522], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3130, -0.6817,  1.1426, -0.5763], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3130, -0.6817,  1.1426, -0.5763], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5926,  0.8153, -0.5200], grad_fn=<TanhBackward0>),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0335], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3387, -1.0866, -2.8087, -4.1762], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3387, -1.0866, -2.8087, -4.1762], grad_fn=<ViewBackward0>),), Output: tensor([-0.9816, -0.7957, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9816, -0.7957, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6338,  0.8832, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6338,  0.8832, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5607,  0.7080, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8691], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8718, -0.5459, -2.1320], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8718, -0.5459, -2.1320], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7023, -0.4974, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7023, -0.4974, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7162, -0.9039, -1.7319,  0.2197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7162, -0.9039, -1.7319,  0.2197], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6146, -0.7182, -0.9393,  0.2162], grad_fn=<TanhBackward0>),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0837], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6981,  0.7994, -1.7996, -0.9096], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6981,  0.7994, -1.7996, -0.9096], grad_fn=<ViewBackward0>),), Output: tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9352,  0.6637, -0.9468, -0.7210], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1591, -1.0410, -0.7464, -1.0681], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1591, -1.0410, -0.7464, -1.0681], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8208, -0.7783, -0.6330, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8451], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7530, -1.5613, -0.6683, -1.8561], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7530, -1.5613, -0.6683, -1.8561], grad_fn=<ViewBackward0>),), Output: tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6370, -0.9156, -0.5838, -0.9523], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3135, -0.6792,  1.1439, -0.5759], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3135, -0.6792,  1.1439, -0.5759], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5910,  0.8157, -0.5197], grad_fn=<TanhBackward0>),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0366], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3380, -1.0941, -2.8091, -4.1781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3380, -1.0941, -2.8091, -4.1781], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.7984, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6304,  0.8858, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6304,  0.8858, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5584,  0.7093, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2307,  0.8695, -0.5415, -2.1330], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2307,  0.8695, -0.5415, -2.1330], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7011, -0.4941, -0.9723], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7195, -0.9045, -1.7301,  0.2237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7195, -0.9045, -1.7301,  0.2237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6166, -0.7185, -0.9391,  0.2200], grad_fn=<TanhBackward0>),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0832], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6975,  0.8014, -1.7997, -0.9111], grad_fn=<ViewBackward0>),), Output: tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9351,  0.6648, -0.9468, -0.7217], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1597, -1.0412, -0.7527, -1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1597, -1.0412, -0.7527, -1.0679], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8210, -0.7784, -0.6367, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8513], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7527, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7527, -1.5656, -0.6681, -1.8569], grad_fn=<ViewBackward0>),), Output: tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6368, -0.9163, -0.5837, -0.9524], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6769,  1.1451, -0.5756], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5895,  0.8161, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5895,  0.8161, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0395], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3372, -1.1013, -2.8096, -4.1800], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8010, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6272,  0.8882, -1.1085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6272,  0.8882, -1.1085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5561,  0.7105, -0.8035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5561,  0.7105, -0.8035], grad_fn=<TanhBackward0>),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8760], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8673, -0.5371, -2.1339], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8673, -0.5371, -2.1339], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.7000, -0.4908, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.7000, -0.4908, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7228, -0.9050, -1.7282,  0.2277], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7228, -0.9050, -1.7282,  0.2277], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6187, -0.7187, -0.9388,  0.2238], grad_fn=<TanhBackward0>),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0825], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6969,  0.8033, -1.7997, -0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6969,  0.8033, -1.7997, -0.9125], grad_fn=<ViewBackward0>),), Output: tensor([-0.9350,  0.6659, -0.9468, -0.7223], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9350,  0.6659, -0.9468, -0.7223], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1604, -1.0415, -0.7586, -1.0676], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1604, -1.0415, -0.7586, -1.0676], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8212, -0.7785, -0.6402, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7524, -1.5698, -0.6680, -1.8576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7524, -1.5698, -0.6680, -1.8576], grad_fn=<ViewBackward0>),), Output: tensor([-0.6366, -0.9170, -0.5837, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6366, -0.9170, -0.5837, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3143, -0.6746,  1.1462, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3143, -0.6746,  1.1462, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5880,  0.8165, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0421], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3364, -1.1083, -2.8102, -4.1817], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3364, -1.1083, -2.8102, -4.1817], grad_fn=<ViewBackward0>),), Output: tensor([-0.9815, -0.8035, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9815, -0.8035, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2872, -0.6242,  0.8905, -1.1086], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5540,  0.7117, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2308,  0.8649, -0.5328, -2.1348], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2308,  0.8649, -0.5328, -2.1348], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6988, -0.4875, -0.9724], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6988, -0.4875, -0.9724], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7261, -0.9056, -1.7261,  0.2317], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7261, -0.9056, -1.7261,  0.2317], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6207, -0.7190, -0.9386,  0.2276], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6207, -0.7190, -0.9386,  0.2276], grad_fn=<TanhBackward0>),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0816], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6963,  0.8050, -1.7998, -0.9138], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6963,  0.8050, -1.7998, -0.9138], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6668, -0.9468, -0.7230], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1610, -1.0417, -0.7642, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1610, -1.0417, -0.7642, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8214, -0.7786, -0.6435, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7521, -1.5739, -0.6679, -1.8583], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7521, -1.5739, -0.6679, -1.8583], grad_fn=<ViewBackward0>),), Output: tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6364, -0.9176, -0.5836, -0.9525], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6724,  1.1472, -0.5750], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6724,  1.1472, -0.5750], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5866,  0.8168, -0.5190], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5866,  0.8168, -0.5190], grad_fn=<TanhBackward0>),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0444], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3355, -1.1151, -2.8108, -4.1835], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3355, -1.1151, -2.8108, -4.1835], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8058, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6212,  0.8928, -1.1087], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6212,  0.8928, -1.1087], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5520,  0.7128, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8819], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2309,  0.8626, -0.5285, -2.1357], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2309,  0.8626, -0.5285, -2.1357], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8428,  0.6976, -0.4842, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8428,  0.6976, -0.4842, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7294, -0.9062, -1.7239,  0.2356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7294, -0.9062, -1.7239,  0.2356], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6227, -0.7193, -0.9383,  0.2314], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6227, -0.7193, -0.9383,  0.2314], grad_fn=<TanhBackward0>),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0806], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6957,  0.8066, -1.7999, -0.9151], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6957,  0.8066, -1.7999, -0.9151], grad_fn=<ViewBackward0>),), Output: tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9349,  0.6677, -0.9468, -0.7236], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1615, -1.0419, -0.7695, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1615, -1.0419, -0.7695, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8215, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8215, -0.7786, -0.6466, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7517, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7517, -1.5779, -0.6679, -1.8590], grad_fn=<ViewBackward0>),), Output: tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6362, -0.9183, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3149, -0.6704,  1.1481, -0.5748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3149, -0.6704,  1.1481, -0.5748], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5852,  0.8171, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5852,  0.8171, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0466], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3347, -1.1216, -2.8115, -4.1851], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3347, -1.1216, -2.8115, -4.1851], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8081, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6184,  0.8950, -1.1088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6184,  0.8950, -1.1088], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5500,  0.7139, -0.8036], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5500,  0.7139, -0.8036], grad_fn=<TanhBackward0>),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8846], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8602, -0.5242, -2.1365], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8602, -0.5242, -2.1365], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6964, -0.4809, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6964, -0.4809, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7326, -0.9068, -1.7216,  0.2396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7326, -0.9068, -1.7216,  0.2396], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6247, -0.7196, -0.9381,  0.2351], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6247, -0.7196, -0.9381,  0.2351], grad_fn=<TanhBackward0>),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0794], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6952,  0.8082, -1.7999, -0.9163], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6952,  0.8082, -1.7999, -0.9163], grad_fn=<ViewBackward0>),), Output: tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9348,  0.6686, -0.9468, -0.7242], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1621, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1621, -1.0420, -0.7745, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8217, -0.7787, -0.6495, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8729], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7514, -1.5817, -0.6679, -1.8597], grad_fn=<ViewBackward0>),), Output: tensor([-0.6360, -0.9189, -0.5836, -0.9526], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6360, -0.9189, -0.5836, -0.9526], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6684,  1.1490, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5839,  0.8174, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0486], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3339, -1.1281, -2.8123, -4.1867], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3339, -1.1281, -2.8123, -4.1867], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8104, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8104, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6158,  0.8971, -1.1089], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5482,  0.7149, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8870], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2310,  0.8578, -0.5200, -2.1373], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2310,  0.8578, -0.5200, -2.1373], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6951, -0.4777, -0.9725], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7358, -0.9073, -1.7191,  0.2435], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7358, -0.9073, -1.7191,  0.2435], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6266, -0.7198, -0.9378,  0.2388], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6266, -0.7198, -0.9378,  0.2388], grad_fn=<TanhBackward0>),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0782], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6946,  0.8096, -1.8000, -0.9175], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6946,  0.8096, -1.8000, -0.9175], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6694, -0.9468, -0.7247], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6694, -0.9468, -0.7247], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1627, -1.0421, -0.7793, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1627, -1.0421, -0.7793, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8219, -0.7787, -0.6523, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8219, -0.7787, -0.6523, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8775], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7510, -1.5854, -0.6680, -1.8603], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7510, -1.5854, -0.6680, -1.8603], grad_fn=<ViewBackward0>),), Output: tensor([-0.6357, -0.9194, -0.5837, -0.9527], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6357, -0.9194, -0.5837, -0.9527], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6664,  1.1498, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6664,  1.1498, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5826,  0.8177, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5826,  0.8177, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0503], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3330, -1.1343, -2.8131, -4.1883], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3330, -1.1343, -2.8131, -4.1883], grad_fn=<ViewBackward0>),), Output: tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9814, -0.8125, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2871, -0.6132,  0.8992, -1.1091], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2871, -0.6132,  0.8992, -1.1091], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8584, -0.5464,  0.7159, -0.8037], grad_fn=<TanhBackward0>),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8893], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2311,  0.8554, -0.5158, -2.1381], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2311,  0.8554, -0.5158, -2.1381], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6939, -0.4745, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6939, -0.4745, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7390, -0.9079, -1.7166,  0.2473], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7390, -0.9079, -1.7166,  0.2473], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6285, -0.7201, -0.9375,  0.2424], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6285, -0.7201, -0.9375,  0.2424], grad_fn=<TanhBackward0>),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0769], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6941,  0.8109, -1.8001, -0.9186], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6941,  0.8109, -1.8001, -0.9186], grad_fn=<ViewBackward0>),), Output: tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9347,  0.6701, -0.9468, -0.7253], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1632, -1.0422, -0.7838, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1632, -1.0422, -0.7838, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8221, -0.7788, -0.6549, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8820], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7506, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7506, -1.5890, -0.6681, -1.8610], grad_fn=<ViewBackward0>),), Output: tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6355, -0.9200, -0.5837, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6646,  1.1506, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5814,  0.8179, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0520], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3322, -1.1404, -2.8139, -4.1898], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8146, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6108,  0.9013, -1.1093], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6108,  0.9013, -1.1093], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5447,  0.7169, -0.8038], grad_fn=<TanhBackward0>),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8915], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2312,  0.8530, -0.5117, -2.1388], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2312,  0.8530, -0.5117, -2.1388], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6926, -0.4713, -0.9726], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7421, -0.9085, -1.7140,  0.2512], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7421, -0.9085, -1.7140,  0.2512], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6304, -0.7204, -0.9371,  0.2460], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6304, -0.7204, -0.9371,  0.2460], grad_fn=<TanhBackward0>),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0755], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6936,  0.8121, -1.8001, -0.9197], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6936,  0.8121, -1.8001, -0.9197], grad_fn=<ViewBackward0>),), Output: tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9346,  0.6707, -0.9468, -0.7258], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1637, -1.0423, -0.7881, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1637, -1.0423, -0.7881, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8222, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8222, -0.7788, -0.6573, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8862], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7502, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7502, -1.5925, -0.6682, -1.8616], grad_fn=<ViewBackward0>),), Output: tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6353, -0.9205, -0.5838, -0.9528], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6628,  1.1512, -0.5746], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6628,  1.1512, -0.5746], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5802,  0.8182, -0.5187], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5802,  0.8182, -0.5187], grad_fn=<TanhBackward0>),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0534], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3313, -1.1464, -2.8148, -4.1912], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3313, -1.1464, -2.8148, -4.1912], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8166, -0.9928, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8166, -0.9928, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2870, -0.6084,  0.9032, -1.1095], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2870, -0.6084,  0.9032, -1.1095], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5430,  0.7179, -0.8039], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5430,  0.7179, -0.8039], grad_fn=<TanhBackward0>),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8935], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2313,  0.8506, -0.5077, -2.1395], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2313,  0.8506, -0.5077, -2.1395], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8429,  0.6914, -0.4681, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8429,  0.6914, -0.4681, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7452, -0.9090, -1.7113,  0.2549], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7452, -0.9090, -1.7113,  0.2549], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6323, -0.7207, -0.9368,  0.2495], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6323, -0.7207, -0.9368,  0.2495], grad_fn=<TanhBackward0>),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0740], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6931,  0.8132, -1.8002, -0.9208], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6714, -0.9468, -0.7263], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1642, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1642, -1.0424, -0.7921, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8224, -0.7788, -0.6596, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8901], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7498, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7498, -1.5959, -0.6684, -1.8622], grad_fn=<ViewBackward0>),), Output: tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6351, -0.9211, -0.5839, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6611,  1.1519, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5791,  0.8184, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0547], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3305, -1.1522, -2.8158, -4.1926], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3305, -1.1522, -2.8158, -4.1926], grad_fn=<ViewBackward0>),), Output: tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9813, -0.8185, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6062,  0.9052, -1.1097], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5414,  0.7188, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5414,  0.7188, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8954], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8482, -0.5037, -2.1402], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8482, -0.5037, -2.1402], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6901, -0.4650, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6901, -0.4650, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7482, -0.9096, -1.7086,  0.2586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7482, -0.9096, -1.7086,  0.2586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6341, -0.7209, -0.9365,  0.2530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6341, -0.7209, -0.9365,  0.2530], grad_fn=<TanhBackward0>),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0725], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6926,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6926,  0.8143, -1.8002, -0.9218], grad_fn=<ViewBackward0>),), Output: tensor([-0.9345,  0.6719, -0.9468, -0.7267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9345,  0.6719, -0.9468, -0.7267], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1647, -1.0424, -0.7960, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1647, -1.0424, -0.7960, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8226, -0.7789, -0.6618, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8939], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7494, -1.5993, -0.6686, -1.8627], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7494, -1.5993, -0.6686, -1.8627], grad_fn=<ViewBackward0>),), Output: tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6348, -0.9216, -0.5841, -0.9529], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6594,  1.1525, -0.5747], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6594,  1.1525, -0.5747], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5780,  0.8186, -0.5188], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5780,  0.8186, -0.5188], grad_fn=<TanhBackward0>),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0559], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3296, -1.1579, -2.8168, -4.1940], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3296, -1.1579, -2.8168, -4.1940], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8204, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2869, -0.6040,  0.9071, -1.1099], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2869, -0.6040,  0.9071, -1.1099], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5399,  0.7197, -0.8040], grad_fn=<TanhBackward0>),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8972], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2314,  0.8458, -0.4998, -2.1409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2314,  0.8458, -0.4998, -2.1409], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6889, -0.4620, -0.9727], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6889, -0.4620, -0.9727], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7512, -0.9101, -1.7059,  0.2623], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7512, -0.9101, -1.7059,  0.2623], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6359, -0.7212, -0.9361,  0.2564], grad_fn=<TanhBackward0>),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6922,  0.8153, -1.8003, -0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6922,  0.8153, -1.8003, -0.9227], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6725, -0.9468, -0.7272], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1652, -1.0425, -0.7997, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8227, -0.7789, -0.6639, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8227, -0.7789, -0.6639, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.8975], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7490, -1.6025, -0.6689, -1.8633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7490, -1.6025, -0.6689, -1.8633], grad_fn=<ViewBackward0>),), Output: tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6346, -0.9220, -0.5842, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6577,  1.1531, -0.5749], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6577,  1.1531, -0.5749], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5769,  0.8188, -0.5189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5769,  0.8188, -0.5189], grad_fn=<TanhBackward0>),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0570], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3288, -1.1636, -2.8178, -4.1953], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3288, -1.1636, -2.8178, -4.1953], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8222, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.6019,  0.9090, -1.1102], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.6019,  0.9090, -1.1102], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5384,  0.7206, -0.8041], grad_fn=<TanhBackward0>),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.8988], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2316,  0.8434, -0.4960, -2.1416], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2316,  0.8434, -0.4960, -2.1416], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8430,  0.6876, -0.4590, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8430,  0.6876, -0.4590, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7541, -0.9106, -1.7031,  0.2659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7541, -0.9106, -1.7031,  0.2659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6376, -0.7214, -0.9358,  0.2598], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6376, -0.7214, -0.9358,  0.2598], grad_fn=<TanhBackward0>),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6917,  0.8162, -1.8003, -0.9237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6917,  0.8162, -1.8003, -0.9237], grad_fn=<ViewBackward0>),), Output: tensor([-0.9344,  0.6730, -0.9468, -0.7276], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9344,  0.6730, -0.9468, -0.7276], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1656, -1.0425, -0.8032, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1656, -1.0425, -0.8032, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8229, -0.7789, -0.6658, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9009], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7486, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7486, -1.6057, -0.6691, -1.8639], grad_fn=<ViewBackward0>),), Output: tensor([-0.6343, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6343, -0.9225, -0.5844, -0.9530], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6562,  1.1536, -0.5751], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5758,  0.8189, -0.5191], grad_fn=<TanhBackward0>),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0580], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3279, -1.1690, -2.8189, -4.1966], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3279, -1.1690, -2.8189, -4.1966], grad_fn=<ViewBackward0>),), Output: tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9812, -0.8240, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2868, -0.5999,  0.9108, -1.1105], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5370,  0.7215, -0.8042], grad_fn=<TanhBackward0>),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9004], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2317,  0.8411, -0.4922, -2.1422], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2317,  0.8411, -0.4922, -2.1422], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6864, -0.4560, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6864, -0.4560, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7569, -0.9112, -1.7003,  0.2694], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7569, -0.9112, -1.7003,  0.2694], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6393, -0.7217, -0.9354,  0.2631], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6393, -0.7217, -0.9354,  0.2631], grad_fn=<TanhBackward0>),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0679], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6913,  0.8170, -1.8004, -0.9246], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6734, -0.9468, -0.7281], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1661, -1.0425, -0.8065, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1661, -1.0425, -0.8065, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8230, -0.7789, -0.6676, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9042], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7482, -1.6088, -0.6695, -1.8644], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7482, -1.6088, -0.6695, -1.8644], grad_fn=<ViewBackward0>),), Output: tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6341, -0.9230, -0.5846, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6546,  1.1541, -0.5753], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6546,  1.1541, -0.5753], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5748,  0.8191, -0.5192], grad_fn=<TanhBackward0>),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0589], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3271, -1.1744, -2.8201, -4.1979], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3271, -1.1744, -2.8201, -4.1979], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8257, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5980,  0.9127, -1.1108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5980,  0.9127, -1.1108], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5356,  0.7224, -0.8043], grad_fn=<TanhBackward0>),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9019], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2318,  0.8387, -0.4886, -2.1428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2318,  0.8387, -0.4886, -2.1428], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6851, -0.4531, -0.9728], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6851, -0.4531, -0.9728], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7597, -0.9117, -1.6975,  0.2728], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7597, -0.9117, -1.6975,  0.2728], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6409, -0.7219, -0.9351,  0.2663], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6409, -0.7219, -0.9351,  0.2663], grad_fn=<TanhBackward0>),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6908,  0.8178, -1.8005, -0.9254], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6908,  0.8178, -1.8005, -0.9254], grad_fn=<ViewBackward0>),), Output: tensor([-0.9343,  0.6739, -0.9469, -0.7285], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9343,  0.6739, -0.9469, -0.7285], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1665, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1665, -1.0425, -0.8096, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8231, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8231, -0.7789, -0.6694, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9073], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7478, -1.6118, -0.6698, -1.8649], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7478, -1.6118, -0.6698, -1.8649], grad_fn=<ViewBackward0>),), Output: tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6339, -0.9234, -0.5848, -0.9531], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3160, -0.6531,  1.1545, -0.5755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3160, -0.6531,  1.1545, -0.5755], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5738,  0.8193, -0.5194], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3262, -1.1797, -2.8212, -4.1991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3262, -1.1797, -2.8212, -4.1991], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8274, -0.9929, -0.9995], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2867, -0.5961,  0.9145, -1.1111], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2867, -0.5961,  0.9145, -1.1111], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8583, -0.5342,  0.7233, -0.8044], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8583, -0.5342,  0.7233, -0.8044], grad_fn=<TanhBackward0>),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9033], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2319,  0.8363, -0.4850, -2.1434], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2319,  0.8363, -0.4850, -2.1434], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8431,  0.6839, -0.4502, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8431,  0.6839, -0.4502, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7624, -0.9122, -1.6946,  0.2762], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7624, -0.9122, -1.6946,  0.2762], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6425, -0.7222, -0.9347,  0.2694], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6425, -0.7222, -0.9347,  0.2694], grad_fn=<TanhBackward0>),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0648], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6904,  0.8185, -1.8005, -0.9263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6904,  0.8185, -1.8005, -0.9263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9342,  0.6742, -0.9469, -0.7289], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1669, -1.0424, -0.8126, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1669, -1.0424, -0.8126, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8233, -0.7788, -0.6710, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8233, -0.7788, -0.6710, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9103], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7474, -1.6148, -0.6702, -1.8654], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7474, -1.6148, -0.6702, -1.8654], grad_fn=<ViewBackward0>),), Output: tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6336, -0.9239, -0.5851, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3159, -0.6516,  1.1550, -0.5758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3159, -0.6516,  1.1550, -0.5758], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8658, -0.5728,  0.8194, -0.5196], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3254, -1.1849, -2.8224, -4.2003], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3254, -1.1849, -2.8224, -4.2003], grad_fn=<ViewBackward0>),), Output: tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9811, -0.8290, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2866, -0.5942,  0.9162, -1.1114], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2866, -0.5942,  0.9162, -1.1114], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5329,  0.7241, -0.8046], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5329,  0.7241, -0.8046], grad_fn=<TanhBackward0>),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9046], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2320,  0.8340, -0.4815, -2.1440], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2320,  0.8340, -0.4815, -2.1440], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6826, -0.4474, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6826, -0.4474, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7651, -0.9127, -1.6918,  0.2795], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7651, -0.9127, -1.6918,  0.2795], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6441, -0.7224, -0.9344,  0.2725], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6441, -0.7224, -0.9344,  0.2725], grad_fn=<TanhBackward0>),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6900,  0.8191, -1.8006, -0.9271], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6746, -0.9469, -0.7292], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6746, -0.9469, -0.7292], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1673, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1673, -1.0424, -0.8154, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8234, -0.7788, -0.6726, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9131], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7470, -1.6177, -0.6706, -1.8659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7470, -1.6177, -0.6706, -1.8659], grad_fn=<ViewBackward0>),), Output: tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6334, -0.9243, -0.5853, -0.9532], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3158, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3158, -0.6502,  1.1554, -0.5761], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5718,  0.8195, -0.5198], grad_fn=<TanhBackward0>),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0610], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3245, -1.1900, -2.8237, -4.2015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3245, -1.1900, -2.8237, -4.2015], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8306, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5925,  0.9180, -1.1118], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5317,  0.7250, -0.8047], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5317,  0.7250, -0.8047], grad_fn=<TanhBackward0>),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9059], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2321,  0.8317, -0.4781, -2.1445], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2321,  0.8317, -0.4781, -2.1445], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6814, -0.4447, -0.9729], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6814, -0.4447, -0.9729], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7677, -0.9132, -1.6890,  0.2828], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7677, -0.9132, -1.6890,  0.2828], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6456, -0.7227, -0.9340,  0.2755], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6456, -0.7227, -0.9340,  0.2755], grad_fn=<TanhBackward0>),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0617], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6896,  0.8197, -1.8007, -0.9279], grad_fn=<ViewBackward0>),), Output: tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9341,  0.6749, -0.9469, -0.7296], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1677, -1.0423, -0.8181, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8235, -0.7788, -0.6741, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8235, -0.7788, -0.6741, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9158], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7466, -1.6206, -0.6710, -1.8664], grad_fn=<ViewBackward0>),), Output: tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6331, -0.9247, -0.5856, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3157, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3157, -0.6488,  1.1558, -0.5765], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5708,  0.8197, -0.5201], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5708,  0.8197, -0.5201], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3237, -1.1951, -2.8249, -4.2026], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3237, -1.1951, -2.8249, -4.2026], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8321, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2865, -0.5908,  0.9197, -1.1121], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5304,  0.7258, -0.8048], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5304,  0.7258, -0.8048], grad_fn=<TanhBackward0>),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9071], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2323,  0.8294, -0.4747, -2.1451], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2323,  0.8294, -0.4747, -2.1451], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8432,  0.6802, -0.4420, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8432,  0.6802, -0.4420, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7702, -0.9137, -1.6862,  0.2859], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7702, -0.9137, -1.6862,  0.2859], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6470, -0.7229, -0.9337,  0.2784], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6470, -0.7229, -0.9337,  0.2784], grad_fn=<TanhBackward0>),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6892,  0.8203, -1.8008, -0.9286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6892,  0.8203, -1.8008, -0.9286], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6752, -0.9469, -0.7300], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1681, -1.0422, -0.8207, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1681, -1.0422, -0.8207, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8237, -0.7788, -0.6755, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8237, -0.7788, -0.6755, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9184], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7462, -1.6234, -0.6714, -1.8669], grad_fn=<ViewBackward0>),), Output: tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6329, -0.9251, -0.5859, -0.9533], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3156, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3156, -0.6474,  1.1562, -0.5768], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5699,  0.8198, -0.5204], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3229, -1.2000, -2.8262, -4.2037], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3229, -1.2000, -2.8262, -4.2037], grad_fn=<ViewBackward0>),), Output: tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9810, -0.8337, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2864, -0.5891,  0.9215, -1.1125], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5292,  0.7266, -0.8049], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5292,  0.7266, -0.8049], grad_fn=<TanhBackward0>),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9083], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2324,  0.8272, -0.4715, -2.1456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2324,  0.8272, -0.4715, -2.1456], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6789, -0.4394, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7726, -0.9141, -1.6834,  0.2890], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7726, -0.9141, -1.6834,  0.2890], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6485, -0.7231, -0.9333,  0.2812], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6485, -0.7231, -0.9333,  0.2812], grad_fn=<TanhBackward0>),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0587], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6888,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6888,  0.8208, -1.8009, -0.9294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9340,  0.6755, -0.9469, -0.7303], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1684, -1.0421, -0.8231, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1684, -1.0421, -0.8231, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8238, -0.7787, -0.6768, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9209], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7458, -1.6261, -0.6719, -1.8674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7458, -1.6261, -0.6719, -1.8674], grad_fn=<ViewBackward0>),), Output: tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6326, -0.9255, -0.5862, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3155, -0.6460,  1.1565, -0.5772], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3155, -0.6460,  1.1565, -0.5772], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8657, -0.5690,  0.8199, -0.5206], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8657, -0.5690,  0.8199, -0.5206], grad_fn=<TanhBackward0>),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0625], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3221, -1.2049, -2.8276, -4.2048], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3221, -1.2049, -2.8276, -4.2048], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8351, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5875,  0.9232, -1.1129], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8582, -0.5281,  0.7274, -0.8051], grad_fn=<TanhBackward0>),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9094], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2325,  0.8249, -0.4683, -2.1461], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2325,  0.8249, -0.4683, -2.1461], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8433,  0.6777, -0.4368, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8433,  0.6777, -0.4368, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7750, -0.9146, -1.6807,  0.2920], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7750, -0.9146, -1.6807,  0.2920], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6498, -0.7233, -0.9329,  0.2840], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6498, -0.7233, -0.9329,  0.2840], grad_fn=<TanhBackward0>),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0572], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6885,  0.8213, -1.8010, -0.9301], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6885,  0.8213, -1.8010, -0.9301], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6758, -0.9469, -0.7306], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6758, -0.9469, -0.7306], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1688, -1.0420, -0.8255, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1688, -1.0420, -0.8255, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8239, -0.7787, -0.6780, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9233], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7454, -1.6288, -0.6724, -1.8678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7454, -1.6288, -0.6724, -1.8678], grad_fn=<ViewBackward0>),), Output: tensor([-0.6324, -0.9259, -0.5866, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6324, -0.9259, -0.5866, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3154, -0.6447,  1.1568, -0.5776], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3154, -0.6447,  1.1568, -0.5776], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5681,  0.8200, -0.5210], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3212, -1.2097, -2.8289, -4.2058], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3212, -1.2097, -2.8289, -4.2058], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8366, -0.9930, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2863, -0.5859,  0.9249, -1.1132], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2863, -0.5859,  0.9249, -1.1132], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5269,  0.7282, -0.8052], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5269,  0.7282, -0.8052], grad_fn=<TanhBackward0>),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9105], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2327,  0.8227, -0.4652, -2.1466], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2327,  0.8227, -0.4652, -2.1466], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6765, -0.4343, -0.9730], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6765, -0.4343, -0.9730], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7773, -0.9150, -1.6779,  0.2949], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7773, -0.9150, -1.6779,  0.2949], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6512, -0.7235, -0.9326,  0.2867], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6512, -0.7235, -0.9326,  0.2867], grad_fn=<TanhBackward0>),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0558], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6881,  0.8217, -1.8011, -0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6881,  0.8217, -1.8011, -0.9308], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6760, -0.9469, -0.7310], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1691, -1.0419, -0.8277, -1.0656], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1691, -1.0419, -0.8277, -1.0656], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8240, -0.7787, -0.6792, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9255], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7449, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7449, -1.6315, -0.6729, -1.8683], grad_fn=<ViewBackward0>),), Output: tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6321, -0.9263, -0.5869, -0.9534], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3152, -0.6434,  1.1572, -0.5781], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3152, -0.6434,  1.1572, -0.5781], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8656, -0.5672,  0.8201, -0.5213], grad_fn=<TanhBackward0>),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0632], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3204, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3204, -1.2144, -2.8303, -4.2069], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8380, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2862, -0.5844,  0.9266, -1.1136], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2862, -0.5844,  0.9266, -1.1136], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5258,  0.7290, -0.8053], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5258,  0.7290, -0.8053], grad_fn=<TanhBackward0>),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9115], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2328,  0.8205, -0.4622, -2.1471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2328,  0.8205, -0.4622, -2.1471], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6753, -0.4319, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7796, -0.9154, -1.6752,  0.2978], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7796, -0.9154, -1.6752,  0.2978], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6525, -0.7237, -0.9322,  0.2893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6525, -0.7237, -0.9322,  0.2893], grad_fn=<TanhBackward0>),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0543], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6877,  0.8221, -1.8012, -0.9314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6877,  0.8221, -1.8012, -0.9314], grad_fn=<ViewBackward0>),), Output: tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9339,  0.6762, -0.9469, -0.7313], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1694, -1.0418, -0.8297, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1694, -1.0418, -0.8297, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8241, -0.7786, -0.6803, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9277], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7445, -1.6341, -0.6735, -1.8687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7445, -1.6341, -0.6735, -1.8687], grad_fn=<ViewBackward0>),), Output: tensor([-0.6319, -0.9266, -0.5873, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6319, -0.9266, -0.5873, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3150, -0.6421,  1.1575, -0.5786], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3150, -0.6421,  1.1575, -0.5786], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5663,  0.8202, -0.5216], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5663,  0.8202, -0.5216], grad_fn=<TanhBackward0>),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0635], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3196, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3196, -1.2190, -2.8317, -4.2079], grad_fn=<ViewBackward0>),), Output: tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9809, -0.8394, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5829,  0.9282, -1.1140], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5829,  0.9282, -1.1140], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5247,  0.7298, -0.8055], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5247,  0.7298, -0.8055], grad_fn=<TanhBackward0>),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9125], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2330,  0.8183, -0.4593, -2.1476], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2330,  0.8183, -0.4593, -2.1476], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8434,  0.6742, -0.4295, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8434,  0.6742, -0.4295, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7818, -0.9159, -1.6725,  0.3006], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7818, -0.9159, -1.6725,  0.3006], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6537, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6537, -0.7239, -0.9319,  0.2918], grad_fn=<TanhBackward0>),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0529], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6874,  0.8224, -1.8013, -0.9321], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6764, -0.9469, -0.7316], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1697, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1697, -1.0417, -0.8317, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8242, -0.7786, -0.6814, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9298], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7441, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7441, -1.6366, -0.6740, -1.8692], grad_fn=<ViewBackward0>),), Output: tensor([-0.6316, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6316, -0.9270, -0.5876, -0.9535], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3148, -0.6409,  1.1577, -0.5791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3148, -0.6409,  1.1577, -0.5791], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8655, -0.5655,  0.8203, -0.5220], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3188, -1.2236, -2.8331, -4.2088], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3188, -1.2236, -2.8331, -4.2088], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8407, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2861, -0.5814,  0.9299, -1.1145], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5237,  0.7305, -0.8056], grad_fn=<TanhBackward0>),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9134], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2331,  0.8162, -0.4565, -2.1480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2331,  0.8162, -0.4565, -2.1480], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6730, -0.4272, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6730, -0.4272, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7839, -0.9163, -1.6699,  0.3033], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7839, -0.9163, -1.6699,  0.3033], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6550, -0.7241, -0.9315,  0.2943], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6550, -0.7241, -0.9315,  0.2943], grad_fn=<TanhBackward0>),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0516], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6870,  0.8227, -1.8014, -0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6870,  0.8227, -1.8014, -0.9327], grad_fn=<ViewBackward0>),), Output: tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9338,  0.6765, -0.9470, -0.7319], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1700, -1.0416, -0.8336, -1.0657], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1700, -1.0416, -0.8336, -1.0657], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8243, -0.7785, -0.6824, -0.7878], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8243, -0.7785, -0.6824, -0.7878], grad_fn=<TanhBackward0>),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9318], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7437, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7437, -1.6391, -0.6746, -1.8696], grad_fn=<ViewBackward0>),), Output: tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6314, -0.9274, -0.5880, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3146, -0.6396,  1.1580, -0.5796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3146, -0.6396,  1.1580, -0.5796], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5646,  0.8204, -0.5224], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5646,  0.8204, -0.5224], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3181, -1.2281, -2.8346, -4.2098], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3181, -1.2281, -2.8346, -4.2098], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8420, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2860, -0.5800,  0.9315, -1.1149], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5226,  0.7313, -0.8058], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5226,  0.7313, -0.8058], grad_fn=<TanhBackward0>),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9143], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2333,  0.8141, -0.4537, -2.1485], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2333,  0.8141, -0.4537, -2.1485], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8435,  0.6718, -0.4249, -0.9731], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8435,  0.6718, -0.4249, -0.9731], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7860, -0.9166, -1.6673,  0.3059], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7860, -0.9166, -1.6673,  0.3059], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6561, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6561, -0.7243, -0.9312,  0.2967], grad_fn=<TanhBackward0>),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0502], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6867,  0.8230, -1.8016, -0.9333], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6867,  0.8230, -1.8016, -0.9333], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6767, -0.9470, -0.7322], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1703, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1703, -1.0414, -0.8354, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8244, -0.7784, -0.6834, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8244, -0.7784, -0.6834, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9338], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7433, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7433, -1.6416, -0.6752, -1.8700], grad_fn=<ViewBackward0>),), Output: tensor([-0.6311, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6311, -0.9277, -0.5884, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3144, -0.6384,  1.1583, -0.5801], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8654, -0.5638,  0.8205, -0.5228], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3173, -1.2325, -2.8361, -4.2108], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3173, -1.2325, -2.8361, -4.2108], grad_fn=<ViewBackward0>),), Output: tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9808, -0.8433, -0.9931, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2859, -0.5786,  0.9332, -1.1153], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8581, -0.5216,  0.7321, -0.8059], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8581, -0.5216,  0.7321, -0.8059], grad_fn=<TanhBackward0>),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9152], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2334,  0.8120, -0.4510, -2.1489], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2334,  0.8120, -0.4510, -2.1489], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6707, -0.4227, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6707, -0.4227, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7880, -0.9170, -1.6647,  0.3085], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7880, -0.9170, -1.6647,  0.3085], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6573, -0.7245, -0.9308,  0.2991], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6573, -0.7245, -0.9308,  0.2991], grad_fn=<TanhBackward0>),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0489], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6864,  0.8232, -1.8017, -0.9339], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6864,  0.8232, -1.8017, -0.9339], grad_fn=<ViewBackward0>),), Output: tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9337,  0.6768, -0.9470, -0.7324], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1706, -1.0413, -0.8371, -1.0658], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1706, -1.0413, -0.8371, -1.0658], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8245, -0.7784, -0.6843, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7429, -1.6440, -0.6758, -1.8704], grad_fn=<ViewBackward0>),), Output: tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6309, -0.9280, -0.5888, -0.9536], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3141, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3141, -0.6372,  1.1585, -0.5807], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5630,  0.8206, -0.5232], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3165, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3165, -1.2369, -2.8375, -4.2117], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8446, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5772,  0.9348, -1.1157], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5772,  0.9348, -1.1157], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5206,  0.7328, -0.8061], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5206,  0.7328, -0.8061], grad_fn=<TanhBackward0>),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9160], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2336,  0.8100, -0.4484, -2.1494], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2336,  0.8100, -0.4484, -2.1494], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8436,  0.6696, -0.4206, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8436,  0.6696, -0.4206, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7900, -0.9174, -1.6622,  0.3110], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7900, -0.9174, -1.6622,  0.3110], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6584, -0.7246, -0.9305,  0.3013], grad_fn=<TanhBackward0>),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0477], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6861,  0.8235, -1.8018, -0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6861,  0.8235, -1.8018, -0.9345], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6769, -0.9470, -0.7327], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1709, -1.0411, -0.8387, -1.0659], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7783, -0.6851, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9374], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7425, -1.6464, -0.6764, -1.8708], grad_fn=<ViewBackward0>),), Output: tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6307, -0.9284, -0.5892, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3139, -0.6360,  1.1588, -0.5813], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8653, -0.5622,  0.8206, -0.5236], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3157, -1.2412, -2.8391, -4.2126], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3157, -1.2412, -2.8391, -4.2126], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8458, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2858, -0.5759,  0.9364, -1.1162], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5197,  0.7336, -0.8062], grad_fn=<TanhBackward0>),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9169], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2337,  0.8080, -0.4459, -2.1498], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2337,  0.8080, -0.4459, -2.1498], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6685, -0.4185, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6685, -0.4185, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7919, -0.9177, -1.6597,  0.3134], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7919, -0.9177, -1.6597,  0.3134], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6595, -0.7248, -0.9302,  0.3035], grad_fn=<TanhBackward0>),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0464], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6857,  0.8237, -1.8020, -0.9351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6857,  0.8237, -1.8020, -0.9351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7330], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7330], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1711, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1711, -1.0409, -0.8403, -1.0660], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8246, -0.7782, -0.6860, -0.7879], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8246, -0.7782, -0.6860, -0.7879], grad_fn=<TanhBackward0>),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7421, -1.6487, -0.6771, -1.8712], grad_fn=<ViewBackward0>),), Output: tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6304, -0.9287, -0.5896, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3136, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3136, -0.6348,  1.1590, -0.5819], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8652, -0.5613,  0.8207, -0.5240], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8652, -0.5613,  0.8207, -0.5240], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3150, -1.2455, -2.8406, -4.2135], grad_fn=<ViewBackward0>),), Output: tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9807, -0.8470, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2857, -0.5746,  0.9380, -1.1166], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5187,  0.7343, -0.8064], grad_fn=<TanhBackward0>),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9177], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2339,  0.8060, -0.4434, -2.1502], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2339,  0.8060, -0.4434, -2.1502], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8437,  0.6674, -0.4165, -0.9732], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8437,  0.6674, -0.4165, -0.9732], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7937, -0.9180, -1.6572,  0.3158], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7937, -0.9180, -1.6572,  0.3158], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6605, -0.7250, -0.9298,  0.3057], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6605, -0.7250, -0.9298,  0.3057], grad_fn=<TanhBackward0>),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0452], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6854,  0.8238, -1.8021, -0.9356], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6854,  0.8238, -1.8021, -0.9356], grad_fn=<ViewBackward0>),), Output: tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9336,  0.6771, -0.9470, -0.7332], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1714, -1.0407, -0.8418, -1.0661], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1714, -1.0407, -0.8418, -1.0661], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8247, -0.7782, -0.6867, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7417, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7417, -1.6510, -0.6777, -1.8716], grad_fn=<ViewBackward0>),), Output: tensor([-0.6302, -0.9290, -0.5901, -0.9537], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6302, -0.9290, -0.5901, -0.9537], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3134, -0.6336,  1.1592, -0.5825], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3134, -0.6336,  1.1592, -0.5825], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5605,  0.8208, -0.5245], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5605,  0.8208, -0.5245], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3142, -1.2497, -2.8421, -4.2143], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3142, -1.2497, -2.8421, -4.2143], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8482, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5733,  0.9396, -1.1171], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5178,  0.7350, -0.8066], grad_fn=<TanhBackward0>),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9185], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2341,  0.8040, -0.4410, -2.1506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2341,  0.8040, -0.4410, -2.1506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6663, -0.4145, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6663, -0.4145, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7955, -0.9183, -1.6548,  0.3180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7955, -0.9183, -1.6548,  0.3180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6615, -0.7251, -0.9295,  0.3077], grad_fn=<TanhBackward0>),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0441], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6851,  0.8240, -1.8023, -0.9362], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6851,  0.8240, -1.8023, -0.9362], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6772, -0.9470, -0.7335], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1716, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1716, -1.0406, -0.8431, -1.0662], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8248, -0.7781, -0.6875, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7413, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7413, -1.6533, -0.6784, -1.8720], grad_fn=<ViewBackward0>),), Output: tensor([-0.6299, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6299, -0.9293, -0.5905, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3131, -0.6325,  1.1594, -0.5831], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8651, -0.5598,  0.8208, -0.5249], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8651, -0.5598,  0.8208, -0.5249], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3135, -1.2538, -2.8437, -4.2152], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3135, -1.2538, -2.8437, -4.2152], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8493, -0.9932, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2856, -0.5721,  0.9411, -1.1175], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2856, -0.5721,  0.9411, -1.1175], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8580, -0.5169,  0.7358, -0.8067], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8580, -0.5169,  0.7358, -0.8067], grad_fn=<TanhBackward0>),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9192], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2342,  0.8021, -0.4387, -2.1510], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2342,  0.8021, -0.4387, -2.1510], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6652, -0.4126, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6652, -0.4126, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7973, -0.9186, -1.6524,  0.3203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7973, -0.9186, -1.6524,  0.3203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6625, -0.7252, -0.9292,  0.3097], grad_fn=<TanhBackward0>),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0429], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6848,  0.8241, -1.8025, -0.9367], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6848,  0.8241, -1.8025, -0.9367], grad_fn=<ViewBackward0>),), Output: tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9335,  0.6773, -0.9471, -0.7337], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1719, -1.0404, -0.8445, -1.0663], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1719, -1.0404, -0.8445, -1.0663], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8249, -0.7780, -0.6882, -0.7880], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8249, -0.7780, -0.6882, -0.7880], grad_fn=<TanhBackward0>),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7409, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7409, -1.6555, -0.6791, -1.8724], grad_fn=<ViewBackward0>),), Output: tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6297, -0.9296, -0.5909, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3128, -0.6313,  1.1596, -0.5837], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3128, -0.6313,  1.1596, -0.5837], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8650, -0.5590,  0.8209, -0.5254], grad_fn=<TanhBackward0>),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0645], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3127, -1.2579, -2.8452, -4.2160], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3127, -1.2579, -2.8452, -4.2160], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8505, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2855, -0.5708,  0.9427, -1.1180], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2855, -0.5708,  0.9427, -1.1180], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5160,  0.7365, -0.8069], grad_fn=<TanhBackward0>),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9199], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2344,  0.8001, -0.4365, -2.1514], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2344,  0.8001, -0.4365, -2.1514], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8438,  0.6641, -0.4107, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8438,  0.6641, -0.4107, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.7989, -0.9189, -1.6501,  0.3224], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.7989, -0.9189, -1.6501,  0.3224], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6634, -0.7254, -0.9289,  0.3117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6634, -0.7254, -0.9289,  0.3117], grad_fn=<TanhBackward0>),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0418], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6845,  0.8242, -1.8026, -0.9372], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6845,  0.8242, -1.8026, -0.9372], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6773, -0.9471, -0.7339], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6773, -0.9471, -0.7339], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1721, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1721, -1.0402, -0.8457, -1.0664], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7780, -0.6888, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9454], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7405, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7405, -1.6577, -0.6798, -1.8727], grad_fn=<ViewBackward0>),), Output: tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6295, -0.9299, -0.5914, -0.9538], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3125, -0.6302,  1.1598, -0.5844], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3125, -0.6302,  1.1598, -0.5844], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8649, -0.5582,  0.8210, -0.5258], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8649, -0.5582,  0.8210, -0.5258], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3120, -1.2619, -2.8468, -4.2168], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3120, -1.2619, -2.8468, -4.2168], grad_fn=<ViewBackward0>),), Output: tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9806, -0.8516, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2854, -0.5696,  0.9443, -1.1185], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2854, -0.5696,  0.9443, -1.1185], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5151,  0.7372, -0.8070], grad_fn=<TanhBackward0>),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9207], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2345,  0.7983, -0.4343, -2.1517], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2345,  0.7983, -0.4343, -2.1517], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6631, -0.4089, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6631, -0.4089, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8006, -0.9192, -1.6478,  0.3245], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8006, -0.9192, -1.6478,  0.3245], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6644, -0.7255, -0.9285,  0.3136], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6644, -0.7255, -0.9285,  0.3136], grad_fn=<TanhBackward0>),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0408], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6843,  0.8243, -1.8028, -0.9377], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6843,  0.8243, -1.8028, -0.9377], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7342], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1723, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1723, -1.0400, -0.8469, -1.0665], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8250, -0.7779, -0.6894, -0.7881], grad_fn=<TanhBackward0>),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7401, -1.6598, -0.6805, -1.8731], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7401, -1.6598, -0.6805, -1.8731], grad_fn=<ViewBackward0>),), Output: tensor([-0.6292, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6292, -0.9302, -0.5919, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3122, -0.6291,  1.1600, -0.5850], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3122, -0.6291,  1.1600, -0.5850], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5574,  0.8210, -0.5263], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5574,  0.8210, -0.5263], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3113, -1.2659, -2.8484, -4.2176], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3113, -1.2659, -2.8484, -4.2176], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8527, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5685,  0.9458, -1.1189], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5142,  0.7379, -0.8072], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5142,  0.7379, -0.8072], grad_fn=<TanhBackward0>),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2347,  0.7964, -0.4321, -2.1521], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2347,  0.7964, -0.4321, -2.1521], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8439,  0.6620, -0.4071, -0.9733], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8439,  0.6620, -0.4071, -0.9733], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8021, -0.9194, -1.6455,  0.3265], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8021, -0.9194, -1.6455,  0.3265], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6652, -0.7256, -0.9282,  0.3154], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6652, -0.7256, -0.9282,  0.3154], grad_fn=<TanhBackward0>),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0397], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6840,  0.8243, -1.8030, -0.9382], grad_fn=<ViewBackward0>),), Output: tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9334,  0.6774, -0.9471, -0.7344], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1726, -1.0397, -0.8480, -1.0666], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1726, -1.0397, -0.8480, -1.0666], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8251, -0.7778, -0.6900, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9482], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7398, -1.6620, -0.6812, -1.8734], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7398, -1.6620, -0.6812, -1.8734], grad_fn=<ViewBackward0>),), Output: tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6290, -0.9305, -0.5923, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3119, -0.6280,  1.1601, -0.5857], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3119, -0.6280,  1.1601, -0.5857], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8648, -0.5567,  0.8211, -0.5268], grad_fn=<TanhBackward0>),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0644], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3105, -1.2698, -2.8500, -4.2184], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3105, -1.2698, -2.8500, -4.2184], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8537, -0.9933, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2853, -0.5673,  0.9473, -1.1194], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5134,  0.7386, -0.8074], grad_fn=<TanhBackward0>),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9220], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2349,  0.7946, -0.4301, -2.1525], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2349,  0.7946, -0.4301, -2.1525], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6610, -0.4054, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6610, -0.4054, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8037, -0.9197, -1.6433,  0.3285], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8037, -0.9197, -1.6433,  0.3285], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6661, -0.7257, -0.9279,  0.3172], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6661, -0.7257, -0.9279,  0.3172], grad_fn=<TanhBackward0>),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0387], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6837,  0.8244, -1.8032, -0.9387], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6837,  0.8244, -1.8032, -0.9387], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9471, -0.7346], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1728, -1.0395, -0.8491, -1.0667], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1728, -1.0395, -0.8491, -1.0667], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7777, -0.6906, -0.7882], grad_fn=<TanhBackward0>),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9495], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7394, -1.6640, -0.6820, -1.8738], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7394, -1.6640, -0.6820, -1.8738], grad_fn=<ViewBackward0>),), Output: tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6288, -0.9308, -0.5928, -0.9539], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3116, -0.6269,  1.1603, -0.5864], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3116, -0.6269,  1.1603, -0.5864], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8647, -0.5559,  0.8211, -0.5273], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8647, -0.5559,  0.8211, -0.5273], grad_fn=<TanhBackward0>),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0643], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3098, -1.2736, -2.8516, -4.2192], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3098, -1.2736, -2.8516, -4.2192], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8548, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2852, -0.5662,  0.9488, -1.1199], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8579, -0.5125,  0.7392, -0.8075], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8579, -0.5125,  0.7392, -0.8075], grad_fn=<TanhBackward0>),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2350,  0.7928, -0.4281, -2.1528], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2350,  0.7928, -0.4281, -2.1528], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8440,  0.6600, -0.4037, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8440,  0.6600, -0.4037, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8052, -0.9199, -1.6411,  0.3304], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8052, -0.9199, -1.6411,  0.3304], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6669, -0.7259, -0.9276,  0.3189], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6669, -0.7259, -0.9276,  0.3189], grad_fn=<TanhBackward0>),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0377], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6834,  0.8244, -1.8034, -0.9391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6834,  0.8244, -1.8034, -0.9391], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6774, -0.9472, -0.7348], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1730, -1.0393, -0.8501, -1.0668], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1730, -1.0393, -0.8501, -1.0668], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8252, -0.7776, -0.6911, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9508], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7390, -1.6661, -0.6827, -1.8741], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7390, -1.6661, -0.6827, -1.8741], grad_fn=<ViewBackward0>),), Output: tensor([-0.6285, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6285, -0.9310, -0.5933, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3112, -0.6258,  1.1605, -0.5871], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3112, -0.6258,  1.1605, -0.5871], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8646, -0.5552,  0.8212, -0.5278], grad_fn=<TanhBackward0>),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0642], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3091, -1.2774, -2.8532, -4.2199], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3091, -1.2774, -2.8532, -4.2199], grad_fn=<ViewBackward0>),), Output: tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9805, -0.8558, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5651,  0.9503, -1.1203], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5651,  0.9503, -1.1203], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5117,  0.7399, -0.8077], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5117,  0.7399, -0.8077], grad_fn=<TanhBackward0>),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9234], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2352,  0.7910, -0.4262, -2.1532], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2352,  0.7910, -0.4262, -2.1532], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6590, -0.4021, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6590, -0.4021, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8066, -0.9201, -1.6390,  0.3323], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8066, -0.9201, -1.6390,  0.3323], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6677, -0.7260, -0.9273,  0.3206], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6677, -0.7260, -0.9273,  0.3206], grad_fn=<TanhBackward0>),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0368], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6832,  0.8244, -1.8035, -0.9396], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6832,  0.8244, -1.8035, -0.9396], grad_fn=<ViewBackward0>),), Output: tensor([-0.9333,  0.6775, -0.9472, -0.7350], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9333,  0.6775, -0.9472, -0.7350], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1732, -1.0391, -0.8511, -1.0670], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7775, -0.6916, -0.7883], grad_fn=<TanhBackward0>),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9521], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7386, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7386, -1.6681, -0.6835, -1.8745], grad_fn=<ViewBackward0>),), Output: tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6283, -0.9313, -0.5938, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3109, -0.6248,  1.1606, -0.5878], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8645, -0.5544,  0.8212, -0.5283], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8645, -0.5544,  0.8212, -0.5283], grad_fn=<TanhBackward0>),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0641], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3084, -1.2812, -2.8548, -4.2207], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3084, -1.2812, -2.8548, -4.2207], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8568, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2851, -0.5640,  0.9518, -1.1208], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5109,  0.7406, -0.8079], grad_fn=<TanhBackward0>),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9240], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2354,  0.7893, -0.4243, -2.1535], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2354,  0.7893, -0.4243, -2.1535], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8441,  0.6580, -0.4005, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8441,  0.6580, -0.4005, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8080, -0.9203, -1.6369,  0.3341], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8080, -0.9203, -1.6369,  0.3341], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6685, -0.7261, -0.9270,  0.3222], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6685, -0.7261, -0.9270,  0.3222], grad_fn=<TanhBackward0>),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0359], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6829,  0.8244, -1.8037, -0.9400], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6829,  0.8244, -1.8037, -0.9400], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6775, -0.9472, -0.7352], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6775, -0.9472, -0.7352], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1734, -1.0388, -0.8520, -1.0671], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1734, -1.0388, -0.8520, -1.0671], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8253, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8253, -0.7774, -0.6921, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9533], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7382, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7382, -1.6701, -0.6842, -1.8748], grad_fn=<ViewBackward0>),), Output: tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6281, -0.9316, -0.5943, -0.9540], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3106, -0.6237,  1.1608, -0.5885], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3106, -0.6237,  1.1608, -0.5885], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8644, -0.5537,  0.8213, -0.5288], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8644, -0.5537,  0.8213, -0.5288], grad_fn=<TanhBackward0>),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3077, -1.2849, -2.8565, -4.2214], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3077, -1.2849, -2.8565, -4.2214], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8578, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2850, -0.5629,  0.9533, -1.1213], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5101,  0.7413, -0.8080], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5101,  0.7413, -0.8080], grad_fn=<TanhBackward0>),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9246], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2356,  0.7876, -0.4225, -2.1538], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2356,  0.7876, -0.4225, -2.1538], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6570, -0.3990, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6570, -0.3990, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8093, -0.9205, -1.6348,  0.3358], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8093, -0.9205, -1.6348,  0.3358], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6692, -0.7262, -0.9267,  0.3237], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6692, -0.7262, -0.9267,  0.3237], grad_fn=<TanhBackward0>),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6827,  0.8244, -1.8039, -0.9404], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6827,  0.8244, -1.8039, -0.9404], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7354], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1736, -1.0386, -0.8529, -1.0672], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1736, -1.0386, -0.8529, -1.0672], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8254, -0.7773, -0.6926, -0.7884], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8254, -0.7773, -0.6926, -0.7884], grad_fn=<TanhBackward0>),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9544], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7379, -1.6721, -0.6850, -1.8752], grad_fn=<ViewBackward0>),), Output: tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6279, -0.9318, -0.5948, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3102, -0.6227,  1.1609, -0.5892], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3102, -0.6227,  1.1609, -0.5892], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8643, -0.5530,  0.8213, -0.5293], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8643, -0.5530,  0.8213, -0.5293], grad_fn=<TanhBackward0>),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0639], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3070, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3070, -1.2886, -2.8581, -4.2222], grad_fn=<ViewBackward0>),), Output: tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9804, -0.8588, -0.9934, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5618,  0.9547, -1.1218], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5618,  0.9547, -1.1218], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5093,  0.7419, -0.8082], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5093,  0.7419, -0.8082], grad_fn=<TanhBackward0>),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2357,  0.7859, -0.4207, -2.1542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2357,  0.7859, -0.4207, -2.1542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8442,  0.6561, -0.3975, -0.9734], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8442,  0.6561, -0.3975, -0.9734], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8107, -0.9207, -1.6328,  0.3375], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8107, -0.9207, -1.6328,  0.3375], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6700, -0.7262, -0.9265,  0.3252], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6700, -0.7262, -0.9265,  0.3252], grad_fn=<TanhBackward0>),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6824,  0.8243, -1.8041, -0.9409], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6824,  0.8243, -1.8041, -0.9409], grad_fn=<ViewBackward0>),), Output: tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9332,  0.6774, -0.9472, -0.7356], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1737, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1737, -1.0384, -0.8537, -1.0674], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7772, -0.6930, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7772, -0.6930, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9555], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7375, -1.6740, -0.6858, -1.8755], grad_fn=<ViewBackward0>),), Output: tensor([-0.6276, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6276, -0.9321, -0.5953, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3099, -0.6216,  1.1610, -0.5900], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3099, -0.6216,  1.1610, -0.5900], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5523,  0.8214, -0.5299], grad_fn=<TanhBackward0>),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0637], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3063, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3063, -1.2922, -2.8597, -4.2229], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8597, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2849, -0.5608,  0.9562, -1.1223], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5086,  0.7426, -0.8084], grad_fn=<TanhBackward0>),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2359,  0.7842, -0.4190, -2.1545], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2359,  0.7842, -0.4190, -2.1545], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6551, -0.3961, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6551, -0.3961, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8119, -0.9209, -1.6308,  0.3391], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8119, -0.9209, -1.6308,  0.3391], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6707, -0.7263, -0.9262,  0.3267], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6707, -0.7263, -0.9262,  0.3267], grad_fn=<TanhBackward0>),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0333], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6822,  0.8243, -1.8044, -0.9413], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7358], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1739, -1.0381, -0.8545, -1.0675], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1739, -1.0381, -0.8545, -1.0675], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8255, -0.7771, -0.6934, -0.7885], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8255, -0.7771, -0.6934, -0.7885], grad_fn=<TanhBackward0>),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9566], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7371, -1.6759, -0.6866, -1.8758], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7371, -1.6759, -0.6866, -1.8758], grad_fn=<ViewBackward0>),), Output: tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6274, -0.9323, -0.5958, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3095, -0.6206,  1.1611, -0.5907], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3095, -0.6206,  1.1611, -0.5907], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8642, -0.5516,  0.8214, -0.5304], grad_fn=<TanhBackward0>),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0636], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3057, -1.2958, -2.8614, -4.2236], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8606, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2848, -0.5598,  0.9576, -1.1227], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2848, -0.5598,  0.9576, -1.1227], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8578, -0.5078,  0.7432, -0.8085], grad_fn=<TanhBackward0>),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2361,  0.7826, -0.4173, -2.1548], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2361,  0.7826, -0.4173, -2.1548], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8443,  0.6542, -0.3947, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8443,  0.6542, -0.3947, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8132, -0.9211, -1.6289,  0.3407], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8132, -0.9211, -1.6289,  0.3407], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6713, -0.7264, -0.9259,  0.3281], grad_fn=<TanhBackward0>),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0325], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6819,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6819,  0.8242, -1.8046, -0.9417], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6774, -0.9473, -0.7360], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6774, -0.9473, -0.7360], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1741, -1.0379, -0.8552, -1.0677], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7770, -0.6938, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7770, -0.6938, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9576], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7368, -1.6778, -0.6873, -1.8761], grad_fn=<ViewBackward0>),), Output: tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6272, -0.9326, -0.5963, -0.9541], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3092, -0.6196,  1.1613, -0.5914], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3092, -0.6196,  1.1613, -0.5914], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8641, -0.5509,  0.8215, -0.5309], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8641, -0.5509,  0.8215, -0.5309], grad_fn=<TanhBackward0>),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0634], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3050, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3050, -1.2993, -2.8630, -4.2243], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8615, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5588,  0.9590, -1.1232], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5071,  0.7438, -0.8087], grad_fn=<TanhBackward0>),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2362,  0.7810, -0.4157, -2.1551], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2362,  0.7810, -0.4157, -2.1551], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6533, -0.3933, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6533, -0.3933, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8144, -0.9212, -1.6270,  0.3423], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8144, -0.9212, -1.6270,  0.3423], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6720, -0.7265, -0.9256,  0.3295], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6720, -0.7265, -0.9256,  0.3295], grad_fn=<TanhBackward0>),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6817,  0.8242, -1.8048, -0.9421], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6817,  0.8242, -1.8048, -0.9421], grad_fn=<ViewBackward0>),), Output: tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9331,  0.6773, -0.9473, -0.7362], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1743, -1.0376, -0.8559, -1.0678], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1743, -1.0376, -0.8559, -1.0678], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8256, -0.7769, -0.6941, -0.7886], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8256, -0.7769, -0.6941, -0.7886], grad_fn=<TanhBackward0>),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9586], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7364, -1.6796, -0.6881, -1.8764], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7364, -1.6796, -0.6881, -1.8764], grad_fn=<ViewBackward0>),), Output: tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6270, -0.9328, -0.5968, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3088, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3088, -0.6186,  1.1614, -0.5922], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8640, -0.5502,  0.8215, -0.5315], grad_fn=<TanhBackward0>),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0633], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3043, -1.3027, -2.8647, -4.2249], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3043, -1.3027, -2.8647, -4.2249], grad_fn=<ViewBackward0>),), Output: tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9803, -0.8624, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2847, -0.5578,  0.9604, -1.1237], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5063,  0.7445, -0.8089], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5063,  0.7445, -0.8089], grad_fn=<TanhBackward0>),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2364,  0.7794, -0.4142, -2.1554], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2364,  0.7794, -0.4142, -2.1554], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8444,  0.6523, -0.3920, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8444,  0.6523, -0.3920, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8155, -0.9213, -1.6251,  0.3438], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8155, -0.9213, -1.6251,  0.3438], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6726, -0.7265, -0.9254,  0.3308], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6726, -0.7265, -0.9254,  0.3308], grad_fn=<TanhBackward0>),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0310], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6814,  0.8241, -1.8050, -0.9424], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6814,  0.8241, -1.8050, -0.9424], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6773, -0.9473, -0.7363], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6773, -0.9473, -0.7363], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1744, -1.0374, -0.8566, -1.0680], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1744, -1.0374, -0.8566, -1.0680], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7768, -0.6945, -0.7887], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7768, -0.6945, -0.7887], grad_fn=<TanhBackward0>),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9596], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7360, -1.6814, -0.6889, -1.8767], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7360, -1.6814, -0.6889, -1.8767], grad_fn=<ViewBackward0>),), Output: tensor([-0.6267, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6267, -0.9330, -0.5973, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3085, -0.6176,  1.1615, -0.5930], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8639, -0.5495,  0.8215, -0.5320], grad_fn=<TanhBackward0>),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3037, -1.3062, -2.8663, -4.2256], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3037, -1.3062, -2.8663, -4.2256], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8633, -0.9935, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5568,  0.9618, -1.1242], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5568,  0.9618, -1.1242], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5056,  0.7451, -0.8090], grad_fn=<TanhBackward0>),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9281], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2366,  0.7778, -0.4126, -2.1557], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2366,  0.7778, -0.4126, -2.1557], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6514, -0.3907, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6514, -0.3907, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8166, -0.9215, -1.6233,  0.3452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8166, -0.9215, -1.6233,  0.3452], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6732, -0.7266, -0.9251,  0.3321], grad_fn=<TanhBackward0>),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6812,  0.8240, -1.8052, -0.9428], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6812,  0.8240, -1.8052, -0.9428], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9473, -0.7365], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1746, -1.0371, -0.8572, -1.0682], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1746, -1.0371, -0.8572, -1.0682], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8257, -0.7767, -0.6948, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8257, -0.7767, -0.6948, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9605], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7357, -1.6832, -0.6897, -1.8770], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7357, -1.6832, -0.6897, -1.8770], grad_fn=<ViewBackward0>),), Output: tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6265, -0.9333, -0.5978, -0.9542], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3081, -0.6166,  1.1616, -0.5937], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3081, -0.6166,  1.1616, -0.5937], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8638, -0.5488,  0.8216, -0.5326], grad_fn=<TanhBackward0>),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0629], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3030, -1.3096, -2.8680, -4.2263], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3030, -1.3096, -2.8680, -4.2263], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8642, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2846, -0.5559,  0.9632, -1.1247], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5049,  0.7457, -0.8092], grad_fn=<TanhBackward0>),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9287], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2367,  0.7763, -0.4112, -2.1560], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2367,  0.7763, -0.4112, -2.1560], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8445,  0.6506, -0.3895, -0.9735], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8445,  0.6506, -0.3895, -0.9735], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8177, -0.9216, -1.6215,  0.3466], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8177, -0.9216, -1.6215,  0.3466], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6738, -0.7267, -0.9248,  0.3334], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6738, -0.7267, -0.9248,  0.3334], grad_fn=<TanhBackward0>),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0295], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6810,  0.8239, -1.8054, -0.9432], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6772, -0.9474, -0.7367], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1747, -1.0368, -0.8578, -1.0683], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1747, -1.0368, -0.8578, -1.0683], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7766, -0.6951, -0.7888], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7766, -0.6951, -0.7888], grad_fn=<TanhBackward0>),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9614], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7353, -1.6850, -0.6905, -1.8773], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7353, -1.6850, -0.6905, -1.8773], grad_fn=<ViewBackward0>),), Output: tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6263, -0.9335, -0.5983, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3077, -0.6156,  1.1617, -0.5945], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3077, -0.6156,  1.1617, -0.5945], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8637, -0.5481,  0.8216, -0.5331], grad_fn=<TanhBackward0>),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0628], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3024, -1.3129, -2.8696, -4.2269], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3024, -1.3129, -2.8696, -4.2269], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8650, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2845, -0.5549,  0.9646, -1.1252], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5042,  0.7463, -0.8094], grad_fn=<TanhBackward0>),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9292], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2369,  0.7747, -0.4098, -2.1563], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2369,  0.7747, -0.4098, -2.1563], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6497, -0.3883, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6497, -0.3883, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8188, -0.9217, -1.6197,  0.3480], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8188, -0.9217, -1.6197,  0.3480], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6744, -0.7267, -0.9246,  0.3346], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6744, -0.7267, -0.9246,  0.3346], grad_fn=<TanhBackward0>),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0289], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6808,  0.8238, -1.8057, -0.9435], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6808,  0.8238, -1.8057, -0.9435], grad_fn=<ViewBackward0>),), Output: tensor([-0.9330,  0.6771, -0.9474, -0.7368], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9330,  0.6771, -0.9474, -0.7368], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1749, -1.0366, -0.8583, -1.0685], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8258, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8258, -0.7765, -0.6954, -0.7889], grad_fn=<TanhBackward0>),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9623], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7350, -1.6867, -0.6913, -1.8776], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7350, -1.6867, -0.6913, -1.8776], grad_fn=<ViewBackward0>),), Output: tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6261, -0.9337, -0.5988, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3073, -0.6147,  1.1618, -0.5952], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3073, -0.6147,  1.1618, -0.5952], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8636, -0.5474,  0.8216, -0.5337], grad_fn=<TanhBackward0>),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0626], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3017, -1.3162, -2.8713, -4.2275], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3017, -1.3162, -2.8713, -4.2275], grad_fn=<ViewBackward0>),), Output: tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9802, -0.8658, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5540,  0.9659, -1.1257], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8577, -0.5035,  0.7469, -0.8095], grad_fn=<TanhBackward0>),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9297], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2371,  0.7732, -0.4084, -2.1565], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2371,  0.7732, -0.4084, -2.1565], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8446,  0.6488, -0.3871, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8446,  0.6488, -0.3871, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8198, -0.9218, -1.6180,  0.3493], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8198, -0.9218, -1.6180,  0.3493], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6750, -0.7268, -0.9243,  0.3358], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6750, -0.7268, -0.9243,  0.3358], grad_fn=<TanhBackward0>),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0282], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6805,  0.8237, -1.8059, -0.9439], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6805,  0.8237, -1.8059, -0.9439], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6771, -0.9474, -0.7370], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1750, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1750, -1.0363, -0.8588, -1.0687], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7764, -0.6957, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7764, -0.6957, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9631], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7346, -1.6884, -0.6922, -1.8779], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7346, -1.6884, -0.6922, -1.8779], grad_fn=<ViewBackward0>),), Output: tensor([-0.6259, -0.9339, -0.5994, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6259, -0.9339, -0.5994, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3070, -0.6137,  1.1618, -0.5960], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3070, -0.6137,  1.1618, -0.5960], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8635, -0.5467,  0.8216, -0.5342], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8635, -0.5467,  0.8216, -0.5342], grad_fn=<TanhBackward0>),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0624], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3011, -1.3195, -2.8729, -4.2282], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8667, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2844, -0.5531,  0.9673, -1.1261], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2844, -0.5531,  0.9673, -1.1261], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5028,  0.7475, -0.8097], grad_fn=<TanhBackward0>),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9302], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2372,  0.7718, -0.4070, -2.1568], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2372,  0.7718, -0.4070, -2.1568], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6480, -0.3859, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6480, -0.3859, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8208, -0.9219, -1.6163,  0.3506], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8208, -0.9219, -1.6163,  0.3506], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6755, -0.7268, -0.9241,  0.3369], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6755, -0.7268, -0.9241,  0.3369], grad_fn=<TanhBackward0>),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0276], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6803,  0.8236, -1.8061, -0.9442], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6803,  0.8236, -1.8061, -0.9442], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6770, -0.9474, -0.7372], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1752, -1.0360, -0.8593, -1.0688], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1752, -1.0360, -0.8593, -1.0688], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8259, -0.7763, -0.6959, -0.7890], grad_fn=<TanhBackward0>),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9640], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7343, -1.6901, -0.6930, -1.8782], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7343, -1.6901, -0.6930, -1.8782], grad_fn=<ViewBackward0>),), Output: tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6257, -0.9342, -0.5999, -0.9543], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3066, -0.6127,  1.1619, -0.5968], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3066, -0.6127,  1.1619, -0.5968], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8634, -0.5461,  0.8217, -0.5348], grad_fn=<TanhBackward0>),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0622], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.3004, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.3004, -1.3227, -2.8746, -4.2288], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8675, -0.9936, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5522,  0.9686, -1.1266], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5021,  0.7481, -0.8099], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5021,  0.7481, -0.8099], grad_fn=<TanhBackward0>),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9308], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2374,  0.7703, -0.4057, -2.1571], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2374,  0.7703, -0.4057, -2.1571], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8447,  0.6471, -0.3848, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8447,  0.6471, -0.3848, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8218, -0.9220, -1.6147,  0.3518], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8218, -0.9220, -1.6147,  0.3518], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6760, -0.7268, -0.9238,  0.3380], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6760, -0.7268, -0.9238,  0.3380], grad_fn=<TanhBackward0>),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0270], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6801,  0.8234, -1.8064, -0.9446], grad_fn=<ViewBackward0>),), Output: tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9329,  0.6769, -0.9475, -0.7373], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1753, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1753, -1.0358, -0.8598, -1.0690], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7762, -0.6962, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7762, -0.6962, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9647], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7339, -1.6918, -0.6938, -1.8785], grad_fn=<ViewBackward0>),), Output: tensor([-0.6254, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6254, -0.9344, -0.6004, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3062, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3062, -0.6118,  1.1620, -0.5976], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8633, -0.5454,  0.8217, -0.5353], grad_fn=<TanhBackward0>),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0620], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2998, -1.3259, -2.8762, -4.2294], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2998, -1.3259, -2.8762, -4.2294], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8682, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2843, -0.5513,  0.9699, -1.1271], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5015,  0.7487, -0.8100], grad_fn=<TanhBackward0>),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9313], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2376,  0.7689, -0.4045, -2.1574], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2376,  0.7689, -0.4045, -2.1574], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6463, -0.3838, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6463, -0.3838, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8227, -0.9221, -1.6131,  0.3530], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8227, -0.9221, -1.6131,  0.3530], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6765, -0.7269, -0.9236,  0.3391], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6765, -0.7269, -0.9236,  0.3391], grad_fn=<TanhBackward0>),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0264], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6799,  0.8233, -1.8066, -0.9449], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6799,  0.8233, -1.8066, -0.9449], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6769, -0.9475, -0.7375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6769, -0.9475, -0.7375], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1755, -1.0355, -0.8602, -1.0692], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8260, -0.7761, -0.6964, -0.7891], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8260, -0.7761, -0.6964, -0.7891], grad_fn=<TanhBackward0>),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9655], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7336, -1.6935, -0.6946, -1.8788], grad_fn=<ViewBackward0>),), Output: tensor([-0.6252, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6252, -0.9346, -0.6009, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3058, -0.6109,  1.1621, -0.5983], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3058, -0.6109,  1.1621, -0.5983], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8632, -0.5447,  0.8217, -0.5359], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8632, -0.5447,  0.8217, -0.5359], grad_fn=<TanhBackward0>),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0618], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2992, -1.3290, -2.8779, -4.2300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2992, -1.3290, -2.8779, -4.2300], grad_fn=<ViewBackward0>),), Output: tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9801, -0.8690, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5504,  0.9712, -1.1276], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5008,  0.7492, -0.8102], grad_fn=<TanhBackward0>),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9317], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2378,  0.7675, -0.4032, -2.1576], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2378,  0.7675, -0.4032, -2.1576], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8448,  0.6455, -0.3827, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8448,  0.6455, -0.3827, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8236, -0.9221, -1.6115,  0.3542], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8236, -0.9221, -1.6115,  0.3542], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6770, -0.7269, -0.9234,  0.3401], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6770, -0.7269, -0.9234,  0.3401], grad_fn=<TanhBackward0>),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0258], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6797,  0.8232, -1.8068, -0.9452], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6797,  0.8232, -1.8068, -0.9452], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6768, -0.9475, -0.7376], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1756, -1.0352, -0.8607, -1.0693], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1756, -1.0352, -0.8607, -1.0693], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7760, -0.6966, -0.7892], grad_fn=<TanhBackward0>),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9662], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7332, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7332, -1.6951, -0.6954, -1.8791], grad_fn=<ViewBackward0>),), Output: tensor([-0.6250, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6250, -0.9348, -0.6015, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3055, -0.6099,  1.1621, -0.5991], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3055, -0.6099,  1.1621, -0.5991], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8631, -0.5441,  0.8217, -0.5364], grad_fn=<TanhBackward0>),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0615], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2986, -1.3321, -2.8795, -4.2306], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2986, -1.3321, -2.8795, -4.2306], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8698, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2842, -0.5495,  0.9725, -1.1281], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2842, -0.5495,  0.9725, -1.1281], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.5002,  0.7498, -0.8104], grad_fn=<TanhBackward0>),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9322], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2379,  0.7661, -0.4020, -2.1579], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2379,  0.7661, -0.4020, -2.1579], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6446, -0.3817, -0.9736], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6446, -0.3817, -0.9736], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8245, -0.9222, -1.6099,  0.3553], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8245, -0.9222, -1.6099,  0.3553], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6775, -0.7269, -0.9231,  0.3411], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6775, -0.7269, -0.9231,  0.3411], grad_fn=<TanhBackward0>),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0252], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6795,  0.8230, -1.8071, -0.9456], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6767, -0.9475, -0.7378], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1757, -1.0349, -0.8610, -1.0695], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1757, -1.0349, -0.8610, -1.0695], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7759, -0.6968, -0.7893], grad_fn=<TanhBackward0>),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9670], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7329, -1.6967, -0.6962, -1.8794], grad_fn=<ViewBackward0>),), Output: tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6248, -0.9350, -0.6020, -0.9544], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3051, -0.6090,  1.1622, -0.5999], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3051, -0.6090,  1.1622, -0.5999], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8630, -0.5434,  0.8218, -0.5370], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8630, -0.5434,  0.8218, -0.5370], grad_fn=<TanhBackward0>),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0613], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2979, -1.3352, -2.8812, -4.2312], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2979, -1.3352, -2.8812, -4.2312], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8705, -0.9937, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5487,  0.9738, -1.1286], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4995,  0.7504, -0.8105], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4995,  0.7504, -0.8105], grad_fn=<TanhBackward0>),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9327], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2381,  0.7647, -0.4009, -2.1581], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2381,  0.7647, -0.4009, -2.1581], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8449,  0.6438, -0.3807, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8449,  0.6438, -0.3807, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8253, -0.9222, -1.6084,  0.3564], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8253, -0.9222, -1.6084,  0.3564], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6780, -0.7270, -0.9229,  0.3421], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6780, -0.7270, -0.9229,  0.3421], grad_fn=<TanhBackward0>),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0247], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6793,  0.8229, -1.8073, -0.9459], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6793,  0.8229, -1.8073, -0.9459], grad_fn=<ViewBackward0>),), Output: tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9328,  0.6766, -0.9476, -0.7379], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1759, -1.0347, -0.8614, -1.0697], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8261, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8261, -0.7758, -0.6970, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9676], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7325, -1.6983, -0.6971, -1.8796], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7325, -1.6983, -0.6971, -1.8796], grad_fn=<ViewBackward0>),), Output: tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6246, -0.9352, -0.6025, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3047, -0.6081,  1.1623, -0.6007], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8629, -0.5428,  0.8218, -0.5375], grad_fn=<TanhBackward0>),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0611], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2973, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2973, -1.3382, -2.8828, -4.2318], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8712, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8712, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2841, -0.5478,  0.9750, -1.1290], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2841, -0.5478,  0.9750, -1.1290], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4989,  0.7509, -0.8107], grad_fn=<TanhBackward0>),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9332], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2383,  0.7634, -0.3998, -2.1584], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2383,  0.7634, -0.3998, -2.1584], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6430, -0.3797, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6430, -0.3797, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8261, -0.9223, -1.6069,  0.3575], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8261, -0.9223, -1.6069,  0.3575], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6784, -0.7270, -0.9227,  0.3430], grad_fn=<TanhBackward0>),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0242], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6791,  0.8227, -1.8075, -0.9462], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6765, -0.9476, -0.7381], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1760, -1.0344, -0.8618, -1.0699], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1760, -1.0344, -0.8618, -1.0699], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7757, -0.6972, -0.7894], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7757, -0.6972, -0.7894], grad_fn=<TanhBackward0>),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9683], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7322, -1.6998, -0.6979, -1.8799], grad_fn=<ViewBackward0>),), Output: tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6244, -0.9354, -0.6030, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3043, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3043, -0.6072,  1.1623, -0.6015], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8628, -0.5421,  0.8218, -0.5381], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8628, -0.5421,  0.8218, -0.5381], grad_fn=<TanhBackward0>),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0609], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2967, -1.3412, -2.8844, -4.2323], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2967, -1.3412, -2.8844, -4.2323], grad_fn=<ViewBackward0>),), Output: tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9800, -0.8720, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5470,  0.9763, -1.1295], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8576, -0.4983,  0.7515, -0.8109], grad_fn=<TanhBackward0>),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9336], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2384,  0.7620, -0.3987, -2.1586], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2384,  0.7620, -0.3987, -2.1586], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8450,  0.6423, -0.3788, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8450,  0.6423, -0.3788, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8270, -0.9223, -1.6054,  0.3585], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8270, -0.9223, -1.6054,  0.3585], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6788, -0.7270, -0.9225,  0.3439], grad_fn=<TanhBackward0>),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0237], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6789,  0.8225, -1.8078, -0.9465], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7382], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1761, -1.0341, -0.8621, -1.0701], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1761, -1.0341, -0.8621, -1.0701], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8262, -0.7755, -0.6973, -0.7895], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8262, -0.7755, -0.6973, -0.7895], grad_fn=<TanhBackward0>),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9690], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7319, -1.7013, -0.6987, -1.8802], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7319, -1.7013, -0.6987, -1.8802], grad_fn=<ViewBackward0>),), Output: tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6242, -0.9356, -0.6036, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3039, -0.6063,  1.1624, -0.6022], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3039, -0.6063,  1.1624, -0.6022], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8627, -0.5415,  0.8218, -0.5386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8627, -0.5415,  0.8218, -0.5386], grad_fn=<TanhBackward0>),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0607], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2961, -1.3442, -2.8861, -4.2329], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2961, -1.3442, -2.8861, -4.2329], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8727, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2840, -0.5462,  0.9775, -1.1300], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4977,  0.7520, -0.8110], grad_fn=<TanhBackward0>),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9341], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2386,  0.7607, -0.3976, -2.1589], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2386,  0.7607, -0.3976, -2.1589], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6415, -0.3779, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6415, -0.3779, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8277, -0.9224, -1.6040,  0.3596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8277, -0.9224, -1.6040,  0.3596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6793, -0.7270, -0.9223,  0.3448], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6793, -0.7270, -0.9223,  0.3448], grad_fn=<TanhBackward0>),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0232], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6787,  0.8224, -1.8080, -0.9468], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6787,  0.8224, -1.8080, -0.9468], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6764, -0.9476, -0.7383], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6764, -0.9476, -0.7383], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1763, -1.0338, -0.8624, -1.0703], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7754, -0.6975, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9696], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7315, -1.7029, -0.6995, -1.8804], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7315, -1.7029, -0.6995, -1.8804], grad_fn=<ViewBackward0>),), Output: tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6240, -0.9358, -0.6041, -0.9545], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3036, -0.6054,  1.1624, -0.6030], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8626, -0.5409,  0.8218, -0.5392], grad_fn=<TanhBackward0>),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0604], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2955, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2955, -1.3471, -2.8877, -4.2335], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8734, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5454,  0.9788, -1.1305], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4970,  0.7525, -0.8112], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4970,  0.7525, -0.8112], grad_fn=<TanhBackward0>),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9345], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2388,  0.7594, -0.3966, -2.1591], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2388,  0.7594, -0.3966, -2.1591], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8451,  0.6407, -0.3770, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8451,  0.6407, -0.3770, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8285, -0.9224, -1.6026,  0.3605], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8285, -0.9224, -1.6026,  0.3605], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6797, -0.7270, -0.9221,  0.3457], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6797, -0.7270, -0.9221,  0.3457], grad_fn=<TanhBackward0>),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0227], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6785,  0.8222, -1.8083, -0.9471], grad_fn=<ViewBackward0>),), Output: tensor([-0.9327,  0.6763, -0.9477, -0.7385], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9327,  0.6763, -0.9477, -0.7385], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1764, -1.0335, -0.8627, -1.0704], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1764, -1.0335, -0.8627, -1.0704], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7753, -0.6976, -0.7896], grad_fn=<TanhBackward0>),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9702], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7312, -1.7044, -0.7004, -1.8807], grad_fn=<ViewBackward0>),), Output: tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6238, -0.9360, -0.6046, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3032, -0.6045,  1.1624, -0.6038], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3032, -0.6045,  1.1624, -0.6038], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8625, -0.5402,  0.8218, -0.5397], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8625, -0.5402,  0.8218, -0.5397], grad_fn=<TanhBackward0>),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0602], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2949, -1.3500, -2.8893, -4.2340], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2949, -1.3500, -2.8893, -4.2340], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8741, -0.9938, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2839, -0.5446,  0.9800, -1.1310], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4964,  0.7531, -0.8114], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4964,  0.7531, -0.8114], grad_fn=<TanhBackward0>),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9350], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2389,  0.7581, -0.3956, -2.1594], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2389,  0.7581, -0.3956, -2.1594], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6400, -0.3762, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6400, -0.3762, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8292, -0.9224, -1.6012,  0.3615], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8292, -0.9224, -1.6012,  0.3615], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6801, -0.7270, -0.9218,  0.3465], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6801, -0.7270, -0.9218,  0.3465], grad_fn=<TanhBackward0>),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0223], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6783,  0.8220, -1.8085, -0.9474], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6762, -0.9477, -0.7386], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1765, -1.0332, -0.8629, -1.0706], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1765, -1.0332, -0.8629, -1.0706], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8263, -0.7752, -0.6978, -0.7897], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8263, -0.7752, -0.6978, -0.7897], grad_fn=<TanhBackward0>),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9708], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7309, -1.7058, -0.7012, -1.8810], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7309, -1.7058, -0.7012, -1.8810], grad_fn=<ViewBackward0>),), Output: tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6236, -0.9361, -0.6051, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3028, -0.6036,  1.1625, -0.6046], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3028, -0.6036,  1.1625, -0.6046], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8624, -0.5396,  0.8218, -0.5403], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8624, -0.5396,  0.8218, -0.5403], grad_fn=<TanhBackward0>),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0600], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2943, -1.3529, -2.8910, -4.2345], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2943, -1.3529, -2.8910, -4.2345], grad_fn=<ViewBackward0>),), Output: tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9799, -0.8747, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5438,  0.9812, -1.1314], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5438,  0.9812, -1.1314], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4959,  0.7536, -0.8115], grad_fn=<TanhBackward0>),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9354], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2391,  0.7569, -0.3946, -2.1596], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2391,  0.7569, -0.3946, -2.1596], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6392, -0.3753, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6392, -0.3753, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8299, -0.9224, -1.5998,  0.3624], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8299, -0.9224, -1.5998,  0.3624], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6804, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6804, -0.7270, -0.9216,  0.3473], grad_fn=<TanhBackward0>),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0218], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6781,  0.8218, -1.8087, -0.9477], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6781,  0.8218, -1.8087, -0.9477], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6761, -0.9477, -0.7387], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1766, -1.0329, -0.8632, -1.0708], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1766, -1.0329, -0.8632, -1.0708], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7751, -0.6979, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9713], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7305, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7305, -1.7073, -0.7020, -1.8812], grad_fn=<ViewBackward0>),), Output: tensor([-0.6234, -0.9363, -0.6057, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6234, -0.9363, -0.6057, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3024, -0.6028,  1.1625, -0.6054], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8623, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8623, -0.5390,  0.8219, -0.5409], grad_fn=<TanhBackward0>),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0597], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-2.2938, -1.3557, -2.8926, -4.2351], grad_fn=<ViewBackward0>),), Output: tensor([-0.9798, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9798, -0.8754, -0.9939, -0.9996], grad_fn=<TanhBackward0>),), Output: tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2838, -0.5430,  0.9824, -1.1319], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8575, -0.4953,  0.7541, -0.8117], grad_fn=<TanhBackward0>),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 2.,  3., -1.]),), Output: tensor([0.9358], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([ 1.2393,  0.7556, -0.3937, -2.1598], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.2393,  0.7556, -0.3937, -2.1598], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8452,  0.6385, -0.3745, -0.9737], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([ 0.8452,  0.6385, -0.3745, -0.9737], grad_fn=<TanhBackward0>),), Output: tensor([ 0.8306, -0.9224, -1.5985,  0.3633], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 0.8306, -0.9224, -1.5985,  0.3633], grad_fn=<ViewBackward0>),), Output: tensor([ 0.6808, -0.7270, -0.9214,  0.3481], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.6808, -0.7270, -0.9214,  0.3481], grad_fn=<TanhBackward0>),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 3.0000, -1.0000,  0.5000]),), Output: tensor([-1.0214], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-1.6779,  0.8217, -1.8090, -0.9479], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-1.6779,  0.8217, -1.8090, -0.9479], grad_fn=<ViewBackward0>),), Output: tensor([-0.9326,  0.6760, -0.9477, -0.7388], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.9326,  0.6760, -0.9477, -0.7388], grad_fn=<TanhBackward0>),), Output: tensor([ 1.1767, -1.0326, -0.8634, -1.0710], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.1767, -1.0326, -0.8634, -1.0710], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8264, -0.7750, -0.6980, -0.7898], grad_fn=<TanhBackward0>),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([0.5000, 1.0000, 1.0000]),), Output: tensor([-0.9719], grad_fn=<ViewBackward0>)\n",
      "Layer: Linear(in_features=3, out_features=4, bias=True), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([-0.7302, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([-0.7302, -1.7087, -0.7028, -1.8815], grad_fn=<ViewBackward0>),), Output: tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=4, bias=True), Input: (tensor([-0.6232, -0.9365, -0.6062, -0.9546], grad_fn=<TanhBackward0>),), Output: tensor([ 1.3020, -0.6019,  1.1625, -0.6061], grad_fn=<ViewBackward0>)\n",
      "Layer: Tanh(), Input: (tensor([ 1.3020, -0.6019,  1.1625, -0.6061], grad_fn=<ViewBackward0>),), Output: tensor([ 0.8622, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>)\n",
      "Layer: Linear(in_features=4, out_features=1, bias=True), Input: (tensor([ 0.8622, -0.5384,  0.8219, -0.5414], grad_fn=<TanhBackward0>),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: Sequential(\n",
      "  (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (3): Tanh()\n",
      "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n",
      "Layer: MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=4, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=4, out_features=4, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "), Input: (tensor([ 1.,  1., -1.]),), Output: tensor([1.0595], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Run model training for multiple epochs with PyTorch model\n",
    "epochs = 100\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Initialize the parameters of the PyTorch model with the values from our model\n",
    "# with torch.no_grad():\n",
    "#     for param_tmlp, param_mlp in zip(tmlp.parameters(), mlp_tensor_parameters):\n",
    "#         param_tmlp.copy_(param_mlp)\n",
    "\n",
    "optimizer = optim.SGD(tmlp.parameters(), lr=learning_rate)  # Create an optimizer\n",
    "tmlp.train()\n",
    "loss_rmse_list = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_preds = [tmlp(torch.tensor(i)) for i in x]\n",
    "    y_true = [torch.tensor([y_i.data]) for y_i in y_true]\n",
    "    loss_rmse = rmse(y_true, y_preds)  # Calculate loss\n",
    "    loss_rmse_list.append(loss_rmse.item())\n",
    "    loss_rmse.backward()  # Perform backpropagation\n",
    "    optimizer.step()  # Update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3c92ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_preds_tmlp = [0.9358316659927368, -1.0214028358459473, -0.9719010591506958, 1.059489369392395]\n",
      "y_true = [tensor([1.]), tensor([-1.]), tensor([-1.]), tensor([1.])]\n"
     ]
    }
   ],
   "source": [
    "# Print prediction using PyTorch model\n",
    "print(f\"y_preds_tmlp = {[item.item() for item in y_preds]}\")\n",
    "print(f\"y_true = {[item.data for item in y_true]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a83fc71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_rmse_list = [1.5003691911697388, 0.9619162678718567, 0.7609615325927734, 0.655165433883667, 0.5759391188621521, 0.5016622543334961, 0.43051496148109436, 0.36708199977874756, 0.31330305337905884, 0.2682991623878479, 0.2305852323770523, 0.19882233440876007, 0.17192722856998444, 0.14904920756816864, 0.12952131032943726, 0.11281421035528183, 0.09849988669157028, 0.08622519671916962, 0.07569411396980286, 0.06665531545877457, 0.058893948793411255, 0.05222536623477936, 0.04649071767926216, 0.04155323654413223, 0.03729568049311638, 0.03361736610531807, 0.030432311818003654, 0.027667148038744926, 0.025259433314204216, 0.023156164214015007, 0.021312301978468895, 0.019689971581101418, 0.018256904557347298, 0.01698593981564045, 0.01585417240858078, 0.014842196367681026, 0.013933653943240643, 0.013114718720316887, 0.012373685836791992, 0.011700637638568878, 0.011087149381637573, 0.010526053607463837, 0.010011209174990654, 0.009537411853671074, 0.00910014659166336, 0.0086955726146698, 0.00832032784819603, 0.00797151681035757, 0.00764659745618701, 0.007343349978327751, 0.007059840019792318, 0.006794353015720844, 0.0065453508868813515, 0.0063115074299275875, 0.006091567687690258, 0.005884472280740738, 0.00568923307582736, 0.005504969507455826, 0.00533088855445385, 0.005166247952729464, 0.005010389722883701, 0.0048626987263560295, 0.00472262641415, 0.004589674063026905, 0.004463345743715763, 0.004343234933912754, 0.004228922072798014, 0.004120033700019121, 0.0040162717923521996, 0.003917261958122253, 0.0038227392360568047, 0.0037324270233511925, 0.003646071534603834, 0.0035634422674775124, 0.003484305925667286, 0.003408467397093773, 0.003335739718750119, 0.003265946637839079, 0.003198919352144003, 0.00313448254019022, 0.003072521183639765, 0.0030128881335258484, 0.002955453936010599, 0.002900109626352787, 0.002846744377166033, 0.0027952452655881643, 0.00274552870541811, 0.0026974882930517197, 0.0026510474272072315, 0.0026061353273689747, 0.0025626537390053272, 0.002520540729165077, 0.002479751594364643, 0.0024402074050158262, 0.0024018418043851852, 0.0023646228946745396, 0.0023284698836505413, 0.0022933539003133774, 0.0022592328023165464, 0.0022260479163378477]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over epochs\n",
    "print(f\"loss_rmse_list = {loss_rmse_list}\")\n",
    "plt.plot(range(epochs), loss_rmse_list)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ec98b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berkeley_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
